---
title: 'Quantum Formalism'
subject: 'Physics'
showToc: true
references:
  - book_auletta_etal_2009
  - book_bengtsson_zyczkowski_2017
  - book_bertlmann_friis_2023
  - book_das_2023
  - book_d√ºrr_lazarovici_2020
  - book_griffiths_schroeter_2018
  - book_mcintyre_2023
---

# Linear algebra

## Dirac notation (bra-ket)

Let $V$ be an inner product space over a field $\mathbb{F}$ with dual space $V^*$. In Dirac notation:
- A *ket* $\ket{v}\in V$ denotes a vector representing the state of a quantum system
- A *bra* $\bra{f}\in V^*$ denotes a linear form $f : V \to\mathbb{F}$ and is a covector to $\ket{f}$
- A *bra-ket* $\braket{f|v} := \bra{f}(\ket{v})$ represents an inner product $\braket{\cdot|\cdot}: V\times V \to\mathbb{F}$
- A *ket-bra* $\ket{v}\bra{f}$ defines an outer product $\ket{\cdot}\bra{\cdot} : V\times V \to V$ given by $\ket{v}{f}(\ket{w}) := \ket{v}\braket{f|w}$, which projects the component of $\ket{w}$ along the covector $\bra{f}$ onto the vector $\ket{v}$
- A *ket-ket* $\ket{v}\ket{w} := \ket{v}\otimes\ket{w}$ denotes a tensor product $\otimes: V \times V \to V \otimes V$

Bra-ket properties
- Conjugate symmetry: $\braket{\psi|\phi} = \braket{\phi|\psi}^*$
- Linearity in the second argument: $\braket{\psi | a_1\phi_1 + a_2 \phi_2} = a_1\braket{\psi|\phi_1} + a_2\braket{\psi|\phi_2}$
- Anti-linearity in the first argument: $\braket{a_1\psi_1 + a_2\psi_2 | \phi} = a_1^*\braket{\psi_1|\phi} + a_2^*\braket{\psi_2|\phi}$
- Positive definiteness: $\braket{\psi | \psi} \geq 0$ and $\braket{\psi|\psi} = 0 \iff \ket{\psi} = 0$
- Triangle inequality: $\sqrt{\braket{\psi + \phi | \psi + \phi}} \leq \sqrt{\braket{\psi|\psi}} + \sqrt{\braket{\phi|\phi}}$
- Schwarz inequality: $\left|\braket{\psi|\phi}\right|^2 \leq \braket{\psi|\psi} \braket{\phi|\phi}$
- Orthogonality: $\braket{\psi|\phi} = 0$ if and only if $\psi$ and $\phi$ are orthogonal
- Hermitian adjoint/conjugate: 
$$
\begin{align*}
  \ket{\psi}^\dagger &= \bra{\psi} \\
  \bra{\phi}^\dagger &= \ket{\phi}
\end{align*}
$$

## Hilbert space

<MathBox title='Hilbert space' boxType='definition'>
A *Hilbert space* $\mathcal{H}$ is a complete vector space over a field $\mathbb{F}$ equipped with an inner product $\braket{\cdot|\cdot}:\mathcal{H}\times\mathcal{H}\to\mathbb{F}$. The vector space structure of $\mathcal{H}$ ensures that for all $\ket{\psi},\ket{\varphi}\in\mathcal{H}$ and all scalars $a, b\in\mathbb{F}$, we have

$$
  a\ket{\psi} + b\ket{\varphi} \in\mathcal{H}
$$

For all $\ket{\psi}, \ket{\psi_1},\ket{\psi_2} \in\mathcal{H}$ and $a_1, a_2 \in\mathbb{F}$, the inner product satisfies
- **Positive definitess**: $\braket{\psi | \psi} \geq 0$ and $\braket{\psi|\psi} = 0 \iff \ket{\psi} = 0$
- **Linearity in the second argument:** $\braket{\psi | a_1\phi_1 + a_2 \phi_2} = a_1\braket{\psi|\phi_1} + a_2\braket{\psi|\phi_2}$ .
- **Conjugate symmetry:** $\braket{\psi|\phi} = \braket{\phi|\psi}^*$

By conjugate symmetry, the inner product is anti-linear in the first argument:

$$
  \braket{a_1\psi_1 + a_2\psi_2 | \phi} = a_1^*\braket{\psi_1|\phi} + a_2^*\braket{\psi_2|\phi}
$$

This inner product induces a norm $\norm{\cdot}:\mathcal{H}\to\R$ defined by $\norm{\psi} \mapsto \sqrt{\braket{\psi|\psi}}$. Completeness of $\mathcal{H}$ in the norm $\norm{\cdot}$ means that every Cauchy sequence $(\ket{\psi_n})_{n\in\N} \subset\mathcal{H}$, satisfying

$$
  \forall \epsilon > 0, \exists N\in\N: m,n \geq N \implies \norm{\ket{\psi_m} - \ket{\psi_n}} < \epsilon
$$

converges to an element $\ket{\psi}\in\mathcal{H}$.

A subset $\mathcal{H}' \subset\mathcal{H}$ which is a vector space and inherits the inner product and the norm from $\mathcal{H}$ is called a subspace of $\mathcal{H}$.
</MathBox>

Let $\d^3 \mathbf{x}$ denote the Lebesgue measure in $\R^3$. Then the set of square integrable functions

$$
  \mathcal{L}^2 (\R^3) := \Set{\psi\in\R^3 \to \mathbb{C} : \int_{\R^3} \norm{\psi(\mathbf{x})}^2 \;\d^3 \mathbf{x} < \infty}
$$

with the inner product

$$
  \braket{\psi|\varphi} := \int_{\R^3} \psi^*(\mathbf{x}) \varphi(\mathbf{x}) \;\d^3 \mathbf{x}
$$

is an infinite-dimensional Hilbert space.

<MathBox title='Normed and orthogonal vectors' boxType='definition'>
A vector $\ket{\psi}\in\mathcal{H}$ is *normed* if $\norm{\psi} = 1$. A normed vector is also called a *unit vector*. Two vectors $\ket{\psi},\ket{\varphi}\in\mathcal{H}$ are orthogonal if $\braket{\psi|\varphi} = 0$. The subspace in $\mathcal{H}$ of vector orthogonal to $\ket{\psi}$ is denoted

$$
  \mathcal{H}_{\psi^\perp} := \set{\varphi\in\mathcal{H} | \braket{\psi|\varphi} = 0}
$$
</MathBox>

<MathBox title='Ray' boxType='definition'>
Let $\mathcal{H}$ be a complex Hilbert space. For any normalized vector $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$, the *ray* associated with $\ket{\psi}$ is the set

$$
  S_\psi := \set{e^{i\alpha} \ket{\psi} | \alpha\in\R}
$$

That is, a ray $S_\psi$ consists of all vectors that differ from $\ket{\psi}$ by a global phase factor.
</MathBox>

Define the equivalence relation $\sim$ on the complex Hilbert space $\mathcal{H}$ such that for $\ket{\psi}, \ket{\varphi}\in\mathcal{H}$,

$$
  \ket{\psi}\sim\ket{\varphi} \iff \ket{\varphi} = e^{i\alpha} \ket{\psi},\; \alpha\in\R
$$

This relation satisfies
- **Reflexivity**: $\ket{\psi} = e^{i0}\ket{\psi}$, so $\ket{\psi}\sim\ket{\psi}$
- **Symmetry**: If $\ket{\psi}\sim\ket{\varphi}$, then $\ket{\varphi} = e^{i\alpha} \ket{\psi}$, and its inverse $\ket{\psi} = e^{-i\alpha} \ket{\varphi}$ also holds, implying $\ket{\varphi}\sim\ket{\psi}$

- **Transitivity:** If $\ket{\psi}\sim\ket{\varphi}$ and $\ket{\varphi}\sim\ket{\xi}$, then there exists $\alpha,\beta\in\R$ such that $\ket{\varphi} = e^{i\alpha}$ and $\ket{\xi} = e^{i\beta} \ket{\varphi}$. Thus,

$$
  \ket{\xi} = e^{i\beta} (e^{i\alpha}\ket{\psi}) = e^{i(\alpha + \beta)} \ket{\psi}
$$

so $\ket{\psi}\sim\ket{\varphi}$. 

The equivalence class of $\ket{\psi}\in\mathcal{H}$ under $\sim$ is precisely the ray associated with $\ket{\psi}$, i.e. $[\psi]_\sim = S_\psi$. The projective Hilbert space is the quotient space $\mathcal{PH} = \mathcal{H}/\sim$, which represents the space of quantum states modulo global phase factors.

<MathBox title='Properties of Hilbert spaces' boxType='proposition'>
Let $\mathcal{H}$ be a separable Hilbert space. Then for any $\ket{\psi}, \ket{\phi}\in\mathcal{H}$
1. **Cauchy-Schwarz inequality:**

$$
\begin{equation*}
  |\braket{\psi|\phi}| \leq \norm{\psi} \cdot \norm{\phi}
\tag{\label{equation-152}}
\end{equation*}
$$

2. **Triangular inequality:**

$$
  \norm{\ket{\psi} + \ket{\phi}} \leq \norm{\ket{\psi}} + \norm{\ket{\phi}}
$$

3. **Bessel's inequality:** For any orthonormal basis $\set{\ket{e_j}}$ and $\ket{\psi}\in\mathcal{H}$, define

$$
  \ket{\psi^{(n)}} = \sum_{j=1}^n \ket{e_j} \braket{e_j | \psi}
$$

Then $\norm{\ket{\psi^{(n)}}} \leq \norm{\ket{\psi}}.

<details>
<summary>Proof</summary>

**(1):** For non-zero and unorthogonal vectors $\ket{\psi}, \ket{\phi} \in\mathcal{H}$, define

$$
  a = \alpha \frac{|\braket{\phi|\psi}|}{\braket{\phi|\psi}},\; \alpha \in\R
$$

Then

$$
\begin{align*}
  0 \leq& \norm{\ket{\psi} + a\ket{\phi}}^2 \\
  =& \norm{\ket{\psi}}^2 + 2\alpha |\braket{\phi|\psi}| + \alpha^2 \braket{\phi}
\end{align*}
$$

minimizing over $\alpha$ gives $\eqref{equation-152}$.

**(2):** We have

$$
  \norm{\ket{\psi} + \ket{\phi}}^2 = \norm{\ket{\psi}}^2 + 2\Re(\braket{\psi|\phi}) + \norm{\ket{\phi}}^2
$$

Applying **(1)** yields

$$
  \Re(\braket{\psi|\phi}) \leq |\braket{\psi|\phi}| \leq \norm{\ket{\psi}} \cdot \norm{\phi}^2
$$

implying that

$$
  \norm{\braket{\psi + \phi}}^2 \leq (\norm{\ket{\psi}} + \norm{\ket{\phi}})^2
$$

To shows **(3)**, we note that

$$
  \Braket{\ket{\psi} - \best{\psi} \braket{\psi - \psi^{(N)}}} = 0
$$

Thus,

$$
\begin{align*}
  \norm{\ket{\psi}}^2 =& \norm{\ket{\psi} - \ket{\psi^{(n)}} + \ket{\psi^{(n)}}}^2 \\
  =& \norm{\ket{\psi} - \ket{\psi^{(n)}}}^2 + \norm{\ket{\psi^{(n)}}} \\
  \geq& \norm{\ket{\psi^{(n)}}}
\end{align*}
$$

</details>
</MathBox>

## Basis

<MathBox title='Linear independence, span and basis' boxType='definition'>
Let $I\subseteq\N$ be an index set. A set of vectors $\set{\ket{\varphi_j}}_{j\in I} \subseteq\mathcal{H}$ is *linearly independent* if for every finite subset $\set{\ket{\varphi}_j}_{j=1}^n$ and $a_k \in\mathbb{F}$ with $k=1,\dots,n$

$$
  \sum_{j=1}^n a_i \varphi_i = 0
$$

holds only if all $a_k = 0$.

A Hilbert space $\mathcal{H}$ is finite-dimensional if $\mathcal{H}$ contains at most $n = \dim(\mathcal{H}) < \infty$ linearly independent vectors. Otherwise $\mathcal{H}$ is called infinite-dimensional, i.e. $\dim(\mathcal{H}) = \infty$.

A set of vectors $\set{\ket{\varphi_j}}_{j\in I} \subseteq\mathcal{H}$ *spans* $\mathcal{H}$ if for every vector $\varphi\in\mathcal{H}$, there are $a_j \in\mathbb{F}$ with $j\in I$ such that

$$
  \varphi = \sum_{j\in I} a_j \varphi_j
$$

In this case we write

$$
  \mathcal{H} = \operatorname{span}\set{\ket{\varphi_j}}_{j\in I}
$$

A linearly independent set of vectors $\set{\ket{\varphi_j}}_{j\in I}$ spanning $\mathcal{H}$ is called a *basis* of $\mathcal{H}$ and the vectors $\varphi_j$ of this set are called basis vectors. A basis $\set{\ket{e}_j}_{j\in I}\subset\mathcal{H}$ is orthonormal if

$$
  \braket{e_j|e_k} = \delta_{jk} := \begin{cases}
    0,\quad& j\neq k \\
    1,\quad& j = k
  \end{cases}
$$

The Hilbert space $\mathcal{H}$ is separable if it admits a countable orthonormal basis. In this case, for any $\ket{\psi}\in\mathcal{H}$ there exists a sequence of coefficients $c_j = \braket{e_j | \psi}$ such that the partial sums of the Fourier series

$$
  \ket{\psi_N} := \sum_{j=1}^N c_j \ket{e_j}
$$

converge to $\ket{\psi}$ in the norm of $\mathcal{H}$, i.e.

$$
  \lim_{N\to\infty} \Norm{\ket{\psi} - \ket{\psi_N}} = 0
$$
</MathBox>

Let $\mathcal{H}$ be a Hilbert space with orthonormal basis $\set{\ket{e_j}}$. For $\ket{\psi}, \ket{\varphi} \in\mathcal{H}$ with $\psi_j = \braket{e_j|\psi}$ and $\varphi_j = \braket{e_j|\varphi}$, then

1. $\ket{\psi} = \sum_j \ket{e_j}\braket{e_j|\psi} = \sum_j \psi_j e_j$
2. $\braket{\varphi|\psi} = \sum_j \braket{e_j|\varphi}^* \braket{e_j|\psi} = \sum_j \braket{\varphi|e_j}\braket{e_j|\psi} = \sum_j \varphi_j^* \psi_j$
3. $\norm{\psi}^2 = \sum_j |\braket{e_j|\psi}|^2 = \sum_j |\psi_j|^2$
4. If $\varphi\in\mathcal{H}_{\psi^\perp}$, then $\norm{\varphi + \psi}^2 = \norm{\varphi}^2 + \norm{\psi}^2$

<details>
<summary>Proof</summary>

**(1):** If $\ket{\psi} = \sum_j a_j \ket{e_j}$, then

$$
\begin{align*}
  \braket{e_k|\psi} =& \Braket{e_k | \sum_j a_j e_j} \\
  =& \sum_j a_j \underbrace{\braket{e_k|e_j}}_{\delta_{kj}} \\
  =& a_k
\end{align*}
$$

and thus $\ket{\psi} = \sum_j \ket{e_j}\braket{e_j|\psi}$.

**(2):** From **(1)**, we have

$$
\begin{align*}
  \braket{\varphi} =& \Braket{\sum_j \varphi_j e_j | \sum_k \psi_k e_k} \\
  =& \sum_j \sum_k \varphi_j^* \psi_k \underbrace{\braket{e_j|e_k}}_{\delta_{jk}} \\
  =& \sum_j \varphi_j^* \psi_j = \sum_j \braket{e_j|\varphi}* \braket{e_j|\psi} \\
  =& \sum_j \braket{\varphi|e_j} \braket{e_j|\psi}
\end{align*}
$$

**(3):** Calculating $\norm{\psi}^2$

$$
  \norm{\psi}^2 = \braket{\psi|\psi} = \sum_j \braket{e_j|\psi}^* \braket{e_j|\psi} = \sum_j |\braket{e_j|\psi}|^2
$$

**(4):** For $\varphi\in\mathcal{H}_{\psi^\perp}$, we have

$$
  \braket{\psi|\varphi} = 0 = \braket{\psi|\varphi}^* = \braket{\varphi|\psi}
$$

such that

$$
\begin{align*}
  \norm{\varphi + \psi}^2 =& \braket{\varphi + \psi|\varphi + \psi} \\
  =& \braket{\varphi|\varphi} + \underbrace{\braket{\varphi|\psi}}_{=0} + \underbrace{\braket{\psi|\varphi}}_{=0} + \braket{\psi|\psi} \\
  =& \norm{\varphi}^2 + \norm{\psi}^2
\end{align*}
$$
</details>

### Pauli matrices

The Pauli matrices is a set of three complex $2\times 2$ matrices $\sigma_j \in\mathcal{M}_2 (\mathbb{C})$ defined as

$$
\begin{align*}
  \sigma_1 = \sigma_x = X :=& \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \\
  \sigma_2 = \sigma_y = Y :=& \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix} \\
  \sigma_3 = \sigma_z = Y :=& \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}
\end{align*}
$$

The Pauli matrices can be written in the general form 

$$
  \sigma_j = \begin{bmatrix} 
    \delta_{j3} & \delta_{j1} - i\delta_{j2} \\
    \delta_{j1} + i\delta_{j2} & -\delta_{j3}
  \end{bmatrix}
$$

where $\delta_{jk}$ is the Kronecker delta. The Hermitian adjoint of $\sigma_j$ is

$$
  \sigma_j^\dagger = \begin{bmatrix} 
    \delta_{j3} & \delta_{j1} + i\delta_{j2} \\
    \delta_{j1} - i\delta_{j2} & -\delta_{j3}
  \end{bmatrix}^\top = \sigma^j
$$

showing that the Pauli matrices are Hermitian.

The Paul matrices satisfy
1. $\sigma_j \sigma_k = \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l$ 
2. $[\sigma_j, \sigma_k] = \sigma_j \sigma_k - \sigma_k \sigma_j = 2i\varepsilon_{jkl} \sigma_l$
3. $[\sigma_j, \sigma_k]_+ = \sigma_j \sigma_k + \sigma_k \sigma_j = 2 \delta_{jk} I_2$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  \sigma_j \sigma_k =& \begin{bmatrix} 
    \delta_{j3} & \delta_{j1} - i\delta_{j2} \\
    \delta_{j1} + i\delta_{j2} & -\delta_{j3}
  \end{bmatrix} \cdot \begin{bmatrix} 
    \delta_{k3} & \delta_{k1} - i\delta_{k2} \\
    \delta_{k1} + i\delta_{k2} & -\delta_{k3}
  \end{bmatrix} \\
  =& \begin{bmatrix} 
    \delta_{j1}\delta_{k1} + \delta_{j2}\delta_{k2} + \delta_{j3}\delta_{k3} + i(\delta_{j1}\delta_{k2} - \delta_{j2}\delta_{k1}) & \delta_{j3}\delta_{k1} - \delta_{j1}\delta_{k3} + i(\delta_{j2}\delta_{k3} - \delta_{j3}\delta_{k2}) \\
    \delta_{j1}\delta_{k3} - \delta_{j3}\delta_{k1} + i(\delta_{j2}\delta_{k3} - \delta_{j3}\delta_{k2}) & \delta_{j1}\delta_{k1} + \delta_{j2}\delta_{k2} + \delta_{j3}\delta_{k3} - i(\delta_{j1}\delta_{k2} + \delta_{j2}\delta_{k1})
  \end{bmatrix} \\
  =& \begin{bmatrix}
      \delta_{jk} + i\varepsilon_{jkl}\delta_{l3} & \varepsilon_{jkl}\delta_{l1} - i\varepsilon_{jkl}\delta_{l2} \\
      \varepsilon_{jkl}\delta_{l1} + i\varepsilon_{jkl}\delta_{l2} & \delta_{jk} - i\varepsilon_{jkl}\delta_{l3}
    \end{bmatrix} \\
  =& \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l
\end{align*}
$$

**(2):** Using **(1)**, we have

$$
\begin{align*}
  [\sigma_j, \sigma_k] =& \sigma_j \sigma_k - \sigma_k \sigma_j \\
  =& \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l - (\underbrace{\delta_{kj}}_{=\delta_{kj}} I_2 + i\underbrace{\varepsilon_{kjl}}_{=-\varepsilon_{jkl}} \sigma_l) \\
   = 2i\varepsilon_{jkl} \sigma_l
\end{align*}
$$

**(3):** Using **(1)**, we have

$$
\begin{align*}
  [\sigma_j, \sigma_k]_+ =& \sigma_j \sigma_k + \sigma_k \sigma_j \\
  =& \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l + \underbrace{\delta_{kj}}_{=\delta_{kj}} I_2 + i\underbrace{\varepsilon_{kjl}}_{=-\varepsilon_{jkl}} \sigma_l \\
   = 2 \delta_{jk} I_2
\end{align*}
$$
</details>

From the first property, we see that 

$$
  \sigma_j \sigma_j = \sigma_j^\dagger \sigma_j = \sigma_j \sigma_j^\dagger = \delta_{jj} I_2 = I_2
$$

meaning that the Pauli matrices are unitary. Additionally, for $\mathbf{a},\mathbf{b}\in\R^3$, the Pauli matrices satisfy the identity

$$
\begin{equation*}
  (\mathbf{a}\cdot\boldsymbol{\sigma})(\mathbf{b}\cdot\boldsymbol{\sigma}) = (\mathbf{a}\cdot\mathbf{b})I_2 + i(\mathbf{a} \times \mathbf{b})\cdot\boldsymbol{\sigma} 
\tag{\label{equation-109}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Recall that the cross-product of $\mathbf{a},\mathbf{b}\in\R^3$ can be written $\mathbf{a} \times \mathbf{b} = \sum_{j,k} a_j b_k \varepsilon_{jkl}$. Expanding the left-hand side of $\eqref{equation-109}$ gives

$$
\begin{align*}
  (\mathbf{a}\cdot\boldsymbol{\sigma})(\mathbf{b}\cdot\boldsymbol{\sigma}) =& \sum_{j,k} a_j b_k \sigma_j \sigma_k \\
  =& \sigma_{j,k} a_j b_k (\delta_{jk}\hat{I}_2 + i\varepsilon_{jkl}\sigma_l) \\
  =& \left(\sum_{j,k} a_j b_k \delta_{jk} \right)\hat{I}_2 + i \sum_{j,k} a_j b_k \varepsilon_{jkl} \sigma_l \\
  =& (\mathbf{a}\cdot\mathbf{b})I_2 + i(\mathbf{a} \times \mathbf{b})\cdot\boldsymbol{\sigma}
\end{align*}
$$
</details>

Actions on qubit basis vectors $\ket{0} = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right]$ and $\ket{1} = \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right]$:
- $\boldsymbol{\sigma}_x \ket{0} = \left[\begin{smallmatrix} 0 & 1 \\ 1 & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \ket{1}$
- $\boldsymbol{\sigma}_x \ket{1} = \left[\begin{smallmatrix} 0 & 1 \\ 1 & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \ket{0}$
- $\boldsymbol{\sigma}_y \ket{0} = \left[\begin{smallmatrix} 0 & -i \\ i & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 0 \\ i \end{smallmatrix}\right] = i\ket{1}$
- $\boldsymbol{\sigma}_y \ket{1} = \left[\begin{smallmatrix} 0 & -i \\ i & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \left[\begin{smallmatrix} -i \\ 0 \end{smallmatrix}\right] = -i\ket{0}$
- $\boldsymbol{\sigma}_z \ket{0} = \left[\begin{smallmatrix} 1 & 0 \\ 0 & -1 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \ket{0}$
- $\boldsymbol{\sigma}_z \ket{1} = \left[\begin{smallmatrix} 1 & 0 \\ 0 & -1 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 0 \\ -1 \end{smallmatrix}\right] = -\ket{1}$

<MathBox title='Pauli matrices form a basis for $\mathbb{C}^{2\times 2}$' boxType='proposition'>
The set $\set{I_2, \sigma_x, \sigma_y, \sigma_z}$ is a basis for $\mathcal{M}_2 (\mathbb{C})$, the set of complex $2\times 2$ matrices.

<details>
<summary>Proof</summary>

To show that $\set{\mathbf{I}_2, \boldsymbol{\sigma}_x, \boldsymbol{\sigma}_y, \boldsymbol{\sigma}_z}$ is a basis for $\mathcal{M}_2 (\mathbb{C})$, we need to verify:
1. The set is linearly independent
2. The set spans $\mathcal{M}_2 (\mathbb{C})$, i.e. $\operatorname{span}\set{\mathbf{I}_2, \boldsymbol{\sigma}_x, \boldsymbol{\sigma}_y, \boldsymbol{\sigma}_z} = \mathcal{M}_2 (\mathbb{C})$

To prove linear independence, we must show that for $c_0, c_1, c_2, c_3 \in\mathbb{C}$

$$
  c_0 I_2 + c_1 \sigma_x + c_2 \sigma_y + c_3 \sigma_z = \mathbf{0}_2
$$

implies $c_0 = c_1 = c_2 = c_3 = 0$. This gives the matrix equation

$$
\begin{bmatrix}
  c_0 + c_3 & c_1 - ic_2 \\
  c_1 + ic_2 & c_0 - c_3
\end{bmatrix} = \mathbf{0}_2
$$

and the matrix elements must satisfy

$$
\begin{align*}
  c_0 + c_3 =& 0 \\
  c_1 - ic_2 =& 0 \\
  c_1 + ic_2 =& 0 \\
  c_0 - c_3 =& 0
\end{align*}
$$

The first and fourth equations imply $c_0 = -c_3$ and $c_0 = c_3$, so $c_0 = c_3 = 0$. The second and third equations imply $c_1 = ic_2$ and $c_1 = -ic_2$, so $c_1 = c_2 = 0$.

An arbitrary complex $2\times 2$ matrix $A = \mathcal{M}_2 (\mathbb{C})$ is of the form

$$
  \mathbf{A} = \begin{bmatrix} a_{00} & a_{01} \\ a_{10} & a_{11} \end{bmatrix}
$$

We need to show that $\mathbf{A}$ can be written as a linear combination

$$
  \mathbf{A} = c_0 \mathbf{I}_2 + c_1 \boldsymbol{\sigma}_x + c_2 \boldsymbol{\sigma}_y + c_3 \boldsymbol{\sigma}_z
$$

where $c_0, c_1, c_2, c_3 \in\mathbb{C}$. This gives the matrix equation

$$
\begin{bmatrix}
  c_0 + c_3 & c_1 - ic_2 \\
  c_1 + ic_2 & c_0 - c_3
\end{bmatrix} = \begin{bmatrix} a_{00} & a_{01} \\ a_{10} & a_{11} \end{bmatrix}
$$

and the matrix elements must satisfy

$$
\begin{align*}
  c_0 + c_3 =& a_{00} \\
  c_1 - ic_2 =& a_{01} \\
  c_1 + ic_2 =& a_{10} \\
  c_0 - c_3 =& a_{11}
\end{align*}
$$

Adding the first and fourth equations gives

$$
  2c_0 = a_{00} + a_{11} \implies c_2 = \frac{1}{2}(a_{00} + a_{11})
$$

Adding the second and third equation gives

$$
  2c_1 = a_{01} + a_{10} \implies c_1 = \frac{1}{2}(a_{01} + a_{10})
$$

Subtracting the third equation from the second gives

$$
  -i2 c_2 = a_{01} - a_{10} \implies c_2 = i\frac{1}{2}(a_{01} - a_{10})
$$

Subtracting the first equation from the first gives

$$
  -2c_3 = a_{11} - a_{00} \implies c_3 = \frac{1}{2}(a_{00} - a_{11})
$$

Since $c_j$ exist for all $a_{kl}$, we conclude that any matrix in $\mathcal{M}_2 (\mathbb{C})$ can be written as a linear combination of $\mathbf{I}_2, \boldsymbol{\sigma}_x, \boldsymbol{\sigma}_y, \boldsymbol{\sigma}_z$.
</details>
</MathBox>

## Linear operators

<MathBox title='Linear operator' boxType='definition'>
A linear map $\hat{A}:\mathcal{H}\to\mathcal{H}$ is called an operator on the Hilbert space $\mathcal{H}$. The set of all operators on $\mathcal{H}$ is denoted by $\mathcal{L}(\mathcal{H})$. A linear map $\hat{T}:\mathcal{L}(\mathcal{H}) \to \mathcal{L}(\mathcal{H})$, that is, an operator acting on operators, is called a *super-operator*.

The operator norm of $\hat{A}\in\mathcal{L}(\mathcal{H})$ is given by

$$
\begin{equation*}
  \norm{\hat{A}} := \sup\Set{\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\ket{\psi}} = 1} 
\tag{\label{equation-107}}
\end{equation*}
$$

This norm measures the largest possible stretching effect that $\hat{A}$ can have on unit vectors in $\mathcal{H}$.

An operator $\hat{A}\in\mathcal{L}(\mathcal{H})$ is bounded if $\norm{\hat{A}} < \infty$. The set of bounded operators on $\mathcal{H}$ is denoted $\mathcal{B}(\hat{H})$.
</MathBox>

A linear operator is a mapping between two vector spaces that is preserved under vector addition and scalar multiplication

- Additivity: 
  - $\hat{A}\left(\ket{\phi_1} + \ket{\phi_2} \right) = \hat{A} \ket{\phi_1} + \hat{A} \ket{\phi_2}$
    - $\left( \bra{\psi_1} + \bra{\psi_2} \right)\hat{A} = \bra{\psi_1}\hat{A} + \bra{\psi_2}\hat{A}$
- Scalar multiplication
  - $\hat{A} \ket{a\phi} = a\hat{A} \ket{\phi}$
  - $ \left( \bra{\psi} a \right) \hat{A} = a \bra{\psi} \hat{A}$

Operator properties
1. **Associativity:** $\hat{A}\hat{B}\hat{C} = \hat{A}\left(\hat{B}\hat{C}\right) = (\hat{A}\hat{B})\hat{C}$
2. **Power property:** $\left(\hat{A}\right)^n \left( \hat{A} \right)^m = \left(\hat{A}\right)^{n + m}$
3. **Inner product:** $\braket{\psi|\hat{A}|\phi} = \braket{\psi|\phi'} \in \mathbb{C}$ where $\ket{\phi'} = \hat{A}\ket{\phi}$
4. **Expectation:** $\langle\hat{A}\rangle_\psi = \frac{\braket{\psi | \hat{A} | \psi}}{\braket{\psi|\psi}}$

Bounded operator properties for $\hat{A},\hat{B}\in\mathcal{B}(\mathcal{H})$ and $a\in\mathbb{F}$
1. $\norm{\hat{A}\ket{\psi}} \leq \norm{\hat{A}}\cdot\norm{\ket{\psi}}$
2. $\norm{\hat{A}\hat{B}} \leq \norm{\hat{A}}\cdot\norm{\hat{B}}$
3. $\norm{\hat{A} + \hat{B}} \leq \norm{\hat{A}} + \norm{\hat{B}}$
4. $\norm{ a\hat{A}} = |a|\cdot\norm{\hat{A}}$

<details>
<summary>Proof</summary>

**(1):** Let $\ket{\psi}\in\mathcal{H}$ be nonzero. Then 

$$
  \norm{\frac{\psi}{\lVert\psi}}\rVert = 1
$$

and

$$
\begin{align*}
  \frac{1}{\norm{\psi}} \norm{ \cdot \lVert\hat{A}\psi} =& \norm{\hat{A}\frac{\psi}{\lVert\psi}}\rVert \\
  \leq& \sup\set{\norm{\hat{A}\varphi} : \ket{\varphi}\in\mathcal{H},\norm{\varphi} = 1} = \norm{\hat{A}} 
\end{align*}
$$

Hence,

$$
  \norm{\hat{A}\ket{\psi}} \leq \norm{\hat{A}}\cdot\norm{\ket{\psi}}
$$

**(2):** From the definition $\eqref{equation-107}$ and **(1)**, we have

$$
\begin{align*}
  \norm{\hat{A}\hat{B}} =& \sup\set{\norm{\hat{A}\hat{B}\psi} : \ket{\psi}\in\mathcal{H},\norm{\psi} = 1} \\
  =& \sup\set{\norm{\hat{A}}\cdot\norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  \leq& \norm{\hat{A}} \sup\set{\norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& \norm{\hat{A}}\cdot\norm{\hat{B}}
\end{align*}
$$

**(3):** From the definition $\eqref{equation-107}$, we have

$$
\begin{align*}
  \norm{\hat{A} + \hat{B}} =& \sup\set{\norm{(\hat{A} + \hat{B})\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  \leq& \sup\set{\norm{\hat{A}\psi} + \norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  \leq& \sup\set{\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H},\norm{\psi} = 1} \\
  &+ \sup\set{\norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H},\norm{\psi} = 1} \\
  =& \norm{\hat{A}} + \norm{\hat{B}}
\end{align*}
$$

**(4):** From the definition $\eqref{equation-107}$, we have

$$
\begin{align*}
  \norm{a\hat{A}} =& \sup\set{\norm{a\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& \sup\set{|a|\cdot\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& |a| \sup\set{\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& |a|\cdot\norm{\hat{A}}
\end{align*}
$$
</details>

### Outer product

<MathBox title='Outer product' boxType='definition'>
Let $\mathcal{H}$ be a Hilbert space. The outer product of two vectors $\ket{\psi}, \ket{\phi} \in\mathcal{H}$ is the operator $\ket{\psi}\bra{\phi} : \mathcal{H} \to\mathcal{H}$ given by

$$
  \ket{\chi} \mapsto \ket{\psi} \braket{\psi|\chi}
$$

which projects the component of $\ket{\chi}$ along $\ket{\phi}$ onto $\ket{\psi}$.
</MathBox>

The operator $\ket{\psi}\bra{\phi}: \mathcal{H} \to\mathcal{H}$ is linear in its action on kets, which follows from the linearity of the inner product in its second argument. For any scalars $a, b \in\mathbb{F}$ and vectors $\ket{\chi_1}, \ket{\chi_2} \in\mathcal{H}$

$$
\begin{align*}
  \ket{\psi}\ket{\phi}(a\ket{\chi_1} + b\ket{\chi_2}) =& \ket{\psi}(a\braket{\phi|\chi_1} + a\braket{\phi|\chi_2}) \\
  =& a\ket{\psi}\bra{\phi}(\ket{\chi_1}) + b\ket{\psi}\bra{\phi}(\ket{\chi_2})
\end{align*}
$$

The map $\ket{\cdot}\bra{\cdot}: \mathcal{H}\times\mathcal{H} \to\mathcal{L}(\mathbf{H})$ is sesquilinear satisfying
- **Linearity in the first argument:** For $a, b \in\mathbb{F}$ and $\ket{\psi_1}, \ket{\psi_2}, \ket{\phi}\in\mathcal{H}$
$$
  (a\ket{\psi_1} + b\ket{\psi_2})\bra{\phi} = a\ket{\psi_1}\bra{\phi} + b\ket{\psi_2}\bra{\phi}
$$

- **Conjugate-linearity in the second argument:** For $\ket{\psi}, \ket{\phi_1}, \ket{\phi_2} \in\mathcal{H}$
$$
  \ket{\psi}(a\bra{\phi_1} + b\bra{\phi_1}) = a^* \ket{\psi}\bra{\phi_1} + b^* \ket{\phi}\bra{\phi_2}
$$

### Matrix representation

<MathBox title='Matrix representation of linear operators' boxType='definition'>
If $\mathcal{H}$ is a finite-dimensional Hilbert space with orthonormal basis $\set{\ket{e_j}}_{j=1}^{\dim\mathcal{H}}$, the matrix elements of a linear operator $\hat{A}$ on $\mathcal{H}$ is given by

$$
  A_{jk} := \braket{e_j |\hat{A}|e_k}
$$

The matrix representation of $\mathbf{A}$ in the basis $\set{\ket{e_j}}$ is the matrix

$$
  \mathbf{A} = (\mathbf{A}_{jk})_{j,k=1}^{\dim\mathcal{H}}
$$ 
</MathBox>

If $\set{\ket{e_j}}_{j=1}^{\dim\mathcal{H}}$ is an ortonormal basis on a Hilbert space $\mathcal{H}$, a vector $\ket{\psi}\in\mathcal{H}$ can be expanded as 

$$
  \ket{\psi} = \sum_j \ket{e_j} \braket{e_j|\psi}
$$

Applying an operator $\hat{A}\in\mathcal{L}(\mathcal{H})$ on $\ket{\psi}$ gives

$$
\begin{align*}
  \hat{A}\ket{\psi} =& \ket{\hat{A}\psi} = \sum_j \ket{e_j} \braket{e_j|\hat{A}\psi} \\
  =& \sum_j \ket{e_j} \Braket{e_j|\hat{A}\left(\sum_k| \ket{e_k} \braket{e_k|\psi}\right)} \\
  =& \sum_{j,k} \braket{e_j|\hat{A}|e_k} \ket{e_j}\braket{e_k|\psi}
\end{align*}
$$

Thus, we can express $\hat{A}$ in the form

$$
\begin{equation*}
  \hat{A} = \sum_{j,k} \ket{e_j} \braket{e_j|\hat{A}|e_k}\bra{e_k} = \sum_{j,k} \ket{e_j} A_{jk} \bra{e_k} 
\tag{\label{equation-147}}
\end{equation*}
$$

where the scalars $A_{jk} := \braket{e_j|\hat{A}|e_k} \in\mathbb{F}$ define the matrix elements of $\hat{A}$ with respect to the basis $\set{\ket{e}_j}$. The matrix representation of $\hat{A}$ in the basis $\set{\ket{e_j}}$ is the matrix

$$
  \mathbf{A} = {A}_{jk}_{j,k=1}^{\dim(\mathcal{H})}
$$ 

From $\eqref{equation-147}$, the product of two linear operators $\hat{A}, \hat{B} \in\mathcal{L}(\mathcal{H})$ is given by

$$
\begin{align*}
  \hat{A}\hat{B} =& \left(\sum_{j, j'} \braket{j|\hat{A}|j'} \ket{j}\bra{j'} \right) \left(\sum_{k, k'} \braket{k|\hat{B}|kk'} \ket{k}\bra{k'} \right) \\
  =& \sum_{j,j',k,k'} \braket{j|\hat{A}|j'} \braket{k|\hat{B}|k'} \underbrace{\braket{j'|k}}_{\delta_{j',k}} \ket{j}\bra{k'} \\
  =& \sum_{j,k'} \left(\sum_{j''} \braket{j|\hat{A}|j'} \braket{j'|\hat{B}|k'} \right) \ket{j}\bra{k'}
\end{align*}
$$

Thus, the matrix elements of the product operator $\hat{A}\hat{B}$ are

$$
  \braket{j|\hat{A} \hat{B}|j'} = \sum_{j''} \braket{j|\hat{A}|j''}\braket{j''|\hat{B}|j'}
$$

which is precisely the rule for ordinary matrix multiplication.



The Hermitian adjoint of $\mathbf{M}$ is

$$
\begin{align*}
  \mathbf{M}^\dagger =& \sum_{j,j'} \braket{j|\hat{M}|j'}^* (\ket{j}\bra{j'})^\dagger \\
  =& \sum_{j,j'} \braket{j|\hat{M}|j'}^* \ket{j'}\bra{j}
\end{align*}
$$

from which we conclude that

$$
  \braket{j|\hat{M}^\dagger|j'} = \braket{j'|\hat{M}|j}^\dagger
$$

### Rotation operators

<MathBox title='' boxType='proposition'>
If $\hat{A}\in\mathcal{L}(\mathcal{H})$ is an involuntary operator, i.e. $\hat{A}^2 = \hat{I}$, then

$$
  e^{i\theta \hat{A}} = \cos(\theta)\hat{I} + i\sin(\theta)\hat{A}
$$

<details>
<summary>Proof</summary>

Taking the Taylor series expansion of $e^{i\theta\hat{A}}$ and using the fact that $\hat{A}^2 = \hat{I}$ gives

$$
\begin{align*}
  e^{i\theta\hat{A}} =& \sum_{n=0}^\infty \frac{(i\theta \hat{A})^n}{n!} \\
  =& \hat{I} + i\theta \hat{A} - \frac{\theta^2 \hat{I}}{2!} - i\frac{\theta^3 \hat{A}}{3!} + \frac{\theta^4 \hat{I}}{4!} \\
  =& \left(\sum_{n=0}^\infty \frac{(-1)^n \theta^{2n}}{(2n)!} \right)\hat{I} + i \left(\sum_{n=1}^\infty \frac{(-1)^n \theta^{2n - 1}}{(2n - 1)!} \right)\hat{A} \\
  =& \cos(\theta)\hat{I} + i\sin(\theta)\hat{A}
\end{align*}
$$
</details>
</MathBox>

In terms of the Pauli matrices, any unitary operator $\hat{U}\in\mathrm{U}(2)$ takes the form

$$
  \mathbf{U} = u_0 \mathbf{I}_2 + i(u_x \boldsymbol{\sigma}_x + u_y \boldsymbol{\sigma}_y + u_z \boldsymbol{\sigma}_z) = u_0 \mathbf{I}_2 + i \mathbf{u}\cdot\boldsymbol{\sigma} 
$$

where $u_0^2 + |\mathbf{u}|^2 = 1$. This last restriction allows us to parametrize $u_0$ and $\mathbf{u}\in\R^3$ in terms of a real unit vector $\unitvec{n}\in\mathbb{S}^2 \subset\R^3$ parallel to $\mathbf{u}$ and a real number $\theta\in\R$ such that

$$
  \mathbf{U} = \cos\left(\frac{\theta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\theta}{2}\right) \unitvec{n}\cdot\boldsymbol{\sigma} = e^{-i\theta \unitvec{n}\cdot\boldsymbol{\sigma} / 2}
$$

The unitary matrix $\mathbf{U}$ represents a counterclockwise rotation through an angle $\theta$ about $\unitvec{n}$. This operator is usually denoted 

$$
  \hat{R}_{\unitvec{n}}(\theta) = e^{-i\theta \unitvec{n}\cdot\boldsymbol{\sigma}}
$$

where $\boldsymbol{\sigma}$ are the Pauli matrices. Since the Pauli matrices are involuntary, i.e. $\hat{\sigma}_j = \hat{I}_2$, their exponentiation simplifies, allowing us to explicitly define the fundamental rotation operators about the Cartesian axes:

$$
\begin{align*}
  \hat{R}_x (\theta) =& e^{-i\theta\hat{\sigma}_x / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{\sigma}_x = \begin{bmatrix} \cos\left(\frac{\theta}{2}\right) & -i\sin\left(\frac{\theta}{2}\right) \\ -i\sin\left(\frac{\theta}{2}\right) & \cos\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  \hat{R}_y (\theta) =& e^{-i\theta\hat{\sigma}_y / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{\sigma}_y = \begin{bmatrix} \cos\left(\frac{\theta}{2}\right) & -\sin\left(\frac{\theta}{2}\right) \\ \sin\left(\frac{\theta}{2}\right) & \cos\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  \hat{R}_z (\theta) =& e^{-i\theta\hat{\sigma}_z / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{\sigma}_z = \begin{bmatrix} e^{-i\frac{\theta}{2}} & 0 \\ 0 & e^{i\frac{\theta}{2}} \end{bmatrix}
\end{align*}
$$

Let $V$ be a 3-dimensional vector space of $2\times 2$ Hermitian matrices with zero trace. Every such matrix $\mathbf{S}\in V$ can be written as $\mathbf{S} = \mathbf{s}\cdot\boldsymbol{\sigma}$, where $\mathbf{s}\in\R^3$ is a real vector. A unitary operator $\hat{U}\in\mathrm{U}(2)$ acts on $V$ by $\mathbf{S} \mapsto S' = \mathbf{USU}^\dagger$. In component form, this can be written as

$$
  \mathbf{s}\cdot\boldsymbol{\sigma} \mapsto \mathbf{s}' \cdot \boldsymbol{\sigma} = \mathbf{U}(\mathbf{s}\cdot\boldsymbol{\sigma}) \mathbf{U}^\dagger
$$

which defines a linear map $\hat{R}_U :\R^3 \to\R^3$. This is an isometry because it preserves the inner product. To verify this, consider $\mathbf{S} = \mathbf{s}\cdot\boldsymbol{\sigma}$ and $\mathbf{T} = \mathbf{t}\cdot\boldsymbol{\sigma}$ for $\mathbf{s},\mathbf{t}\in\R^3$. Then

$$
\begin{align*}
  \mathbf{s}'\cdot \mathbf{t}' =& \frac{1}{2}\operatorname{tr}(\mathbf{S}' \mathbf{T}') \\
  =& \frac{1}{2}\operatorname{tr}\left[(\mathbf{USU}^\dagger)(\mathbf{UTU}^\dagger) \right] \\
  =& \frac{1}{2}\operatorname{tr}(\boldsymbol{ST}) \\
  =& \mathbf{s}\cdot\mathbf{t}
\end{align*}
$$

This means that $\hat{R}_U \in \mathrm{SO}(3)$ represents a rotation in $\R^3$. We have thus established a group homomorphism

$$
\begin{align*}
  \operatorname{U}(2)\to& \operatorname{SO}(3) \\
  \hat{U} \mapsto \hat{R}_U
\end{align*}
$$

### Trace

<MathBox title='Trace' boxType='definition' tag='definition-1'>
Let $\set{\ket{e_j}}_{j=1}^{n\in\N}$ be an orthonormal basis in a finite-dimensional Hilbert space $\mathcal{H}$ with $\dim(\mathcal{H}) = n$. The trace is defined as the map $\operatorname{tr}: \mathcal{L}(\mathcal{H}) \to\mathbb{F}$ given by

$$
\begin{equation*}
  \operatorname{tr}(\hat{A}) := \sum_{j=1}^n \braket{e_j |\hat{A}|e_j} = \sum_{j=1}^n A_{jj}
\tag{\label{equation-148}}
\end{equation*}
$$
</MathBox>

Properties of the trace
1. Linearity: $\operatorname{tr}(\hat{A} + \hat{B}) = \operatorname{tr}(\hat{A}) + \operatorname{tr}(\hat{B})$
2. Commutatitivity: $\operatorname{tr}(\hat{A}\hat{B}) = \operatorname{tr}(\hat{B}\hat{A})$
3. $\operatorname{tr}(\hat{A}\hat{B}) = 0, \;\forall \hat{A}\in\mathcal{L}(\mathcal{H}) \iff \hat{B} = 0$
4. $\operatorname{tr}(a \ket{\phi}{\psi}) = a \braket{\psi|\phi}$ for scalar $a\in\mathbb{F}$
5. $\operatorname{tr}(\hat{A} \ket{phi}{\psi}) = \braket{\psi|\hat{A}|\phi}$

<details>
<summary>Proof</summary>

Let $\set{\ket{e_i}}_{i=1}^{\dim(\mathcal{H})}$ be an orthonormal basis of $\mathcal{H}$. 

**(4):** By the definition of the trace $\eqref{equation-148}$, we obtain

$$
\begin{align*}
  \operatorname{tr}(a \ket{\phi}\bra{\psi}) =& a \sum_j \braket{e_j | (\ket{\phi}\bra{\psi})|e_j} \\
  =& a \sum_j \braket{e_j |\phi} \braket{\psi|e_j} \\
  =& a \sum_j \braket{\psi|e_j}\braket{e_j |\phi} \\
  =& a \Braket{\psi | \left(\sum_j \bra{e_j} \ket{e_j}\right)| \phi \ket} = a\braket{\psi|\phi}
\end{align*}
$$

where we have used the completeness relation

$$
  \sum_j \bra{e_j} \ket{e_j} = \hat{I}
$$

**(5):** By the definition of the trace $\eqref{equation-148}$, we obtain

$$
\begin{align*}
  \operatorname{tr}(\hat{A}\ket{\phi}\bra{\psi}) =& \sum_j \braket{e_j|(\hat{A}\ket{\phi}\bra{\psi})|e_j} \\
  =& \sum_j = \braket{e_j|\hat{A}|\phi}\braket{\psi|e_j} \\
  =& \sum_j = \braket{\psi|e_j}\braket{e_j |\hat{A}|\phi} \\
  =& \Braket{\psi | \left(\sum_j \bra{e_j} \ket{e_j}\right) \hat{A}| \phi \ket} = \braket{\psi|\hat{A}|\phi}
\end{align*}
$$

</details>

In particular for the identity operator $\hat{I}$ with respect to an orthonormal basis $\set{\ket{e_j}}$ we have

$$
  \operatorname{tr}(\hat{I} \ket{e_k}\bra{e_j}) = \braket{e_j|\hat{I}|e_k} = \delta_{jk}
$$

From $\eqref{equation-147}$, we retrieve the completeness relation

$$
  \mathbf{I} = \sum_{j} \ket{e_j}\bra{e_j}
$$

If $\set{\ket{j}}$ is orthonormal basis of a Hilber space $\mathcal{H}$, then by the completeness relation, a vector $\ket{\psi} \in\mathcal{H}$ can be expanded as

$$
  \ket{\psi} = \sum_j \ket{j}\braket{j|\psi}
$$

The coordinate representation of $\ket{\psi}$ in this basis defines a wavefunction $\psi(j) := \braket{j|\psi}$. Taking the Hermitian adjoint yields

$$
  \ket{\psi}^\dagger = \sum_j \psi^* (j) \bra{j} =: \bra{\psi} \in\mathcal{H}^*
$$

For any $\ket{\psi}, \ket{\phi} \in\mathcal{H}$, the trace of the outer product $\ket{\psi}\bra{\phi}$ defines an inner product

$$
\begin{align*}
  \operatorname{tr}(\ket{\psi}\bra{\psi}) =& \sum_j \braket{j|\psi} \braket{\phi|j} \\
  =& \sum_{j, j'} \phi^* (j) \psi(j) = \braket{\phi|\psi}
\end{align*}
$$

### Hermitian adjoint

<MathBox title='Hermitian adjoint' boxType='definition'>
The $\hat{A}:\mathcal{H}\to\mathcal{H}$ be a linear operator on a Hilbert space $\mathcal{H}$. The Hermitian adjoint $\hat{A}$ is the unique linear operator $\hat{A}^\dagger :\mathcal{H}\to\mathcal{H}$ that satisfies

$$
  \braket{\varphi|\hat{A}\psi} = \braket{\hat{A}^\dagger \varphi|\psi},\; \forall \ket{\psi},\ket{\varphi} \in\mathcal{H}
$$

Equivalently, using Dirac notation, this condition can be rewritten as 

$$
  \braket{\varphi|\hat{A}|\psi} = \braket{\psi|\hat{A}^\dagger |\varphi}^*
$$

An operator $\hat{A}$ is Hermitian (or self-adjoint) if it it equal to its own adjoint:

$$
  \hat{A} = \hat{A}^\dagger
$$

An operator $\hat{A}$ is anti-Hermitian if it is the negative of its own adjoint:

$$
  \hat{A} = -\hat{A}^\dagger
$$

A Hermitian operator $\hat{A}$ is *positive* if for all $\ket{\psi}\in\mathcal{H}$,

$$
  \braket{\psi|\hat{A}|\psi} \geq 0
$$

which is written $\hat{A}\geq 0$. The operator $\hat{A}$ is *strictly positive* if for all nonzero $\ket{\psi}\in\mathcal{H}\setminus\set{0}$

$$
  \braket{\psi|\hat{A}|\psi} > 0
$$

which is written $\hat{A} > 0$.
</MathBox>

Hermitian adjoint properties
1. $\left(\hat{A}^\dagger \right)^\dagger = \hat{A}$
2. $\left(\hat{A} + \hat{B}\right)^\dagger = \hat{A}^\dagger + \hat{B}^\dagger$
3. $\left(\hat{A}\hat{B} \right)^\dagger = \hat{B}^\dagger\hat{A}^\dagger$
4. $\left(\hat{A}\ket{\psi}\right)^\dagger = \ket{\psi}\hat{A}^\dagger$
5. $\left(\ket{\psi}\bra{\phi}\right)^\dagger = \ket{\phi}\bra{\psi}$
6. $\ket{a\hat{A}\psi} = a^* \ket{\psi}\hat{A}^\dagger$ for any $a\in\mathbb{F}$
7. $(\hat{A}\times\hat{B})^\dagger = -\hat{B}^\dagger \times\hat{A}^\dagger$
8. $\hat{A}^{\dagger}\hat{B}\hat{C} + \hat{C}^{\dagger}\hat{B}\hat{A} = \frac{1}{2}\left[(\hat{A}+\hat{C})^{\dagger}\hat{B}(\boldsymbol{A}+\hat{C}) - (\hat{A}-\hat{C})^{\dagger} \hat{B}(\boldsymbol{A}-\hat{C})\right]$

<details>
<summary>Proof</summary>

**(7):** In terms of the Levi-Civita symbol, $\varepsilon_{ijk}$, we can write

$$
  (\hat{A}\times\mathbf{B})_i = \varepsilon_{ijk} A_j B_k
$$

Thus,

$$
\begin{align*}
  (\hat{A} \times \hat{B})^\dagger =& (\varepsilon_{ijk} A_j B_k)^\dagger = \varepsilon_{ijk} (A_j B_k)^\dagger \\
  =& \varepsilon_{ijk} B_k^\dagger A_j^\dagger = -\varepsilon_{ikj} B_k^\dagger A_j^\dagger \\
  =& -(\hat{B}^\dagger \times\hat{A}^\dagger)_i
\end{align*}
$$

**(8):** We start by expanding the operator products on the right-hand side. For the first term we have

$$
\begin{align*}
  (\hat{A} + \hat{C})^\dagger \hat{B} (\hat{A} + \hat{C}) =& (\hat{A}^\dagger + \hat{C}^\dagger) \hat{B} (\hat{A} + \hat{C}) \\
  =& \hat{A}^\dagger \hat{B}\hat{A} + \hat{A}^\dagger \hat{B}\hat{C} + \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C} 
\end{align*}
$$

Similarly, for the second term

$$
\begin{align*}
  (\hat{A} - \hat{C})^\dagger \hat{B} (\hat{A} - \hat{C}) =& (\hat{A}^\dagger - \hat{C}^\dagger) \hat{B} (\hat{A} + \hat{C}) \\
  =& \hat{A}^\dagger \hat{B}\hat{A} - \hat{A}^\dagger \hat{B}\hat{C} - \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C} 
\end{align*}
$$

Subtracting the terms yields

$$
\begin{align*}
  & \hat{A}^\dagger \hat{B}\hat{A} + \hat{A}^\dagger \hat{B}\hat{C} + \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C} \\
  -& (\hat{A}^\dagger \hat{B}\hat{A} - \hat{A}^\dagger \hat{B}\hat{C} - \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C}) \\
  =& 2(\hat{A}^\dagger \hat{B}\hat{C} + \hat{C}^\dagger \hat{B} \hat{A})
\end{align*}
$$

This shows that

$$
  \hat{A}^{\dagger}\hat{B}\hat{C} + \hat{C}^{\dagger}\hat{B}\hat{A} = \frac{1}{2}\left[(\hat{A}+\hat{C})^{\dagger}\hat{B}(\boldsymbol{A}+\hat{C}) - (\hat{A}-\hat{C})^{\dagger} \hat{B}(\boldsymbol{A}-\hat{C})\right]
$$
</details>

### Unitary operator

<MathBox title='Unitary operator' boxType='definition'>
A linear operator $\hat{U}:\mathcal{H}\to\mathcal{H}$ on a Hilbert space $\mathcal{H}$ is *unitary* if its Hermitian adjoint equals its inverse;

$$
  \hat{U}^\dagger = \hat{U}^{-1}
$$

This implies that

$$
  \hat{U}\hat{U}^\dagger = \hat{U}^\dagger \hat{U} = \hat{I}
$$

where $\hat{I}$ is the identity operator on $\mathcal{H}$. The set of all unitary operators on $\mathcal{H}$ is denoted $\mathcal{U}(\mathcal{H})$.
</MathBox>

A unitary operator $\hat{U}\in\mathcal{U}(\mathcal{H})$ on a Hilbert space $\mathcal{H}$ has the following properties:

- **Preservation of inner products:** 

$$
  \braket{\hat{U}\psi|\hat{U}\varphi} = \braket{\psi|\hat{U}^\dagger U|\varphi} = \braket{\psi|\varphi},\; \forall \ket{\psi},\ket{\varphi}\in\mathcal{H}
$$

- **Preservation of norm:**

$$
  \norm{ \hat{U}\ket{\psi}} = \sqrt{\braket{\hat{U}\psi|\hat{U}\psi}} = \sqrt{\braket{\psi|\hat{U}^\dagger \hat{U}|\psi}} = \sqrt{\braket{\psi|\psi}} = \norm{\ket{\psi}}
$$

- **Preservation of trace:** Any normal operator $\hat{Q}$ can be written in terms of a orthonormal eigenbasis $\set{\ket{q_j}}$ as

$$
  \hat{Q} = \sum_j q_j \ket{q_j} \bra{q_j}
$$

Under a unitary transformation $\hat{U}$, the transformed operator $\hat{Q}_U$ is given by

$$
  \hat{Q}\mapsto \hat{Q}_U = \sum_j q_j \hat{U} \ket{q} \bra{q}_k \hat{U}^\dagger = \hat{U} \hat{Q} \hat{U}^\dagger
$$

Consequently, the trace of $\hat{Q}_U$ remains unchanged:

$$
\begin{align*}
  \operatorname{tr}(\hat{Q}_U) = \operatorname{tr}(\hat{U}\hat{Q}\hat{U}^\dagger) = \operatorname{tr}(\hat{U}^\dagger \hat{U} \hat{Q}) = \operatorname{tr}(\hat{Q})
\end{align*}
$$

<MathBox title='' boxType='proposition'>
Let $\set{\ket{e_j}}_{j=1}^{n\in\N}$ be an orthonormal basis of an $n$-dimensional Hilbert space $\mathcal{H}$. For $\hat{A},\hat{U}\in\mathcal{L}(\mathcal{H})$, we have

1. $\set{\ket{\tilde{e}_j} = \hat{U}\ket{e_j}}$ is an orthonormal basis in $\mathcal{H}$ if an only if $\hat{U}\in\mathcal{U}(\mathcal{H})$ is unitary
2. 
$$
  \sum_{j=1}^n \braket{e_j|\hat{A}|e_j} = \sum_j \braket{\tilde{e}_j|\hat{A}|\tilde{e}_j}
$$

<details>
<summary>Proof</summary>

**(1):** To show $\implies$, let $\set{\ket{\tilde{e}_j} = \hat{U}\ket{e_j}}$ be an orthonormal basis in $\mathcal{H}$. If follows that $U_{jk} = \braket{e_j |\hat{U}|e_k} = \braket{e_j|\tilde{e}_k}$ and thus

$$
\begin{align*}
  (\mathbf{U}\mathbf{U}^\dagger)_{kl} =& \sum_{j=1}^n \mathbf{U}_{kj} \mathbf{U}_{jl}^* = \sum_{j=1}^n \mathbf{U}_{kj} \mathbf{U}_{jk} \\
  =& \sum_{j=1}^n \braket{e_k|\tilde{e}_j} \braket{e_l|\tilde{e}_j}^* = \sum_{j=1}^n \braket{e_k|\tilde{e}_j}\braket{\tilde{e}_j|e_l} \\
  =& \Braket{e_k | \sum_{j=1}^n \tilde{e}_j \braket{\tilde{e}_j | e_l}} = \braket{e_k|e_l} \\
  =& \delta_{kl}
\end{align*}
$$

such that $U\in\mathcal{U}(\mathcal{H})$.

To show $\impliedby$, let $U\in\mathcal{U}(\mathcal{H})$ and $\ket{\tilde{e}_j} = \hat{U}\ket{e_j}$. For any $\set{a_j}\subset\mathbb{F}$ it follows that

$$
\begin{align*}
  &\sum_{j=1}^n a_j \ket{\tilde{e}_j} = 0 \implies& \sum_{j=1}^n a_j \hat{U}\ket{e_j} = 0 \\
  \implies& \hat{U} \sum_{j=1}^m a_j \ket{e_j} = 0 \implies& \hat{U}^\dagger \hat{U} \sum_{j=1}^n a_j \ket{e_j} \\
  \implies& \sum_{j=1}^n a_j\ ket{e_j} = 0 \implies& a_j = 0, \; \forall j
\end{align*}
$$

such that the $\set{\tilde{e}_j} \subset\mathcal{H}$ are linearly independent. Moreover, we have for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \hat{U}^\dagger \ket{\psi} =& \sum_{j=1}^n \braket{e_j|\hat{U}^\dagger|\psi}\ket{e_j} = \sum_{j=1}^n \braket{\hat{U}e_j | \psi}\ket{e_j} \\
  =& \sum_{j=1}^n \braket{\tilde{e}_j |\psi} \ket{e_j}
\end{align*}
$$

This implies that

$$
\begin{align*}
  \ket{\psi} =& \hat{U}\hat{U}^\dagger \ket{\psi} = \sum_{j=1}^n \braket{\tilde{e}_j | \psi}\hat{U}\ket{e_j} \\
  =& \sum_{j=1}^n \braket{\tilde{e}_j|\psi} \ket{\tilde{e}_j}
\end{align*}
$$

showing that any vector in $\mathcal{H}$ can be written as a linear combination of $\set{\ket{\tilde{e}_j}}$. Finally, we have

$$
\begin{align*}
  \braket{\tilde{e}_j|\tilde{e}_k} =& \braket{\hat{U}e_j | \hat{U}e_k} = \braket{e_j | \hat{U}^\dagger \hat{U}| e_k} \\
  =& \braket{e_j|e_k} = \delta_{jk}
\end{align*}
$$

**(2):** We have that

$$
\begin{align*}
  \sum_j \braket{\tilde{e}_j|\hat{A}|\tilde{e}_j} =& \sum_j \braket{\hat{U}e_j|\hat{A}\hat{U}|e_j} = \sum_j \braket{e_j | \hat{U}^* \hat{A} \hat{U} e_j} \\
  =& \sum_j (\hat{U}^\dagger \hat{A} \hat{U})_{jj} \\
  =& \sum_{j,k,l} \mathbf{U}_{jk}^\dagger \mathbf{A}_{jk} \mathbf{U}_{lj} = \sum_{k,l} \mathbf{A}_{kl} \sum_j \mathbf{U}_{lj} \mathbf{U}_{jl}^\dagger \\
  =& \sum_{k,l} \mathbf{A}_{kl} \sum_j \underbrace{(\mathbf{U}\mathbf{U}^\dagger)_{lk}}_{\delta_{lk}} = \sum_k \mathbf{A}_{kk} \\
  =& \sum_k \braket{e_k |\hat{A}| e_k}
\end{align*}
$$
</details>
</MathBox>

<MathBox title="Stone's theorem" boxType='theorem'>
Let $(U_t)_{t\in\R}$ be a strongly continuous one-parameter group on a Hilbert space $\mathcal{H}$, satisfying
1. $\hat{U}(t)$ is unitary for all $t\in\R$
2. $\hat{U}(t + s) = \hat{U}(t) \hat{U}(s)$ for all $s,t \in \R$
3. $\lim_{t\to 0} \norm{\hat{U}(t) \psi - \psi} = 0$ for all $\psi\in\mathcal{H}$

Then there exists a unique Hermitian operator $\hat{O}$ on $\mathcal{H}$ such tahat

$$
  \hat{U} = e^{it\hat{O}},\; \forall t\in\R
$$

Conversely, if $\hat{O}$ is Hermitian, then $e^{it\hat{O}}$ defines a strongly continuous one-parameter unitary group.
</MathBox>

The Stone theorem ensures the existence of a Hermitian infinitesimal generator for an Abelian group of unitary transformations.

### Eigenvalues

<MathBox title='Eigenvalue, eigenvector, eigenspace and spectrum' boxType='definition'>
Let $\hat{A}$ be a linear operator on a Hilbert space $\mathcal{H}$. A nonzero vector $\ket{\psi}\in\mathcal{H}$ is an *eigenvector* of $\hat{A}$ with *eigenvalue* $a\in\mathbb{F}$ if it satisfies the eigenvalue equation

$$
  \hat{A}\ket{\psi} = a\ket{\psi}
$$

The *eigenspace* associated with an eigenvalue $a$ is the subspace spanned by all eigenvectors corresponding to $a$, given by

$$
  \operatorname{eig}(\hat{A}, a) = \set{\ket{\psi} \in \mathcal{H}\setminus\set{0} | \hat{A}\ket{\psi} = a\ket{\psi}}
$$

An eigenvalue $a$ is called non-degenerate if its eigenspace is one-dimensional, meaning it has only one linearly independent eigenvector. Otherwise, $a$ is called degenerate. 

The spectrum of $\hat{A}$, denoted $\sigma(\hat{A})$, is the set of all scalars $a\in\mathbb{F}$ for which the operator $(\hat{A} - a\hat{I})^{-1}$ does not, exist, i.e.

$$
  \sigma(\hat{A}) := \set{a\in\mathbb{F} | (\hat{A} - a\hat{I})^{-1} \text{ does not exist}}
$$
</MathBox>

Let $\hat{A}\in\mathcal{L}(\mathcal{H})$ be an operator in a Hilbert space $\mathcal{H}$, and let $a$ be an eigenvalue with eigenvector $\ket{\psi}$, so that

$$
  \hat{A}\ket{\psi} = a\ket{\psi}
$$

Taking the adjoint on both sides, we get

$$
\begin{align*}
  (\hat{A}\ket{\psi})^\dagger =& (a\ket{\psi})^\dagger \\
  \bra{\psi}\hat{A} =& a^* \bra{\psi}
\end{align*}
$$

To confirm the result, consider the inner product with $\ket{\varphi}\in\mathcal{H}$:

$$
  \braket{\psi|\hat{A}^\dagger|\varphi} = \braket{\hat{A}\psi|\varphi} \braket{a\psi|\varphi} = a^* \braket{\psi|\varphi}
$$

This verifies that

$$
  \bra{\psi}\hat{A} = a^* \bra{\psi}
$$

#### Eigenvalues of Hermitian operators

Let $\hat{A}$ be a Hermitian operator on a Hilbert space $\mathcal{H}$, and consider the eigenvalue equation

$$
  \hat{A} \ket{\psi_i} = a_i \ket{\psi_i}
$$

Taking the inner product with another eigenvector $\ket{\psi_j}$, we obtain

$$
\begin{gather*}
\begin{aligned}
  \braket{\psi_i | \hat{A} \psi_j} &= \braket{\hat{A} \psi_i | \psi_j} \\
  \lambda_i^* \braket{\psi_i | \psi_j} &= \lambda_i \braket{\psi_i | \psi_j}
\end{aligned}\\
  \implies \left( \lambda_j^* - \lambda_i \right) \braket{\psi_i | \psi_j} = 0
\end{gather*}
$$

This leads to two conclusions:
1. If $i = j$, then $\lambda_i = \lambda_i^*$, meaning that all eigenvalue of a Hermitian operator are real. 
2. If $i \neq j$, then $\braket{\psi_i | \psi_j} = 0$, meaning that the eigenvectors corresponding to distinct eigenvalues are orthogonal.

In the finite-dimensional case, the smallest and larget eigenvalues of a Hermitian operator $\mathbf{A}$ serve as lower and upper bound of the inner product of $\braket{\psi|\hat{A}\psi}$ for normalized $\ket{\psi}$.

#### Eigenvalues of unitary operators

Let $\hat{U}\in\mathcal{U}(\mathcal{H})$ be a unitary operator on the Hilbert space $\mathcal{H}$ and let $u$ be an eigenvalue with eigenvector $\ket{\psi}\in\mathcal{H}$. Since unitary operators preserve norms, we get

$$
  \norm{\psi} = \norm{ \hat{U}\psi} = \norm{ u\psi} = |u|\cdot\norm{\psi}
$$

and thus $|u| = 1$, meaning that the eigenvalues of a unitary operator always lie on the unit circle in the complex plane.

#### Spectral decomposition of operators

A Hermitian operator $\hat{A}$ is diagonalizable, meaning that there is an orthonormal basis consisting of eigenvectors $\set{\ket{e_{j,\alpha}}}$ of $\hat{A}$ such that

$$
  \hat{A}\ket{e_{j,\alpha}} = a_j \ket{e_{j,\alpha}}
$$

where $\alpha\in\set{1,\dots,d_j}$ indexes the eigenvectors associated with the possibly $d_j$-fold degerate eigenvalue $a_j$.

The matrix elements in this basis have the form $\mathbf{A}_{j,\alpha;k,\beta} = a_j \delta_{j,k} \delta_{\alpha,\beta}$ such that

$$
\begin{align*}
  \mathbf{A} =& \sum_{j,k\alpha,\beta} \ket{e_{j,\alpha}} a_j \delta_{j,k} \delta_{\alpha,\eta} \bra{e_{k,\beta}} \\
  =& \sum_{j,\alpha} a_j \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}
\end{align*}
$$

This is referred to as the spectral decomposition or the diagonal form of the operator.

##### Infinite-dimensional case

If $\hat{A}$ is an operator with a complete set of orthonormal eigenvectors, i.e.

$$
  \hat{A}\ket{e_n} = a_n \ket{e_n}, \; n\in\N
$$

then it can be written in terms of its spectral decomposition:

$$
  \hat{A} = \sum_{n\in\N} a_n \ket{e_n} \bra{e_n}
$$

<details>
<summary>Proof</summary>

By completeness of the orthonormal eigenvectors, any vector $\ket{\psi}$ can be expanded as a linear combination

$$
  \ket{\psi} = \sum_{n\in\N} \psi_n \ket{e_n}
$$

where $\psi_n$ is given by the inner product

$$
  \braket{e_i|\psi} = \ket{e_i} \sum_{n\in\N} \psi_n \ket{e_n} = \sum_{n\in\N} \psi_n \braket{e_i|e_n} = \sum_{n\in\N} \psi_n \delta_{in}
$$

Hence, $\psi_n = \braket{e_n | \psi}$. Applying $\hat{A}$ to $\ket{\psi}$ yields

$$
\begin{align*}
  \hat{A}\ket{\psi} =& \hat{\psi} \sum_{n\in\N} \psi_n \ket{e_n} = \sum_{n\in\N} \psi_n (\hat{A}\ket{e_n}) \\
  =& \sum_{n\in\N} \psi_n (a_n \ket{e_n}) = \sum_{n\in\N} (a_n \ket{e_n}) \psi_n \\
  =& \sum_{n\in\N} \psi_n \ket{e_n} \braket{e_n | \psi} = \left(\sum_{n\in\N} a_n \ket{e_n} \bra{e_n} \right)\ket{\psi}  
\end{align*}
$$
</details>

The spectral decomposition of the $k$th power of $\hat{A}$ is

$$
  \hat{A}^k = \sum_{n\in\N} a_n^k \ket{e_n} \bra{e_n}
$$

<details>
<summary>Proof</summary>

This can be shown by induction. For the base case $k=2$, we have

$$
\begin{align*}
  \hat{A}^2 =& \left(\sum_{m\in\N} a_m \ket{e_m}\bra{e_m} \right) \left(\sum_{n\in\N} a_n \ket{e_n}\bra{e_n} \right) \\
  =& \sum_{m,n\in\N} a_m a_n \ket{e_m} \underbrace{\braket{e_m|e_n}}_{\delta_{mn}} \bra{e_n} \\
  =& \sum_{m\in\N} a_m^2 \ket{e_m} \bra{e_m} 
\end{align*}
$$

Assuming

$$
  \hat{A}^{k-1} = \sum_{m\in\N} a_m^{k-1} \ket{e_n} \bra{e_n}
$$

it follows that the spectral decomposition of $\hat{A}^k$ is

$$
\begin{align*}
  \hat{A}^k =& \left(\sum_{m\in\N} a_m^{k-1} \ket{e_m}\bra{e_m} \right) \left(\sum_{n\in\N} a_n \ket{e_n}\bra{e_n} \right) \\
  =& \sum_{m,n\in\N} a_m^{k-1} a_n \ket{e_m} \underbrace{\braket{e_m|e_n}}_{\delta_{mn}} \bra{e_n} \\
  =& \sum_{m\in\N} a_m^k \ket{e_m} \bra{e_m} 
\end{align*}
$$
</details>

The spectral decomposition of the exponential of $\hat{A}$ is

$$
  e^{\hat{A}} = \sum_{n\in\N} e^{a_n} \ket{e_n} \bra{e_n}
$$

<details>
<summary>Proof</summary>

Computing $e^{\hat{A}}$ we find

$$
\begin{align*}
  e^{\hat{A}} =& \sum_{n\in\N} e^{a_n} \ket{e_n} \bra{e_n} \\
  =& \sum_{n\in\N} \left(\sum_{k=0}^\infty \frac{q_n^k}{k!} \right) \ket{e_n} \bra{e_n} \\
  =& \sum_{k=0}^\infty \frac{1}{k!} \left(\sum_{n=1}^\infty a_n^k \ket{e_n} \bra{e_n} \right) \\
  =& \sum_{k=0}^\infty \frac{1}{k!} \hat{A}^k
\end{align*}
$$
</details>

### Projection operator

<MathBox title='Projection operator' boxType='definition'>
Let $\mathcal{H}$ be a Hilbert space. A projection operator (or simply projector) is a linear operator $\hat{P}\in\mathcal{L}(\mathcal{H})$ that is idempotent, i.e. $\hat{P}^2 = \hat{P}$. If, in addition $\hat{P}$ is Hermitian, i.e. $\hat{P}^\dagger = \hat{P}$, then $\hat{P}$ is called an *orthogonal projector*.
</MathBox>

The complement of a projector $\hat{P}\in\mathcal{L}(\mathcal{H})$ on a Hilbert space $\mathcal{H}$ is the operator $\hat{Q} = \hat{I} - \hat{P}$, which is also a projector since it satisfies idempotency:

$$
\begin{align*}
  \hat{Q}^2 =& (\hat{I} - \hat{P})^2 \\
  =& \hat{I} - 2\hat{P} + \underbrace{\hat{P}^2}_{=\hat{P}} \\
  =& \hat{I} - \hat{P} = \hat{Q}
\end{align*}
$$

If $\hat{P}$ is Hermitian, then so is $\hat{Q}$ since

$$
  \hat{Q}^\dagger = (\hat{I} - \hat{P})^\dagger = \hat{I} - \underbrace{\hat{P}^\dagger}_{=\hat{P}} = \hat{Q}
$$

meaning that $\hat{Q}$ is an orthogonal projector. In this case $\hat{P}$ and $\hat{Q}$ are mutually orthogonal projectors, satisfying

$$
  \hat{P}\hat{Q} = \hat{Q}\hat{P} = 0
$$

Thus, $\hat{P}$ and $\hat{Q}$ define an orthogonal decomposition of $\mathcal{H}$ into two subspaces, i.e. $\mathcal{H} = \operatorname{ran}(\hat{P}) \oplus \operatorname{ran}(\hat{Q})$. This orthogonal decomposition allows us to express any vector $\ket{\psi}\in\mathcal{H}$ uniquely as a sum components in the ranges of $\hat{P}$ and $\hat{Q}$:

$$
  \ket{\psi} = \hat{P}\ket{\psi} + \hat{Q}\ket{\psi}
$$

#### Projections onto unit vectors

If $\ket{\psi}\in \mathcal{H}$ is a unit vector in the Hilbert space $\mathcal{H}$, i.e. $\braket{\psi|\psi} = 1$, the projection onto $\ket{\psi}$ is given by

$$
  \hat{P}_\psi = \ket{\psi}\bra{\psi}
$$

To see that $\hat{P}_\psi$ is a projection, we compute

$$
\begin{align*}
  \hat{P}_\psi^2 =& (\ket{\psi}\bra{\psi})(\ket{\psi}\bra{\psi}) \\
  =& \ket{\psi}(\underbrace{\braket{\psi|\psi}}_{=1})\bra{\psi} \\
  =& \ket{\psi}\bra{\psi} = \hat{P}_\psi
\end{align*}
$$

showing that $\hat{P}_\psi$ is idempotent as required. Additionally, $\hat{P}$ is Hermitian, since

$$
  \hat{P}_\psi^\dagger = (\ket{\psi}\bra{\psi})^\dagger = \ket{\psi}\bra{\psi} = \hat{P}_\psi
$$

The projection of $\ket{\varphi}\in\mathcal{H}$ onto $\ket{\psi}$ becomes

$$
  \hat{P}_\psi \ket{\varphi} = \ket{\psi}\braket{\psi|\varphi} = \braket{\psi|\varphi}\ket{\psi}
$$

Since $\braket{\psi|\varphi}\in\mathbb{F}$ is a scalar, this means that $\hat{P}_\psi \ket{\varphi}$ projects $\ket{\varphi}$ onto the one-dimensional subspace spanned by $\ket{\psi}$.

The find the eigenvalues of $\hat{P}_\psi$, we solve

$$
\begin{align*}
  \hat{P}_\psi \ket{\lambda} =& \lambda\ket{\lambda} \\
  \ket{\psi}\underbrace{\braket{\psi|\lambda}}_{=c\in\mathbb{F}} =& \lambda\ket{\lambda} \\
  c\ket{\psi} =& \lambda\ket{\lambda}
\end{align*}
$$

If $\ket{\lambda} = \ket{\psi}$, then $\lambda = \braket{\psi|\lambda} = \braket{\psi|\psi} = 1$. Otherwise, for $\ket{\lambda}\neq\ket{\psi}$ we have $\lambda = \braket{\psi|\lambda} = 0$, implying that $\ket{\lambda}$ and $\ket{\psi}$ are orthogonal. Thus, the eigenvalues of $\hat{P}_\psi$ are $0$ and $1$, with the eigenspace corresponding to $\lambda = 1$ being spanned by $\ket{\psi}$, and the eigenspace corresponding to $\lambda = 0$ being the ortogonal complement of $\ket{\psi}$.

In terms of $\hat{P}_\psi$, any vector $\ket{\varphi}\in\mathcal{H}$ can be uniquely decomposed as 

$$
\begin{align*}
  \ket{\varphi} =& \hat{I}\ket{\varphi} + \hat{P}_\psi \ket{\varphi} - \hat{P}_\psi \ket{\varphi} \\
  =& \hat{P}_\psi \ket{\varphi} + (\hat{I} - \hat{P})\ket{\varphi}
\end{align*}
$$

Since 

$$
  \hat{P}_\psi (\hat{P}_\psi \ket{\varphi}) = \hat{P}_\psi^2 \ket{\varphi} = \hat{P}_\psi \ket{\varphi}
$$

then $\hat{P}_\psi \ket{\varphi}$ is an eigenvector of $\hat{P}_\psi$ with eigenvalue $1$. Since

$$
  \hat{P}_\psi [(\hat{I} - \hat{P}_\psi)\ket{\varphi}] = (\hat{P}_\psi - \underbrace{\hat{P}_\psi^2}_{=\hat{P}_psi})\ket{\varphi} = 0 
$$

then $(\hat{I} - \hat{P}_\psi)\ket{\varphi}$ is an eigenvector of $\hat{P}_\psi$ with eigenvalue $0$.

In particular, if $\set{\ket{e}_n}_{n\in\N}$ is an orthonormal basis, i.e. $\braket{e_i | e_j} = \delta_{ij}$, then

$$
  \sum_{n\in\N} \ket{e_n} \bra{e_n} = 1
$$

defines the identity operator. If we let this operator act on any vector $\ket{v}$, we recover the expansion of $\ket{\psi}$ in the $\set{\ket{e}_n}_{n\in\N}$ basis:

$$
  \sum_{n\in\N} (\braket{e_n|\psi})\ket{e_n} = \ket{\psi}
$$

If $\mathcal{H}' \subset\mathcal{H}$ is an $n$-dimensional subspace with orthonormal basis $\set{\ket{e}_i}_{i=1}^n$, the projection onto $W$ is given by

$$
  \hat{P}_{\mathcal{H}'} = \sum_{i=1}^n \ket{e_i}\bra{e_i}
$$

#### Spectral decomposition of Hermitian operators

If $\hat{A}$ is a Hermitian operator on an finite-dimensional Hilbert space $\mathcal{H}$, its eigenvectors form an orthonormal basis. Let $\ket{e_{j,\alpha}}$ denote an eigenvector of $\hat{A}$ corresponding to the eigenvalue $a_j$, where $\alpha\in\set{1,\dots,d_j}$ indexes the possibly $d_j$-fold degenerate eigenvalue $a_j$ of $\hat{A}$. The orthogonal projection onto the eigenspace $\operatorname{eig}(\hat{A}, a_j)$ with $\dim[\operatorname{eig}(\hat{A}, d_j)] = d_j$ is given by

$$
  \hat{P}_j = \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}
$$

<details>
<summary>Proof</summary>

To verify that $\hat{P}_j$ is a projection, we check idempotency

$$
\begin{align*}
  \hat{P}_j^2 =& \left(\sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}\right)  \left(\sum_{\beta=1}^{d_j} \ket{e_{j,\beta}} \bra{e_{j,\beta}}\right) \\
  =& \sum_{\alpha=1}^{\d_j} \sum_{\alpha=1}^{\d_j} \ket{e_{j,\alpha}} \underbrace{\braket{e_{j,\alpha}|e_{j,\beta}}}_{=\delta_{\alpha\beta}} \bra{e_{j,\beta}} \\
  =& \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} = \hat{P}_j
\end{align*}
$$

Since $\hat{P}_j^2 = \hat{P}_j$, it is a projection. Next, we check that $\hat{P}_j$ is Hermitian taking its adjoint:

$$
\begin{align*}
  \hat{P}_j^\dagger =& \left(\sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}\right)^\dagger \\
  =& \sum_{\alpha=1}^{d_j} (\ket{e_{j,\alpha}} \bra{e_{j,\alpha}})^\dagger \\
  =& \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} = \hat{P}_j
\end{align*}
$$

Since $\hat{P}_j^\dagger = \hat{P}_j$, the operator is self-adjoint. Because $\set{\ket{e_{j,\alpha}}|j\in I\subset\N, \alpha\in\set{1,\dots,d_j}}$ is an orthonormal eigenbasis of $\hat{A}$, any eigenvector $\operatorname{eig}(\hat{A}, a_j)$ can be written in the form

$$
  \ket{\psi} = \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \braket{e_{j,\alpha}|\psi} = \hat{P}_j \ket{\psi}
$$
</details>

A Hermitian operator $\hat{A}$ can be expressed in terms of its spectral projections as

$$
  \hat{A} = \sum_{j,\alpha} a_j \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} = \sum_j a_j \hat{P}_j
$$

In particular, since any orthonormal basis $\set{\ket{e_j}}$ constitutes an eigenbasis of the identity operator $\hat{I}$ with eigenvalue $1$, we have

$$
\begin{align*}
  \hat{I} =& \sum_{j,k} \ket{e_j} \braket{e_j|e_k} \bra{e_k} \\
  =& \sum_{j,k} \delta_{jk} \ket{e_j} \bra{e_k} \\
  =& \sum_j \ket{e_j} \bra{e_j} = \sum_j \hat{P}_j
\end{align*}
$$

which is known as the completeness relation. Moreover, the projection satisfy the orthogonality relation

$$
\begin{align*}
  \hat{P}_j \hat{P}_k =& \left(\sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} \right) \left(\sum_{\beta=1}^{d_j} \ket{e_{j,\beta}} \bra{e_{j,\beta}} \right) \\
  =& \sum_{\alpha=1}^{d_j} \sum_{\beta=1}^{d_k} \ket{e_{j,\alpha}} \braket{e_{j,\alpha}|e_{k,\beta}} \bra{e_{k,\beta}} \\
  =& \delta_{jk} \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} \\
  =& \delta_{jk} \hat{P}_j
\end{align*}
$$

#### Continuous projectors

If $V$ is an infinite-dimensional space, the continuous projector satisfy

$$
  \int \hat{P}(v) \;\d v = \int \ket{v}\bra{v} \;\d v = 1
$$

and

$$
  \hat{P}(v) \hat{P}(v') = \delta(v - v') \hat{P}(v)
$$

where $\delta$ is the Dirac delta function. In particular, if $\set{\ket{e_x}}_{x\in\R}$ is a Dirac orthonormalized continuous basis, i.e. $\braket{e_x | e_{x'}} = \delta(x - x')$, then

$$
  \int_\R \ket{e_x} \bra{e_x} \;\d x = 1 
$$

### Commutator

The commutator of two operators $\hat{A}$ and $\hat{B}$ is written

$$
  [\hat{A}, \hat{B}] := \hat{A}\hat{B} - \hat{B}\hat{A}
$$

while the anticommutator is written 

$$
\{\hat{A}, \hat{B}\} := \hat{A}\hat{B} + \hat{B}\hat{A}
$$

Commutator properties
- Self-commution: $[\hat{A}, \hat{A}] = 0$
- Antisymmetry: $[\hat{A}, \hat{B}] = -[\hat{B}, \hat{A}]$
- Linearity: $[\hat{A}, \hat{B} + \hat{C}] = [\hat{A}, \hat{B}] + [\hat{A}, \hat{C}]$
- Hermitian conjugable: $[\hat{A}, \hat{B}]^\dagger = [\hat{A}^\dagger, \hat{B}^\dagger]$
- Distributivity:
$$
\begin{align*}
  [\hat{A}, \hat{B}\hat{C}] &= [\hat{A}, \hat{B} ]\hat{C} + \hat{B}[ \hat{A}, \hat{C}] \\
  [\hat{A}\hat{B}, \hat{C}] &= \hat{A}[\hat{B}, \hat{C}] + [ \hat{A}, \hat{C}]\hat{B}
\end{align*}
$$
- $[\hat{A}^2,\hat{B}] = \hat{A}[\hat{A},\hat{B}] + [\hat{A},\hat{B}]\hat{A}$
- Jacobi identity: $\left[\hat{A}, [\hat{B}, \hat{C}]\right] + \left[\hat{B}, [\hat{C}, \hat{A}]\right] + \left[\hat{C}, [\hat{A}, \hat{B}]\right] = 0$
- Operators commute with scalars
- If $\hat{A}$ and $\hat{B}$ Hermitian operators then
  * $[\hat{A}, \hat{B}]$ is anti-Hermitian
  * $\{\hat{A}, \hat{B}\}$ is Hermitian

The commutator gives an alternative expression for the dot product of two operators $\hat{A}$ and $\hat{B}$

$$
  \hat{A}\cdot\hat{B} = \hat{A}_i \hat{B}_i = (\hat{A}_i \hat{B}_i - \hat{B}_i \hat{A}_i) + \hat{B}_i \hat{A}_i = [\hat{A}_i, \hat{B}_i] + \hat{B}_i \hat{A}_i = [\hat{A}_i, \hat{B}_i] + \hat{B}\cdot\hat{A} 
$$

and likewise for their cross product

$$
  (\hat{A}\times\hat{B})_i = \varepsilon_{ijk} \hat{A}_j \hat{B}_k = \varepsilon_{ijk}[(\hat{A}_j \hat{B}_k - \hat{B}_k \hat{A}_j) + \hat{B}_k \hat{A}_j] = \varepsilon_{ijk}([\hat{A}_j, \hat{B}_k] + \hat{B}_k \hat{A}_j) = -\varepsilon_{ikj} \hat{B}_k \hat{A}_j + \varepsilon_{ijk} [\hat{A}_j, \hat{B}_k] = -(\hat{B} \times \hat{A})_i + \varepsilon_{ijk} [\hat{A}_j, \hat{B}_k]
$$
    
Two operators $\hat{A}$ and $\hat{B}$ are said to commute if $[ \hat{A}, \hat{B}] = 0$. Two commuting operators share the same eigenvectors. Suppose $\hat{A}$ and $\hat{B}$ commute with common eigenvectors

$$
  \hat{A}\phi_i (\mathbf{x}) = \lambda_i \phi_i (\mathbf{x}),\quad \hat{B}\phi_i (\mathbf{x}) = \mu_i \phi_i (\mathbf{x})
$$

then any function $\phi$ can be expanded in terms of these eigenstates $\psi = \sum_i a_i \phi_i$ giving

$$
  [\hat{A}, \hat{B}]\psi = \sum_i a_i [\hat{A}, \hat{B}]\phi_i = \sum_i a_i \left(\lambda_i \mu_i - \mu_i \lambda_i \right)\phi_i = 0 
$$

## Spectral theory

### Spectral decomposition of Hermitian operators

A self-adjoint operator $\hat{A}$ on a Hilbert space $\mathcal{H}$ can be heuristically expanded as

$$
\begin{align*}
  \hat{A} = \int_{-\infty}^\infty \lambda \delta(\lambda - \hat{A}) \;\d\lambda
\tag{\label{equation-153}}
\end{align*}
$$

where $\delta(\lambda - \hat{A})$ represents the spectral density of $\hat{A}$. 

<details>
<summary>Proof</summary>

To make this argument rigorous we have to replace $\delta(\lambda - \hat{A})$, which is not a genuine operator-valued function, with a projection-valued measure $E: \mathcal{B}(\R) \to \mathcal{B}(\mathcal{H})$, where $\mathcal{B}(\R)$ is the Borel $\sigma$-algebra on $\R$ and $\mathcal{B}(\mathcal{H})$ is the set of bounded operators on $\mathcal{H}$. In terms of $E$, the heuristic $\delta(\lambda - \hat{A})$ is interpreted as the measure derivative

$$
  E(\d\lambda) := \delta(\lambda - \hat{A}) \;\d\lambda
$$
</details>

To get the spectral decomposition of $\hat{A}$, define the operator

$$
\begin{align*}
  \hat{P}_A (\lambda) =& \Theta(\lambda - \hat{A}) \\
  =& \int_{-\infty}^\lambda \delta(\lambda' - \hat{A}) \;\d\lambda'
\end{align*}
$$

where $\Theta$ is the step function

$$
  \Theta(\lambda) = \begin{cases}
    1,\quad& \lambda > 0 \\
    0,\quad& \lambda \leq 0
  \end{cases}
$$

Then formally $\d\hat{P}_A (\lambda) = \delta(\lambda - \hat{A}) \;\d\lambda$, such that $\eqref{equation-153}$ can be rewritten

$$
\begin{equation*}
  \hat{A} = \int_{-\infty}^\infty \lambda \;\d\hat{P}_A (\lambda)
\tag{\label{equation-156}}
\end{equation*}
$$

which is the spectral decomposition of $\hat{A}$. The collection $\set{\hat{P}_A (\lambda)}_{\lambda\in\R}$ are projection operators with properties
1. **Boundedness:** Since a step-function is bounded by $1$, it follows that $\norm{\hat{P}_A (\lambda)} \leq \norm{\psi}$ for all $\ket{\psi}\in\mathcal{H}$. In particular $\hat{P}_A (\lambda)$ is self-adjoint.

2. **Limits at infinity:**
$$
\begin{align*}
  \hat{P}_A (-\infty) =& \lim_{\lambda\to -\infty} \hat{P}_A (\lambda) = \mathbf{0}
  \hat{P}_A (\infty) =& \lim_{\lambda\to \infty} \hat{P}_A (\lambda) = \hat{I} \tag{\label{equation-159}}
$$

4. **Monotonicity:** If $\lambda_1 < \lambda_2$, then $\hat{P}_A (\lambda_1) \leq \hat{P}_A (\lambda_2)$, i.e.
$$
  \braket{\psi|\hat{P}_A (\lambda_1)|\psi} \leq \braket{\psi|\hat{P}_A (\lambda_2)|\psi}
$$

5. **Projection property:**
$$
  \hat{P}_A (\lambda_1) \hat{P}_A (\lambda_2) = \hat{P}_A (\min\set{\lambda_1, \lambda_2})
$$

The limit $\eqref{equation-159}$ implies the resolution of the identity operator

$$
\begin{equation*}
  \hat{I} = \int_{-\infty}^\infty \d\hat{P}_A (\lambda)
\tag{\label{equation-154}}
\end{equation*}
$$

which rigorously encodes completenes of the spectral projectors. From $\eqref{equation-154}$, the norm of any $\ket{\psi}\in\mathcal{H}$ can be written as
$$
\begin{align*}
  \norm{\psi}^2 =& \braket{\psi|\psi} = \int_{-\infty}^\infty \d\braket{\psi|\hat{P}_A (\lambda)|\psi} \\
  =& \int_{-\infty}^\infty \d\norm{\hat{P}_A (\lambda) \psi}^2 \tag{\label{equation-157}}
\end{align*}
$$

To study the spectrum of $\hat{A}$, consider the projection corresponding to a small interval around $\lambda_0$

$$
\begin{align*}
  \hat{E}_{\lambda_0, \epsilon} :=& [\hat{P}_A (\lambda_0 + \epsilon) - \hat{P}_A (\lambda_0 - \epsilon)] \\
  =& \int_{\lambda_0 - \epsilon}^{\lambda_0 + \epsilon} \d\hat{P}_A (\lambda) \tag{\label{equation-155}}
\end{align*}
$$

If $\lambda_0$ is an isolated point of the spectrum $\sigma(\hat{A})$, there exists $\epsilon > 0$ such that $\hat{A}$ has no spectrum in $(\lambda_0 - \epsilon, \lambda_0 + \epsilon)$ except $\lambda_0$ itself. Then $\hat{E}_{\lambda_0, \epsilon}$ projects onto the nonempty subspace

$$
  \mathcal{H}_{\lambda_0} = \hat{E}_{\lambda_0, \epsilon} \mathcal{H}
$$

In the limit $\epsilon\to 0$, then $\mathcal{H}_{\lambda_0}$ contains at least one vector, say, $\ket{\psi}$, and

$$
  [\hat{P}_A (\lambda_0 + 0) - \hat{P}_A (\lambda_0 - 0)] \ket{\psi} = \ket{\psi}
$$

Accordingly, from $\eqref{equation-156}$, $\eqref{equation-154}$ and $\eqref{equation-157}$

$$
\begin{align*}
  \norm{(\hat{A} - \lambda_0)\psi}^2 =& \int_{-\infty}^\infty (\lambda - \lambda_0)^2 \;\d\norm{\hat{P}_A (\lambda) \psi}^2 \\
  =& \int_{\lambda_0 - 0}^{\lambda_0 + 0} (\lambda - \lambda_0)^2 \;\d\norm{\hat{P}_A (\lambda) \psi}^2 = 0
\end{align*}
$$

where we have also used $\eqref{equation-155}$ and $\eqref{equation-157}$. Thus, $(\hat{A} - \lambda_0)\ket{\psi}$ is the zero vector, i.e.

$$
  \hat{A}\ket{\psi} = \lambda_0 \ket{\psi}
$$

which is the familiar discrete eigenvalue equation. Thus, a discrete eigenvalue corresponds precisely to a discontinuity of the spectral projectors $\hat{P}_A (\lambda)$ at $\lambda_0$.

If $\lambda_0$ is not an isolated eigenvalue of $\hat{A}$, for which every neighbourhood of $\lambda_0$ intersects the spectrum $\sigma(\hat{A})$ in more than one point, then 

$$
  \lim_{\epsilon\to 0} \hat{E}_{\lambda_0, \epsilon} = \mathbf{0}
$$

For such a point the eigenspace $\hat{E}_{\lambda_0, 0} \mathcal{H}$ is empty, meaning that there are no proper eigenvectors corresponding to the continuous spectrum of $\hat{A}$. However, we can construct approximate eigenvectors that are localized in small spectral intervals around $\lambda_0$. For $\epsilon > 0$, choose a normalized vector $\ket{\psi(\epsilon)} \in \operatorname{ran}(\hat{E}_{\lambda_0, \epsilon})$ with $\norm{\psi(\epsilon)} = 1$, such that

$$
  \hat{E}_{\lambda_0, \epsilon} \ket{\psi(\epsilon)} = \ket{\psi(\epsilon)}
$$

Thus

$$
  \norm{(\hat{A} - \lambda_0) \psi(\epsilon)}^2 = \int_{\lambda_0 - \epsilon}^{\lambda_0 + \epsilon} (\lambda - \lambda_0)^2 \;\d\norm{\hat{P}_A (\lambda) \psi(\epsilon)}^2
$$

where the right-hand side is bounded above by

$$
  \epsilon^2 \int_{\lambda_0 - \epsilon}^{\lambda_0 + \epsilon} \d\norm{\hat{P}_A (\lambda) \psi(\epsilon)}^2 = \epsilon^2 \int_{-\infty}^\infty \d\norm{\hat{P}_A (\lambda)\psi(\epsilon)}^2 = \epsilon^2
$$

which follows from the normalizability of $\ket{\psi(\epsilon)}$ for $\epsilon > 0$. This means that we can find a vector $\ket{\psi(\epsilon)} \in\mathcal{H}$ such that

$$
\begin{equation*}
  \norm{(\hat{A} - \lambda_0) \psi(\epsilon)} \leq \epsilon > 0
\tag{\label{equation-158}}
\end{equation*}
$$

This means that $\set{\ket{\psi(\epsilon)}}$ forms a sequence of approximate eigenvectors satisfying

$$
  \lim_{\epsilon\to 0} \norm{(\hat{A} - \lambda_0) \psi(\epsilon)} = 0
$$

but with no actual eigenvector limit in $\mathcal{H}$.

From this analysis the spectrum of a self-adjoint operator $\hat{A}$ can be defined as

$$
  \sigma(\hat{A}) = \set{\lambda_0 \in \R : \hat{E}_{\lambda_0, \epsilon} \neq \mathbf{0},\; \forall \epsilon > 0}
$$

Equivalently

$$
  \inf_{\ket{\psi}\in\mathcal{D}(\hat{A}),\;\norm{\psi}=1} \norm{(\hat{A} - \lambda_0 ) \psi} = 0
$$

that is, for every neighbourhood of $\lambda_0$ we can find a normalized vector whose image under $(\hat{A} - \lambda)$ has arbitrarily small norm.

For $\lambda \in\R \setminus \sigma(\hat{A})$, the operator $(\hat{A} - \lambda_0 \hat{I})$ is invertible and its inverse

$$
  \hat{R}(\lambda; \hat{A}) := (\hat{A} - \lambda\hat{I})^{-1}
$$

called the resolvent, is bounded on all of $\mathcal{H}$. For $\epsilon > 0$, an approximate eigenvector can be written

$$
  \ket{\phi(\epsilon)} = (\hat{A} - \lambda_0 \hat{I}) \ket{\psi(\epsilon)}
$$

Using the normalizability for $\ket{\psi(\epsilon)}$, we have from $\eqref{equation-158}$

$$
  \norm{\ket{\phi(\epsilon)}} \leq \epsilon = \epsilon \norm{\hat{R}(\lambda; \hat{A}) \phi(\epsilon)}
$$

which leads to

$$
  \frac{\norm{\hat{R}(\lambda; \hat{A}) \phi(\epsilon)}}{\norm{\phi(\epsilon)}} \geq \frac{1}{\epsilon}
$$

This implies that $\hat{R}(\lambda; \hat{A})$ is unbounded a spectral points $\lambda_0 \in\sigma(\hat{A})$, i.e.

$$
  \norm{\hat{R}(\lambda; \hat{A})} \xrightarrow{\lambda\to\lambda_0} \infty
$$


<MathBox title="Asymptotic orthogonality of approximate eigenvectors" boxType="proposition">
Let $\hat{A}$ be a self-adjoint operator on a Hilbert space $\mathcal{H}$, and let $\lambda_1, \lambda_2 \in \sigma(\hat{A})$ with $\lambda_1 \neq \lambda_2$. For each $j = 1,2$, let $\epsilon_j > 0$ and let $\ket{\psi_j (\epsilon_j)} \in\mathcal{H}$ be normalized vectors, i.e. $\norm{\psi_j (\epsilon_j)} = 1$, satisfying the approximate eigenvalue condition

$$
  \norm{(\hat{A} - \lambda_j) \psi_j (\epsilon_j)} \leq \epsilon_j \; j=1,2
$$

In the limit $\epsilon_j \to 0$, the following orthogonality relation holds

$$
\begin{equation*}
  \lim_{\substack{\epsilon_1 \to 0 \\ \epsilon_2 \to 0}} \braket{\psi_1 (\epsilon_1) | \psi_2 (\epsilon_2)} = 0
\tag{\label{equation-160}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Write

$$
\begin{align*}
  (\lambda_1 - \lambda_2) \braket{\psi_1 (\epsilon_1) | \psi_2 (\epsilon_2)} =& \braket{\psi_1 (\epsilon_1)|(\hat{A} - \lambda_2 \hat{I})|\psi_2 (\epsilon_2) } \\
  &- \braket{\psi_1 (\epsilon_1)|(\hat{A} - \lambda_1 \hat{I})|\psi_2 (\epsilon_2) }
\end{align*}
$$

Taking the norm and applying the triangle and Cauchy-Schwarz inequalities we get

$$
\begin{align*}
  |(\lambda_1 - \lambda_2)|\cdot |\braket{\psi_1 (\epsilon_1) | \psi_2 (\epsilon_2)}| \leq& \norm{\braket{\psi_1 (\epsilon_1)|(\hat{A} - \lambda_2 \hat{I})|\psi_2 (\epsilon_2)} \\
  &+ \norm{\braket{\psi_1 (\epsilon_1)|(\hat{A} - \lambda_1 \hat{I})|\psi_2 (\epsilon_2) }} \\
  \leq& \epsilon_1 + \epsilon_2
\end{align*}
$$

such that

$$
\begin{equation*}
  |\braket{\psi_1 (\epsilon_1) | \psi_2 (\epsilon_2)} \leq \frac{\epsilon_1 + \epsilon_2}{|\lambda_1 - \lambda_2|}
\tag{\label{equation-161}}
\end{equation*}
$$

Taking the limit $\epsilon_1, \epsilon_2 \to 0$ yields the orthogonality condition $\eqref{equation-160}$.
</details>
</MathBox>


From the orthogonality relation $\eqref{equation-160}$, we can derive the following special cases for distinct $\lambda_1, \lambda_2 \in\sigma(\hat{A})$ in the spectrum of a self-adjoint operator $\hat{A}$:

1. **Discrete-discrete case:** If both $\lambda_1, \lambda_2$ are isolated eigenvalues and $\epsilon_1, \epsilon_2 = 0$, then $\ket{\psi_1}, \ket{\psi_2}$ are exact eigenvectors, satisfying the standard orthogonality relation
$$
  \braket{\psi_1 | \psi_2} = 0
$$

2. **Continuous-continuous case:** If both $\lambda_1, \lambda_2$ belong to the continuous spectrum, then we can choose approximate eigenvectors $\psi_j (\epsilon_j)$ for $j = 1,2$ with spectral support in disjoint intervals $(\lambda_j - \epsilon_j, \lambda_j + \epsilon_j)$, whose inner product vanishes in the limit $\epsilon_j \to 0$.

3. **Discrete-continuous case:** If $\lambda_1$ is an eigenvalue and $\lambda_2$ lies in the continuous spectrum, we can take

$$
\begin{gather*}
  \hat{A}\ket{\psi_1} = \lambda_1 \ket{\psi_1} \\
  \norm{(\hat{A} - \lambda_2 \hat{I}) \ket{\psi_2 (\epsilon_2)}} \leq \epsilon_2
\end{gather*}
$$

From $\eqref{equation-161}$, we get

$$
  |\braket{\psi_1 | \psi_2 (\epsilon_2)}| \leq \frac{\epsilon_2}{|\lambda_1 - \lambda_2} \xrightarrow{\epsilon_2 \to 0} 0
$$

### Completeness relation

If $\hat{A}$ is a self-adjoint operator on a Hilbert space with spectrum $\sigma(\hat{A})$, there is a projection-valued measure $E(\lambda)$ such that

$$
  \hat{A} = \int_{\sigma(\hat{A})} \lambda\;\d E(\lambda)
$$

In particular, if $\hat{A}$ has both discrete and continuous spectra, i.e. $\sigma(\hat{A}) = \sigma_\text{d} (\hat{A}) \cup \sigma_\text{c} (\hat{A})$, where
- $\sigma_\text{d} (\hat{A}) = \Set{a_i}$ is the set of discrete eigenvalues with corresponding eigenvectors $\set{\ket{a_i}}$
- $\sigma_\text{c} (\hat{A})$ is the continuum of eigenvalues with corresponding eigenfunctions $\set{\ket{\lambda}}$

then the identity operator $\hat{I}$ can be decomposed as

$$
  \hat{I} = \sum_i \ket{a_i} \bra{a_i} + \int_{\sigma_{\text{c}}(\hat{A})} \ket{\lambda}\bra{\lambda}\;\d\lambda
$$

which is known as the completeness relation.

## Tensor products

Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be Hilbert spaces. For $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$, we define the map $\ket{\varphi}\otimes\ket{\psi}:\mathcal{H}_A \times \mathcal{H}_B \to \mathbb{C}$ as

$$
  (\xi, \eta) \mapsto \braket{\xi|\varphi}_{\mathcal{H}_A} \braket{\eta|\psi}_{\mathcal{H}_B}
$$

called a tensor product. This is map is continuous and anti-linear in both $\xi$ and $\eta$. The set of all such maps is denoted

$$
  \mathcal{H}_A \otimes \mathcal{H}_B : \set{\Psi : \mathcal{H}_A \times \mathcal{H}_B \to \mathbb{C} | \text{anti-linear and continuous}}
$$

This set forms a vector space over $\mathbb{C}$ since for $\Psi_1, \Psi_2 \in\mathcal{H}_A \otimes \mathcal{H}_B$ and $a, b \in\mathbb{C}$, the map defined by

$$
  (a\Psi_1 + b\Psi_2)(\xi, \eta) := a\Psi_1 (\xi,\eta) + b\Psi_2 (\xi,\eta)
$$

is also in $\mathcal{H}_A \otimes \mathcal{H}_B$. The zero map is the zero vector in this vector space, and for any $\Psi \in \mathcal{H}_A \otimes \mathcal{H}_B$, the map $-\Psi$ is its additive inverse. In other words, the tensor product $\ket{\varphi}\otimes\ket{\psi}$ is a vector in the vector space of the anti-linear and continuous maps $\mathcal{H}_A \otimes \mathcal{H}_B$ from $\mathcal{H}_A \times \mathcal{H}_B$ to $\mathbb{C}$. More compactly, we also write

$$
  \ket{\varphi\otimes\psi} := \ket{\varphi}\otimes\ket{\psi}
$$

The tensor product has the following properties:
1. **Homogeneity:**
$$
  (a\ket{\varphi})\otimes\ket{\psi} = \ket{\varphi}\otimes (a\ket{\psi}) = a(\ket{\varphi} \otimes\ket{\psi})
$$
2. **Distributivity over scalar multiplication:**
$$
  a(\ket{\varphi}\otimes\ket{\psi}) + b(\ket{\varphi} \otimes\ket{\psi}) = (a + b)\ket{\varphi} \otimes \ket{\psi}
$$
3. **Distributivity over vector addition in the first argument:**
$$
  (\ket{\varphi_1} \otimes \ket{\varphi_2}) \otimes \ket{\psi} = \ket{\varphi_1}\otimes\ket{\psi} + \ket{\psi_2}\otimes\ket{\psi}
$$
4. **Distributivity over vector addition in the second argument:**
$$
  \ket{\psi}\otimes(\ket{\psi_1} + \ket{\psi_2}) = \ket{\varphi}\otimes\ket{\psi_1} + \ket{\varphi}\otimes\ket{\psi_2}
$$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  [(a\ket{\varphi})\otimes\ket{\psi}](\xi,\eta) =& \braket{\xi|a\varphi} \braket{\eta|\psi} \\
  =& a\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& a(\ket{\varphi}\otimes\ket{\psi})(\xi,\eta)
\end{align*}
$$

Similarly,

$$
\begin{align*}
  [\ket{\varphi} \otimes(a\ket{\psi})](\xi,\eta) =& \braket{\xi|\varphi} \braket{\eta|a\psi} \\
  =& a\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& \braket{\xi|a\varphi} \braket{\eta|\psi} \\
  =& [(a\ket{\varphi})\otimes\ket{\psi}](\xi,\eta)
\end{align*}
$$

**(2):**

$$
\begin{align*}
  [a(\ket{\varphi}\otimes\ket{\psi}) + b(\ket{\varphi} \otimes\ket{\psi})](\xi,\eta) =& a(\ket{\varphi}\otimes\ket{\psi})(\xi,\eta) + b(\ket{\varphi}\otimes\ket{\psi})(\xi,\eta) \\
  =& a\braket{\xi|\varphi}\ket{\eta|\psi} + b\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& (a + b)\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& (a + b)(\ket{\varphi}\otimes(\ket{\psi}))(\xi,\eta)
\end{align*}
$$

**(3):**

$$
\begin{align*}
  [(\ket{\varphi_1}\otimes\ket{\varphi_2})\otimes\ket{\psi}](\xi, \eta) =& \bra{\xi}(\ket{\varphi_1} + \ket{\varphi_2})\braket{\eta|\psi} \\
  =& (\braket{\xi|\varphi_1} + \braket{\xi|\varphi_2})\braket{\eta|\psi} \\
  =& \braket{\xi|\varphi_1}\braket{\eta|\psi} + \braket{\xi|\varphi_2}\braket{\eta|\psi} \\
  =& (\ket{\varphi_1}\otimes\ket{\psi} + \ket{\varphi_2}\otimes\ket{\psi})(\xi,\eta)
\end{align*}
$$

**(4):**

$$
\begin{align*}
  [\ket{\varphi}\otimes(\ket{\psi_1} + \ket{\psi_2})](\xi,\eta) =& \braket{\xi|\varphi}\bra{\eta}(\ket{\psi_1} + \ket{\psi_2}) \\
  =& \braket{\xi|\varphi}(\braket{eta|\psi_1} + \braket{\eta|\psi_2})
  =& ket{\varphi}\otimes\ket{\psi_1} + \ket{\varphi}\otimes\ket{\psi_2} \\
  =& (\ket{\varphi}\otimes\ket{\psi_1} + \ket{\varphi}\otimes\ket{\psi_2})(\xi,\eta)
\end{align*}
$$
</details>

For vectors $\ket{\varphi_k}\otimes\ket{\psi_k}\in\mathcal{H}_A \otimes \mathcal{H}_B$ with $k\in\set{1,2}$ and $\ket{\varphi_k}\in\mathcal{H}_A$, $\ket{\psi_k}\in\mathcal{H}_B$, we define the inner product as

$$
  \braket{\varphi_1 \otimes \psi|\varphi_2 \otimes\psi_2} := \braket{\varphi_1|\varphi_2}_{\mathcal{H}_A} \braket{\psi_1|\psi_2}_{\mathcal{H}_B}
$$

This defines an inner product for simple tensor product vectors $\ket{\varphi}\otimes\ket{\psi}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$. To extend this to all vectors $\Psi\in\mathcal{H}_A \otimes\mathcal{H}_B$, we consider an orthonormal basis for each Hilbert subspace. Let $\set{\ket{e_a}}\subset\mathcal{H}_A$ be an orthonormal basis in $\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$ be an orthonormal basis in $\mathcal{H}_B$. The set $\set{\ket{e_a}\otimes\ket{f_b}}\subset \mathcal{H}_A \otimes \mathcal{H}_B$ then forms an orthonormal basis for $\mathcal{H}_A \otimes \mathcal{H}_B$ since

$$
  \braket{e_{a_1} \otimes f_{b_1}|e_{a_2} \otimes f_{b_2}} = \braket{e_{a_1}|e_{a_2}}\braket{f_{b_1}|f_{b_2}} = \delta_{a_1 a_2} \delta_{b_1 b_2}
$$

<details>
<summary>Details</summary>

To verify that $\set{\ket{e_a}\otimes\ket{f_b}}$ is linearly independent, suppose there exists coefficients $\Psi_{ab}\in\mathbb{C}$ such that

$$
  \sum_{a,b} \Psi_{ab} \ket{e_a \otimes e_b} = 0 \in \mathcal{H}_A \otimes \mathcal{H}_B
$$

Applying this to an arbitrary pair $(\xi,\eta)\in\mathcal{H}_A \times \mathcal{H}_B$, we obtain

$$
  \left(\sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b}\right)(\xi,\eta) = \sum_{a,b} \Psi_{ab} \braket{e_a|\xi} \braket{f_b|\eta} = 0
$$

and in particular for every $(\xi,\eta) = (e_{a'}, f_{b'})$, we get

$$
  0 = \sum_{a,b} \Psi_{ab} \underbrace{\braket{e_a|e_{a'}}}_{\delta_{a,a'}} \underbrace{\braket{f_b|f_{b'}}}_{\delta_{b,b'}} = \Psi_{a', b'} 
$$

Since this holds for all $a'$ and $b'$, it follows that $\Psi_{ab} = 0$ for all $a, b$, proving that $\set{\ket{e_a}\otimes\ket{f_b}}$ is linearly independent.
</details>

Equivalently, for linear functionals acting on tensor product states, we define

$$
  \braket{\varphi_1 \otimes \psi_1}(\ket{\varphi_2} \otimes \ket{\psi_2}) = \braket{\varphi_1 \otimes \psi_1 | \varphi_2 \otimes \psi_2} = \braket{\varphi_1|\varphi_2}\braket{\psi_1|\psi_2}
$$

so that

$$
  \bra{\varphi\otimes\psi} = \ket{\varphi}\otimes\ket{\psi}
$$

In terms of orthonormal bases $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$, we can expand an arbitrary vector $\Psi\in\mathcal{H}_A \otimes \mathcal{H}_B$ as

$$
\begin{align*}
  \Psi(\xi,\eta) =& \Psi\left(\sum_a \ket{e_a}\braket{e_a|\xi}, \sum_b \ket{f_b}\braket{f_b|\eta} \right) \\
  =& \sum_{a,b} \underbrace{\Psi(\ket{e_a},\ket{f_b})}_{=:\Psi_{ab}\in\mathbb{C}} \braket{\xi|e_a}\braket{\eta|f_b} \\
  =& \sum_{a,b} \Psi_{ab}(\ket{e_a}\otimes\ket{f_b})(\xi, \eta) \\
  =& \sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b}(\xi,\eta)
\end{align*}
$$

showing that every vector $\ket{\Psi}\in\mathcal{H}_A \otimes \mathcal{H}_B$ can be written as a linear combination

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b}
$$

Given another vector $\ket{\Phi} = \sum_{a,b} \Phi_{ab} \ket{e_a \otimes f_b}$, the inner product is defined as

$$
\begin{equation*}
\begin{split}
  \braket{\Psi|\Phi} =& \sum_{a_1,b_1} \sum_{a_2,b_2} \Psi_{a_1 b_1}^* \Phi_{a_2 b_2} \braket{e_{a_1} \otimes f_{b_1}|e_{a_2} \otimes f_{b_2}} \\
  =& \sum_{a,b} \Psi_{ab}^* \Phi_{ab}
\end{split}
\tag{\label{equation-110}}
\end{equation*}
$$

<details>
<summary>Details</summary>

To verify that $\eqref{equation-110}$ is positive-definite, consider an orthonormal basis $\set{\ket{e_a}}$ of $\mathcal{H}_A$ and $\set{\ket{f_b}}$ of $\mathcal{H}_B$. Then for any $\ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a \otimes e_b}$, we have

$$
  \braket{\Psi|\Psi} = \sum_{a,b} |\Psi_{ab}|^2 \geq 0
$$

and thus

$$
  \braket{\Psi|\Psi} = 0 \iff \Psi_{ab} = 0 \forall a,b \iff \ket{\Psi} = 0
$$

This shows that $\braket{\Psi|\Phi}$ defines a valid inner product.

To show that the inner product is independent of the choice of orthonormal basis, let $\set{\ket{\tilde{e}_a}} \subset\mathcal{H}_A$ and $\set{\ket{\tilde{f}_b}}\subset\mathcal{H}_B$ be alternative orthonormal bases, related to the original bases by unitary transformations

$$
\begin{align*}
  \ket{\tilde{e}_a} =& \hat{U}_A \ket{e_a} = \sum_{a_1} \braket{e_{a_1}|\hat{U}_A e_a} \ket{e_{a_i}} = \sum_{a_1} \mathbf{U}_{a_1 a}^{(A)} \ket{e_{a_1}} \\
  \ket{\tilde{b}_a} =& \hat{U}_B \ket{f_b} = \sum_{b_1} \braket{f_{b_1}|\hat{U}_B f_b} \ket{f_{b_i}} = \sum_{b_1} \mathbf{U}_{b_1 b}^{(B)} \ket{f_{b_1}}
\end{align*}
$$

Expanding $\ket{\Phi}$ in terms of the new basis, we have

$$
\begin{align*}
  \ket{\Phi} =& \sum_{a_1, b_1} \Phi_{a_1 b_1} \ket{e_{a_1} \otimes f_{b_1}} = \sum_{a,b} \tilde{\Phi}_{ab} \ket{\tilde{e}_a \otimes \tilde{f}_b} \\
  =& \sum_{a,b} \tilde{\Phi}_{ab} \sum_{a_1} \mathbf{U}_{a_1 a}^{(A)} \ket{e_{a_1}} \otimes \sum_{b_1} \mathbf{U}_{b_1 b}^{(B)} \ket{f_{b_1}} \\
  =& \sum_{a_1, b_1} \sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Phi}_{ab} \ket{e_{a_1} \otimes f_{b_1}}
\end{align*}
$$

from which it follows that

$$
  \Psi_{a_1, b_1} = \sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Phi}_{ab}
$$

Similarly, we obtain

$$
  \Psi_{a_1 b_1} = \sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Psi}_{ab}
$$

Substituting the expansions into the inner product yields

$$
\begin{align*}
  \sum_{a_1 b_1} \Psi_{a_1 b_1}^* \Phi_{a_1 b_1} =& \sum_{a_1, b_1} \left(\sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Phi}_{ab} \right)^* \sum_{a_2, b_2} \mathbf{U}_{a_1 a_2}^{(A)} \mathbf{U}_{b_1 b_2}^{(B)} \tilde{\Phi}_{a_2 b_2} \\
  =& \sum_{a, b} \sum_{a_2, b_2} \sum_{a_1, b_1} (\mathbf{U}_{a_1 a}^{(A)})^* \mathbf{U}_{a_1 a_2}^{(A)} (\mathbf{U}_{b_1 b}^{(B)})^* \mathbf{U}_{b_1 b_2}^{(B)} \tilde{\Psi}_{ab}^* \tilde{\Phi}_{a_2 b_2} \\
  =& \sum_{a, b} \sum_{a_2, b_2} \underbrace{\left(\sum_{a_1} (\mathbf{U}_{aa_1}^{(A)})^\dagger \mathbf{U}_{a_1 a_2}^{(A)}\right)}_{=\delta_{aa_2}} \underbrace{\left(\sum_{b_1} (\mathbf{U}_{bb_1}^{(B)})^\dagger \mathbf{U}_{b_1 b_2}^{(B)}\right)}_{=\delta_{bb_2}} \tilde{\Psi}_{ab} \tilde{\Phi}_{a_2 b_2} \\
  =& \sum_{a,b} \tilde{\Psi}_{ab}^* \tilde{\Phi}_{ab}
\end{align*}
$$

showing that $\braket{\Psi|\Phi}$ remains invariant under a change of basis.
</details>

The dual vector (covector) associated with $\ket{\Psi}$ is given by

$$
  \bra{\Psi} = \sum_{a,b} \Psi_{ab}^* \ket{e_a \otimes f_b}
$$

The norm of $\ket{\Psi}$ is follows from the inner product definition:

$$
  \norm{\Psi}^2 = \braket{\Psi|\Psi} = \sum_{a,b} |\Psi_{ab}|^2
$$

For any $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$, the norm of $\ket{\varphi}\otimes\ket{\psi}$ is

$$
\begin{align*}
  \norm{\varphi\otimes\psi} =& \sqrt{\braket{\varphi\otimes\psi|\varphi\otimes\psi}} \\
  =& \sqrt{\braket{\varphi|\varphi}\braket{\psi|\psi}} = \norm{\varphi}\cdot\norm{\psi}
\end{align*}
$$

This shows that $\mathcal{H}_A \otimes \mathcal{H}_B$ is a complex inner product space. For finite-dimensional subspaces, completeness in the induced norm follows, implying that $\mathcal{H}_A \otimes \mathcal{H}_B$ is a Hilbert space, known as the tensor product Hilbert space. Its dimension is given by

$$
  \dim(\mathcal{H}_A \otimes \mathcal{H}_B) = \dim(\mathcal{H}_A) \dim(\mathcal{H}_B)
$$

<details>
<summary>Proof</summary>

If $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$ are finite-dimensional orthonormal bases, then $\set{\ket{e_a \otimes f_b}}$ forms an orthonormal basis in the tensor product $\mathcal{H}_A \otimes \mathcal{H}_B$. The dimension of the tensor product is given by the number basis, which is the product of the which is the product of the dimensions of the individual subspaces
</details>

Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional complex Hilbert spaces with $\dim(\mathcal{H}_A) = n_A$ and $\dim(\mathcal{H}) = n_B$, respectively. Suppose they have orthonormal bases $\set{\ket{e_a}}_{a=1}^{n_A}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}_{b=1}^{n_B}$. The tensor product space $\mathcal{H}_A \otimes \mathcal{H}_B$ has an orthonormal basis $\set{\ket{e_a \otimes f_b}}$ and we establish the isomorphism $\mathcal{H}_A \otimes \mathcal{H}_B \cong \mathbb{C}^{n_A n_B}$ by identifying each basis with a standard basis vectors in $\mathbb{C}^{n_A n_B}$, i.e.

$$
  \ket{e_a \otimes f_b} = \mathbf{e}_{(a-1)n_B + b} \in\mathbb{C}^{n_A n_B}
$$

Conceptually, this partitions the $n_A n_B$ coordinates of a vector in $\mathbb{C}^{n_A n_B}$ into $n_A$ row-blocks of $n_B$ entries each. For a general vector $\ket{\Psi}\in\mathcal{H}_A \otimes \mathcal{H}_B$, we have

$$
  \ket{\Psi} = \sum_{a=1}^{n_A} \sum_{b=1}^{n_B} \Psi_{ab} \ket{e_a \otimes f_b} = \begin{matrix} 1 \\ \vdots \\ (a - 1)n_B + b \\ \vdots \\ n_A n_B \end{matrix} \begin{bmatrix} \Psi_{11} \\ \vdots \\ \Psi_{ab} \\ \vdots \\ \Psi_{n_A n_B} \end{bmatrix}
$$

For several tensor products, such as $\mathcal{H}_A \otimes \mathcal{H}_B \otimes \mathcal{H}_C$, associativity holds

$$
  (\mathcal{H}_A \otimes \mathcal{H}_B) \otimes \mathcal{H}_C = \mathcal{H}_A \otimes (\mathcal{H}_B \otimes \mathcal{H}_C) = \mathcal{H}_A \otimes \mathcal{H}_B \otimes \mathcal{H}_C
$$

and accordingly

$$
  \braket{\varphi_1 \otimes \psi_1 \otimes \chi_1 | \varphi_2 \otimes \psi_2 \otimes \chi_2} = \braket{\varphi_1|\varphi_2}\braket{\psi_1|\psi_2}\braket{\chi_1|\chi_2}
$$

Likewise, with orthonormal bases $\set{\ket{e_a}}\subset\mathcal{H}_A$, $\set{\ket{f_b}}\subset\mathcal{H}_B$ and $\set{\ket{g_c}}\subset\mathcal{H}_C$, a vector $\ket{\Psi}\in\mathcal{H}^A \otimes \mathcal{H}_B \otimes \mathcal{H}_C$ can be expanded as

$$
  \ket{\Psi} = \sum_{a,b,c} \Psi_{abc} \ket{\psi_a \otimes f_b \otimes g_c}, \; \Psi_{abc}\in\mathbb{C}
$$

### Operators on tensor products

Let $\hat{M}^X : \mathcal{H}_X \to\mathcal{H}_X$ be Hermitian operators for $X \in\set{A,B}$. The tensor product operator $\hat{M}_A \otimes \hat{M}_B$ act factor-wise on a tensor product $\ket{\varphi\otimes\psi} = \ket{\varphi}\otimes\ket{\psi}$:

$$
  (\hat{M}_A \otimes \hat{M}_B) \ket{\varphi\otimes\psi} = \underbrace{(\hat{M}_A \ket{\varphi})}_{\in\mathcal{H}_A} \otimes \underbrace{\hat{M}_B \ket{\psi}}_{\in\mathcal{H}_B}
$$

By linearity, for an arbitrary vector $\ket{\Phi}\in\mathcal{H}_A \otimes \mathcal{H}_B$ expanded as

$$
  \ket{\Phi} = \sum_{a,b} \Phi_{ab} \ket{e_a} \otimes \ket{f_b}
$$

the tensor product operator acts as

$$
  (\hat{M}_A \otimes \hat{M}_B)\ket{\Phi} = \sum_{a,b} \Phi_{ab} (\hat{M}_A \ket{e_a}) \otimes (M_B \ket{f_b}) \in \mathcal{H}_A \otimes \mathcal{H}_B
$$

The Hermitian adjoint of the tensor product operator is given by

$$
  (\hat{M}_A \otimes \hat{M}_B)^\dagger = \hat{M}_A^\dagger \otimes \hat{M}_B^\dagger
$$

If $\hat{M}_A$ and $\hat{M}_B$ are Hermitian, i.e. $\hat{M}_X^\dagger = \hat{M}_X$ for $X\in\set{A,B}$, it follows that their tensor product is also Hermitian:

$$
  (\hat{M}_A \otimes \hat{M}_B)^\dagger = \hat{M}_A \otimes \hat{M}_B
$$

<details>
<summary>Proof</summary>

For $i\in\set{1,2}$ let $\ket{\varphi_i} \in\mathcal{H}_A$ and $\ket{\psi_i}\in\mathcal{H}_B$. Then we have

$$
\begin{align*}
  \Braket{(\hat{M}_A \otimes \hat{M}_B)^\dagger \varphi_1 \otimes \psi_1 | \varphi_2 \otimes \psi_2} =& \Braket{\varphi_1 \otimes\psi |(\hat{M}_A \otimes \hat{M}_B)|\varphi_2 \otimes \psi_2} \\
  =& \Braket{\varphi_1 \otimes \psi_1 | \hat{M}_A \varphi_2 \otimes \hat{M}_B \psi_2} \\
  =& \braket{\varphi_1 | \hat{M}_A| \varphi_2} \braket{\psi_1 |\hat{M}_B|\psi_2} \\
  =& \braket{\hat{M}_A^\dagger \varphi_1 | \varphi_2} \braket{\hat{M}_B^\dagger \psi_1 | \psi_2} \\
  =& \Braket{\hat{M}_A^\dagger \varphi_1 \otimes \hat{M}_B^\dagger \psi_1 | \varphi_2 \otimes \psi_2} \\
  =& \Braket{(\hat{M}_A^\dagger \otimes \hat{M}_B^\dagger)\varphi_1 \otimes \psi_1 | \varphi_2 \otimes \psi_2}
\end{align*}
$$
</details>

Suppose the operators $\hat{M}_X : \mathcal{H}_X \to \mathcal{H}_X$ for $X\in\set{A,B}$ have matrices $\mathbf{M}_{ij}^{(X)}$ in the respective basis $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_n}}\subset\mathcal{H}_B$. To find the matrix for the tensor product $\hat{M}_A \otimes \hat{M}_B$ in the basis $\set{\ket{e_a \otimes f_b}}\subset \mathcal{H}_A \otimes \mathcal{H}_B$, we expand it as

$$
\begin{align*}
  \hat{M}_A \otimes \hat{M}_B =& \sum_{a,a'=1}^{n_A} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b} \Braket{e_a \otimes f_b |(\hat{M}_A \otimes \hat{M}_B)|e_{a'} \otimes f_{b'}} \bra{e_{a'} \otimes f_{b'}} \\
  =& \sum_{a,a'=1}^{n_A} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b} \Braket{e_a \otimes f_b |\hat{M}_A e_{a'} \otimes \hat{M}_B f_{b'}} \bra{e_{a'} \otimes f_{b'}} \\
  =& \sum_{a,a'=1}^{n_A} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b} \braket{e_a | \hat{M}_A | e_{a'}} \braket{f_b | \hat{M}_B f_{b'}} \bra{e_{a'} \otimes f_{b'}} \\
  =& \sum_{a,a'=1}^{n_A} \mathbf{M}_{aa'}^{(A)} \mathbf{M}_{bb'}^{(B)} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b}\bra{e_{a'} \otimes f_{b'}} \tag{\label{equation-111}}
\end{align*}
$$

so that

$$
  \mathbf{M}_{aa'}^{(A)} \mathbf{M}_{bb'}^{(B)} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b}\bra{e_{a'} \otimes f_{b'}} = 
  \overset{\begin{matrix} 1\hphantom{-} & \cdots & \hphantom{\mathbf{M}} k \hphantom{\mathbf{M_{bb'}^{(B)}}} & \cdots & n \end{matrix}}{
  \begin{matrix} 1 \\ \vdots \\ j \\ \vdots \\ n \end{matrix}\begin{bmatrix}
    \vphantom{1}\hphantom{1} & \hphantom{\cdots} & | & \hphantom{\cdots} & \hphantom{n} \\
    \vphantom{\vdots} & & | & &  \\
    -- & -- & \mathbf{M}_{aa'}^{(A)} \mathbf{M}_{bb'}^{(B)} & & \\
    \vphantom{\vdots} & & & & \\
    \vphantom{n} & & & & 
  \end{bmatrix}
  }
$$

where $j = (a - 1)n_B + b$ and $k = (a' - 1)n_B + b'$. Inserting this into the expansion $\eqref{equation-111}$ gives

$$
\begin{gather*}
  \mathbf{M}_A \otimes \mathbf{M}_B = \\
  \overset{\begin{matrix} 1 \hphantom{---} & \cdots & n_B \hphantom{--} & n_B + 1 \hphantom{-} & \cdots & 2n_B \hphantom{--} & \cdots & n_A n_B \hphantom{--} \end{matrix}}{
  \begin{matrix} 1 \\ \vdots \\ n_B \\ n_B + 1 \\ \vdots \\ 2n_B \\ \vdots \\ n_A n_B \end{matrix}\begin{bmatrix}
    \mathbf{M}_{11}^{(A)} \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{11}^{(M)} \mathbf{M}_{1 n_B}^{(B)} & \mathbf{M}_{12}^{(A)} \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{12}^{(A)} \mathbf{M}_{1n_B}^{(B)} & \cdots & \mathbf{M}_{1n_A}^{(A)} \mathbf{M}_{1n_B}^{(B)} \\
    \vdots & & \vdots & \vdots & & \vdots & & \vdots \\
    \mathbf{M}_{11}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{11}^{(M)} \mathbf{M}_{n_B n_B}^{(B)} & \mathbf{M}_{12}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{12}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} & \cdots & \mathbf{M}_{1n_A}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} \\
    \mathbf{M}_{21}^{(A)} \mathbf{M}_{1 1}^{(B)} & \cdots & \mathbf{M}_{21}^{(M)} \mathbf{M}_{1 n_B}^{(B)} & \mathbf{M}_{22}^{(A)} \mathbf{M}_{1 1}^{(B)} & \cdots & \mathbf{M}_{22}^{(A)} \mathbf{M}_{1 n_B}^{(B)} & \cdots & \mathbf{M}_{2n_A}^{(A)} \mathbf{M}_{1 n_B}^{(B)} \\
    \vdots & & \vdots & \vdots & & \vdots & & \vdots \\
    \mathbf{M}_{21}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{21}^{(M)} \mathbf{M}_{n_B n_B}^{(B)} & \mathbf{M}_{22}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{22}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} & \cdots & \mathbf{M}_{2n_A}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} \\
    \vdots & & \vdots & \vdots & & \vdots & & \vdots \\
    \mathbf{M}_{n_A 1}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_A 1}^{(M)} \mathbf{M}_{n_B n_B}^{(B)} & \mathbf{M}_{n_A 2}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_A 2}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} & \cdots & \mathbf{M}_{n_A n_A}^{(A)} \mathbf{M}_{n_B n_B}^{(B)}
  \end{bmatrix}
  }
\end{gather*}
$$

This can be factored as the block matrix

$$
  \mathbf{M}_A \otimes \mathbf{M}_B = \begin{bmatrix} 
    \mathbf{M}_{11}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\ 
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix} & \cdots & \mathbf{M}_{1n_A}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix} \\ 
    \vdots & & \vdots \\
    \mathbf{M}_{n_A 1}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\ 
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix} & \cdots & \mathbf{M}_{n_A n_A}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix}
  \end{bmatrix}
$$

<MathBox title='' boxType='proposition'>
For vectors $\ket{\varphi_1},\ket{\varphi_2}\in\mathcal{H}_A$ and $\ket{\psi_1}, \ket{\psi_2}\in\mathcal{H}_B$ in Hilbert spaces $\mathcal{H}_A$ and $\mathcal{H}_B$, then

$$
  \ket{\varphi_1 \otimes \psi_1}\bra{\varphi_2 \otimes \psi_2} = \ket{\varphi_1}\bra{\varphi_2} \otimes \ket{\psi_1}\bra{\psi_2}
$$

That is, the projection onto a tensor product of vectors is equal to the tensor product of projections onto the factor vectors.

<details>
<summary>Proof</summary>

For any $\ket{\xi_1},\ket{\xi_2}\in\mathcal{H}_A$ and $\ket{\zeta_1},\ket{\zeta_2}\in\mathcal{H}_B$, we have

$$
\begin{align*}
  \Braket{\xi_1 \otimes \zeta_1 |(\ket{\varphi_1 \otimes \psi_1}\bra{\varphi_2 \otimes \psi_2})| \xi_2 \otimes \zeta_2} =& \ \braket{\xi_1 \otimes \zeta_1 | \varphi_1 \otimes \psi_1} \braket{\varphi_2 \otimes \psi_2 | \xi_2 \otimes \zeta_2} \\
  =& \braket{\xi_1|\varphi_1}\braket{\zeta_1|\psi_1}\braket{\varphi_2|\zeta_2}\braket{\psi_2|\zeta_2} \\
  =& \braket{\xi_1|\varphi_1}\braket{\varphi_2|\xi_2}\braket{\zeta_1|\psi_1}\braket{\psi_2|\zeta_2} \\
  =& \Braket{\xi_1 \otimes \zeta_1|(\ket{\varphi_1}\bra{\varphi_2} \otimes \ket{\psi_1}\bra{\psi_2})|\xi_2 \otimes \zeta_2}
\end{align*}
$$
</details>
</MathBox>

### Partial trace

<MathBox title='Partial trace' boxType='definition'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces. The *partial trace* $\operatorname{tr}_B$ over $\mathcal{H}_B$ is defined as the linear map

$$
  \operatorname{tr}_B : \mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B) \to& \mathcal{L}(\mathcal{H}_A)
$$

which for each $\hat{M} \in \mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$ is uniquely characterized by

$$
\begin{equation*}
  \operatorname{tr}\left(\hat{M}_A \operatorname{tr}_B (\hat{M}) \right) = \operatorname{tr}\left((\hat{M}_A \otimes \hat{I}_B)\hat{M}\right),\; \forall \hat{M}_A \in \mathcal{L}(\mathcal{H}_A)
\tag{\label{equation-145}}
\end{equation*}
$$

In other words, $\operatorname{tr}_B (\hat{M}) \in \mathcal{L}(\mathcal{H}_A)$ is the unique operator that reproduces the trace pairings between operators on $\mathcal{H}_A$ and the tensor product space $\mathcal{H}_A \otimes \mathcal{H}_B$.

Similarly, the partial trace $\operatorname{tr}_A$ over $\mathcal{H}_A$ is the linear map

$$
  \operatorname{tr}_A : \mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B) \to& \mathcal{L}(\mathcal{H}_B) \\
$$

uniquely characterized for each $\hat{M} \in \mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$ by

$$
\begin{equation*}
  \operatorname{tr}\left(\hat{M}_B \operatorname{tr}_A (\hat{M}) \right) = \operatorname{tr}\left((\hat{I}_A \otimes \hat{M}_B)\hat{M}\right),\; \forall \hat{M}_B \in\mathcal{L}(\hat{H}_B)
\tag{\label{equation-146}}
\end{equation*}
$$
</MathBox>

<MathBox title='' boxType='proposition'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces with respective orthonormal bases $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$. Consider an operator $\hat{M}\in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$, whose matrix elements in the orthonormal basis $\set{\ket{e_a \otimes f_b}}$ of $\mathcal{H}_A \otimes \mathcal{H}_B$ are given by $\mathbf{M}_{a_1 b_1, a_2 b_2}$.

In the given bases, the partial traces $\operatorname{tr}_A (\hat{M}) \in\mathcal{L}(\mathcal{H}_A)$ and $\operatorname{tr}(\mathcal{H}_B)$ are defined as

$$
\begin{align*}
  \operatorname{tr}_B (\hat{M}) =& \sum_{a_1,a_2,b} \mathbf{M}_{a_1, b, a_2, b} \ket{e_{a_1}} \bra{e_{a_2}} \\
  \operatorname{tr}_A (\hat{M}) =& \sum_{b_1,b_2,a} \mathbf{M}_{ab_1, ab_2} \ket{f_{b_1}} \bra{f_{b_2}}
\end{align*}
$$

The partial traces $\operatorname{tr}_B (\hat{M})$ and $\operatorname{tr}_A (\hat{M})$ do not depend on the choice of the orthonormal bases $\set{\ket{e_a}}$ and $\set{\ket{f_b}}$ and are the unique operators satisfying

$$
\begin{equation*}
\begin{split}
  \operatorname{tr}\left(\hat{M}_A \operatorname{tr}_B (\hat{M})\right) =& \operatorname{tr}\left((\hat{M}_A \otimes \hat{I})\hat{M}\right),\; \forall \hat{M}_A \in\mathcal{L}(\mathcal{H}_A) \\
  \operatorname{tr}\left(\hat{M}_B \operatorname{tr}_A (\hat{M})\right) =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{M}_B)\hat{M}\right),\; \forall \hat{M}_B \in\mathcal{L}(\mathcal{H}_B)
\end{split}
\tag{\label{equation-112}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

We show that $\operatorname{tr}_B (\hat{M})$ satisfy the first equation in $\eqref{equation-112}$. Let $\set{\ket{e_a}}$ be an orthonormal basis in $\mathcal{H}_A$ and $\set{\ket{f_b}}$ an orthonormal basis in $\mathcal{H}_B$. Suppose $\hat{M}\in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$ is given by

$$
  \hat{M} = \sum_{a_1, a_2, b_1, b_2} \mathbf{M}_{a_1 b_1, a_2, b_2} \ket{e_{a_1} \otimes f_{b_1}} \bra{e_{a_2} \otimes f_{b_2}}
$$

Furthermore, let

$$
  \hat{M}_A = \sum_{a_1, a_2} \mathbf{M}_{a_1 a_2}^{(A)} \ket{e_{a_1}} \bra{e_{a_2}}
$$

be an arbitrary operator in $\mathcal{L}(\mathcal{H}_A)$. Then

$$
\begin{align*}
  & \operatorname{tr}[(\hat{M}_A \otimes \hat{I}_B)\hat{M}] \\
  =& \sum_{a_3, b_3} \bra{e_{a_3} \otimes f_{b_3}} (\hat{M}_A \otimes \hat{I}_B) \sum_{a_1, a_2, b_1, b_2} \ket{e_{a_1} \otimes f_{b_1}} \mathbf{M}_{a_1 b_1, a_2 b_2} \braket{e_{a_2} \otimes f_{b_2}|e_{a_3} \otimes f_{b_3}} \\
  =& \sum_{a_1, a_2, b_1, b_2} \braket{e_{a_2} \otimes f_{b_2}|(\hat{M}_A e_{a_1}) \otimes f_{b_1}} \mathbf{M}_{a_1 b_1, a_2, b_2} \\
  =& \sum_{a_1, a_2, b_1, b_2} \braket{e_{a_2}|\hat{M}_A|e_{a_1}} \underbrace{\braket{f_{b_2}|f_{b_1}}}_{=\delta_{b_1 b_2}} \mathbf{M}_{a_1 b_1, a_2 b_2} \\
  =& \sum_{a_1, a_2, b} \mathbf{M}_{a_2 a_1}^{(A)} \mathbf{M}_{a_1 b, a_2 b} \\
  =& \sum_{a_1, a_2} \mathbf{M}_{a_2 a_1}^{(A)} \operatorname{tr}_B (\mathbf{M})_{a_1 a_2} = \sum_{a_2} [\mathbf{M}^A \operatorname{tr}_B (\mathbf{M})]_{a_2 a_2} \\
  =& \operatorname{tr}[\hat{M}_A \operatorname{tr}_B (\hat{M})]
\end{align*}
$$

**Uniqueness**

Next, we show uniqueness. Suppose there exists another operator $\tilde{\operatorname{tr}}_B (\hat{M})$ on $\mathcal{H}_A$ that also satisfies the first equation in $\eqref{equation-112}$. Then, for any $\mathbf{M}_A \in\mathcal{L}(\mathcal{H}_A)$

$$
\begin{align*}
  \operatorname{tr}\left(\hat{M}_A (\tilde{\operatorname{tr}}_B (\hat{M}) - \operatorname{tr}_B (\hat{M})) \right) =& \operatorname{tr}\left(\hat{M}_A \tilde{\operatorname{tr}}_B (\hat{M}) \right) - \operatorname{tr}\left(\mathcal{M}_A \operatorname{tr}(\hat{M}) \right) \\
  =& \operatorname{tr}\left((\hat{M}_A \otimes\hat{I}_B)\hat{M} \right) - \operatorname{tr}\left((\hat{M}_A \otimes\hat{I}_B)\hat{M} \right) \\
  =& 0
\end{align*}
$$

Since this holds for all $\hat{M}_A$, it follows that $\tilde{\operatorname{tr}}_B (\hat{M}) = \operatorname{tr}_B (\hat{M})$.

**Basis independence**

To show that $\operatorname{tr}_B (\hat{M})$ is independent of the choice of basis, let $\set{\ket{\tilde{e}_a}}\subset\mathcal{H}_A$ and $\set{\ket{\tilde{f}_b}}\subset\mathcal{H}_B$ be another set of orthonormal bases, related by unitary transformations

$$
\begin{align*}
  \ket{\tilde{e}_a} =& \hat{U}_A \ket{e_a} = \sum_{a'} \mathbf{U}_{a' a}^{(A)} \ket{e_{a'}} \\
  \ket{\tilde{f}_b} =& \hat{U}_B \ket{f_b} = \sum_{b'} \mathbf{U}_{b' b}^{(B)} \ket{f_{b'}}
\end{align*}
$$

Let $\tilde{\mathbf{M}}_{a_1 b_1, a_2 b_2}$ be the matrix of $\hat{M}$ in the orthonormal basis $\set{\ket{\tilde{e}_a \otimes\tilde{f}_b}}$ such that

$$
\begin{align*}
  \tilde{\mathbf{M}}_{a_1 b_1, a_2 b_2} =& \braket{\tilde{e}_{a_1} \otimes \tilde{f}_{b_1}|\hat{M}|\tilde{e}_{a_2} \otimes \tilde{f}_{b_2}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} \Braket{\mathbf{U}_{a'_1 a_1}^{(A)}  \ket{e_{a'_1}} \otimes \mathbf{U}_{b'_1 b_1}^{(B)} \ket{f_{b'_1}} |\hat{M}|\mathbf{U}_{a'_2 a_2}^{(A)} \ket{e_{a'_2}} \otimes \mathbf{U}_{b'_2 b_2}^{(B)} \ket{f_{b'_2}}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} (\mathbf{U}_{a'_1 a_1}^{(A)})^* (\mathbf{U}_{b'_1 b_1}^{(B)})^* \mathbf{U}_{a'_2 b_2}^{(A)} \mathbf{U}_{b'_2 b_2}^{(B)} \braket{e_{a'_1} \otimes f_{b'_1}|\hat{M}| e_{a'_2} \otimes f_{b'_2}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} (\mathbf{U}_{a'_1 a_1}^{(A)})^* (\mathbf{U}_{b'_1 b_1}^{(B)})^* \mathbf{U}_{a'_2 b_2}^{(A)} \mathbf{U}_{b'_2 b_2}^{(B)} \mathbf{M}_{a'_1 b'_1, a'_2 b'_2}
\end{align*}
$$

Using the fact that $(\mathbf{U}_{a'_1 a_1}^{(A)})^* (\mathbf{U}_{b'_1 b_1}^{(B)})^* = (\mathbf{U}_{a'_1 a_1}^{(A)})^\dagger (\mathbf{U}_{b'_1 b_1}^{(B)})^\dagger$, we obtain

$$
\begin{align*}
  & \sum_{a_1 a_2 b} \tilde{\mathbf{M}}_{a_1 b, a_2 b} \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}} \\
  =& \sum_{a_1 a_2 b a'_1 b'_1 a'_2 b'_2} (\mathbf{U}_{a'_1 a_1}^{(A)})^\dagger (\mathbf{U}_{b'_1 b_1}^{(B)})^\dagger \mathbf{U}_{a'_2 a_2}^{(A)} \mathbf{U}_{b'_2 b}^{(B)} \mathbf{M}_{a'_1 b'_1, a'_2 b'_2} \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} \left(\sum_b \mathbf{U}_{b'_2 b}^{(B)} (\mathbf{U}_{b b'_1}^{(B)})^\dagger \right) \mathbf{M}_{a'_1 b'_1, a'_2 b'_2} \left(\sum_{a_1} (\mathbf{U}_{a'_1 a_1}^{(A)})^\dagger \ket{\tilde{e}_{a_1}} \right) \left(\sum_{a_2} (\mathbf{U}_A^\dagger)_{a'_2 a_2} \bra{\tilde{e}_{a_2}} \right)
\end{align*}
$$

By unitarity of $\hat{U}_A$ and $\hat{U}_B$, we have

$$
  \sum_b \mathbf{U}_{b'_2 b}^{(B)} (\mathbf{U}_{b b'_1}^{(B)})^\dagger = \delta_{b_2 b_1}
$$

and

$$
\begin{align*}
  \sum_{a_1} (\mathbf{U}_{a_1 a'_1}^{(A)})^\dagger \ket{\tilde{e}_{a_1}} =& \sum_{a_1 a'} (\mathbf{U}_{a_1 a'_1}^{(A)})^\dagger \mathbf{U}_{a' a_1}^{(A)} \ket{e_{a'}} \\
  =& \sum_{a'} \underbrace{\left(\sum_{a_1} \mathbf{U}_{a' a_1}^{(A)} (\mathbf{U}_{a_1 a'_1}^{(A)})^\dagger \right)}_{=\delta_{a' a'_1}} \ket{e_{a'}} \\
  =& \ket{e_{a'}}
\end{align*}
$$

Likewise,

$$
\begin{align*}
  \sum_{a_2} \mathbf{U}_{a'_2 a_2}^{(A)} \bra{\tilde{e}_{a_2}} =& \sum_{a_2 a'} \mathbf{U}_{a'_2 a_2}^{(A)} (\mathbf{U}_{a'_2 a'}^{(A)})^\dagger \bra{e_{a'}} \\
  =& \sum_{a'} \underbrace{\left( \sum_{a_2} (\mathbf{U}_{a' a_2}^{(A)})^\dagger \mathbf{U}_{a_2 a'_2}^{(A)} \right)}_{=\delta_{a' a'_2}} \bra{e_{a'}} \\
  =& \bra{e_{a'_2}}
\end{align*}
$$

Substituting back gives

$$
\begin{align*}
  \sum_{a_1 a_2 b} \tilde{M}_{a_1 b, a_2 b} \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}} =& \sum_{a'_1 b'_1 a'_2 b'_2} \mathbf{M}_{a'_1 b'_1 a'_2 b'_2} \delta_{b'_1 b'_2} \ket{e_{a'_1}} \bra{e_{a'_2}} \\
  =& \sum_{a_1 a_2} \mathbf{M}_{a_1 b, a_2 b} \ket{e_{a_1}} \bra{e_{a_2}}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Properties of partial trace' boxType='proposition'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces. For any operator $\hat{M}\in\mathcal{L}(\hat{H}_A \otimes \mathcal{H}_B)$, the partial traces satisfy

1. $\operatorname{tr}\left(\operatorname{tr}_B (\hat{M})\right) = \operatorname{tr}(\hat{M}) = \operatorname{tr}\left(\operatorname{tr}_A (\hat{M})\right)$

For any operator $\hat{M}_A \otimes \hat{M}_B \in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$, the partial traces satisfy

2. $\operatorname{tr}(\hat{M}^A \otimes \hat{M}^B) = \operatorname{tr}(\hat{M}_A) \operatorname{tr}(\hat{M}_B)$
3. $\operatorname{tr}_B (\hat{M}^A \otimes \hat{M}^B) = \operatorname{tr}(\hat{M}_B) \hat{M}_A$
4. $\operatorname{tr}_A (\hat{M}^A \otimes \hat{M}^B) = \operatorname{tr}(\hat{M}_A) \hat{M}_B$
 
<details>
<summary>Proof</summary>

**(1):** From $\eqref{equation-145}$, we have

$$
\begin{align*}
  \operatorname{tr}\left(\operatorname{tr}_B (\hat{M}) \right) =& \operatorname{tr}\left(\hat{I}_A \operatorname{tr}_B (\hat{M}) \right) \\
  =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{I}_B)\hat{M} \right) = \operatorname{tr}(\hat{M})
\end{align*}
$$

and similarly from $\eqref{equation-146}$, we obtain

$$
\begin{align*}
  \operatorname{tr}\left(\operatorname{tr}_A (\hat{M})\right) =& \operatorname{tr}\left(\operatorname{tr}_A (\hat{M}) \hat{I}_B \right) \\
  =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{I}_B)\hat{M} \right) = \operatorname{tr}(\hat{M})
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \operatorname{tr}(\hat{M}_A \otimes \hat{M}_B) =& \sum_{a,b} (\mathbf{M}_A \otimes \mathbf{M}_B)_{ab, ab} \\
  =& \left(\sum_a \mathbf{M}_{aa}^{(A)} \right) \left(\sum_b \mathbf{M}_{bb}^{(B)} \right) \\
  =& \operatorname{tr}(\hat{M}_A) \operatorname{tr}(\hat{M}_B)
\end{align*}
$$

**(3):** Expanding in terms of an orthonormal basis $\set{\ket{e_a}}\subset\mathcal{M}_A$, we find

$$
  \operatorname{tr}_B (\hat{M}_A \otimes \hat{M}_B) = \sum_{a_1, a_2} \left(\operatorname{tr}_B (\hat{M}_A \otimes\hat{M}_B)\right)_{a_1 a_2} \ket{e_{a_1}} \bra{e_{a_2}}
$$

where

$$
\begin{align*}
  \left(\operatorname{tr}_B (\hat{M}_A \otimes\hat{M}_B)\right)_{a_1 a_2} =& \sum_b (\hat{M}_A \otimes \hat{M}_B)_{a_1 b, a_2 b} \\
  =& \mathbf{M}_{a_1 a_2}^{(A)} \sum_b \mathbf{M}_{bb}^{(B)} \\
  =& \mathbf{M}_{a_1 a_2}^{(A)} \operatorname{tr}(\hat{M}_B)
\end{align*}
$$

so that
$$
  \operatorname{tr}_B (\hat{M}_A \otimes \hat{M}_B) = \hat{M}_A \operatorname{tr}(\hat{M}_B)
$$
</details>
</MathBox>

# Quantum formalism

## Postulates

1. **Description of quantum states** The state space of a quantum system is described a complex separable Hilbert space $\mathcal{H}$. The possible states of the system can be categorized into *pure states* and *mixed states*:

    - A pure state is described by a ray $[\psi]_\sim \in\mathcal{PH}$ in the projective Hilbert space $\mathcal{PH} = \mathcal{H}/\sim$, where vectors differing only by a global phase are equivalent. Formally, a pure state is given by an equivalence classes of normalized vectors $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$:
    $$
      [\psi]_\sim = \set{e^{i\phi} \ket{\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1, \phi\in\R}
    $$
    For convenience, the equivalence class notation is often omitted, as the the global phase has no physical significance.

    - A mixed state is described by a *density operator* $\hat{\rho}$, which is a positive semidefinite operator on $\mathcal{H}$ with unit trace, i.e. $\operatorname{tr}(\hat{\rho}) = 1$. The operator $\hat{\rho}$ represents a statistical mixture of pure states and can be expressed as
    $$
      \hat{\rho} = \sum_i p_i \ket{\psi_i} \bra{\psi_i}
    $$
    where $\set{\ket{\psi_i}}$ are pure states, $p_i$ are probabilities satisfying $p_i \geq 0$ and $\sum_i p_i = 1$.

2. **Description of system observables:** Each physical observable $A$ of a quantum system is associated with a Hermitian operator $\hat{A}$ acting on $\mathcal{H}$. Since $\hat{A}$ is Hermitian, its eigenvalues are real, and its eigenstates form a complete, orthonormal set that spans $\mathcal{H}$, provided that $\hat{A}$ has a discrete spectrum. If $\hat{A}$ has a continuous spectrum, its eigenstates form a generalized orthonormal basis, expressed using distribution functions. 
3. **Measurement of physical observables:** The possible measurable values of an observable $A$ corresponds to the spectrum of its associated operator $\hat{A}$. The probability of measuring an eigenvalue $\lambda$ of $\hat{A}$ depends on whether the system is in a pure state or a mixed state.
    - If the quantum system is in a pure state $\ket{\psi}\in\mathcal{H}$, the probability $\Pr_\psi (\lambda)$ of measuring $A$ and obtaining $\lambda$ is given by
    $$
      \Pr_\psi (\lambda) = \norm{\hat{P}_\lambda \ket{\psi}}
    $$
    where $\hat{P}_\lambda$ is the projection onto the eigenspace $\operatorname{eig}(\hat{A}, \lambda)$. The expectation value of $A$ is given by $\langle A \rangle = \braket{\psi|\hat{A}|\psi}$.
    - If the system is in a mixed state $\hat{\rho}$, the probability $\Pr_{\hat{\rho}} (\lambda)$ that a measurement of $A$ yields the eigenvalue $\lambda$ is given by
    $$
      \Pr_{\hat{\rho}} (\lambda) = \operatorname{tr}(\hat{\rho}\hat{P}_\lambda)
    $$
    The expectation values is given by $\braket{A}_{\hat{\rho}} = \operatorname{tr}(\hat{\rho}\hat{A})$.

4. **Effect of measurement on the state:** A measurement of an observable $A$ modifies the quantum state depending on whether the quantum system was initially in a pure state or a mixed state.
    - If the system initially exists in a pure state $\ket{\psi}$, measuring $A$ and obtaining eigenvalue $\lambda$ transforms the state to
    $$
      \ket{\psi'} = \frac{\hat{P}_\lambda \ket{\psi}}{\sqrt{\braket{\psi|\hat{P}_\lambda|\psi}}}
    $$
    where $\hat{P}_\lambda$ is the projection onto the eigenspace $\operatorname{eig}(\hat{A}, \lambda)$.

    - If the system is initially described by a mixed state $\hat{\rho}$, a measurement of $A$ yielding $\lambda$, projects the state to
    $$
      \hat{\rho}' = \frac{\hat{P}_\lambda \hat{\rho} \hat{P}_\lambda}{\operatorname{tr}(\hat{\rho}\hat{P}_\lambda)}
    $$
5. **Time evolution of a system:** In the Schr√∂dinger picture, any time evolution of a pure state $\ket{\psi(t)}\in\mathcal{H}$ that is not caused by a measurement is governed by a unitary evolution operator $\hat{U}(t, t_0)$ satisfying
$$
  \ket{\psi(t)} = U(t,t_0)\ket{\psi (t_0)}
$$
which is equivalent to the Schr√∂dinger equation
$$
  i\hbar\frac{\d}{\d t}\ket{\psi(t)} = \hat{H}\ket{\psi(t)}
$$
where $\hat{H}$ is the Hamiltonian of the quantum system.
    - For a mixed state $\hat{\rho}$, the time evolution is given by
    $$
      \hat{\rho}(t) = \hat{U}(t, t_0) \hat{\rho}(t_0) \hat{U}^\dagger(t, t_0)
    $$

6. **Description of composite systems:** The Hilbert space of a composite system that consists of the subsystems $\mathcal{H}_{A_i}$ for $i\in I\subseteq\N$ is the tensor product $\bigotimes_{i\in I} \mathcal{H}_{A_i}$.

### Time evolution pictures

| Evolution of | Schr√∂dinger $(S)$ | Heisenberg $(H)$ | Interaction $(I)$ |
| --- | --- | --- | --- |
| State vector | $\ket{\psi_s (t)} = e^{-i\hat{H}_S t/\hbar} \ket{\psi_S (0)}$ | constant | $\ket{\psi_I (t)} = e^{i\hat{H}_{0;S} t/\hbar} \ket{\psi_S (t)}$ |
| Observable | constant | $\hat{O}_H = e^{i\hat{H}_S t/\hbar} \hat{O}_S e^{-i\hat{H}_S t/\hbar}$ | $\hat{O}_I = e^{i\hat{H}_{0;S} t/\hbar} \hat{O}_S e^{-i\hat{H}_{0;S} t/\hbar}$ |
| Density matrix | $\rho_S (t) = e^{i\hat{H}_S t/\hbar} \rho_S (0) e^{-i\hat{H}_S t/\hbar}$ | constant | $\rho_I (t) = e^{i\hat{H}_{0;S} t/\hbar} \rho_S (t) e^{-i\hat{H}_{0;S} t/\hbar}$ |

## Quantum states and observables

The pure state of a quantum system is represented by a ray $[\ket{\psi}]_\sim \in \mathcal{PH}$, where $\mathcal{PH} = \mathcal{H}/\sim$ is the projective Hilbert space of a complex separable Hilbert space $\mathcal{H}$, and $\sim$ is an equivalence relation on $\mathcal{H}$. For $\ket{\psi},\ket{\varphi}\in\mathcal{H}$, this relation is defined as

$$
  \ket{\psi}\sim\ket{\varphi} \iff \ket{\varphi} = e^{i\alpha} \ket{\psi}, \alpha\in\R
$$

Each ray $S_\psi$ associated with a normalized vector $\ket{\psi}\in\mathcal{H}$, i.e. $\norm{\psi} = 1$, is the equivalence class

$$
  S_\psi = [\ket{\psi}]_\sim := \set{e^{i\alpha} \ket{\psi} | \alpha\in\R}
$$

representing a pure state of the quantum system. All vectors in $S_\psi$ differ only by a global phase factor and correspond to the same physical state.

For convenience, the global phase factor $e^{i\alpha}$ is typically ignored when dealing with pure states. In practice, we often identify a pure state with a normalized vector $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$, rather than considering the entire equivalence class of vectors that differ only by a global phase. This is because the global phase does not affect physical observables or measure quantities, which are invariant under such transformations. Thus, we can simplify the description of pure states by associating them directly with normalized vectors in $\mathcal{H}$, leaving the equivalence class formalism implicit.

The dimensionality of $\mathcal{H}$ is determined by the degrees of freedom of the system. Systems with continuous degrees of freedom (like position and momentum) have infinite-dimensional Hilbert spaces, while systems of discrete degrees of freedom have finite-dimensional Hilbert spaces. For instance, the Hilbert space for the position and momentum of a particle in $n$ dimensions is the space of square-integrable complex-valued function function $\mathcal{L}^2 (\R^n, \mathbb{C})$, while for a spin-$s$ particle it is the finite-dimensional complex vector space $\mathbb{C}^{2s + 1}$.

An observable refers to a physcial quantity that can be measured in a quantum system. All quantum observables are represented by Hermitian operators on $\mathcal{H}$. The possible values of an observable are given by the spectrum of the operator, which can be discrete (finite or infinite-dimensional), continuous or a combination of both. In general, systems with bound states (e.g., a particle confined in a potential well) have discrete spectra, corresponding to quantized energy levels. In contrast, for scattering states (e.g., a free particle or a particle with energy above a potential barrier), the spectrum is continuous, corresponding to a range of energies.

<details>
<summary>Details</summary>

For infinite-dimensional Hilbert spaces, we also require that a Hermitian operator $\hat{Q}$ is bounded. In this case, there exists a constant $c$ such that, for any non-zero vector $\ket{\psi}\in\mathcal{H}$, we have

$$
  \frac{\braket{\psi|\hat{Q}^\dagger \hat{Q}|\psi}}{\braket{\psi|\psi}} \leq c^2
$$

The operator norm of $\hat{Q}$ is defined as the lower bound of $c$.
</details>

The Hermiticity of a quantum operator ensures that its spectrum is real. Furthermore, the eigenvectors corresponding to distinct eigenvalues are orthogonal and can be normalized to form an orthonormal basis. In the case of degenerate eigenvalues, the corresponding eigenspace can be spanned by orthonormal eigenvectors. For continuous spectra, generalized eigenstates may be used.

### Discrete observables

A discrete quantum observable is represented by a Hermitian operator $\hat{Q}$ on a Hilbert space $\mathcal{H}$ with a discrete spectrum $\set{q_j}_j$. If $\hat{Q}$ has eigenbasis $\set{\ket{q_{j,\alpha}}}$, where $\alpha \in\set{1,\dots,d_j}$ denotes the degeneracy of $q_j$, i.e. $d_j = \dim[\operatorname{eig}(\hat{Q}, q_j)]$, the spectral representation of $\hat{Q}$ is

$$
  \hat{Q} = \sum_j q_j \hat{P}_j = \sum_j q_j \sum_{\alpha=1}^{d_j} \ket{q_{j,\alpha}} \bra{q_{j,\alpha}}
$$

where $\hat{P}_j$ is the projector onto the eigenspace $\operatorname{eig}(\hat{Q}, q_j)$. Since $\hat{Q}$ is Hermitian, the eigenbasis $\set{\ket{q_{j,\alpha}}}$ is orthonormal, i.e.

$$
  \braket{q_{j,\alpha}|a_{k,\beta}} = \delta_{jk} \delta_{\alpha\beta}
$$

From the spectral representation, we can derive the action of $\hat{Q}$ on the eigenvectors $\ket{q_{k,\beta}}$

$$
\begin{align*}
  \hat{Q}\ket{q_{k,\beta}} =& \sum_j q_{j,\alpha} \hat{P}_j \ket{q_{k\beta}} \\
  =& \sum_j q_j \sum_{\alpha=1}^{d_j} \ket{q_{j,\alpha}} \underbrace{\braket{q_{j,\alpha}|q_{k,\beta}}}_{\delta_{jk} \delta_{\alpha\beta}} \\
  =& q_k \ket{q_{k,\beta}}
\end{align*}
$$

The relation $\hat{Q}\ket{q_{k,\beta}} = q_k \ket{q_{k,\beta}}$ is the eigenvalue equation of $\hat{Q}$. 

If the spectrum of $\hat{Q}$ is finite-dimensional, the set of eigenvectors forms a complete orthonormal basis for $\mathcal{H}$, meaning that: 

$$
  \operatorname{span}(\set{\ket{q_{j,\alpha}}}_j) = \mathcal{H}
$$

Thus, the Hilbert space $\mathcal{H}$ is spanned by the eigenstates of $\hat{Q}$, and any state $\ket{\psi}\in\mathcal{H}$ can be expressed as a linear combination (or superposition):

$$
  \ket{\psi} = \sum_{j,\alpha} c_{j,\alpha} \ket{q_{j,\alpha}}
$$

where $c_{j,\alpha}$ are complex coefficients representing probability amplitudes. Applying $\bra{q_{k,\beta}}$ to $\ket{\psi}$ yields

$$
  \braket{q_{k,\beta} | \psi} = \sum_{j,\alpha} c_{j,\alpha} \underbrace{\braket{q_{k,\beta}|q_{j,\alpha}}}_{\delta_{kj}\delta_{\beta\alpha}} = c_{k,\beta}
$$

showing that $c_{k,\beta}$ is the projection of $\ket{\psi}$ onto $\ket{q_{k,\beta}}$.

#### Matrix representation of observables

The matrix representation of an observable $\hat{Q}$ with finite-dimensional discrete spectrum can be obtained by expanding $\mathbf{Q}$ in terms of an orthonormal basis $\set{\ket{b_j}}_j$. Using the completeness relation $\sum_j \ket{b_j}\bra{b_j} = \hat{I}$, we write

$$
  \hat{Q} = \sum_j \ket{b_j} \bra{b_j} \hat{Q} = \sum_{j,k} \ket{b_j} \braket{b_j|\hat{Q}|b_k} \bra{b_k}
$$

The matrix elements of $\hat{Q}$ in this basis are given by

$$
  \mathbf{Q}_{jk} = \braket{b_j|\hat{Q}|b_k}
$$

An observable $\hat{Q}$ with a non-degenerate spectrum $\set{q_j}_{j=1}^n$ can be diagonalized. The resulting matrix representation has diagonal elements corresponding to the eigenvalues of $\hat{Q}$:

$$
  \mathbf{Q}_{jk} = q_j \delta_{jk} 
$$

The $n\times n$ matrix $\mathbf{U}$ that diagonalizes $\hat{Q}$ is formed by using the eigenvectors $\ket{q_j}$ as its columns. In a basis $\set{\ket{b_k}}_k$, the eigenvector $\ket{q_j}$ can be expanded as

$$
  \ket{q_j} = \sum_k q_{jk} \ket{b_k}, \; q_{jk} = \braket{b_k | q_j}
$$

showing that $\mathbf{U}$ has matrix elements $\mathbf{U}_{jk} = q_{jk}$. Since the eigenbasis $\set{\ket{q_j}}_j$ is orthonormal, we have

$$
  \sum_\ell (q_{k\ell})^* q_{j\ell} = \braket{q_k | q_j} = \delta_{kj}
$$

This can be used to verify that $\mathbf{U}$ is unitary:

$$
\begin{align*}
  (\mathbf{U}^\dagger \mathbf{U})_{kj} =& \sum_\ell \mathbf{U}_{k\ell}^\dagger \mathbf{U}_{\ell j} = \sum_\ell \mathbf{U}_{\ell k}^* \mathbf{U}_{\ell j} \\
  =& \sum_\ell (q_{k\ell})^* q_{j\ell} = \braket{q_k | q_j} = \delta_{kj}
\end{align*}
$$

### Continuous observables and wavefunctions

A quantum observable $\hat{Q}$ with a continuous spectrum has spectral representation

$$
  \hat{Q} = \int q \hat{P}(q) \;\d q = \int q \ket{q}\bra{q} \;\d q
$$

where $q$ is a continuous eigenvalue, and $\ket{q}$ is the corresponding eigenfunction. These eigenvectors are not normalizable in the usual sense, but satisfy the orthogonality condition

$$
  \braket{q' | q} = \delta(q - q')
$$

where $\delta$ is the Dirac delta function. In this representation, any state vector $\ket{\psi}$ can be expanded as

$$
  \ket{\psi} = \int \psi(q) \ket{q} \; \d q
$$

where $\psi(q) = \braket{q|\psi}$ is called the wavefunction. The wavefunction $\psi(q)$ is the projection of $\ket{\psi}$ onto $\ket{q}$. It is describes how $\ket{\psi}$ is distributed over the eigenstates of $\hat{Q}$.

### Change of basis

If $\mathcal{H}$ is a finite-dimensional Hilbert space with orthonormal basis $\set{\ket{b_n}}_n$, a state vector $\ket{\psi}\in\mathcal{H}$ can be expanded as

$$
\begin{equation*}
  \ket{\psi} = \sum_k c_{b_k} \ket{b_k}, \; c_{b_k} = \braket{b_k | \psi} \in\mathbb{C} 
\tag{\label{equation-76}}
\end{equation*}
$$

We can expand $\ket{\psi}$ in terms of another orthonormal basis $\set{\ket{a_k}}_k$:

$$
\begin{equation*}
  \ket{\psi} = \sum_k c_{a_k} \ket{a_k}, \; c_{a_k} = \braket{a_k | \psi} 
\tag{\label{equation-77}}
\end{equation*}
$$

To find a relationship between the coefficients $\set{c_{b_k}}_k$ and $\set{c_{a_k}}_k$, we insert $\sum_j \ket{a_j} \bra{a_j} = 1$ into $\eqref{equation-76}$ to get

$$
\begin{align*}
  \ket{\psi} =& \sum_{j,k} c_{b_k} \ket{a_j} \braket{a_j | b_k} \\
  =& \sum_{j,k} \mathbf{U}_{j,k} c_{b_j} \ket{a_k}
\end{align*}
$$

with the matrix elements $\mathbf{U}_{j,k} = \braket{a_k | b_j}$. Equating this with $\eqref{equation-77}$, we find

$$
  c_{a_j} = \sum_{k} \mathbf{U}_{j, k} c_{b_k}
$$

or in matrix form

$$
  \mathbf{c}_a = \mathbf{Uc}_b
$$

A change of basis has the following properties:
1. The matrix $\mathbf{U}$ is unitary.
2. The inner product of $\mathcal{H}$ is preserved
3. The trace of an operator is preserved

<details>
<summary>Proof</summary>

**(1):** If $\mathbf{U}_{j,k} = \braket{a_j | b_k}$, then

$$
\begin{align*}
  (\mathbf{U}_{j,k})^* =& \braket{b_k | a_j} \\
  \mathbf{U}_{j,k}^\dagger =& \braket{b_j | a_k}
\end{align*}
$$

Consequently, we have

$$
\begin{align*}
  (\mathbf{UU}^\dagger)_{j,k} =& \sum_\ell \mathbf{U}_{j,\ell} U_{\ell, k} = \sum_\ell \braket{a_j | b_\ell} \braket{b_\ell | a_k} \\
  =& \braket{a_j | a_k} = \delta_{jk}
\end{align*}
$$

Similarly, we have

$$
\begin{align*}
  (\mathbf{U}^\dagger \mathbf{U})_{j,k} =& \sum_\ell \mathbf{U}_{j,\ell}^\dagger \mathbf{U}_{\ell,k} = \sum_\ell \braket{b_j | a_\ell}\braket{a_\ell | b_k} \\
  =& \delta_{jk}
\end{align*}
$$

Hence, it follows that $\mathbf{UU}^\dagger = \mathbf{U}^\dagger U = \mathbf{I}$.

**(2):** If $\set{\ket{b_j}}$ and $\set{\ket{a_j}}$ are two orthonormal bases on $\mathcal{H}$, then the two state vectors $\ket{\psi}, \ket{\phi}\in\mathcal{H}$ can be expanded as

$$
\begin{align*}
  \psi =& \sum_j c_{b_j} \ket{b_j} = \sum_j c_{a_j} \ket{a_j}
  \phi =& \sum_j d_{b_j} \ket{b_j} = \sum_j d_{a_j} \ket{a_j}
\end{align*}
$$

The inner product $\braket{\psi|\phi}$ in the basis $\set{\ket{b_j}}$ is

$$
  \braket{\phi|\psi} = \sum_{j,k} d_{b_j}^* c_{b_k} \underbrace{\braket{b_j | b_k}}_{\delta_{jk}} = \sum_j d_{b_j} c_{b_j}
$$

The inner product $\braket{\psi|\phi}$ in the basis $\set{\ket{a_j}}$ is

$$
\begin{equation*}
  \braket{\phi|\psi} = \sum_{j,k} d_{a_j}^* c_{a_k} \underbrace{\braket{a_j | a_k}}_{\delta_{jk}} = \sum_j d_{a_j} c_{a_j} 
\tag{\label{equation-78}}
\end{equation*}
$$

Substituting

$$
  c_{a_j} = \sum_k \mathbf{U}_{j,k} c_{b_j}
$$

and

$$
  d_{a_j}^* = \sum_k \mathbf{U}_{j,k}^* d_{b_k}^* = \sum_k d_{b_k}^* \mathbf{U}_{k,j}^\dagger
$$

into $\eqref{equation-78}$, we get

$$
\begin{align*}
  \braket{\phi|\psi} =& \sum_{j,k} d_{b_k}^* \mathbf{U}_{k,j}^\dagger \sum_\ell \mathbf{U}_{j,\ell} c_{b_\ell} \\
  =& \sum_{k,\ell} d_{b_k}^* \underbrace{\left(\sum_j \mathbf{U}_{k,j}^\dagger \mathbf{U}_{j, \ell} \right)}_{(\mathbf{U}^\dagger \mathbf{U})_{k,\ell} = \delta_{k,\ell}} c_{b_\ell} \\
  =& \sum_\ell d_{b_\ell}^* c_{b_\ell}
\end{align*}
$$

**(3):** Let $\hat{Q}$ be a linear operator on $\mathcal{H}$. The trace of $\hat{O}$ in the orthonormal basis $\set{\ket{a_j}}$ is given by

$$
  \operatorname{tr}(\hat{Q}) = \sum_j \braket{a_j |\hat{Q}| a_j}
$$

The trace of $\hat{Q}$ in the orthonormal basis $\set{\ket{b_j}}$ can be written

$$
\begin{align*}
  \operatorname{tr}(\hat{Q}) =& \sum_j \braket{b_j |\hat{Q}|b_j} \\
  =& \sum_{j,k,\ell} \braket{b_j | a_k} \braket{a_k | \hat{Q} | a_\ell} \braket{a_\ell | b_j} \\
  =& \sum_{j,k,\ell} \braket{a_\ell | b_j} \braket{b_j | a_k} \braket{a_k | \hat{Q} | a_\ell} \\
  =& \sum_{k, \ell} \braket{a_\ell | a_k} \braket{a_k |\hat{Q}| a_k} \\
  =& \sum_\ell \braket{a_\ell | \hat{Q} | a_\ell}
\end{align*}
$$
</details>

#### Infinite-dimensional case

If $\mathcal{H}$ is an infinite-dimensional Hilbert space with basis $\set{\ket{\xi}}$, then any state vector $\ket{\psi}\in\mathcal{H}$ can be expanded as

$$
  \ket{\psi} = \int \psi_\xi (\xi) \ket{\xi} \;\d \xi, \; \psi_\xi (\xi) = \braket{\xi|\psi}
$$

We can expand $\ket{\psi}$ in terms of another orthonormal basis $\set{\ket{\eta}}$ as

$$
  \ket{\psi} = \int \psi_\eta (\eta) \ket{\eta}, \; \psi_\eta (\eta) = \braket{\eta|\psi}
$$

Using the completeness relation of $\ket{\eta}$, we can express $\psi_\xi$ as

$$
\begin{align*}
  \psi_\xi (\xi) =& \braket{\xi|\psi} = \int \overbrace{\braket{\xi|\eta}}^{\phi_\eta (\xi)} \overbrace{\braket{\eta|\psi}}^{\psi_\eta (\eta)} \;\d\eta \\
  =& \int \phi_\eta (\xi) \psi_\eta (\eta) = \hat{U}(\eta,\xi) \psi(\eta)
\end{align*}
$$

In the following we show that the transformation

$$
  \hat{U}(\eta,\xi) = \int \phi_\eta (\xi) \;\d\eta
$$

is unitary. The scalar product of two wavefunctions $\psi_\eta$ and $\psi'_\eta$ in the $\eta$-representation is given by

$$
  \braket{\psi_\eta, \psi_\eta'} = \int \psi_\eta^* (\eta) \psi'_\eta (\eta) \;\d\eta
$$

Applying $\hat{U}$ to $\psi_eta$ and $\psi'_\eta$ and taking the scalar product yields

$$
\begin{align*}
  \braket{\hat{U}\psi_\eta, \hat{U} \psi'_\eta} =& \int \d\xi \left(\int \phi_\eta^* (\xi) \psi_\eta^* (\eta) \;\d\eta \right) \left(\int \phi_{\eta'} (\xi) \psi'_\eta (\eta') \;\d\eta' \right) \\
  =& \int \eta' \psi_\eta^* (\eta) \psi'_\eta (\eta') \;\d\eta \int \phi_\eta^* (\eta) \phi_{\eta'} (\eta) \;\d\xi \tag{\label{equation-94}}
\end{align*}
$$

Since $\phi_\eta (\xi) = \braket{\xi|\eta'}$ and $\phi_\eta (\xi) = \braket{\xi|\eta}$, we obtain

$$
\begin{align*}
  \int \phi_\eta^* (\xi) \phi_{\eta'} (\xi) =& \int \braket{\eta|\xi}\braket{\xi|\eta'} \\
  =& \braket{\eta|\eta'} = \delta(\eta - \eta')
\end{align*}
$$

Substituting this into $\eqref{equation-94}$, we get

$$
\begin{align*}
  \braket{\hat{U}\psi, \hat{U}\psi'} =& \int \eta' \psi_\eta^* (\eta) \psi'_\eta (\eta') \delta(\eta - \eta') \\
  =& \int \psi_\eta^* (\eta) \psi_\eta (\eta) \;\d\eta = \braket{\psi,\psi'}
\end{align*}
$$

showing that $\hat{U}$ preserves the inner product. Hence, it follows that $\hat{U}$ is unitary.

## Measurements

Let $\hat{Q}$ be a Hermitian operator on $\mathcal{H}$ with a discrete spectrum $\set{q_j}_j$, and an orthonormal eigenbasis $\set{\ket{q_{j,\alpha}}}$, where $\alpha\in\set{1,\dots,d_j}$ denotes the degeneracy $q_j$, i.e. $d_j = \dim[\operatorname{eig}(\hat{Q}, q_j)]$. If $Q$ is the corresponding observable on a quantum system in state 

$$
  \ket{\psi} = \sum_{j,\alpha} c_{j,\alpha} \ket{q_{j,\alpha}}, \; c_{j,\alpha} = \braket{q_{j,\alpha} | \psi}
$$

then the probability of measuring the eigenvalue $q_j$ is given by

$$
\begin{align*}
  \Pr_\psi (q_j) =& \norm{\hat{P}_j \ket{\psi}}^2 \\
  =& \Norm{\sum_{\alpha=1}^{d_j} \ket{q_{j,\alpha}}\braket{q_{j,\alpha}|\psi}} \\
  =& \sum_{\alpha=1}^{d_j} |\braket{q_{j,\alpha}|\psi}|^2 = \sum_{\alpha=1}^{d_j} |c_{j,\alpha}|^2
\end{align*}
$$

This statistical interpretation of quantum observables is known as *Born's rule*, which states that the probability of obtaining an eigenvalue $q_j$ in a measurement of $Q$ is given by the square modulus of the projection of $\ket{\psi}$ onto the corresponding eigenspace.

To see that the map $\Pr_\psi : \sigma(\hat{Q}) \to [0,1]$ defines a probability measure on $\sigma(\hat{Q})$, we note that $\Pr_\psi (q_j) \geq 0$ because square moduli are non-negative. Furthermore, since $\set{\ket{q_{j,\alpha}}}$ forms an orthonormal basis for $\mathcal{H}$ and $\ket{\psi}$ is normalized, it follows that

$$
\begin{align*}
  \sum_j \Pr_\psi (q_j) =& \sum_j \norm{\hat{P}_{q_j} \ket{\psi}}^2 \\
  =& \sum_j \sum_{\alpha=1}^{d_j} |\braket{q_{j,\alpha}|\psi}|^2 \\
  =& \norm{\psi} = 1
\end{align*}
$$

Thus, the normalization condition of quantum states ensures that the total probability sums to $1$, validating that $\Pr_\psi$ is a probability measure over the spectrum $\sigma(\hat{Q})$.

If a quantum system has been prepared in the state $\ket{\psi}\in\mathcal{H}$, the probability to observe it in the state $\ket{\varphi}\in\mathcal{H}$ is given by $\Pr(\varphi|\psi) = |\braket{\varphi|\psi}|^2$, assuming both states are normalized, i.e. $\norm{\psi}^2 = 1 = \norm{\varphi}$. To see this, note that the measurement corresponds to the observable given by the orthogonal projection $\hat{P}_\varphi = \ket{\varphi}\bra{\varphi}$ onto $\ket{\varphi}$. This operator has the eigenvalues $0$ and $1$. The eigenvalue $\lambda = 1$ is non-degenerate and its eigenspace is spanned by $\ket{\varphi}$. Hence, the projection onto the eigenspace for eigenvalue $\lambda = 1$ is given by

$$
\begin{align*}
  \Pr_\psi (\lambda = 1) =& \norm{\hat{P}_\varphi \ket{\psi}}^2 = \norm{\ket{\varphi}\braket{\varphi|\psi}}^2 \\
  =& |\braket{\varphi|\psi}|^2 \underbrace{\norm{\varphi}^2}_{=1} = |\braket{\varphi|\psi}|^2
\end{align*}
$$

### Expectation value

The expectation value of an observable $Q$ in the normalized state $\ket{\psi}\in\mathcal{H}$ is defined as

$$
  \braket{Q}_\psi := \frac{\braket{\psi|\hat{Q}|\psi}}{\braket{\psi|\psi}} = \braket{\psi|\hat{Q}|\psi}
$$

If $\hat{Q}$ has spectral decomposition

$$
  \hat{Q} = \sum_{j,\alpha} q_j \ket{q_{j,\alpha}}\bra{q_{j,\alpha}}
$$

the expectation value is given by

$$
\begin{align*}
  \braket{Q}_\psi =& \braket{\psi|\hat{Q}|\psi} = \Braket{\psi|\sum_{j,\alpha} q_j \ket{q_{j,\alpha}}\braket{q_{j,\alpha}|\psi}} \\
  =& \sum_{j,\alpha} q_j \braket{\psi|q_{j,\alpha}}\braket{q_{j,\alpha}|\psi} \\
  =& \sum_{j,\alpha} q_j |\braket{\psi|q_{j,\alpha}}|^2 = \sum_{j,\alpha} q_j |c_{j,\alpha}|^2
\end{align*}
$$

Properties of expectation values
1. $\braket{Q}_\psi \in\R$ is real since $\hat{Q}$ is Hermitian
2. **Invariance unde global phase:** For any global phase factor $e^{i\phi}$, where $\phi\in\R$, we have $\braket{Q}_{e^{i\phi} \psi} = \braket{Q}_\psi$
3. **Equality of observables:** Two observables $\hat{Q}$ and $\hat{Q}'$ are equal if and only if $\braket{\psi|\hat{Q}|\psi} = \braket{\psi|\hat{Q}'|\psi}$ for all $\ket{\psi}\in\mathcal{H}$

<details>
<summary>Proof</summary>

**(1):** Taking the complex conjugate of $\braket{Q}_\psi$, we find

$$
\begin{align*}
  \braket{Q}_\psi^* =& \braket{\psi|\hat{Q}|\psi}^* = \braket{\psi|\hat{Q}^\dagger|\psi} \\
  =& \braket{\psi|\hat{Q}|\psi} = \braket{Q}_\psi
\end{align*}
$$

Since $\braket{Q}_\psi^* = \braket{Q}_\psi$, it follows that $\braket{Q}_\psi \in\R$ is real.

**(2):** Calculating $\braket{Q}_{e^{i\phi}\psi}$, we find 

$$
\begin{align*}
  \braket{Q}_{e^{i\phi} \psi} =& \braket{e^{i\phi}\psi |\hat{Q}|e^{i\phi} \psi} = e^{-i\phi} e^{i\phi} \braket{\psi|\hat{Q}|\psi} \\
  =& \braket{\psi|\hat{Q}|\psi} = \braket{Q}_\psi
\end{align*}
$$
</details>

The expectation value of any observable $Q$ in the state $\ket{\psi}\in\mathcal{H}$ is unaffected under a global phase transformation $e^{i\phi} \ket{\psi}$. In an orthonormal basis $\set{\ket{q_j}}$, we have

$$
  |\braket{e^{i\phi}\psi|q_j}|^2 = |e^{-i\phi}|^2 \cdot |\braket{\psi|q_j}|^2 = |\braket{\psi|q_j}|
$$

showing that the measurement probabilities remain the same. This means that the states $e^{i\phi}\ket{\psi}$ and $\ket{\psi}$ are physically indistinguishable.

While global phase is physically irrelevant, relative phases between components in a quantum superposition can have physical consequences. Specifically, consider two orthonormal states $\ket{\eta},\ket{\psi}\in\mathcal{H}$ satisfying $\braket{\eta|\psi} = 0$. Then 

$$
\begin{align*}
  \ket{a} =& 2^{-1/2} (\ket{\eta} + \ket{\psi}) \\ 
  \ket{b} =& 2^{-1/2} (\ket{\eta} + e^{i\phi} \psi)
\end{align*}
$$

are normalized state vectors. However, while $\ket{\psi}$ and $e^{i\phi} \ket{\psi}$ represents the same state, the states $\ket{a}$ and $\ket{b}$ are physically distinct because they lead to different measurement outcomes. The expectation value of an observable $A$ in state $\ket{a}$ is

$$
\begin{align*}
  \braket{A}_{\ket{\eta} + \ket{\psi}/\sqrt{2}} =& \frac{1}{2} (\braket{\eta + \psi|\hat{A}|\varphi + \psi}) \\
  =& \frac{1}{2}(\braket{\eta|\hat{A}|\eta} + \braket{\psi|\hat{A}|\psi} + \braket{\eta|\hat{A}|\psi} + \underbrace{\braket{\psi|\hat{A}|\eta}}_{\braket{\hat{A}\psi|\eta}}) \\
  =& \frac{1}{2}(\braket{A}_\eta + \braket{A}_\psi) + \Re(\braket{\eta|\hat{A}|\psi})
\end{align*}
$$

where $\Re(\braket{\eta|\hat{A}|\psi})$ is called the interference terms, which arises du to quantum superposition. Similarly, for $\ket{b}$, we find

$$
\begin{align*}
  \braket{A}_{\ket{\eta} + e^{i\phi}\ket{\psi}/\sqrt{2}} =& \frac{1}{2} (\braket{\eta + e^{i\phi} \psi|\hat{A}|\varphi + e^{i\phi} \psi}) \\
  =& \frac{1}{2}(\braket{\eta|\hat{A}|\eta} + \braket{e^{i\phi} \psi|\hat{A}|e^{i\phi} \psi} + e^{i\phi} \braket{\eta|\hat{A}|\psi} + e^{-i\phi} \underbrace{\braket{\psi|\hat{A}|\eta}}_{\braket{\hat{A}\psi|\eta}}) \\
  =& \frac{1}{2}(\braket{A}_\eta + \braket{A}_\psi) + \Re(e^{i\phi} \braket{\eta|\hat{A}|\psi})
\end{align*}
$$

Thus, whenever $\braket{\eta|\hat{A}|\psi} \neq 0$ the real part of $\braket{\eta|\hat{A}|\psi}$ and of $e^{i\phi}\braket{\eta|\hat{A}|\psi}$ differ.

### Determinate states

The uncertainty of an observable $Q$ is state $\ket{\psi}\in\mathcal{H}$ is defined as

$$
  \Delta_\psi (Q) := \sqrt{\braket{\psi|(\hat{Q} - \braket{Q}_\psi \hat{I})^2|\psi}} = \sqrt{\braket{(\hat{Q} - \braket{Q}\hat{I})^2}}
$$

where $\hat{I}$ is the identity operator. If the uncertainty vanishes, i.e. $\Delta_\psi (Q) = 0$, the observable $Q$ in the state $\ket{\psi}$ is said to have a *sharp* value. This is the case if and only if $\ket{\psi}$ is an eigenvector of $\hat{Q}$, i.e.

$$
  \Delta_\psi (Q) = 0 \iff \hat{Q}\ket{\psi} = \braket{Q}_\psi \ket{\psi}
$$

Since $\hat{Q}$ is Hermitian, its expectation value $\braket{Q}_\psi \in\R$ is real, i.e. $\braket{Q}_\psi = \braket{Q}_\psi^*$. Consequently,

$$
  (\hat{Q} - \braket{Q}_\psi \hat{I})^\dagger = \hat{Q} - \braket{Q}_\psi \hat{I} 
$$

and thus

$$
\begin{align*}
  (\Delta_\psi (Q))^2 =& \braket{\psi|(\hat{Q} - \braket{Q}_\psi \hat{I})^2|\psi} \\
  =& \braket{(\hat{Q} - \braket{Q}_\psi \hat{I})\psi | (\hat{Q} - \braket{Q}_\psi \hat{I})\psi} \\
  =& \Norm{(\hat{Q} - \braket{Q}_\psi \hat{I})\psi}^2
\end{align*}
$$

This shows that

$$
  \Delta_\psi (Q) = 0 \iff \hat{Q}\ket{\psi} = \braket{Q}_\psi \ket{\psi}
$$

A state $\ket{\psi}$ that is an eigenvector of an operator associated with an observable is called an *eigenstate* of that operator.

### Continuous spectrum

Let $\hat{Q}$ be a Hermitian operator on the Hilbert space $\mathcal{H}$ with a continuous spectrum, and let $\ket{q}$ denote its eigenstates. The correspodning observable $Q$ in a quantum system described by the state vector $\ket{\psi}$ can be expanded as 

$$
  \ket{\psi} = \int \psi(q) \ket{q} \;\d q, \; \psi(q) = \braket{q|\psi}
$$

where $\psi(q) = \braket{q|\psi}$ is the wavefunction in the eigenbasis $\set{\ket{q}}$. By Born's rule, the probability of measuring $Q$ and finding the eigenvalue in the interval $(q, q + \d q)$ is given by the square modulus of the wavefunction, i.e. $|\psi(q)|^2 \d q$. Expanding the normalization condition on $\ket{\psi}$, we find

$$
\begin{align*}
  \braket{\psi|\psi} =& \int \braket{\psi|q} \braket{q|\psi} \;\d q \\
  =& \int \psi^* (q) \psi(q) \;\d q \\
  =& \int |\psi(q)|^2 \;\d q = 1
\end{align*}
$$

#### Generalized orthonormality condition

Let $\hat{O}$ be a one-dimensional observable with a continuous spectrum, and let $\set{\ket{o}}$ be its eigenbasis. The state vector $\ket{\psi}$ of the system can be expanded as

$$
  \ket{\psi} = \int c(o)\ket{o} \;\d o
$$

where $c(o) = \braket{o|\psi}$ is the projection of $\psi$ onto $\ket{o}$. If $\psi(q) = \ket{q|\psi}$ is a wavefunction in terms of another continuous eigenbasis $\set{\ket{q}}$, the normalization condition requires that

$$
  \int |c(o)|^2 \;\d o = \int |\psi(q)|^2 \;\d q 
$$

Substituting $\psi^* (q) = \braket{\psi|q}$ into the right hand side and applying the completeness relation $\int \ket{q}\bra{q} \;\d q = \hat{I}$ we obtain

$$
\begin{align*}
  \int c^* (o) c(o) \;\d o =& \int \d o \;c^* (o) \left(\int \d q \braket{o|q} \braket{q|\psi} \right) \\
  =& \int \d o\; c^*(o) \left(\int \d q\; \psi(q) \phi_{o}^* (q) \right)
\end{align*}
$$

where $\phi_o (q) = \braket{q|o}$, which yields

$$
  c(o) = \braket{o|\psi} = \int \psi(q) \phi_{o}^* (q) \;\d q
$$

Back-substituting $\psi(q) = \braket{q|\psi}$, we get

$$
\begin{align*}
  c(o) =& \int \d o'\; c(o') \left(\int \d q\; \phi_{o'} (q) \phi_o^* (q) \right) \\
  =& \int \d o'\; c(o') \left(\int \d q\; \braket{o|q} \braket{q|o'} \right) \\
  =& \int c(o') \braket{o|o'} \;\d o' 
\end{align*}
$$

from which it follows that

$$
  \braket{o|o'} = \left(\int \d q\; \phi_{o'} (q) \phi_o^* (q) \right) = \delta(o - o')
$$

### Mixed spectrum

Let $\hat{Q}$ be a Hermitian operator on the Hilbert space $\mathcal{H}$ with both a discrete and a continuous spectrum. In this case, the eigenvalues corresponding to the discrete spectrum are labeled by $q_n$, while the continuous spectrum is parametrized by $q$. Assuming that the continuous spectrum is in the range $q\in(\tilde{q},\infty)$, the projection operators for the discrete are continuous components are given by:

$$
\begin{align*}
  \hat{P}_\text{d} =& \sum_n \ket{q_n} \bra{q_n} \\
  \hat{P}_\text{c} =& \int_{\tilde{q}}^\infty \ket{q} \bra{q} \; \d q
\end{align*}
$$

These projection operators must satisfy the completeness relation 

$$
  \hat{P}_\text{c} + \hat{P}_\text{d} = \hat{I}
$$

where $\hat{I}$ is the identity operator on $\mathcal{H}$. In terms of this eigenbasis, a state vector $\ket{\psi}$ can be expanded as

$$
  \ket{\psi} = \sum_n c(q_n) \ket{q_n} + \int_{\tilde{q}}^\infty \psi(q) \ket{\psi} \; d q
$$

where
- $c(q_n) = \ket{q_n |\psi}$ is the expansion coefficient for the discrete eigenbasis $\set{\ket{q_n}}_n$
- $\psi(q) = \ket{q|\psi}$ is the wavefunction in the continuous eigenbasis $\set{\ket{q}}$

According to Born's rule, the probability of measuring $q_n$ in the discrete spectrum is given by $|c(q_n)|^2$, while the probability of measuring the eigenvalue in the interval $(q, q + \d q)$ is given by $|\psi(q)|^2 \d q$. The normalization condition implies that

$$
  \braket{\psi|\psi} = \sum_n |c(q_n)|^2 + \int_{\tilde{q}}^\infty |\psi(q)|^2 \;\d q = 1
$$

### Compatible observables

Two observables $P$ and $Q$ are compatible if they are simultaneously measurable with arbitrary precision. This means that there exists a common eigenbasis for their corresponding operators $\hat{P}$ and $\hat{Q}$, allowing them to be jointly diagonalized. This condition holds if and only if $\hat{P}$ and $\hat{Q}$ commute. In summary, the following statements are equivalent:
1. $P$ and $Q$ are compatible observables
2. $\hat{P}$ and $\hat{Q}$ have a common eigenbasis
3. $\hat{P}$ and $\hat{Q}$ commute, i.e. $[\hat{P}, \hat{Q}] = 0$

<details>
<summary>Proof</summary>

**(2) $\implies$ (3):**
Assuming $\hat{P}$ and $\hat{Q}$ have a common basis of eigenvectors, $\set{\ket{b_k}}_k$, we have

$$
  \hat{P}\ket{b_k} = p_k \ket{b_k}, \quad \hat{Q} \ket{b_k} = q_k \ket{b_k}
$$

It follows that

$$
\begin{align*}
  \hat{P}\hat{Q}\ket{b_k} = \hat{P} q_k \ket{b_k} = q_k \hat{P} \ket{b_k} = q_k p_k \ket{b_k}
  \hat{Q}\hat{P}\ket{b_k} = \hat{Q} p_k \ket{b_k} = p_k \hat{P} \ket{b_k} = p_k q_k \ket{b_k}
\end{align*}
$$

Since $p_k, q_k \in\mathbb{C}$ are scalars it follows that $\hat{P}\hat{Q} = \hat{Q}\hat{P}$.

**(3) $\implies$ (2):**
We now assume that $\mathbf{P}$ and $\mathbf{Q}$ commute. In a basis $\set{\ket{a_k}}$ we have

$$
\begin{equation*}
\begin{split}
  (\mathbf{P}\mathbf{Q})_{jk} =& \braket{a_j | \hat{P}\hat{Q} | a_k} \\
  =& \sum_\ell \braket{a_j | \hat{P} | a_\ell} \braket{a_\ell | \hat{Q} | a_k} \\
  =& \sum_\ell \mathbf{P}_{k\ell} \mathbf{Q}_{\ell j}
\end{split}
\tag{\label{equation-79}}
\end{equation*}
$$

If $\set{\ket{a_k}}_k$ is an eigenbasis of $\hat{P}$, we can rewrite $\eqref{equation-79}$ as

$$
\begin{align*}
  (\mathbf{P}\mathbf{Q})_{jk} =& \sum_\ell \braket{a_j | \hat{P} | a_\ell} \braket{a_\ell | \hat{Q} | a_k} \\
  =& \sum_\ell p_\ell \delta_{j\ell} \mathbf{Q}_{\ell k} = p_j \mathbf{Q}_{jk}
\end{align*}
$$

Inverting the orders of the operators, we have

$$
\begin{align*}
  (\mathbf{Q}\mathbf{P})_{jk} =& \sum_\ell \braket{a_j | \hat{Q} | a_\ell} \braket{a_\ell | \hat{P} | a_k} \\
  =& \sum_\ell \mathbf{Q}_{j\ell} p_k \delta_{\ell k} = p_k \mathbf{Q}_{jk}
\end{align*}
$$

Since $[\hat{P}, \hat{Q}] = 0$, we must have $(p_j - p_k) \mathbf{Q}_{jk} = 0$. This condition is trivially satisfied for $j = k$. In the non-degenerate case, if $p_k \neq p_j$ for $j \neq k$, it follows that $\mathbf{Q}_{jk} = 0$ for $j \neq k$, or equivalently $\mathbf{Q}_{jk} = \mathbf{Q}_{jj} \delta_{jk}$. This implies that the operator $\hat{Q}$ is diagonal in the eigenbasis of $\hat{P}$, proving the result.

In the degenerate case, where $p_j = p_k$ for $j \neq k$, we can consider the subspace spanned by the eigenvectors corresponding to the degenerate eigenvalues. Since $\hat{Q}$ is Hermitian and commutes with $\hat{P}$, we can diagonalize $\hat{Q}$ within this subspace, where $\hat{P} = p_k \hat{I}$. This shows that $\hat{P}$ and $\hat{Q}$ can be jointly diagonlized, and therefore, they share a common eigenbasis.
</details>

In general, a quantum system can be fully characterized by a set of mutually commuting observables, which collectively determine the eigenbasis describing the system's physical states. Such a set is called a *complete set of commuting observables* (CSCO). 

In the simplest case, an observable has a non-degenerate discrete spectrum, meaning each eigenvalue uniquely corresponds to a single eigenstate. In such cases, the observable itself is sufficient to form a CSCO. However, when the spectrum is degenerate, multiple eigenstates may correspond to the same eigenvalue. In such cases, additional commuting observables are needed to distinguish between the degenerate eigenvectors and uniquely specify the system's state.

For finite-dimensional Hilbert spaces, Schur's lemma guarantees that a complete set of commuting observables always exists. This means that in such systems, it is always possible to find a set of commuting operators whose eigenvalues uniquely determine the system's state. In infinite-dimensional systems, there is no universal guarantee for a CSCO, but in many cases - such as systems with continuous symmetries - there can still be a sufficient set of commuting variables to determine the quantum states.

<MathBox title='Complete set of commuting variables' boxType='definition'>
A set of observables $\mathcal{S} = \set{A, B, C, \dots}$ is a complete set of commuting observables (CSCO) if:
1. All the observables commute by pairs
2. Specifying the eigenvalues of all the operators in the CSCO identifies a unique common eigenvector
</MathBox>

## Uncertainty principle

Two quantum observables $P$ and $Q$ are incompatible if they cannot be simultaneously measurable with arbitrary precision. This implies that there is no common eigenbasis for the corresponding operators $\hat{P}$ and $\hat{Q}$. In this case, measuring one observable disturbs the system's state in such a way that it affects the measurement of the other observable. Incompatibility occurs if $\hat{P}$ and $\hat{Q}$ do not commute.

To quantify the uncertainty of an observable $Q$, we define the operator

$$
  \Delta_\psi \hat{Q} = \hat{Q} - \braket{\hat{Q}}_\psi
$$

as the deviation of $\hat{Q}$ from its expectation value in the state $\ket{\psi}$. The variance $\sigma_Q^2$ of $Q$ in the state $\ket{\psi}$ is given by $\sigma_Q^2 = \langle (\Delta_\psi \hat{Q})^2 \rangle$. Expanding this expression we get

$$
\begin{align*}
  \braket{(\Delta_\psi \hat{Q} )^2} &= \Braket{(\hat{Q} - \langle \hat{Q} \rangle_\psi )^2}_\psi \\
  &= \Braket{\hat{Q}^2 - 2 \braket{\hat{Q}}_\psi \hat{Q} + \braket{\hat{Q}}_\psi^2 }_\psi \\
  &= \braket{\hat{Q}^2}_\psi - \braket{\hat{Q}}_\psi^2 \\
  &= \braket{\psi|\hat{Q}^2|\psi} - \braket{\psi |\hat{Q}|\psi}^2
\end{align*}
$$

For two Hermitian operators $\hat{P}$ and $\hat{Q}$, the generalized uncertainty principle, also known as the Robertson-Schr√∂dinger uncertainty relation, states that

$$
\begin{align*}
  \sigma_P^2 \sigma_Q^2 \geq& \left|\frac{1}{2} \Braket{\{\hat{P},\hat{Q}\}} - \braket{\hat{P}} \braket{\hat{Q}} \right|^2 + \left|\frac{1}{2i}\Braket{[\hat{P},\hat{Q}]} \right|^2 \\
  =& |\operatorname{cov}(\hat{P}, \hat{Q})|^2 + \left|\frac{1}{2}\Braket{[\hat{P},\hat{Q}]} \right|^2
\end{align*}
$$

where $\operatorname{cov}(\hat{P}, \hat{Q})$ is the covariance of $\hat{P}$ and $\hat{Q}$. If $\operatorname{cov}(\hat{P}, \hat{Q}) = 0$, the uncertainty principle reduces to

$$
\begin{equation*}
  \sigma_P \sigma_Q \geq \frac{1}{2} \left|\Braket{[\hat{P},\hat{Q}]} \right| 
\tag{\label{equation-102}}
\end{equation*}
$$

which is known as the Heisenberg-Robertson uncertainty relation.

<details>
<summary>Proof</summary>

Let $\hat{P}$ and $\hat{Q}$ be Hermitian operators and define

$$
\begin{align*}
  \ket{f} :=& \Delta\hat{P}\ket{\psi} = (\hat{P} - \braket{\hat{P}})\ket{\psi} \\
  \ket{g} :=& \Delta\hat{Q}\ket{\psi} = (\hat{Q} - \braket{\hat{Q}})\ket{\psi}
\end{align*}
$$

By Hermiticity of $\hat{P}$ and $\hat{Q}$, it follows that $\braket{\hat{P}}, \braket{\hat{Q}}\in\R$ such that $\Delta\hat{P}$ and $\Delta\hat{Q}$ are also Hermitian. Thus,

$$
  \braket{f|f} = \braket{\psi|\Delta \hat{P}^\dagger \Delta\hat{P}|\psi} = \braket{\psi|(\Delta\hat{P})^2|\psi} = \sigma_P^2
$$

and similarly $\braket{g|g} = \sigma_Q^2$. Furthermore

$$
  \braket{f|g} = \braket{\psi|\Delta\hat{P}^\dagger \Delta\hat{Q}|\psi} = \braket{\psi|\Delta\hat{P} \Delta\hat{Q}|\psi} = \braket{\Delta\hat{P}\Delta\hat{Q}}
$$

To find $\braket{\Delta\hat{P}\Delta\hat{Q}}$ we decompose $\Delta\hat{P}\Delta\hat{Q}$ it into its commutator and anti-commutator:

$$
  \Delta\hat{P}\Delta\hat{Q} = \frac{1}{2}[\Delta\hat{P},\Delta\hat{Q}] + \frac{1}{2}\{\Delta\hat{P},\Delta\hat{Q}\}
$$

By Hermiticity, $[\Delta\hat{P},\Delta\hat{Q}]$ is anti-Hermitian and thus $\Braket{[\Delta\hat{P},\Delta\hat{Q}]}$ is purely imaginary. Meanwhile, $\{\Delta\hat{P},\Delta\hat{Q}\}$ is Hermitian and thus $\Braket{\{\Delta\hat{P},\Delta\hat{Q}\}}$ is real. This implies that $\braket{\Delta\hat{P}\Delta\hat{Q}}\in\mathbb{C}$ is a complex number with modulus given by

$$
  |\braket{\Delta\hat{P}\Delta\hat{Q}}|^2 = \left|\frac{1}{2}[\Delta\hat{P},\Delta\hat{Q}]\right|^2 + \left|\frac{1}{2}\{\Delta\hat{P},\Delta\hat{Q}\}\right|^2
$$

Computing $[\Delta\hat{P},\Delta\hat{Q}]$, we find

$$
\begin{align*}
  [\Delta\hat{P},\Delta\hat{Q}] =& (\hat{P} - \braket{\hat{P}})(\hat{Q} - \braket{\hat{Q}}) - (\hat{Q} - \braket{\hat{Q}})(\hat{P} - \braket{\hat{P}}) \\
  =& \hat{P}\hat{Q} - \braket{\hat{Q}}\hat{P} - \braket{\hat{P}}\hat{Q} + \braket{\hat{Q}}\braket{\hat{P}} \\
  &- \hat{Q}\hat{P} + \braket{\hat{P}}\hat{Q} + \braket{\hat{Q}}\hat{P} - \braket{\hat{P}}\braket{\hat{Q}} \\
  =& \hat{P}\hat{Q} - \hat{Q}\hat{P} = [\hat{P},\hat{Q}]
\end{align*}
$$

Computing $\braket{\{\Delta\hat{P},\hat{Q}\}}$, we find

$$
\begin{align*}
  \Braket{\{\Delta\hat{P},\hat{Q}\}} =& \Braket{(\hat{P} - \braket{\hat{P}})(\hat{Q} - \braket{\hat{Q}}) + (\hat{Q} - \braket{\hat{Q}})(\hat{P} - \braket{\hat{P}})} \\
  =& \left\langle \hat{P}\hat{Q} - \braket{\hat{Q}}\hat{P} - \braket{\hat{P}}\hat{Q} + \braket{\hat{Q}}\braket{\hat{P}} \right. \\
  &\left. +\hat{Q}\hat{P} - \braket{\hat{P}}\hat{Q} - \braket{\hat{Q}}\hat{P} + \braket{\hat{P}}\braket{\hat{Q}} \right\rangle \\
  =& \braket{\hat{P}\hat{Q} + \hat{Q}\hat{P}} - 4\braket{\hat{P}}\braket{\hat{Q}} + 2\braket{\hat{P}}\braket{\hat{Q}} \\
  =& \Braket{\{\hat{P}, \hat{Q}\}} - 2\braket{\hat{P}}\braket{\hat{Q}}
\end{align*}
$$

Combining the results, we obtain

$$
\begin{align*}
  |\braket{\Delta\hat{P}\Delta\hat{Q}}|^2 =& \left|\frac{1}{2}\Braket{[\Delta\hat{P},\Delta\hat{Q}]}\right|^2 + \left|\frac{1}{2}\Braket{\{\Delta\hat{P},\Delta\hat{Q}\}}\right|^2 \\
  =& \left|\frac{1}{2}\Braket{[\hat{P},\hat{Q}]}\right|^2 + \left|\frac{1}{2}\Braket{\{\hat{P},\hat{Q}\}} - \braket{\hat{P}}\braket{\hat{Q}}\right|^2
\end{align*}
$$

Invoking the Cauchy-Schwarz inequality, we get

$$
\begin{align*}
  \braket{f|f}\braket{g|g} \geq& |\braket{f|g}|^2 \\
  \sigma_P^2 \sigma_Q^2 \geq& |\braket{\Delta\hat{P}\Delta\hat{Q}}|^2
\end{align*}
$$

from which it follows that

$$
  \sigma_P^2 \sigma_Q^2 \geq \left|\frac{1}{2}\Braket{[\hat{P},\hat{Q}]}\right|^2 + \left|\frac{1}{2}\Braket{\{\hat{P},\hat{Q}\}} - \braket{\hat{P}}\braket{\hat{Q}}\right|^2
$$
</details>

## Schr√∂dinger equation

The time evolution of a state vector $\ket{\psi}$ is given by the Schr√∂dinger equation

$$
\begin{equation*}
  i\hbar \frac{\partial}{\partial t}\ket{\psi} = \hat{H} \ket{\psi} 
\tag{\label{equation-98}}
\end{equation*}
$$

If $\ket{\psi}$ can be expanded in a continuous eigenbasis $\ket{q}$ as

$$
  \ket{\psi} = \int \psi(q,t)\ket{q} \;\d q, \; \psi(q,t) = \braket{q|\psi}
$$

then taking the scalar product of both sides of the Schr√∂dinger equation with $\ket{q}$ gives

$$
\begin{align*}
  \Braket{q|i\hbar \frac{\partial}{\partial t}|\psi(t)} =& \braket{q|\hat{H}|\psi} \\
  i\hbar \frac{\partial}{\partial t} \psi(q, t) =& \braket{q|\hat{H}|\psi}
\end{align*}
$$

If $\hat{H}$ has eigenstates $\ket{q}$, then

$$
  \braket{q|\hat{H}|\psi} = \hat{H}\psi(q,t)
$$

This leads to the Schr√∂dinger equation for the wavefunction $\psi(q,t)$ in the eigenbasis of $\hat{q}$:

$$
  i\hbar \frac{\partial}{\partial t} \psi(q, t) = \hat{H} \psi(q, t)
$$

### Derivation of the Sch√∂dinger equation

In general, an evolution equation must conform to the fundamental principles of quantum mechanics. We begin by assuming that the evolution of the state vector is deterministic. This implies that the state at a given time $t_0$ is sufficient to determine the state at any later time. 

Next, we note that the evolution equation can only contain the first time derivative of the state vector. If it were of higher order, the solution would require knowledge of the higher time derivatives of the state at $t_0$, violating the requirement that the state vector encodes all the information about the quantum system.

The superposition principle tells that any linear combination of states must also be a solution to the evolution equation. Consequently, the equation must be linear and homogenous. The most general form of such an equation is

$$
  \frac{\partial}{\partial t} \ket{\psi} = \hat{Q}\ket{\psi}
$$

where $\hat{Q}$ is a linear operator to be determined.

The equation implies that $\hat{Q}$ must correspond to the generator of time translations, or equivalently, to a quantity conserved under time translations. We know from classical mechanics that the generator of time translations is the energy of the system, represented by the Hamiltonian. By the correspondence principle, we deduce that the operator $\hat{Q}$ is a function of the Hamiltonian operator $\hat{H}$:

$$
  \frac{\partial}{\partial t} \ket{\psi} = f(\hat{H})\ket{\psi}
$$

Next, we consider a composite system made of two subsystems with Hamiltonians $\hat{H}_1$ and $\hat{H}_2$, respectively. Since total Hamiltonian is $\hat{H} = \hat{H}_1 + \hat{H}_2$, we require that $f$ must be linear, i.e.

$$
  f(\hat{H}_1 + \hat{H}_2) = f(\hat{H}_1) + f(\hat{H}_2) 
$$

The only form that satisfies this in the most general case is

$$
  f(\hat{H}) = a\hat{H}
$$

where $a \in\mathbb{C}$ is a complex constant with dimension of inverse action. To determine $a$, we use the fact that the normalization condition $\braket{\psi|\psi} = 1$ is preserved during time evolution. Thus, the time derivative of $\braket{\psi|\psi}$ must vanish:

$$
\begin{equation*}
  \frac{\partial}{\partial t} \braket{\psi|\psi} = \frac{\partial\bra{\psi}}{\partial t} \ket{\psi} + \bra{\psi} \frac{\partial\ket{\psi}}{\partial t} = 0 
\tag{\label{equation-80}}
\end{equation*}
$$

Taking the Hermitian adjoint of $\frac{\partial}{\partial t}\ket{\psi} = a\hat{H}\ket{\psi}$ and noting that $\hat{H}$ is Hermitian, we find

$$
  \frac{\partial}{\partial t} \bra{\psi} = \bra{\psi} a^* \hat{H}
$$

Substuting this into $\eqref{equation-80}$, we obtain

$$
  \Braket{\psi|(a^* \hat{H} + a\hat{H})|\psi} = 0
$$

For this to hold for any $\ket{\psi}$, we require $a^* = -a$, meaning that $a$ is purely imaginary. Since $a$ has the dimension of inverse action, it must be proportional to $\hbar$. If we choose $1/a = i\hbar$, we retrieve the Schr√∂dinger equation:

$$
  i\hbar \frac{\partial}{\partial t}\ket{\psi} = \hat{H} \ket{\psi}
$$

### Time symmetry

The Schr√∂dinger equation is invariant under time reversal transformations $t \mapsto -t$, provided we also exchange kets with bras, i.e. $\ket{\psi} \to \bra{\psi}$. Taking the Hermitian conjugate of the Schr√∂dinger equation $\eqref{equation-98}$ yields

$$
  -i\hbar\frac{\partial}{\partial t} \bra{\psi} = \bra{\psi}\hat{H}
$$

or equivalently

$$
  i\hbar\frac{\partial}{\partial(-t)} \bra{\psi} = \bra{\psi}\hat{H}
$$

### Preservation of probability

The Schr√∂dinger equation preserves the Born rule if $\hat{H}$ is Hermitian. To prove this, note that probility is conserved, if the norm of $\ket{\psi}$ remains constant over time

$$
  \frac{\d}{\d t} \braket{\psi(t)|\psi(t)} = 0
$$

Applying the product rule to the left-hand side gives

$$
  \frac{\d}{\d t} \braket{\psi|\psi} = \frac{\d}{\d t}(\bra{\psi})\ket{\psi} + \ket{\psi} \frac{\d}{\d t}(\ket{\psi})
$$

Taking the Hermitian adjoint of the equation yields

$$
  -i\hbar\frac{\d}{\d t}\bra{\psi(t)} = \bra{\psi(t)}\hat{H}^\dagger 
$$

Substituting the Schr√∂dinger equation and its conjugate gives

$$
\begin{align*}
  \frac{\d}{\d t} \braket{\psi|\psi} =& \left(-\frac{i}{\hbar}\bra{\psi}\hat{H}^\dagger \right)\ket{\psi} + \bra{\psi}\left(\frac{i}{\hbar}\hat{H}\ket{\psi} \right) \\
  =& \frac{i}{\hbar}\left(\braket{\psi|\hat{H}|\psi} - \braket{\psi|\hat{H}^\dagger|\psi} \right) = 0
\end{align*}
$$

This expression vanishes if and only if $\braket{\psi|\hat{H}|\psi} = \braket{\psi|\hat{H}^\dagger|\psi}$. Since this must hold for any arbitrary state $\ket{\psi(t)}$, it follows that $\hat{H} = \hat{H}^\dagger$.

### Stationary states

If the Hamiltonian operator has a time-independent potential, the solution to the Schr√∂dinger equation is obtained by integrating $\eqref{equation-98}$, giving

$$
  \ket{\psi(t)} = e^{-i\hat{H}t/\hbar} \ket{\psi(0)}
$$

where $\ket{\psi(0)}$ is the state vector at time $t_0 = 0$. If the initial state vector is an eigenstate of the Hamiltonian, i.e.

$$
  \hat{H} \ket{\psi(0)} = E\ket{\psi(0)}
$$

where $E$ is the corresponding eigenvalue of $\hat{H}$, then the action of the operator $e^{i\hat{H}t/\hbar}$ on the state vector $\ket{\psi(0)}$ becomes trivial. In this case, the state vector at time $t$ is simply

$$
  \ket{\psi(t)} = e^{-iEt/\hbar} \ket{\psi(0)}
$$

Consequently, an energy eigenstate does not evolve with time since the phase factor $e^{-iEt/\hbar}$ is irrelevant for the physical state. In order to find a time-evolved state vector $\ket{\psi(t)}$, we first need to solve the eigenvalue equation for the Hamiltonian, called the time-independent Schr√∂dinger equation. In the case of a discrete spectrum, this reads

$$
  \hat{H}\ket{\psi_n} = E_n \ket{\psi_n}
$$

where $\ket{\psi_n}$ are the stationary states and $E_n$ are the corresponding eigenvalues, representing the energy levels of the system. Next, we expand the intial state vector $\ket{\psi(0)}$ in terms of the basis $\set{\ket{\psi_n}}$ by determining the complex coefficients $c_n^(0)$ such that

$$
  \ket{\psi(0)} = \sum_n c_n^{(0)} \ket{\psi_n}
$$

The time-evolved state is the given by

$$
  \ket{\psi(t)} = \sum_n e^{-iE_nt/\hbar} c_n^{(0)} \ket{\psi_n}
$$

For a continuous spectrum, the eigenvalue equation becomes

$$
  \hat{H}\ket{\psi_E} = E\ket{\psi_E}
$$

and the expansion of $\ket{\psi(0)}$ onto the continuous basis $\ket{\psi_E}$ is 

$$
  \ket{\psi(0)} = \int c^{(0)} (E) \ket{\psi_E} \;\d E
$$

The time-evolved state is then

$$
  \ket{\psi(t)} = \int e^{-iEt/\hbar} c^{(0)} (E) \ket{\psi_E} \;\d E
$$

Taking the expectation value of $\hat{H}$ with respect to an initial eigenstate $\ket{\psi(0)}$, we get

$$
\begin{align*}
  \braket{\hat{H}}_\psi =& \braket{\psi|\hat{H}|\psi} = E\underbrace{\braket{\psi|\psi}}_{=1} = E
\end{align*}
$$

Since

$$
  \hat{H}^2 \ket{\psi} = \hat{H}(\hat{H}\ket{\psi}) = \hat{H}(E\ket{\psi}) = E(\hat{H}\ket{\psi}) = E^2 \ket{\psi}
$$

it follows that $\braket{\hat{H}^2} = E^2$. Thus, the variance of $H$ is

$$
  \sigma_H^2 = \braket{H^2} - \braket{H}^2 = E^2 - E^2 = 0
$$

showing that the total energy is a determinate state.

#### Wavefunction formulation

In terms of a wavefunction $\psi(x,t)$, the Schr√∂dinger equation for a time-independent potential can be solved by separation of variables. Assuming a wavefunction of the form $\Psi(\mathbf{x},t) = \psi(\mathbf{x})\phi(t)$ with partial derivatives

$$
  \frac{\partial\Psi}{\partial t} = \psi \frac{\d\phi}{\d t}, \quad \nabla^2 \Psi = (\nabla^2 \psi) \phi
$$

the Schr√∂dinger equation reads

$$
\begin{align*}
  i\hbar \psi \frac{\d\phi}{\partial t} =& -\frac{\hbar^2}{2m} (\nabla^2 \psi)\phi + V\psi\phi \\
  i\hbar \frac{1}{\phi} \frac{\d\phi}{\d t} =& -\frac{\hbar^2}{2m} \frac{1}{\psi} \nabla^2 \psi + V
\end{align*}
$$

The equation holds if both sides equal a separation constant, which in this case corresponds with the systems total energy $E$. This results in the temporal equation

$$
  \frac{\d\phi}{\d t} = -\frac{iE}{\hbar} \phi
$$

and the spatial equation

$$
\begin{align*}
  -\frac{\hbar^2}{2m} \nabla^2 \psi + V\psi =& E\psi \\
  \hat{H}\psi =& E\psi 
\end{align*}
$$

which is called the time-independent Schr√∂dinger equation. The temporal equation has general solution

$$
  \phi(t) = C e^{-iEt/\hbar}
$$

Absorbing the normalization constant $C$ into $\psi$, the wavefunction becomes

$$
  \Psi(\mathbf{x}, t) = \psi(\mathbf{x}) e^{-iEt/\hbar}
$$

Although $\Psi$ depends on $t$, the probability density

$$
  |\Psi(\mathbf{x},t)|^2 = \Psi^* \Psi = \psi^* e^{iEt/\hbar} \psi e^{-iEt/\hbar} = |\psi(x)|^2
$$

is time-independent.

### Degenerate eigenvalues

Energy eigenstate can be degenerate, in which case two or more eigenstates share the same eigenvalue. A neccessary and sufficient condition for energy degeneracy is that an observable $\hat{Q}$ commutes with the Hamiltonian, and is not the identity operator. Specifically, if

$$
  [\hat{H}, \hat{Q}] = 0
$$

and $\hat{Q}$ is not a function of $\hat{H}$ alone, then

$$
  \hat{H}\hat{Q} \ket{\psi_j} = \hat{Q}\hat{H}\ket{\psi_j} = E_j \hat{Q} \ket{\psi_j}
$$

which shows that $\hat{Q}\ket{\psi_j}$ is an eigenvector of $\hat{H}$ with eigenvalue $E_j$. Moreover, $\hat{Q}\ket{\psi_j}$ cannot be proportional to $\ket{\psi_j}$. In other words, it cannot be written as $\hat{Q}\ket{\psi_j} = f(E_j) \ket{\psi_j}$, where $f(E_j)$ is a function of the $j$-th energy eigenvalue. If this were the case, $\hat{Q}$ would be equal to $f(\hat{H})$, which contradicts the assumptions that $\hat{Q}$ is not a function of $\hat{H}$.

Let us prove that degeneracy implies commutativity in the case of a discrete spectrum. If degeneracy exists, the whole Hilbert space $\mathcal{H}$ can always be partitioned into subspaces $\mathcal{H}_k$ for $k\in\N_+$, each of which is associated with a constant energy eigenvalue $E_k$. In this case, we can write

$$
  \mathcal{H} = \bigoplus_k \mathcal{H}_k
$$

For any $\ket{\varphi}\in\mathcal{H}_k$, we have

$$
  \hat{H}\ket{\varphi} = E_k \ket{\varphi}
$$

Thus, within each subspace $\mathcal{H}_k$, the Hamiltonian $\hat{H}_k$ acts as multiple of the identity, i.e. $\hat{H}_k = E_k \hat{I}$. The dimension of $\mathcal{H}_k$ is equal to the degeneracy of the eigenvalue $E_k$. Next, we can define a Hermitian operator $\hat{Q}$

$$
  \hat{Q} = \bigotimes_n \hat{Q}_n
$$

where $\hat{Q}_k$ is an arbitrary operator acting within $\mathcal{H}_k$. Furthermore, since $\hat{H}_k = E_k \hat{I}$, it follows that $[\hat{Q}_k, \hat{H}_k] = 0$. This implies that $\hat{Q}$ commutes with $\hat{H}$, i.e. $[\hat{Q},\hat{H}] = 0$.

## Time evolution operator

A time evolution operator $\hat{U}$ translates a state vector $\ket{\psi(t)}$ from time $t_a$ to $t_b$ by

$$
  \hat{U}(t_b,t_a)\ket{\psi(t_a)} = \ket{\psi(t_b)}
$$

with the initial condition $\hat{U}(t_a, t_a) = \hat{I}$.

If the Hamiltonian is time-independent, the time evolution operator is obtainable from the Schr√∂dinger equation

$$
  i\hbar\frac{\partial}{\partial t_b}(\hat{U}(t_b,t_a)\ket{\psi(t_a)}) = \hat{H}\hat{U}(t_b,t_a)\ket{\psi(t_a)} 
$$

Since $\ket{\psi(t_a)}$ is indepedent of $t_b$, we can factor it out from the partial time derivative

$$
  i\hbar\frac{\partial\hat{U}(t_b,t_a)}{\partial t_b}\ket{\psi(t_a)} = \hat{H}\hat{U}(t_b,t_a)\ket{\psi(t_a)} 
$$

This equation must hold for any initial state $\ket{\psi(t_a)}$ giving a first-order differential equation for $\hat{U}(t_b,t_a)$

$$
  i\hbar\frac{\partial\hat{U}(t_b,t_a)}{\partial t_b} = \hat{H}\hat{U}(t_b,t_a)
$$

with solution

$$
  \hat{U}(t_b,t_a) = e^{i\hat{H}(t_a - t_b)/\hbar}
$$

Its inverse is obtained by interchanging the order of $t_a$ and $t_b$

$$
  \hat{U}^{-1}(t_b,t_a) = e^{-i\hat{H}(t_a - t_b)/\hbar}
$$

Since $\hat{H}$ is Hermitian, $\hat{U}$ is unitary because

$$
\begin{equation*}
\begin{split}
  \hat{U}^\dagger (t_b,t_a) =& e^{i(t_b - t_a)\hat{H}^\dagger /\hbar} \\
  =& e^{i(t_b - t_a)\hat{H} /\hbar} \\
  =& \hat{U}^{-1}(t_b,t_a)
\end{split}
\tag{\label{equation-6}}
\end{equation*}
$$

If the Hamiltonian depends explicitly on time, the time evolution operator can be found iteratively. The time interval $[t_a, t_b]$ with $t_a < t_b$ is partitioned into $N + 1$ subintervals of length $\epsilon = (t_b - t_a)/(N + 1)$, such that $t_n = t_a + n\epsilon$ for $n=0,\dots,N+1$. Schr√∂dinger's equation approximates the time evolution at each step $\epsilon$

$$
\begin{align*}
  \ket{\psi(t_a + \epsilon)} \approx& \left(1 - \frac{i}{\hbar} \int_{t_a}^{t_a + \epsilon} \hat{H}(t)\;\d t \right)\ket{\psi(t_a)} \\
  \ket{\psi(t_a + 2\epsilon)} \approx& \left(1 - \frac{i}{\hbar} \int_{t_a}^{t_a + 2\epsilon} \hat{H}(t)\;\d t \right)\ket{\psi(t_a + \epsilon)} \\
  \vdots& \\
  \ket{\psi(t_a + (N+1)\epsilon)} \approx& \left(1 - \frac{i}{\hbar} \int_{t_a}^{t_a + (N+1)\epsilon} \hat{H}(t)\;\d t \right)\ket{\psi(t_a + N\epsilon)} 
\end{align*}
$$

Combining the equation, the time evolution operator is approximated as

$$
  \hat{U}(t_b, t_a) \approx \prod_{n=0}^{N} \left(\int_{t_n}^{t_{n+1}} \hat{H}(t'_{n+1})\;\d t'_{n+1} \right)
$$

Expanding the product and taking the limit $N\to\infty$ gives the series

$$
\begin{align*}
  \hat{U}(t_b, t_a) =& 1 - \frac{1}{\hbar} \int_{t_a}^{t_b} \d t'_1 \;\hat{H}(t'_1) \\
  &+ \left(\frac{-i}{\hbar}\right) \int_{t_a}^{t_b} \d t'_n \int_{t_a}^{t_n} \d t'_{n-1} \cdots \int_{t_a}^{t'_2} \d t'_1 \;\hat{H}(t'_n)\hat{H}(t'_{n-1})\cdots\hat{H}(t'_1)
\end{align*}
$$

known as the *Neumann-Liouville expansion* or *Dyson series*. Note that each integral has the time arguments in the Hamilton operators ordered causally since the operators are ordered descending in time. It is useful to introduce a time-ordering operator, which when applied to an arbitrary product of operators

$$
  \hat{O}_n (t_n) \cdots\hat{O}_1 (t_1)
$$

reorders the times successivelse, i.e.

$$
  \hat{T}(\hat{O}_n (t_n)c\dots\hat{O}_1 (t_1)) := \hat{O}_{i_n} (t_{i_n})\cdots\hat{O}_{i_1} (t_{i_1})
$$

where $t_{i_n},\dots,t_{i_1}$ are the times $t_n,\dots,t_1$ relabeled in the causal order, so that

$$
  t_{i_n} > t_{i_{n-1}} >\cdots> t_{i_1}
$$

With this operator, the Neumann-Liouville expansion can be written more compactly. Consider the third term of the series

$$
\begin{equation*}
  \int_{t_a}^{t_b} \d t_2 \int_{t_a}^{t_2} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1)
\tag{\label{equation-1}}
\end{equation*}
$$

The integration covers the triangle above the diagonal in the square $t_1, t_2 \in [t_a, t_b]$ in the $(t_1, t_2)$ plane. Comparing this the with the remaining integral over the lower triangle

$$
\begin{equation*}
  \int_{t_a}^{t_b} \d t_2 \int_{t_2}^{t_b} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1)
\tag{\label{equation-2}}
\end{equation*}
$$

we see that the two expressions coincide except for the order of the operators. Applying the time-ordering operator to $\eqref{equation-2}$, gives

$$
  \hat{T} \int_{t_a}^{t_b} \d t_2 \int_{t_2}^{t_b} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1)
$$

which is equal to $\eqref{equation-1}$ because $\eqref{equation-2}$ can be rewritten as

$$
\begin{equation*}
  \int_{t_a}^{t_b} \d t_2 \int_{t_2}^{t_b} \d t_1 \; \hat{H}(t_1)\hat{H}(t_2) = \int_{t_a}^{t_b} \d t_1 \int_{t_a}^{t_1} \d t_2 \; \hat{H}(t_1)\hat{H}(t_2) 
\tag{\label{equation-3}}
\end{equation*}
$$

where the order of integration is changed in the last step. Apart from the dummy integration variables $t_2 \leftrightarrow t_1$, the double integral $\eqref{equation-3}$ coincides with $\eqref{equation-1}$. Since the time arguments are properly ordered, the time-ordering operator can be applied to $\eqref{equation-1}$ to give

$$
  \frac{1}{2}\hat{T}\int_{t_a}^{t_b} \d t_2 \int_{t_a}^{t_b} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1) = \frac{1}{2}\hat{T}\left(\int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)^2
$$

Similarly, we may rewrite the $n$-th order term of the Neumann-Liouville expansion as

$$
\begin{align*}
  &\frac{1}{n!} \hat{T} \int_{t_a}^{t_b} \d t_n \int_{t_a}^{t_b} \d t_{n-1} \cdots \int_{t_a}^{t_b} \d t_1 \; \hat{H}(t_n)\hat{H}(t_{n-1})\cdots\hat{H}(t_1) \\
  =& \frac{1}{n!} \hat{T}\left(\int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)^n 
\end{align*}
$$

The time evolution operator $\hat{U}(t_b, t_a)$ has therefore the series expansion

$$
\begin{align*}
  \hat{U}(t_b, t_a) = \sum_{n=0}^\infty \frac{1}{n!}\left(\frac{-i}{\hbar}\right)^n \hat{T}\left(\int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)^n
\end{align*}
$$

which we recognize as the power series expansion of the exponential, giving

$$
\begin{equation*}
  \hat{U}(t_b, t_a) = \hat{T}\exp\left(-\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)
\tag{\label{equation-5}}
\end{equation*}
$$

Note that a small variation $\delta\hat{H}(t)$ of $\hat{H}(t)$ changes $\hat{U}(t_b, t_a)$ by

$$
\begin{align*}
  \delta\hat{U}(t_b, t_a) =& -\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{T}\exp\left(-\frac{i}{h} \int_{t'}^{t_b} \hat{H}(t)\; \d t \right) \delta\hat{H}(t') \hat{T}\exp\left(-\frac{i}{\hbar} \int_{t_a}^{t'} \hat{H}(t)\;\d t \right)\; \d t'\\
  =& -\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{U}(t_b, t') \delta\hat{H} (t') \hat{U}(t', t_a)\; \d t'
\end{align*}
$$

### Properties of the time evolution operator

#### Fundamental composition law

If two time translation are performed successively, the corresponding operators $\hat{U}$ are related by

$$
\begin{equation*}
  \hat{U}(t_c, t_a) = \hat{U}(t_c, t_b)\hat{U}(t_b, t_a),\; t_b \in(t_a, t_c)
\tag{\label{equation-4}}
\end{equation*}
$$

This composition law makes the operators $\hat{U}$ a representation of the Abelian group of time translations. For time-independent Hamiltonians the composition law $\eqref{equation-4}$ is trivial. In the general case with $\hat{U}(t_b, t_a)$ given by $\eqref{equation-5}$, the composition law follows from the additivity rule of the exponential

$$
\begin{align*}
  &\hat{T}\exp\left(-\frac{i}{\hbar} \int_{t'}^{t_b} \hat{H}(t)\;\d t \right)\hat{T} \exp\left(\int_{t_a}^{t'} \hat{H} (t) \;\d t \right) \\
  =& \hat{T}\left[\exp\left(-\frac{i}{\hbar} \int_{t'}^{t_b} \hat{H}(t)\;\d t \right) \exp\left(-\frac{i}{\hbar} \int_{t_a}^{t'} \hat{H}(t)\;\d t \right) \right] \\
  =& \hat{T}\exp\left(-\frac{i}{\hbar} \left[ \int_{t'}^{t_b} \hat{H}(t)\;\d t + \int_{t_a}^{t'} \hat{H}(t)\;\d t \right]\right) \\
  =& \hat{T}\exp\left(-\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)
\end{align*}
$$

#### Unitarity (time reversal)

The inverse of the time evolution operator $\hat{U}(t_b, t_a)$ is obtained by interchanging the order of $t_a$ and $t_b$, which gives its anticasual form, i.e.

$$
  \hat{U}(t_b, t_a) = \hat{U}(t_a, t_b)^{-1}
$$

<details>
<summary>Proof</summary>

The time-reversal invertibility of $\hat{U}(t_b, t_a)$ follows by setting $t_b = t_a$ in $\eqref{equation-4}$ resulting in

$$
  \hat{I} = \hat{U}(t_a, t_a) = \hat{U}(t_a, t_b) \hat{U}(t_b, t_a)
$$

so that

$$
  \hat{U}(t_b, t_a)^{-1} = \hat{U}(t_a, t_b)
$$
</details>

This implies that $\hat{U}$ is unitary. The unitarity was already established for time independent Hamiltonians in $\eqref{equation-6}$. In the general case, a direct solution of the Schr√∂dinger equation shows that the operator $\hat{U}(t_b, t_a)$ for $t_b < t_a$ has a representation just like $\eqref{equation-5}$, except for a reversed time order of its argument, written as

$$
  \hat{U}(t_b, t_a) = \hat{\bar{T}} \exp\left(\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}(t) \;\d t \right)
$$

where $\hat{\bar{T}}$ denotes the time-antiordering operator, which satisfies

$$
  \left[\hat{T}\left(\hat{O}_1 (t_1)\cdots \hat{O}_n (t_n) \right) \right]^\dagger = \hat{\bar{T}} \left(\hat{O}_n^\dagger (t_n)\cdots \hat{O}_1^\dagger (t_1) \right)
$$

It follows that

$$
\begin{align*}
  \hat{U}^\dagger (t_b, t_a) =& \left[\hat{T} \exp\left(\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H} (t) \;\d t \right)\right]^\dagger \\
  =& \hat{\bar{T}} \exp\left(\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}^\dagger (t) \;\d t \right) \\
  =& \hat{T} \exp\left(-\frac{i}{\hbar} \int_{t_b}^{t_a} \hat{H} (t) \;\d t \right) \\
  =& \hat{U}(t_a, t_b) = \hat{U}^{-1} (t_b, t_a)
\end{align*}
$$

#### Transition amplitudes

The transition amplitude between an initial state $\ket{\phi}$ at time $t_a$ and a final state $\ket{\psi}$ at time $t_b$ is given by $\braket{\psi|\hat{U}(t_b, t_a)|\phi}$. Taking the complex congujate of the expectation value we obtain

$$
  \left(\braket{\psi|\hat{U}(t_b, t_a)|\phi}\right)^* = \braket{\phi|\hat{U}(t_a, t_b)|\psi}
$$

which represents the probability amplitude for evolving $\ket{\psi}$ backward from $t_b$ to $t_a$. In this context, kets may viewed as input states and bras as output states of a unitary evolution. 

In particular, the amplitude $\braket{\psi|\hat{U}(t_b, t_a)|\psi}$ is the autocorrelation amplitude, giving the overlap of the evolved state with the initial state. Its squared modulus

$$
  C(t_b, t_a) = |\braket{\psi|\hat{U}(t_b, t_a)|\psi}|^2
$$

is the autocorrelation function, which measures the probability that the state $\ket{\psi}$ remains unchanged under time evolution.

#### Time evolution for $\hat{U}(t_b, t_a)$

Since the time-evolution operator $\hat{U}(t_b, t_a)$ gives the relation between arbitrary wavefunctions at different times

$$
  \ket{\psi(t_b)} = \hat{U}(t_b, t_a) \ket{\psi(t_a)}
$$

the Schr√∂dinger equation implies that the operator $\hat{U}(t_a, t_b)$ satisfies

$$
\begin{equation*}
\begin{split}
  i\hbar\frac{\partial}{\partial t} \hat{U}(t, t_a) =& \hat{H}\hat{U}(t, t_a) \\
  i\hbar\frac{\partial}{\partial t} \hat{U}^{-1} (t, t_a) =& -\hat{U}(t, t_a)^{-1} \hat{H}
\end{split}
\tag{\label{equation-8}}
\end{equation*}
$$

with the initial condition $\hat{U}(t_a, t_a) = 1$.

### Green's function

If the Hamiltonian admits a discrete spectrum, the elements of the time-evolution matrix can be written as

$$
  \Braket{k|e^{-i\hat{H}(t - t_0)/\hbar}|j} = i G(j, t_0; k, t)
$$

here $\ket{j}$ and $\ket{k}$ are state vectors, and $G$ denotes the Green's function. 

For a wavefunction in position space, we can derive an analogous expression by multiplying the time-independent Schr√∂dinger equation

$$
  \ket{\psi(t')} = e^{-i\hat{H}(t' - t)/\hbar}\ket{\psi(t)}
$$

with the position bra $\bra{\mathbf{r}'}$ and use the completeness relation $\hat{I} = \int \ket{\mathbf{r}}\bra{\mathbf{r}} \;\d\mathbf{r}$. This gives

$$
  \psi(\mathbf{r}',t) = i\int G(\mathbf{r}', t'; \mathbf{r}, t) \psi(\mathbf{r}, t) \;\d\mathbf{r}
$$

This equation reflects an instance of Huygens' principle: if the wwave function $\psi(\mathbf{r},t)$ is known at a time $t$, it can be determined at any later time $t'$ by considering each point $\mathbf{r}$ at time $t$ is a source of waves propagating outward. The amplitude of the wave arriving at point $\mathbf{r}'$ at time $t'$ from the point $\mathbf{r}$ is proportional to the original wave amplitude $\psi(\mathbf{r},t)$, with proportionality constant given by $iG(\mathbf{r}', t'; \mathbf{r}, t)$.

Green's functions are related to the resolvent of the Hamiltonian as the latter is the Fourier transform of the relative unitary operator, i.e.

$$
  \hat{R}_{\hat{H}}(\eta) = i \int_0^\infty e^{-\eta\tau} e^{-i\hat{H}\tau/\hbar} \;\d\tau
$$

where $\tau = t' - t$. For a linear operator $\hat{Q}$ on the Hilbert space $\mathcal{H}$, the resolvent $\hat{R}_{\hat{Q}}(\eta)$ is the operator-valued function

$$
  \hat{R}_{\hat{Q}}(\eta) = (\hat{Q} - \eta)^{-1s}
$$

which is defined for all complex values of $\eta$ where $(\hat{Q} - \eta)^{-1}$ exists. For the case of the Hamiltonian, we can use the projectors $\hat{P}_j$ onto the eigenvalues $E_j$ of $\hat{H}$. This gives the relation:

$$
  \hat{R}_{\hat{H}} (\eta) \hat{P}_j = \frac{\hat{P}_j}{E_j - \eta}
$$

This allows us to interpret the projectors $\hat{P}_j$ as the residues of the closed contour $f_j$ in the complex plane, enclosing the point $E_j$ on the real axis of the complex plane, i.e.

$$
  \hat{P}_j = \frac{1}{2\pi i} \oint_{f_j} \hat{R}_{\hat{H}} (\eta) \;\d\eta
$$

For the continuous part of the spectrum, we have

$$
  \hat{P}(\Delta j) = \frac{1}{2\pi i} \oint_{f(\Delta j)} \hat{R}_{\hat{H}} (\eta) \;\d\eta
$$

where $\hat{P}(\Delta j)$ is a projector on a small interval around the continuous eigenvalue $E_j$. 

In the case of a free particle, the Hamiltonian has a pure continuous spectrum in the iterval $[0,\infty)$. The resolvent of the free particle Hamiltonian $\hat{H}_0$ is

$$
  \hat{R}_{\hat{H}_0} (\eta) = \frac{1}{\hat{H}_0 - \eta}
$$

which is defined for all $\eta$ outside the spectrum. This resolvent is a bounded operator on the entire Hilbert space when $\Re(\eta) < 0$ or $\Im(\eta) \neq 0$, i.e. when the argument of $\eta$ is within the open interval $(0,2\pi)$. Using Green's functions, the evolution of a free particle in space and time takes the form

$$
  \psi(\mathbf{r}', t') = i\int G_0 (\mathbf{r}', t'; \mathbf{r}, t) \psi(\mathbf{r},t) \;\d\mathbf{r}
$$

for $t' > t$ and for all values $0 < \eta < 2\pi$. Here $G_0$ is called the free Green's function and its explicit expression is

$$
  G_0 (\mathbf{r}', t'; \mathbf{r}, t) = -i\left(\frac{m}{2\pi i \hbar(t' - t)} \right)^{3/2} \exp\left( i\frac{m|\mathbf{r}' - \mathbf{r}|^2}{2\hbar (t' - t)} \right)
$$

## Propagator

The matrix elements of the time evolution operator in the localized basis states $\set{\ket{\mathbf{x}}}_{\mathbf{x}\in\R^3}$ defines a function

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) := \braket{\mathbf{x}_b|\hat{U}(t_b,t_a)|\mathbf{x}_a}
$$

called the *propagator* of a quantum system. The propagator gives an alternate representation for the wavefunction of a quantum particle. In the position basis $\set{\ket{\mathbf{x}}}_{\mathbf{x}\in\R^3}$, the completeness relation gives

$$
  \int_{\R^3} \ket{\mathbf{x}}\bra{\mathbf{x}}\;\d^3 x = 1
$$

The time evolution of a state vector $\ket{\psi(t)}$ from $t=0$ to $t$ can be written as

$$
\begin{align*}
  \ket{\psi(t)} =& \hat{U}(t,0)\ket{\psi(0)} = \int_{\R^3} \hat{U}(t,0) \ket{\mathbf{y}}\braket{\mathbf{y}|\psi(0)}\; \d^3 y \\
  =& \int_{\R^3} \hat{U}(t,0)\ket{\mathbf{y}} \psi(\mathbf{y}, 0)\;\d^3 y
\end{align*}
$$

The wavefunction $\psi(\mathbf{x},t) = \braket{\mathbf{x}|\psi(t)}$ thus takes the form

$$
\begin{align*}
  \psi(\mathbf{x},t) =& \braket{\mathbf{x}|\psi(t)} = \int_{\R^3} \braket{\mathbf{x}|\hat{U}(t,0)|\mathbf{y}}\psi(\mathbf{y},0)\; d^3 y \\
  =& \int_{\R^3} (\mathbf{x},0|\mathbf{y},t)\psi(\mathbf{y}, 0)\; \d^3 y
\end{align*}
$$

We can recover the time evolution operator from the propagator by

$$
  \hat{U}(t) = \int (\mathbf{x},0|\mathbf{y},t) \ket{\mathbf{x}}\bra{\mathbf{y}}\; \d^3 x\;\d^3 y
$$

The propagator and the time evolution operator both completely describe the behaviour a the system. One can intuitively think of the propagator $K(\mathbf{x}_a, t_a \mathbf{x}_b; t_b)$, as the probability amplitude for a particle to travel from $\mathbf{x}_a$ to $\mathbf{x}_b$ in time $t_b - t_a$ with $t_b > t_a$. The propagator is therefore also referred to as *time evolution amplitude*.

From the operator equations $\eqref{equation-8}$, the propagator satisfies the Schr√∂dinger equation

$$
  i\hbar \frac{\partial}{\partial t_b} (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) = H(-i\hbar\nabla_{\mathbf{x}_b}, \mathbf{x}_b,t_b) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)
$$

When dealing with non-relativistic particles, it is customary to introduce a casual/retarded time evolution operator

$$
  \hat{U}_R (t_b,t_a) = \begin{cases}
    \hat{U}(t_b,t_a),\quad& t_b \geq t_a \\
    0,\quad& t_b < t_a
  \end{cases}
$$

and the associated casual/retarded time evolution amplitude

$$
  (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)_R := \braket{\mathbf{x}|\hat{U}_R (t_b,t_a)|\mathbf{y}}
$$

The retarded time evolution operator can be expressed in terms of the Heaviside step function

$$
  \Theta(t) := \begin{cases}
    1,\quad& t > 0 \\
    0,\quad& t \leq 0
  \end{cases}
$$

giving

$$
\begin{align*}
  \hat{U}_R (t_b,t_a) =& \Theta(t_b - t_a) \hat{U}(t_b, t_a) \\
  (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)_R =& \Theta(t_b - t_a) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)
\end{align*}
$$

Note that the derivative of the Heaviside function is given by Dirac's delta function, i.e.  $\frac{\d}{\d t}\Theta(t) = \delta(t)$. In terms of the Heaviside function, the retarded propagator satisfies the Schr√∂dinger equations

$$
  \left[H_R(-i\hbar\nabla_{\mathbf{x}_b},\mathbf{x}_b,t_b) - i\hbar\frac{\partial}{\partial t_b}\right] (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) = -i\hbar \delta(t_b - t_a) \delta(\mathbf{x}_b - \mathbf{x}_a)
$$

The nonzero right-hand side arises from the extra term

$$
\begin{align*}
  -i\hbar \left(\frac{\partial}{\partial t_b}\Theta(t_b - t_a)\right) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) =& -i\hbar\delta(t_b - t_a) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) \\
  =& -i\hbar (\mathbf{x}_a,t_a|\mathbf{x}_b,t_a)
\end{align*}
$$

and the initial condition $K(\mathbf{x}_a,t_a;\mathbf{x}_b,t_a) = \braket{\mathbf{x}_b|\mathbf{x}_a}$ since $\hat{U}(t_a, t_a) = 1$.

If the Hamiltonian does not depend on time, the propagator depends only on the time difference $t = t_b - t_a$. The retarded propagator vanishes for $t < 0$. This property leads to a class of functions $f(t)$ with a characteristic Fourier transform of the form

$$
  \tilde{f}(E) = \int_0^\infty f(t) e^{iEt/\hbar} \;\d t
$$

which is analytic in the upper half of the complex energy plane. This analyticity property is necessary and sufficient to produce a factor $\Theta(t)$ in the inverse Fourier transform

$$
  f(t) = \frac{1}{2\pi\hbar} \int_{-\infty}^\infty \tilde{f}(E) e^{-iEt/\hbar}\;\d E 
$$

For $t < 0$, the contour integration may be closed by an infinite semicircle in the upper half-plane at no extra cost. Since the contour encloses no singularities, it can be contracted to a point, yielding $f(t) = 0$.

### Fixed-energy amplitude

The *fixed-energy amplitude* of a quantum system is defined by the Fourier transform of the retarded time evolution amplitude

$$
\begin{equation*}
\begin{split}
  (\mathbf{x}_b,\mathbf{x}_a)_E =& \int_{-\infty}^\infty e^{iE(t_b - t_a)/\hbar} (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a)_R \;\d t_b \\
  =& \int_{t_a}^\infty e^{iE(t_b - t_a)/\hbar} (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) \;\d t_b
\end{split}
\tag{\label{equation-11}}
\end{equation*}
$$

If the Hamiltonian is time-independent, the propagator takes the form

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) = \braket{\mathbf{x}_b|e^{-i\hat{H}(t_b - t_a)/\hbar}|\mathbf{x}_a}
$$

In this case, the fixed-energy amplitudes are matrix element

$$
  (\mathbf{x}_b,\mathbf{x}_a)_E = \braket{\mathbf{x}_b |\hat{R}(E)|\mathbf{x}_a}
$$

of the *resolvent operator*

$$
  \hat{R}(E) = \frac{i\hbar}{E - \hat{H} + i\eta}
$$

which is the Fourier transform of the retarded time evolution operator

$$
\begin{align*}
  \hat{R}(E) =& \int_{-\infty}^\infty e^{iE(t_b - t_a)/\hbar} \hat{U}_R (t_b, t_a)\;\d t_b \\
  =& \int_{t_a}^\infty e^{iE(t_b - t_a)/\hbar} \hat{U}(t_b, t_a) \;\d t_0
\end{align*}
$$

If $\hat{H}$ has a discrete spectrum $\sigma(\hat{H}) = \Set{E_n}_{n\in\N}$ with corresponding eigenstates $\set{\ket{\psi_n}}_{n\in\N}$, the propagator has the following spectral representation

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) = \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) e^{-iE_n (t_b - t_a)/\hbar}
$$

where $\psi_n (\mathbf{x}) = \braket{\mathbf{x}|n}$ is the wavefunction associated with the eigenstate $\ket{\psi_n}$. Applying the Fourier transform $\eqref{equation-11}$, we obtain the fixed-energy amplitude

$$
\begin{equation*}
\begin{split}
  (\mathbf{x}_b|\mathbf{x}_a)_E =& \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) R_n (E) \\
  =& \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) R_n (E) \frac{i\hbar}{E - E_n + i\eta}
\end{split}
\tag{\label{equation-12}}
\end{equation*}
$$

The time evolution amplitude is recovered by the inverse Fourier transform

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) = \frac{1}{2\pi\hbar}\int_{-\infty}^\infty e^{-iE(t_b - t_a)/\hbar} (\mathbf{x}_a|\mathbf{x}_b)_E \;\d E
$$

The small $i\eta$-shift in the energy $E$ in $\eqref{equation-12}$ can be thought of as being attached to each of the energies $E_n$, which are thus placed by an infinitesimal piece below the real energy axis. This makes the exponential behaviour of the wavefunctions slighty damped, vanishing at infinite time, i.e. $e^{-i(E_n - i\eta)t/\hbar} \xrightarrow{t\to\infty} 0$.

If the eigenstates are nondegenerate, the residues at the poles of $\eqref{equation-12}$ render directly the products of eigenfunctions (barring degeneracies, which must be discussed separately). For a system with a continuum of energy eigenvalues, there is a cut in the complex energy plane which may be thought of as a closely spaced sequence of poles. In general, the wavefunctions are recovered from the discontinuity of the amplitudes $(\mathbf{x}_b|\mathbf{x}_a)_E$ across the cut, using the formula

$$
\begin{align*}
  \operatorname{disc}\left(\frac{i\hbar}{E - E_n}\right) =& \frac{i\hbar}{E - E_n + i\eta} - \frac{i\hbar}{E - E_n - i\eta} \\
  =& 2\pi\hbar\delta(E - E_n)
\end{align*}
$$

This follows from Sochocki's formula, valid inside integrals over $E$

$$
  \frac{1}{E - E_n \pm i\eta} = \frac{\mathcal{P}}{E - E_n} \mp i\pi\delta(E - E_n)
$$

where $\mathcal{P}$ indicates that the principal value of the integral has to be taken.

The energy integral over the discontinuity of the fixed-energy amplitude $\eqref{equation-12}$ reproduces the completeness relation taken between the local states $\bar{\mathbf{x}_b}$ and $\ket{\mathbf{x}_a}$

$$
\begin{equation*}
\begin{split}
  \int_{-\infty}^\infty \frac{\d E}{2\pi\hbar} \operatorname{disc}(\mathbf{x}_b|\mathbf{x}_a)_E =& \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) \\
  =& \braket{\mathbf{x}_b|\mathbf{x}_a} = \delta^(3) (\mathbf{x}_b - \mathbf{x}_a)
\end{split}
\tag{\label{equation-13}}
\end{equation*}
$$

The completeness relation reflects the following property of the resolvent operator

$$
  \int_{-\infty}^\infty \frac{\d E}{2\pi\hbar} \operatorname{disc}\left(\hat{R}(E)\right) = \hat{I}
$$

If the system also possesses a continuous spectrum, the completeness relation has the form

$$
  \sum_{n\in\sigma(\hat{H})} \ket{\psi_n}\bra{\psi_n} + \int \ket{\psi_\nu}\bra{\psi_\nu}\;\d\nu = 1
$$

The continuum causes a branch cut along in the complex energy plan, such that $\eqref{equation-13}$ also includes an integral over the discontinuity along the cut.

## Time-evolution pictures

### Heisenberg picture

The Heisenberg picture offers an alternate formulation of quantum mechanics that is more closely related to classical mechanics than the Schr√∂dinger picture. In the Heisenberg picture, the time dependence is entirely transferred from the state vector to the observable.

In the Schr√∂dinger picture the expectation value of an arbitrary observable $\hat{O}$ is given by

$$
  {}_\text{S}\braket{\psi(t)|\hat{O}^\text{S}|\psi(t)}_\text{S}
$$

Applying the time evolution operator $\hat{U}_t$, this expectation value can be written as

$$
\begin{equation*}
\begin{split}
  {}_\text{S}\braket{\psi(t)|\hat{O}^\text{S}|\psi(t)}_\text{S} =& {}_\text{S}\braket{\psi(0)|\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t|\psi(0)}_\text{S} \\
  =& {}_\text{H}\braket{\psi|\hat{O}^\text{H} (t)|\psi}_\text{H}
\end{split}
\tag{\label{equation-99}}
\end{equation*}
$$

where $\ket{\psi}_\text{H} = \ket{\psi(0)}_\text{S}$ is the state vector in the Heisenberg picture, and $\hat{O}^\text{H} (t) = \hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t$ is the time-dependent observable in the Heisenberg picture. Since the transformation from the Schr√∂dinger to the Heisenberg picture is unitary, the Hamiltonian is invariant, i.e.

$$
  \hat{H}^\text{H} = \hat{H}^\text{S} = \hat{H}
$$

To find the equation of motion for an observable, we take the time derivative of $\eqref{equation-99}$:

$$
\begin{align*}
  &\frac{\d}{\d t} \left({}_\text{S}\braket{\psi(t)|\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t|\psi(t)}_\text{S} \right) \\
  =& {}_\text{S}\Braket{\psi(0)|\left(\frac{i}{\hbar}\hat{H}\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t - \frac{i}{\hbar}\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t \hat{H} + \hat{U}_t^\dagger \frac{\partial\hat{O}^\text{S}}{\partial t} \hat{U}_t \right)|\psi(0)}_\text{S} \\
  =& {}_\text{H} \Braket{\psi|\left(\frac{i}{\hbar}[\hat{H},\hat{O}^\text{H}] + \frac{\partial}{\partial t} \hat{O}^\text{H} (t) \right)|\psi}_\text{H}
\end{align*}
$$

Since the expectation value of an observable is idependent of the time-evolution picture, this must equal the time derivative of the expectation value in the Heisenberg picture, i.e.

$$
  \frac{\d}{\d t} {}_\text{H}\braket{\psi|\hat{O}^\text{H} (t)|\psi}_\text{H}
$$

Thus, we obtain the Heisenberg equation of motion

$$
  i\hbar \frac{\d}{\d t} \hat{O}^\text{H} (t) = i\hbar \frac{\partial}{\partial t} \hat{O}^\text{H} (t) + [\hat{O}^\text{H}, \hat{H}]
$$

If the operator $\hat{O}$ does not explicitly depend on time in the Schr√∂dinger picture, this simplifies to

$$
\begin{equation*}
  i\hbar \frac{\d}{\d t} \hat{O}^\text{H} (t) = [\hat{O}^\text{H} (t), \hat{H}]
\tag{\label{equation-104}}
\end{equation*}
$$

which is the Heisenberg equation. This equation shows that an observable that does not explicitly on time and commutes with the Hamiltonian is a conserved quantity, or a constant of motion. 

In Hamiltonian mechanics, an observable function $O(\mathbf{p}(t), \mathbf{x}(t), t)$, satisfies the equation of motion

$$
\begin{align*}
  \frac{\d O}{\d t} =& \nabla_\mathbf{p} H \cdot\nabla_\mathbf{x} O - \nabla_\mathbf{p} O \cdot\nabla_\mathbf{x} H + \frac{\partial O}{\partial t} \\
  =& \{H, O\} + \frac{\partial O}{\partial t}
\end{align*}
$$

If $O$ is time-independent, this reduces to

$$
  \frac{\d O}{\d t} = \{H, O\}
$$

This shows that the Heisenberg equation can be retrived by the substitution

$$
  \{H,O\} \to \frac{1}{i\hbar}[\hat{H},\hat{O}]
$$

This can be seen as a formal rule for transitioning from classical to quantum mechanics. Specifically, in classical mechanics, if the Poisson bracket between a classical variable and the Hamiltonian is zero, this variable is conserved. Similarly, the Heisenberg evolution is formally analogous to classical time evolution. In fact, in classical mechanics, there is no direct analogue to the Schr√∂dinger evolution. More accurately, the classical time evolution coincides with the "Heisenberg evolution" in quantum mechanics, since in classical mechanics, the state is simply a set of properties, and thus it itself can be considered an observable.

In terms of expectation values, the Heisenberg equation of motion becomes

$$
\begin{equation*}
  i\hbar \frac{\d}{\d t} \Braket{\hat{O}^\text{H} (t)} = i\hbar \Braket{\frac{\partial}{\partial t} \hat{O}^\text{H} (t)} + \Braket{[\hat{O}^\text{H}, \hat{H}]}
\tag{\label{equation-105}}
\end{equation*}
$$

### Dirac's interaction picture

Dirac's interaction picture is an intermediate representation between the Heisenberg and Schr√∂dinger pictures, where both the state vectors and the operators carry part of the time dependence of observables. The interaction picture is formed by splitting the Hamiltonian operator in the Schr√∂dinger picture into two contributions

$$
  \hat{H} = \hat{H}_0 + \hat{V}
$$

where $\hat{H}_0$ is the unperturbed Hamiltonian, whose eigenvalues satisfy the time-independent Schr√∂dinger equation, and $\hat{V}$ is a (possibly time-dependent) interaction potential which perturbs these solutions.

To transition to the interaction picture, we remove the time evolution associated with the unperturbed Hamiltionian and the define the transformed state as

$$
\begin{equation*}
  \ket{\psi(t)}_\text{I} = \hat{U}_{H_0, t}^\dagger \ket{\psi(t)}_\text{S}
\tag{\label{equation-100}}
\end{equation*}
$$

where the unitary operator

$$
  \hat{U}_{H_0, t}^\dagger = e^{i\hat{H}_0 t/\hbar}
$$

accounts for the free evolution generated by $\hat{H}_0$. In order to establish the corresponding transformation for observables, we apply $\hat{U}_{H_0, t}^\dagger$ to the expectation value of an arbitrary observable $\hat{Q}$:

$$
\begin{align*}
  {}_\text{S} \braket{\psi(t)|\hat{Q}^\text{S}|\psi(t)}_\text{S} =& {}_\text{I} \braket{\psi(t)|\hat{U}_{H_0, t}^\dagger \hat{Q}^\text{S} \hat{U}_{H_0, t}|\psi(t)}_\text{I} \\
  =& {}_\text{I} \braket{\psi(t)|\hat{Q}^\text{I} (t)|\psi(t)}_\text{I}
\end{align*}
$$

This relation implies that the observable in the interaction picture is obtained from its counterpart in the Schr√∂dinger picture by the unitary transformation

$$
\begin{equation*}
  \hat{Q}^\text{I} (t) = \hat{U}_{H_0, t}^\dagger \hat{Q}^\text{S} \hat{U}_{H_0, t}
\tag{\label{equation-101}}
\end{equation*}
$$

It follows that the free part of the Hamiltonian is invariant under the transformation to the interaction picture, i.e.

$$
  \hat{H}_0^\text{I} = \hat{H}_0^\text{S} = \hat{H}_0
$$

whereas in the Heisenberg picture, the transformation generally modifies $\hat{H}_0^\text{I}$:

$$
  \hat{H}_0^\text{H} = \hat{U}_t^\dagger \hat{H}_0 \hat{U}_t
$$

Differentiating $\eqref{equation-100}$, we obtain the evolution equation for the state in the Dirac picture:

$$
  i\hbar \frac{\d}{\d t} \ket{\psi(t)}_\text{I} = \hat{V}^\text{I} (t) \ket{\psi(t)}_\text{I}
$$

where the interaction Hamiltonian in the interaction picture is given by

$$
  \hat{V}^\text{I} = e^{i\hat{H}_0 t/\hbar} \hat{H}_\text{I} e^{-i\hat{H}_0 t/\hbar}
$$

Similarly, differentiating $\eqref{equation-101}$, we obtain the equation of motion for the observable in the Dirac picture:

$$
  i\hbar \frac{\d}{\d t} \hat{Q}^\text{I} (t) = i\hbar \frac{\partial}{\partial t} \hat{Q}^\text{I} (t) + [\hat{Q}^\text{I} (t), \hat{H}_0]
$$

where the partial time derivative transforms as

$$
  \frac{\partial}{\partial t} \hat{Q}^\text{I} (t) = \hat{U}_{H_0, t}^\dagger \left( \frac{\partial}{\partial t} \hat{Q}^\text{S} \right) \hat{U}_{H_0, t}
$$

#### Perturbed equation of motion

In the interaction picture, state vectors evolve according to

$$
  \ket{\psi (t_b)}_\text{I} = \hat{U}_\text{I} (t_b, t_a) \ket{\psi (t_a)}_\text{I}
$$

where $\hat{U}_\text{I}$ is the time evolution operator given by

$$
\begin{equation*}
  \hat{U}_\text{I} (t_b, t_a) = e^{i\hat{H}_0 t_b /\hbar} e^{-i\hat{H}(t_b - t_a)/\hbar} e^{-i \hat{H}_0 t_a /\hbar}
\tag{\label{equation-10}}
\end{equation*}
$$

If $\hat{V} = 0$, the states $\ket{\psi (t_b)}_\text{I}$ are time-independent and coincide with the Heisenberg states of the operator $\hat{H}_0$. The operator $\hat{U}_\text{I} (t_b, t_a)$ satisfies the equation of motion

$$
  i\hbar\frac{\partial}{\partial t_b} \hat{U}_\text{I} (t_b, t_a) = \hat{V}_\text{I} (t_b) \hat{U}_\text{I} (t_b, t_a)
$$

where $\hat{V}_\text{I} = e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar}$ is the potential in the interaction picture. This differential equation can be turned into an integral equation

$$
\begin{align*}
  \hat{U}_\text{I} (t_b, t_a) =& 1 - \frac{i}{\hbar} \int_{t_a}^{t_b} \hat{V}_\text{I} \hat{U}_\text{I} (t, t_a)\;\d t \\
  =& 1 - \frac{i}{\hbar} \int_{t_a}^{t_b} e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar} \hat{U}_\text{I} (t, t_a)\;\d t
\end{align*}
$$

This equation can be iterated to find a perturbation expansion for the operator $\hat{U}_\text{I} (t_b, t_a)$ in powers of the interaction potential

$$
\begin{align*}
  \hat{U}_\text{I} (t_b, t_a) =& 1 - \frac{i}{\hbar} \int_{t_a}^{t_b} e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar} \\
  &+ \left(-\frac{i}{\hbar}\right)^2 \int_{t_a}^{t_b} \d t \int_{t_a}^t \d t' e^{i\hat{H}_0 t/\hbar}\hat{V}e^{-i\hat{H}_0 (t - t')/\hbar} \hat{V} e^{-i\hat{H}_0 t'/\hbar} + \cdots
\end{align*}
$$

Inserting $\eqref{equation-10}$ on the left-hand side and multiplying the equation from the left by $e^{-i\hat{H}_0 t_b/\hbar}$ and from the right by $e^{i\hat{H}_0 t_a/\hbar}$, this can be rewritten as

$$
\begin{align*}
  e^{-i\hat{H}_0 (t_b - t_a)/\hbar} =& e^{-i\hat{H}_0 (t_b - t_a)/\hbar} - \frac{i}{\hbar}\int_{t_a}^{t_b} \d t e^{-i\hat{H}_0 (t_b - t)/\hbar} \hat{V} e^{-i\hat{H}_0 (t-t_a)/\hbar} \\
  &+ \left(-\frac{i}{\hbar}\right)^2 \int_{t_a}^{t_b} \d t \int_{t_a}^t \d t' e^{i\hat{H}_0 (t_b - t)/\hbar}\hat{V}e^{-i\hat{H}_0 (t - t')/\hbar} \hat{V} e^{-i\hat{H}_0 (t' - t_a)/\hbar} + \cdots
\end{align*}
$$

This expansion is recognized as the recursive solution of the integral equation

$$
  e^{-i\hat{H}_0 (t_b - t_a)/\hbar} = e^{-i\hat{H}_0 (t_b - t_a)/\hbar} - \frac{i}{\hbar}\int_{t_a}^{t_b} e^{-i\hat{H}_0 (t_b - t)/\hbar} \hat{V} e^{-i\hat{H}_0 (t-t_a)/\hbar} \;\d t
$$

In terms of a time-ordering operator $\hat{T}$, the expansion can also be written as

$$
  e^{-i\hat{H}_0 (t_b - t_a)/\hbar} = e^{-i\hat{H}_0 t_b/\hbar} \hat{T} \exp\left(-\frac{i}{\hbar} \int_{t_a}^{t_b} e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar}\;\d t\right)e^{i\hat{H}t_a/\hbar}
$$

which can be represented as a mathematical operator formula

$$
  e^{T(\hat{A} + \hat{B})} = \hat{T}\exp\left(\int_0^T e^{(T - t)\hat{A}} \hat{B} e^{t\hat{A}} \; \d t \right) = e^{T\hat{A}}\hat{T} \exp\left(\int_0^T e^{-t\hat{A}} \hat{B} e^{t\hat{A}} \;\d t \right)
$$

Due to the time-ordering operator, the right-hand side cannot be evaluated using Lie's expansion formula (Hadamard's lemma). Instead, the proper formulation requires the use Campbell-Baker-Hausdorff expansion.

## Time-derivatives of observables

The most natural way to define the time derivative $\hat{\dot{Q}}$ of a quantum mechanical observable $\hat{Q}$ in the Schr√∂dinger picture is to assume that its expectation value $\braket{\hat{\dot{Q}}}$ is equal to the time derivative of the expectation value of $\hat{Q}$, i.e.

$$
  {}_\text{S} \braket{\psi|\hat{\dot{Q}}^\text{S}|\psi}_\text{S} = \frac{\d}{\d t} \left({}_\text{S} \braket{\psi|\hat{Q}^\text{S}|\psi}_\text{S} \right)
$$

Appying the Schr√∂dinger equation and its Hermitian adjoint to the right-hand side, we obtain

$$
\begin{align*}
  \frac{\d}{\d t} \left({}_\text{S} \braket{\psi|\hat{Q}^\text{S}|\psi}_\text{S} \right) =& {}_\text{S} \Braket{\psi|\left(\frac{i}{\hbar} \hat{H}\hat{Q}^\text{S} - \frac{i}{\hbar} \hat{Q}^\text{S} \hat{H} + \frac{\partial}{\partial t} \hat{Q}^\text{S} \right)|\psi} \\
  =& {}_\text{S} \Braket{\psi|\left(\frac{i}{\hbar}[\hat{H}, \hat{Q}] + \frac{\partial}{\partial t} \hat{Q}^\text{S} \right)|\psi}
\end{align*}
$$

Hence,

$$
\begin{equation*}
  \braket{\hat{\dot{Q}}} = \frac{i}{\hbar} \braket{[\hat{H},\hat{Q}]} + \Braket{\frac{\partial}{\partial t} \hat{Q}}
\tag{\label{equation-81}}
\end{equation*}
$$

which is known as Ehrenfest's theorem.

## Density operator

In the most general sense, quantum systems can exist in mixed states, which include pure states as a special case. A quantum system is described by a mixed state when it is in one of a set of possible states $\set{\ket{\psi_j}}$, each occuring with probability $p_j$. Unlike a pure state, which represents a coherent quantum superposition, a mixed state represents a statistical ensemble of quantum states. This contrasts with a pure state $\ket{\psi} = \sum_j \sqrt{p_j} \ket{\psi_j}$, where the quantum system exists in a coherent superposition of the $\ket{\psi_j}$. In this case, the system is described entirely by $\ket{\psi}$, rather than by a statistical mixture of the $\ket{\psi_j}$.

A mixed state is represented by a density operator (or density matrix) $\hat{\rho}$ on a Hilbert space $\mathcal{H}$, which satisfies the properties
1. **Hermiticity:** $\hat{\rho}^\dagger = \hat{\rho}$
2. **Positive semidefiniteness:** $\braket{\psi|\hat{\rho}|\psi} \geq 0$ for all $\ket{\psi}\in\mathcal{H}$
3. **Unit trace:** $\operatorname{tr}(\hat{\rho}) = 1$

The set of all density operators on $\mathcal{H}$ is denoted $\mathcal{D}(\mathcal{H})$, that is

$$
  \mathcal{D}(\mathcal{H}) := \set{\hat{\rho}\in\mathcal{L}(\mathcal{H}) | \hat{\rho}^\dagger = \hat{\rho}, \hat{\rho}\geq 0, \operatorname{tr}(\hat{\rho}) = 1}
$$

and is a convex set.

<details>
<summary>Details</summary>


Convexity of $\mathcal{D}(\mathcal{H})$ means that for every $\hat{\rho}_1, \hat{\rho}_2 \in\mathcal{D}(\mathcal{H})$ and $u\in[0,1]\subset\R$, we have

$$
  u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \in \mathcal{D}(\mathcal{H})
$$

Since $\hat{\rho}_1$ and $\hat{\rho}_2$ are Hermitian it follows that

$$
  \left(u\hat{\rho}_1 + (1 - u)\hat{\rho}\right)^\dagger = u\hat{\rho}_1^\dagger + (1 - u)\hat{\rho}_2^\dagger = u\hat{\rho}_1 + (1 - u)\hat{\rho}_2
$$

Since $\hat{\rho}_1$ and $\hat{\rho}_2$ are positive semi-definite, it follows that for every $\ket{\psi}\in\mathcal{H}$

$$
  \braket{\psi|u\hat{\rho}_1 + (1 - u)\hat{\rho}_2|\psi} = u\underbrace{\braket{\psi|\hat{\rho}_1|\psi}}_{\geq 0} + (1 - u)\underbrace{\braket{\psi|\hat{\rho}_2|\psi}} \geq 0 
$$

Since $\hat{\rho}_1$ and $\hat{\rho}_2$ have unit trace, it follows that

$$
  \operatorname{tr}\left(u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \right) = u\underbrace{\operatorname{tr}(\hat{\rho}_1)}_{=1} + (1- u) \underbrace{\boldsymbol{tr}(\hat{\rho}_2)}_{=1} = 1
$$

This verifies that $u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \in \mathcal{D}(\mathcal{H})$.
</details>

If $\hat{U}\in\mathcal{U}(\mathcal{H})$ is a unitary operator, then $\hat{U}\hat{\rho}\hat{U}\in\mathcal{D}(\mathcal{H})$ is a density operator.

<details>
<summary>Proof</summary>

Since $\hat{\rho}^\dagger = \hat{\rho}$, we have

$$
  (\hat{U}\hat{\rho}\hat{U}^\dagger)^\dagger = (\hat{U}^\dagger)^\dagger \hat{\rho}^\dagger \hat{U}^\dagger = \hat{U}\hat{\rho}\hat{U}
$$

Since $\braket{\psi|\hat{\rho}|\psi} \geq 0$, we have

$$
  \braket{\psi|\hat{U}\hat{\rho}\hat{U}^\dagger|\psi} = \braket{\hat{U}^\dagger \psi|\hat{\rho}\hat{U}^\dagger \psi} \geq 0
$$

Since $\operatorname{tr}(\hat{\rho}) = 1$ and using the commutativity of trace, we have

$$
  \operatorname{tr}(\hat{U}\hat{\rho}\hat{U}^\dagger) = \operatorname{tr}(\hat{U}^\dagger \hat{U} \rho) = \operatorname{tr}(\hat{\rho}) = 1
$$

Hence, $\hat{U}\hat{\rho}\hat{U}^\dagger \in\mathcal{D}(\mathcal{H})$.
</details>

Let $\set{\ket{\psi_j}}$ be an orthonormal basis of a Hilbert space $\mathcal{H}$. Since a density operator $\rho$ is Hermitian, it admits a diagonal spectral decomposition

$$
  \hat{\rho} = \sum_j p_j \ket{\psi_j} \bra{\psi_j} = \sum_j p_j \hat{P}_{\psi_j}
$$

where $p_j$ are the eigenvalues of $\hat{\rho}$ and $\hat{P}_{\psi_j}$ are the associated rank-one projectors. The density operator satisfies:
1. **Probability conditions:** $p_j \geq 0$ and $\sum_j p_j = 1$
2. **Positivity constraint:** $0 \leq \hat{\rho}^2 \leq \hat{\rho}$
3. **Operator norm bound:** $\norm{\rho}\leq 1$

<details>
<summary>Proof</summary>

**(1):** Since $\hat{\rho}$ is Hermitian, its eigenvalues $p_j$ are real. By the positivity of $\hat{\rho}$, we have for any $\ket{\psi}\in\mathcal{H}$

$$
  0 \leq \braket{\psi|\hat{\rho}|\psi} = \sum_j p_j \braket{\psi|\psi_j} \braket{\psi_j|\psi} = \sum_j p_j |\braket{\psi_j|\psi}|^2
$$

Since $\operatorname{tr}(\rho) = 1$, we have

$$
\begin{align*}
  1 =& \operatorname{tr}(\hat{\rho}) = \sum_k \braket{\psi_k|\hat{\rho}|\psi_k} \\
  =& \sum_{k,j} p_j \underbrace{\braket{\psi_k|\psi_j}}_{=\delta_{kj}} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \\
  =& \sum_k p_k
\end{align*}
$$

**(2):** The positivity of $\hat{\rho}^2$ follows from the fact that for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \braket{\psi|\hat{\rho}^2|\psi} =& \braket{\hat{\rho}^\dagger \psi|\hat{\rho} \psi} \\
  =& \braket{\hat{\rho}\psi|\hat{\rho}\psi} = \norm{\hat{\rho}\ket{\psi}}^2 \geq 0
\end{align*}
$$

Since $0 \leq p_j \leq 1$, it follows that $p_j^2 \leq p_j$ and

$$
\begin{align*}
  \hat{\rho}^2 =& \left(\sum_j p_j \ket{\psi_j} \bra{\psi_j} \right)^2 \\
  =& \sum_{j,k} p_j p_k \ket{\psi_j} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \bra{\psi_k} \\
  =& \sum_j p_j^2 \ket{\psi_j} \bra{\psi_j}
\end{align*}
$$

and thus for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \braket{\psi|\hat{\rho} - \hat{\rho}^2|\psi} =& \bra{\psi} \sum_j (p_j - p_j^2) \ket{\psi_j}\braket{\psi_j|\psi} \\
  =& \sum_j (p_j - p_j^2) \braket{\psi|\psi_j}\braket{\psi_j|\psi} \\
  =& \sum_j \underbrace{(p_j - p_j^2)}_{\geq 0} \underbrace{|\braket{\psi_j|\psi}|^2}_{\geq 0} \geq 0
\end{align*}
$$

Hence, $0 \leq \hat{\rho}^2 \leq \rho$.

**(3):** From **(2)** it follows that

$$
\begin{align*}
  \norm{\hat{\rho}}^2 =& \braket{\hat{\rho}|\hat{\rho}} = \braket{\hat{\rho}^\dagger \psi|\hat{\rho}\psi} \\
  =& \braket{\psi|\hat{\rho}^2|\psi} = \braket{\psi|\hat{\rho}|\psi} \\
  \leq& \norm{\psi}\cdot\norm{\hat{\rho} \psi}
\end{align*}
$$

which implies

$$
  \frac{\norm{\hat{\rho}\ket{\psi}}}{\norm{\psi}} \leq 1 \implies \norm{\hat{\rho}} \leq 1
$$
</details>

If $\set{\ket{\psi_j}}_j$ is an orthonormal basis on $\mathcal{H}$, the density matrix is defined as

$$
\begin{align*}
  \hat{\rho} =& \sum_j \sum_k \ket{\psi_j}\braket{\psi_j|\hat{\rho}|\psi_k}\bra{\psi_k} \\
  =& \sum_{j,k} \boldsymbol{\rho}_{jk} \ket{\psi_j}\bra{\psi_k}
\end{align*}
$$

where $\boldsymbol{\rho}_{jk} = \braket{\psi_j|\hat{\rho}|\psi_k}$ are the matrix elements of $\hat{\rho}$. This definition utilizes the fact that

$$
  \sum_j \ket{\psi_j}\bra{\psi_k} = \hat{I} \left(\sum_k \ket{\psi_k}\bra{\psi_k} \right)
$$

In a mixture described by $\hat{\rho} = \sum_j p_j \ket{\psi_j} \bra{\psi_j}$ the relative phases of the $\ket{\psi_j}$ are not physically observable. This is because for $\phi_j \in\R$, we have

$$
\begin{align*}
  \sum_j p_j \ket{e^{i\phi_j} \psi_j} \bra{e^{i\phi_j} \psi_j} =& \sum_j p_j e^{-i\phi_j} e^{i\phi_j} \ket{\psi_j} \bra{\psi_j} \\
  =& \sum_j p_j \ket{\psi_j} \bra{\psi_j} = \hat{\rho}
\end{align*}
$$

showing that the states $e^{i\phi_j} \ket{\psi_j}$ generate the same mixture as the $\ket{\phi_j}$.

<MathBox title='' boxType='proposition'>
Let $\mathcal{H}$ be a finite-dimensional Hilbert space and $\hat{\rho}\in\mathcal{D}(\mathcal{H})$ be a density operator with diagonal form

$$
  \hat{\rho} = \sum_{i=1}^n p_j \ket{\psi_j} \bra{\psi_j}
$$

where $p_j \in (0,1]$ for $j\in\set{1,\dots,n}$ with $n \leq \dim(\mathcal{H})$ are the nonzero eigenvalues of $\hat{\rho}$ and $\set{\ket{\psi_j}}_{j=1}^{\dim(\mathcal{H})}$ is an orthonormal eigenbasis. For $m\leq\dim(\mathcal{H})$, suppose we have normalized states $\set{\ket{\varphi_i}}_{i=1}^m \subset\mathcal{H}$ and probabilities $q_i \in (0,1]$ such that $\sum_{j=1}^m q_i = 1$. Then,

$$
  \hat{\rho} = \sum_{j=1}^m q_i \ket{\varphi_i} \bra{\varphi_i}
$$

if and only if $m \geq n$ and there is a unitary matrix $\mathbf{U} \in\mathrm{U}(m)$ such that

$$
  \sqrt{q_i} \ket{\varphi_i} = \sum_{j=1}^n \mathbf{U}_{ij} \sqrt{p_j} \ket{\psi_j}, \; i \in\set{1,\dots,m}
$$

<details>
<summary>Proof</summary>

**($\implies$):**

Since $\set{\ket{\psi_j}}_{j=1}^n$ is an orthonormal eigenbasis, the range of $\hat{\rho}$ has dimension

$$
  \dim[\operatorname{ran}(\hat{\rho})] = \dim\left(\operatorname{span}\set{ket{\psi_j}}_{j=1}^n \right) = n
$$

On the other hand, $\hat{\rho}[\mathcal{H}] \subseteq \operatorname{span}\set{\ket{\psi_i}}_{i=1}^m$ such that

$$
  \dim[\operatorname{ran}(\hat{\rho})] \leq \dim\left(\operatorname{span}\set{ket{\varphi_i}}_{i=1}^n \right) \leq m
$$

and it follows that $n \leq m$. By assumption, the eigenvectors of $\hat{\rho}$ for the eigenvalue $0$ are given by $\ket{\psi_k}$, where $k \in \set{n+1,\dots,\dim(\mathcal{H})}$. They satisfy

$$
  0 = \braket{\psi_k | \psi_k} = \sum_{i=1}^m q_i |\braket{\psi_k|\varphi_i}|^2
$$

which implies $\braket{\psi_k|\varphi_i} = 0$ for all $k\in\set{n+1,\dots,\dim(\mathcal{H})}$ and $i\in\set{1,\dots,m}$. We can thus expand $\ket{\varphi_i}$ as

$$
  \ket{\varphi_i} = \sum_{k=1}^{\dim(\mathcal{H})} \braket{\psi_k|\varphi_i} \ket{\psi_k} = \sum_{k=1}^n \braket{\psi_k | \varphi_i} \ket{\psi_k}
$$

Since $\hat{\rho}$ is unchanged under either decomposition, we must have

$$
  \sum_{j=1}^n p_j \ket{\varphi_j} \bra{\varphi_j} = \sum_{i=1}^m q_i \ket{\varphi_i} \bra{\varphi_i}
$$

Next, we define the $m\times n$ matrix $\mathbf{V}\in\mathcal{M}_{m,n} (\mathbf{C})$ by

$$
  \mathbf{V}_{ij} = \sqrt{\frac{q_i}{p_j}} \braket{\psi_j|\varphi_i}
$$

for $i\in\set{1,\dots,m}$ and $j\in\set{1,\dots,n}$ such that

$$
  \sum_{j=1}^n \mathbf{V}_{ij} \sqrt{p_j} \ket{\psi_j} = \sum_{j=1}^n \sqrt{q_i} \braket{\psi_j|\varphi_i} \ket{\psi_j} = \sqrt{q_i} \ket{\varphi_i}
$$

We proceed to show that we can extend $\mathbf{V}\in\mathcal{M}_{m,n} (\mathbb{C})$ to a unitary $m\times m$ matrix $\mathbf{U}$. For this, we first note that

$$
  \mathbf{V}_{ji}^\dagger = \mathbf{V}_{ij}^* = \sqrt{\frac{q_i}{p_j}} \braket{\psi_j|\varphi_i}^* = \sqrt{\frac{q_i}{p_j}} \braket{\varphi_i|\psi_j}
$$

and thus for $i,j\in\set{1,\dots,n}$

$$
\begin{align*}
  \sum_{i=1}^m \mathbf{V}_{ji}^\dagger \mathbf{V}_{ik} =& \frac{1}{\sqrt{p_j p_k}} \sum_{i=1}^m q_i \braket{\psi_j|\varphi_i} \braket{\varphi_i|\psi_k} \\
  =& \frac{1}{\sqrt{p_j p_k}} \braket{\psi_j |\hat{\rho}|\psi_k} \\
  =& \frac{1}{\sqrt{p_j p_k}} \bra{\psi_j} \sum_{l=1}^n p_l \ket{\psi_l} \braket{\psi_l|\psi_k} \\
  =& \sum_{l=1}^n \frac{p_l \delta_{jl} \delta_{lk}}{\sqrt{p_j p_k}} = \delta_{jk}
\end{align*}
$$

We have specified $\mathbf{V} \in\mathcal{M}_{m,n} (\mathbb{C})$, where $n\leq m$, such that $\mathbf{V}^\dagger \mathbf{V} = \mathbf{I}_n$. This means that the $n$ column vectors of $\mathbf{V}$ viewed as vectors in $\mathbb{C}^m$ are mutually orthogonal and normalized to $1$. Applying the Gram-Schmidt orthogonalization procedure, we can add $m - n$ orthonormal columns vectors such that all $m$ column vectors of the resulting $m\times m$ matrix $\mathbf{U}$ form a basis in $\mathbb{C}^m$. By this procedure, we extend $\mathbf{V}$ to form a unitary matrix $\mathbf{U} \in\mathrm{U}(m)$ such that $\mathbf{U}_{ij} = \mathbf{V}_{ij}$ for $j\in\set{1,\dots,n}$.

**($\impliedby$):**

Let $m \geq n$ and $\mathbf{U} \in\mathrm{U}(m)$ be a unitary matrix such that for $j\in\set{1,\dots,m}$

$$
  \sqrt{q_i} \ket{\varphi_i} = \sum_{j=1}^n \mathbf{U}_{ij} \sqrt{p_j} \ket{\psi_j}
$$

This implies

$$
\begin{align*}
  \sum_{i=1}^m q_i \ket{\varphi_i} \bra{\varphi_i} =& \sum_{j=1}^m q_i \left(\frac{1}{\sqrt{q_i}} \sum_{j=1}^n \mathbf{U}_{ij} \sqrt{p_j} \ket{\psi_j} \right) \left(\frac{1}{\sqrt{q_i}} \sum_{k=1}^n \mathbf{U}_{ik}^* \sqrt{p_k} \ket{\psi_k} \right) \\
  =& \sum_{j,k=1}^n \sqrt{p_j p_k} \left(\sum_{i=1}^m \mathbf{U}_{ki}^\dagger \mathbf{U}_{ij} \right) \ket{\psi_j} \bra{\psi_k} \\
  =& \sum_{j,k=1}^n \sqrt{p_j p_k} \underbrace{(\mathbf{U}^\dagger \mathbf{U})_{ij}}_{=\delta_{ij}} \ket{\psi_j} \bra{\psi_k} \\
  =& \sum_{j=1}^n p_j \ket{\psi_j} \bra{\psi_j} = \hat{\rho}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Qubit' boxType='example'>
A two-state quantum system is known as a qubit. It is represented by a two-dimensional Hilbert space. An arbitrary mixed state for a qubit can be written as a linear combination

$$
  \rho = \frac{1}{2} \begin{bmatrix} 
    1 + r_z & r_x - i r_y \\
    r_x + i r_y & 1 - r_z 
  \end{bmatrix} = \frac{1}{2} (1 + \mathbf{r}\cdot\boldsymbol{\sigma})
$$

where $\mathbf{r} = (r_x, r_y, r_z)$ is a Bloch vector and $\boldsymbol{\sigma}$ are the Pauli matrices. The density matrix $\rho$ represents a pure state if and only if $\rVert\mathbf{r}\rVert = 1$. For a mixed state we have $\norm{\mathbf{r}} < 1$.

<details>
<summary>Proof</summary>

Since $\rho\in\mathcal{M}_2 (\mathbb{C})$ is a complex $2\times 2$ matrix, it can be written as a linear combination

$$
\begin{align*}
  \rho =& c_0 I_2 + c_x \sigma_x + c_y \sigma_y + c_z \sigma_z = c_0 I_2 + \mathbf{c}\cdot\boldsymbol{\sigma} \\
  =& \begin{bmatrix}
    c_0 + c_z & c_x - i c_y \\
    c_x + i c_y & c_0 - c_z
  \end{bmatrix}
\end{align*}
$$

By Hermiticity, the diagonal elements of $\rho$ are real, while the off-diagonal elements are complex conjugates. Since $\operatorname{tr}(\rho) = 1$, it follows that

$$
  1 = (c_0 + c_z) + (c_0 + c_z) = 2c_0 \iff c_0 = \frac{1}{2}
$$

Since $\rho$ is semi-definite, its determinant is positive 

$$
  \det(\rho) = c_0^2 - c_z^2 - |c_x + ic_y|^2 = c_0^2 - c_x^2 - c_y^2 - c_z^2 \geq 0
$$

This implies that

$$
  \norm{ \mathbf{c} } \leq |c_0| = \frac{1}{2}
$$

Writing $\mathbf{r} = \frac{1}{2}\mathbf{c}$, we get that

$$
  \rho = \frac{1}{2} (I_2 + \mathbf{r}\cdot\boldsymbol{\sigma})
$$

with $\norm{ \mathbf{r} } \leq 1$.

If $\rho$ describes a pure state, then $\rho^2 = \rho$. Calculating $\rho^2$ yields

$$
\begin{align*}
  \rho^2 =& \frac{1}{4}[I_2 + 2\mathbf{r}\cdot\boldsymbol{\sigma} + (\mathbf{r}\cdot\boldsymbol{\sigma})^2] \\
  =& \frac{1}{4}(I_2 + 2\mathbf{r}\cdot\boldsymbol{\sigma} + \mathbf{r}^2 I_2) \\
  =& \frac{1}{4}[(1 + \mathbf{r}^2) I_2 + 2\mathbf{r}\cdot\boldsymbol{\sigma}] \\
\end{align*}
$$

where we have used the fact that $\sigma_i \sigma_j = \delta_{ij} I_2 + i\epsilon_{ijk} \sigma_k$. We see that $\rho^2 = \rho$ if and only if $\mathbf{r}^2 = \norm{\mathbf{r}}^2 = 1$.
</details>
</MathBox>

### Density operator for pure states

A pure state $\ket{\psi}\in\mathcal{H}$ can be represented by the rank-one projector $\hat{P}_\psi = \ket{\psi}\bra{\psi}$. Since $\operatorname{tr}(\hat{P}_\psi) = 1$ and $\hat{P}_\psi^2 = \hat{P}_\psi$, pure states can be viewed as a special case of mixed states with density operator

$$
  \hat{\rho}_\psi := \hat{P}_\psi = \ket{\psi}\bra{\psi}
$$

Thus, the density operator formalism generalizes the description of quantum states, encompassing both pure states and statistical mixtures.

<details>
<summary>Details</summary>

To show that the density operator for a pure state $\ket{\psi}\in\mathcal{H}$ given by $\rho_\psi = \ket{\psi}\bra{\psi}$ satisfies the quantum postulates for mixed states, we verify the following properties.

**Expectation value**

Consider an observable $A$ with spectral decomposition

$$
  \hat{A} = \sum_j \lambda_j \ket{e_j} \bra{e_j} 
$$

where $\set{\lambda}_j$ are the eigenvalues of $\hat{A}$ and $\set{\ket{e_j}}$ is an orthonormal basis of $\mathcal{H}$. The expectation value of $\hat{A}$ in the state $\hat{\rho}_\psi$ is

$$
\begin{align*}
  \braket{A}_{\rho_\psi} =& \operatorname{tr}(\rho_\psi \hat{A}) = \operatorname{tr}(\ket{\psi}\braket{\psi|\hat{A}}) \\
  =& \operatorname{tr}\left(\ket{\psi}\bra{\psi} \sum_j \lambda_j \ket{e_j} \bra{e_j} \right) \\
  =& \sum_j \lambda_j \operatorname{tr}(\ket{\psi}\braket{\psi|e_j}\bra{e_j}) \\
  =& \sum_{j,k} \lambda_j \braket{e_j|\psi}\braket{\psi|e_j}\underbrace{\braket{e_j|e_k}}_{=\delta_{jk}} \\
  =& \sum_j \lambda_j \braket{\psi|e_j} \braket{e_j|\psi} \\
  =& \braket{\psi} \sum_j \lambda_j \ket{e_j} \braket{e_j|\psi} \\
  =& \braket{\psi|\hat{A}|\psi} = \braket{\hat{A}}_\psi
\end{align*}
$$

**Measurement probability**

The probability of measuring an eigenvalue $\lambda$ associated with the projector $\hat{P}_\lambda$ is given by

$$
\begin{align*}
  \Pr_{\rho_\psi} (\lambda) =& \operatorname{tr}(\hat{\rho}\hat{P}_\lambda) = \operatorname{tr}(\ket{\psi}\bra{\psi}\hat{P}_\lambda) \\
  =& \operatorname{tr}(\ket{\psi}\bra{\psi}\hat{P}_\lambda^2) = \operatorname{tr}(\hat{P}_\lambda \ket{\psi}\braket{\psi|\hat{P}_\lambda}) \\
  =& \sum_j \braket{e_j|\hat{P}_\lambda|\psi} \braket{\psi|\hat{P}_\lambda|e_k} \\
  =& \sum_j \braket{e_j|\hat{P}_\lambda|\psi} \braket{\hat{P}_\lambda \psi|e_j} \\
  =& \braket{\hat{P}_\lambda \psi} \underbrace{\sum_j \ket{e_j} \braket{e_j|\hat{P}_\lambda|\psi}}_{=\hat{P}_\lambda \ket{\psi}} \\
  =& \braket{\hat{P}_\lambda \psi| \hat{P}_\lambda \psi} = \norm{\hat{P}_\lambda \ket{\psi}}^2 = \Pr_\psi (\lambda) 
\end{align*}
$$

**Projection**

If a measurement of an observable $A$ yields the eigenvalue $\lambda$, the post-measurement state is given by the normalized projection of $\rho_\psi$:

$$
\begin{align*}
  \frac{\hat{P}_\lambda \hat{\rho}_\psi \hat{P}_\lambda}{\operatorname{tr}(\hat{\rho}_\psi \hat{P}_\lambda)} =& \frac{\hat{P}_\lambda \ket{\psi}\bra{\psi} \hat{P}_\lambda}{\norm{\hat{P}_\lambda \ket{\psi}}^2} = \frac{\hat{P}_\lambda \ket{\psi}\bra{\psi} \hat{P}_\lambda^\dagger}{\norm{\hat{P}_\lambda \ket{\psi}}^2} \\
  =& \frac{\hat{P}_\lambda \ket{\psi} \bra{\hat{P}_\lambda \psi}}{\norm{\hat{P}_\lambda \ket{\psi}}^2} = \frac{\hat{P}_\lambda \ket{\psi}}{\norm{\hat{P}_\lambda \ket{\psi}}} \frac{\bra{\hat{P}_\lambda \psi}}{\norm{\hat{P}_\lambda \ket{\psi}}} \\
  =& \hat{\rho}_{\hat{P}_\lambda \ket{\psi} / \norm{\hat{P}_\lambda \ket{\psi}}}
\end{align*}
$$

Thus, $\frac{\hat{P}_\lambda \hat{\rho}_\psi \hat{P}_\lambda}{\operatorname{tr}(\hat{\rho}_\psi \hat{P}_\lambda)}$ os the density operator of the pure state $\hat{\rho}_{\hat{P}_\lambda \ket{\psi} / \norm{\hat{P}_\lambda \ket{\psi}}}$.

**Time evolution**

Let $\hat{\rho} (t_0) = \rho_{\psi(t_0)} = \ket{\psi(t_0)}\bra{\psi(t_0)}$ be the initial state and $\hat{\rho}(t)$ be the state at time $t$. If the system evolves unitarily under a propagator $\hat{U} (t, t_0)$, the time evolution of $\hat{\rho}$ is

$$
\begin{align*}
  \hat{\rho}(t) =& \hat{U}(t, t_0) \hat{\rho} (t_0) \hat{U}^\dagger (t, t_0) \\
  =& \hat{U}(t, t_0) \ket{\psi(t_0)} \bra{\psi(t_0)} \hat{U}^\dagger (t, t_0) \\
  =& \ket{\hat{U}(t, t_0) \psi(t_0)} \bra{\hat{U}(t, t_0) \psi(t_0)} \\
  =& \hat{\rho}_{\hat{U}(t, t_0)\ket{\psi(t_0)}} \\
  =& \rho_\psi (t)
\end{align*}
$$
</details>

A density operator $\hat{\rho}$ describes a pure state if and only it is a projector, i.e. $\hat{\rho}^2 = \hat{\rho} = \ket{\psi}\bra{\psi}$ for some normalized $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$.

<details>
<summary>Proof</summary>

**($\implies$): If $\hat{\rho}$ describes a pure state, then $\hat{\rho}^2 = \hat{\rho}$**

By definition, a pure state is represented by a rank-one density operator $\hat{\rho} = \ket{\psi}\bra{\psi}$ for $\ket{\psi}\in\mathcal{H}$. If $\set{\ket{e_j}}$ is an orthonormal basis of $\mathcal{H}$, then since $\operatorname{tr}(\hat{\rho}) = 1$, we have

$$
\begin{align*}
  1 =& \operatorname{tr}(\hat{\rho}) = \operatorname{tr}(\ket{\psi}\bra{\psi}) \\
  =& \sum_j |\braket{e_j|\psi}|^2 = \norm{\psi}^2
\end{align*}
$$

verifying that $\ket{\psi}$ is normalized. It follows that

$$
  \hat{\rho}^2 = \ket{\psi}\underbrace{\braket{\psi|\psi}}_{=\norm{\psi}^2}\bra{\psi} = \ket{\psi}\bra{\psi} = \hat{\rho}
$$

**($\impliedby$): If $\hat{\rho}$ satisfies $\hat{\rho}^2 = \hat{\rho}$, it is a pure state**

Since $\hat{\rho}$ is a density operator, it admits a spectral decomposition in an orthonormal basis $\set{\ket{\psi_j}}$

$$
  \hat{\rho} = \sum_j p_j \ket{\psi_j} \bra{\psi_j}
$$

where $p_j \geq 0$ are real eigenvalues summing to $1$. Calculating $\hat{\rho}^2$, we obtain

$$
\begin{align*}
  \hat{\rho}^2 =& \left(\sum_j p_j \ket{\psi_j} \bra{\psi_j} \right) \left(\sum_k p_k \ket{\psi_k} \bra{\psi_k} \right) \\
  =& \sum_{j,k} p_j p_k \ket{\psi_j} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \bra{\psi_k} \\
  =& \sum_j p_j^2 \ket{\psi_j} \bra{\psi_j} 
\end{align*}
$$

Using idempotency, $\hat{\rho}^2 = \hat{\rho}$, we find that $p_j^2 = p_j$. Taking the expectation of $\hat{\rho}^2 - \hat{\rho}$ in $\ket{\psi_k} \in\mathcal{H}$, we get

$$
\begin{align*}
  0 =& \braket{\psi_k|\hat{\rho}^2 - \hat{\rho}|\psi_k} \\
  =& \bra{\psi_k} \sum_j (p_j^2 - p_j) \ket{\psi_j} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \\
  =& p_k^2 - p_k = p_k (p_k - 1)
\end{align*}
$$

Consequently, $p_j = 1$ or $p_j = 0$ for each $j$. Since $\sum_j p_j = 1$, exactly one $p_j$ is equal to $1$, while all others are $0$. If $\check{\jmath}$ is the index where $p_j = 1$, then

$$
  \hat{\rho} = \ket{\psi_{\check{\jmath}}}\bra{\psi_{\check{\jmath}}}
$$

describes a pure state.
</details>

A density operator $\hat{\rho}$ describe a true mixture if and only if $\hat{\rho}^2 < \hat{\rho}$. This means that mixed states satisfy $\hat{\rho}^2 \neq \hat{\rho}$.

<details>
<summary>Proof</summary>

We prove the statement by contraposition, showing that $\hat{\rho}^2 = \hat{\rho}$ if and only if there exists $\ket{\psi}\in\mathcal{H}$ such that for every Hermitian operator $\hat{A}\in\mathcal{B}(\mathcal{H})$, we have $\braket{A}_\psi = \braket{A}_\rho$. 

**($\implies$): If $\hat{\rho}^2 = \hat{\rho}$, then $\hat{\rho}$ represents a pure state**

Consider an orthonormal basis $\set{\ket{e_j}}$ in $\mathcal{H}$ and let $\ket{\psi}\in\mathcal{H}$ be such that $\hat{\rho} = \ket{\psi}\bra{\psi}$. Expanding $\ket{\psi}$ as

$$
  \ket{\psi} = \sum_j \ket{e_j} \braket{e_j|\psi}
$$

the expectation value of an Hermitian operator $\mathcal{A}\in\mathcal{B}(\mathcal{H})$ is

$$
\begin{align*}
  \braket{A}_\rho =& \operatorname{tr}(\hat{\rho}\hat{A}) = \sum_j \braket{e_j}\ket{\psi}\braket{\psi|\hat{A}|e_j} \\
  =& \Braket{\psi|\hat{A}| \sum_j \braket{e_j|\psi} e_j} = \braket{\psi|\hat{A}|\psi} \\
  =& \braket{A}_\psi
\end{align*}
$$

Hence, $\hat{\rho}$ is indistinguishable from the pure state $\ket{\psi}$.

**($\impliedby$): If $\braket{A}_\rho = \braket{A}_\psi$, then $\hat{\rho}^2 = \hat{\rho}$**

Suppose $\hat{\rho}$ has the form

$$
  \hat{\rho} = \sum_{j_1, j_2} \rho_{j_1 j_2} \ket{e_{j_1}} \bra{e_{j_2}}
$$

If there exists a state $\ket{\psi} = \sum_j \psi_j \ket{e_j}\in\mathcal{H}$ is such that $\braket{A}_\rho = \braket{A}_\psi$ for all Hermitian operators $\hat{A}\in\mathcal{B}(\mathcal{H})$, then

$$
\begin{align*}
  \braket{A}_\rho =& \operatorname{tr}(\hat{\rho}\hat{A}) = \sum_j \braket{e_j|\hat{\rho}\hat{A}|e_j} \\
  =& \sum_j \ket{e_j} \sum_{j_1, j_2} \rho_{j_1, j_2} \ket{e_{j_1}} \braket{e_{j_2} |\hat{A}| e_{j_1}} \\
  =& \sum_{j_1, j_2} \hat{\rho}_{j_1, j_2} \sum_j \underbrace{\braket{e_j | e_{j_1}}}_{\delta_{j j_1}} A_{j_2 j} \\
  =& \sum_{j_1, j_2} \rho_{j_1, j_2} A_{j_2 j_1}
\end{align*}
$$

and

$$
\begin{align*}
  \braket{A}_\psi =& \braket{\psi|\hat{A}|\psi} = \Braket{\sum_{j_2} \psi_{j_2} e_{j_2}|\hat{A}| \sum_{j_1} \psi_{j_1} e_{j_1}} \\
  =& \sum_{j_1, j_2} \psi_{j_2}^* \psi_{j_1} \braket{e_{j_2}|\hat{A}|e_{j_1}} \\
  =& \sum_{j_1, j_2} \psi_{j_2}^* \psi_{j_1} A_{j_2 j_1}
\end{align*}
$$

Since $\braket{A}_\psi = \braket{A}_\psi$ for all $\hat{A}$, the matrix elements of $\hat{\rho}$ must be of the form $\rho_{j_1 j_2} = \psi_{j_1} \psi_{j_2}^*$. Consequently,

$$
  \hat{\rho} = \sum_{j_1,j_2} \psi_{j_1} \psi_{j_2}^* \ket{e_{j_1}} \bra{e_{j_2}} = \ket{\psi}\bra{\psi}
$$

which is equivalent to $\hat{\rho}^2 = \hat{\rho}$.
</details>

### Measurement

<MathBox title="Gleason's theorem" boxType='theorem'>
Let $\mathcal{H}$ be a Hilbert space with finite dimension $\dim(\mathcal{H}) \geq 3$. Any map $\Pr$ that assigns probabilities to the orthogonal projections of $\mathcal{H}$ and satisfies

- $\Pr(\hat{0}) = 0$
- $\Pr(\hat{I}) = 1$
- $\hat{P}_1 \hat{P}_2 = 0 \implies \Pr(\hat{P}_1 + \hat{P}_2) = \Pr(\hat{P}_1) + \Pr(\hat{P}_2)$ for any orthogonal projections $\hat{P}_1, \hat{P}_2$ 

must be of the form

$$
  \Pr (\hat{P}) = \operatorname{tr}(\hat{\rho}\hat{P})
$$

where $\hat{\rho}$ is a unique positive semidefinite, Hermitian operator $\hat{\rho}$ with $\operatorname{tr}(\hat{\rho}) = 1$.
</MathBox>

In terms of a density operator $\hat{\rho}$, the expectation value of an observable $\hat{Q}$ is defined as

$$
\begin{equation*}
  \braket{\hat{Q}}_\rho = \operatorname{tr}(\hat{\rho} \hat{Q})
\tag{\label{equation-96}}
\end{equation*}
$$

The probability that a measurement of $\hat{Q} = \sum_j \lambda_j \ket{q_j} \bra{q_j}$ yields an eigenvalue $\lambda_j$ corresponding to the eigenstate $\ket{q_j}$ is given by

$$
\begin{align*}
  \Pr_\rho (\lambda) =& \braket{P_{q_j}}_\rho = \operatorname{tr}(\rho \hat{P}_{q_j}) \\
  =& \operatorname{tr}(\hat{\rho}\ket{q_j}\bra{q_j}) \\
  =& \sum_{k,l} p_j \braket{q_l|\psi_k} \braket{\psi_k|q_j} \underbrace{\braket{q_j|q_l}}_{\delta_{jl}} \\
  =& \sum_k p_k |\braket{e_j|\psi_k}|^2 
\end{align*}
$$

If the system is in a pure state, $\hat{\rho} = \ket{\psi}\bra{\psi}$, the probability of measuring the eigenvalue $\lambda_j$ of $Q$ is

$$
\begin{align*}
  \braket{P_{q_j}}_{\rho_\psi} =& \operatorname{tr}(\hat{\rho}_\psi \hat{P}_{q_j}) = \operatorname{tr}(\ket{\psi}\braket{\psi|q_j}\bra{q_j}) \\
  =& \sum_k \braket{q_k|\psi} \braket{\psi|q_j}\underbrace{\braket{q_j|q_k}}_{=\delta_{jk}} \\
  =& |\braket{q_j|\psi}|^2
\end{align*}
$$

The expectation value of $Q$ in this case is

$$
\begin{align*}
  \braket{Q}_{\rho_\psi} =& \operatorname{tr}(\hat{\rho}_\psi \hat{Q}) \\
  =& \sum_{j,k} \braket{q_k|\psi}\braket{\psi|q_j}\lambda_j \underbrace{\braket{q_j|q_k}}_{=\delta_{jk}} \\
  =& \sum_j \lambda_j |\braket{q_j|\psi}|^2 
\end{align*}
$$

For a pure state $\ket{\psi}$, the expectation value can be written

$$
  \braket{\hat{Q}}_\psi = \sum_j \braket{q_j | \hat{\rho} \hat{Q} | q_j} = \sum_j \braket{q_j | \psi} \braket{\psi|\hat{Q}|q_j}
$$

Let $\set{\ket{\psi_j}}_{j\in I\subset\N}$ be an orthonormal basis of a Hilbert space $\mathcal{H}$. If the density operator is $\hat{\rho} = \sum_{j\in I} p_j \ket{\psi_j} \bra{\psi_j}$ and the state $\ket{\psi}\in\mathcal{H}$ is given by 

$$
  \ket{\psi} = \sum_{j\in I} \sqrt{p_j} \ket{\psi_j}
$$

then for any observable $Q$, the expectation value is

$$
  \braket{Q}_\psi = \braket{Q}_\rho + \sum_{j,k\in I:j\neq k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k}
$$

<details>
<summary>Proof</summary>

The expectation value of $Q$ in terms of $\hat{\rho}$ is

$$
\begin{align*}
  \braket{Q}_\rho =& \operatorname{tr}(\hat{\rho}\hat{Q}) = \operatorname{tr}\left(\sum_j p_j \ket{\psi_j} \bra{\psi_j} \right) \\
  =& \sum_j p_j \operatorname{tr}(\ket{\psi_j} \bra{\psi_j}\hat{Q}) \\
  =& \sum_j p_j \sum_k \underbrace{\braket{\psi_k|\psi_j}}_{=\delta_{jk}} \braket{\psi_j|\hat{Q}|\psi_k} \\
  =& \sum_j p_j \braket{\psi_j|\hat{Q}|\psi_j}
\end{align*}
$$

and thus

$$
\begin{align*}
  \braket{Q}_\psi =& \braket{\psi|\hat{Q}|\psi} = \Braket{\sum_j \sqrt{p_j}\psi_j|\hat{Q}|\sum_k \sqrt{p_k} \psi_k} \\
  =& \sum_{j,k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k} \\
  =& \sum_j p_j \braket{\psi_j|\hat{Q}|\psi_j} + \sum_{j\neq k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k} \\
  =& \braket{Q}_\rho + \sum_{j\neq k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k}
\end{align*}
$$
</details>

### Time-evolution

For a state $\ket{\psi(t)}$, the density matrix can be written as $\hat{\rho}(t) = \ket{\psi(t)} \bra{\psi(t)}$. For a pure state under unitary evolution, the time derivative of the density matrix is

$$
\begin{align*}
  \frac{\d\hat{\rho}}{\d t} =& \frac{\hat{H}}{i\hbar} \ket{\psi(t)} \bra{\psi(t)} + \ket{\psi(t)} \bra{\psi(t)} \frac{\hat{H}}{-i\hbar} \\
  =& \frac{i}{\hbar} \left(\hat{\rho}\hat{H} - \hat{H}\hat{\rho} \right) = \frac{i}{\hbar} [\hat{\rho}, \hat{H}]
\end{align*}
$$

or, equivalently

$$
  i\hbar\frac{\d\hat{\rho}}{\d t} = [\hat{H}, \hat{\rho}]
$$

This is the von Neumann equation, which describes the evolution of the density matrix for pure states under Schr√∂dinger evolution. It shows that pure states evolve into pure states in this framework.

To express this evolution in the Heisenberg picture, we use the fact that the state in the Schr√∂dinger picture is related to the state in the Heisenberg picture by $\ket{\psi(t)}_\text{S} = \hat{U}_t \ket{\psi(0)}_\text{S}$, where $\hat{U}_t$ is the time evolution operator. Thus, the density matrix in the Schr√∂dinger picture at time $t$ can be written

$$
  \hat{\rho}_\text{S} (t) = \hat{U}_t \ket{\psi}_\text{H} \bra{\psi}_\text{H} \hat{U}_t^\dagger = \hat{U}_t \hat{\rho}_\text{H} \hat{U}_t^\dagger
$$

In the Heisenberg picture, the density matrix evolves as

$$
  \hat{\rho}_\text{H} = \hat{U}_t^\dagger \hat{\rho}_\text{S} \hat{U}_t = \hat{\rho}_\text{S} (0)
$$

In the Dirac interaction picture, the density matrix evolves as

$$
  \hat{\rho}_\text{I} = \hat{U}_{H_0, t}^\dagger \hat{\rho}_\text{S} \hat{U}_{H_0, t}
$$

where $\hat{U}_{H_0, t}$ is the evolution operator in the interaction picture corresponding to the free Hamiltonian $\hat{H}_0$.

### Pure random mixtures

Let $\mathcal{H}$ be a finite-dimensional Hilbert space with $\dim(\mathcal{H}) = n$ and let $\set{\ket{\Phi_j}}_{j=1}^n \subset\mathcal{H}$ be a collection of normalized states. A pure random mixture (or random coherent superposition) is a normalized vector

$$
  \ket{\Phi_\boldsymbol{\alpha}} = \sum_{j=1}^n \alpha_j \ket{\Phi_j}
$$

with complex coefficients $\alpha_j = r_j e^{i\delta_j}$ where

$$
\begin{equation*}
  \sum_{j=1}^n r_j^2 = 1
\tag{\label{equation-149}}
\end{equation*}
$$

For a fixed realization $\boldsymbol{\alpha} = (a_j)_{j=1}^n$, the expectation value of an observable $\hat{Q}$ in the state $\ket{\Phi_\boldsymbol{\alpha}}$ is

$$
\begin{align*}
  \braket{\hat{Q}}|_\boldsymbol{\alpha} =& \braket{\Phi_\boldsymbol{\alpha}|\hat{Q}|\Phi_\boldsymbol{\alpha}} \\
  =& \sum_{j,k=1}^n \alpha_j^* \alpha_k \braket{\Phi_j|\hat{Q}|\Phi_k}
  =& \sum_{j,k=1}^n r_j r_k e^{-i\gamma_{jk}} \braket{\Phi_j |\hat{Q}|\Phi_k}\; \gamma_jk = \delta_j - \delta_k
\end{align*}
$$

Let $f(r_1,\dots,r_n,\gamma_{12},\dots,\gamma_{n-1, n})$ denote the probability density describing the statistical distribution of $\boldsymbol{\alpha}$. To obtain the expectation value of $\hat{Q}$ over all fluctuation of the coefficients $r_j r_k e^{-i\gamma_{jk}}$, we have to average $\braket{\hat{Q}}$ the density $f$. Define the expectation values

$$
  w_{jk} := \mathbb{E}_f [r_j r_k e^{-i\gamma_{jk}}]
$$

Accordingly, the overall expectation of the observable $\hat{Q}$ is given by

$$
\begin{equation*}
  \braket{Q} = \sum_{j,k=1}^n w_{jk} \braket{\Phi_j |\hat{Q}|\Phi_k}
\tag{\label{equation-150}}
\end{equation*}
$$

The matrix $\boldsymbol{w} = [w_{jk}]$ is Hermitian, since

$$
  w_{jk}^* = \mathbb{E}_f [r_j r_k e^{i\gamma_{jk}}] = w_{kj}
$$

Moreover, from the normalization contraint $\eqref{equation-148}$ it follows that

$$
  \operatorname{tr}(\mathbf{w}) = \sum_j w_{jj} = \mathbb{E}_f \left[\sum_j r_j^2 \right] = 1
$$

Since $\boldsymbol{w}$ is Hermitian and positive semidefinite, there exists a unitary matrix $\mathbf{U}$ such that

$$
  \mathbf{U}^\dagger \mathbf{wU} = \operatorname{diag}[w_1, \dots, w_n]
$$

where

$$
  \sum_{j=1}^n w_j = 1,\; w_j \geq 0
$$

Define new orthonormal state 

$$
  \ket{\psi_j} := \sum_{k=1}^n U_{kj}^* \ket{\Phi_k}
$$

Then $\eqref{equation-150}$ can be rewritten in the diagonal basis as

$$
  \braket{\hat{Q}} = \sum_{j=1}^n w_j \braket{\psi_j |\hat{Q}|\psi_j}
$$

Hence, the random mixture behaves statistically as a mixed state

$$
\begin{equation*}
  \hat{\rho} = \sum_{j=1}^n w_j \ket{\psi_j} \bra{\psi_j}
\tag{\label{equation-151}}
\end{equation*}
$$

For a completely random system, where the probability density $f$ is uniform, the random phases $\gamma_{jk}$ are uniformly distributed on $[0, 2\pi)$, and the amplitudes $r_j$ are statistically equivalent. In this case, the phase averages $(j < k)$ are given by

$$
  \frac{1}{2\pi} \int_0^{2\pi} e^{-i\gamma_{jk}} \d\gamma_{jk} = \delta_{jk}
$$

and by symmetry

$$
  \mathbb{E}_f [r_j^2] = \frac{1}{n}
$$

under the constraint $\eqref{equation-149}$. Thus $w_{jk} = \delta_{jk}/n$ so that the density operator $\eqref{equation-151}$ reduces to

$$
  \hat{\rho} = \frac{1}{n} \sum_{j=1}^n \ket{\Phi_j} \bra{\Phi_k} = \frac{1}{n} \hat{I}
$$

and the expectation value becomes

$$
  \braket{\hat{Q}} = \operatorname{tr}(\hat{rho}\hat{Q}) = \frac{1}{n} \sum_{j=1}^n \braket{\psi_j |\hat{Q}|\psi_j} = \frac{1}{n} \operatorname{tr}(\hat{Q})
$$

Thus, a completely randomized ensemble corresponds to the maximally mixed state

$$
  \hat{\rho} = \frac{1}{n} \hat{I}
$$

## Composite systems

The quantum state space of composite system formed of $n\in\N_+$ sub-systems $\mathcal{H}_{A_j}$ for $j\in\set{1,\dots,n}$ is given by the Hilbert tensor product

$$
  \bigotimes_{j=1}^n \mathcal{H}_{A_j}
$$

States of the composite system are generally represented by density operators $\hat{\rho}$ on $\bigotimes_{j=1}^n \mathcal{H}_{A_j}$, which take the form

$$
  \hat{\rho} = \sum_{j\in I} p_j \ket{\Psi_j} \bra{\Psi_j}
$$

where $\set{\ket{\Psi_j}}_{j\in I}$ is an orthonormal basis of $\bigotimes_{j=1}^n \mathcal{H}_{A_j}$.

<MathBox title='Alice and Bob' boxType='remark'>
For a bipartite quantum system $\mathcal{H}_A \otimes \mathcal{H}_B$, it is common to refer to subsystem $A$ as *Alice* and subsystem $B$ as *Bob* for notational convenience.
</MathBox>

### Pure states of bipartite systems

Consider a bipartite system $\mathcal{H}_A \otimes \mathcal{H}_B$ with a density operator $\hat{\rho}\in\mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B)$ describing its state. Measurement of an observable on subsystem $A$, represented by the operator $\hat{M}_A$, corresponds to measuring the composite system with the operator $\hat{M}_A \otimes \hat{I}_B$. Similarly, measurements on subsystem $B$ are represented by operators of the form $\hat{I}_A \otimes \hat{M}_B$. 

For a pure state of the composite system

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a} \otimes \ket{f_b} \in\mathcal{H}_A \otimes \mathcal{H}_B
$$

where $\set{\ket{e_a}}$ and $\set{\ket{f_b}}$ are orthonormal bases of $\mathcal{H}_A$ and $\mathcal{H}_B$, respectively, the expectation value of the observable $M_A$ on subsystem $A$ is given by

$$
\begin{align*}
  \braket{\hat{M}_A \otimes \hat{I}_B}_\Psi =& \braket{\Psi|\hat{M}_A \otimes \hat{I}|\Psi} \\
  =& \sum_{a_1, b_1} \sum_{a_2, b_2} \Psi_{a_2 b_2}^* \Psi_{a_1 b_1} \braket{e_{a_2} \otimes f_{b_2}|\hat{M}_A|e_{a_1} \otimes f_{b_1}} \\
  =& \sum_{a_1, b_1} \sum_{a_2, b_2} \Psi_{a_2 b_2}^* \Psi_{a_1 b_1} \braket{e_{a_2}|\hat{M}_A|e_{a_1}} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{=\delta_{b_1, b_2}} \\
  =& \sum_{a_2, a_1, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \braket{e_{a_2}|\hat{M}_A|e_{a_1}}
\end{align*}
$$

This expectation value remains unchanged if subsystem $A$ were in the mixed state:

$$
  \hat{\rho}_A (\Psi) := \sum_{a_2, a_1, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \ket{e_{a_1}} \bra{e_{a_2}}
$$

For observables of the form $\hat{M}_A$, the state $\hat{\rho}_A (\psi)$ reproduces the expectation values of $\hat{M}_A \otimes \hat{I}_B$ in the composite state $\ket{\Psi}$. Computing the expectation of $M_A$ with respect to $\hat{\rho}_A (\Psi)$ gives

$$
\begin{align*}
  \braket{\hat{M}_A}_{\rho_A (\Psi)} =& \operatorname{tr}(\hat{\rho}_A (\Psi) \hat{M}_A) \\
  =& \sum_a \braket{e_a|\hat{\rho_A} (\Psi) \hat{M}_A e_a} \\
  =& \sum_{a, a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \underbrace{\braket{e_a|e_{a_1}}}_{\delta_{a,a_1}} \braket{e_{a_2}|\hat{M}_A|e_a} \\
  =& \sum_{a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \braket{e_{a_2}|\hat{M}_A|e_{a_1}} \\
  =& \braket{\hat{M}_A \otimes \hat{I}}_\Psi
\end{align*}
$$

Every measurement performed on subsystem $A$, which is a part of a composite system in state $\ket{\Psi}$, suggests that subsystem $A$ is in the mixed state $\hat{\rho}_A (\Psi)$. This means that if the composite system is in the pure state $\ket{\Psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$, described by the density operator $\hat{\rho} = \ket{\Psi}\bra{\Psi}$ on $\mathcal{H}_A \otimes \mathcal{H}_B$, then the reduced state of subsystem $A$ is given by

$$
  \hat{\rho}_A (\Psi) = \sum_{a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \ket{e_{a_1}}\bra{e_{a_2}}
$$

Similarly, for subsystem $B$, the expectation values of observables $\hat{M}_B$ in the pure state $\ket{\Psi}$ are given

$$
  \braket{\hat{I}_A \otimes \hat{M}_B} = \sum_{b_1, b_2, a} \Psi_{ab_1} \Psi_{ab_2}^* \braket{f_{b_2}|\hat{M}_B|f_{b_1}}
$$

where the reduced density operator for subsystem $B$ is

$$
  \hat{\rho}_B (\Psi) = \sum_{b_1, b_2, a} \Psi_{ab_2}^* \Psi_{ab_1} \ket{f_{b_1}} \bra{f_{b_2}} 
$$

which satisfies

$$
  \braket{\hat{M}_B}_{\rho_B (\Psi)} = \braket{\hat{I}_A \otimes \hat{M}_B}_\Psi
$$

<details>
<summary>Details</summary>

We verify that $\hat{\rho}_A (\Psi)$ has all properties of a density operator.

**Hermiticity:** Taking the Hemitian adjoint of $\hat{\rho}_A (\Psi)$ gives
$$
\begin{align*}
  \hat{\rho}_A^\dagger (\Psi) =& \sum_{a_1, a_2, b} (\Psi_{a_2 b}^*)^* \Psi_{a_1 b}^* \underbrace{(\ket{e_{a_1}}\bra{e_{a_2}})^\dagger}_{=\ket{e_{a_2}}\bra{e_{a_1}}} \\
  =& \sum_{a_1, a_2, b} \Psi_{a_1 b}^* \Psi_{a_2 b} \ket{e_{a_2}} \bra{e_{a_1}} \\
  =& \hat{\rho}_A (\Psi)
\end{align*}
$$

showing that $\hat{\rho}_A (\Psi)$ is Hermitian.

**Positive semi-definiteness:** For any $\varphi\in \mathcal{H}_A \otimes \mathcal{H}_B$, we have

$$
\begin{align*}
  \braket{\varphi|\hat{\rho}_A (\Psi)|\varphi} =& \sum_{a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \braket{\varphi|e_{a_1}} \braket{e_{a_2}|\varphi} \\
  =& \sum_b \left(\sum_{a_1} \Psi_{a_1 b} \braket{\varphi|e_{a_1}}\right)\left(\sum_{a_2} \Psi_{a_2 b} \braket{\varphi|e_{a_2}} \right)^* \\
  =& \sum_b \left| \sum_a \Psi_{ab} \braket{\varphi|e_a} \right|^2 \geq 0
\end{align*}
$$

**Unit trace:** Taking the trace of $\hat{\rho}_A (\Psi)$ gives

$$
\begin{align*}
  \operatorname{tr}(\hat{\rho}_A (\Psi)) =& \sum_{a_3, a_1, a_2, b} \Psi_{a_2}^* \Psi_{a_1 b} \braket{e_{a_3}|e_{a_1}} \braket{e_{a_2}|e_{a_3}} \\
  =& \sum_{a,b} |\Psi_{ab}|^2 = \norm{\Psi}^2 = 1
\end{align*}
$$
</details>

### Mixed states of bipartite systems
Consider a bipartite system $\mathcal{H}_A \otimes \mathcal{H}_B$ and let $\hat{\rho}\in\mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B)$ be a density operator describing the state of the system. The reduced density operator $\hat{\rho}_A (\hat{\rho})$ on $\mathcal{H}_A$, which describes the state if the subsystem $A$ alone is observed, is given by the partial trace

$$
  \operatorname{\rho}_A (\hat{\rho}) := \operatorname{tr}_B (\hat{\rho})
$$

For any observable $\hat{M}_A$ in $A$, the density operator $\hat{\rho}_A (\hat{\rho})$ satisifes

$$
  \braket{\hat{M}_A}_{\hat{\rho}_A (\hat{\rho})} = \braket{\hat{M}_A \otimes \hat{I}_B}_{\hat{\rho}}
$$

<details>
<summary>Details</summary>

$$
\begin{align*}
  \braket{\hat{M}_A \otimes \hat{I}_B}_{\hat{\rho}} =& \operatorname{tr}\left((\hat{M}_A \otimes \hat{I}_B)\hat{\rho} \right) \\
  =& \operatorname{tr}\left(\hat{M}_A \operatorname{tr}_B (\hat{\rho}) \right) \\
  =& \operatorname{tr}\left(\hat{M}_A \hat{\rho}_A (\rho) \right) \\
  =& \braket{\hat{M}_A \otimes \hat{I}_B}_{\hat{\rho}}
\end{align*}
$$
</details>

If $\boldsymbol{\rho}_{a_1 b_1, a_2 b_2}$ is the matrix of $\hat{\rho}$ in the orthonormal basis $\set{\ket{e_a \otimes f_b}}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$, then the matrix of $\hat{\rho}_A (\hat{\rho})$ in the orthonormal basis $\set{\ket{e_a}} \subset\mathcal{H}_A$ is given by

$$
  \boldsymbol{\rho}_A (\hat{\rho})_{a_1 a_2} = \sum_b \boldsymbol{\rho}_{a_1 b, a_2 b}
$$

<details>
<summary>Details</summary>

We verify that $\hat{\rho}_A (\hat{\rho})$ has all properties of a density operator.

**Hermiticity:** To prove that $\hat{\rho}_A (\hat{\rho})$ is Hemitian, it suffices to show $\boldsymbol{\rho}_A^\dagger (\hat{\rho})_{a_1 a_2} = \boldsymbol{\rho}_A (\hat{\rho})_{a_1 a_2}$ in an arbitrary orthonormal basis $\set{\ket{e_a}} \subset\mathcal{H}_A$

$$
\begin{align*}
  \boldsymbol{\rho}_A^\dagger {\hat{\rho}}_{a_1 a_2} =& \boldsymbol{\rho}_A^* (\hat{\rho})_{a_1 a_2} = \left(\sum_b \boldsymbol{\rho}_{a_2 b, a_1 b} \right)^* \\
  =& \sum_b \boldsymbol{\rho}_{a_2 b, a_1 b}^* = \sum_b \boldsymbol{\rho}_{a_1 b, a_2 b} \\
  =& \boldsymbol{\rho}_A (\hat{\rho})_{a_1 a_2}
\end{align*}
$$

**Positive semi-definiteness:** Let $\set{\ket{f_b}}$ be an orthonormal basis of $\mathcal{H}_B$ and $\ket{\varphi}\in\mathcal{H}_A$ be arbitrary. Since $\hat{\rho} \geq 0$, it follows that

$$
\begin{align*}
  \braket{\varphi|\hat{\rho}_A (\hat{\rho})|\varphi} =& \sum_{a_1, a_2} \boldsymbol{\varphi}_{a_1}^* \boldsymbol{\rho}_A (\hat{\rho})_{a_1, a_2} \boldsymbol{\varphi}_{a_2} \\
  =& \sum_{a_1, a_2} \boldsymbol{\varphi_{a_1}}^* \sum_b \boldsymbol{\rho}_{a_1 b, a_2 b} \boldsymbol{\varphi}_{a_2} \\
  =& \sum_{a_1, a_2, b} \boldsymbol{\varphi}_{a_1}^* \boldsymbol{\rho}_{a_1 b, a_2 b} \boldsymbol{\varphi}_{a_2} \\
  =& \sum_b \braket{\varphi\otimes f_b|\hat{\rho}|\varphi\otimes f_b} \geq 0
\end{align*}
$$

**Unit trace:** Since $\boldsymbol{tr}(\hat{\rho}) = 1$, it follows that

$$
\begin{align*}
  \operatorname{tr}\left(\hat{\rho}_A (\hat{\rho}) \right) =& \sum_a \boldsymbol{\rho}_A (\hat{\rho})_{aa} \\
  =& \sum_a \sum_b \boldsymbol{\rho}_{ab, ab} = \operatorname{tr}(\hat{\rho}) = 1
\end{align*}
$$
</details>

Similarly, the reduced density operator $\hat{\rho}_B (\hat{\rho})$ on $\mathcal{H}_B$ is given by the partial trace

$$
  \hat{\rho}_B (\hat{\rho}) := \operatorname{tr}_A (\hat{\rho}) 
$$

For any observable $\hat{M}_B$ in $A$, the density operator $\hat{\rho}_B (\hat{\rho})$ satisifes

$$
  \braket{\hat{M}_B}_{\hat{\rho}_B (\hat{\rho})} = \braket{\hat{I}_A \otimes \hat{M}_B}_{\hat{\rho}}
$$

If $\boldsymbol{\rho}_{a_1 b_1, a_2 b_2}$ is the matrix of $\hat{\rho}$ in the orthonormal basis $\set{\ket{e_a \otimes f_b}}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$, then the matrix of $\hat{\rho}_B (\hat{\rho})$ in the orthonormal basis $\set{\ket{f_b}}\subset\mathcal{H}_B$ is given by

$$
  \boldsymbol{\rho}_B (\hat{\rho})_{b_1 b_2} = \sum_a \boldsymbol{\rho}_{a b_1, a b_2}
$$

### Schmidt decomposition of pure states

Schmidt decomposition provides a way to express a pure states $\ket{\Psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$ in terms of the eigenvectors of the reduced density operators. Let

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{a,b} \ket{e_a \otimes f_b}
$$

be a pure state in the composite Hilbert space $\mathcal{H}_A \otimes \mathcal{H}_B$ and let

$$
  \hat{\rho}_A (\Psi) = \sum_{a_1, a_2, b} \Psi_{a_1 b} \Psi_{a_2 b}^* \ket{e_{a_1}} \bra{e_{a_2}}
$$

be the corresponding reduced density operator for subsystem $A$. Since $\hat{\rho}_A (\Psi)$ is a Hermitian and positive operator on $\mathcal{H}_A$, there exists an orthonormal basis $\set{\ket{\tilde{e}_a}}$ in $\mathcal{H}_A$ consisting of eigenvector of $\hat{\rho}_A (\Psi)$ such that

$$
  \hat{\rho}^A (\Psi) = \sum_{a} q_a \ket{\tilde{e}_a} \bra{\tilde{e}_a}
$$

where $q_a \geq 0$ are the eigenvalues. The othornormal bases $\set{\ket{\tilde{e}_a}}$ and $\set{\ket{\tilde{e}_a}}$ are related by a unitary operator $\hat{U}\in\mathcal{U}(\mathcal{H}_A)$

$$
  \ket{\tilde{e}_a} = \hat{U}\ket{e_a} = \sum_{a_1} \ket{e_{a_1}} \underbrace{\braket{e_{a_1}|\hat{U}|e_a}}_{=\mathbf{U}_{a_1 a}}
$$

Defining the transformed coefficients

$$
  \tilde{\Psi}_{ab} := \sum_{a_1} \mathbf{U}_{a a_1} \Psi_{a_1 b}
$$

we find

$$
  \ket{\Psi} = \sum_{a, b} \tilde{\Psi}_{ab} \ket{\tilde{e}_a \otimes f_b}
$$

This imples that the reduced density matrix takes the form

$$
  \hat{\rho}_A (\Psi) = \sum_{a_1, a_2, b} \tilde{\Psi}_{a_1 b} \tilde{\Psi}_{a_2 b}^* \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}}
$$

By comparing the eigenvalue coefficients of $\hat{\rho}_A (\Psi)$, we deduce that

$$
  \sum_b \tilde{\Psi}_{a_1 b} \Psi_{a_2 b}^* = \delta_{a_1 a_2} q_{a_2}
$$

In particular,

$$
  q_a = 0 \iff \Psi_{ab}^* = 0, \; \forall b
$$

For $q_a > 0$ we define the vectors

$$
  \ket{\tilde{f}_a} := \frac{1}{\sqrt{q_a}} \sum_b \tilde{\Psi}_{ab} \ket{f_b} \in\mathcal{H}_B
$$

The set $\set{\ket{\tilde{f}_a}}$ forms an orthonormal basis in $\mathcal{H}_B$ since

$$
\begin{align*}
  \braket{\tilde{f}_{a_1}|\tilde{f}_{a_2}} =& \frac{1}{\sqrt{q_{a_1} q_{a_2}}} \sum_{b_1, b_2} \tilde{\Psi}_{a_1 b_1}^* \tilde{\Psi}_{a_2 b_2} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{\delta_{b_1 b_2}} \\
  =& \frac{1}{\sqrt{q_{a_1} q_{a_2}}} \sum_b \tilde{\Psi}_{a_1 b}^* \tilde{\Psi}_{a_2 b} \\
  =& \delta_{a_1 a_2}
\end{align*}
$$

Thus, we obtain

$$
\begin{align*}
  \ket{\Psi} =& \sum_{a,b} \tilde{\Psi}_{ab} \ket{\tilde{e}_a \otimes f_b} \\
  =& \sum_{q_a \neq 0} \ket{\tilde{e}_a} \otimes \underbrace{\sum_{b} \tilde{\Psi}_{ab} \ket{f_b}}_{=\sqrt{q_a}\ket{f_b}} + \sum_{q_a = 0} \sum_b \underbrace{\tilde{\Psi}_{ab}}_{=0} \ket{\tilde{e}_a \otimes f_b} \\
  =& \sum_{q_a \neq 0} \sqrt{q_a} \ket{\tilde{e}_a \otimes \tilde{f}_b}
\end{align*}
$$

which is the Schmidt decomposition

$$
  \ket{\Psi} = \sum_a \sqrt{q_a} \ket{\tilde{e}_a \otimes \tilde{f}_a}
$$

The orthonormal bases $\set{\ket{\tilde{e}_a}}$ and $\set{\ket{\tilde{f}_b}}$ depend on $\ket{\Psi}$. In terms of the Schmidt decomposition, the reduced density operators can be written as

$$
\begin{align*}
  \hat{\rho}_A (\Psi) =& \sum_a q_a \ket{\tilde{e}_a} \bra{\tilde{e}_a}
  \hat{\rho}_B (\Psi) =& \sum_{b} q_b \ket{\tilde{f}_b} \bra{\tilde{f}_b}
\end{align*}
$$

The Schmidt bases $\set{\ket{\tilde{e}_a}}$ and $\set{\ket{\tilde{f}_b}}$ are unique only if all nonzero eigenvalues of $\hat{\rho}_A (\Psi)$ (or equivalently, $\hat{\rho}_B (\Psi)$) are non-degenerate. If a nonzero eigenvalue $q_{\bar{a}} \neq 0$ of $\hat{\rho}_A (\Psi)$ has degeneracy $d_{\bar{a}} > 1$, then the corresponding eigenspace allows for an arbitrary choice of orthonormal basis. For $k\in\set{1,\dots,d_{\bar{a}}}$ let $\ket{\tilde{e}_{\bar{a}, k}}$ be the eigenvectors associated with $q_{\bar{a}}$. Then

$$
\begin{align*}
  \hat{\rho}_A (\Psi) =& \sum_{a \neq \bar{a}} q_a \ket{\tilde{e}_a} \bra{\tilde{e}_a} + q_{\bar{a}} \sum_{k=1}^{d_{\bar{a}}} \ket{\tilde{e_{\bar{a}, k}}} \bra{\tilde{e}_{\bar{a}, k}} \\
  =& \sum_{a \neq \bar{a}} q_a \ket{\tilde{e}_a} \bar{\tilde{e}_a} + q_{\bar{a}} \sum_{k=1}^{d_{\bar{a}}} {\ket{\tilde{\tilde{e}}}_{\bar{a}, k}} \bra{\tilde{\tilde{e}}_{\bar{a}, k}}
\end{align*}
$$

with

$$
  {\ket{\tilde{\tilde{e}}}_{\bar{a}, k}} = \sum_{l = 1}^{d_{\bar{a}}} \mathbf{U}_{kl}^{\bar{a}} \ket{\tilde{e}_{\bar{a},l}}
$$

where $\mathbf{U}_{kl}^{\bar{a}}$ is the matrix of an arbitrary unitary transformation in the eigenspace for $q_{\bar{a}}$. This shows that $\ket{\Psi}$ has the following equivalent Schmidt decompositions 

$$
\begin{align*}
  \ket{\Psi} =& \sum_{a \neq \bar{a}} \sqrt{q_a} \ket{\tilde{e}_a \otimes \tilde{f}_b} + \sqrt{q_{\bar{a}}} \sum_{k=1}^{d_{\bar{a}}} \ket{\tilde{e}_a \otimes \tilde{f}_b} \\
  =& \sum_{a \neq \bar{a}} q_a \ket{\tilde{e}_a \otimes \tilde{f}_b} + q_{\bar{a}} \sum_{k=1}^{d_{\bar{a}}} \ket{\tilde{\tilde{e}}_a \otimes \tilde{\tilde{f}}_b}
\end{align*}
$$

## Entanglement

A state $\hat{\rho}\in\mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B)$ in a composite system $\mathcal{H}_A \otimes \mathcal{H}_B$ is *separable* with respect to the subsystems $\mathcal{H}_A$ and $\mathcal{H}_B$ if there exists states $\hat{\rho}_j^{(A)} \in\mathcal{D}(\mathcal{H}_A)$ and $\hat{\rho}_j^B \in\mathcal{D}(\mathcal{H}_B)$ for $I\subset\N_+$, along with real numbers $p_j > 0$ satisfying $\sum_{j\in I} p_j = 1$, such that

$$
  \hat{\rho} = \sum_{j\in I} p_j \hat{\rho}_j \hat{\rho}_j^{(A)} \otimes \hat{\rho}_j^{(B)}
$$

Separable states are also known as *product-states*. States that cannot be written in this form are *entangled*. A pure state $\ket{A}$ in the tensor product of identical Hilbert spaces $\mathcal{H}_A$ is *maximally intangled* if

$$
  \hat{\rho}_A (\Psi) = \lambda\hat{I}, \; 0 < \lambda < 1
$$

<details>
<summary>Details</summary>

To verify that the tensor product of two density matrices is itself a valid density matrix, consider $\hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)$ and $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$. We need to check that $\hat{\rho}_A \otimes \hat{\rho}_B \in\mathcal{D}(\mathcal{H}_A \otimes\mathcal{H}_B)$, which requires that it is Hermitian, positive semi-definite, and has unit trace.

**Hermiticity:** Since $\hat{\rho}_A$ and $\hat{\rho}_B$ are Hermitian then so is $\hat{\rho}_A \otimes\hat{\rho}_B$. 


**Positivity:** In order to show the positivity of $\hat{\rho}_A \otimes \hat{\rho}_B$ note first that

$$
\begin{align*}
  \hat{\rho}_A \otimes \hat{\rho}_B =& (\hat{\rho}_A \otimes\hat{I}_B)(\hat{I}\otimes\hat{\rho}_B) \\
  =& (\hat{I}_A \otimes\hat{\rho}_B)(\hat{\rho}_A \otimes\hat{I}_B)
\end{align*}
$$

where also

$$
  (\hat{\rho}_A \otimes\hat{I}_B)^\dagger = \hat{\rho}_A \otimes\hat{I}_B, \quad (\hat{I}_A \otimes\hat{\rho}_B)^\dagger = \hat{I}_A \otimes\hat{\rho}_B
$$

Both $\hat{\rho}_A \otimes\hat{I}_B$ and $\hat{I}_A \otimes\hat{\rho}_B$ are positive because for an arbitrary vector

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a} \otimes\ket{f_b} \in\mathcal{H}_A \otimes\mathcal{H}_B
$$

and positivity of $\hat{\rho}_A$ we find that

$$
\begin{align*}
  \braket{\Psi|\hat{\rho}_A \otimes\hat{I}_B|\Psi} =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \Braket{e_{a_1} \otimes f_{b_1}|\hat{\rho}_A \otimes\hat{I}_B|e_{a_2} \otimes f_{b_2}} \\
  =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \braket{e_{a_1}|\hat{\rho}_A|e_{a_2}} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{=\delta_{b_1 b_2}} \\
  =& \sum_{a_1 a_2, b} \Psi_{a_1 b}^* \Psi_{a_2 b} \braket{e_{a_1}|\hat{\rho}_A|e_{a_2}} \\
  =& \sum_b \Braket{\sum_{a_1} \Psi_{a_1 b} e_{a_1}|\hat{\rho}_A| \sum_{a_2} \Psi_{a_2 b} e_{a_2}} \\
  =& \sum_b \braket{\psi_b |\hat{\rho}_A|\psi_b} \geq 0
\end{align*}
$$

Similarly, by positivity of $\hat{\rho}_B$ we find that

$$
\begin{align*}
  \braket{\Psi|\hat{I}_A \otimes\hat{\rho}_B|\Psi} =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \Braket{e_{a_1} \otimes f_{b_1}|\hat{I}_A \otimes\hat{P}_B|e_{a_2} \otimes f_{b_2}} \\
  =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \underbrace{\braket{e_{a_1}|e_{a_2}}}_{=\delta_{a_1 a_2}} \braket{f_{b_1}|\hat{\rho}_B|f_{b_2}} \\
  =& \sum_{a, b_1 b_2} \Psi_{a b_1}^* \Psi_{a b_2} \braket{f_{b_1}|\hat{\rho}_B|f_{b_2}} \\
  =& \sum_a \Braket{\sum_{b_1} \Psi_{a b_1} f_{b_1}|\hat{\rho}_B| \sum_{b_2} \Psi_{a b_2} f_{b_2}} \\
  =& \sum_a \braket{\psi_a |\hat{\rho}_B|\psi_a} \geq 0
\end{align*}
$$

Since $\hat{\rho}_A \otimes\hat{I}_B$ and $\hat{I}_A \otimes\hat{\rho}_B$ commute, and are Hermitian and posite, it follows that for every pair $\hat{\rho}_A \otimes\hat{I}_B$, $\hat{I}_A \otimes\hat{\rho}_B$ there exists an orthonormal basis $\ket{e_a \otimes f_b}$ in which both are diagonal, i.e.

$$
\begin{align*}
  \hat{\rho}_A \otimes\hat{I}_B =& \sum_{a,b} \lambda_{a,b}^{(A)} \ket{e_a \otimes f_b} \bra{e_a \otimes f_b} \\
  \hat{I}_A \otimes\hat{\rho}_B =& \sum_{a,b} \lambda_{a,b}^{(B)} \ket{e_a \otimes f_b} \bra{e_a \otimes f_b}
\end{align*}
$$

where due to positivity we also have $\lambda_{a,b}^{(A)} \geq 0$ and $\lambda_{a,b}^{(B)} \geq 0$, so that

$$
  \hat{\rho}_A \otimes \hat{\rho}_B = \sum_{a,b} \lambda_{a,b}^{(A)} \lambda_{a,b}^{(B)} \ket{e_a \otimes f_b} \bra{e_a \otimes f_b}
$$

and since $\lambda_{a,b}^{(A)}\lambda_{a,b}^{(B)} \geq 0$, it follows that $\hat{\rho}_A \otimes\hat{\rho}_B$ is positive.

**Unit trace:** Since $\hat{\rho}_A$ and $\hat{\rho}_B$ have unit trace, it follows that

$$
  \operatorname{tr}(\hat{\rho}_A \otimes\hat{\rho}_B) = \operatorname{tr}(\hat{\rho}_A)\operatorname{tr}(\hat{\rho}_B) = 1
$$
</details>

<MathBox title='Separability criterion for pure states' boxType='theorem' tag='theorem-1'>
A pure state $\ket{\psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$ is separable if and only if there exists pure states $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$ such that

$$
\begin{equation*}
  \ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}
\tag{\label{equation-113}}
\end{equation*}
$$

Otherwise, $\ket{\psi}$ is entangled.

<details>
<summary>Proof</summary>

**Sufficiency**

First we show that $\eqref{equation-113}$ is sufficient for separability. Suppose we have $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi} \in\mathcal{H}_A \otimes\mathcal{H}_B$. Then it follows that

$$
\begin{align*}
  \hat{\rho}(\Psi) =& \ket{\Psi}\bra{\Psi} = \ket{\varphi\otimes\psi}\bra{\varphi\otimes\psi} \\
  =& \ket{\psi}\bra{\psi} \otimes\ket{\varphi}\bra{\varphi}
\end{align*}
$$

Setting $\hat{\rho}^A = \ket{\varphi}\bra{\varphi}$ and $\hat{\rho}^B = \ket{\psi}\bra{\psi}$, we see that $\eqref{equation-113}$ holds.

**Necessity**
To show that $\eqref{equation-113}$ is also necessary, let $\hat{\rho}$ be a pure separable state. Then its density matrix $\hat{\rho} = \ket{\Psi}\bra{\Psi}$ must be of the form

$$
  \hat{\rho} = \sum_{j\in I} p_j \hat{\rho}_j^{(A)} \otimes \hat{\rho}_j^{(B)}, \; I\subset\N_+
$$

where $p_j > 0$ with $\sum_{j\in I} p_j = 1$, and $\hat{\rho}_j^{(A)}\in\mathcal{D}(\mathcal{H}_A)$, $\hat{\rho}_j^{(B)}\in\mathcal{D}(\mathcal{H}_B)$.

We show that there exists $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$ such that $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}$. For all $j\in I$ we set

$$
  \hat{\rho}_j = \hat{\rho}_j^{(A)} \otimes\hat{\rho}_j^{(B)} \in\mathcal{D}(\mathcal{H}_A \otimes\mathcal{H}_B)
$$

which define density operators in $\mathcal{H}_A \otimes \mathcal{H}_B$. From properties of density operators, there exists $p_{j,k}\in (0,1]$ for every $j\in I$ with $k \in I_j \subset \N_+$ satisfying $\sum_{k\in I_j} p_{j,k} = 1$, and an orthonormal basis $\set{\ket{\Omega_{j,k}}}_{k=1}^{\dim(\mathcal{H}_A \otimes\mathcal{H}_B)}$ of $\mathcal{H}_A \otimes \mathcal{H}_B$ such that

$$
\begin{equation*}
  \hat{\rho}_j = \sum_{k\in I_j} p_{j,k} \ket{\Omega_{j,k}} \bra{\Omega_{j,k}}
\tag{\label{equation-114}}
\end{equation*}
$$

We extend $\ket{\Psi}$ to another orthonormal basis $\set{\ket{\Psi}, \ket{\Psi_l}}_{l=1}^{\dim(\mathcal{H}_A \otimes\mathcal{H}_B) - 1}$ of $\mathcal{H}_A \otimes\mathcal{H}_B$. It follows that

$$
  0 = |\braket{\Psi_l|\Psi}|^2 = \braket{\Psi_l|\hat{\rho}|\Psi_l} = \sum_{j\in I} p_j \braket{\Psi_l|\hat{\rho}_j|\Psi_l}
$$

and since $p_j > 0$, we must have $\braket{\Psi_l|\hat{\rho}_j|\Psi_l} = 0$ for all $j\in I$ and $l\in\set{1,dots,\dim(\mathcal{H}_A \otimes \mathcal{H}_B) - 1}$. Together with $\eqref{equation-114}$ this implies

$$
  \sum_{k\in I_j} p_{j,k} |\braket{\Psi_l |\Omega_{j,k}}|^2 = 0
$$

and thus, again because $p_{j,k} > 0$ for all $l\in\set{1,\dots,\dim(\mathcal{H}_A \otimes \mathcal{H}_B - 1)}$, $j\in I$ and $k\in I_j$, we have

$$
  \braket{\Psi|\Omega_{j,k}} = 0
$$

Thus, for every $j\in I$ and $k\in I_j$ the basis vector $\ket{\Omega_{j,k}}$ is orthogonal to all $\ket{\Psi_l}$. Consequently, every $\ket{\Psi_{j,k}}$ is in the ray of $\ket{\Psi}$ and there exist $\alpha_{j,k} \in\R$ such that

$$
  \ket{\Omega_{j,k}} = e^{i\alpha_{j,k}} \ket{\Psi}
$$

This implies

$$
\begin{align*}
  \hat{\rho}_j^{(A)} \otimes\hat{\rho}_j^{(B)} =& \hat{\rho}_j = \sum_{k \in I_j} p_{j,k} e^{i\alpha_{j,k}} \ket{\Psi}\bra{\Psi} e^{-i\alpha_{j,k}} \\
  =& \underbrace{\sum_{k\in I_j} p_{j,k}}_{=1} \ket{\Psi}\bra{Psi} = \ket{\Psi}\bra{\Psi} \\
  =& \hat{\rho}
\end{align*}
$$

and thus there are $\hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)$ and $\hat{\rho}_B \in\mathcal{H}_B$ such that for all $j\in I$

$$
  \hat{\rho}_j = \hat{\rho}_A \otimes\hat{\rho}_B = \hat{\rho}
$$

Using the Schmidt decomposition, we can find $q_a \in (0,1]$ and orthonormal bases $\set{e_a}_{a=1}^{\dim(\mathcal{H}_A)}$ and $\set{f_b}_{b=1}^{\dim(\mathcal{H}_B)}$ such that we can write

$$
\begin{equation*}
  \ket{\Psi} = \sum_a \sqrt{q_a} \ket{e_a} \otimes\ket{f_b}
\tag{\label{equation-115}}
\end{equation*}
$$

This implies

$$
\begin{align*}
  \hat{\rho}_A \otimes\hat{\rho}_B =& \hat{\rho} = \ket{\Psi}\bra{\Psi} \\
  =& \sum_{a,b} \sqrt{q_a q_b} \ket{e_a}\bra{e_a} \otimes \ket{f_b} \bra{f_b}
\end{align*}
$$

such that in the orthonormal basis $\set{\ket{e_a}\otimes\ket{f_b}}$ of $\mathcal{H}_A \otimes\mathcal{H}_B$ we see that $\hat{\rho}$ has the matrix

$$
\begin{align*}
  \boldsymbol{\rho}_{a_1 a_2}^{(A)} \boldsymbol{\rho}_{b_1 b_2}^{(B)} = \mathbf{\rho}_{a_1 b_1, a_2 b_2} \\
  =& \sqrt{q_{a_1} q_{a_2}} \delta_{a_1 b_1} \delta_{a_2 b_2}
\end{align*}
$$

From this it follows that

$$
\begin{equation*}
\begin{split}
  \hat{\rho}_A =& \operatorname{tr}_B (\hat{\rho}) = \sum_a q_a \ket{e_a}\bra{e_a} \\
  \hat{\rho}_B =& \operatorname{tr}_A (\hat{\rho}) = \sum_b q_b \ket{f_b}\bra{f_b}
\end{split}
\tag{\label{equation-118}}
\end{equation*}
$$

Now, by unit trace of $\hat{\rho}$

$$
\begin{align*}
  1 =& \operatorname{tr}(\hat{\rho}) = \operatorname{tr}(\hat{\rho}^2) \\
  =& \operatorname{tr}(\hat{\rho}_A^2 \otimes \hat{\rho}_B^2) \\
  =& \sum_{c, d} \braket{e_c \otimes f_d |\sum_{a,b} q_a^2 q_b^2 \ket{e_a \otimes f_b} \bra{e_a \otimes f_b} | e_c \otimes f_d} \\
  =& \sum_{a, b, c, d} q_a^2 q_b^2 \delta_{ca} \delta_{db} = \sum_{a,b} q_a^2 q_b^2 \\
  =& \left(\sum_a q_a^2 \right)^2 \tag{\label{equation-116}}
\end{align*}
$$

where $q_a \in [0,1]$ for all $a$. On the other hand, it follows from $\eqref{equation-115}$ that

$$
\begin{equation*}
  \sum_a q_a = \norm{\Psi} = 1
\tag{\label{equation-117}}
\end{equation*}
$$

Together, $\eqref{equation-116}$ and $\eqref{equation-117}$ imply that there can be only on $\bar{a} = 1$ with $q_{\bar{a}} = 1$ and else $q_a = 0$ for all $a \neq \bar{a}$ must hold. Consequently, $\eqref{equation-118}$ becomes

$$
  \hat{\rho}_A = \ket{e_{\bar{a}}} \bra{e_{\bar{a}}}, \quad \hat{\rho}_B = \ket{f_{\bar{a}}}\bra{f_{\bar{a}}}
$$

and $\eqref{equation-115}$ implies $\ket{\Psi} = \ket{e_{\bar{a}}}\otimes\ket{f_{\bar{a}}}$.
</details>
</MathBox>

<MathBox title='Separability criterion for pure states' boxType='theorem'>
A pure state $\ket{\Psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$ is separable if and only if $\hat{\rho}_X (\Psi)$ is pure for all $X\in\set{A,B}$. Or, equivalently, $\ket{\Psi}$ is entangled if and only if $\hat{\rho}_X (\Psi)$ is a true mixture for any $X\in\set{A,B}$.

<details>
<summary>Proof</summary>

It suffices to prove only the first statement, since the second is equivalent.

**($\implies$):** Let $\ket{\Psi}$ be separable. Then we know from Theorem $\ref{theorem-1}$ that there exist $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$ with $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}$. Because

$$
\begin{align*}
  1 =& \norm{\Psi} = \sqrt{\braket{\Psi|\Psi}} \\
  =& \sqrt{\braket{\varphi|\varphi}}\sqrt{\braket{\psi|\psi}} \\
  =& \norm{\varphi}\cdot\norm{\psi}
\end{align*}
$$

we must have $\norm{\varphi} \neq 0 \neq \norm{\psi}$. We define the unit vectors $\ket{e_0} := \frac{\ket{\varphi}}{\norm{\varphi}}$ and $\ket{f_0} := \frac{\ket{\psi}}{\norm{\psi}}$ and augment them by suitable vectors in order to form the orthornomal bases

$$
\begin{align*}
  &\Set{\ket{e_0} := \frac{\ket{\varphi}}{\norm{\varphi}}, \ket{e_1}, \dots} \subset\mathcal{H}_A \\
  &\Set{\ket{f_0} := \frac{\ket{\psi}}{\norm{\psi}}, \ket{f_1}, \dots} \subset\mathcal{H}_B \\
\end{align*}
$$

such that

$$
\begin{align*}
  \ket{\Psi} =& \ket{\varphi}\otimes\ket{\psi} \\
  =& \norm{\varphi}\cdot\norm{\psi} \ket{e_0} \otimes\ket{f_0} \\
  =& \sum_{a,b} \Psi_{a,b} \ket{e_a} \otimes\ket{f_b}
\end{align*}
$$

where

$$
  \Psi_{ab} = \begin{cases}
    \norm{\varphi}\cdot\norm{\psi} = 1, \quad& a = 0 = b \\
    0, \quad& \text{else}
  \end{cases}
$$

Thus, we have

$$
\begin{align*}
  \hat{\rho}_A (\Psi) =& \sum_{a_1, a_2, b} \Psi_{a_1 b} \Psi_{a_2 b}^* \ket{e_{a_2}} \bra{e_{a_1}} \\
  =& \norm{\varphi}\cdot\norm{\psi} \ket{e_0} \bra{e_0} \\
  =& \ket{e_0} \bra{e_0}
\end{align*}
$$

which as a rank-one projection onto a one-dimensional subspace is a pure state. Consequently, it satisfies $\hat{\rho}_A (\Psi)^2 = \ket{e_0}\braket{e_0|e_0}\bra{e_0} = \hat{\rho}_A (\Psi)$. Similarly, it follows that $\hat{\rho}_B (\Psi) = \ket{f_0} \bra{f_0}$, proving that $\hat{\rho}_B (\Psi)$ is a pure state as well.

**($\impliedby$):** Let $\hat{\rho}_A (\Psi)$ be a pure state. Then there exists a unit vector $\ket{\varphi}\in\mathcal{H}_A$ such that $\hat{\rho}_A (\Psi) = \ket{\varphi}\bra{\varphi}$. This density operator $\hat{\rho}_A (\Psi)$ has a single eigenvector with eigenvalue $1$ and a degenerate eigenvalue $0$. According to the Schmidt decomposition, the vector $\ket{\Psi}$ then has the form $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}$ with unit vectors $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$. The same argument apply if $\hat{\rho}_B (\Psi)$ is assumed as a pure state.
</details>
</MathBox>

Two systems $\mathcal{S}_1$ and $\mathcal{S}_2$ are entangled with respect to a certain degree of freedom if their total state $\ket{\Psi}_{12}$, relative to that degree of freedom, cannot be factored into a product of individual states, i.e. $\ket{\Psi}_{12} = \ket{\psi}_1 \otimes\ket{\varphi}_2$.

In simpler terms, an entangled state describes a situation where the quantum state of the entire system cannot be separated into independent states for each subsystem. This means that the subsystems are not probabilistically independent, and the measurement outcomes of one system can affect the other, even when they are spatially separated.

It's important to note that entanglement implies superposition, but the reverse is not true. In other words, while entangled states always involve superposition, not all superpositions are necessarily entangled.

On the other hand, a state $\hat{\rho}$ is separable (i.e., non-entangled) if it can be written as a statistical mixture of product states:

$$
  \hat{\rho} = \sum_j w_j \hat{\rho}_1^{(j)} \otimes \hat{\rho}_2^{(j)}
$$

where $w_j \geq 0$ and $\sum_j w_j = 1$ with the $w_j$ representing probabilities of the different product states $\hat{\rho}_1^{(j)}$ and $\hat{\rho}_2^{(j)}$ for subsystems $\mathcal{S}_1$ and $\mathcal{S}_2$ respectively. In such a separable state, the subsystems are described by independent statistical mixtures, and no non-classical correlations (like entanglement) exist between them.

### Bell basis

The Bell basis forms an orthonormal basis for the four-dimensional Hilbert space ${}^\P \mathcal{H}^{\otimes 2}$ and consists of the Bell states

$$
\begin{align*}
  \ket{\Phi^\pm} :=& \frac{1}{\sqrt{2}} \left(\ket{00} \pm \ket{11}\right) \\
  \ket{\Psi^\pm} :=& \frac{1}{\sqrt{2}} \left(\ket{01} \pm \ket{10}\right) 
\end{align*}
$$

The Bell basis describe a maximally entangled system.

<details>
<summary>Details</summary>

To see that the Bell basis orthonormal we verify that the basis vectors are normalized and orthogonal.

**Normalization**

Computing the norm of $\ket{\Phi^\pm}$

$$
\begin{align*}
  \braket{\Phi^\pm |\Phi^\pm} =& \frac{1}{2} \braket{00 \pm 11|00 \pm 11} \\
  =& \frac{1}{2} \left(\braket{00|00} \pm \braket{11|00} \pm \braket{00|11} + \braket{11|11}\right) \\
  =& \frac{1}{2} (\underbrace{\braket{0|0}}_{=1}\braket{0|0} \pm \underbrace{\braket{1|0}}_{=0} \braket{1|0} \pm \underbrace{\braket{0|1}}_{=0} \braket{0|1} + \underbrace{\braket{1|1}}_{=1} \braket{1|1}) \\
  =& 1
\end{align*}
$$

Computing the norm of $\ket{\Psi^\pm}$

$$
\begin{align*}
  \braket{\Psi^\pm |\Psi^\pm} =& \frac{1}{2} \braket{01 \pm 10|01 \pm 10} \\
  =& \frac{1}{2} \left(\braket{01|01} \pm \braket{01|10} \pm \braket{10|01} + \braket{10|10}\right) \\
  =& \frac{1}{2} (\underbrace{\braket{0|0}\braket{1|1}}_{=1} \pm \underbrace{\braket{0|1} \braket{1|0}}_{=0} \pm \underbrace{\braket{1|0}\braket{0|1}}_{=0} + \underbrace{\braket{1|1}\braket{0|0}}_{=1}) \\
  =& 1
\end{align*}
$$

**Orthogonality**

Computing the inner product of $\braket{\Phi^+|\Phi^-}$

$$
\begin{align*}
  \braket{\Phi^+|\Phi^-} =& \frac{1}{2}\braket{00 + 11|00 - 11} \\
  =& \frac{1}{2}\left(\braket{00|00} - \braket{00|11} + \braket{11|00} - \braket{11|11}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{0|0}}_{=1} - \underbrace{\braket{0|1}\braket{0|1}}_{=0} + \underbrace{\braket{1|0}\braket{1|0}}_{=0} - \underbrace{\braket{1|1}\braket{1|1}}_{=1}) \\
  =& 0
\end{align*}
$$

Computing the inner product $\braket{\Psi^+|\Psi^-}$

$$
\begin{align*}
  \braket{\Psi^+|\Psi^-} =& \frac{1}{2}\braket{01 + 10|01 - 10} \\
  =& \frac{1}{2}\left(\braket{01|01} - \braket{01|10} + \braket{10|01} - \braket{10|10}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{1|1}}_{=1} - \underbrace{\braket{0|1}\braket{1|0}}_{=0} + \underbrace{\braket{1|0}\braket{0|1}}_{=0} - \underbrace{\braket{1|1}\braket{0|0}}_{=1}) \\
  =& 0
\end{align*}
$$

Computing the inner product $\braket{\Phi^\pm|\Psi^\pm}$

$$
\begin{align*}
  \braket{\Phi^\pm|\Psi^\pm} =& \frac{1}{2}\braket{00 \pm 11|01 \pm 10} \\
  =& \frac{1}{2}\left(\braket{00|01} \pm \braket{00|10} \pm \braket{11|01} + \braket{11|10}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{0|1}}_{=0} \pm \underbrace{\braket{0|1}\braket{0|0}}_{=0} \pm \underbrace{\braket{1|0}\braket{1|1}}_{=0} + \underbrace{\braket{1|1}\braket{1|0}}_{=0}) \\
  =& 0
\end{align*}
$$

Computing the inner product of $\braket{\Phi^\mp|\Psi^\pm}$

$$
\begin{align*}
  \braket{\Phi^\mp|\Psi^\pm} =& \frac{1}{2}\braket{00 \mp 11|01 \pm 10} \\
  =& \frac{1}{2}\left(\braket{00|01} \pm \braket{00|10} \mp \braket{11|01} - \braket{11|10}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{0|1}}_{=0} \pm \underbrace{\braket{0|1}\braket{0|0}}_{=0} \mp \underbrace{\braket{1|0}\braket{1|1}}_{=0} - \underbrace{\braket{1|1}\braket{1|0}}_{=0}) \\
  =& 0
\end{align*}
$$
</details>

The spin operators $\hat{\sigma}_j^{(A)} \otimes \hat{\sigma}_j^{(B)}$ act on the Bell basis of the composite system ${}^\P \mathcal{H}_{AB} = {}^\P \mathcal{H} \otimes {}^\P \mathcal{H}$ in the following way

$$
\begin{align*}
  (\hat{\sigma}_x \otimes \hat{\sigma}_x) \ket{\Phi^\pm} =& \pm\ket{\Phi}, \quad (\hat{\sigma}_x \otimes \hat{\sigma}_x) \ket{\Psi^\pm} =& \pm\ket{\Psi} \\
  (\hat{\sigma}_x \otimes \hat{\sigma}_y) \ket{\Phi^\pm} =& -\ket{\Phi^\mp}, \quad (\hat{\sigma}_x \otimes \hat{\sigma}_y) \ket{\Psi^\pm} =& \pm\ket{\Psi^\pm} \\
  (\hat{\sigma}_z \otimes \hat{\sigma}_z) \ket{\Phi^\pm} =& \ket{\Phi}, \quad (\hat{\sigma}_z \otimes \hat{\sigma}_z) \ket{\Psi^\pm} =& -\ket{\Psi}
\end{align*}
$$

<details>
<summary>Details</summary>

Calculating $(\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Phi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Phi^\pm} =& (\hat{\sigma}_x \otimes \hat{\sigma}_x) \frac{1}{\sqrt{2}}(\ket{00} \pm\ket{11}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \otimes \hat{\sigma}_x)(\ket{0} \otimes \ket{0} \pm \ket{1} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \ket{0} \otimes \hat{\sigma}_x \ket{0} \pm \hat{\sigma}_x \ket{1} \otimes \hat{\sigma}_x \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\ket{1} \otimes \ket{1} \pm \ket{0} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\ket{11}\pm\ket{00}) = \pm\ket{\Phi}
\end{align*}
$$

Calculating $(\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Psi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Psi^\pm} =& (\hat{\sigma}_x \otimes \hat{\sigma}_x) \frac{1}{\sqrt{2}}(\ket{01} \pm\ket{10}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \otimes \hat{\sigma}_x)(\ket{0} \otimes \ket{1} \pm \ket{1} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \ket{0} \otimes \hat{\sigma}_x \ket{1} \pm \hat{\sigma}_x \ket{1} \otimes \hat{\sigma}_x \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\ket{1} \otimes \ket{0} \pm \ket{0} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\ket{10}\pm\ket{01}) = \pm\ket{\Phi^\pm}
\end{align*}
$$

Calculating $(\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Phi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Phi^\pm} =& (\hat{\sigma}_y \otimes \hat{\sigma}_y) \frac{1}{\sqrt{2}}(\ket{00} \pm\ket{11}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \otimes \hat{\sigma}_y)(\ket{0} \otimes \ket{0} \pm \ket{1} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \ket{0} \otimes \hat{\sigma}_y \ket{0} \pm \hat{\sigma}_y \ket{1} \otimes \hat{\sigma}_y \ket{1}) \\
  =& \frac{1}{\sqrt{2}} [i\ket{1} \otimes i\ket{1} \pm (-i\ket{0}) \otimes (-i\ket{0})] \\
  =& \frac{1}{\sqrt{2}} (-\ket{11} \mp \ket{00}) = -\ket{\Phi^\mp}
\end{align*}
$$

Calculating $(\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Psi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Psi^\pm} =& (\hat{\sigma}_y \otimes \hat{\sigma}_y) \frac{1}{\sqrt{2}}(\ket{01} \pm\ket{10}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \otimes \hat{\sigma}_y)(\ket{0} \otimes \ket{1} \pm \ket{1} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \ket{0} \otimes \hat{\sigma}_y \ket{1} \pm \hat{\sigma}_y \ket{1} \otimes \hat{\sigma}_y \ket{0}) \\
  =& \frac{1}{\sqrt{2}} [i\ket{1} \otimes (-i\ket{0}) \pm (-i\ket{0}) \otimes i\ket{1}] \\
  =& \frac{1}{\sqrt{2}} (\ket{10} \pm \ket{01}) = \pm\ket{\Psi^\pm}
\end{align*}
$$

Calculating $(\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Phi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Psi^\pm} =& (\hat{\sigma}_z \otimes \hat{\sigma}_z) \frac{1}{\sqrt{2}}(\ket{00} \pm\ket{11}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \otimes \hat{\sigma}_z)(\ket{0} \otimes \ket{0} \pm \ket{1} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \ket{0} \otimes \hat{\sigma}_z \ket{0} \pm \hat{\sigma}_z \ket{1} \otimes \hat{\sigma}_z \ket{1}) \\
  =& \frac{1}{\sqrt{2}} [\ket{0} \otimes \ket{0} \pm (-\ket{1}) \otimes (-\ket{1})] \\
  =& \frac{1}{\sqrt{2}} (\ket{00} \pm \ket{11}) = \ket{\Psi^\pm}
\end{align*}
$$

Calculating $(\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Psi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Psi^\pm} =& (\hat{\sigma}_z \otimes \hat{\sigma}_z) \frac{1}{\sqrt{2}}(\ket{01} \pm\ket{10}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \otimes \hat{\sigma}_z)(\ket{0} \otimes \ket{1} \pm \ket{1} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \ket{0} \otimes \hat{\sigma}_z \ket{1} \pm \hat{\sigma}_z \ket{1} \otimes \hat{\sigma}_z \ket{0}) \\
  =& \frac{1}{\sqrt{2}} [\ket{0} \otimes (-\ket{1}) \pm (-\ket{1}) \otimes \ket{0}] \\
  =& \frac{1}{\sqrt{2}} (-\ket{01} \mp \ket{10}) = -\ket{\Psi^\pm}
\end{align*}
$$
</details>

In the Bell basis, the operators $\hat{\sigma}_x \otimes \hat{\sigma}_x$ and $\hat{\sigma}_z \otimes \hat{\sigma}_z$ have matrix representations

$$
  \hat{\sigma}_x \otimes \hat{\sigma}_x = \left[\begin{smallmatrix} 
    1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{smallmatrix}\right]
  ,\quad 
  \hat{\sigma}_z \otimes \hat{\sigma}_z = \left[\begin{smallmatrix} 
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & -1 & 0 \\
    0 & 0 & 0 & -1
  \end{smallmatrix}\right]
$$

from which it is evident that these operators commute, i.e. $[\hat{\sigma}_x \otimes \hat{\sigma}_x, \hat{\sigma}_z \otimes \hat{\sigma}_z] = 0$.

In a composite system ${}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$, the Bell basis vectors have partial traces

$$
  \hat{\rho}_A (\Phi^\pm) = \hat{\rho}_A (\Psi^\pm) = \frac{1}{2}(\ket{0}_A \bra{0} + \ket{1}_A \bra{1}) = \frac{1}{2}\hat{I}_A
$$

and

$$
  \hat{\rho}_B (\Phi^\pm) = \hat{\rho}_A (\Psi^\pm) = \frac{1}{2}(\ket{0}_B \bra{0} + \ket{1}_B \bra{1}) = \frac{1}{2}\hat{I}_B
$$

<details>
<summary>Details</summary>

In the Bell basis, the partial trace coefficients are

$$
\begin{align*}
  \Phi_{00}^\pm = \pm\Phi_{11}^\pm = \Psi_{01}^\pm = \pm\Psi_{10}^\pm =& \frac{1}{\sqrt{2}} \\
  \Phi_{01}^\pm = \pm\Phi_{10}^\pm = \Psi_{00}^\pm = \pm\Psi_{11}^\pm =& 0
\end{align*}
$$

The partial trace of $\ket{\Phi^\pm}$ over $\mathcal{H}_X$ for $X\in\set{A,B}$ is

$$
\begin{align*}
  \hat{\rho}_X (\ket{\Phi^\pm}) =& (\overline{\Phi_{00}^\pm} \Phi_{00}^\pm + \underbrace{\overline{\Phi_{01}^\pm} \Phi_{01}^\pm}_{=0}) \ket{0}^X \bra{0} \\
  +& (\overline{\Phi_{00}^\pm} \underbrace{\Phi_{10}^\pm}_{=0} + \underbrace{\overline{\Phi_{01}^\pm}}_{=0} \Phi_{11}^\pm) \ket{1}^X \bra{0} \\
  +& (\underbrace{\overline{\Phi_{10}^\pm}}_{=0} \Phi_{00}^\pm + \overline{\Phi_{11}^\pm} \underbrace{\Phi_{01}^\pm}_{=0}) \ket{0}^X \bra{1} \\
  +& (\underbrace{\overline{\Phi_{10}^\pm} \Phi_{10}^\pm}_{=0} + \overline{\Phi_{11}^\pm} \Phi_{11}) \ket{1}^X \bra{1} \\
  =& \frac{1}{2}(\ket{0}^X \bra{0} + \ket{1}^X \bra{1})
\end{align*}
$$

The partial trace of $\ket{\Psi^\pm}$ over $\mathcal{H}_X$ for $X\in\set{A,B}$ is

$$
\begin{align*}
  \hat{\rho}_X (\ket{\Psi^\pm}) =& (\underbrace{\overline{\Psi_{00}^\pm} \Psi_{00}^\pm}_{=0} + \overline{\Psi_{01}^\pm} \Psi_{01}^\pm) \ket{0}^X \bra{0} \\
  +& (\overline{\underbrace{\Psi_{00}^\pm}}_{=0} \Psi_{10}^\pm + \overline{\Psi_{01}^\pm} \underbrace{\Psi_{11}^\pm}_{=0}) \ket{1}^X \bra{0} \\
  +& (\overline{\Psi_{10}^\pm} \underbrace{\Psi_{00}^\pm}_{=0} + \underbrace{\overline{\Psi_{11}^\pm}}_{=0} \Psi_{01}^\pm) \ket{0}^X \bra{1} \\
  +& (\overline{\Psi_{10}^\pm} \Psi_{10}^\pm + \underbrace{\overline{\Psi_{11}^\pm} \Psi_{11}}_{=0}) \ket{1}^X \bra{1} \\
  =& \frac{1}{2}(\ket{0}^X \bra{0} + \ket{1}^X \bra{1})
\end{align*}
$$
</details>

If $\unitvec{n}\in \mathbb{S}^2 \subset\R^3$ is unit vector, then $\ket{\Psi^-}$ can be expressed as

$$
\begin{equation*}
  \ket{\Psi^-} = \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{n}}} \otimes \ket{\downarrow_{\unitvec{n}}} - \ket{\downarrow_{\unitvec{n}}} \otimes \ket{\uparrow_{\unitvec{n}}})
\tag{\label{equation-120}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Recall that in the basis $\Set{\ket{0} = \left[\begin{smallmatrix}1 \\ 0 \end{smallmatrix}\right], \ket{1} = \left[\begin{smallmatrix}0 \\ 1 \end{smallmatrix}\right]}$, a qubit $\ket{\psi}\in {}^\P \mathcal{H} \cong\mathbb{C}^2$ has the general form

$$
  \ket{\psi(\theta,\phi)} := e^{-i\phi/2} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\phi/2} \sin\left(\frac{\theta}{2}\right)
$$

so that

$$
\begin{align*}
  \ket{\uparrow_{\unitvec{n}}} =& e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right)
  \ket{\downarrow_{\unitvec{n}}} =& -e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right)
\end{align*}
$$

Thus

$$
\begin{align*}
  &\ket{\uparrow_{\unitvec{n}}} \otimes \ket{\downarrow_{\unitvec{n}}} - \ket{\downarrow_{\unitvec{n}}} \otimes \ket{\uparrow_{\unitvec{n}}} \\
  =& \left[e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right)\right] \otimes \left[-e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \right] \\
  &- \left[-e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right)\right] \otimes \left[e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \right] \\
  =& e^{-i\varphi} \cos\left(\frac{\theta}{2}\right) \sin\left(\frac{\theta}{2}\right) \ket{00} + \cos^2\left(\frac{\theta}{2}\right) \ket{01} - \sin^2\left(\frac{\theta}{2}\right) \ket{10} + e^{i\varphi} \cos\left(\frac{\theta}{2}\right)\sin\left(\frac{\theta}{2}\right) \ket{11} \\
  &- \left[-e^{-i\varphi} \cos\left(\frac{\theta}{2}\right) \sin\left(\frac{\theta}{2}\right) \ket{00} - \sin^2\left(\frac{\theta}{2}\right) \ket{01} + \cos^2\left(\frac{\theta}{2}\right) \ket{10} + e^{i\varphi} \cos\left(\frac{\theta}{2}\right)\sin\left(\frac{\theta}{2}\right) \ket{11}\right] \\
  =& \left(\sin^2\left(\frac{\theta}{2}\right) + \cos^2\left(\frac{\theta}{2}\right)\right)\ket{01} - \left(\sin^2\left(\frac{\theta}{2}\right) + \cos^2\left(\frac{\theta}{2}\right)\right)\ket{10} \\
  =& \ket{01} - \ket{10} = \sqrt{2}\ket{\Psi^-}
\end{align*}
$$
</details>

### Entanglement swapping

Entanglement swapping is a phenomenon in which quantum systems become entangled without direct interaction between them. This can be illustrated as follows.

Consider a four-qubit state

$$
  \ket{\Phi}_{ABCD} \in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B \otimes {}^\P \mathcal{H}_C \otimes {}^\P \mathcal{H}_D =: \mathcal{H}_{ABCD}
$$

prepared as a separable product-state of two entangled two-qubit Bell states $\ket{\Psi^-}_{AB} \in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B =: \mathcal{H}_{AB}$ and $\ket{\Psi^-}_{CD} \in {}^\P \mathcal{H}_C \otimes {}^\P \mathcal{H}_D =: \mathcal{H}_{CD}$ such that

$$
\begin{align*}
  \ket{\Phi}_{ABCD} =& \ket{\Psi^-}_{AB} \otimes\ket{\Psi^-}_{CD} \\
  =& \frac{1}{\sqrt{2}}(\ket{01}_{AB} - \ket{10}_{AB}) \otimes \frac{1}{\sqrt{2}}(\ket{01}_{CD} - \ket{10}_{CD}) \\
  =& \frac{1}{2}(\ket{0101} - \ket{0110} - \ket{1001} + \ket{1010}) \\
  =& \frac{1}{2}(\ket{\Psi^+}_{AD} \otimes \ket{\Psi^+}_{BC} - \ket{\Psi^-}^{AD} \otimes \ket{\Psi^-}_{BC} \\
  &- \ket{\Phi^+}_{AD} \otimes \ket{\Phi^+}_{BC} + \ket{\Phi^-}_{AD} \otimes \ket{\Phi^-}_{BC}) 
\end{align*}
$$

Here, systems $A$ and $B$ may have interacted in some way to form the entangled state $\ket{\Psi^-}_{AB}$. Likewise, systems $C$ and $D$ may have interacted to form the entangled state $\ket{\Psi^-}_{CD}$. However, it is possible to prepare the entangled states $\ket{\Psi^-}_{AB}$ and $\ket{\Psi^-}_{CD}$ such that system $A$ has never interacted with either $C$ or $D$. Nevertheless, by suitable measurement in the state $\ket{\Phi}_{ABCD}$ it is possible to create entangled states in the system $AD$ composed of the subsystems $A$ and $D$. 

Since $[\hat{\sigma}_z \otimes \hat{\sigma}_z, \hat{\sigma}_x \otimes \hat{\sigma}_x] = 0$, it follows that the operators

$$
\begin{align*}
  \hat{\Sigma}_z^{(BC)} := \hat{I}_A \otimes \hat{\sigma}_z \otimes \hat{\sigma}_z \otimes \hat{I}_D \\
  \hat{\Sigma}_x^{(BC)} := \hat{I}_A \otimes \hat{\sigma}_x \otimes \hat{\sigma}_x \otimes \hat{I}_D
\end{align*}
$$

commute. Consequently, the corresponding observables, $BC$-spin in the $z$-direction and $BC$-spin in the $x$-direction, can both be measured sharply in a given state. The measurement of the these observables in the state $\ket{\Phi}_{ABCD}$ collapses the $BC$-state state to one of the states $\ket{\Psi^\pm}_{BC}$ or $\ket{\Phi^\pm}_{BC}$, depending on the values observed.

After measurement, the composite system of subsystems $AD$ and $BC$ will always be separable in the Bell basis states in $\mathcal{H}_{AD}$ and $\mathcal{H}_{BC}$. The observed $BC$-state is determined by the pair of measured values for $\hat{\Sigma}_z^{(BC)}$ and $\hat{\Sigma}_x^{(BC)}$, while the qubit-pair $AD$ becomes entangled with the observed $BC$-state. As a result, the qubits $A$ and $D$ are entangled even though they have never interacted directly.

<TableFigure caption="Determination of post-measurement state by measurement of $\hat{\Sigma}_z^{(BC)}$ and $\hat{\Sigma}_x^{(BC)}$ on $\ket{\Phi}_{ABCD}$">
| Measured value of $\hat{\Sigma}_z^{(BC)}$ | Measured value of $\hat{\Sigma}_x^{(BC)}$ | Composite state after measurement | State of subsystem $AD$ after measurement |
| --- | --- | --- | --- |
| $1$ | $1$ | $\ket{\Phi^+}_{AD} \otimes \ket{\Phi^+}_{BC}$ | $\ket{\Phi^+}_{AD}$ |
| $1$ | $-1$ | $\ket{\Phi^-}_{AD} \otimes \ket{\Phi^-}_{BC}$ | $\ket{\Phi^-}_{AD}$ |
| $-1$ | $1$ | $\ket{\Psi^+}_{AD} \otimes \ket{\Psi^+}_{BC}$ | $\ket{\Psi^+}_{AD}$ |
| $-1$ | $-1$ | $\ket{\Phi^-}_{AD} \otimes \ket{\Phi^-}_{BC}$ | $\ket{\Phi^-}_{AD}$ |
</TableFigure>

### Einstein-Podolsky-Rosen (EPR) paradox

In 1935, Albert Einstein, Boris Podolsky and Nathan Rosen (EPR) published a seminal paper arguing that quantum mechanics is incomplete by refuting the following claim:

> **EPR Claim 1:** The quantum mechanical description of a system by its state vector is complete (quantum mechanics is complete).

According to EPR, a physical theory is complete if every element of physical reality has a counterpart in the theory. In other words, physical quantities describing a physical system must correspond to pre-existing elements of reality. In their definition a physical quantity is an element of reality of a system if the value of this quantity can be predicted with certainty without having to interact with the system. From this, they concluded that *incompatible observables* cannot both be elements of reality, because their values cannot be simultaneously predicted with certainty. This statement can be formulated as:

> **EPR Claim 2:** The physical quantities of a system corresponding to two incompatible observables cannot jointly be elements of reality for that system (the values of incompatible observables are not jointly real).

EPR then showed by contraposition that the completeness of a quantum mechanics (*Claim 1*) implies that the values of incompatible observables are not jointly real (*Claim 2*). They argue that if the negation of *Claim 2* were true, the physical quantities corresponding to two incompatible observables of a system were both elements of reality of that system and thus could both be predicted with certainty, implying that quantum mechanics is incomplete, i.e.

$$
  \lnot\text{Claim 2} \implies \lnot\text{Claim 1}
$$

which is logically equivalent to the contraposition

$$
  \text{Claim 1} \implies \text{Claim 2}
$$

EPR then proceeded to prove with the help of entangled states and a 'reasonable definition of reality' that *Claim 1* actually implies the negation *Claim 2*, i.e.

$$
\begin{equation*}
  \text{Claim 1} \implies \lnot\text{Claim 2}
\tag{\label{equation-119}}
\end{equation*}
$$

This contradiction is the EPR paradox. Since both implications cannot be simultaneously true, EPR concluded that *Claim 1* must be false, meaning that quantum mechanics is incomplete. However, repeated experiments have demonstrated that $\eqref{equation-119}$ does not hold, suggesting that the reality of the considered system is 'unreasonable' in the classical sense.

#### Bohm's version of the EPR thought experiment

The following is Bohm's version of the EPR thought experiment used prove $\eqref{equation-119}$. Consider a pair of qubits in described by the entangled Bell state in ${}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$

$$
  \ket{\Phi^+} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{z}}}_A \otimes \ket{\uparrow_{\unitvec{z}}}_B + \ket{\downarrow_{\unitvec{z}}}_A \otimes \ket{\downarrow_{\unitvec{z}}}_B) = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11})
$$

where qubit $A$ is accessible to Alice and qubit $B$ to Bob. Assuming that quantum mechanics is complete (*Claim 1* holds), all predictions can be obtained from the state $\ket{\Phi^+}$. Since

$$
  \ket{\uparrow_{\unitvec{x}}}_A \otimes \ket{\uparrow_{\unitvec{x}}}_B + \ket{\downarrow_{\unitvec{x}}}_A \otimes \ket{\downarrow_{\unitvec{x}}}_B = \ket{00} + \ket{11}
$$

It follows that

$$
\begin{align*}
  \ket{\Phi}^+ =& ket{\uparrow_{\unitvec{z}}}_A \otimes \ket{\uparrow_{\unitvec{z}}}_B + \ket{\downarrow_{\unitvec{z}}}_A \otimes \ket{\downarrow_{\unitvec{z}}}_B \\
  \ket{\uparrow_{\unitvec{x}}}_A \otimes \ket{\uparrow_{\unitvec{x}}}_B + \ket{\downarrow_{\unitvec{x}}}_A \otimes \ket{\downarrow_{\unitvec{x}}}_B
\end{align*}
$$

If Alice measures the observable $\hat{\sigma}_z$ in her subsystem, she effectively measures of $\hat{\sigma}_z \otimes \hat{I}_B$ in the composite system. The eigenvalues of this composite observables are $\pm 1$ with corresponding degenerate eigenspaces

$$
\begin{align*}
  \operatorname{eig}(\hat{\sigma}_z, 1) =& \operatorname{span}\set{\ket{\uparrow_{\unitvec{z}}} \otimes\ket{\psi} : \ket{\psi}\in {}^\P \mathcal{H}_B} \\
  \operatorname{eig}(\hat{\sigma}_z, -1) =& \operatorname{span}\set{\ket{\downarrow_{\unitvec{z}}} \otimes\ket{\psi} : \ket{\psi}\in {}^\P \mathcal{H}_B}
\end{align*}
$$

The projections onto these eigenspaces are

$$
\begin{align*}
  \hat{P}_{z,1} = \ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}} \otimes \hat{I}_B \\
  \hat{P}_{z,-1} = \ket{\downarrow_{\unitvec{z}}} \bra{\downarrow_{\unitvec{z}}} \otimes \hat{I}_B
\end{align*}
$$

which satisfy

$$
\begin{align*}
  \hat{P}_{z,1} =& \ket{\Phi^+} = \frac{1}{\sqrt{2}}\left((\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\otimes\hat{I}_B)(\ket{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}} + \ket{\downarrow_{\unitvec{z}}}\otimes\ket{\downarrow_{\unitvec{z}}}) \right) \\
  =& \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{z}}} \underbrace{\braket{\uparrow_{\unitvec{z}}|\uparrow_{\unitvec{z}}}}_{=1} \otimes \ket{\uparrow_{\unitvec{z}}} + \ket{\uparrow_{\unitvec{z}}}\underbrace{\braket{\uparrow_{\unitvec{z}}|\downarrow_{\unitvec{z}}}}_{=0} \otimes\ket{\downarrow_{\unitvec{z}}}) \\
  =& \frac{1}{\sqrt{2}} \ket{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}}
\end{align*}
$$

and similarly

$$
  \hat{P}_{z,-1} = \ket{\Phi^+} = \frac{1}{\sqrt{2}}\ket{\downarrow_{\unitvec{z}}}\otimes\ket{\downarrow_{\unitvec{z}}}
$$

with norm

$$
  \norm{\hat{P}_{z,\pm 1}} = \frac{1}{\sqrt{2}}
$$

If Alice measures $\hat{\sigma}_z$ in her subsystem and obtains $1$, the composite system collapses to

$$
\begin{align*}
  \ket{\Psi_{z,1}} :=& \frac{\hat{P}_{z,1}\ket{\Phi^+}}{\norm{\hat{P}_{z,1}\ket{\Phi^+}}} \\
  =& \frac{(\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}{\Norm{(\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}} \\
  =& \ket{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}}
\end{align*}
$$

This means that Bob's qubit is in state

$$
\begin{align*}
  \hat{\rho}_B (\ket{\Psi_{z,1}}\bra{\Psi_{z,1}}) =& \operatorname{tr}_A (\ket{\Psi_{z,1}}\bra{\Psi_{z,1}}) \\
  =& \operatorname{tr}\left((\ket{\uparrow_{\unitvec{z}}} \otimes \ket{\uparrow_{\unitvec{z}}})(\ket{\uparrow_{\unitvec{z}}} \otimes \ket{\uparrow_{\unitvec{z}}}) \right) \\
  =& \operatorname{tr}\left(\ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\right) \\
  =& \underbrace{\operatorname{tr}(\ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}})}_{=1}\ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}} \\
  =& \ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}}
\end{align*}
$$

which is the density operator of the pure state $\ket{\uparrow_{\unitvec{z}}}$. Hence, after a measurement of $\hat{\sigma}_z$ in which Alice observes the value $1$, Bob's system has to be in the state $\ket{\uparrow_{\unitvec{z}}}$ with sharp eigenvalue $1$. Analogously, if Alice measures $\hat{\sigma}_z$ on her qubit and observes the value $-1$, then the composite system collapses to

$$
\begin{align*}
  \ket{\Psi_{z,-1}} :=& \frac{\hat{P}_{z,1}\ket{\Phi^+}}{\norm{\hat{P}_{z,1}\ket{\Phi^+}}} \\
  =& \frac{(\ket{\downarrow_{\unitvec{z}}}\bra{\downarrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}{\Norm{(\ket{\downarrow_{\unitvec{z}}}\bra{\downarrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}} \\
  =& \ket{\downarrow_{\unitvec{z}}}\otimes\ket{\downarrow_{\unitvec{z}}}
\end{align*}
$$

In this case, Bob's system has to be in the state $\ket{\downarrow_{\unitvec{z}}}$ with eigenvalue $-1$. Consequently,the spin in $z$-direction is an element of reality for Bob's qubit.

If, however, Alice chooses instead to measure $\hat{\sigma}_x$ and observes the value $1$, then the composite system collpases to 

$$
\begin{align*}
  \ket{\Psi_{x,-1}} :=& \frac{\hat{P}_{x,1}\ket{\Phi^+}}{\norm{\hat{P}_{x,1}\ket{\Phi^+}}} \\
  =& \frac{(\ket{\downarrow_{\unitvec{x}}}\bra{\downarrow_{\unitvec{x}}}\otimes\hat{I}_B)\ket{\Phi^+}}{\Norm{(\ket{\downarrow_{\unitvec{x}}}\bra{\downarrow_{\unitvec{x}}}\otimes\hat{I}_B)\ket{\Phi^+}}} \\
  =& \ket{\downarrow_{\unitvec{x}}}\otimes\ket{\downarrow_{\unitvec{x}}}
\end{align*}
$$

In this case Bob's qubit will be in the state $\ket{\uparrow_{\unitvec{x}}}$ with sharp eigenvalue $1$. Similarly, if Alice measures $\hat{\sigma}_x$ and observes the value $-1$, then Bob's qubit after a measurement will be in the state $\ket{\downarrow_{\unitvec{x}}}$ with sharp eigenvalue $-1$. Thus, if Alice measures $\hat{\sigma}_x$ on her qubit, then for Bob's qubit, the spin in $x$-direction is an element of reality.

Regardless in which direction Alice measures the spin of her qubit, the corresponding spin component of Bob's qubit can always be predicted with certainty. This means that Alice's choice of measuring the spin of her qubit in $z$- or $x$-direction determines whether the spin in $z$- or $x$-direction is an element of its reality for Bob's qubit. Importantly, this also holds when Alice and Bob are separated in such a way that no signal from Alice traveling at the speed of light could inform Bob's qubit of Alice's measurement choice in time. 

EPR argued that noe reasonable definition of reality should permit measurement choices at one loccation to instantenously determine elements of reality at another, spatially separated location. If one accepts this argument then $\eqref{equation-119}$ would be proven, implying that quantum mechanics is incomplete. One resolution could be the existence of hidden variables, additional parameters determining the system's behaviour but not reveal by a quantum state vector.

However, experiments have shown that the physical reality behaves in an 'unreasonable' manner according to EPR's crieria. Specifically, local measurements by Alice do appear to influence Bob's system instantaneously, even though no signal is transmitted. This phenomenon, called quantum non-locality, suggests that nature does not adhere to classical locality constraints, challenging the classical notion of independent reality.

### Bell inequality

Bell's inequality is based on the assumption that the results of spin measurements on two qubits can be represented as discrete random variables of a joint distribution. This implies that the observed spin values are predetermined by hidden variables. However, Bell's inequality is violated for certain entangled states. Consequently, the assumption of a joint distribution for spin values of two qubits in certain entangled states is invalid, which invalidates the equivalent assumption of hidden variables.

Consider a pair of qubits in the Hilbert space ${}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$ prepared in the Bell state

$$
  \ket{\Psi^-} = \frac{1}{\sqrt{2}}(\ket{01} - \ket{10})
$$

where qubit $A$ is sent to Alice and qubit $B$ to Bob. Alice and Bob can perform a spin measurement in any direction they choose, represented by a unit vector $\unitvec{n}\in\mathbb{S}^2 \subset \R^3$ given by

$$
  \unitvec{n}(\theta, \phi) = \begin{bmatrix} 
    \sin(\theta)\cos(\phi) \\ 
    \sin(\theta)\sin(\phi) \\
    \cos(\theta)
  \end{bmatrix}
$$

On their respective qubits, Alice and Bob measures the observables

$$
\begin{align*}
  \hat{\Sigma}_{\unitvec{n}_A}^{(A)} =& \unitvec{n}_A \cdot\boldsymbol{\sigma} \\
  \hat{\Sigma}_{\unitvec{n}_B}^{(B)} =& \unitvec{n}_B \cdot\boldsymbol{\sigma}
\end{align*}
$$

The respective measurement results, denoted $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$, are discrete random variables parametrized by $\hat{\mathbf{n}_A}$ and $\hat{\mathbf{n}_B}$, respectively, which can only take values in $\set{\pm 1}$.

The expectation value of the joint measurement $\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}$ in the Bell state $\ket{\Psi^-}$ is given by

$$
\begin{equation*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} = -\unitvec{n}_A \cdot \unitvec{n}_B
\tag{\label{equation-129}}
\end{equation*}
$$

<details>
<summary>Details</summary>

From $\eqref{equation-120}$, we can write $\ket{\Psi^-}$ as

$$
  \ket{\Psi^-} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}})
$$

with $\hat{\Sigma}_{\unitvec{n}_A}^{(A)} = \unitvec{n}_A \cdot\boldsymbol{\sigma}$ and $\hat{\Sigma}_{\unitvec{n}_B}^{(B)} = \unitvec{n}_B \cdot\boldsymbol{\sigma}$ it then follows that

$$
\begin{align*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} =& \braket{\Psi^- |\unitvec{n}_A \cdot\boldsymbol{\sigma} \otimes \unitvec{n}_B \cdot \boldsymbol{\sigma}|\Psi^-} \\
  =& \frac{1}{\sqrt{2}} \braket{\Psi^- | \underbrace{\unitvec{n}\cdot\boldsymbol{\sigma} \ket{\uparrow}_{\unitvec{n}_A}}_{=\ket{\uparrow_{\unitvec{n}_A}}} \otimes \unitvec{n}_B \cdot\boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}_A}} - \underbrace{\unitvec{n}_A \cdot \boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}}}_{=-\ket{\downarrow_{\unitvec{n}_A}}} \otimes \unitvec{n}_B \cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}} \\
  =& \frac{1}{\sqrt{2}} \Braket{\Psi^-|(\ket{\uparrow_{\unitvec{n}_A}} \otimes \unitvec{n}_B \cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}} + \ket{\downarrow_{\unitvec{n}_A}} \otimes \unitvec{n}_B \cdot \ket{\uparrow_{\unitvec{n}_A}})}
\end{align*}
$$

In the last term we can use the identity $\eqref{equation-109}$ to get

$$
\begin{align*}
  \unitvec{n}_B \cdot\boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}_A}} =& \unitvec{n}_B \cdot (-\unitvec{n}_A \cdot\boldsymbol{\sigma}) \ket{\downarrow_{\unitvec{n}_A}} \\
  =& -(\unitvec{n}_B \cdot\boldsymbol{\sigma})(\unitvec{n}_A \cdot\boldsymbol{\sigma}) \ket{\downarrow_{\unitvec{n}_A}} \\
  =& -\left((\unitvec{n}_B \cdot \unitvec{n}_A)\mathbf{I}_2 + i(\unitvec{n}_A \times \unitvec{n}_B) \cdot \boldsymbol{\sigma} \right)\ket{\downarrow_{\unitvec{n}_A}}
\end{align*}
$$

Analogously, we show that

$$
  \unitvec{n}_B \cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}_A}} = \left((\unitvec{n}_B \cdot \unitvec{n}_A)\mathbf{I}_2 + i(\unitvec{n}_A \times \unitvec{n}_B) \cdot \boldsymbol{\sigma} \right)\ket{\uparrow_{\unitvec{n}_A}}
$$

Substituting back gives

$$
\begin{align*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} =& \frac{-\unitvec{n}_B \cdot\unitvec{n}_A}{\sqrt{2}} \Braket{\Psi^-|(\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}})} \\
  &- \frac{i}{\sqrt{2}} \Braket{\Psi^- |(\ket{\uparrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}})} \\
  +& \frac{i}{\sqrt{2}} \Braket{\Psi^- |(\ket{\downarrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}})} \\
  =& -\unitvec{n}_B \cdot \unitvec{n}^A \underbrace{\braket{\Psi^-|\Psi^-}}_{=1} \\
  &- \frac{i}{2} \Braket{\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}} | \ket{\uparrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}}} \\
  &+ \frac{i}{2} \Braket{\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}} | \ket{\downarrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}} \\
  =& -\unitvec{n}_B \cdot \unitvec{n}_A \\
  &- \frac{i}{2} \left(\Braket{\ket{\downarrow_{\unitvec{n}_A}}|(\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}_A}}} + \Braket{\ket{\uparrow_{\unitvec{n}_A}}|(\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}_A}}} \right)
\end{align*}
$$

To prove $\Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} = -\unitvec{n}_B \cdot \unitvec{n}_A$, we show that in general for $\unitvec{m}, \unitvec{n} \in\mathbb{S}^2 \subset\R^3$

$$
\begin{equation*}
  \braket{\downarrow_{\unitvec{n}} |\unitvec{m} \cdot\boldsymbol{\sigma} |\downarrow_{\unitvec{n}}} + \braket{\uparrow_{\unitvec{n}} |\unitvec{m} \cdot\boldsymbol{\sigma} |\downarrow_{\unitvec{n}}} = 0
\tag{\label{equation-121}}
\end{equation*}
$$

Consider first $\unitvec{m}\cdot\ket{\uparrow_{\unitvec{n}}}$ in the orthonormal basis $\set{\ket{\uparrow_{\unitvec{n}}}, \ket{\downarrow_{\unitvec{n}}}}$:

$$
\begin{equation*}
  \unitvec{m} \cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}}} = a_{\unitvec{m}} \ket{\uparrow_{\unitvec{n}}} + b_{\unitvec{m}} \ket{\downarrow_{\unitvec{n}}}
\tag{\label{equation-124}}
\end{equation*}
$$

If $b_{\unitvec{m}} = 0$, it follows that

$$
\begin{equation*}
  \unitvec{m} \cdot \ket{\uparrow_{\unitvec{n}}} = a_{\unitvec{m}} \ket{\uparrow_{\unitvec{n}}}
\tag{\label{equation-122}}
\end{equation*}
$$

and $a_{\unitvec{m}}$ is an eigenvalue of $\unitvec{m}\cdot\boldsymbol{\sigma}$ with eigenvector $\ket{\uparrow_{\unitvec{n}}}$. From $\eqref{equation-109}$, it follows that $(\unitvec{m}\cdot\boldsymbol{\sigma})^2 = \mathbf{I}_2$, and thus the eigenvalues of $\unitvec{m}\cdot\boldsymbol{\sigma}$ are $\pm 1$. The eigenspace for the eigenvalue $-a_{\unitvec{m}}$ is one-dimensional and orthogonal to the eigenvector $\ket{\downarrow_{\unitvec{n}}}$ for the eigenvalue $a_{\unitvec{m}}$. Hence,

$$
\begin{equation*}
  \unitvec{m} \cdot \boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}}} = -a_{\unitvec{m}} \ket{\downarrow_{\unitvec{n}}}
\tag{\label{equation-123}}
\end{equation*}
$$

and $\eqref{equation-121}$ follows from $\eqref{equation-122}$ and $\eqref{equation-123}$. In case $b_{\unitvec{m}} \neq 0$, we obtain $\eqref{equation-124}$ because of $\braket{\ket{\downarrow_{\unitvec{n}}}|\ket{\uparrow_{\unitvec{n}}}} = 0$ giving

$$
\begin{equation*}
  \braket{\downarrow_{\unitvec{n}}|\unitvec{m}\cdot\boldsymbol{\sigma}|\downarrow_{\unitvec{n}}}
\tag{\label{equation-125}}
\end{equation*}
$$

On the other hand, because of $(\unitvec{m}\cdot\boldsymbol{\sigma})^2 = \mathbf{I}_2$ it follows from $\eqref{equation-124}$ also that

$$
\begin{align*}
  \ket{\uparrow_{\unitvec{n}}} =& a_{\unitvec{m}} \unitvec{m}\cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}}} + b_{\unitvec{m}} \unitvec{m}\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}}} \\
  =& a_{\unitvec{m}} \left(a_{\unitvec{m}} \ket{\uparrow_{\unitvec{n}}} + b_{\unitvec{m}} \right) + b_{\unitvec{m}} \unitvec{m}\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}}}
\end{align*}
$$

Taking the inner product on both side with $\bra{\downarrow_{\unitvec{n}}}$ yields

$$
\begin{equation*}
  \braket{\downarrow_{\unitvec{n}}|\unitvec{m}\cdot\boldsymbol{\sigma}|\downarrow_{\unitvec{n}}} = -a_{\unitvec{m}}
\tag{\label{equation-126}}
\end{equation*}
$$

since $\braket{\downarrow_{\unitvec{n}}|\uparrow_{\unitvec{n}}} = 0$. From $\eqref{equation-125}$ and $\eqref{equation-126}$ follows $\eqref{equation-121}$.
</details>

In particular, when Alice and Bob measure along the same direction $\unitvec{n}_A = \unitvec{n} = \unitvec{n}_B$, the expectation value becomes

$$
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} = -1
$$

Now, suppose now that the properties of each qubit are determined by a hidden variable $\omega\in\Omega$. We assume that this hidden variable provides a complete description of the qubits, meaning that the measured spin values $s_{\unitvec{n}_A}^{(A)} (\omega)$ and $s_{\unitvec{n}_B}^{(B)} (\omega)$ in any directions $\unitvec{n}_A$ and $\unitvec{n}_B$ are fully determined by $\omega$. 

If Alice knew the value of $\omega$ for her qubit, she could determine the function $s_{\unitvec{n}_A}^{(A)} (\omega)$ by sufficient measurements, thereby predicting the result of spin measurements on her qubit. The same applies for Bob. However, since $\omega$ is uknown, it is referred to as a hidden variable. We assume that each value of $\omega\in\Omega$ occurs with a probability $0 \leq \mathbb{P}(\omega) \leq 1$, satisfying

$$
  \mathbb{P}(\Omega) = \sum_\Omega \d\mathbb{P}(\omega) = 1
$$

Altogether, this means that the spin measurement values $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$ are random variables on a probability space $(\Omega, \mathscr{A}, \mathbb{P})$, parametrized by unit vectors $\unitvec{n}_A$ and $\unitvec{n}_B$. These random variables depend on the quantum state, which in our case is $\ket{\Psi^-}$. Since we consider $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$ as the measured spin values for the particles in the state $\ket{\Psi^-}$, we require that their expectation value satisfies

$$
  \mathbb{E}(s_{\unitvec{n}_A}^{(A)} s_{\unitvec{n}_B}^{(B)}) = \sum_{(s_1,s_2)\in\set{\pm 1, \pm 1}} s_1 s_2 \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = s_1 \land s_{\unitvec{n}_B}^{(B)} = s_2} = -1
$$

<MathBox title="Bell's inequality" boxType='theorem'>
Let $s_{\unitvec{n}}^{(A)}$ and $s_{\unitvec{n}}^{(B)}$ be two discrete random variables on a probability space $(\Omega,\mathscr{A},\mathbb{P})$ that are parametrized by unit vectors $\unitvec{n}\in\R^3$ and take values in $\set{\pm 1}$, i.e. for $X \in \set{A,B}$

$$
\begin{align*}
  s^{(X)} : \mathbb{S}^2 \times \Omega \to& \set{\pm 1} \\
  (\unitvec{n}, \omega) \mapsto& s_{\unitvec{n}}^{(X)}
\end{align*}
$$

and which additionally satisfy

$$
\begin{equation*}
  \mathbb{E}\left(s_{\unitvec{n}}^{(A)} s_{\unitvec{n}}^{(B)}\right) = -1,\; \forall \unitvec{n}\in\mathbb{S}^2 \subset\R^3
\tag{\label{equation-127}}
\end{equation*}
$$

Then for arbitrary unit vectors $\unitvec{n}^{(i)}$ with $i\in\set{1,2,3}$ the Bell inequality

$$
\begin{equation*}
  \left|\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(B)}\right) - \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right)\right| - \mathbb{E}\left(s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right) \leq 1
\tag{\label{equation-128}}
\end{equation*}
$$

holds.

<details>
<summary>Proof</summary>

From $\eqref{equation-127}$ it follows for arbitrary directions $\unitvec{n}$ that

$$
\begin{align*}
  -1 =& \mathbb{E}\left(s_{\unitvec{n}}^{(A)} s_{\unitvec{n}}^{(B)}\right) = \underbrace{\mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = s_{\unitvec{n}}^{(B)}}}_{1 - \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}}} - \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}} \\
  =& 1 - 2\mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}}
\end{align*}
$$

and thus

$$
  \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}} = 1
$$

Furthermore, we get

$$
\begin{align*}
  \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(B)}\right) - \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right) =& -\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)}\right) + \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right) \\
  =& \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} (s_{\unitvec{n}^{(3)}}^{(A)} - s_{\unitvec{n}^{(2)}}^{(A)})\right) \\
  \underbrace{=}_{(s_{\unitvec{n}^{(2)}}^{(A)})^2 = 1}& \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} \left[(s_{\unitvec{n}^{(3)}}^{(A)})^2 s_{\unitvec{n}^{(2)}}^{(A)} - s_{\unitvec{n}^{(2)}}^{(A)}\right]\right) \\
  =& \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)} (s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1)\right)
\end{align*}
$$

This implies the claimed inequality as follows:

$$
\begin{align*}
  \left|\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(B)}\right) - \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right)\right| =& \left|\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)} (s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1 )\right)\right| \\
  \leq& \mathbb{E}\left(\left|s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)} (s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1)\right|\right) \\
  =& \mathbb{E}\left(\left|s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)}\right|\cdot\left|s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1)\right|\right) \\
  \underbrace{=}_{|s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)}| = 1}& \mathbb{E}\left(\left|1 - s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right|\right) \\
  \underbrace{=}_{s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} \leq 1}& \mathbb{E}\left(1 - s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right) \\
  =& 1 - \mathbb{E}\left(s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right) \\
  =& 1 + \mathbb{E}\left(s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right)
\end{align*}
$$
</details>
</MathBox>

If we measure the spin in the directions

$$
  \unitvec{n}^{(1)} = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}, \quad \unitvec{n}^{(2)} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ 0 \\ \frac{1}{\sqrt{2}} \end{bmatrix}, \quad \unitvec{n}^{(3)} = \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}
$$

and substitute the corresponding quantum mechanical expectation values into $\eqref{equation-128}$, we obtain

$$
\begin{align*}
  &\left| \Braket{\hat{\Sigma}_{\unitvec{n}^{(1)}}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}^{(2)}}^{(B)}}_{\Psi^-} - \Braket{\hat{\Sigma}_{\unitvec{n}^{(1)}}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}^{(3)}}^{(B)}}_{\Psi^-}  \right| - \Braket{\hat{\Sigma}_{\unitvec{n}^{(2)}}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}^{(3)}}^{(B)}}_{\Psi^-} \\
  =& |\unitvec{n}^{(1)} \cdot \unitvec{n}^{(3)} - \unitvec{n}^{(1)} \cdot \unitvec{n}^{(3)}| + \unitvec{n}^{(2)} \cdot \unitvec{n}^{(3)} \\
  =& \left|-\frac{1}{\sqrt{2}}\right| + \frac{1}{\sqrt{2}} = \sqrt{2} > 1
\end{align*}
$$

which means that quantum mechanics predicts a violation of the Bell inequality for the state $\ket{\Psi^-}$ in the given directions.

Since hidden variable theories rely on joint probability distributions, it is natural to analyze correlations. For arbitrary unitvectors $\unitvec{n}_A$ and $\unitvec{n}_B$ we find that

$$
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{I}_B}_{\Psi^-} = 0 = \Braket{\hat{I}_A \otimes \hat{\Sigma}_{\unitvec{n}_A}^{(A)}}
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-120}$, we express $\ket{\Psi^-}$ in terms of the basis defined by $\unitvec{n} = \unitvec{n}_A$

$$
  \ket{\Psi^-} = \frac{1}{\sqrt{2}} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}})
$$

With $\hat{\Sigma}_{\unitvec{n}_A}^{(A)} = \unitvec{n}_A \cdot\boldsymbol{\sigma}$ we have

$$
\begin{align*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{I}_B}_{\Psi^-} =& \braket{\Psi^- |\unitvec{n}_A \cdot\boldsymbol{\sigma} \otimes \hat{I}_B |\Psi^-} \\
  =& \frac{1}{\sqrt{2}} \braket{\Psi^-|\underbrace{\unitvec{n}_A \cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}}_{=\ket{\uparrow_{\unitvec{n}_A}}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \underbrace{\unitvec{n}_A \cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}}_{=-\ket{\downarrow_{\unitvec{n}_A}}} \otimes \ket{\uparrow_{\unitvec{n}_A}}} \\
  =& \frac{1}{\sqrt{2}} \braket{\Psi^-| \uparrow_{\unitvec{n}_A} \otimes \downarrow_{\unitvec{n}_A} + \downarrow_{\unitvec{n}_A} \otimes \uparrow_{\unitvec{n}_A}} \\
  =& \frac{1}{2} \braket{\uparrow_{\unitvec{n}_A} \otimes \downarrow_{\unitvec{n}_A} - \downarrow_{\unitvec{n}_A} \otimes \uparrow_{\unitvec{n}_A} | \uparrow_{\unitvec{n}_A} \otimes \downarrow_{\unitvec{n}_A} + \downarrow_{\unitvec{n}_A} \otimes \uparrow_{\unitvec{n}_A}} \\
  =& 0
\end{align*}
$$

where we used $\braket{\uparrow_{\unitvec{n}_A} | \uparrow_{\unitvec{n}_A}} = 1$ and $\braket{\uparrow_{\unitvec{n}_A} | \downarrow_{\unitvec{n}_A}} = 0$ in the last step. A similar argument shows that

$$
  \Braket{\hat{I}_A \otimes \hat{\Sigma}_{\unitvec{n}_A}^{(A)}}_{\Psi^-} = 0
$$
</details>

For the hidden variables $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$, the corresponding expectation value must satisfy

$$
  \mathbb{E}\left(s_{\unitvec{n}_A}^{(A)}\right) = 0 = \mathbb{E}\left(s_{\unitvec{n}_A}^{(A)}\right)
$$

Thus, the correlation between $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$ is given by

$$
  \operatorname{cor}\left(s_{\unitvec{n}_A}^{(A)}, s_{\unitvec{n}_A}^{(A)}\right) = \mathbb{E}\left(s_{\unitvec{n}_A}^{(A)}, s_{\unitvec{n}_A}^{(A)}\right)
$$

The correlations arising from entangled states are known as EPR-correlations.

### CHSH generalization of the Bell inequality

Just as the original Bell inequality, the generalization derived by Clause, Horne, Simony and Holt (CHSH) also considers a pair of particles on which individual measurements yielding possible values in $\set{\pm 1}$ can be performed. The key distinction is that, unlike in Bell's original derivation, no requirement of the form $\eqref{equation-127}$ needs to be made. Additionally it establishes an upper bound for expectation values of products of observable single-particle measurements.

Consider a pair of particles, one accessible to Alice and the other to Bob. Unlike in Bell's original formulation, the observables they measure are not restricted to those identified by a direction $\unitvec{n}\in\R^3$. Instead, Alice and Bob can choose their measurement using (possibly multi-dimensional) parameters $\mathbf{p}_A \in P_A$ and $\mathbf{p}_B \in P_B$, respectively. This means they measure respective observables $\hat{S}_{\mathbf{p}_A}^{(A)}$ and $\hat{S}_{\mathbf{p}_B}^{(B)}$, each taking values $\pm 1$. 

Now, suppose each particle is completely described by a hidden variable $\omega\in\Omega$, which determine the measurement outcomes $s_{\mathbf{p}_A}^{(A)}$ and $s_{\mathbf{p}_B}^{(B)}$. These outcomes, corresponding to the chosen measurement settings $\mathbf{p}_A$ and $\mathbf{p}_B$ are treated as parametrized random variables with a joint distribution on a probability space $(\Omega,\mathscr{A},\mathbb{P})$.

<MathBox title='' boxType='lemma' tag='lemma-1'>
Let $s_i: \Omega\to\set{\pm 1}$ for $i\in{1,2,3,4}$ be four discrete random variables on a probability space $(\Omega,\mathscr{A},\mathbb{P})$ that can take only the values in $\set{\pm 1}$. Then the following inequality holds

$$
  \left|\mathbb{E}(s_1 s_2) - \mathbb{E}(s_1 s_3) + \mathbb{E}(s_2 s_3) + \mathbb{E}(s_3 s_4) \right| \leq 2
$$

<details>
<summary>Proof</summary>

Since $s_i (\omega) \in\set{\pm 1}$ for all $\omega\in\Omega$ and $i\in\set{1,2,3,4}$, it follows that either

$$
  s_2 (\omega) - s_3(\omega) \implies s(\omega) + s_3 (\omega) = \pm 2
$$

or

$$
  s_2 (\omega) + s_3(\omega) \implies s(\omega) - s_3 (\omega) = \pm 2
$$

an

$$
  s_1 (\omega) [s_2 (\omega) - s_3 (\omega)] + s_4 (\omega) [s_2 (\omega) + s_3 (\omega)] = \pm 2
$$

This implies

$$
  |s_1 (\omega) [s_2 (\omega) - s_3 (\omega)] + s_4 (\omega) [s_2 (\omega) + s_3 (\omega)]| \leq 2
$$

and by linearity of expectation it follows that

$$
\begin{align*}
  &\left|\mathbb{E}(s_1 s_2) - \mathbb{E}(s_1 s_3) + \mathbb{E}(s_2 s_3) + \mathbb{E}(s_3 s_4) \right| \\
  &=|\mathbb{E}\left(s_1 (\omega) [s_2 (\omega) - s_3 (\omega)] + s_4 (\omega) [s_2 (\omega) + s_3 (\omega)]\right)| \leq 2
\end{align*}
$$
</details>
</MathBox>

<MathBox title='CHSH inequality' boxType='theorem'>
Let $s_\mathbf{p}^{(A)}$ and $s_\mathbf{p}^{(B)}$ be two discrete random variables on a probability space $(\Omega,\mathscr{A},\mathbb{P})$, taking values in $\set{\pm 1}$ and parametrized by $\mathbf{p}\in P$, i.e. for $X \in\set{A,B}$

$$
\begin{align*}
  s^X : P\times\Omega \to& \set{1 \pm} \\
  (\mathbf{p},\omega) \mapsto& s_\mathbf{p}^{(X)}
\end{align*}
$$

Then for arbitrary parameters $\mathbf{p}_1,\dots,\mathbf{p}_4 \in P$ the following generalization of the Bell inequality holds

$$
\begin{equation*}
  \left|\mathbb{E}(s_{\mathbf{p}_1}^{(A)} s_{\mathbf{p}_2}^{(B)}) - \mathbb{E}(s_{\mathbf{p}_1}^{(A)} s_{\mathbf{p}_3}^{(B)}) + \mathbb{E}(s_{\mathbf{p}_4}^{(A)} s_{\mathbf{p}_2}^{(B)}) + \mathbb{E}(s_{\mathbf{p}_4}^{(A)} s_{\mathbf{p}_3}^{(B)}) \right| \leq 2
\tag{\label{equation-130}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

This follows immediately from Lemma $\ref{lemma-1}$ by setting $s_i = s_{\mathbf{p}_i}^{(A)}$ for $i\in\set{1,4}$ and $s_i = s_{\mathbf{p}_i}^{(B)}$ for $i\in\set{2,3}$.
</details>
</MathBox>

Consider two particles in the entangled Bell state $\ket{\Psi^-}$. Let the observables $\hat{S}_{\mathbf{p}_i}^{(X)}$ correspond to the spin observables along directions $\unitvec{n}_X$, defined as

$$
  \hat{\Sigma}_{\unitvec{n}_i}^{(X)} = \unitvec{n}_X \cdot\boldsymbol{\sigma}, \; X\in\set{A,B},\; i\in{1,\dots,4}
$$

We choose measurement directions in the $(x,z)$-plane, given by

$$
  \unitvec{n}_i = \begin{bmatrix} \cos(\nu_i) \\ 0 \\ \sin(\nu_i) \end{bmatrix} \in \mathbb{S}^2, \; i\in\set{1,\dots,4}
$$

From $\eqref{equation-129}$, it follows that

$$
\begin{align*}
  &\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-} \\
  =& -\cos(\nu_1 - \nu_2) + \cos(\nu_1 - \nu_3) - \cos(\nu_4 - \nu_2) - \cos(\nu_4 - \nu_3)
\end{align*}
$$

Choosing the specific directions

$$
  \nu_1 = \frac{3\pi}{4}, \quad \nu_2 = \frac{\pi}{2}, \quad \nu_3 = 0, \quad \nu_4 = \frac{\pi}{4}
$$

we obtain

$$
\begin{equation*}
  \left|\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-}\right| = 2\sqrt{2} > 2
\tag{\label{equation-131}}
\end{equation*}
$$

which contradicts the CHSH inequality $\eqref{equation-130}$. 

#### Aspect, Dalibard and Roger experiment

An experiment conducted by Aspect, Dalibard and Roger confirmed the violation of the CHSH inequality. Their setup involved a source emitting two entangled photons via a cascade transition, with one photon sent to Alice and the other to Bob. The photons traveled for approximately $40$ ns before reaching their respective measurement devices. During this travel time
- Alice independently choose to measure either $\hat{\Sigma}_{\unitvec{n}_1}^{(A)}$ or $\hat{\Sigma}_{\unitvec{n}_4}^{(A)}$. The switching time between these observables was at most $10$ ns.
- Bob independently choose to measure either $\hat{\Sigma}_{\unitvec{n}_2}^{(B)}$ or $\hat{\Sigma}_{\unitvec{n}_3}^{(B)}$.

A coincidence filter ensured that only photon pairs originating from the same cascade were considered. The detectors registered one of the two possible outcomes, $\pm 1$, for each photon.

Let $M_{i,j}^{A,B}$ for $i,j\in\set{1,\dots,4}$ be the set of measurements where $\hat{\Sigma}_{\unitvec{n}_i}^{(A)}$ and $\hat{\Sigma}_{\unitvec{n}_j}^{(B)}$ were measured. Define $N_{i,j}^{A,B}$ as the number of such measurements, and let $s_{\unitvec{n}_i}^{(X)} (l)$ for $X\in\set{A,B}$ denote the observed outcome in measurement $l\in M_{i,j}^{A,B}$. The empirical expectation values, denoted $\overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}}$, are computed as

$$
  \overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}} = \frac{1}{N_{i,j}^{A,B}} \sum_{l\in M_{i,j}^{A,B}} s_{\unitvec{n}_i}^{(A)} (l) s_{\unitvec{n}_j}^{(B)} (l)
$$

Inserting the empirical expectation values $\overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}}$ as approximations of the quantum mechanical expectation values $\Braket{\hat{\Sigma}_{\unitvec{n}_i}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_j}^{(B)}}_{\Psi^-}$ confirms $\eqref{equation-131}$, and thus the quantum mechanical prediction. However, inserting $\overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}}$ into the classical expectation $\mathbb{E}[s_{\unitvec{n}_i}^{(A)} s_{\unitvec{n}_j}^{(B)}]$ reveals a violation of the Bell inequality.

Each measurement of $\hat{\Sigma}_{\unitvec{n}_i}^{(X)}$ for $X\in\set{A,B}$ and $i\in\set{1,\dots,4}$ consitently yields a value in $\set{\pm 1}$. It may seem reasonable to assume that these observables always possess definite values before measurement. If that were the case, every pair of observables $(\hat{\Sigma}_{\unitvec{n}_i}^{(A)}, \hat{\Sigma}_{\unitvec{n}_j}^{(B)})$ for $i,j\in\set{1,\dots,4}$ would always predetermined values in $\set{\pm 1, \pm 1}$, thereby ensuring the validity of the CHSH inequality. However, as shown in $\eqref{equation-131}$, this assumption is violated by quantum mechanics.

This contradiction implies that $\hat{\Sigma}_{\unitvec{n}_i}^{(A)}$ and $\hat{\Sigma}_{\unitvec{n}_j}^{(B)}$ cannot simultaneously posess definite values, even though each can be individually measured with definite outcomes. In other words, while these observables yield $\pm 1$ when measured separately, their joint values do not preexist independently of the measurement process.

Quantum mechanics predicts Bell inequality violations only for entangled states and specific measurement directions. For example, in $\ket{\Psi^-}$, if we choose spin measurements along $\unitvec{n}_2 = \unitvec{n}_3$, the quantum mechanical predicition yields $-\sqrt{2}$, satisfying the CHSH inequality. Furthermore, for separable (i.e., non-entangled) states, quantum mechanical predictions always satisfy the Bell inequality.

<MathBox title='' boxType='proposition'>
In any separable state $\ket{\varphi}\otimes\ket{\psi}\in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$ the expectation values of spin observables $\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_1}^{(B)}$ in arbitrary spin directions $\unitvec{n}_i$ with $i\in\set{1,\dots,4}$ satisfy the CHSH variant of the Bell inequality, i.e.

$$
  \left|\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi}\right| \leq 2
$$

holds.

<details>
<summary>Proof</summary>

Generally, the expectation values of products of observables $\hat{M}_A \otimes \hat{M}_B$ factorize in separable states $\ket{\varphi}\otimes\ket{\psi} \in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$, i.e.

$$
\begin{align*}
  \braket{\hat{M}_A \otimes \hat{M}_B} =& \braket{\varphi\otimes\psi|\hat{M}_A \otimes \hat{M}_B|\varphi\otimes\psi} \\
  =& \braket{\varphi\otimes\psi|\hat{M}_A \varphi \otimes \hat{M}_B \psi} \\
  =& \braket{\varphi|\hat{M}_A|\varphi}\braket{\psi|\hat{M}_B|\psi} \\
  =& \braket{\hat{M}_A}_\varphi \braket{\hat{M}_B}_\psi \tag{\label{equation-132}}
\end{align*}
$$

An arbitrary state $\ket{\varphi}\in {}^\P \mathcal{H}_A$ can be given in the form

$$
  \ket{\varphi} = e^{i\alpha} \cos(\beta)\ket{0} + e^{i\gamma} \sin(\beta)\ket{1}
$$

The spin-up state for a spin in the direction $\unitvec{n}(\theta,\phi)$ is given by

$$
  \ket{\uparrow_{\unitvec{n}(\theta,\phi)}} = e^{-i\phi/2} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\phi/2} \sin\left(\frac{\theta}{2}\right)\ket{1}
$$

such that we can write $\ket{\varphi}$ with the help of a unit vector $\unitvec{n}_\varphi := \unitvec{n}(2\beta, \frac{\gamma - \alpha}{2})$ in the form

$$
  \ket{\varphi} = e^{i(\alpha + \gamma)/2} \ket{\uparrow_{\unitvec{n}_\varphi}}
$$

The same holds for $\ket{\psi} = e^{i\delta} \ket{\uparrow_{\unitvec{n}_\psi}}$ with suitably chosen $\delta$ and $\unitvec{n}_\psi$.

Next, we show that

$$
\begin{equation*}
  \braket{\hat{\sigma}_{\unitvec{n}}}_{\uparrow_{\unitvec{m}}} = \unitvec{n}\cdot\unitvec{m}
\tag{\label{equation-133}}
\end{equation*}
$$

Since

$$
\begin{align*}
  \hat{\Sigma}_{\unitvec{n}} =& \unitvec{n}\cdot\boldsymbol{\sigma} \\
  \unitvec{m}\cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{m}}} =& \ket{\uparrow_{\unitvec{m}}} \\
  (\unitvec{m}\cdot\boldsymbol{\sigma})^\dagger =& \unitvec{m}\cdot\boldsymbol{\sigma}
\end{align*}
$$

if follows that

$$
\begin{align*}
  \braket{\hat{\sigma}_{\unitvec{n}}}_{\uparrow_{\unitvec{m}}} =& \braket{\uparrow_{\unitvec{m}}|\unitvec{n}\cdot\boldsymbol{\sigma}|\uparrow_{\unitvec{m}}} \\
  =& \frac{1}{2}\left[\Braket{(\unitvec{m}\cdot\boldsymbol{\sigma}) \uparrow_{\unitvec{m}}|(\unitvec{n}\cdot\boldsymbol{\sigma})\uparrow_{\unitvec{m}}} + \Braket{\uparrow_{\unitvec{m}}|(\unitvec{n}\cdot\boldsymbol{\sigma})(\unitvec{m}\cdot\boldsymbol{\sigma})|\uparrow_{\unitvec{m}}}\right] \\
  =& \frac{1}{2}\Braket{\uparrow_{\unitvec{m}}|(\unitvec{m}\cdot\boldsymbol{\sigma})(\unitvec{n}\cdot\boldsymbol{\sigma}) + (\unitvec{n}\cdot\boldsymbol{\sigma})(\unitvec{m}\cdot\boldsymbol{\sigma})|\uparrow_{\unitvec{m}}} \\
  =& \frac{1}{2}\Braket{\uparrow_{\unitvec{m}}|(\unitvec{m}\cdot\unitvec{n})\mathbf{I} + i((\unitvec{m}\times\unitvec{n})\cdot\boldsymbol{\sigma}) + (\unitvec{n}\cdot\unitvec{m})\mathbf{I} + i((\unitvec{n}\times\unitvec{m})\cdot\boldsymbol{\sigma})|\uparrow_{\unitvec{m}}} \\
  =& \unitvec{n}\cdot\unitvec{m} + \frac{i}{2}\braket{\uparrow_{\unitvec{n}}|\underbrace{(\unitvec{m}\times\unitvec{n} + \unitvec{n}\times\unitvec{m})}_{=0} \cdot\boldsymbol{\sigma}|\uparrow_{\unitvec{m}}} \\
  =& \unitvec{n}\cdot\unitvec{m}
\end{align*}
$$

Combining $\eqref{equation-132}$ and $\eqref{equation-133}$ yields

$$
\begin{align*}
  \braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_1}^{(B)}}_{\varphi\otimes\psi} =& \braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)}}_\varphi \braket{\hat{\Sigma}_{\unitvec{n}_1}^{(B)}}_\psi \\
  =& (\unitvec{n}_i \cdot \unitvec{n}_\varphi) (\unitvec{n}_j \cdot \unitvec{n}_\psi)
\end{align*}
$$

and thus

$$
\begin{align*}
  & \left|\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi}\right| \\
  =& \left| \unitvec{n}_1 \cdot \unitvec{n}_\varphi (\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi) + \unitvec{n}_4 \cdot \unitvec{n}_\varphi (\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi) \right| \\
  \leq& \left| \unitvec{n}_1 \cdot \unitvec{n}_\varphi\right|\cdot \left|\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi \right| + \left|\unitvec{n}_4 \cdot \unitvec{n}_\varphi\right|\cdot \left|\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi) \right| \\
  \leq& \left|(\unitvec{n}_2 - \unitvec{n}_3)\cdot\unitvec{n}_\psi \right| + \left|(\unitvec{n}_2 + \unitvec{n}_3)\cdot\unitvec{n}_\psi \right|
\end{align*}
$$

For arbitrary $x,y \in\R$, we have

$$
  |x| + |y| = \begin{cases}
    |x + y|, \quad& xy \geq 0 \\
    |x - y|, \quad& xy < 0
  \end{cases}
$$

and thus

$$
  \left|(\unitvec{n}_2 - \unitvec{n}_3)\cdot\unitvec{n}_\psi \right| + \left|(\unitvec{n}_2 + \unitvec{n}_3)\cdot\unitvec{n}_\psi \right| = 2\max\Set{\left\lvert\unitvec{n}_2 \cdot \unitvec{n}_\psi \right\rvert, \left\lvert\unitvec{n}_3 \cdot \unitvec{n}_\psi \right\rvert} \leq 2
$$
</details>
</MathBox>

### Bell telephone

The seemingly 'unreasonable' behavior of quantum mechanics, where Alice's measurement appears to instantaneously affect the state of Bob's particle‚Äîhas led some to speculate about the possibility of superluminal communication. This hypothetical communication device, often referred to as the Bell telephone, would allow Alice to send information to Bob faster than the speed of light. However, as we will now show, such a device cannot be used to transmit any information at all, not even at subluminal speeds.

The proposed Bell telephone operates as follows: Suppose Alice and Bob each possess a particle that together form the Bell state $\ket{\Phi^+}$. Alice can choose to measure her particle along different bases, thereby influencing Bob's state. Specifically:
- If Alice measures $\hat{\sigma}_z$, she projects Bob's particle into $\ket{0} = \ket{\uparrow_{\unitvec{z}}}$ or $\ket{1} = \ket{\downarrow_{\unitvec{z}}}$.
- If Alice measures $\hat{\sigma}_x$, she projects Bob's particle into $\ket{+} = \ket{\uparrow_{\unitvec{z}}}$ or $\ket{1} = \ket{\downarrow_{\unitvec{z}}}$.

Alice's idea is to send a message to Bob by encoding bits according to the measurement she performs, as outlined in the table below.

<TableFigure caption="Protocol for the Bell telephone">
| Agreed bit value | Alice measures | Bob's qubit value in the state |
| --- | --- | --- |
| $0$ | $\hat{\sigma}_z$ | $\ket{0}$ or $\ket{1}$ |
| $1$ | $\hat{\sigma}_x$ | $\ket{+}$ or $\ket{-}$ |
</TableFigure>

Bob is supposed to determine the bit Alice intended to send by checking whether his particle is in $\set{\ket{0},\ket{1}}$ or $\set{\ket{+},\ket{-}}$. However, this scheme fails because, from Bob's perspective, his particle is always in a mixed state after Alice's measurement. Mathematically, this mixed state can be expressed using either the $\set{\ket{0},\ket{1}}$ basis or $\set{\ket{+},\ket{-}}$ basis. Regardless of which observable Alice measures, Bob's reduced density matrix remains unchanged. Consequently, Bob has no way of distinguishing between the two cases, meaning he cannot infer the bit Alice intended to send.
 
Bob might attempt to determine the state of his particle by measuring either $\hat{\sigma}_z$ or $\hat{\sigma}_x$. Suppose he measures $\hat{\sigma}_z$ and observes the value $1$. He still cannot conclude that his particle was in state $\ket{0}$, since the probability to observed the value $1$ when measuring $\hat{\sigma}_z$ is also different in the states $\ket{+}$ and $\ket{-}$:

$$
  |\braket{0|+}|^2 = \frac{1}{2} = |\braket{0|-}|^2
$$

Consider a bipartite quantum system where Alice and Bob control subsystems $\mathcal{H}_A$ and $\mathcal{H}_B$, respectively. Alice has access to two distinct observables $\hat{M}_A$ and $\hat{\tilde{M}}_A$, each with a purely discrete spectrum. She encodes the classical bits $0$ nad $1$ by chooseing to measure either $\hat{M}_A$ or $\hat{\tilde{M}}$.

For simplicity, assume that the eigenvalues $\lambda_a \in\sigma(\hat{M}_A)$ and $\tilde{\lambda}_a \in\sigma(\hat{\tilde{M}}_A)$ are all non-degenerate in $\mathcal{H}_A$. The argument extends to degenerate eigenvalues, but with more cumbersome notation.

The observables $\hat{M}_A$ and $\hat{\tilde{M}}_A$ have respective orthonormal eigenbases $\set{\ket{\tilde{e}_a}| \ket{e_a} \in \operatorname{eig}(\hat{M}_A, \lambda_a)}$ and $\set{\ket{\tilde{e}_a}| \ket{\tilde{e}_a} \in \operatorname{eig}(\hat{\tilde{M}}_A, \tilde{\lambda}_a)}$ in $\mathcal{H}_A$, which are related by a unitary transformation $\hat{U}\in\mathcal{U}(\mathcal{H})$ such that

$$
\begin{equation*}
\begin{split}
  \ket{\tilde{e}_a} =& \hat{U}\ket{e_a} \\
  =& \sum_{a_1} \braket{e_{a_1}|\hat{U}|e_{a_1}}\ket{e_{a_1}} \\
  =& \sum_{a_1} \hat{U}_{a_1 a} \ket{e_{a_1}}
\end{split}\
\tag{\label{equation-138}}
\end{equation*}
$$

For Bob's system let $\set{\ket{f_b}}$ be an orthonormal basis of $\mathcal{H}_B$. The composite system $\mathcal{H}_A \otimes \mathcal{H}_B$ has orthornomal eigenbases $\set{\ket{e_a \otimes f_b}}$ corresponding to $\hat{M}_A \otimes \hat{I}_B$, and $\set{\ket{\tilde{e}_a} \otimes \ket{f_b}}$ corresponding to $\hat{\tilde{M}}_A \otimes \hat{I}_B$, so that

$$
\begin{align*}
  (\hat{M}_A \otimes \hat{I}_B) \ket{e_a \otimes f_b} =& \lambda_a \ket{e_a \otimes f_b} \\
  (\hat{\tilde{M}}_M \otimes \hat{I}_B) \ket{\tilde{e}_a \otimes f_b} =& \tilde{\lambda}_a \ket{\tilde{e}_a \otimes f_b}
\end{align*}
$$

such that $\sigma(\hat{M}_A \otimes \hat{I}_B) = \sigma(\hat{M}_A)$ as well as $\sigma(\hat{\tilde{M}}_A \otimes\hat{I}_B) = \sigma(\hat{\tilde{M}}_A)$. As an eigenvalue of the observable $\hat{M}_A \otimes\hat{I}_B$ each of these eigenvalues is $\dim(\mathcal{H}_B)$-fold degenerate, i.e. $\dim[\operatorname{eig}(\hat{M}\times\hat{I}_B), \lambda_A] = \dim(\mathcal{H}_B)$. A general eigenstate of $\hat{M}_A \otimes \hat{I}_B$ is of the form

$$
  \ket{e_a \otimes \varphi} = \sum_b \varphi_b \ket{e_a \otimes f_b}
$$

and similar statements hold for $\hat{\tilde{M}}_A \otimes\hat{I}_B$.

Let the composite system initially be prepared in the pure state

$$
\begin{equation*}
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b} = \sum_{a,b} \tilde{\Psi}_{ab} \ket{\tilde{e}_a \otimes f_b}
\tag{\label{equation-137}}
\end{equation*}
$$

If Alice measures $\hat{M}_A$ to send bit $0$, the composite system collapses into

$$
  \hat{\rho}_{\lambda_a} := \frac{\hat{P}_{\lambda_a} \hat{\rho}_\Psi \hat{P}_{\lambda_a}}{\operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a})}
$$

where $\hat{P}_{\lambda_a} = \ket{e_a} \otimes \bra{e_a}\otimes\hat{I}_B$ is the projector onto the eigenspace $\operatorname{eig}(\hat{M}_A \otimes \hat{I}_B, \lambda_a)$ and $\hat{\rho}_\Psi = \ket{\Psi}\bra{\Psi}$ is the density operator of the original pure state.

The probability to observe $\lambda_a$ and thus to end up in the state $\hat{\rho}_{\lambda_a}$, is given by $\operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a})$. For an observer unaware of the measurement outcome, including Bob, the post-measurement composite system is then described by the mixed state $\hat{\rho}$ which is a statistical ensemble of state $\hat{\rho}_{\lambda_a}$ each occuring with a probability $\operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a})$, i.e.

$$
\begin{equation*}
  \hat{\rho} = \sum_a \operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a}) = \sum_a \hat{P}_{\lambda_a} \hat{\rho}_\Psi \hat{P}_{\lambda_a}
\tag{\label{equation-136}}
\end{equation*}
$$

The mixed state, which describes Bob's sub-system after Alice's measurement of the observable $\hat{M}_A$ is given by the partial trace operator

$$
\begin{equation*}
  \hat{\rho}_B (\hat{\rho}) = \sum_{b_1, b_2} \sum_a \Psi_{ab_1} \Psi_{ab_2}^* \ket{f_{b_1}}\bra{f_{b_1}}
\tag{\label{equation-134}}
\end{equation*}
$$

<details>
<summary>Details</summary>

To derive $\eqref{equation-134}$, we have

$$
\begin{align*}
  \hat{P}_{\lambda_a}\ket{\Psi} =& (\ket{e_a}\bra{e_a} \otimes\hat{I}_B) \sum_{a_1,b} \Psi_{a_1 b} \ket{e_{a_1}} \otimes \ket{f_b} \\
  =& \sum_{a_1, b} \Psi_{a_1 b} \ket{e_a} \underbrace{\braket{e_a|e_{a_1}}}_{=\delta_{aa_1}} \otimes\ket{f_b} \\
  =& \sum_b \Psi_{ab} \ket{e_a} \otimes \ket{f_b} 
\end{align*}
$$

which implies

$$
\begin{align*}
  \hat{P}_{\lambda_a} \ket{\Psi}\bra{\Psi} \hat{P}_{\lambda_a} =& \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a} \otimes \bra{f_{b_1}} \ket{e_{a_1}} \otimes \ket{f_{b_2}} \\
  =& \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a} \bra{e_a} \otimes \ket{f_{b_1}} \bra{f_{b_2}} \tag{\label{equation-135}}
\end{align*}
$$

Inserting $\eqref{equation-135}$ into $\eqref{equation-136}$ yields

$$
  \hat{\rho} = \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a}\bra{e_a}\otimes\ket{f_{b_1}}\bra{f_{b_2}}
$$

for the density operator of the composite system. The reduced density operator for the subsystem $\mathcal{H}_B$ is given by

$$
\begin{align*}
  \hat{\rho}_B (\hat{\rho}) =& \operatorname{tr}_A (\hat{\rho}) \\
  =& \operatorname{tr}_A \left( \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a}\bra{e_a}\otimes\ket{f_{b_1}}\bra{f_{b_2}} \right) \\
  =& \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \operatorname{tr}_A \left(\ket{e_a}\bra{e_a}\otimes\ket{f_{b_1}}\bra{f_{b_2}}\right) \\
  =& \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \underbrace{\operatorname{tr}(\ket{e_a}\bra{e_a})}_{=1} \ket{f_{b_1}}\bra{f_{b_2}} \\
  =& \sum_{b_1, b_2} \sum_a \Psi_{ab_1} \Psi_{ab_2}^* \ket{f_{b_1}}\bra{f_{b_1}} 
\end{align*}
$$
</details>

Similarly, if Alice measures the observable $\hat{\tilde{M}}_A$ to send bit $1$, Bob's subsystem is in the mixed state

$$
\begin{equation*}
  \hat{\rho}_B (\hat{\tilde{\rho}}) = \sum_{b_1, b_2} \sum_a \tilde{\Psi}_{ab_1} \tilde{\Psi}_{ab_2}^* \ket{f_{b_1}}\bra{f_{b_2}}
\tag{\label{equation-139}}
\end{equation*}
$$

From $\eqref{equation-138}$ and $\eqref{equation-137}$ it follows that

$$
  \Psi_{ab} = \sum_{a_1} \mathbf{U}_{aa_1} \tilde{\Psi}_{a_1 b}
$$

and thus

$$
\begin{align*}
  \sum_a \Psi_{ab_1} \Psi_{ab_2}^* =& \sum_{a, a_1, a_2} \mathbf{U}_{aa_1} \tilde{\Psi}_{a_1 b_1} \mathbf{U}_{aa_2}^* \tilde{\Psi}_{a_2 b_2}^* \\
  =& \sum_{a, a_1, a_2} \mathbf{U}_{aa_1} \mathbf{U}_{a_2 a}^\dagger \tilde{\Psi}_{a_1 b_1} \tilde{\Psi}_{a_2 b_2}^* \\
  =& \sum_{a_1, a_2} \underbrace{(\mathbf{U}^\dagger \mathbf{U})_{a_1 a_1}}_{=\delta_{a_2 a_1}} \tilde{\Psi}_{a_1 b_1} \tilde{\Psi}_{a_2 b_2}^* \\
  =& \sum_a \tilde{\Psi}_{ab_1} \tilde{\Psi}_{ab_2}^* \tag{\label{equation-140}}
\end{align*}
$$

From $\eqref{equation-134}$ and $\eqref{equation-139}$ together with $\eqref{equation-140}$, it follows that

$$
  \hat{\rho}_B (\hat{\rho}) = \hat{\rho}_B (\hat{\tilde{\rho}})
$$

which means that Bob's subsystem is always in the same mixed state regardless of which observable Alice measures. This means that Bob has no way to infer whether Alice intended to send bit $0$ or $1$, proving that classical information cannot be transmitted in this manner.

### Perfect quantum copier

The fact that a quantum-copier does not exist, or as formulated alternatively, that quantum states cannot be cloned, is due to the linear structure of the Hilbert space $\mathcal{H}$ containing the state vectors. Given
- an arbitrary state $\ket{\psi}\in\mathcal{H}$ to be copied and
- a state $\ket{\omega}\in\mathcal{H}$ to emerge as a copy

A quantum copier $\hat{K}$ is a linear transformation that leaves the original state $\ket{\psi}$ unchanged and transforms the white-page state $\ket{\omega}$ such that it becomes the original state $\ket{\psi}$, i.e. $\hat{K}: \mathcal{H}^{\otimes 2}\to \mathcal{H}^{\otimes 2}$ is given by

$$
  \ket{\psi}\otimes\ket{\omega} \mapsto \ket{\psi}\otimes\ket{\psi}
$$

for arbitrary $\ket{\psi}\in\mathcal{H}$ and a given fixed $\ket{\omega}\in\mathcal{H}$.

<MathBox title='Quantum no-cloning theorem' boxType='theorem'>
A quantum copier cannot exist.

<details>
<summary>Proof</summary>

It suffices to consider qubits, i.e. $\mathcal{H} = {}^\P \mathcal{H}$ and the action of a quantum-copier on the qubit-states $\ket{0}$, $\ket{1}$ and $\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$. Per definition, $\hat{K}$, has to satisfy

$$
\begin{align*}
  \hat{K}(\ket{0}\otimes\ket{\omega}) =& \ket{0}\otimes\ket{0} \\
  \hat{K}(\ket{1}\otimes\ket{\omega}) =& \ket{1}\otimes\ket{1} \\
  \hat{K}\left(\frac{\ket{0} + \ket{1}}{\sqrt{2}} \otimes\ket{\omega}\right) =& \frac{\ket{0} + \ket{1}}{\sqrt{2}}\otimes\frac{\ket{0} + \ket{1}}{\sqrt{2}} \\
\end{align*}
$$

Since $\hat{K}$ is supposed to be linear, we find instead that 

$$
\begin{align*}
  \hat{K}\left(\frac{\ket{0} + \ket{1}}{\sqrt{2}} \otimes\ket{\omega}\right) =& \hat{K}\left(\frac{1}{\sqrt{2}}(\ket{0}\otimes\ket{\omega}) + \frac{1}{\sqrt{2}}(\ket{1}\otimes\ket{\omega})\right) \\
  =& \frac{1}{\sqrt{2}}\left(\hat{K}(\ket{0}\otimes\ket{\omega}) + \hat{K}(\ket{1}\otimes\ket{\omega})\right) \\
  =& \frac{1}{\sqrt{2}} (\ket{0}\otimes\ket{0} + \ket{1}\otimes\ket{1}) \\
  \neq& \frac{\ket{0} + \ket{1}}{\sqrt{2}}\otimes\frac{\ket{0} + \ket{1}}{\sqrt{2}}
\end{align*}
$$
</details>
</MathBox>

It is worth noting that there can be devices that copy particular states. The quantum no-cloning theorem only makes the statement that there is no device which does that for all states.

# Matter wave formulation

A free particle moving in a $3$-dimensional Euclidean space with momentum $\mathbf{p}$ is described by a plane wave $\psi_\mathbf{p}: \R^3 \times\R\to\mathbb{C}$, which in Cartesian coordinates takes the form

$$
  \psi_\mathbf{p}(\mathbf{x}, t) = N e^{i(\mathbf{k}\cdot\mathbf{x} - \omega t)}
$$

where
- $\mathbf{x}\in\R^3$ is the position of the particle
- $\mathbf{k}$ is the wave vector pointing in the same direction as a $\mathbf{p}$
- $\omega$ is the wave frequency
- $N$ is a normalization constant

The square norm of the wavefunction describes the probability density of the particle at $\mathbf{x}$, i.e. $|\psi(\mathbf{x}, t)|^2 \;\d^3 x$ gives the probability of finding the particle in the volume element $\d^3 x$ around $\mathbf{x}$. Thus, the square norm of the wavefunction is normalized to unity

$$
  \int |\psi(\mathbf{r}, t)|^2 \;\d^3 x = 1
$$

The de Broglie equations relate the wavelength $\lambda$ of the particle to the modulus of the momentum $|\mathbf{p}| = mv$, and the frequency $f$ of the particle to the energy $E$

$$
\begin{align*}
  \lambda =& \frac{2\pi}{|\mathbf{k}|} = \frac{h}{p} = \frac{h}{mv} \\
  f =& \frac{\omega}{2\pi} = \frac{E}{p}
\end{align*}
$$

where $h$ is the Planck constant. Introducing the reduced Planck constant $\hbar = h/2\pi$, the equations can be written as

$$
\begin{align*}
  \mathbf{p} =& \hbar\mathbf{k} \\
  E =& \hbar\omega
\end{align*}
$$

In terms of momentum and energy, the plane wave takes the alternative form

$$
  \psi(\mathbf{x},t) = N e^{i(\mathbf{p}\cdot\mathbf{x} - E_\mathbf{p})/\hbar}
$$

The energy $E_\mathbf{p}$ depends on the momentum of the particle in the following ways
- non-relativistic particles: $E_\mathbf{p} = \mathbf{p}^2 / 2m$
- relativistic particles: $E_\mathbf{p} = c\sqrt{\mathbf{p}^2 + m^2 c^2}$
- massless particles: $E_\mathbf{p} = c|\mathbf{p}|$

In an infinite volume, the normalization constant makes the wavefunction vanish. This can be avoided by introducing the *current density* of the particle probability

$$
  \mathbf{j}(\mathbf{x}, t) := -i\frac{\hbar}{2m} \psi^* (\mathbf{x}, t) \overset{\leftrightarrow}{\nabla} \psi(\mathbf{x},t)
$$

where $\overset{\leftrightarrow}{\nabla}$ is short notation for the difference between forward- and backward-gradients

$$
\begin{align*}
  \psi^* (\mathbf{x}, t) \overset{\leftrightarrow}{\nabla} \psi(\mathbf{x},t) :=& \psi^* (\mathbf{x}, t) \overset{\rightarrow}{\nabla} \psi(\mathbf{x},t) - \psi^* (\mathbf{x}, t) \overset{\leftarrow}{\nabla} \psi(\mathbf{x},t) \\
  =& \psi^* (\mathbf{x}, t) \nabla \psi(\mathbf{x},t) - [\nabla\psi^* (\mathbf{x}, t)]\psi(\mathbf{x}, t)
\end{align*}
$$

A particle wave can be expressed as a superposition of plane waves in the form of a Fourier transform

$$
  \psi(\mathbf{x},t) = \frac{1}{(2\pi\hbar)^3} \int f(\mathbf{p})e^{i(\mathbf{p}\cdot\mathbf{x} - E_\mathbf{p})/\hbar}\;\d^3 p
$$

The momentum wavefunction $f(\mathbf{p})$ is given by the inverse Fourier transform

$$
  f(\mathbf{p}) = \int e^{i\mathbf{p}\cdot\mathbf{x}/\hbar} \psi(\mathbf{x},0)\;\d^3 r
$$

By the uncertainty principle of Fourier transformations, the position and momentum wavefunctions cannot both be concentrated. In general the variances of the particles position and momentum distributions are related by

$$
  \Delta\mathbf{x} \Delta\mathbf{p} \geq \frac{\hbar}{2}
$$

which is known as Heisenberg's uncertainty principle.

## Schr√∂dinger equation

The energy of a nonrelativistic particle with momentum $\mathbf{p}$ and mass $m$ is equal to its Hamiltonian

$$
  H(\mathbf{p}) = E_\mathbf{p} = \frac{\mathbf{p}^2}{2m}
$$

This gives the following identity for the wavefunction $\psi_\mathbf{p}(\mathbf{x},t)$ in Cartesian coordinates

$$
  \frac{1}{(2\pi\hbar)^3} \int f(\mathbf{p})[H(\mathbf{p} - E_\mathbf{p})]e^{i(\mathbf{p}\cdot\mathbf{x} - E_\mathbf{p}t)/\hbar} \;\d^3 p = 0
$$

Substituting for the operators

$$
\begin{align*}
  \unitvec{p} =& -i\hbar\nabla \\
  \hat{E} =& i\hbar\frac{\partial}{\partial t}
\end{align*}
$$

we get the differential equation

$$
  \left[H(-i\hbar\nabla) - i\hbar\frac{\partial}{\partial t}\right] \psi(\mathbf{p},t) = 0
$$

which is the Schr√∂dinger equation for the wavefunction of a free particle. For an arbitrary Hamiltonian $\hat{H} := H(-i\hbar\nabla,\mathbf{x},t)$, the equation takes the general form

$$
  \left(\hat{H} - i\hbar\frac{\partial}{\partial t}\right)\psi(\mathbf{x},t) = 0
$$

The rule of quantizing the classical Hamiltonian $H(\mathbf{p},\mathbf{x},t)$ by the substitution $\mathbf{p}\to\unitvec{p} = -i\hbar\nabla$ is called the correspondence principle.

### Deriving the Schr√∂dinger equation from the classical wave equation

The scalar wave displacement $\Psi(\mathbf{x},t)$ of a non-relativistic particle with mass $m$ and speed $v$ is given by the second-order linear partial differential equation 

$$
\begin{equation*}
  \frac{\partial^2 }{\partial t^2}\Psi(\mathbf{x},t) = v^2 \nabla^2 u(\mathbf{x}, t)
\tag{\label{equation-10}}
\end{equation*}
$$

The wave equation can be solved by separation of variables. Assuming a solution of the form $\Psi(\mathbf{x},t) = \psi(\mathbf{x})g(t)$, equation $\eqref{equation-1}$ can be written as

$$
\begin{align*}
  \frac{\partial^2}{\partial t^2} \psi(\mathbf{x})g(t) =& v^2 \nabla^2 \psi(\mathbf{x})g(t) \\
  \psi(\mathbf{x}) \frac{\partial^2}{\partial t^2} g(t) =& v^2 g(t) \nabla^2 \psi(\mathbf{x}) \\
  \frac{1}{v^2 g(t)} \frac{\partial^2}{\partial t^2} g(t) =& \frac{1}{\psi(\mathbf{x})} \nabla^2 \psi(\mathbf{x}) \tag{\label{equation-9}}
\end{align*}
$$

The separated equation $\eqref{equation-9}$ holds if and only if both sides are equal to a constant $\alpha\in\R$, i.e.

$$
\begin{aligned}
  \frac{1}{v^2 g(t)} \frac{\partial^2}{\partial t^2} g(t) =& \alpha \\
  \frac{\partial^2}{\partial t^2} g(t) =& \alpha v^2 g(t)
\end{aligned}
\quad
\begin{aligned}
  \frac{1}{\psi(\mathbf{x})} \nabla^2 \psi(\mathbf{x}) =& \alpha \\
  \nabla^2 \psi(\mathbf{x}) = \alpha \psi(\mathbf{x})
\end{aligned}
$$

The spatial equation is an eigenvalue problem with real solutions for negative eigenvalues $\alpha = -k^2$, where $k = \frac{2\pi}{\lambda}$ is the wavenumber. Using the de Broglie relation $\lambda = \frac{h}{mv}$ and the energy relation $K = \frac{1}{2}mv^2 = E -V(\mathbf{x})$, assuming energy conservation, the spatial equation can be written

$$
\begin{align*}
  \nabla^2 \psi(\mathbf{x}) =& -k^2 \psi(\mathbf{x}) \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{4\pi^2}{\lambda^2} \tag{$k = \frac{2\pi}{\lambda}$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{4\pi^2 m^2 v^2}{h^2} \psi(\mathbf{x}) \tag{$\lambda = \frac{h}{mv}$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{8\pi^2 m K}{h^2}\psi(\mathbf{x}) \tag{$K = \frac{1}{2}mv^2$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{8\pi^2 m}{h^2} [E - V(\mathbf{x})]\psi(\mathbf{x}) \tag{$K = E - V(\mathbf{x})$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{2m}{\hbar^2} [E - V(\mathbf{x})] \psi(\mathbf{x}) \tag{$\hbar = \frac{h}{2\pi}$} \\
\end{align*}
$$

Reordering the equation and introducing the Hamiltonian operator $\hat{H} = -\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{x})$, we obtain the time-independent Schr√∂dinger equation

$$
\begin{align*}
  -\frac{\hbar^2}{2m} \nabla^2 \psi(\mathbf{x}) + V(\mathbf{x})\psi(\mathbf{x}) =& E \psi(\mathbf{x}) \\
  \left(-\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{x}) \right)\psi(\mathbf{x}) =& E \psi(\mathbf{x}) \\
  \hat{H}\psi(\mathbf{x}) =& E \psi(\mathbf{x}) \tag{\label{equation-17}}
\end{align*}
$$

Noting that $\omega = kv$, the time equation takes the form

$$
  \frac{\partial^2}{\partial^2 t} g(t) = -\omega^2 g(t)
$$

with general solution $e^{-i\omega t}$. The solution to $\eqref{equation-10}$ therefore takes the form $\Psi(\mathbf{x}, t) = \psi(\mathbf{x}) e^{-i\omega t}$. Using the Planck-Einstein relation $E = hf = h\frac{\omega}{2\pi}$ and taking the partial time derivative yields

$$
\begin{align*}
  \Psi(\mathbf{x}, t) =& \psi(\mathbf{x})e^{-i\omega t} \\
  \Psi(\mathbf{x}, t) =& \psi(\mathbf{x})e^{-i2\pi Et/h} \tag{$\omega = \frac{2\pi E}{h}$} \\
  \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& -i\frac{2\pi E}{h} \psi(\mathbf{x})e^{-i2\pi Et/h} \\
  \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& -i\frac{2\pi E}{h} \Psi(\mathbf{x}, t) \\
  i\frac{h}{2\pi} \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& E\Psi(\mathbf{x}, t) \\
  i\hbar \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& E\Psi(\mathbf{x}, t) \tag{$\hbar = \frac{h}{2\pi}$}
\end{align*}
$$

Inserting the time-independent equation $\eqref{equation-17}$, we get

$$
  i\hbar \frac{\partial\Psi}{\partial t} = {H}\Psi
$$