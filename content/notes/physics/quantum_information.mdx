---
title: 'Quantum Information'
subject: 'Physics'
showToc: true
references:
  - book_scherer_2019
  - book_watrous_2018
  - book_wilde_2017
  - book_nielsen_chuang_2000
---

# Qubit

<MathBox title='Qubit' boxType='definition' tag='definition-9'>
A *qubit* is a quantum system described by a two-dimensional Hilbert space, denoted ${}^\P \mathcal{H} \cong \mathbb{C}^2$, called the *qubit space*. The state of a qubit is represented by a unit vector in ${}^\P \mathcal{H}$, which evolves according to the postulates of quantum mechanics. 

Since ${}^\P \mathcal{H}$ is isomorphic to $\mathbb{C}^2$, a qubit state can be represented by a normalized vector in $\mathbb{C}^2$ with orthonormal basis $\set{\ket{0}, \ket{1}}$:

$$
  \ket{\psi} = \alpha\ket{0} + \beta\ket{1}
$$

To associate measurable quantities with the qubit, select an observable corresponding to the Pauli spin operator $\hat{\sigma}_z$ with eigenvalue $1$ for the eigenvector $\ket{0}$ and eigenvalue $-1$ for the eigenvector $\ket{1}$. A measurement of $\hat{\sigma}_z$ on qubit state yields thus $\pm 1$ as observed values and projects the qubit in the eigenstate $\ket{0}$ or $\ket{1}$ corresponding to the observed value.
</MathBox>

The physical realization of a two-dimensional quantum state space is accomplished by restricting the preparation of two-dimensional eigenspaces of a suitably chosen observable. Example of such quantum systems and observables with two-dimensional eigenspaces are

- **Electrons and their spin:** The spin state of an electron is described by a qubit space ${}^\P \mathcal{H} \simeq \mathbb{C}^2$, which have different orthonormal bases corresponding to the eigenstates of different spin operators:
    - Eigenstates of $\boldsymbol{\sigma}_z$ (spin along the $z$-axis)
    $$
      \ket{0} = \ket{\uparrow_{\unitvec{z}}}, \quad \ket{1} = \ket{\downarrow_{\unitvec{z}}}
    $$
    - Eigenstates of $\boldsymbol{\sigma}_x$ (spin along the $x$-axis)
    $$
    \begin{align*}
      \ket{+} :=& \ket{\uparrow_{\hat{\mathbf{x}}}} = \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{z}}} + \ket{\downarrow_{\unitvec{z}}}) \\
      \ket{-} :=& \ket{\uparrow_{\hat{\mathbf{x}}}} = \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{z}}} - \ket{\downarrow_{\unitvec{z}}})
    \end{align*}
    $$
    - Eigenstates of $\boldsymbol{\sigma}_y$ (spin along the $y$-axis)
    $$
    \begin{align*}
      \ket{i} :=& \ket{\uparrow_{\unitvec{y}}} = \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{z}}} + i\ket{\downarrow_{\unitvec{z}}}) \\
      \ket{-i} :=& \ket{\uparrow_{\unitvec{y}}} = \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{z}}} - i\ket{\downarrow_{\unitvec{z}}})
    \end{align*}
    $$
- **Photons and their polarization**: The polarization of a photon propagating in a fixed direction is described by a two-dimensional vector, known as the Jones vector. This forms a Hilbert space $\mathcal{H}\simeq\mathbb{C}^2$, with different orthonormal bases corresponding to eigenstates of different polarization observables
    - Eigenstates of $\boldsymbol{\sigma}_z$ (horizontal/vertical polarization)
    $$
      \ket{0} = \ket{H}, \quad \ket{1} = \ket{V}
    $$
    where $\ket{H}$ (horizontal polarization) and $\ket{V}$ (vertical polarization) are eigenstates of the operator 
    $$
      \boldsymbol{\sigma}_z = \ket{H}\bra{H} - \ket{V}\bra{V}
    $$
    - Eigenstates of $\boldsymbol{\sigma}_x$ (diagonal polarizer)
    $$
    \begin{align*}
      \ket{+} =& \frac{1}{\sqrt{2}} (\ket{H} + \ket{V}) \\
      \ket{-} =& \frac{1}{\sqrt{2}} (\ket{H} - \ket{V})
    \end{align*}
    $$
    - Eigenstates of $\boldsymbol{\sigma}_y$ (circular polarizer)
    $$
    \begin{align*}
      \ket{R} =& \frac{1}{\sqrt{2}} (\ket{H} + i\ket{V}) \\
      \ket{L} =& \frac{1}{\sqrt{2}} (\ket{H} - i\ket{V})
    \end{align*}
    $$
    where $\ket{R}$ and $\ket{L}$ correspond to right- and left-circular polarization, respectively.

<TableFigure caption="Representation of classical bits by qubits">
| Observed value of $\boldsymbol{\sigma}_z$ | Qubit state | Classical bit value |
| --- | --- | --- |
| $1$ | $\ket{0} = \ket{\uparrow_{\unitvec{z}}}$ | $0$ |
| $-1$ | $\ket{1} = \ket{\downarrow_{\unitvec{z}}}$ | $1$ |
</TableFigure>

The normalization condition $|a|^2 + |b|^2 = 1$ for a qubit state $\ket{\psi} = a\ket{0} + b\ket{1}$ admits a parametrization of $a,b\in\mathbb{C}$ in terms of real parameters $\alpha,\beta,\theta\in\R$ such that $a = e^{i\alpha} \cos(\theta/2)$ and $b = e^{i\beta} \sin(\theta/2)$. Thus, a qubit state takes the general form

$$
  \ket{\psi} = e^{i\alpha} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\beta} \sin\left(\frac{\theta}{2}\right) \ket{1}
$$

Since global phase factors do not affect quantum states, the physically equivalent representative in the same ray $[\psi]_\sim \in \mathcal{H}\mathrm{P}$ is obtained by factoring out $e^{-(\alpha + beta)/2}$. Defining $\phi = \beta - \alpha$ yields the parametrization

$$
  \ket{\psi(\theta,\phi)} := e^{-i\phi/2} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\phi/2} \sin\left(\frac{\theta}{2}\right)\ket{1}
$$

which is called the the Bloch sphere representation of a qubit state.

## Observables and eigenstates

To construct an observable that has $\ket{\psi(\theta,\phi)}$ as an eigenstate, we define the Hermitian operator

$$
\begin{equation}
  \mathbf{a}\cdot\boldsymbol{\sigma} := \sum{j=1}^3 a_j \boldsymbol{\sigma}_j = \begin{bmatrix} a_3 & a_1 - ia_2 \\ a_1 + ia_2 & -a_3 \end{bmatrix}
\tag{\label{equation-1}}
\end{equation}
$$

where $\boldsymbol{\sigma} = (\boldsymbol{\sigma}_1, \boldsymbol{\sigma}_2, \boldsymbol{\sigma}_3)$ are the Pauli matrices. For a unit vector $\hat{\mathbf{n}}(\theta,\phi)$ on the Bloch sphere

$$
  \hat{\mathbf{n}}(\theta, \phi) = \begin{bmatrix} \sin(\theta)\cos(\phi) \\ \sin(\theta)\cos(\phi) \\ \cos(\theta) \end{bmatrix}
$$

the corresponing operator is

$$
  \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} = \begin{bmatrix}
    \cos\theta & e^{-i\phi} \sin\theta \\
    e^{i\phi} \sin(\theta) & -\cos\theta
  \end{bmatrix}
$$

This represents the spin measurement along direction $\hat{\mathbf{n}}$. Applying it to $\ket{\psi(\theta, \phi)}$ yields

$$
\begin{align*}
  \hat{\mathbf{n}}(\theta, \phi) \cdot\boldsymbol{\sigma} \ket{\psi(\theta, \phi)} =& \begin{bmatrix} \cos\theta & e^{-i\phi} \sin\theta \\ e^{i\phi} \sin\theta & -\cos\theta \end{bmatrix} \cdot \begin{bmatrix} e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \\ e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  =& \begin{bmatrix} 
    e^{-i\frac{\phi}{2}} \left[\cos(\theta) \cos\left(\frac{\theta}{2}\right) + \sin(\theta)\sin\left(\frac{\phi}{2}\right)\right] \\
    e^{i\frac{\phi}{2}} \left[\sin(\theta) \cos\left(\frac{\theta}{2}\right) - \sin(\theta)\sin\left(\frac{\phi}{2}\right)\right]
  \end{bmatrix} \\
  =& \begin{bmatrix} e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \\ e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  =& \ket{\psi(\theta, \phi)}
\end{align*}
$$

The state $\ket{\psi(\theta,\phi)}$ is thus the spin-up state $\ket{\uparrow_{\hat{\mathbf{n}}}}$ for spin in the direction $\hat{\mathbf{n}}$. Similarly, the spin-down state is

$$
  \ket{\downarrow_{\hat{\mathbf{n}}}} = \begin{bmatrix} -e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \\ e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \end{bmatrix}
$$

which satisfies

$$
  \hat{\mathbf{n}} \cdot \boldsymbol{\sigma} \ket{\downarrow_{\hat{\mathbf{n}}}} = -\ket{\downarrow_{\hat{\mathbf{n}}}}
$$

In particular, it follows that
- $\hat{\mathbf{n}}(0,0) \cdot\boldsymbol{\sigma} = \boldsymbol{\sigma}_z$ and $\ket{\uparrow_{\hat{\mathbf{n}}(0,0)}} = \ket{\uparrow_{\unitvec{z}}}$
- $\hat{\mathbf{n}}\left(\frac{\pi}{2},0 \right) \cdot\boldsymbol{\sigma} = \boldsymbol{\sigma}_x$ and $\ket{\uparrow_{\hat{\mathbf{n}}\left(\frac{\pi}{2},0 \right)}} = \ket{\uparrow_{\hat{\mathbf{x}}}}$

The state $\ket{\psi(\theta,\phi)} = \ket{\uparrow_{\hat{\mathbf{n}}}}$ parametrized by $\theta, \phi$, thus represents an arbitrary qubit state on the Bloch sphere, and the operator $\hat{\mathbf{n}}\cdot\boldsymbol{\sigma}$ represents the observable with this state as eigenstate of eigenvalue $1$.

<LatexFigure width={75} src='/fig/bloch_sphere.svg' alt=''
  caption='Bloch representation of a qubit'
>
```latex
\documentclass[tikz]{standalone}
\usepackage{amsmath}
\usepackage{braket}
\usepackage{tikz}
\usepackage{tikz-3dplot}
\usetikzlibrary{3d}

% Set 3D plot view angle
\tdplotsetmaincoords{70}{110}

\def\rvec{3}
\def\thetavec{40}
\def\phivec{60}

\begin{document}

\begin{tikzpicture}[tdplot_main_coords]
  \coordinate (O) at (0,0,0);

  % Shaded ball (not working in svg)
  %\shade[ball color=lightgray, opacity=0.5] (0,0,0) circle (\rvec cm);
  \fill[lightgray!40] (0,0,0) circle (\rvec cm);

  % Axes
  \draw[] (0,0,0) -- (\rvec,0,0);
  \draw[] (0,0,0) -- (0,\rvec,0);
  \draw[] (0,0,0) -- (0,0,\rvec);

  % Great circles
  \draw[canvas is xy plane at z=0, red, dashed] (0,0) circle (\rvec);
  \draw[canvas is zx plane at y=0, green, dashed] (0,0) circle (\rvec);

  % Eigenstates
  \draw plot [mark=*, mark size=1] (0, 0, \rvec) node[anchor=south, shift=({-0.3,0})] {\scriptsize $\ket{0} = \ket{\uparrow_{\unitvec{z}}}$};
  \draw plot [mark=*, mark size=1] (0, 0, -\rvec) node[anchor=north, shift=({0.3,0})] {\scriptsize $\ket{1} = \ket{\downarrow_{\unitvec{z}}}$};

  \draw plot [mark=*, mark size=1] (0, \rvec, 0) node[anchor=west, shift=({0,0.2})] {\scriptsize $\ket{i} = \ket{\uparrow_{\unitvec{y}}}$};
  \draw plot [mark=*, mark size=1] (0, -\rvec, 0) node[anchor=east, shift=({0,-0.2})] {\scriptsize $\ket{-i} = \ket{\downarrow_{\unitvec{y}}}$};

  \draw plot [mark=*, mark size=1] (\rvec, 0, 0) node[anchor=north east] {\scriptsize $\ket{+} = \ket{\uparrow_{\hat{\mathbf{x}}}}$};
  \draw plot [mark=*, mark size=1] (-\rvec, 0, 0) node[anchor=south west, shift=({-0.2,0.2})] {\scriptsize $\ket{-} = \ket{\downarrow_{\hat{\mathbf{x}}}}$};

  % Qubit
  \tdplotsetcoord{P}{\rvec}{\thetavec}{\phivec};
  \draw[thick,->,color=blue] (0,0,0) -- (P) node[anchor=south west] {\scriptsize $\ket{\psi} = \ket{\uparrow_{\hat{\mathbf{n}}(\theta,\phi)}}$};
  \draw[dashed, color=blue] (O) -- (Pxy);
  \draw[dashed, color=blue] (P) -- (Pxy);

  \tdplotdrawarc{(O)}{0.3*\rvec}{0}{\phivec}{anchor=north}{$\phi$};

  \tdplotsetthetaplanecoords{\phivec};
  \tdplotdrawarc[tdplot_rotated_coords]{(O)}{0.3*\rvec}{0}{\thetavec}{anchor=south west}{$\theta$};

\end{tikzpicture}

\end{document}
```
</LatexFigure>

### Mixed states

A mixed state of a qubit is represented by a density matrix of the form

$$
  \boldsymbol{\rho}_\mathbf{x} = \frac{1}{2} \begin{bmatrix} 1 + x_3 & x_1 - ix_2 \\ x_1 + ix_2 & 1 - x_3 \end{bmatrix} = \frac{1}{2}(\mathbf{I}_2 + \mathbf{x}\cdot\boldsymbol{\sigma})
$$

where $\mathbf{x}\in\R^3$ is a Bloch vector.

<details>
<summary>Proof</summary>

A general density matrix $\boldsymbol{\rho} \in\mathcal{M}_2 (\mathbb{C})$ has the form

$$
  \boldsymbol{\rho} = \begin{bmatrix} a & b \\ c & d \end{bmatrix}
$$

Since $\boldsymbol{\rho}$ is Hermitian, i.e. $\boldsymbol{\rho}^\dagger = \boldsymbol{\rho}$, it follows that $a, d \in\R$ and $b = c^*$. The trace condition $\operatorname{tr}(\boldsymbol{\rho}) = 1$ implies that $a + d  1$. Thus, we can introduce a real parameter $x_3\in\R$ such that

$$
  a = \frac{1 + x_3}{2}, \quad d = \frac{1 - x_3}{2}
$$

Similarly, defining the real numbers $x_1 = 2\Re(c)$ and $x_2 = 2\Im(c)$, we rewrite $\boldsymbol{\rho}$ as

$$
  \boldsymbol{\rho}_\mathbf{x} = \frac{1}{2} \begin{bmatrix} 1 + x_3 & x_1 - ix_2 \\ x_1 + ix_2 & 1 - x_3 \end{bmatrix}
$$

Using $\eqref{equation-1}$, we can write this succintly as $\operatorname{\rho} = \frac{1}{2}(\mathbf{I}_2 + \mathbf{x}\cdot\boldsymbol{\sigma})$.
</details>

The eigenvalues of $\operatorname{\rho}_\mathbf{x}$ are given by

$$
  q_{1,2} = \frac{1 + \norm{\mathbf{x}}}{2}
$$

<details>
<summary>Details</summary>

The eigenvalues of $\boldsymbol{\rho}$ are found by solving $\det(\boldsymbol{\rho} - q\mathbf{I}_2) = 0$ or in component form

$$
\begin{align*}
  0 =& \frac{1}{2}\begin{vmatrix}
    1 + x_3 - 2q & x_1 - ix_2 \\
    x_1 + ix_2 & 1 - x_3 - 2q
  \end{vmatrix} \\
  =& \left(\frac{1 + x_3}{2} - q \right) \left(\frac{1 - x_3}{2} - q \right) - \left(\frac{x_1 - ix_2}{2}\right) \left(\frac{x_1 + ix_2}{2}\right)
\end{align*}
$$

Expanding the first term gives

$$
\begin{align*}
  \left(\frac{1 + x_3}{2} - q \right) \left(\frac{1 - x_3}{2} - q \right) =& \left(\frac{1 + x_3}{2}\right)\left(\frac{1 - x_3}{2}\right) - q + q^2 \\
  \frac{1 - x_3^2}{4} - q + q^2
\end{align*}
$$

while the second term becomes

$$
  \left(\frac{x_1 - ix_2}{2}\right) \left(\frac{x_1 + ix_2}{2}\right) = \frac{x_1^2 + x_2^2}{4}
$$

Combining the terms gives the quadratic equation

$$
  q^2 - q + \frac{1}{4}(1 - x_3^2 - (x_1^2 + x_2^2)) = q^2 - q -\frac{1}{4}(1 - \norm{\mathbf{x}}^2) = 0
$$

with solutions

$$
  q = \frac{1 \pm \sqrt{1 - (1 - \norm{\mathbf{x}}^2)}}{2} = \frac{1 \pm \norm{x}^2}{2}
$$
</details>

From the positivity of $\boldsymbol{\rho}$, i.e. $\boldsymbol{\rho} \geq 0$, we require $q_{1,2} \geq 0$, which implies $\norm{\mathbf{x}} \leq 1$. This means that the density matrices for mixtures of qubits can be parametrized by vectors $\mathbf{x}$ in the unit ball of $\R^3$, written $\mathbf{x}\in\mathcal{B}_1 (0, \R^3)$. This parametrization is called the Bloch representation. 

Squaring the density matrix $\boldsymbol{\rho}_\mathbf{x}$ gives

$$
  \boldsymbol{\rho}_\mathbf{x}^2 = \frac{1}{4} (\mathbf{I}_2 + \mathbf{x}\cdot\boldsymbol{\sigma}) = \frac{1}{4}[\boldsymbol{I}_2 (1 + \norm{\mathbf{x}}^2) + 2\mathbf{x}\cdot\boldsymbol{\sigma}]
$$

It follows that $\boldsymbol{\rho}_\mathbf{x}^2 = \boldsymbol{\rho}_\mathbf{x}$ if and only if $\norm{\mathbf{x}} = 1$. Thus, states corresponding to bounday points $\norm{\mathbf{x}} = 1$ of the Bloch sphere are pure states, while those inside the Bloch ball, $\norm{\mathbf{x}} < 1$ are mixed states.

The Bloch vector $\mathbf{x}$ characterize a qubit's state by encoding expectation values of the Pauli matrices. Specifically, it is given by

$$
  \mathbf{x} = \operatorname{tr}(\boldsymbol{\rho}_\mathbf{x} \mathbf{\sigma})
$$

<details>
<summary>Proof</summary>

$$
\begin{align*}
  \operatorname{tr}(\boldsymbol{\rho}_\mathbf{x} \boldsymbol{\sigma}_j) =& \operatorname{tr}\left(\frac{1}{2}(\mathbf{I}_2 + \mathbf{x}\cdot\boldsymbol{\sigma})\boldsymbol{\sigma}_j \right) \\
  =& \frac{1}{2}\left(\boldsymbol{\sigma}_j + \sum_{k=1}^3 x_k \boldsymbol{\sigma}_k \boldsymbol{\sigma}_j \right) \\
  =& \frac{1}{2} \underbrace{\operatorname{tr}(\boldsymbol{\sigma}_j)}_{=0} + \frac{1}{2} \sum_{k=1}^3 x_k \operatorname{tr}(\boldsymbol{\sigma}_k \boldsymbol{\sigma}_j) \\
  =& \frac{1}{2} \sum_{k=1}^3 x_k \operatorname{tr}(\mathbf{I}_2 \delta_{kj} + i\epsilon_{kjl} \boldsymbol{\sigma}_l) \\
  =& \frac{1}{2} x_k [\delta_{kj} \underbrace{\operatorname{tr}(\mathbf{I}_2)}_{=2} + i\epsilon_{kjl} \underbrace{\operatorname{tr}(\boldsymbol{\sigma}_l)}_{=0}] \\
  =& x_j
\end{align*}
$$
</details>

## Operators on qubits

<MathBox title='Spin rotation' boxType='definition'>
Let $\hat{\mathbf{n}} \in \mathbb{S}^2$ be unit vector in $\R^3$. A rotation about $\hat{\mathbf{n}}$ by an angle $\alpha$ on the qubit space ${}^\P \mathcal{H}$ is given by

$$
  \hat{D}_{\hat{\mathbf{n}}}(\alpha) := e^{-i\frac{\alpha}{2} \hat{\mathbf{n}}\cdot\boldsymbol{\sigma}}
$$

known as the spin rotation operator
</MathBox>

<MathBox title='Properties of spin rotation' boxType='proposition' tag='proposition-3'>
Let $\hat{\mathbf{n}} \in\mathbb{S}^2$ be unit vector in $\R^3$. The spin operator $\mathbf{D}_{\hat{\mathbf{n}}}$ has the following properties
1. $\mathbf{D}_{\hat{\mathbf{n}}}(\alpha) = \exp\left(-i\frac{\alpha}{2} \unitvec{n}\cdot\boldsymbol{\sigma} \right) = \cos\left(\frac{\alpha}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\alpha}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma}$
2. $\mathbf{D}_{\hat{\mathbf{n}}}^\dagger (\alpha) = \mathbf{D}_{\hat{\mathbf{n}}} (-\alpha) = \cos\left(\frac{\alpha}{2}\right)\mathbf{I}_2 + i\sin\left(\frac{\alpha}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma}$
3. $\mathbf{D}_{\hat{\mathbf{n}}}(\alpha) \mathbf{D}^\dagger_{\hat{\mathbf{n}}}(\alpha) = \mathbf{I}_2$
4. $\mathbf{D}_{\hat{\mathbf{n}}}(\alpha) \mathbf{D}^\dagger_{\hat{\mathbf{n}}}(\beta) = \mathbf{D}_{\hat{\mathbf{n}}}(\alpha + \beta)$

<details>
<summary>Proof</summary>

Recall that for matrices $\mathbf{A}$ satisfying $\mathbf{A}^2 = \mathbf{I}$

$$
\begin{equation}
  e^{i\alpha\mathbf{A}} := \sum_{n=0}^\infty \frac{(i\alpha)^n}{n!} \mathbf{A}^n = \cos(\alpha)\mathbf{I} + i\sin(\alpha)\mathbf{A}
\tag{\label{equation-2}}
\end{equation}
$$

**(1):** Since $\norm{\hat{\mathbf{n}}} = 1$ it follows that $(\hat{\mathbf{n}}\cdot\boldsymbol{\sigma})^2 = \mathbf{I}$. Hence, the results follows immediately from $\eqref{equation-2}$.

**(2):** Since $(-i\hat{\mathbf{n}} \cdot \boldsymbol{\sigma})^\dagger = i\hat{\mathbf{n}}\cdot\boldsymbol{\sigma}$, the result follows immediately from **(1)**.

**(3):** From **(1)** and **(2)**, we have

$$
\begin{align*}
  \mathbf{D}_{\hat{\mathbf{n}}} (\alpha) \mathbf{D}_{\hat{\mathbf{n}}}^\dagger (\alpha) =& \left(\cos\left(\frac{\alpha}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\alpha}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \right) \left(\cos\left(\frac{\alpha}{2}\right)\mathbf{I}_2 + i\sin\left(\frac{\alpha}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \right) \\
  =& \left[\cos\left(\frac{\alpha}{2}\right) \mathbf{I}_2 \right]^2 - \left[i \sin\left(\frac{\alpha}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \right]^2 \\
  =& \left(\cos^2 \left(\frac{\alpha}{2}\right) + \sin^2 \left(\frac{\alpha}{2}\right) \right)\mathbf{I}_2 \\
  =& \mathbf{I}_2
\end{align*}
$$

**(4):**

$$
\begin{align*}
  \mathbf{D}_{\hat{\mathbf{n}}} (\alpha) \mathbf{D}_{\hat{\mathbf{n}}} (\beta) =& \left(\cos\left(\frac{\alpha}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\alpha}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \right) \left(\cos\left(\frac{\beta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\beta}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \right) \\
  =& \cos\left(\frac{\alpha}{2}\right)\cos\left(\frac{\beta}{2}\right)\mathbf{I}_2 - \sin\left(\frac{\alpha}{2}\right)\sin\left(\frac{\beta}{2}\right) \underbrace{(\hat{\mathbf{n}}\cdot\boldsymbol{\sigma})^2}_{=\mathbf{I}_2} \\
  &- i\underbrace{\left(\cos\left(\frac{\alpha}{2}\right)\sin\left(\frac{\beta}{2}\right) + \sin\left(\frac{\alpha}{2}\right)\cos\left(\frac{\beta}{2}\right)\right)}_{=\sin[(\alpha + \beta)/2]} \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \\
  =& \underbrace{\left(\cos\left(\frac{\alpha}{2}\right)\cos\left(\frac{\beta}{2}\right) - \sin\left(\frac{\alpha}{2}\right)\sin\left(\frac{\beta}{2}\right)\right)}_{=\cos[(\alpha + \beta)/2]}\mathbf{I}_2 - i\sin\left(\frac{\alpha + \beta}{2}\right) \hat{\mathbf{n}} \cdot\boldsymbol{\sigma} \\
  =& \cos\left(\frac{\alpha + \beta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\alpha + \beta}{2}\right) \hat{\mathbf{n}}\cdot\boldsymbol{\sigma} \\
  =& \mathbf{D}_{\hat{\mathbf{n}}} (\alpha + \beta)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Inverse spin rules' boxType='proposition'>
Inverse spin rotations about the $y$ and $z$ axes are given by
1. $\boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{y}} (\eta) \boldsymbol{\sigma}_x = \mathbf{D}_{\unitvec{y}} (-\eta)$
2. $\boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{z}} (\eta) \boldsymbol{\sigma}_x = \mathbf{D}_{\unitvec{z}} (-\eta)$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  \boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{y}} (\eta) \boldsymbol{\sigma}_x =& \boldsymbol{\sigma}_x \left(\cos\left(\frac{\eta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\eta}{2}\right) \unitvec{y} \cdot \boldsymbol{\sigma} \right)\boldsymbol{\sigma}_x \\
  =& \cos\left(\frac{\eta}{2}\right) \underbrace{\boldsymbol{\sigma}_x^2}_{=\mathbf{I}_2} - i\sin\left(\frac{\eta}{2}\right) \underbrace{\boldsymbol{\sigma}_x \boldsymbol{\sigma}_y}_{=i\boldsymbol{\sigma}_z} \boldsymbol{\sigma}_x \\
  =& \cos\left(\frac{\eta}{2}\right) \mathbf{I}_2 + \sin\left(\frac{\eta}{2}\right) \underbrace{\boldsymbol{\sigma}_z \boldsymbol{\sigma}_x}_{i\sigma y} \\
  =& \cos\left(\frac{\eta}{2}\right) \mathbf{I}_2 + i\sin\left(\frac{\eta}{2}\right) \boldsymbol{\sigma}_y \\
  =& \mathbf{D}_{\unitvec{y}} (-\eta)
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{z}} (\eta) \boldsymbol{\sigma}_x =& \boldsymbol{\sigma}_x \left(\cos\left(\frac{\eta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\eta}{2}\right) \unitvec{z} \cdot \boldsymbol{\sigma} \right)\boldsymbol{\sigma}_x \\
  =& \cos\left(\frac{\eta}{2}\right) \underbrace{\boldsymbol{\sigma}_x^2}_{=\mathbf{I}_2} - i\sin\left(\frac{\eta}{2}\right) \underbrace{\boldsymbol{\sigma}_x \boldsymbol{\sigma}_z}_{=-i\boldsymbol{\sigma}_y} \boldsymbol{\sigma}_x \\
  =& \cos\left(\frac{\eta}{2}\right) \mathbf{I}_2 - \sin\left(\frac{\eta}{2}\right) \underbrace{\boldsymbol{\sigma}_y \boldsymbol{\sigma}_x}_{-i\boldsymbol{\sigma}_z} \\
  =& \cos\left(\frac{\eta}{2}\right) \mathbf{I}_2 + i\sin\left(\frac{\eta}{2}\right) \boldsymbol{\sigma}_z \\
  =& \mathbf{D}_{\unitvec{z}} (-\eta)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-1'>
Let $\hat{U}$ be a unitary operator on the qubit space ${}^\P \mathcal{H}$. Then there exists parameters $\alpha,\beta,\delta,\gamma\in\R$ such that the matrix representation of $\hat{U}$ in the standard basis $\set{\ket{0}, \ket{1}}$ is given by

$$
\begin{equation}
  \mathbf{U} = e^{i\alpha} \begin{bmatrix}
    e^{-i\frac{\beta + \delta}{2}} \cos\left(\frac{\gamma}{2}\right) & -e^{-i\frac{\delta - \beta}{2}} \sin\left(\frac{\gamma}{2}\right) \\
    e^{-i\frac{\beta - \delta}{2}} \sin\left(\frac{\gamma}{2}\right) & e^{-i\frac{\beta + \delta}{2}} \cos\left(\frac{\gamma}{2}\right)
  \end{bmatrix}
\tag{\label{equation-3}}
\end{equation}
$$

<details>
<summary>Proof</summary>

Let $\mathbf{U}$ be a unitary matrix in the standard basis $\set{\ket{0}, \ket{1}}$, given by

$$
  \mathbf{U} = \begin{bmatrix} a & b \\ c & d \end{bmatrix}, \; a,b,c,d\in\mathbb{C}
$$

From the unitarity condition $\mathbf{UU}^\dagger = \mathbf{I}_2$, we obtain the constraints

$$
\begin{gather*}
  |a|^2 + |b|^2 = 1 = |c|^2 + |d|^2 \\
  ac^* + bd^* = 0
\end{gather*}
$$

**Case 1: $c = 0$ (or equivalently $b = 0$)**

If $c = 0$, then from $|d|^2 = 1$ follows that $d = e^{i\eta}$. This again implies $b = 0$ and from $|a|^2 = 1$ it follows that $a = e^{i\xi}$. In this case $\mathbf{U}$ takes the diagonal form

$$
  \mathbf{U} = \begin{bmatrix}
    e^{i\xi} & 0 \\
    0 & e^{i\eta}
  \end{bmatrix}
$$

Setting $\alpha = (\xi + \eta)/2$, $\beta = \eta - \xi$ and $\delta = \gamma = 0$, we recover the desired form. If $a = 0$, a similar argument leads to

$$
  \mathbf{U} = \begin{bmatrix}
    0 & e^{i\omega} \\
    e^{i\tau} & 0
  \end{bmatrix}
$$

Setting $\alpha = (\omega + \tau + \pi)/2$, $\delta = \omega + \pi - \tau$, $\beta = 0$ and $\gamma = \pi$, we obtain the desired form of $\mathbf{U}$.

**Case 2: $c \neq 0$**

If $ac^* \neq 0$, the unitarity condition yields

$$
\begin{align*}
  a =& -b \frac{d^*}{c^*} \\
  \implies |a|^2 =& |b|^2 \frac{|d|^2}{|c|^2} \\
  \implies 1 =& |a|^2 + |b|^2 = |b|^2 \left(1 + \frac{|d|^2}{|c|^2} \right) \\
  =& |b|^2 \frac{|c|^2 + |d|^2}{|c|^2} = \frac{|b|^2}{|c|^2}
\end{align*}
$$

which implies $|b| = |c|$ and $|a| = |d|$. Thus, there are $\xi,\eta,\gamma\in\R$ such that

$$
  a = e^{i\xi} \cos\left(\frac{\gamma}{2}\right), \quad d = e^{i\eta} \cos\left(\frac{\gamma}{2} \right)
$$

which in turn implies that

$$
  |c|^2 = |b|^2 = 1 - |a|^2 = \sin^2 \left(\frac{\gamma}{2}\right)
$$

Thus, there are $\omega,\tau\in\R$ such that

$$
  b = -e^{i\omega} \sin\left(\frac{\gamma}{2}\right), \quad c = e^{i\tau} \sin\left(\frac{\gamma}{2}\right)
$$

Using the identity $ac^* = -bd^* \neq 0$, we obtain

$$
  e^{i(\xi - \tau)} \sin\left(\frac{\gamma}{2}\right) \cos\left(\frac{\gamma}{2}\right) = e^{i(\omega - \eta)} \sin\left(\frac{\gamma}{2}\right) \cos\left(\frac{\gamma}{2}\right)
$$

and thus $\xi - \tau = \omega - \eta + 2k\pi$. Choosing $\eta = \omega + \tau - \xi$, we can rewrite $\mathbf{U}$ as

$$
  \mathbf{U} = \begin{bmatrix}
    e^{i\xi} \cos\left(\frac{\gamma}{2}\right) & -e^{i\omega} \sin\left(\frac{\gamma}{2}\right) \\
    e^{i\tau} \sin\left(\frac{\gamma}{2}\right) & e^{i(\omega + \tau - \xi)} \cos\left(\frac{\gamma}{2} \right)
  \end{bmatrix}
$$

With the change of variables

$$
\begin{align*}
  \alpha :=& \frac{\omega + \tau}{2} \\
  \beta :=& \tau - \xi \\
  \delta := \omega - \xi
\end{align*}
$$

we obtain

$$
\begin{align*}
  \xi =& \alpha - \frac{\beta + \delta}{2} \\
  \omega =& \alpha + \frac{\delta - \beta}{2} \\
  \tau =& \alpha + \frac{\beta -\delta}{2} \\
  \omega + \tau - \xi =& \alpha + \frac{\beta + \delta}{2}
\end{align*}
$$

giving $\mathbf{U}$ the desired form.
</details>
</MathBox>

<MathBox title='' boxType='corollary' tag='corollary-1'>
Let $\hat{U}\in\mathrm{U}(2)$ be a unitary operator on the qubit space ${}^\P \mathcal{H}$. Then there exists parameters $\alpha,\beta,\delta,\gamma\in\R$ such that

$$
  \hat{U} = e^{i\alpha} \mathbf{D}_{\unitvec{z}} (\beta) \mathbf{D}_{\unitvec{y}} (\gamma) \mathbf{D}_{\unitvec{z}} (\delta)
$$

<details>
<summary>Proof</summary>

We have

$$
\begin{align*}
  \mathbf{D}_{\unitvec{z}} (\beta) =& \cos\left(\frac{\delta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\delta}{2}\right) \unitvec{z}\cdot\boldsymbol{\sigma} = \cos\left(\frac{\delta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\delta}{2}\right) \boldsymbol{\sigma}_z \\
  =& \begin{bmatrix} 
    \cos\left(\frac{\delta}{2}\right) - i\sin\left(\frac{\delta}{2}\right) & 0 \\
    0 & \cos\left(\frac{\delta}{2}\right) + i\sin\left(\frac{\delta}{2}\right) \end{bmatrix} = \begin{bmatrix} e^{-i\delta/2} & 0 \\ 0 & e^{i\delta/2}
  \end{bmatrix}
\end{align*}
$$

and

$$
\begin{align*}
  \mathbf{D}_{\unitvec{y}} (\gamma) =& \cos\left(\frac{\gamma}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\gamma}{2}\right) \unitvec{y} - i\sin\left(\frac{\gamma}{2}\right) \boldsymbol{\sigma}_y \\
  =& \begin{bmatrix} \cos\left(\frac{\gamma}{2}\right) & -\sin\left(\frac{\gamma}{2}\right) \\ \sin\left(\frac{\gamma}{2}\right) & \cos\left(\frac{\gamma}{2}\right) \end{bmatrix}
\end{align*}
$$

such that

$$
\begin{align*}
  \mathbf{D}_{\unitvec{z}}(\beta) \mathbf{D}_{\unitvec{y}}(\gamma) \mathbf{D}_{\unitvec{z}}(\delta) =& \begin{bmatrix} e^{-i\frac{\beta}{2}} & 0 \\ 0 & e^{i\frac{\beta}{2}} \end{bmatrix} \begin{bmatrix} \cos\left(\frac{\gamma}{2}\right) & -\sin\left(\frac{\gamma}{2}\right) \\ \sin\left(\frac{\gamma}{2}\right) & \cos\left(\frac{\gamma}{2}\right) \end{bmatrix} \begin{bmatrix} e^{-i\frac{\beta}{2}} & 0 \\ 0 & e^{i\frac{\beta}{2}} \end{bmatrix} \\
  =& \begin{bmatrix}
    e^{-i\frac{\beta + \delta}{2}} \cos\left(\frac{\gamma}{2}\right) & -e^{-i\frac{\delta - \beta}{2}} \sin\left(\frac{\gamma}{2}\right) \\
    e^{-i\frac{\beta - \delta}{2}} \sin\left(\frac{\gamma}{2}\right) & e^{-i\frac{\beta + \delta}{2}} \cos\left(\frac{\gamma}{2}\right)
  \end{bmatrix}
\end{align*}
$$

Multiplying with $e^{i\alpha}$ gives the desired result.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-4'>
For every unitary operator $\hat{U}$ on ${}^\P \mathcal{H}$ there exists operators $\hat{A}, \hat{B}$ and $\hat{C}$ on ${}^\P \mathcal{H}$ and $\alpha\in\R$ such that $\mathbf{ABC} = \mathbf{I}$ and

$$
  \mathbf{U} = e^{i\alpha} \mathbf{A} \boldsymbol{\sigma}_x \mathbf{B} \boldsymbol{\sigma}_x \mathbf{C}
$$

<details>
<summary>Proof</summary>

From Corollary $\ref{corollary-1}$, we have

$$
  \hat{U} = e^{i\alpha} \hat{D}_{\unitvec{z}} (\beta) \hat{D}_{\unitvec{y}} (\gamma) \hat{D}_\mathbf{z} (\delta)
$$

We set

$$
\begin{align*}
  A: &= \mathbf{D}_{\hat{\mathbf{x}}}(\beta) \mathbf{D}_{\unitvec{y}}(\frac{\gamma}{2}) \\
  B: &= \mathbf{D}_{\unitvec{y}}\left(-\frac{\gamma}{2}\right) \mathbf{D}_{\unitvec{z}}\left(\frac{\delta + \beta}{2}\right) \\
  C: &= \mathbf{D}_{\unitvec{z}}\left(\frac{\delta - \beta}{2}\right).
\end{align*}
$$

Then it follows that

$$
\begin{align*}
  \mathbf{ABC} =& \mathbf{D}_{\unitvec{z}} (\beta) \underbrace{\mathbf{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right) \mathbf{D}_{-\unitvec{y}} \left(\frac{\gamma}{2}\right)}_{=\mathbf{D}_{\unitvec{y}}(0) = \mathbf{I}_2} \mathbf{D}_{\unitvec{z}} \left(-\frac{\delta + \beta}{2} \right) \underbrace{\mathbf{D}_{\unitvec{z}} \left(\frac{\delta - \beta}{2} \right)}_{=\mathbf{D}_{\unitvec{z}} (-\beta)} \\
  =& \mathbf{D}_{\unitvec{z}} (\beta) \mathbf{D}_{\unitvec{z}} (-\beta) \\
  =& \mathbf{I}_2
\end{align*}
$$

and

$$
\begin{align*}
  &e^{i\alpha} \mathbf{A} \boldsymbol{\sigma}_x \mathbf{B} \boldsymbol{\sigma}_x \mathbf{C} \\
  =& e^{i\alpha} \mathbf{D}_{\hat{\mathbf{x}}} (\beta) \mathbf{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right) \boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{y}} \left(-\frac{\gamma}{2}\right) \mathbf{D}_{\unitvec{z}} \left(-\frac{\delta + \beta}{2}\right) \boldsymbol{\sigma}_x \boldsymbol{D}_{\unitvec{z}} \left(\frac{\delta - \beta}{2} \right) \\
  =& e^{i\alpha} \mathbf{D}_{\hat{\mathbf{x}}} (\beta) \mathbf{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right) \boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{y}} \left(-\frac{\gamma}{2}\right) \overbrace{\boldsymbol{\sigma}_x \boldsymbol{\sigma}_x}^{\mathbf{I}_2} \mathbf{D}_{\unitvec{z}} \left(-\frac{\delta + \beta}{2}\right) \boldsymbol{\sigma}_x \boldsymbol{D}_{\unitvec{z}} \left(\frac{\delta - \beta}{2} \right) \\
  =& e^{i\alpha} \mathbf{D}_{\hat{\mathbf{x}}} (\beta) \mathbf{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right) \underbrace{\boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{y}} \left(-\frac{\gamma}{2}\right) \boldsymbol{\sigma}_x}_{=\mathbf{D}_{\unitvec{y}}(\gamma/2)} \underbrace{\boldsymbol{\sigma}_x \mathbf{D}_{\unitvec{z}} \left(-\frac{\delta + \beta}{2}\right) \boldsymbol{\sigma}_x}_{=\mathbf{D}_{\unitvec{z}}[(\delta + \beta)/2]} \boldsymbol{D}_{\unitvec{z}} \left(\frac{\delta - \beta}{2} \right) \\
  =& e^{i\alpha} \mathbf{D}_{\unitvec{z}} (\beta) \underbrace{\mathbf{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right) \mathbf{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right)}_{=\mathbf{D}_{\unitvec{y}}(\gamma)} \underbrace{\mathbf{D}_{\unitvec{z}} \left(\frac{\delta + \beta}{2}\right) \mathbf{D}_{\unitvec{z}} \left(\frac{\delta - \beta}{2}\right)}_{=\mathbf{D}_{\unitvec{z}}(\delta)} \\
  =& e^{i\alpha} \mathbf{D}_{\unitvec{z}} (\beta) \mathbf{D}_{\unitvec{y}} (\gamma) \mathbf{D}_{\unitvec{z}} (\delta) = \mathbf{U}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-2'>
Let $\hat{U}$ be a unitary operator on ${}^\P \mathcal{H}$. Then there exists parameters $\alpha, \xi\in\R$ and a unit vector $\hat{\mathbf{n}}\in\mathbb{S}^2$ in $\R^3$ such that

$$
  \mathbf{U} = e^{i\alpha} \mathbf{D}_{\hat{\mathbf{n}}} (\xi)
$$

<details>
<summary>Proof</summary>

From Proposition $\ref{proposition-1}$, we know that there exists parameters $\alpha,\beta,\delta,\gamma\in\R$ such that

$$
\begin{align*}
  \mathbf{U} =& e^{i\alpha} \begin{bmatrix}
    e^{-i\frac{\beta + \delta}{2}} \cos\left(\frac{\gamma}{2}\right) & -e^{-i\frac{\delta - \beta}{2}} \sin\left(\frac{\gamma}{2}\right) \\
    e^{-i\frac{\beta - \delta}{2}} \sin\left(\frac{\gamma}{2}\right) & e^{-i\frac{\beta + \delta}{2}} \cos\left(\frac{\gamma}{2}\right)
  \end{bmatrix} \\
  =& e^{i\alpha} \begin{bmatrix}
    \left[\cos\left(\frac{\beta + \delta}{2}\right) - i\cos\left(\frac{\beta + \delta}{2}\right)\right] \cos\left(\frac{\gamma}{2}\right) & \left[\cos\left(\frac{\delta - \beta}{2}\right) - i\cos\left(\frac{\delta - \beta}{2}\right)\right] \sin\left(\frac{\gamma}{2}\right) \\
    \left[\cos\left(\frac{\beta - \delta}{2}\right) - i\cos\left(\frac{\beta - \delta}{2}\right)\right] \sin\left(\frac{\gamma}{2}\right) & \left[\cos\left(\frac{\beta + \delta}{2}\right) - i\cos\left(\frac{\beta + \delta}{2}\right)\right] \cos\left(\frac{\gamma}{2}\right)
  \end{bmatrix} \\
  =& e^{i\alpha} \left(\cos\left(\frac{\beta + \delta}{2}\right) \cos\left(\frac{\gamma}{2}\right) \mathbf{I}_2 \right. \\
  & \left.-i\left[\sin\left(\frac{\beta + \delta}{2}\right) \cos\left(\frac{\gamma}{2}\right) \boldsymbol{\sigma}_z + \cos\left(\frac{\delta - \beta}{2}\right) \sin\left(\frac{\gamma}{2}\right) \boldsymbol{\sigma}_y + \sin\left(\frac{\delta - \beta}{2}\right) \sin\left(\frac{\gamma}{2}\right)\boldsymbol{\sigma}_x \right]\right)
\end{align*}
$$

We aim to find $\xi$ and $\hat{\mathbf{n}}(\theta,\phi)$ such that $\mathbf{U} = e^{i\alpha} \mathbf{D}_{\hat{\mathbf{n}}} (\xi)$ for

$$
  \mathbf{D}_{\hat{\mathbf{n}}} (\xi) = \cos\left(\frac{\xi}{2}\right) \mathbf{I}_2 - i\sin\left(\frac{\xi}{2}\right) \hat{\mathbf{n}} \cdot \boldsymbol{\sigma}
$$

We thus seek a $\tilde{\xi}$ such that 

$$
\begin{equation}
  \cos\left(\frac{\tilde{\xi}}{2}\right) = \cos\left(\frac{\delta + \beta}{2}\right) \cos\left(\frac{\gamma}{2}\right)
\tag{\label{equation-4}}
\end{equation}
$$

which leads to

$$
\begin{align*}
  \left|\sin\left(\frac{\tilde{\xi}}{2}\right)\right| =& \sqrt{1 - \cos^2 \left(\frac{\tilde{\xi}}{2}\right)} \\
  =& \sqrt{1 - \cos^2 \left(\frac{\delta + \beta}{2}\right) \cos^2 \left(\frac{\gamma}{2}\right)} \\
  \geq& \sqrt{1 - \cos^2 \left(\frac{\gamma}{2}\right)} = \left|\sin\left(\frac{\gamma}{2}\right)\right|
\end{align*}
$$

We choose $\xi = \tilde{\xi}$ if $\sin(\tilde{\xi}/2)$ and $\sin(\gamma/2)$ have the same sign and $\xi = -\tilde{\xi}$ otherwise. Then there exists $\theta_1 \in [0, \pi/2]$ and $\theta_2 = \pi - \theta_1 \in [\pi/2, \pi]$ such that

$$
  \sin(\theta_j) \sin\left(\frac{\gamma}{2}\right), \; j\in\set{1,2}
$$

From this it follows that

$$
  (1 - \cos^2 (\theta_j)) \sin^2 \left(\frac{\xi}{2}\right) = 1 - \cos^2 \left(\frac{\gamma}{2}\right)
$$

and this in turn implies

$$
\begin{align*}
  \cos^2 (\theta_j) \sin\left(\frac{\xi}{2}\right) =& \cos^2 \left(\frac{\gamma}{2}\right) + \sin^2 \left(\frac{\xi}{2}\right) - 1 \\
  =& \cos^2 \left(\frac{\gamma}{2}\right) - \cos^2 \left(\frac{\xi}{2}\right) \\
  =& \left(1 - \cos^2 \left(\frac{\delta + \beta}{2}\right)\right) \cos^2 \left(\frac{\gamma}{2}\right) \\
  =& \sin^2 \left(\frac{\delta + \beta}{2}\right) \cos^2 \left(\frac{\gamma}{2}\right)
\end{align*}
$$

Thus, we have

$$
  \left|\cos(\theta)_j \sin\left(\frac{\xi}{2}\right)\right| = \left|\sin\left(\frac{\delta + \beta}{2}\right) \cos\left(\frac{\gamma}{2}\right)\right|
$$

If $\sin(\xi/2)$ and $\sin[(\delta + \beta)/2]\cos(\gamma/2)$ have the same sign, we set $\theta = \theta_1$, otherwise $\theta = \theta_2$, such that in every case

$$
  \cos(\theta) \sin\left(\frac{\xi}{2}\right) = \sin\left(\frac{\delta + \beta}{2}\right) \cos\left(\frac{\gamma}{2}\right)
$$

We now set $\phi := (\beta - \delta + \pi)/2$ such that

$$
\begin{align*}
  \sin(\phi) =& \sin\left(\frac{\beta - \delta + \pi}{2}\right) = \cos\left(\frac{\beta - \delta}{2}\right) \\
  \cos(\phi) =& \cos\left(\frac{\beta - \delta + \pi}{2}\right) = -\sin\left(\frac{\beta - \delta}{2}\right) = \sin\left(\frac{\delta -\beta}{2}\right) 
\end{align*}
$$

Altogher, we thus have in $\eqref{equation-4}$

$$
\begin{align*}
  \cos\left(\frac{\beta + \delta}{2}\right) \cos\left(\frac{\gamma}{2}\right) =& \cos\left(\frac{\xi}{2}\right) \\
  \sin\left(\frac{\beta + \delta}{2}\right) \cos\left(\frac{\gamma}{2}\right) =& \sin\left(\frac{\xi}{2}\right) \cos(\theta) = \sin\left(\frac{\xi}{2}\right) \hat{n}_z \\
  \cos\left(\frac{\beta - \delta}{2}\right) \cos\left(\frac{\gamma}{2}\right) =& \sin\left(\frac{\xi}{2}\right) \sin(\theta)\sin(\phi) = \sin\left(\frac{\xi}{2}\right) \hat{n}_y \\
  \sin\left(\frac{\delta - \beta}{2}\right) \cos\left(\frac{\gamma}{2}\right) =& \sin\left(\frac{\xi}{2}\right) \sin(\theta)\cos(\phi) = \sin\left(\frac{\xi}{2}\right) \hat{n}_x
\end{align*}
$$

and finally

$$
\begin{align*}
  e^{-i\alpha} \mathbf{U} =& \cos\left(\frac{\xi}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\xi}{2}\right) \hat{\mathbf{n}}\cdot\mathbf{\sigma} \\
  =& \mathbf{D}_{\hat{\mathbf{n}}} (\xi)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Every unitary operator $\hat{U}\in\mathcal{U}({}^\P \mathcal{H})$ has a root, that is, there exists an operator $\sqrt{\hat{U}} \in\mathcal{U}({}^\P \mathcal{U})$ such that

$$
  (\sqrt{\hat{U}})^2 = \hat{U}
$$

<details>
<summary>Proof</summary>

From Proposition $\ref{proposition-2}$ we know that there exists $\alpha,\xi\in\R$ and $\hat{\mathbf{n}}\in\mathbb{S}^2$ such that

$$
  \mathbf{U} = e^{i\alpha} \mathbf{D}_{\hat{\mathbf{n}}} (\xi)
$$

With this we set set

$$
  \sqrt{\mathbf{U}} e^{i\frac{\alpha}{2}} \mathbf{D}_{\hat{\mathbf{n}}} \left(\frac{\xi}{2}\right)
$$

From Proposition $\ref{proposition-3}$ we know that $\mathbf{D}_{\hat{\mathbf{n}}} (\xi/2) \in\mathbb{U}({}^\P \mathcal{H})$, and since $e^{i\alpha/2} \in \mathcal{U}({}^\P \mathcal{H})$ it follows that $\sqrt{\mathbf{U}} \in\mathcal{U}({}^\P \mathcal{H})$ as well. Moreover, we find 

$$
\begin{align*}
  (\sqrt{\mathbf{U}})^2 = e^{i\frac{\alpha}{2}} \mathbf{D}_{\hat{\mathbf{n}}} \left(\frac{\xi}{2} \right) e^{i\frac{\alpha}{2}} \mathbf{D}_{\hat{\mathbf{n}}} \left(\frac{\xi}{2}\right) \\
  =& e^{i\alpha} \mathbf{D}_{\hat{\mathbf{n}}} (\xi) = \mathbf{U}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Hadamard transformation' boxType='definition'>
The Hadamard transformation $\hat{H}: {}^\P \mathcal{H} \to {}^\P \mathcal{H}$ is defined as

$$
  \mathbf{H} := \frac{1}{\sqrt{2}}(\boldsymbol{\sigma}_x + \boldsymbol{\sigma}_z) = -i \exp\left[i \frac{\pi}{2} \frac{1}{\sqrt{2}}(\boldsymbol{\sigma}_x + \boldsymbol{\sigma}_z) \right]
$$

and represents rotation about diagonal $(x + z)$-axis by an angle of $\pi$.
</MathBox>

<MathBox title='Properties of Hadamard transformations' boxType='proposition'>
In the basis $\set{\ket{0},\ket{1}}$, the matrix representation of the Hadamard transformation $\mathbf{H}$ is

$$
  \mathbf{H} = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
$$

It satisfies the following properties:

3. $\mathbf{H}\ket{x_j} = \frac{1}{\sqrt{2}}(\ket{0} + e^{\pi ix_j} \ket{1})$
4. $\mathbf{H}^2 = \mathbf{I}_2$
5. $\mathbf{H} = e^{i \frac{3\pi}{2}} \mathbf{D}_{\unitvec{z}} (0) \mathbf{D}_{\unitvec{y}} \left(\frac{\pi}{2}\right) \mathbf{D}_{\mathbf{z}} (-\pi)$
</MathBox>

## Computational basis

The $n$-fold tensor product of qubit spaces is defined as

$$
  {}^\P \mathcal{H}^{\otimes n} := \bigotimes_{j=n-1}^{0} {}^\P \mathcal{H}_j
$$

We denote the $(j+1)$th factor space counting from the right in ${}^\P \mathcal{H}^{\otimes n}$ by ${}^\P \mathcal{H}_j$. In other words, we can write

$$
  {}^\P \mathcal{H}^{\otimes n} = {}^\P \mathcal{H}_{n-1} \otimes\cdots\otimes \overbrace{{}^\P \mathcal{H}_j}^{\text{$(j+1)$th factor}} \otimes\cdots\otimes {}^\P \mathcal{H}_0
$$

The Hilbert tensor product space ${}^\P \mathcal{H}^{\otimes n}$ has dimension $2^n$. Every natural number $x\in\N_0$ with $x < 2^n$ can be expressed in binary form as

$$
  x = \sum_{j=0}^{n-1} x_j 2^j, \; x_j \in\set{0,1}
$$

which results in the usual binary representation

$$
  (x)_2 = x_{n-1} \dots x_0, \; x_j \in\set{0,1}
$$

For each $x$ we define a vector $\ket{x}\in {}^\P \mathcal{H}^{\otimes n}$ as

$$
\begin{align*}
  \ket{x}^n :=& \ket{x_{n-1} \dots x_0} \\
  =& \bigotimes_{j=n-1}^0 \ket{j} 
\end{align*}
$$

If the context of the product space ${}^\P \mathcal{H}^{\otimes}$ is clear, we will also simply write $\ket{x} := \ket{x}^n$.

For the smallest and largest representable numbers, $0$ and $2^n - 1$ in ${}^\P \mathcal{H}^{\otimes n}$, we have

$$
\begin{align*}
  \ket{2^n - 1}^n =& \bigotimes_{j=0}^{n-1} \ket{1} \in {}^\P \mathcal{H}^{\otimes n} \\
  \ket{0}^n =& \bigotimes_{j=0}^{n-1} \ket{0} \in {}^\P \mathcal{H}^{\otimes n}
\end{align*}
$$

The set of vectors $\set{\ket{x}\in {}^\P \mathcal{H}^{\otimes n} | x\in\N_0, x < 2^n}$ forms an orthonormal basis in ${}^\P \mathcal{H}^{\otimes n}$, called the computational basis.

<details>
<summary>Proof</summary>

The inner product of $\ket{x},\ket{y} \in {}^\P \mathcal{H}^{\otimes n}$ is

$$
\begin{align*}
  \braket{x|y} =& \braket{x_{n-1} \dots x_0 | y_{n-1} \dots y_0} \\
  =& \sum_{j=0}^{n-1} \braket{x_j | y_j} = \begin{cases} 1, \quad& x_j = y_j \; \forall j \\ 0, \quad& \text{else} \end{cases} \\
  =& \delta_{xy}
\end{align*}
$$

Hence, $\set{\ket{x} | x\in\N_0, x < 2^n}$ forms a set of $2^n = \dim({}^\P \mathcal{H}^{\otimes n})$ orthonormal vectors in ${}^\P \mathcal{H}^{\otimes n}$. Since the numbe of orthonormal vectors in this set is equal to the dimension of ${}^\P \mathcal{H}^{\otimes n}$, this set constitutes is an orthonormal basis of this Hilbert space.
</details>

<MathBox title='Local operator' boxType='definition'>
An operator $\hat{A}\in\mathcal{L}({}^\P \mathcal{H}^{\otimes n})$ is $k$-local if it is of the form

$$
  \hat{A} = \sum_{j\in I} a_{j_{n-1},\cdots,j_0} \hat{A}_{j_{n-1}} \otimes \cdots \otimes \hat{A}_{j_0}
$$

where $I\subset\N_+$ is an index set and for $j\in I$ and $l\in {0,\dots,n-1}$ we have $a_{j_l} \in\mathbb{C}$ and $\hat{A}_{j_l} \in\mathcal{L}({}^\P \mathcal{H})$, and the index sets

$$
  I_j = \Set{l \in\set{0,\dots,n-1}|A_{j_l} \neq \hat{I}}
$$

of qubits on which the $\hat{A}_{j_{n-1}} \otimes\cdots\otimes\hat{A}_{j_0}$ act non-trivially satisfy $|I_j| \leq k$.
</MathBox>

## Quantum operations

According to the quantum postulates, a quantum system can change in two fundamental ways:
1. **Unitary evolution** governed by a Hamiltonian
2. **State transformation** induced by measurement

However, yet another way to generate a state transformation is to couple our system of interest with another system, forming a composite system. Once combined, we can apply time evolution or measurements to the larger system. Afterward, the added system is discarded, leaving only the transformed state of the original system. This process of extending the system and then discarding part of it occurs in two scenarios:
- **Deliberate use (on purpose):** This happens when we introduce an auxilliary system as a computational resource, typically using ancillary qubits (ancillas). This includes cases where we intentionally measure these ancillas, influencing the evolution of our principal system.
- **Unintended interaction (by error):** This happens when our system of interest cannot be perfectly isolated and interacts with its surrounding environment. Such interactions can lead to decoherence, effectively entangling the system with the environment. If the environment is late observed, it can have measurable effects on the principal system.

The process of transforming a quantum state through enlargement to a composite system can be described in the following steps:
1. **Preparation of the principal system:** We with the principle system $A$ in the initial state
$$
  \hat{\rho}_A \in \mathcal{D}(\mathcal{H}_A)
$$
2. **Enlargement to a composite system:** We introduce an auxilliary system $B$, initially in state  $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$. Assuming the that system $A$ and $B$ are initially separable, the composite system is described by the tensor product state $\hat{\rho}_A \otimes\hat{\rho}_B$. Mathematically, this is represented by the embedding
$$
\begin{align*}
  \iota_{\hat{\rho}_B} : \mathcal{D}(\mathcal{H}_A) \to& \mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B) \\
  \hat{\rho}_A \mapsto& \hat{\rho}_A \otimes \hat{\rho}_B
\end{align*}
$$
3. **Time evolution of the composite system:** The combined system undergoes unitary evolution given by $\hat{U}\in\mathcal{U}(\mathcal{H}_A \otimes \mathcal{H}_B)$ transforming the state as
$$
\begin{align*}
  \hat{U} : \mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B) \to& \mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B) \\
  \hat{\rho}_A \otimes \hat{\rho}_B \mapsto& \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger
\end{align*}
$$
In general, this operation can generate entanglement between $A$ and $B$.

4. **Measurement on system $B$:** Suppose we measure an observable of system $B$, with a corresponding projector $\hat{P}_B$ onto the eigenspace of the observable. Upon otaining an eigenvalue associated with $\hat{P}_B$, the post-measurement state is transformed as
$$
  \hat{U}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger \to \frac{(\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)}{\operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)\hat{U}(\hat{\rho}^A \otimes \hat{\rho}_B) \hat{U}^\dagger \right)}
$$

If no measurement is performed on $B$, we set $\hat{P}_B = \hat{I}_B$, in which case the state remains $\hat{U}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger$. This follows from the fact that
$$
\begin{align*}
  \operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)\hat{U}(\hat{\rho}^A \otimes \hat{\rho}_B) \hat{U}^\dagger \right) =& \operatorname{tr}\left(\hat{U}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger \right) \\
  =& \operatorname{tr}\left((\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger \hat{U} \right) \\
  =& \operatorname{tr}(\hat{\rho}_A \otimes \hat{\rho}_B) = \operatorname{tr}(\hat{\rho}_A) \operatorname{tr}(\hat{\rho}_B) \\
  =& 1
\end{align*}
$$

5. **Tracing out system $B$:** Discarding or ignoring system $B$, the final state of $A$ is obtained by taking the partial trace over $B$:
$$
  \frac{(\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)}{\operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)\hat{U}(\hat{\rho}^A \otimes \hat{\rho}_B) \hat{U}^\dagger \right)} \to \frac{\operatorname{tr}_B \left((\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)\right)}{\operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)\hat{U}(\hat{\rho}^A \otimes \hat{\rho}_B) \hat{U}^\dagger \right)}
$$

Altogether the initial state $\hat{\rho}_A$ of the principal system $A$ of interest is thus transformed as

$$
\begin{equation}
  \hat{\rho}_A \mapsto \frac{\operatorname{tr}_B \left((\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)\right)}{\operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)\hat{U}(\hat{\rho}^A \otimes \hat{\rho}_B) \hat{U}^\dagger \right)} \in\mathcal{D}(\mathcal{H}_A)
\tag{\label{equation-15}}
\end{equation}
$$

<MathBox title='Quantum operation' boxType='definition'>
Let $\mathcal{H}$ be a finite-dimensional Hilbert space. A *quantum operation* is a convex-linear map

$$
\begin{align*}
  \hat{K} : \mathcal{D}(\mathcal{H}) \to& \mathcal{D}_\leq (\mathcal{H}) \\
  \hat{\rho} \mapsto& \hat{K}(\hat{\rho})
\end{align*}
$$

where

$$
  \mathcal{D}_\leq (\mathcal{H}_A) := \set{\hat{\rho} \in\mathcal{H}_A | \hat{\rho}^\dagger = \hat{\rho}, \hat{\rho}\geq 0, \operatorname{tr}(\hat{\rho}) \leq 1}
$$

is the set of positive semi-definite operators with trace at most one. A quantum operation $\hat{K}$ admits two equivalent representations

1. **Operator-sum representation (Kraus representation)**

There exists operators $\hat{K}_l \in\mathcal{L}(\mathcal{H})$ for $l\in\set{1,\dots,m}$, called *Kraus operators* or *operation elements*, such that 

$$
\begin{equation}
  \hat{K}(\hat{\rho}) = \sum_{l=1}^m \hat{K}_l \hat{\rho} \hat{K}_l^\dagger
\tag{\label{equation-13}}
\end{equation}
$$

where $\hat{K}_l$ satisfy $\sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \leq \hat{I}$.

2. **Environmental representation (Stinespring representation):**

There exists an auxilliary Hilbert space $\mathcal{H}_B$, a density operator $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$ and an isometry $\hat{V}\in\mathcal{B}(\mathcal{H} \otimes \mathcal{H}_B)$ satisfying $\hat{V}^\dagger \hat{V} \leq \hat{I}$ such that

$$
\begin{equation}
  \hat{K}(\rho) = \operatorname{tr}_B \left(\hat{V}(\hat{\rho}\otimes\hat{\rho}_B)\hat{V}^\dagger \right)
\tag{\label{equation-14}}
\end{equation}
$$

A quantum operation $\hat{K}$ is called *trace-preserving* (or a *quantum channel*) if

$$
  \sum_{k=1}^m \hat{K}_l^\dagger \hat{K}_l = \hat{I}
$$

which is equivalent to $\operatorname{tr}\left(\hat{K}(\rho)\right) = 1 = \operatorname{tr}(\rho)$ for all $\hat{\rho}\in\mathcal{D}(\mathcal{H})$. In this case, $\hat{K}$ is an operator on $\mathcal{D}(\mathcal{H})$, i.e. $\hat{K}:\mathcal{D}(\mathcal{H}) \to\mathcal{D}(\mathcal{H})$.
</MathBox>

<MathBox title='' boxType='proposition'>
Let $\hat{K}: \mathcal{D}(\mathcal{H}) \to\mathcal{D}_\leq (\mathcal{H})$ be a quantum operation with Kraus operators $\hat{K}_l \in\mathcal{L}(\mathcal{H})$ for $l\in\set{1,\dots,m}$. Additionally, let $\tilde{m}\geq m$ and consider a unitary matrix $\mathbf{U}\in\mathrm{U}(\tilde{m})$ be a unitary $\tilde{m}\times\tilde{m}$ matrix. Then the operators $\tilde{K}_j \in\mathcal{L}(\mathcal{H})$ with $j\in\set{1,\dots,\tilde{m}}$ given by

$$
  \tilde{\hat{K}}_j = \sum_{l=1}^m \mathbf{U}_{jl} \mathbf{K}_l
$$

are Kraus operators for $\hat{K}$ as well.

<details>
<summary>Proof</summary>

Note that the Hermitian of adjoint of $\tilde{\hat{K}}$ is

$$
  \tilde{\hat{K}}_j^\dagger = \sum_{l=1}^m \mathbf{U}_{jl}^* \hat{K}_l^\dagger = \sum_{l=1}^m \mathbf{U}_{lj}^\dagger \hat{K}_l
$$

We expand $\eqref{equation-13}$ for $\tilde{\hat{K}}$

$$
\begin{align*}
  \sum_{j=1}^{\tilde{m}} \tilde{\hat{K}}_j^\dagger \tilde{\hat{K}}_j =& \sum_{j=1}^{\tilde{m}} \left(\sum_{l=1}^m \mathbf{U}_{lj}^\dagger \hat{K}_l^\dagger \right) \left(\sum_{k=1}^m \mathbf{U}_{jk} \hat{K}_k \right) \\
  =& \sum_{l, k=1}^m \left(\sum_{j=1}^{\tilde{m}} \mathbf{U}_{lj}^\dagger \mathbf{U}_{jk} \right) \hat{K}_l^\dagger \hat{K}_k \\
  =& \sum_{l,k=1}^m \underbrace{(\mathbf{U}^\dagger \mathbf{U})}_{\delta_{lk}} \hat{K}_l^* \hat{K}_k = \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \\
  \leq& \hat{I}
\end{align*}
$$

This shows that $\tilde{\hat{K}}_l$ are valid Kraus operators.

The proof of $\eqref{equation-14}$ is almost identical since for any $\hat{\rho}\in\mathcal{D}(\mathcal{H})$, we have

$$
\begin{align*}
  \sum_{j=1}^{\tilde{m}} \tilde{\hat{K}}_j^\dagger \tilde{\hat{K}}_j =& \sum_{j=1}^{\tilde{m}} \left(\sum_{l=1}^m \mathbf{U}_{lj}^* \hat{K}_l^\dagger \right)\hat{\rho}\left( \sum_{k=1}^m \mathbf{U}_{jk}^* \hat{K}_k^\dagger \right) \\
  =& \sum_{l,k=1}^m \left(\sum_{j=1}^{\tilde{m}} \mathbf{U}_{lj}^\dagger \mathbf{U}_{jk} \right) \hat{K}_l^\dagger \hat{\rho}\hat{K}_k \\
  =& \sum_{l,k=1}^m \underbrace{\left(\mathbf{U}^\dagger \mathbf{U} \right)_{lk}}_{=\delta_{lk}} \hat{K}_l^\dagger \hat{\rho} \hat{K}_k = \sum_{l=1}^m \hat{K}_l^\dagger \hat{\rho} \hat{K}_l \\
  =& \hat{K}(\hat{\rho})
\end{align*}
$$

This shows that $\tilde{\hat{K}}$ is a valid operator-sum representation.
</details>
</MathBox>

A state transformation $\eqref{equation-15}$ can be formulated in terms of the quantum operation

$$
  \hat{K}(\hat{\rho}_A) = \operatorname{tr}_B \left(\hat{V} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger \right)
$$

in its environmental representation, where $\hat{V} = (\hat{I}_A \otimes \hat{P}_B)\hat{U}$ with $\hat{U}\in\mathcal{U}(\mathcal{H}_A \otimes \mathcal{H}_B)$.

<details>
<summary>Details</summary>

Since the orthogonal projection $\hat{P}_2$ satisfies

$$
  \hat{I}_A \otimes \hat{P}_B = \hat{I}_A \otimes \hat{P}_B^2 = \left(\hat{I}_A \otimes \hat{P}_B \right)^2
$$

and

$$
  \hat{I}_A \otimes \hat{P}_B = \hat{I}_A \otimes \hat{P}_B^\dagger = (\hat{I}_A \otimes \hat{P}_B)^\dagger
$$

we have

$$
\begin{align*}
  \operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger \right) =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)^2 \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger \right) \\
  =& \operatorname{tr}\left( (\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I} _A \otimes \hat{P}_B) \right) \\
  =& \operatorname{tr}\left( (\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I} _A \otimes \hat{P}_B)^\dagger \right) \\
  =& \operatorname{tr}\left( (\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \left((\hat{I} _A \otimes \hat{P}_B) \hat{U}\right)^\dagger \right) \\
  =& \operatorname{tr}\left(\hat{V} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger \right) \\
  =& \operatorname{tr}\left(\operatorname{tr}_B \left(\hat{V} (\hat{\rho}_A \otimes \hat{\rho}_B) \right) \right) \\
  =& \operatorname{tr}\left(\hat{K}(\hat{\rho})\right)
\end{align*}
$$
</details>

In terms of $\hat{K}$, the state transformation $\eqref{equation-15}$ can be expressed as

$$
  \frac{\operatorname{tr}_B \left((\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)\right)}{\operatorname{tr}\left((\hat{I}_A \otimes \hat{P}_B)\hat{U}(\hat{\rho}^A \otimes \hat{\rho}_B) \hat{U}^\dagger \right)} \in\mathcal{D}(\mathcal{H}_A) = \frac{\hat{K}(\hat{\rho}_A)}{\operatorname{tr}\left(\hat{K}(\hat{\rho}_A) \right)}
$$

Consequently, the total state transformation can be expressed succintly in terms of a quantum operation $\hat{K}$ in the form

$$
\begin{align*}
  \mathcal{D}(\mathcal{H}_A) \to& \mathcal{D}(\mathcal{H}_A) \\
  \hat{\rho}_A \mapsto& \frac{\hat{K}(\hat{\rho}_A)}{\operatorname{tr}\left(\hat{K}(\hat{\rho})\right)}
 \end{align*}
$$

<MathBox title='' boxType='proposition'>
Let $\hat{K}:\mathcal{D}(\mathcal{H}_A) \to\mathcal{D}_\leq (\mathcal{H}_A)$ be a quantum operation in the environmental representation given by

$$
  \hat{K}(\hat{\rho}_A) = \operatorname{tr}_B \left( (\hat{I}_A \otimes \hat{P}_B) \hat{U} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B) \right)
$$

where $\hat{P}_B \in\mathcal{L}(\mathcal{H}_B)$ is an orthonormal projection, $\hat{U}\in\mathcal{U}(\mathcal{H}_A \otimes \mathcal{H}_B)$ and $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$. Then we have

$$
  [\hat{I}^A \otimes \hat{P}_B, \hat{U}] = 0 \implies \operatorname{tr}\left(\hat{K}(\hat{\rho}_A) \right) = \operatorname{tr}\left(\hat{\rho}_B \hat{P}_B \right), \; \hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)
$$

and in particular fo $\hat{P}_B = \hat{I}_B$ it follows that

$$
  \operatorname{tr}\left(\hat{K}(\hat{\rho}_A)\right) = 1, \; \forall \hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)
$$

<details>
<summary>Proof</summary>

The quantum operation $\hat{K}$ is in environmental representation with $\hat{V} = (\hat{I}_A \otimes \hat{P}_B)\hat{U}$ such that

$$
\begin{align*}
  \hat{V}^\dagger =& \left((\hat{I}_A \otimes \hat{P}_B)\hat{U}\right)^\dagger = \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B) \\
  =& \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B^\dagger) = \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)
\end{align*}
$$

and thus since $[\hat{I}_A \otimes \hat{P}_B, \hat{U}] = 0$

$$
\begin{align*}
  \hat{V}^\dagger \hat{V} =& \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)(\hat{I}_A \otimes \hat{P}_B)\hat{U} \\
  =& \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B^2)\hat{U} = \hat{U}^\dagger (\hat{I}_A \otimes \hat{P}_B)\hat{U} \\
  =& \hat{U}^\dagger \hat{U} (\hat{I}_A \otimes\hat{P}_B) = \hat{I}_A \otimes \hat{P}_B
\end{align*}
$$

Furthermore, we have a set of Kraus operators $\hat{K}_l$ for $\hat{K}$ such that

$$
\begin{align*}
  \sum_l \hat{K}_l^\dagger \hat{K}_l =& \operatorname{tr}_B \left((\hat{I}_A \otimes\sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \right) \\
  =& \operatorname{tr}_B \left((\hat{I}_A \otimes \sqrt{\hat{\rho}_B})(\hat{I}_A \otimes\hat{P}_B)(\hat{I}_A \otimes\sqrt{\hat{P}_B}) \right) \\
  =& \operatorname{tr}_B \left(\hat{I}_A \otimes\sqrt{\hat{\rho}_B} \hat{P}_B \sqrt{\hat{\rho}_B} \right) \\
  =& \operatorname{tr}\left(\sqrt{\hat{\rho}_B} \hat{P}_B \sqrt{\hat{\rho}_B} \right) \hat{I}_A \\
  =& \operatorname{tr}\left( \sqrt{\hat{\rho}_B^2} \hat{P}_B \right) \hat{I}_A \\
  =& \operatorname{tr}(\hat{\rho}_B \hat{P}_B) \hat{I}_A
\end{align*}
$$

Applying Proposition $\ref{proposition-}$ with $\kappa = \operatorname{tr}(\hat{\rho}_B \hat{P}_B)$ then implies that $\operatorname{tr}\left(\hat{K}(\hat{\rho}) \right) = \operatorname{tr}(\hat{\rho}_B \hat{P}_B)$. If $\hat{P}_B = \hat{I}_B$, then $\operatorname{tr}\left(\hat{K}(\hat{\rho})\right) = \operatorname{tr}(\hat{\rho}_B) = 1$ since $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$.
</details>
</MathBox>

If the time evolution $\hat{U}\in\mathcal{U}(\mathcal{H}_A \otimes\mathcal{H}_B)$ of the combined system acts separably on the two subsystems $\mathcal{H}_A$ and $\mathcal{H}_B$ in the sense that it commutes with the measurement projections $\hat{I}_A \otimes\hat{P}_B$ on subsystem $\mathcal{H}_B$, the trace of the overall quantum operation can be determined from the product $\hat{\rho}_B \hat{P}_B$.

Since the domain $\mathcal{D}(\mathcal{H})$ of a quantum operation $\hat{K}$ is convex, it follows that for each $\hat{\rho}_1, \hat{\rho}_2 \in\mathcal{D}(\mathcal{H})$ and $u\in[0,1]$, we have

$$
  u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \in\mathcal{D}(\mathcal{H})
$$

Every quantum operation $\hat{K}$ is convex-linear, meaning it satisfies

$$
  \hat{K}\left(u\hat{\rho}_1 + (1 - u) \hat{\rho}_2 \right) = u\hat{K}(\hat{\rho}_1) + (1 - u)\hat{K}(\hat{\rho}_2)
$$

For a single qubit system $\mathcal{H} = {}^\P \mathcal{H}$, every $\hat{\rho}\in\mathcal{D}({}^\P \mathcal{H})$ can be parametrized by a Bloch vector $\mathbf{x}\in \mathcal{B}_1 (\R^3)$ expressed as

$$
  \hat{\rho}_\mathbf{x} = \frac{1}{2}(\mathbf{I}_2 + \mathbf{x}\cdot\boldsymbol{\sigma})
$$

where $\boldsymbol{\sigma}$ is the vector of Pauli matrices. Thus, the image of a trace-preserving quantum operation $\hat{K}:\mathcal{D}({}^\P \mathcal{H}) \to\mathcal{D}({}^\P \mathcal{H})$ on a single qubit must be of the form

$$
  \hat{K}(\hat{\rho}) = \frac{1}{2}\left(\mathbf{I}_2 + \mathbf{y}(\mathbf{x}) \cdot\hat{\sigma} \right)
$$

where $\mathbf{y}(\mathbf{x}) = \operatorname{tr}\left(\hat{K}(\hat{\rho}_\mathbf{x}) \hat{\sigma} \right)$. Consequently, every trace-preserving quantum operation $\hat{K}$ on a single qubit defines a tranformation $\hat{K} :\mathcal{B}_1 (\R^3) \to \mathcal{B}_1 (\R^3)$ given by 

$$
\begin{equation}
  \mathbf{x} \mapsto \operatorname{tr}\left(\hat{K}(\hat{\rho}_\mathbf{x}) \hat{\sigma} \right)
\tag{\label{equation-16}}
\end{equation}
$$

<details>
<summary>Proof</summary>

To show that $\hat{K}(\hat{\rho})$ for a single qubit is convex-linear, note that for any Bloch vectors $\mathbf{x}_1, \mathbf{x}_2 \in\mathcal{B}_1 (\R^3)$, we have

$$
\begin{align*}
  \hat{\rho}_{u\mathbf{x}_1 + (1 - u)\mathbf{x}_2} =& \frac{1}{2}\left(\hat{I}_2 + (u\mathbf{x}_1 + (1 - u)\mathbf{x}_2) \cdot\boldsymbol{\sigma} \right) \\
  =& u \frac{1}{2} (\mathbf{I}_2 + \mathbf{x}_2 \cdot\boldsymbol{\sigma}) + (1 - u) \frac{1}{2}(\mathbf{I} + \mathbf{x}_2 \cdot\boldsymbol{\sigma}) \\
  =& u\hat{rho}_{\mathbf{x}_1} + (1 - u)\hat{\rho}_{\mathbf{x}_2}
\end{align*}
$$

and thus

$$
\begin{align*}
  \hat{K}(u\mathbf{x}_1 + (1 - \mu)\mathbf{x}_2) =& \operatorname{tr}\left(\hat{K}(\hat{\rho}_{u\mathbf{x}_1 + (1 - u)\mathbf{x}_2})\hat{\sigma} \right) \\
  =& \operatorname{tr}\left(\hat{K}(u \hat{\rho}_{\mathbf{x}_1} + (1 - u) \hat{\rho}_{\mathbf{x}_2} )\hat{\sigma} \right) \\
  =& \operatorname{tr}\left(u \hat{K}_(\hat{\rho}_{\mathbf{x}_1}) \sigma +(1 - u) \hat{K}(\hat{\rho}_{\mathbf{x}_2}) \hat{\sigma} \right) \\
  =& u \operatorname{tr}\left(\hat{K}(\hat{\rho}_{\mathbf{x}_1} \hat{\sigma}) + (1 - u)\boldsymbol{tr}\left(\hat{K}(\hat{\rho}_{\mathbf{x}_2})\right) \hat{\sigma} \right) \\
  =& u \hat{K}(\mathbf{x}_1) + (1 - u)\hat{K}(\mathbf{x}_2)
\end{align*}
$$

completing the proof.
</details>

### Equivalence of quantum operation representations

<MathBox title='' boxType='lemma' tag='lemma-1'>
Let $\mathcal{H}$ be a Hilbert space and for $l\in\set{1,\dots,m}$ let $\hat{K}_l \in \mathcal{L}(\mathcal{H})$. Then for any density operator $\hat{\rho}\in\mathcal{D}(\mathcal{H})$ the operator

$$
  \hat{K}(\hat{\rho}) = \sum_{l=1}^m \hat{K}_l \hat{\rho} \hat{K}_l^\dagger
$$

satifies $\hat{K}^\dagger (\hat{\rho}) = \hat{K}(\hat{\rho})$ and $0 \leq \hat{K}(\hat{\rho})$. Moreover, for any $\kappa\in (0,1]$ we have

$$
\begin{equation}
  \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I} \iff \operatorname{tr}(\hat{K}(\hat{\rho})) \leq \kappa, \;\forall \hat{\rho}\in\mathcal{D}(\mathcal{H})
\tag{\label{equation-5}}
\end{equation}
$$

and the equality in one side implies equality in the other.

<details>
<summary>Proof</summary>

By Hermiticity of $\hat{\rho}$ we have

$$
\begin{align*}
  \hat{K}^\dagger =& \left(\sum_{l=1}^m \hat{K}_l \hat{\rho} \hat{K}_l^\dagger \right)^\dagger = \sum_{l=1}^m (\hat{K}_l \hat{\rho} \hat{K}_l^\dagger)^\dagger \\
  =& \sum_{l=1}^m (\hat{K}_l^\dagger)^\dagger \hat{\rho}^\dagger \hat{K}_l^\dagger = \sum_{l=1}^m \hat{K}_l \hat{\rho} \hat{K}_l^\dagger \\
  =& \hat{K}(\rho)
\end{align*}
$$

and likewise by Hermiticity of $\hat{K}(\hat{\rho})$

$$
\begin{align*}
  \left(\sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \right)^\dagger =& \sum_{l=1}^m (\hat{K}_l^\dagger \hat{K}_l)^\dagger = \sum_{l=1}^m \hat{K}_l^\dagger (\hat{K}_l^\dagger)^\dagger \\
  =& \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l
\end{align*}
$$

By positivity of $\hat{\rho}$, we have for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \braket{\psi|\hat{K}(\hat{\rho})|\psi} =& \Braket{\psi|\sum_{l=1}^m \hat{K}_l \hat{\rho} \hat{K}_l^\dagger|\psi} \\
  =& \sum_{l=1}^m \braket{\psi|\hat{K}_l \hat{\rho}\hat{K}_l^\dagger|\psi} \\
  =& \sum_{l=1}^m \braket{\hat{K}_l^\dagger \psi|\hat{\rho}|\hat{K}_l^\dagger \psi} \geq 0
\end{align*}
$$

Next, we show $\implies$ in $\eqref{equation-5}$. Since $\sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l$ is Hermitian it admits a spectral decomposition

$$
\begin{equation}
  \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l = \sum_a \lambda_a \ket{e_a} \bra{e_a}
\tag{\label{equation-6}}
\end{equation}
$$

where $\set{\ket{e_a}} \subset\mathcal{H}$ is an orthonormal eigenbasis for eigenvalues $\set{\lambda_a}$. Consequently, we find for every eigenvalue $\lambda_a$ that

$$
\begin{align*}
  \lambda_a =& \Braket{e_a|\sum_{a'} \lambda_{a'} \ket{e_{a'}} \bra{e_{a'}}| e_a} = \Braket{e_a|\sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l|e_a} \\
  \leq& \braket{e_a|\kappa e_a} = \kappa
\end{align*}
$$

Thus, we obtain for any $\hat{\rho}\in\mathcal{D}(\mathcal{H})$

$$
\begin{align*}
  \operatorname{tr}\left(\hat{K}(\hat{\rho})\right) =& \operatorname{tr}\left(\sum_{l=1}^m \hat{K}_l \hat{\rho} \hat{K}_l^\dagger \right) = \sum_{l=1}^m \operatorname{tr}(\hat{K}_l \hat{\rho} \hat{K}_l^\dagger) \\
  =& \sum_{l=1}^m \operatorname{tr}(\hat{\rho}\hat{K}_l^\dagger \hat{K}_l) = \operatorname{tr}\left(\hat{\rho} \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \right) \\
  =& \operatorname{tr}\left(\hat{\rho} \sum_a \lambda_a \ket{e_a} \bra{e_a} \right) = \sum_a \lambda_a \operatorname{tr}(\hat{\rho}\ket{e_a}\bra{e_a}) \\
  \leq& \kappa \sum_a \operatorname{tr} (\hat{\rho}\ket{e_a}\bra{e_a}) = \kappa \sum_{a,a'} \braket{e_{a'}|\hat{\rho}|e_a} \underbrace{\braket{e_a|e_{a'}}}_{=\delta_{aa'}} \\
  =& \kappa \sum_a \braket{e_a|\hat{\rho}|e_a} = \kappa \operatorname{tr}(\hat{\rho}) \\
  =& \kappa
\end{align*}
$$

proving

$$
  \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I} \implies \operatorname{tr}\left(\hat{K}(\hat{\rho}) \right) \leq \kappa, \; \forall \hat{\rho}\in\mathcal{D}(\mathcal{H})
$$

We also see that $\sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l = \kappa\hat{I}$ implies

$$
  \operatorname{tr}\left(\hat{K}(\hat{\rho})\right) = \operatorname{tr}(\hat{\rho}\kappa) = \kappa \operatorname{tr}(\hat{\rho}),\;\forall \hat{\rho}\in\mathcal{D}(\mathcal{H})
$$

To show $\impliedby$ in $\eqref{equation-5}$, we also note that $\operatorname{tr}\left(\hat{K}(\hat{\rho}) \right) \leq \kappa$ implies for every $\hat{\rho}\in\mathcal{D}(\mathcal{H})$

$$
  \kappa \geq \operatorname{tr}\left(\hat{\rho} \sum_{l=1}^m  \hat{K}_l^\dagger \hat{K}_l \right) = \sum_a \lambda_a \operatorname{tr}(\hat{\rho}\ket{e_a} \bra{e_a})
$$

Choosing $\hat{\rho} = \ket{e_{a'}} \bra{e_{a'}}$, we have $\operatorname{tr}(\hat{\rho}\ket{e_a}\bra{e_a}) = \delta_{aa'}$. It follows that $\lambda_a \leq \kappa$ for all $a$ and thus from $\eqref{equation-6}$ that

$$
  \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}
$$

Similarly, $\operatorname{tr}(\hat{K}(\rho)) = \kappa$ implies $\sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l = \kappa\hat{I}$.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-2'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces and let $\hat{V}\in\mathcal{B}(\mathcal{H}_A \otimes \mathcal{H}_B)$ be a bounded operator satisfying $\hat{V}^\dagger \hat{V} \leq \kappa \hat{I}_{AB}$ for any $\kappa\in (0,1]$. For $b_1, b_2 \in\set{1,\dots,\dim(\mathcal{H}_B)}$, define the operators $\hat{K}_{(b_1, b_2)}$ by specifying their matrix elements $(\hat{K}_{(b_1, b_2)})_{a_1 a_2}$ in the orthonormal basis $\set{\ket{e_a}}$ as

$$
  (\hat{K}_{(b_1, b_2)})_{a_1 a_2} = \left(\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}_B})\right)_{a_1 b_2, a_2 b_2}
$$

Then for any nonzero $\ket{\psi}\in\mathcal{H}_A$, we have

$$
  \Braket{\psi | \sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)}|\psi} = \frac{1}{\norm{\psi}^2} \operatorname{tr}\left((\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}) \right)
$$

where

$$
  \operatorname{tr}\left((\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}) \right) \leq \kappa \norm{\psi}^4
$$

<details>
<summary>Proof</summary>

Note that for any nonzero $\ket{\psi}\in\mathcal{H}_A$ we have

$$
\begin{align*}
  (\ket{\psi}\bra{\psi} \otimes\hat{I}_B)^2 =& \ket{\psi}\braket{\psi|\psi} \ket{\psi} \otimes \hat{I}_B \\
  =& \norm{\psi}^2 (\ket{\psi}\bra{\psi} \otimes\hat{I}_B) 
\end{align*}
$$

Using an orthonormal basis $\set{\ket{e_a}}\subset\mathcal{H}_A$, we find

$$
\begin{align*}
  &\Braket{\psi|\sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)}|\psi} \\
  =& \sum_{a_1, a_2} \braket{\psi|e_{a_1}} \Braket{e_{a_1}|\sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)}|e_{a_2}} \braket{e_{a_2}|\psi} \\
  =& \sum_{a_1, a_2} \braket{e_{a_2}|\psi} \braket{\psi|e_{a_1}} \Braket{e_{a_1}|\sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)}|e_{a_2}} \\
  =& \operatorname{tr}\left(\ket{\psi}\bra{\psi} \sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)} \right) \\
  =& \operatorname{tr}\left(\ket{\psi}\bra{\psi} \operatorname{tr}_B \left((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \right) \right) \\
  =& \operatorname{tr}\left((\ket{\psi}\bra{\psi} \otimes \hat{I}_B) (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B})\right) \\
  =& \frac{1}{\norm{\psi}^2} \operatorname{tr}\left((\ket{\psi}\bra{\psi} \otimes \hat{I}_B)^2 (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B})\right) \\
  =& \frac{1}{\norm{\psi}^2} \operatorname{tr}\left((\ket{\psi}\bra{\psi} \otimes \hat{I}_B)^2 (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B})(\ket{\psi}\bra{\psi}\otimes\hat{I}_B)\right) \\
  =& \frac{1}{\norm{\psi}^2} \operatorname{tr}\left((\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}) \right)
\end{align*}
$$

To prove the upper bound of the trace, let $\set{\ket{e_a \otimes f_b}}$ be an orthonormal basis of $\mathcal{H}_A \otimes \mathcal{H}_B$. Then

$$
\begin{align*}
  &\operatorname{tr}\left(\left(\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}\right) \hat{V}^\dagger \hat{V} \left(\ket{\psi}\bra{\psi} \otimes \sqrt{\hat{\rho}_B}\right) \right) \\
  =& \sum_{a,b} \Braket{e_a \otimes f_b|\left(\ket{\psi}\bra{\psi} \otimes\sqrt{\hat{\rho}_B}\right)\hat{V}^\dagger \hat{V} \left(\ket{\psi}\bra{\psi}\otimes\sqrt{\hat{\rho}_B}\right)|e_a \otimes f_b} \\
  =& \sum_{a,b} \Braket{\left(\ket{\psi}\bra{\psi} \otimes\sqrt{\hat{\rho}_B}\right)^\dagger e_a \otimes f_b |\hat{V}^\dagger \hat{V}| \left(\ket{\psi}\bra{\psi}\otimes\sqrt{\hat{\rho}_B}\right) e_a \otimes f_b} \\
  =& \sum_{a,b} \Braket{\left(\ket{\psi}\bra{\psi}^\dagger \otimes\sqrt{\hat{\rho}_B}^\dagger\right) e_a \otimes f_b |\hat{V}^\dagger \hat{V}| \left(\ket{\psi}\bra{\psi}\otimes\sqrt{\hat{\rho}_B}\right) e_a \otimes f_b} \\
  =& \sum_{a,b} \Braket{\left(\ket{\psi}\bra{\psi} \otimes\sqrt{\hat{\rho}_B}\right) e_a \otimes f_b |\hat{V}^\dagger \hat{V}| \left(\ket{\psi}\bra{\psi}\otimes\sqrt{\hat{\rho}_B}\right) e_a \otimes f_b} \\
  =& \sum_{a,b} \Braket{\ket{\psi}\braket{\psi|e_a} \otimes \sqrt{\hat{\rho}_B}\ket{f_b} |\hat{V}^\dagger \hat{V}| \ket{\psi}\braket{\psi|e_a}\otimes\sqrt{\hat{\rho}_B} \ket{f_b}} \\
  =& \sum_{a,b} |\braket{e_a|\psi}|^2 \Braket{\ket{\psi} \otimes \sqrt{\hat{\rho}_B}\ket{f_b} |\hat{V}^\dagger \hat{V}| \ket{\psi}\otimes\sqrt{\hat{\rho}_B} \ket{f_b}} \\
  \leq& \kappa \sum_{a,b} |\braket{e_a|\psi}|^2 \Braket{\ket{\psi} \otimes \sqrt{\hat{\rho}_B}\ket{f_b} | \ket{\psi}\otimes\sqrt{\hat{\rho}_B} \ket{f_b}} \\
  =& \kappa\norm{\psi}^2 \sum_b \braket{\psi|\psi} \Braket{\sqrt{\hat{\rho}_B}\ket{f_b}|\sqrt{\hat{\rho}_B}\ket{f_b}} \\
  =& \kappa\norm{\psi}^4 \sum_b \Norm{\sqrt{\rho}_B f_b}^2 = \kappa \norm{\psi}^4 \sum_b \norm{\sqrt{q_b} f_b}^2 \\
  =& \kappa\norm{\psi}^4 \sum_b q_b \underbrace{\norm{f_b}^2}_{=1} = \kappa\norm{\psi}^4 \underbrace{\sum_b q_b}_{=1} \\
  =& \kappa\norm{\psi}^4
\end{align*}
$$

</details>
</MathBox>

<MathBox title='Equivalence of operator-sum and environmental representation of quantum operations' boxType='theorem' tag='theorem-1'>
Let $\mathcal{H}_A$ be a finite-dimensional Hilbert space, and consider the convex-linear map

$$
\begin{align*}
  K:\mathcal{D}(\mathcal{H}_A) \to& \mathcal{D}_\leq (\mathcal{H}_A) \\
  \hat{\rho}_A \mapsto& \hat{K}(\hat{\rho}_A)
\end{align*}
$$

where

$$
  \mathcal{D}_\leq (\mathcal{H}_A) := \set{\hat{\rho} \in\mathcal{H}_A | \hat{\rho}^\dagger = \hat{\rho}, \hat{\rho}\geq 0, \operatorname{tr}(\hat{\rho}) \leq 1}
$$

Then for any $\kappa\in (0,1]$, the following equivalence holds: There exists a finite-dimensional Hilbert space $\mathcal{H}_B$, a bounded operator $\hat{V}\in\mathcal{B}(\mathcal{H}_A \otimes \mathcal{H}_B)$ and a density operator $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$ such that 

$$
\begin{equation}
  \hat{V}^\dagger \hat{V} \leq \kappa \hat{I}_{AB}
\tag{\label{equation-7}}
\end{equation}
$$

and

$$
\begin{equation}
  \hat{K}(\hat{\rho}_A) = \operatorname{tr}^B \left(\hat{V}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger \right)
\tag{\label{equation-8}}
\end{equation}
$$

if and only if there exist operators $\hat{K}_l \in\mathcal{L}(\mathcal{H}_A)$ for $l \in\set{1,\dots,m}$ with $m\leq \dim(\mathcal{H}_B)^2$ such that

$$
\begin{equation}
  \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}_A
\tag{\label{equation-9}}
\end{equation}
$$

and

$$
\begin{equation}
  \hat{K}(\hat{\rho}_A) = \sum_{l=1}^m \hat{K}_l \hat{\rho}_A \hat{K}_l^\dagger
\tag{\label{equation-10}}
\end{equation}
$$

Within this equivalence we have the special case

$$
  \hat{V}^\dagger \hat{V} = \kappa\hat{I}_{AB} \iff \sum_{l=1}^m \hat{K}_l^\dagger \hat{K}_l = \kappa\hat{I}_A
$$

<details>
<summary>Proof</summary>

From Lemma $\ref{lemma-1}$ we know that any superoperator of the form $\eqref{equation-10}$ maps into $\mathcal{D}_\leq (\mathcal{H}_A)$. Hence, it remains to prove the equivalence.

**($\implies$):** Let $\hat{V}\in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$ be such that it satisfies $\eqref{equation-7}$ and $\eqref{equation-8}$. Let $\set{\ket{e_a}}$ be an orthonormal basis of $\mathcal{H}_A$. From properties of density operators, we know that there exists an orthonormal basis $\set{\ket{f_b}}\subset\mathcal{H}_B$ and a set of eigenvectors $q_b \geq 0$ with $\sum_b q_b = 1$ admitting the spectral decomposition

$$
  \hat{\rho}_B = \sum_b q_b \ket{f_b} \bra{f_b}
$$

Using this, we also define

$$
  \sqrt{\hat{\rho}_B} = \sum_b \sqrt{q_b} \ket{f_b} \bra{f_b}
$$

which satisfies

$$
\begin{align*}
  (\sqrt{\hat{\rho}})^2 =& \sum_{b_1, b_2} \sqrt{q_{b_1} q_{b_2}} \ket{f_{b_1}} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{=\delta_{b_1 b_2}} \bra{f_{b_2}} \\
  =& \sum_b q_b \ket{f_b} \bra{f_b} = \hat{\rho}_B
\end{align*}
$$

and

$$
\begin{align*}
  (\sqrt{\hat{\rho}_B})^\dagger =& \left(\sum_b \sqrt{q_b} \ket{f_b} \bra{f_b} \right) \\
  =& \sum_b \sqrt{q_b} (\ket{f_b} \bra{f_b})^\dagger \\
  =& \sum_b \sqrt{q_b} \ket{f_b} \bra{f_b} = \sqrt{\hat{\rho}_B}
\end{align*}
$$

For $b_1, b_2 \in\set{1,\dots,\dim(\mathcal{\mathcal{H}_B})}$ we then define the operators $\hat{K}_{(b_1, b_2)}$ by specifying their matrix elements $(\hat{K}_{(b_1, b_2)})_{a_1 a_2}$ in the orthonormal basis $\set{\ket{e_a}}$ as

$$
  (\hat{K}_{(b_1, b_2)})_{a_1 a_2} = (\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}_B}))_{a_1 b_1, a_2 b_2}
$$

Then we have

$$
\begin{align*}
  (\hat{K}_{(b_1, b_2)}^\dagger)_{a_1 a_2} =& (\hat{K}_{(b_1, b_2)})_{a_1 a_2}^* \\
  =& (\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}_B}))_{a_1 b_1, a_2 b_2}^* \\
  =& (\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}_B}))_{a_1 b_1, a_2 b_2}^\dagger \\
  =& ((\hat{I}_A \otimes \sqrt{\hat{\rho}_B})^\dagger \hat{V}^\dagger)_{a_1 b_1, a_2 b_2} \\
  =& ((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}^\dagger) \hat{V}^\dagger)_{a_1 b_1, a_2 b_2} \\
  =& ((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger)_{a_1 b_1, a_2 b_2}
\end{align*}
$$

and thus

$$
\begin{align*}
  & \left(\sum_{b_1, b_2} \hat{K}_{(b_1, b_2)} \hat{\rho}_A \hat{K}_{(b_1, b_2)}^\dagger \right) = \sum_{b_1, b_2} \sum_{a_3, a_4} (\hat{K}_{(b_1, b_2)})_{a_1 a_3} \boldsymbol{\rho}_{a_3 a_4}^{(A)} (\hat{K}_{(b_1, b_2)}^\dagger)_{a_4 a_2} \\
  =& \sum_{b_1, b_2} \sum_{a_3, a_4} \left(\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\right)_{a_1 b_1, a_3 b_2} \boldsymbol{\rho}_{a_3 a_4}^{(A)} \left((\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\hat{V}^\dagger\right)_{a_4 b_2, a_2 b_1} \\
  =& \sum_{b_1, b_2, b_3} \sum_{a_3, a_4} \left(\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\right)_{a_1 b_1, a_3 b_2} \boldsymbol{\rho}_{a_3 a_4}^{(A)} \delta_{b_2, b_3} \left((\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\hat{V}^\dagger\right)_{a_4 b_3, a_2 b_1} \\
  =& \sum_{b_1, b_2, b_3} \sum_{a_3, a_4} \left(\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\right)_{a_1 b_1, a_3 b_2} \underbrace{(\hat{\rho}_A \otimes \hat{I}_B)_{a_3 b_2, a_4, b_3}}_{=\boldsymbol{\rho}_{a_3 a_4}^{(A)} \delta_{b_2, b_3}} \left((\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\hat{V}^\dagger\right)_{a_4 b_3, a_2 b_1} \\
  =& \sum_b \left(\hat{V}(\hat{I}_A \otimes \sqrt{\hat{\rho}^B}) (\hat{\rho}_A \otimes \hat{I}_B) (\hat{I}_A \otimes \sqrt{\hat{\rho}^B})\hat{V}^\dagger \right)_{a_1 b, a_2 b} \\
  =& \sum_b \left(\hat{V}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger\right)_{a_1 b, a_2 b} \\
  =& \operatorname{tr}_B \left(\hat{V} (\hat{\rho}_A \otimes \hat{\rho}_B)\hat{V}^\dagger \right)_{a_1 a_2} \\
  =& \hat{K}(\hat{\rho}_A) _{a_1 a_2}
\end{align*}
$$

proving $\eqref{equation-10}$. The sums $\sum_{b_1, b_2}$ run over the index sets indexing an orthonormal basis of $\mathcal{H}_B$ and thus the total number $m$ of operators $\hat{K}_{b_1, b_2}$ cannot exceed $\dim(\mathcal{H}_B)^2$. To show that $\eqref{equation-7}$ implies $\eqref{equation-9}$ we first note that

$$
\begin{align*}
  & \sum_{b_1, b_2} (\hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)})_{a_1 a_2} = \sum_{b_1, b_2, a_3} (\hat{K}_{(b_1, b_2)}^\dagger)_{a_1 a_3} (\hat{K}_{(b_1, b_2)})_{a_3 a_2} \\
  =& \sum_{b_1, b_2, a_3} \left((\hat{I}_A \otimes \sqrt{\hat{\rho}}_B)\hat{V}^\dagger \right)_{a_1 b_2, a_3 b_1} \left(\hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \right)_{a_3 b_1, a_2 b_2} \\
  =& \sum_b \left((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B})\right)_{a_1 b, a_2 b} \\
  =& \operatorname{tr}_B \left((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \right)_{a_1 a_2}
\end{align*}
$$

such that

$$
  \sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)} = \operatorname{tr}\left((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}\hat{V}^\dagger (\hat{I}_A \otimes \sqrt{\hat{\rho}}_B) \right)
$$

From Lemma $\ref{lemma-2}$, it follows that for any $\ket{\psi}\in\mathcal{H}_A$

$$
  \Braket{\psi|\sum_{b_1, b_2} \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)}|\psi} \leq \kappa\norm{\psi}^2 = \braket{\psi|\kappa\hat{I}_A|\psi}
$$

which is equivalent to $\eqref{equation-9}$. For the special case $\hat{V}^\dagger \hat{V} = \kappa\hat{I}_{AB}$ we have

$$
\begin{align*}
  \sum_{b_1, b_2} =& \hat{K}_{(b_1, b_2)}^\dagger \hat{K}_{(b_1, b_2)} = \operatorname{tr}\left((\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \hat{V}^\dagger \hat{V} (\hat{I}_A \otimes \sqrt{\hat{\rho}_B}) \right) \\
  =& \kappa\operatorname{tr}_B \left((\hat{I}_A \otimes \sqrt{\hat{\rho}})(\hat{I}_A \otimes\sqrt{\hat{\rho}_B}) \right) \\
  =& \kappa\operatorname{tr}_B (\hat{I}_A \otimes \hat{\rho}_B) = \kappa\operatorname{tr}(\hat{\rho}_B) \hat{I}_A \\
  =& \kappa\hat{I}_A 
\end{align*}
$$

To prove $\impliedby$ let $\hat{K}_l \in\mathcal{L}(\mathcal{H}_A)$ for $l\in\set{1,\dots,m}$ be such that they satisfy $\eqref{equation-9}$ and $\eqref{equation-10}$. Furthermore, let $\mathcal{H}_B$ be a Hilbert space with an orthonormal basis $\set{\ket{f_b}}_{b=1}^m$. We embed $\mathcal{H}_A$ in $\mathcal{H}_A \otimes \mathcal{H}_B$ by

$$
\begin{align*}
  \iota : \mathcal{H}_A \to& \hat{H}_B \\
  \ket{\psi} \mapsto& \ket{\psi\otimes f_1} = \ket{\psi}\otimes\ket{f_1}
\end{align*}
$$

and define

$$
\begin{align*}
  \check{V} : \iota\set{\mathcal{H}_A} \to& \mathcal{H}_A \otimes \mathcal{H}_B \\
  \ket{\psi\otimes f_1} \mapsto& \sum_{l=1}^m \hat{K}_l \ket{\psi} \otimes \ket{f_l}
\end{align*}
$$

Noting that

$$
\begin{align*}
  \braket{\check{V}^\dagger (e_a \otimes f_b)|\psi\otimes f_1} =& \braket{e_a \otimes f_b | \check{V}(\psi \otimes f_1)} \\
  =& \Braket{e_a \otimes | \sum_l \hat{K}_l \ket{\psi}\otimes \ket{f_l}} \\
  =& \sum_l \braket{e_a|\hat{K}_l \psi} \underbrace{\braket{f_b|f_l}}_{\delta_{bl}} \\
  =& \braket{e_a|K_b \psi}
\end{align*}
$$

then for any $\ket{\psi\otimes f_1}\in\iota\set{\mathcal{H}_A}$ the linear operator $\check{V}$ satisfies

$$
\begin{align*}
  \braket{\psi\otimes f_1 | \check{V}^\dagger (e_a \otimes f_b)} =& \braket{\check{V}^\dagger (e_a \otimes f_b)|\psi\otimes f_1}^\dagger \\
  =& \braket{e_a|\hat{K}_b \psi}^\dagger = \braket{\hat{K}_b \psi|e_a} = \braket{\psi|\hat{K}_b^\dagger e_a} \\
  =& \sum_l \braket{\psi|\hat{K}_l^\dagger e_a} \braket{f_l|f_b}_{=\delta_{lb}} \\
  =& \left(\sum_l \bra{\psi} \hat{K}_l^\dagger \otimes \ket{f_l} \right) \left(\ket{e_a \otimes f_b} \right)
\end{align*}
$$

For every $\ket{\psi\otimes f_1}\in\iota\set{\mathcal{H}_A}$ the linear operator $\check{V}$ also satisfies

$$
\begin{align*}
  \braket{\psi\otimes f_1 | \check{V}^\dagger \check{V} (\psi\otimes f_1)} =& \braket{\check{V}(\psi\otimes f_1)|\check{V}(\psi\otimes f_1)} \\
  =& \sum_{l_1, l_2} \braket{\hat{K}_{l_1} \psi\otimes f_{l_1}|\hat{K}_{l_2} \psi \otimes f_{l_2}} \\
  =& \sum_{l_1, l_2} \braket{\hat{K}_{l_1} \psi|\hat{K}_{l_2} \psi} \underbrace{f_{l_1}|f_{l_2}}_{=\delta_{l_1 l_2}} \\
  =& \sum_l \braket{\hat{K}_l \psi| \hat{K}_l \psi} \\
  =& \Braket{\psi|\sum_l \hat{K}_l^\dagger \hat{K}_l|\psi}
\end{align*}
$$

We thus have

$$
\begin{align*}
  & \sum_l \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}_A \\
  \implies& \Braket{\psi|\sum_l \hat{K}_l^\dagger \hat{K}_l|\psi} \leq \kappa\norm{\psi}^2 = \kappa\norm{\psi}^2 \norm{f_1}^2, \;\forall \ket{\psi}\in\mathcal{H}_A \\
  \implies& \braket{\psi\otimes f_1| \check{V}^\dagger \check{V}|\psi\otimes f_1} \leq \kappa\norm{\psi\otimes f_1}^2, \;\ket{\psi}\otimes f_1 \in \iota\set{\mathcal{H}_A} \\
  \implies& \check{V}^\dagger \check{V} \leq \kappa\hat{I}_{\iota\set{\mathcal{H}_A}}
\end{align*}
$$

where equality implies equality in each step. The operator $\check{V}$ is defined on the $\dim(\mathcal{H}_A)$-dimensional subspace $\iota\set{\mathcal{H}_A}$ of $\mathcal{H}_A \otimes \mathcal{H}_B$ with dimension $\dim(\mathcal{H}_A)\dim(\mathcal{H}_B)$. We can extend $\check{V}$ to an operator $\hat{V}$ on all of $\mathcal{H}_A \otimes \mathcal{H}_B$ by setting

$$
  \mathbf{V}^\dagger \mathbf{V} = \begin{bmatrix}
    \check{\mathbf{V}}^\dagger \check{\mathbf{V}} & \mathbf{0}_{\dim(\mathcal{H}_A) \times \dim(\mathcal{H}_B)} \\
    \mathbf{0}_{\dim(\mathcal{H}_B) \times \dim(\mathcal{H}_A)} & \kappa \mathbf{I}_{\dim(\mathcal{H}_B)}
  \end{bmatrix}
$$

which satisfies $\hat{V}^\dagger \hat{V} \leq \kappa\hat{I}_{AB}$ if $\sum_l \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}_A$ or $\hat{V}^\dagger \hat{V} = \kappa\hat{I}_{AB}$ if $\sum_l \hat{K}_l^\dagger \hat{K}_l = \kappa\hat{I}_A$.

It remains to show $\eqref{equation-8}$. For this we set

$$
  \hat{\rho}_B = \ket{f_1} \bra{f_1} \in\mathcal{D}(\mathcal{H}_B)
$$

and recall that any $\hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)$ can be written in the form

$$
  \hat{\rho}_A = \sum_a p_a \ket{e_a} \bra{e_a}
$$

where $p_a \in [0,1]$ satisfy $\sum_a p_a = 1$ and $\set{\ket{e_a}}$ forms an orthonormal basis of $\mathcal{H}_A$. Thus, we obtain

$$
\begin{align*}
  \hat{V} (\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger =& \sum_a p_a \hat{V} (\ket{e_a}\bra{e_a} \otimes \ket{f_1}\bra{f_1}) \hat{V}^\dagger \\
  =& \sum_a p_a \hat{V} \ket{e_a \otimes f_1} \bra{e_a \otimes f_1} \hat{V}^\dagger
\end{align*}
$$

where

$$
\begin{align*}
  V\ket{e_a \otimes f_1} =& \check{V} \ket{e_a \otimes f_1} = \sum_l \hat{K}_l \ket{e_a} \otimes \ket{f_1} \\
  \bra{e_a \otimes f_1} \hat{V}^\dagger =& \bra{e_a \otimes f_1} \check{V}^\dagger = \sum_l \bra{e_a}\hat{K}_l^\dagger \otimes \bra{f_l}
\end{align*}
$$

This yields

$$
\begin{align*}
  \hat{V}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger =& \sum_{a, l_1, l_2} p_a \left(\hat{K}_{l_1} \ket{e_a} \otimes \ket{f_{l_1}} \right) \left(\bra{e_a} \hat{K}_{l_2}^\dagger \otimes \bra{f_{l_2}} \right) \\
  =& \sum_{a, l_1, l_2} p_a \hat{K}_{l_1} \ket{e_a} \bra{e_a} \hat{K}_{l_2}^\dagger \otimes \ket{f_{l_1}} \bra{f_{l_2}} \\
  =& \sum_{l_1, l_2} \hat{K}_{l_1} \left(\sum_a p_a \ket{e_a} \bra{e_a} \right) \hat{K}_{l_2}^\dagger \otimes \ket{f_{l_1}} \bra{f_{l_2}} \\
  =& \sum_{l_1, l_2} \hat{K}_{l_1} \rho^A \hat{K}_{l_2}^\dagger \otimes \ket{f_{l_1}} \bra{f_{l_2}}
\end{align*}
$$

Taking the partial trace over $\mathcal{H}_B$ it follows that

$$
\begin{align*}
  \operatorname{tr}_B \left(\hat{V}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger \right) =& \operatorname{tr}_B \left( \sum_{l_1, l_2} \hat{K}_{l_1} \hat{\rho}_A \hat{K}_{l_2}^\dagger \otimes \ket{f_{l_1}} \bra{f_{l_2}} \right) \\
  =& \sum_{l_1, l_2} \operatorname{tr}_B \left(\hat{K}_{l_1} \hat{\rho}_A \hat{K}_{l_2}^\dagger \otimes \ket{f_{l_1}}\bra{f_{l_2}} \right) \\
  =& \sum_{l_1, l_2} \operatorname{tr}(\ket{f_{l_1}}\bra{f_{l_2}}) \hat{K}_{l_1} \hat{\rho}_A \hat{K}_{l_2}^\dagger
\end{align*}
$$

where we can use

$$
\begin{align*}
  \operatorname{tr}(\ket{f_{l_1}}\bra{f_{l_2}}) =& \sum_b \braket{f_b|f_{l_1}} \braket{f_{l_2}|f_b} \\
  =& \sum_b \delta_{bl_1} \delta_{l_2} b = \delta_{l_1 l_2}
\end{align*}
$$

leading to

$$
  \operatorname{tr}_B \left(\hat{V}(\hat{\rho}_A \otimes \hat{\rho}_B) \hat{V}^\dagger \right) = \sum_l \hat{K}_l \hat{\rho}_A \hat{K}_l^\dagger = \hat{K}(\hat{\rho}_A)
$$

This verifies $\eqref{equation-8}$, completing the proof.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces and let $\hat{K}: \mathcal{D}(\mathcal{H}_A) \to\mathcal{D}_\leq (\mathcal{H}_A)$ have the equivalent representations given in Theorem $\ref{theorem-1}$ with $\hat{V}\in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$, $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$ and $\hat{K}_l \in\mathcal{L}(\mathcal{H}_A)$ for $l\in\set{1,\dots,m}$. For any $\kappa\in (0,1]$ we then have

$$
\begin{align*}
  \hat{V}^\dagger \hat{V} \leq \kappa\hat{I}_{AB} \iff& \sum_l \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}_A \\
  \iff& \operatorname{tr}\left(\hat{K}(\hat{\rho}^A) \right) \leq \kappa, \forall \hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)
\end{align*}
$$

and equality in one relation is equivalent to equality in the other two relations. In particular, for equality with $\kappa = 1$ we have

$$
\begin{align*}
  \hat{V} \in\mathcal{U}(\mathcal{H}_A \otimes H_B) \iff& \sum_l \hat{K}_l^\dagger \hat{K}_l = \hat{I}_A \\
  \iff& \operatorname{tr}\left(\hat{K}(\rho_A) \right) = 1, \forall \hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)
\end{align*}
$$

<details>
<summary>Proof</summary>

From Theorem $\ref{theorem-1}$ we know that

$$
  \hat{V}^\dagger \hat{V} \leq \kappa\hat{I}_{AB} \iff \sum_l \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}_A
$$

with equality on one side implying equality on the other and from Lemma $\ref{lemma-1}$ we know that

$$
  \sum_l \hat{K}_l^\dagger \hat{K}_l \leq \kappa\hat{I}_A \iff \operatorname{tr}\left(\hat{K}(\hat{\rho}_A)\right) \leq \kappa, \; \forall\hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)
$$

where again equality on one side implies equality on the other.
</details>
</MathBox>

# Classical gates

<TableFigure caption="Classical logic gates">
| Name | Symbol | Function | Truth table |
| --- | --- | --- | --- |
| NOT | <img src="/fig/not_gate.svg"/> | $x_1 \mapsto 1 \overset{2}{\oplus} x_1$ | $$\begin{array}{c:c} x_1 & \operatorname{NOT}(x_1) \\ \hline 0 & 1 \\ 1 & 0 \end{array}$$ |
| AND | <img src="/fig/and_gate.svg"/> | $(x_1, x_2) \mapsto x_1 x_2$ | $$\begin{array}{c:c:c} x_1 & x_2 & \operatorname{AND}(x_1, x_2) \\ \hline 0 & 0 & 0 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \\ 1 & 1 & 1 \end{array}$$ |
| OR | <img src="/fig/or_gate.svg"/> | $(x_1, x_2) \mapsto x_1 \overset{2}{\oplus} x_2 \overset{2}{\oplus} x_1 x_2$ | $$\begin{array}{c:c:c} x_1 & x_2 & \operatorname{OR}(x_1, x_2) \\ \hline 0 & 0 & 0 \\ 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 1 \end{array}$$ |
| XOR | <img src="/fig/xor_gate.svg"/> | $(x_1, x_2) \mapsto x_1 \overset{2}{\oplus} x_2$ | $$\begin{array}{c:c:c} x_1 & x_2 & \operatorname{XOR}(x_1, x_2) \\ \hline 0 & 0 & 0 \\ 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{array}$$ |
| ID | | $x_1 \mapsto x_1$ | $$\begin{array}{c:c} x_1 & \operatorname{ID}(x_1) \\ \hline 0 & 0 \\ 1 & 1 \end{array}$$ |
| FALSE | | $x_1 \mapsto 0$ | $$\begin{array}{c:c} x_1 & \operatorname{FALSE}(x_1) \\ \hline 0 & 0 \\ 1 & 0 \end{array}$$ |
| TRUE | | $x_1 \mapsto 1$ | $$\begin{array}{c:c} x_1 & \operatorname{TRUE}(x_1) \\ \hline 0 & 1 \\ 1 & 1 \end{array}$$ |
| COPY | | $x_1 \mapsto (x_1, x_1)$ | $$\begin{array}{c:c} x_1 & \operatorname{COPY}(x_1) \\ \hline 0 & (0,0) \\ 1 & (1,1) \end{array}$$ |
</TableFigure>

<MathBox title='Classical logic gate' boxType='definition'>
A classical logic gate is a function $g:\set{0,1}^n \to \set{0,1}$ that maps an $n$-bit input to a single output bit. An extended classical logic gate generalizes this concept to multiple outputs as a function $g: \set{0,1}^n \to\set{0,1}^m$ given by

$$
  (x_1,\dots,x_n) \mapsto (g_1(x_1,\dots,x_n),\dots,g_m(x_1,\dots,x_n))
$$

where each $g_j$ is an elementary gate. 

A classical gate $g$ is *reversible* if it is a bijection.
</MathBox>

<MathBox title='Binary addition' boxType='definition' tag='definition-8'>
For $u,v\in\set{0,1}$ we define binary addition as

$$
  u \overset{2}{\oplus} v := (u + v) \bmod 2
$$
</MathBox>

<MathBox title='Logical circuits' boxType='definition' tag='definition-1'>
We denote by $\mathcal{F}[g_1,\dots,g_K]$ the set og all gates which can be constructed from $g_1,\dots,g_K$. This set is defined by the following construction rules:
1. the $g_1,\dots,g_K$ are elements of this set, i.e. $g_1,\dots,g_K\in\mathcal{F}[g_1,\dots,g_K]$ 
2. padding operations of the form
$$
\begin{align*}
  p_{y_1,\dots,y_l;j_1,\dots,j_l}^{(n)} : \set{0,1}^n \to& \set{0,1}^{n+1} \\
  (x_1,\dots,x_n) \mapsto& (x_1,\dots,x_{j_1} - 1, y_{j_1}, x_{j_1 + 1},\dots,x_n)
\end{align*}
$$

which insert pre-determined bit values $y_1,\dots,y_l \in\set{0,1}$ at pre-determined slots $j_1,\dots,j_l \in\set{1,\dots,n+1}$ are lelemts of the set, that is, for any $l,n\in\N_+, y_1,\dots,y_l\in\set{0,1}$ and pairwise distinct $j_1,\dots,j_l\in\set{1,\dots,n+1}$
$$
  p_{y_1,\dots,y_l;j_1,\dots,j_l}^{(n)} \in\mathcal{F}[g_1,\dots,g_K]
$$

3. restriction and/or re-ordering operations
$$
\begin{align*}
  r_{j_1,\dots,j_l}^{(n)} : \set{0,1}^n \to& \set{0,1}^l \\
  (x_1,\dots,x_n) \mapsto& (x_{j_1},\dots,x_{j_l})
\end{align*}
$$
are elements of the set, that is, for any $l,n\in\N_+$, and pairwise distinct $j_1,\dots,j_k\in\set{1,\dots,l}$
$$
  r_{j_1,\dots,j_l}^{(n)} \in\mathcal{F}[g_1,\dots,g_K]
$$

4. compositions of elements of the set belong to the set, that is, for any $h_1:\set{0,1}^n \to\set{0,1}^m$ and $h_2 :\set{0,1}^l \to\set{0,1}^n$ we have that
$$
  h_1, h_2 \in\mathcal{F}[g_1,\dots,g_k] \implies h_1 \circ h_2 \in\mathcal{F}[g_1,\dots,g_K]
$$

5. cartesian products of elements of the set belong to the set, that is, for any $h:\set{0,1}^n \to\set{0,1}^m$ and $k:\set{0,1}^p \to\set{0,1}^q$ we have that
$$
  h, k \in\mathcal{F}[g_1,\dots,g_K] \implies h\times k \in\mathcal{F}[g_1,\dots,g_K]
$$
where $h\times k :\set{0,1}^{n+p} \to \set{0,1}^{m+q}$ with
$$
\begin{align*}
  &h\times k (x_1,\dots,x_{n+p}) \\
  =& (h(x_1,\dots,x_n)_1,\dots,h(x_1,\dots,x_n)_m, k(x_{n+1},\dots,x_{n+p})_1,\dots,k(x_{n+1},\dots,x_{n+p})_q)
\end{align*}
$$

A set $G = \set{g_1,\dots,g_J}$ of classical gates is universal if any gate $g$ can be constructed with gates from $G$, that is, for every gate $g$
$$
  g\in\mathcal{F}[g_1,\dots,g_J], \; g_1,\dots,g_J \in G
$$

When multiple gates are connected the resulting arrays are called classical digital logical circuits.
</MathBox>

<MathBox title='' boxType='lemma'>
For gates $h_1,\dots,h_L,g_1,\dots,g_K$ we have

$$
  h_1,\dots,h_L \in\mathcal{F}[g_1,\dots,g_K] \implies \mathcal{F}[h_1,\dots,h_L]\subset \mathcal{F}[g_1,\dots,g_K]
$$

such that in particular

$$
  \mathcal{F}[\mathcal{F}[g_1,\dots,g_K]] \subset \mathcal{F}[g_1,\dots,g_K]
$$

<details>
<summary>Proof</summary>

The stated inclusion is a direct consequence of Definition $\ref{definition-1}$ since the operations to build any element in $\mathcal{F}[h_1,\dots,h_L]$ from the $h_1,\dots,h_L$ are the same as to build any element in $\mathcal{F}[g_1,\dots,g_K]$ from its elements and since the $h_1,\dots,h_L$ are members of this set.
</details>
</MathBox>

<MathBox title='Toffoli gate' boxType='example'>
For $(x_1,x_2,x_3)\in\set{0,1}^3$ we have

$$
\begin{align*}
  &(\operatorname{ID}\times\operatorname{ID}\times\operatorname{XOR})\circ(\operatorname{ID}\times\operatorname{ID}\times\operatorname{AND}\times\operatorname{ID}) \\
  &\circ r_{1,3,2,4,5}^{(5)} \circ (\operatorname{COPY}\times\operatorname{COPY}\times\operatorname{ID})(x_1,x_2,x_3) \\
  =& (\operatorname{ID}\times\operatorname{ID}\times\operatorname{XOR})\circ(\operatorname{ID}\times\operatorname{ID}\times\operatorname{AND}\times\operatorname{ID}) \\
  &\circ r_{1,3,2,4,5}^{(5)} (x_1,x_1,x_2,x_2,x_3) \\
  =& (\operatorname{ID}\times\operatorname{ID}\times\operatorname{XOR})\circ(\operatorname{ID}\times\operatorname{ID}\times\operatorname{AND}\times\operatorname{ID}) (x_1,x_1,x_2,x_2,x_3) \\
  =& (\operatorname{ID}\times\operatorname{ID}\times\operatorname{XOR}) (x_1,x_1,x_2,x_2,x_3) \\
  =& (x_1,x_2,x_1 x_2 \overset{2}{\oplus} x_3) \\
  =& \operatorname{TOF}(x_1,x_2,x_3)
\end{align*}
$$

Hence,

$$
\begin{align*}
  \operatorname{TOF} =& (\operatorname{ID}\times\operatorname{ID}\times\operatorname{XOR})\circ(\operatorname{ID}\times\operatorname{ID}\times\operatorname{AND}\times\operatorname{ID}) \\
  &\circ r_{1,3,2,4,5}^{(5)} \circ (\operatorname{COPY}\times\operatorname{COPY}\times\operatorname{ID})
\end{align*}
$$

so that $\operatorname{TOF}\in\mathcal{F}[\operatorname{ID},\operatorname{AND},\operatorname{XOR},\operatorname{COPY}]$.
</MathBox>

<MathBox title='' boxType='proposition'>
The classical Toffoli gate is universal and reversible.

<details>
<summary>Proof</summary>

Since every gate $g:\set{0,1}^n \to\set{0,1}^m$ can be decomposed in $m$ gates $g_j : \set{0,1}^n \to\set{0,1}$, where $j\in\set{1,\dots,m}$ it suffices to show universality only for a gate of the form $f:\set{0,1}^n \to\set{0,1}$, which we shall do by induction in $n$.

Consider the base case $n = 1$. From the elementary gates, we see that $\operatorname{ID}$, $\operatorname{FALSE}$, $\operatorname{TRUE}$ and $\operatorname{NOT}$ can be replicated by the various channels of $\operatorname{TO}$ as follows:

$$
\begin{equation}
\begin{split}
  \operatorname{ID}(x_1) =& x_1 = \operatorname{TOF}_1 (x_1, 1, 1) = r_1^{(3)} \circ \operatorname{TOF}\circ p_{1,1;2,3}^{(1)} (x_1) \\
  \operatorname{FALSE}(x_1) =& 0 = \operatorname{TOF}_1 (0,0,0) = r_1^{(3)} \circ \operatorname{TOF}\circ p_{0,0,0;1,2,3}^{(0)} (x_1) \\
  \operatorname{TRUE}(x_1) =& 1 = \operatorname{TOF}_1 (1,0,0) = r_1^{(3)} \circ \operatorname{TOF}\circ p_{1,0,0;1,2,3}^{(1)} (x_1) \\
  \operatorname{NOT}(x_1) =& 1\overset{2}{\oplus} = \operatorname{TOF}_3 (1,1,x_1) = r_1^{(3)} \circ \operatorname{TOF}\circ p_{1,1;1,2}^{(1)} (x_1)
\end{split}
\tag{\label{equation-11}}
\end{equation}
$$

Consequently, every gate $f:\set{0,1}\to\set{0,1}$ can be constructed with $\operatorname{TOF}$. Morevover, the following shows that we can also build $\operatorname{AND}$, $\operatorname{XOR}$, $\operatorname{COPY}^{(1)}$ and $\operatorname{COPY}^{(n)}$ with $\operatorname{TOF}$, i.e.

$$
\begin{equation}
\begin{split}
  \operatorname{AND}(x_1, x_2) =& x_1 x_2 = \operatorname{TOF}_3 (x_1,x_2,0) = r_3^{(3)} \circ \operatorname{TOF}\circ p_{0;3}^{(2)} (x_1, x_2) \\
  \operatorname{XOR}(x_1, x_2) =& x_1 \overset{2}{\oplus} x_2 = \operatorname{TOF}_3 (1,x_1,x_2) = r_3^{(3)} \circ \operatorname{TOF}\circ p_{1;1}^{(2)} (x_1, x_2)
\end{split}
\tag{\label{equation-12}}
\end{equation}
$$

and

$$
\begin{align*}
  \operatorname{COPY}^{(1)}(x_1) =& (x_1, x_2) = (\operatorname{TOF}_3 (x_1,1,0), \operatorname{TOF}_3 (x_1, 1, 0)) \\
  =& r_{1,3}^{(3)} \circ \operatorname{TOF} \circ p_{1,0;2,3}^{(1)} (x_1) \\
  \operatorname{COPY}^{(n)}(x_1,\dots,x_n) =& (x_1,\dots,x_n,x_1,\dots,x_n) \\
  =& r_{1,3,5,\dots,2n-1,2,4,\dots,2n}^{(2n)} \circ \operatorname{COPY}^{(1)} \times\cdots\times \operatorname{COPY}^{(1)} (x_1,\dots,x_n)
\end{align*}
$$

Hence, according to Definition $\ref{definition-1}$, it follows that

$$
\begin{equation}
  \operatorname{ID},\operatorname{FALSE},\operatorname{TRUE},\operatorname{NOT},\operatorname{AND},\operatorname{XOR},\operatorname{COPY}^{(n)}\in\mathcal{F}[\operatorname{TOF}]
\tag{\label{equation-14}}
\end{equation}
$$

For the inductive step from $n-1$ to $n$, assume $\operatorname{TOF}$ is universal for gates of the form $g:\set{0,1}^{n-1} \to \set{0,1}$. Let $f:\set{0,1}^n \to\set{0,1}$ be arbitrary. Then, for $x_n \in\set{0,1}$ define

$$
  g_{x_n} (x_1,\dots,x_{n-1}) := f(x_1,\dots,x_{n-1},x_n)
$$

and

$$
\begin{equation}
\begin{split}
  h(x_1,\dots,x_n) := \operatorname{XOR} \Big( &\operatorname{AND}\big(g_0(x_1,\dots,x_{n-1}), \operatorname{NOT}(x_n)\big), \\
  & \operatorname{AND}\big(g_1(x_1,\dots,x_{n-1}), x_n\big) \Big)
\end{split}
\tag{\label{equation-13}}
\end{equation}
$$

Due to the induction assumption, $g_0$ and $g_1$ can be built with $\operatorname{TOF}$, and because of $\eqref{equation-11}$ and $\eqref{equation-12}$, we know that $\operatorname{NOT}$, $\operatorname{AND}$ and $\operatorname{XOR}$ can be constructed with $\operatorname{TOF}$. Altogether thus $h$ in $\eqref{}$ can be built with $\operatorname{TOF}$. At the same time, we have $h=f$, since

$$
\begin{align*}
  h(x_1,\dots,x_{n-1},0) =& \operatorname{XOR}\Big(\operatorname{AND}\big(g_0(x_1,\dots,x_{n-1}), \operatorname{NOT}(0)\big), \\
  &\hphantom{\operatorname{XOR}\Big(} \operatorname{AND}\big(g_1(x_1,\dots,x_{n-1}), 0\big) \Big) \\
  =& \operatorname{XOR}(g_0(x_1,\dots,x_{n-1}), 0) \\
  =& g_0 (x_1,\dots,x_{n-1}) \\
  =& f(x_1,\dots,x_{n-1},0)
\end{align*}
$$

and

$$
\begin{align*}
  h(x_1,\dots,x_{n-1},1) =& \operatorname{XOR}\Big(\operatorname{AND}\big(g_0(x_1,\dots,x_{n-1}), \operatorname{NOT}(1)\big), \\
  &\hphantom{\operatorname{XOR}\Big(} \operatorname{AND}\big(g_1(x_1,\dots,x_{n-1}), 1\big) \Big) \\
  =& \operatorname{XOR}(0, g_0(x_1,\dots,x_{n-1}), 0) \\
  =& g_0 (x_1,\dots,x_{n-1}) \\
  =& f(x_1,\dots,x_{n-1},1)
\end{align*}
$$

In other words, we have

$$
  f = \operatorname{XOR}\circ(\operatorname{AND}\times\operatorname{AND})\circ((g_0 \times \operatorname{NOT})\times(g_1 \times\operatorname{ID})) \circ \operatorname{COPY}^{(n)}
$$

and because of $\eqref{equation-14}$ and the induction-assumption $g_0, g_1 \in\mathcal{F}[\operatorname{TOF}]$, it follows from Definition $\ref{definition-1}$ that $f\in\operatorname{TOF}$. Consequently, $\operatorname{TOF}$ is universall. The invertibility of $\operatorname{TOF}$ follows fomr

$$
\begin{align*}
  \operatorname{TOF}\circ\operatorname{TOF}(x_1,x_2,x_3) =& \operatorname{TOF}(x_1,x_2,x_3 \overset{2}{\oplus} x_1 x_2) \\
  =& (x_1,x_2,x_3 \overset{2}{\oplus} \underbrace{x_1 x_2 \overset{2}{\oplus} x_1 x_2}_{=0}) \\
  =& (x_1,x_2,x_3)
\end{align*}
$$

which means that $\operatorname{TOF}$ is its own inverse gate and thus reversible.
</details>
</MathBox>

# Quantum gates

<MathBox title='Quantum gate' boxType='definition' tag='definition-2'>
A *quantum $n$-gate* is a unitary operator

$$
  \hat{U}: {}^\P \mathcal{H}^{\otimes n} \to {}^\P \mathcal{H}^{\otimes n}, \; \hat{U}\in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})
$$

For $n = 1$ a gate $\hat{U}$ is called a *unary quantum gate* and for $n = 2$ a *binary quantum gate*.
</MathBox>

## Unary quantum gates

<TableFigure caption="Unary quantum gates">
| Name | Symbol | Operator | Matrix in basis $\set{\ket{0},\ket{1}}$ |
| --- | --- | --- | --- |
| Identity | <img src="/fig/identity_gate.svg"/> | $\hat{I} = \ket{0}\bra{0} + \ket{1}\bra{1}$ | $\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$ |
| Pauli-X or Q-NOT | <img src="/fig/pauli_x_gate.svg"/> | $\hat{X} := \boldsymbol{\sigma}_x = \ket{0}\bra{1} + \ket{1}\bra{0}$ | $\begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$ |
| Pauli-Y | <img src="/fig/pauli_y_gate.svg"/> | $\hat{Y} := \boldsymbol{\sigma}_y = -i\ket{0}\bra{1} + i\ket{1}\bra{0}$ | $\begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix}$ |
| Pauli-Z | <img src="/fig/pauli_z_gate.svg"/> | $\hat{Z} := \boldsymbol{\sigma}_z = \ket{0}\bra{0} - \ket{1}\bra{1}$ | $\begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}$ |
| Rotation-X | <img src="/fig/rotation_x_gate.svg"/> | $\hat{R}_x (\theta) := e^{-i\theta\hat{X} / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I} - i\sin\left(\frac{\theta}{2}\right)\hat{X}$ | $\begin{bmatrix} \cos\left(\frac{\theta}{2}\right) & -i\sin\left(\frac{\theta}{2}\right) \\ -i\sin\left(\frac{\theta}{2}\right) & \cos\left(\frac{\theta}{2}\right) \end{bmatrix}$ |
| Rotation-Y | <img src="/fig/rotation_y_gate.svg"/> | $\hat{R}_y (\theta) := e^{-i\theta\hat{Y} / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I} - i\sin\left(\frac{\theta}{2}\right)\hat{Y}$ | $\begin{bmatrix} \cos\left(\frac{\theta}{2}\right) & -\sin\left(\frac{\theta}{2}\right) \\ \sin\left(\frac{\theta}{2}\right) & \cos\left(\frac{\theta}{2}\right) \end{bmatrix}$ |
| Rotation-Z | <img src="/fig/rotation_z_gate.svg"/> | $\hat{R}_z (\theta) := e^{-i\theta\hat{Z} / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I} - i\sin\left(\frac{\theta}{2}\right)\hat{Z}$ | $\begin{bmatrix} e^{-i\theta/2} & 0 \\ 0 & e^{i\theta/2} \end{bmatrix}$ |
| X power | <img src="/fig/x_power_gate.svg"/> | $\hat{X}^t := \exp\left(-i\frac{\pi}{2}t(\hat{X} - \hat{I})\right) = e^{i\pi t/2} \hat{R}_x (\pi t)$ | $e^{-i\pi t/2} \begin{bmatrix} \cos\left(\frac{\pi}{2} t\right) & -i\sin\left(\frac{\pi}{2} t\right) \\ -i\sin\left(\frac{\pi}{2} t\right) & \cos\left(\frac{\pi}{2} t\right) \end{bmatrix}$ |
| Y power | <img src="/fig/y_power_gate.svg"/> | $\hat{Y}^t := \exp\left(-i\frac{\pi}{2}t(\hat{Y} - \hat{I})\right) = e^{i\pi t/2} \hat{R}_y (\pi t)$ | $e^{-i\pi t/2}\begin{bmatrix} \cos\left(\frac{\pi}{2} t\right) & -\sin\left(\frac{\pi}{2} t\right) \\ \sin\left(\frac{\pi}{2} t\right) & \cos\left(\frac{\pi}{2} t\right) \end{bmatrix}$ |
| Z power | <img src="/fig/y_power_gate.svg"/> | $\hat{Z}^t := \exp\left(-i\frac{\pi}{2}t(\hat{Z} - \hat{I})\right) = e^{i\pi t/2} \hat{R}_z (\pi t)$ | $\begin{bmatrix} 1 & 0 \\ 0 & e^{i\pi t} \end{bmatrix}$ |
| Phase shift | <img src="/fig/phaseshift_gate.svg"/> | $\hat{P}(\alpha) := \ket{0}\bra{0} + e^{i\alpha}\ket{1}\bra{1} = \hat{Z}^{\alpha/\pi}$ | $\begin{bmatrix} 1 & 0 \\ 0 & e^{i\alpha} \end{bmatrix}$ |
| Discrete phase shift | <img src="/fig/discrete_phaseshift_gate.svg"/> | $\hat{P}_k := \hat{P}\left(\frac{2\pi}{2^k}\right) = \hat{Z}^{2^{1-k}}$ | $\begin{bmatrix} 1 & 0 \\ 0 & e^{i 2\pi /2^k} \end{bmatrix}$ |
| V | <img src="/fig/v_gate.svg"/> | $\hat{V} := \hat{X}^{1/2}$ | $\frac{1}{2}\begin{bmatrix} 1 + i & 1 - i \\ 1 - i & 1 + i \end{bmatrix}$ |
| S | <img src="/fig/s_gate.svg"/> | $\hat{S} := \hat{Z}^{1/2}$ | $\begin{bmatrix} 1 & 0 \\ 0 & i \end{bmatrix}$ |
| Phase-factor | <img src="/fig/phasefactor_gate.svg"/> | $\hat{K}(\alpha) := e^{i\alpha}\hat{I}$ | $\begin{bmatrix} e^{i\alpha} & 0 \\ 0 & e^{i\alpha} \end{bmatrix}$ |
| Hadamard | <img src="/fig/hadamard_gate.svg"/> | $\hat{H} := \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z})$ | $\frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}$ |
</TableFigure>

<MathBox title='Preparing a single qubit in an arbitrary state' boxType='example'>
A qubit initially in state $\ket{0}$ can be prepared in in an arbitrary state $\ket{\psi} = \alpha\ket{0} + \beta\ket{1}$ using the quantum gate $\hat{R}_y (2 \arccos\alpha)$, assuming $\alpha,\beta\in\R$ are real with $\alpha^2 + \beta^2 = 1$, i.e.

$$
  \hat{R}_y (2 \arccos\alpha)\ket{0} = \alpha\ket{0} + \beta\ket{1}
$$

If $\alpha = r_1 e^{i\theta_1}$ and $\beta = r_2 e^{i\theta_2}$ are complex, the state preparation requires an additional  phase $\hat{P}(\theta_2 - \theta_1)$ to adjust the relative phase. In this case, the qubit can be initialized using the sequence of gates

$$
  \hat{P}(\theta_2 - \theta_1) \hat{R}_y (2\arccos r_1) = r_1 \ket{0} + r_2 e^{i(\theta_2 - \theta_1)}\ket{1}
$$

<details>
<summary>Details</summary>

Since $\hat{R}_y (2\theta) = \left[\begin{smallmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{smallmatrix}\right]$, we obtain

$$
\begin{align*}
  \hat{R}_y (2\theta) \ket{0} =& \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}\cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix} \\
  =& \cos(\theta)\ket{0} + \sin(\theta)\ket{1} \\
  =& \cos(\theta)\ket{0} + \sqrt{1 - \cos^2 (\theta)} \ket{1}
\end{align*}
$$

If $\alpha,\beta\in\R$ with $\alpha^2 + \beta^2 = 0$, it follows that $\beta = \sqrt{1 - \alpha^2}$. Setting $\cos(\theta) = \alpha$ or $\theta = \arccos(\alpha)$ yields

$$
\begin{align*}
  \hat{R}_y (2\arccos\alpha) \ket{0} =& \cos(\arccos(\alpha))\ket{0} + \sqrt{1 - \cos^2(\arccos\alpha)}\ket{1} \\
  =& \alpha\ket{0} + \beta\ket{1}
\end{align*}
$$

If $\alpha = r_1 e^{i\theta_1}$ and $\beta = r_2 e^{i\theta_2}$, then

$$
\begin{align*}
  \ket{\psi} =& r_1 e^{i\theta_1} \ket{0} + r_2 e^{i\theta_2} \ket{1} \\
  =& e^{i\theta_1} (r_1 \ket{0} + r_2 e^{i(\theta_2 - \theta_1)}\ket{1}) \\
  \equiv& r_1 \ket{0} + r_2 e^{i(\theta_2 - \theta_1)}\ket{1}
\end{align*}
$$

Since $r_1^2 + r_2^2 = 1$, it follows from the previous argument that

$$
  \hat{R}_y (2\arccos r_1) \ket{0} = r_1 \ket{0} + r_2 \ket{1}
$$

To add the phase $\theta_2 - \theta_1$, we apply the phase gate $\hat{P}(\theta_2 - \theta_1)$ giving

$$
\begin{align*}
  \hat{P}(\theta_2 - \theta_1)(r_1 \ket{0} + r_2\ket{1}) =& (\ket{0}\bra{0} + e^{i(\theta_2 - \theta_1)}\ket{1}\bra{1})(r_1 \ket{0} + r_2\ket{1}) \\
  =& r_1 \ket{0} + r_2 e^{i(\theta_2 - \theta_1)}\ket{1}
\end{align*}
$$
</details>
</MathBox>

### Pauli gates

#### Pauli-X gate
The Pauli-X gate generates a half-turn in the Bloch sphere about the $x$ axis. Applying the X gate to a qubit $\ket{\psi} = \alpha\ket{0} + \beta\ket{1}$ gives

$$
\begin{align*}
  \hat{X}(\alpha\ket{0} + \beta\ket{1}) =& \big(\ket{0}\bra{1} + \ket{1}\bra{0}\big)\big(\alpha\ket{0} + \beta\ket{1}\big) \\
  =& \beta\ket{1} + \alpha\ket{0}
\end{align*}
$$

meaning that it flips the qubit. In particular, the Pauli-X gate swaps the standard basis $\set{\ket{0},\ket{1}}$:

$$
  \hat{X}\ket{0} = \ket{1},\quad \hat{X}\ket{1} = \ket{0}
$$

However, the Pauli-X gates does not affect the Hadamard basis $\set{\ket{+}, \ket{-}}$. Specifically,

$$
  \hat{X}\ket{+} = \ket{+},\quad \hat{X}\ket{-} = -\ket{-}
$$

Since $-\ket{-} = e^{i\pi} \ket{-}$, it follows that $\ket{-}$ and $-\ket{-}$ are equivalent up to a global phase.

<MathBox title='Pauli-X is not a true quantum NOT gate' boxType='remark'>
The Pauli-X gate is also known as the quantum NOT gate because it is equivalent to a classical NOT operation, or logical negation. However, it is not a true quantum NOT gate, since it only logically negates the state in the computational basis. A true quantum negation would require mapping every point on the Bloch sphere to its antipodal point. This would required an inversion of the sphere which cannot be generated by rotations alone. There is no general quantum NOT operation that would negate an arbitrary qubit state.

<details>
<summary>Proof</summary>

An arbitrary qubit state takes the form

$$
  \ket{\psi} = \cos\left(\frac{\theta}{2}\right)\ket{0} + e^{i\phi} \sin\left(\frac{\theta}{2}\right)\ket{1}
$$

Its antipodal state is given by

$$
\begin{align*}
  \ket{\psi^\top} =& \cos\left(\frac{\pi - \theta}{2}\right)\ket{0} + e^{i(\phi + \pi)} \sin\left(\frac{\pi - \theta}{2}\right)\ket{1} \\
  =& \cos\left(\frac{\pi - \theta}{2}\right)\ket{0} - e^{i\phi} \sin\left(\frac{\pi - \theta}{2}\right)\ket{1} \\
  =& \sin\left(\frac{\theta}{2}\right)\ket{0} - e^{i\phi} \cos\left(\frac{\theta}{2}\right)\ket{1}
\end{align*}
$$

Applying the X gate to $\ket{\psi}$, we obtain

$$
\begin{align*}
  \hat{X}\ket{\psi} = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \begin{bmatrix} \cos\left(\frac{\theta}{2}\right) \\ e^{i\phi}\sin\left(\frac{\theta}{2}\right) \end{bmatrix} = \begin{bmatrix} e^{i\phi}\sin\left(\frac{\theta}{2}\right) \\ \cos\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  =& e^{i\phi}\sin\left(\frac{\theta}{2}\right)\ket{0} + \cos\left(\frac{\theta}{2}\right)\ket{1}
\end{align*}
$$

Mulitplying with the global phase $e^{i\phi}$ gives

$$
  \hat{X}\ket{\psi} \equiv \sin\left(\frac{\theta}{2}\right)\ket{0} + e^{-i\phi}\cos\left(\frac{\theta}{2}\right)\ket{1} \neq \ket{\psi^\top}
$$

This shows that the X gate does not an arbitrary qubit.
</details>
</MathBox>

#### Pauli Y-gate
The Pauli-Y gate generates a half-turn in the Bloch sphere about the $y$ axis. Applying the Y gate to a qubit $\ket{\psi} = \alpha\ket{0} + \beta\ket{1}$ yields

$$
\begin{align*}
  \hat{Y}(\alpha\ket{0} + \beta\ket{1}) =& \big(-i\ket{0}\bra{1} + i\ket{1}\bra{0}\big)\big(\alpha\ket{0} + \beta\ket{1}\big) \\
  =& i\big(\alpha\ket{1} - \beta\ket{0}\big)
\end{align*}
$$

whichs shows that it flips the qubit and multiplies the phase by $i$.

#### Pauli Z gate
Applying the Pauli-Z gate to a qubit $\ket{\psi} = \alpha\ket{0} + \beta\ket{1}$ gives

$$
\begin{align*}
  \hat{Z}(\alpha\ket{0} + \beta\ket{1}) =& \big(\ket{0}\bra{0} - \ket{1}\bra{1}\big)\big(\alpha\ket{0} + \beta\ket{1}\big) \\
  =& \alpha\ket{0} - \beta\ket{1} = \alpha\ket{0} + e^{i\pi}\beta\ket{1}
\end{align*}
$$

showing that it multiplies the phase of $\ket{1}$ by $-1$. Particularly, it swaps the Hadamard basis:

$$
  \hat{Z}\ket{+} = \ket{-}, \quad \hat{Z}\ket{-} = \ket{+}
$$

#### Pauli gate identities
1. $\hat{X}\hat{Y} = -\hat{Y}\hat{X} = i\hat{Z}$
2. $\hat{Y}\hat{Z} = -\hat{Z}\hat{Y} = i\hat{X}$
3. $\hat{Z}\hat{X} = -\hat{X}\hat{Z} = i\hat{Y}$
4. $\hat{X}\hat{Y}\hat{Z} = \hat{Y}\hat{Z}\hat{X} = \hat{Z}\hat{X}\hat{Y} = i\hat{I}_2$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  \hat{X}\hat{Y} =& \big(\ket{0}\bra{1} + \ket{1}\bra{0}\big)\big(-i\ket{0}\bra{1} + i\ket{1}\bra{0}\big) \\
  =& i\ket{0}\bra{0} - i\ket{1}\bra{1} = i\hat{Z}
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \hat{Y}\hat{Z} =& \big(-i\ket{0}\bra{1} + i\ket{1}\bra{0}\big)\big(\ket{0}\bra{0} - \ket{1}\bra{1}\big) \\
  =& i\ket{0}\bra{1} + i\ket{1}\bra{0} = i\hat{X}
\end{align*}
$$

**(3):**

$$
\begin{align*}
  \hat{Z}\hat{X} =& \big(\ket{0}\bra{0} - \ket{1}\bra{1}\big)\big(\ket{0}\bra{1} + \ket{1}\bra{0}\big) \\
  =& \ket{0}\bra{1} - \ket{1}\bra{0} = -i^2 \ket{0}\bra{1} + i^2 \ket{1}\bra{0}\\
  =& i\big(-i \ket{0}\bra{1} + i\ket{1}\bra{0}\big) = i\hat{Y}
\end{align*}
$$

</details>

### Rotation gates

The Pauli rotation gates $\hat{R}_x$, $\hat{R}_y$ and $\hat{R}_z$ rotate the qubit by an arbitrary angle anti-clockwise about the corresponding axis in the Bloch sphere.

<details>
<summary>Details</summary>

Apply $\hat{R}_z (\theta')$ to a qubit $\ket{\psi} = \cos\left(\frac{\theta}{2}\right)\ket{0} + e^{i\phi} \sin\left(\frac{\theta}{2}\right)\ket{1}$ yields

$$
\begin{align*}
  \hat{R}_z (\theta') =& \left(e^{-i\theta'/2} \ket{0}\bra{0} + e^{i\theta'/2} \ket{1}\bra{1} \right)\left(\cos\left(\frac{\theta}{2}\right)\ket{0} + e^{i\phi} \sin\left(\frac{\theta}{2}\right)\ket{1} \right) \\
  =& e^{-i\theta'/2} \left(\cos\left(\frac{\theta}{2}\right)\ket{0} + e^{i(\phi + \theta')} \sin\left(\frac{\theta}{2}\right)\ket{1} \right) \\
  \equiv& \cos\left(\frac{\theta}{2}\right)\ket{0} + e^{i(\phi + \theta')} \ket{1}
\end{align*}
$$

This shows that the $\hat{R}_z$ gate leaves the polar angle unchanged and adds $\theta'$ to the azimuth angle, which corresponds to a rotation about the $z$ axis.
</details>

Geometrically, the Pauli gates generate half turns about their respective axes. In particular for $\theta = \pi$, we obtain

$$
  \hat{R}_\sigma (\pi) = \cos\left(\frac{\pi}{2}\right)\hat{I}_2 - i\sin\left(\frac{\pi}{2}\right)\hat{\sigma} = -i\hat{\sigma},\; \hat{\sigma}\in\Set{\hat{X}, \hat{Y}, \hat{Z}}
$$

which shows that each Pauli gate (up to a global phase $-i$) is equivalent to a $\pi$-rotation about its respective axis.

### Phase shift gates

The phase shift gate is defined in terms of $\hat{R}_z$ as

$$
  \hat{P}(\theta) = e^{-i\theta/2} \hat{R}_z (\theta) = \hat{Z}^{\theta/\pi}
$$

Discrete fractional power of the Z gate define discete phase gates

$$
  \hat{P}_k = \hat{P}\left(\frac{2\pi}{2^k}\right) = \hat{Z}^{2 - k}
$$

### Pauli power gates

The Pauli power gates are defined in terms of the Pauli rotation gates. Noting that that a $\pi$ rotation correspond to a Pauli gate up to a phase factor $\pm i = e^{\pm i\pi/2}$, we have

$$
  \hat{R}_x (\pi) = -i\hat{X}, \quad \hat{R}_y (\pi) = -i\hat{Y}, \quad \hat{R}_z (\pi) = i\hat{Z}
$$

This allows us to express fractional powers of the Pauli matrices using the corresponding rotation operators: 

$$
\begin{align*}
  \hat{X}^t =:& e^{-i\frac{\pi}{2}t(\hat{X} - \hat{I}_2)} \equiv \hat{R}_x (\pi t) \\
  \hat{Y}^t =:& e^{-i\frac{\pi}{2}t(\hat{Y} - \hat{I}_2)} \equiv \hat{R}_y (\pi t) \\
  \hat{Z}^t =:& e^{-i\frac{\pi}{2}t(\hat{Z} - \hat{I}_2)} \equiv \hat{R}_z (\pi t)
\end{align*}
$$

Special cases of the Pauli power gates include
- **V gate (square root of X)**

The V gate is the square root of $X$, representing a quarter-turn about the $x$-axis on the Bloch sphere:
$$
  \hat{V} = \hat{X}^{1/2} \equiv \hat{R}_x \left(\frac{\pi}{2}\right),\quad \hat{V}^\dagger = \hat{X}^{-1/2} \equiv \hat{R}_x \left(-\frac{\pi}{2}\right)
$$

- **Pseudo-Hadamard gate**

The inverse square root of the Y defines the pseudo-Hadamard gate, generating a quarter turn about the $y$-axis on the Bloch sphere 
$$
  \tilde{\hat{H}} = \frac{\sqrt{2}}{1 + i} \hat{Y}^{-1/2}, \quad \tilde{\hat{H}}^\dagger = \frac{\sqrt{2}}{1 + i} \hat{Y}^{1/2}
$$

- **S-gate (square root of Z)** 

The S gate is the square root of the Z gate, generating a quarter turn counterclockwise about the $z$-axis on the Bloch sphere
$$
  \hat{S} = \hat{Z}^{1/2} = \hat{P}\left(\frac{\pi}{2}\right) = \hat{P}_2 \equiv \hat{R}_z \left(\frac{\pi}{2}\right)
$$

Its Hermitian adjoint $\hat{S}^\dagger = \hat{Z}^{-1/2}$, representing a quarter turn clockwise about the $z$ axis, also defines a square root of $\hat{Z}$ since

$$
\begin{align*}
  \hat{S}^\dagger \hat{S}^\dagger =& \big(\ket{0}\bra{0} - i\ket{1}\bra{0} \big)\big(\ket{0}\bra{0} - i\ket{1}\bra{0} \big) \\
  =& \ket{0}\bra{0} + i^2 \ket{1}\bra{1} = \ket{0}\bra{0} - \ket{1}\bra{1} = \hat{Z}
\end{align*}
$$

Properties of the S gate:
1. $\hat{S}^{4-k} = \hat{S}^{-k} = (\hat{S}^\dagger)^k$
2. $\hat{S}\hat{X}\hat{S}^\dagger = \hat{Y}$
3. $\hat{S}^\dagger \hat{Y}\hat{S} = \hat{X}$
4. $\hat{S}\hat{Z}\hat{S}^\dagger = \hat{Z}$

<details>
<summary>Proof</summary>

**(1):** This follows from the fact that $\hat{S}^n = \hat{Z}^{n/2} = \exp\left(-i\frac{\pi}{2} n \hat{Z} \right)$. In particular

$$
  \hat{S}^4 = e^{-i2\pi \hat{Z}} = \hat{I}_2
$$

meaning that $\hat{S}^{4 + n} = \hat{S}^n$

**(2):**

$$
\begin{align*}
  \hat{S}\hat{X}\hat{S}^\dagger =& \big(\ket{0}\bra{0} + i\ket{1}\bra{1} \big)\big(\ket{0}\bra{1} + \ket{1}\bra{0} \big)\big(\ket{0}\bra{0} - i\ket{1}\bra{1} \big) \\
  =& \big(\ket{0}\bra{1} + i\ket{1}\bra{0}\big) \big(\ket{0}\bra{0} - i\ket{1}\bra{1} \big) \\
  =& -i\ket{0}\bra{1} + i\ket{1}\bra{0} = \hat{Y}
\end{align*}
$$
</details>

Identities **(2)** and **(3)** show that the S gate transforms between the $\hat{X}$- and the $\hat{Y}$ basis
$$
\begin{align*}
  \hat{S}\ket{+} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 0 \\ 0 & i \end{bmatrix} \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ 1 \end{bmatrix} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ i \end{bmatrix} = \frac{\ket{0} + i\ket{1}}{\sqrt{2}} = \ket{i} \\
  \hat{S}\ket{-} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 0 \\ 0 & i \end{bmatrix} \frac{1}{\sqrt{2}} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -i \end{bmatrix} = \frac{\ket{0} - i\ket{1}}{\sqrt{2}} = \ket{-i}
\end{align*}
$$

- **T-gate**: The square root of the S gate
$$
  \hat{T} = \hat{S}^{1/2} = \hat{Z}^{1/4} = \hat{P}_3
$$

Identities
1. $\hat{TZT}^\dagger = \hat{Z}$
2. $\hat{TXT}^\dagger = \hat{H}$

### Hadamard gate

Applying the Hadamard gate to $\ket{0}$ and $\ket{1}$ creates superpositions:

$$
  \hat{H}\ket{0} = \frac{1}{\sqrt{2}}(\underbrace{\hat{X}\ket{0}}_{=\ket{1}} + \underbrace{\hat{Z}\ket{0}}_{=\ket{0}}) = \frac{1}{\sqrt{2}}(\ket{0} + \ket{1})
$$

and similarly

$$
  \hat{H}\ket{1} = \frac{1}{\sqrt{2}}(\underbrace{\hat{X}\ket{1}}_{=\ket{0}} + \underbrace{\hat{Z}\ket{0}}_{=-\ket{1}}) = \frac{1}{\sqrt{2}} (\ket{0} - \ket{1})
$$

The Hadamard gate is related to the Pauli gates as follows

1. $\hat{H}\hat{X}\hat{H} = \hat{Z}$
2. $\hat{H}\hat{Y}\hat{H} = -\hat{Y}$
3. $\hat{H}\hat{Z}\hat{H} = \hat{X}$
4. $\hat{S}\hat{H}\hat{Z}\hat{H}\hat{S}^\dagger = \hat{Y}$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  \hat{HXH} =& \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z})\hat{X} \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z}) \\
  =& \frac{1}{2} (\underbrace{\hat{X}^2}_{=\hat{I}_2} \hat{X} + \hat{X}^2 \hat{Z} + \hat{Z} \underbrace{\hat{X}^2}_{=\hat{I}_2} + \underbrace{\hat{Z}\hat{X}\hat{Z}}_{=-\mathbf{X}}) \\
  =& \mathbf{Z}
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \hat{HYH} =& \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z}) \hat{Y} \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z}) \\
  =& \frac{1}{2} (\underbrace{\hat{X}\hat{Y}\hat{X}}_{=-\hat{Y}} + \underbrace{\hat{X}\hat{Y}\hat{Z}}_{=i\hat{I}_2} + \underbrace{\hat{Z}\hat{Y}\hat{X}}_{=-i\hat{I}_2} + \underbrace{\hat{Z}\hat{Y}\hat{Z}}_{=-\hat{Y}}) \\
  =& -\mathbf{Y}
\end{align*}
$$

**(3):**

$$
\begin{align*}
  \hat{H}\hat{Z}\hat{H} =& \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z})\hat{Z} \frac{1}{\sqrt{2}}(\hat{X} + \hat{Z}) \\
  =& \frac{1}{2} (\underbrace{\hat{X}\hat{Z}\hat{X}}_{=-\hat{Z}} + \hat{X}\underbrace{\hat{Z}^2}_{=\hat{I}_2} + \underbrace{\hat{Z}^2}_{=\hat{I}_2} \hat{X} + \underbrace{\hat{Z}^2}_{=\hat{I}_2} \hat{Z}) \\
  =& \hat{X}
\end{align*}
$$

**(4):**

$$
  \hat{S}\underbrace{\hat{H}\hat{Z}\hat{H}}_{=\hat{X}}\hat{S}^\dagger = \hat{S}\hat{X}\hat{S}^\dagger = \hat{Y}
$$

</details>

Identities **(1)** and **(2)** show that the Hadamard gate transforms between the $\hat{Z}$- and $\hat{X}$-bases:

$$
\begin{align*}
  \hat{H}\ket{0} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ 1 \end{bmatrix} = \frac{\ket{0} + \ket{1}}{\sqrt{2}} = \ket{+} \\
  \hat{H}\ket{1} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -1 \end{bmatrix} = \frac{\ket{0} + \ket{1}}{\sqrt{2}} = \ket{+}
\end{align*}
$$

Identity **(4)** shows that the $\hat{H}\hat{S}^\dagger$ operator transforms the $\hat{Y}$-basis to the $\hat{Z}$-basis

$$
\begin{align*}
  \hat{H}\hat{S}^\dagger \ket{i} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & -i \\ 1 & i \end{bmatrix} \frac{1}{\sqrt{2}} \begin{bmatrix} 1 \\ i \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \ket{0} \\
  \hat{H}\hat{S}^\dagger \ket{-i} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & -i \\ 1 & i \end{bmatrix} \frac{1}{\sqrt{2}} \begin{bmatrix} 1 \\ -i \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \ket{1}
\end{align*}
$$

The Hadamard gate is related to the rotation gates as follows

1. $\hat{H}\hat{R}_x (\theta) \hat{H} = \hat{R}_z (\theta)$
2. $\hat{H}\hat{R}_y (\theta) \hat{H} = \hat{R}_y (-\theta)$
3. $\hat{H}\hat{R}_z (\theta) \hat{H} = \hat{R}_x (\theta)$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  \hat{H} \hat{R}_x (\theta) \hat{H} =& \hat{H}\left(\cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{X}\right)\hat{H} \\
  =& \cos\left(\frac{\theta}{2}\right) \underbrace{\hat{H}^2}_{=\hat{I}_2} - i\sin\left(\frac{\theta}{2}\right) \underbrace{\hat{H}\hat{X}\hat{H}}_{=\hat{Z}} \\
  =& \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right) \hat{Z} = \hat{R}_z (\theta)
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \hat{H} \hat{R}_y (\theta) \hat{H} =& \hat{H}\left(\cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{Y}\right)\hat{H} \\
  =& \cos\left(\frac{\theta}{2}\right) \underbrace{\hat{H}^2}_{=\hat{I}_2} - i\sin\left(\frac{\theta}{2}\right) \underbrace{\hat{H}\hat{Y}\hat{H}}_{=\hat{-Y}} \\
  =& \cos\left(\frac{\theta}{2}\right)\hat{I}_2 + i\sin\left(\frac{\theta}{2}\right) \hat{Y} = \hat{R}_y (-\theta)
\end{align*}
$$

**(3):**

$$
\begin{align*}
  \hat{H} \hat{R}_z (\theta) \hat{H} =& \hat{H}\left(\cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{Z}\right)\hat{H} \\
  =& \cos\left(\frac{\theta}{2}\right) \underbrace{\hat{H}^2}_{=\hat{I}_2} - i\sin\left(\frac{\theta}{2}\right) \underbrace{\hat{H}\hat{Z}\hat{H}}_{=\hat{X}} \\
  =& \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right) \hat{X} = \hat{R}_x (\theta)
\end{align*}
$$
</details>

The Hadamard gate is related to the quarter turn gates as follows
1. $\hat{H}\hat{S}\hat{H} = \hat{V}$
2. $\hat{H}\hat{S}^\dagger \hat{H} = \hat{V}^\dagger$

<details>
<summary>Proof</summary>

**(1):** This is most easily shown with a direct matrix computation in the basis $\set{\ket{0}, \ket{1}}$

$$
\begin{align*}
  \mathbf{HSH} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & i \end{bmatrix} \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \\
  =& \frac{1}{2} \begin{bmatrix} 1 & i \\ 1 & -i \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \\
  =& \frac{1}{2} \begin{bmatrix} 1 + i & 1 - i \\ 1 - i & 1 + i \end{bmatrix} = \mathbf{V}
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \mathbf{HS}^\dagger\mathbf{H} =& \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & -i \end{bmatrix} \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \\
  =& \frac{1}{2} \begin{bmatrix} 1 & -i \\ 1 & i \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \\
  =& \frac{1}{2} \begin{bmatrix} 1 - i & 1 + i \\ 1 + i & 1 - i \end{bmatrix} = \mathbf{V}^\dagger
\end{align*}
$$
</details>

### Pauli basis transformations

<TableFigure caption="Pauli eigenbases">
| Pauli gate | Eigenstate for eigenvalue $1$ | Eigenstate for eigenvalue $-1$ |
| --- | --- | --- |
| $\hat{X}$ | $\begin{array}{rl} \ket{+} &= \hat{H}\ket{0} = \frac{1}{\sqrt{2}}(\ket{0} + \ket{1}) \\ &= \hat{S}^\dagger \ket{i} = \frac{1 - i}{2}\ket{i} + \frac{1 + i}{2}\ket{-i} \\ &= \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ 1 \end{bmatrix} \end{array}$ | $\begin{array}{rl} \ket{-} &= \hat{H}\ket{1} = \frac{1}{\sqrt{2}}(\ket{0} - \ket{1}) \\ &= \hat{S}^\dagger \ket{-i} = \frac{1 + i}{2}\ket{i} + \frac{1 - i}{2}\ket{-i} \\ &= \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -1 \end{bmatrix} \end{array}$ |
| $\hat{Y}$ | $\begin{array}{rl} \ket{i} &= \hat{S} \ket{+} = \frac{1 + i}{2}\ket{+} + \frac{1 - i}{2}\ket{-} \\ &= \hat{S} \hat{H} \ket{0} = \frac{1}{\sqrt{2}}(\ket{0} + i\ket{1}) \\ &= \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ i \end{bmatrix} \end{array}$ | $\begin{array}{rl} \ket{-i} &= \hat{S} \ket{-} = \frac{1 - i}{2}\ket{+} + \frac{1 + i}{2}\ket{-} \\ &= \hat{S} \hat{H} \ket{1} = \frac{1}{\sqrt{2}}(\ket{0} - i\ket{1}) \\ &= \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -i \end{bmatrix} \end{array}$ |
| $\hat{Z}$ | $\begin{array}{rl} \ket{0} &= \hat{H} \ket{+} = \frac{1}{\sqrt{2}}(\ket{+} + \ket{-}) \\ &= \hat{H} \hat{S}^\dagger \ket{i} = \frac{1}{\sqrt{2}}(\ket{i} + \ket{-i}) \\ &= \begin{bmatrix} 1 \\ 0 \end{bmatrix} \end{array}$ | $\begin{array}{rl} \ket{1} &= \hat{H} \ket{-} = \frac{1}{\sqrt{2}}(\ket{+} + \ket{-}) \\ &= \hat{H} \hat{S}^\dagger \ket{-i} = \frac{-i}{\sqrt{2}}(\ket{i} - \ket{-i}) \\ &= \begin{bmatrix} 0 \\ 1 \end{bmatrix} \end{array}$ | 
</TableFigure>

## Binary quantum gates

<TableFigure caption="Binary quantum gates">
| Name | Symbol | Operator | Matrix in basis $\set{\ket{0},\ket{1}}$ |
| --- | --- | --- | --- |
| Controlled NOT (C-NOT) | <img src="/fig/controlled_not_gate.svg"/> | $\Lambda^1 (\hat{X}) = \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{X}$ | $\begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \end{bmatrix}$ |
| C-NOT with control in 2nd qubit | <img src="/fig/controlled_not_2nd_qubit_gate.svg"/> | $ \Lambda_1 (\hat{X}) = \hat{I}\otimes\ket{0}\bra{0} + \hat{X}\otimes\ket{1}\bra{1}  = \hat{H}^{\otimes 2} \Lambda^1 (X) \hat{H}^{\otimes 2} $ | $\begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \end{bmatrix}$ |
| Controlled phase-multiplication | <img src="/fig/controlled_phase_multiplication_gate.svg"/> | $ \Lambda^1 (\hat{M}(\alpha)) = \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes e^{i\alpha} \hat{I}  = \hat{P}(\alpha) $ | $\begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & e^{i\alpha} & 0 \\ 0 & 0 & 0 & e^{i\alpha} \end{bmatrix}$ |
| C-NOT with $\ket{0}$ | <img src="/fig/controlled_not_down_gate.svg"/> | $ \Lambda^{\ket{0}} (\hat{X}) = \ket{1}\bra{1}\otimes\hat{I} + \ket{0}\bra{0}\otimes\hat{X}  = (\hat{X}\otimes\hat{I})\Lambda^1 (\hat{X})(\hat{X}\otimes\hat{I}) $ | $\begin{bmatrix} 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}$ |
| Swap | <img src="/fig/swap_gate.svg"/> | $ \hat{S} =\ket{00}\bra{00} + \ket{11}\bra{11} + \ket{01}\bra{10} + \ket{10}\bra{01} = \Lambda^1 (\hat{X}) \Lambda_1 (\hat{X}) \Lambda^1 (X) $ | $\begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}$ |
| Controlled V | <img src="/fig/controlled_v_gate.svg"/> | $ \Lambda^1 (\hat{V}) = \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{V} = (P(\alpha)\otimes\hat{A})\Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{B})\Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{C}) $ where $\hat{V} = \hat{M}(\alpha) \hat{A}\hat{X}\hat{B}\hat{X}\hat{C}$ and $\hat{I} = \hat{A}\hat{B}\hat{C}$ | $\begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & \nu_{00} & \nu_{01} \\ 0 & 0 & \nu_{10} & \nu_{11} \end{bmatrix}$ |
</TableFigure>

Controlled gate identities
- $\hat{C}_x \hat{X}_0 \hat{C}_x = \hat{X}_0 \hat{X}_1$
- $\hat{C}_x \hat{Y}_0 \hat{C}_x = \hat{Y}_0 \hat{X}_1$
- $\hat{C}_x \hat{Z}_0 \hat{C}_x = \hat{Z}_0$
- $\hat{C}_x \hat{X}_1 \hat{C}_x = \hat{X}_1$
- $\hat{C}_x \hat{Y}_1 \hat{C}_x = \hat{Z}_0 \hat{Y}_1$
- $\hat{C}_x \hat{Z}_1 \hat{C}_x = \hat{Z}_0 \hat{Z}_1$
- $\hat{R}_{z,0} (\phi) \hat{C}_x = C_x \hat{R}_{z,0} (\phi)$
- $\hat{R}_{x,1} (\phi) \hat{C}_x = C_x \hat{R}_{x,1} (\phi)$

## Clifford group

The Pauli group $\mathcal{P}_n$ of $n$ qubit operators is formed from the phase factors $\set{\pm 1, \pm i}$ and the unary Pauli matrices $\set{\hat{I}_2, \hat{X}, \hat{Y}, \hat{Z}}$

$$
  \mathcal{P}_n = \set{\pm 1, \pm i} \times \set{\hat{I}_2, \hat{X}, \hat{Y}, \hat{Z}}^{\otimes n}
$$

The Clifford group $\mathcal{C}_n$ consists of all unitary operators that normalize the Pauli group, in the sense taht conjugation by any Clifford element maps Pauli operators to other Pauli operators. That is, for every $\hat{U}\in\mathcal{C}_n$ and every Pauli operator $\hat{\sigma}\in\mathcal{P}_n$, we have

$$
  \hat{U}\hat{\sigma}\hat{U}^\dagger \in \mathcal{P}_n
$$

or

$$
  \mathcal{C}_n = \set{\hat{U} \in \mathrm{U}(2^n) | \hat{U} \hat{\sigma} \hat{U} \in\mathcal{P}_n, \forall \hat{\sigma}\in\mathcal{P}_n}
$$

## General quantum gates

<MathBox title='' boxType='definition'>
For $\hat{U}_j \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n_j})$ with $j\in\set{1,\dots,K}$ we by $\mathcal{F}[\hat{U}_1,\dots,\hat{U}_k]$ the set of gates which can be constructed with the $\hat{U}_1,\dots,\hat{U}_k$. This set is defined by the following rules:
1.
$$
  \hat{U}_1,\dots,\hat{U}_K \in\mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]
$$
2. for any $n\in\N_+$
$$
  \hat{I}^{\otimes n} \in \mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]
$$
3. for any $\hat{V}_1, \hat{V}_2 \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})$ we have
$$
  \hat{V}_1, \hat{V}_2 \in \mathcal{F}[\hat{U}_1,\dots,\hat{U}_K] \implies \hat{V}_1 \hat{V}_2 \in\mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]
$$
4. for any $\hat{V}_i \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n_i})$ with $i\in\set{1,2}$ we have
$$
  \hat{V}_1, \hat{V}_2 \in\mathcal{F}[\hat{U}_1,\dots,\hat{U}_K] \implies \hat{V}_1 \otimes \hat{V}_2 \in\mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]
$$

A set of quantum gates $U = \set{\hat{U}_1,\dots,\hat{U}_J}$ is called universal if any quantum gate $\hat{U}$ can be constructed with gates from $U$, that is, for every quantum gate $\hat{U}$

$$
  \hat{U} \in\mathcal{F}[\hat{U}_1,\dots,\hat{U}_J]
$$

When acting on a system in the state $\hat{\rho}\in\mathcal{D}(\mathcal{H})$ the gate $\hat{U}$ transforms it to a new state $\hat{U}\hat{\rho}\hat{U}^\dagger$.
</MathBox>

<MathBox title='' boxType='lemma'>
For gates $\hat{V}_1,\dots,\hat{V}_L,\hat{U}_1,\dots,\hat{U}_K \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})$ we have

$$
  \hat{V}_1,\dots,\hat{V}_L \in \mathcal{F}[\hat{U}_1,\dots,\hat{U}_K] \implies \mathcal{F}[\hat{V}_1,\dots,\hat{V}_L] \subset \mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]
$$

such that, in particular

$$
  \mathcal{F}\left[\mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]\right] = \mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]
$$

<details>
<summary>Proof</summary>

The stated inclusion is a direct consequence of Definition $\ref{definition-2}$ since the operations to construct any elements in $\mathcal{F}[\hat{V}_1,\dots,\mathcal{V}_L]$ from the $\hat{V}_1,\dots,\hat{V}_L$ are the same as to construct any element in $\mathcal{F}[\hat{U}_1,\dots,\hat{U}_K]$ from its elements and since the $\hat{V}_1,\dots,\hat{V}_L$ are members of this set.
</details>
</MathBox>

<MathBox title='Controlled gate' boxType='definition' tag='definition-3'>
Let $n, n_a, n_b \in\N_0$ with $n = n_a + n_b$ and let $\ket{a}\in {}^\P \mathcal{H}^{\otimes n_a}$ and $\ket{b}\in {}^\P \mathcal{H}^{\otimes n_b}$ be vectors in the respective computational basis. Moreover, let $\hat{U}\in\mathcal{U}({}^\P \mathcal{H})$. We denote the $(\ket{a},\ket{b})$-controlled $\hat{U}$ by $\Lambda_{\ket{b}}^{\ket{a}} (\hat{U})$ and define it as the $n + 1$-gate

$$
\begin{align*}
  \Lambda_{\ket{b}}^{\ket{a}} (\hat{U}) :=& \hat{I}^{\otimes n + 1} + \ket{a}\bra{a} \otimes (\hat{U} - \hat{I})\otimes \ket{b}\bra{b} \\
  =& \hat{I}^{\otimes n+1} + \bigotimes_{j=n_a - 1}^0 \ket{a_j} \bra{a_j} \otimes (\hat{U} - \hat{I}) \otimes \bigotimes_{j = n_b - 1}^0 \ket{b_j} \bra{b_j}
\end{align*}
$$

The qubit on which $\hat{U}$ acts is called *target-qubit*. In the special case $a = 2^{n_a} - 1$ and $2^{n_b} - 1$ one has $\ket{a} = \ket{1\dots 1}^{n_a}$ and $\ket{b} = \ket{1\dots 1}^{n_b}$, and we define the abbreviation notation

$$
  \Lambda_{n_b}^{n_a} (\hat{U}) := \Lambda_{\ket{2}^{n_b} - 1}^{\ket{2}^{n_a} - 1} (\hat{U})
$$

as well as in the case $n_a = n$ and $a = 2^n - 1$

$$
  \Lambda^n (\hat{U}) := \Lambda^{\ket{2^n - 1}} (\hat{U})
$$

Likewise, in the case $n_b = n$ and $b = 2^n - 1$ we define

$$
  \Lambda_n (\hat{U}) := \Lambda_{\ket{2^n - 1}} (\hat{U})
$$

In the case $n = 0$ we define

$$
  \Lambda^0 (\hat{U}) := \hat{U} =: \Lambda_0 (\hat{U})
$$
</MathBox>

For $\hat{U}\in\mathcal{U}({}^\P \mathcal{H})$ and $\alpha\in\R$, we have
1. $\Lambda^1 (\hat{U}) = \ket{0}\bra{0} \otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{U}$
2. $\Lambda_1 (\hat{X}) = \hat{H}^{\otimes 2} \Lambda^1 (\hat{X}) \hat{H}^{\otimes 2}$
3. $\Lambda^1 (\hat{M}(\alpha)) = \hat{P}(\alpha) \otimes\hat{I}$

<details>
<summary>Proof</summary>

**(1):** By definition, we have

$$
\begin{align*}
  \Lambda^1 (\hat{U}) =& \hat{I}^{\otimes 2} + \ket{1}\bra{1} \otimes (\hat{U} - \hat{I}) \\
  =& \hat{I}\otimes\hat{I} + \ket{1}\bra{1} \otimes \hat{U} - \ket{1}\bra{1}\hat{I} \\
  =& (\ket{0}\bra{0} + \ket{1}\bra{1})\otimes\hat{I} + \ket{1}\bra{1} \otimes \hat{U} - \ket{1}\bra{1}\hat{I} \\
  =& \ket{0}\bra{0} \otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{U}
\end{align*}
$$

**(2):** In terms of the matrix representation in the computational basis, we have

$$
\begin{align*}
  \Lambda^1 (\hat{X}) =& \ket{0}\bra{0} \otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{X} \\
  =& \begin{bmatrix} 1 \\ 0 \end{bmatrix} \begin{bmatrix} 1, 0 \end{bmatrix} \otimes \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} + \begin{bmatrix} 0 \\ 1 \end{bmatrix} \begin{bmatrix} 0, 1 \end{bmatrix} \otimes \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \\
  =& \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} \otimes \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} + \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix} \otimes \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \\
  =& \left[\begin{smallmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{smallmatrix}\right] + \left[\begin{smallmatrix} 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \end{smallmatrix}\right] \\
  =& \left[\begin{smallmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \end{smallmatrix}\right]
\end{align*}
$$

Similarly, we have

$$
\begin{align*}
  \Lambda_1 (\hat{X}) =& \hat{I}\otimes\hat{I} + (\hat{X} - \hat{I}) \otimes \ket{1}\bra{1} \\
  =& \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \otimes \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} + \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix} \otimes \begin{bmatrix} 0 & 0 \\ 1 & 0 \end{bmatrix} \\
  =& \left[\begin{smallmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{smallmatrix}\right] + \left[\begin{smallmatrix} 0 & 0 & 0 & 0 \\ 0 & -1 & 0 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & -1 \end{smallmatrix}\right] \\
  =& \left[\begin{smallmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \end{smallmatrix}\right]
\end{align*}
$$

and

$$
\begin{align*}
  \hat{H}^{\otimes 2} =& \frac{1}{\sqrt{2}} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \otimes \frac{1}{\sqrt{2}} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \\
  =& \frac{1}{2} \left[\begin{smallmatrix} 1 & 1 & 1 & 1 \\ 1 & -1 & 1 & -1 \\ 1 & 1 & -1 & -1 \\ 1 & -1 & -1 & 1 \end{smallmatrix}\right]
\end{align*}
$$

Combining the results, we see that

$$
\begin{align*}
  \hat{H}^{\otimes 2} \Lambda^1 (\hat{X}) \hat{H}^{\otimes 2} =& \frac{1}{4} \left[\begin{smallmatrix} 1 & 1 & 1 & 1 \\ 1 & -1 & 1 & -1 \\ 1 & 1 & -1 & -1 \\ 1 & -1 & -1 & 1 \end{smallmatrix}\right] \left[\begin{smallmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \end{smallmatrix}\right] \left[\begin{smallmatrix} 1 & 1 & 1 & 1 \\ 1 & -1 & 1 & -1 \\ 1 & 1 & -1 & -1 \\ 1 & -1 & -1 & 1 \end{smallmatrix}\right] \\
  =& \left[\begin{smallmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \end{smallmatrix}\right] = \Lambda_1 (\hat{X})
\end{align*}
$$

**(3):** From **(1)**, we have

$$
\begin{align*}
  \Lambda^1 (\hat{M}(\alpha)) =& \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{M}(\alpha) \\
  =& \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes e^{i\alpha} \hat{I} \\
  =& (\ket{0}\bra{0} + e^{i\alpha}\ket{1}\bra{1})\otimes\hat{I} = \hat{P}(\alpha)\hat{I}
\end{align*}
$$
</details>

<MathBox title='' boxType='proposition' tag='proposition-5'>
For an arbitrary unitary operator $\hat{U}: {}^\P \mathcal{H} \to {}^\P \mathcal{H}$ the following holds

$$
\begin{align*}
  \hat{U}\in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}},\hat{D}_{\unitvec{z}}] \\
  \Lambda^1 (\hat{U}), \Lambda_1 (\hat{U}) \in \mathcal{F}[\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]
\end{align*}
$$

that is, any unitary $\hat{U}: {}^\P \mathcal{H} \to {}^\P \mathcal{H}$ can be generated from phase-multiplications $\hat{M}$ and spin-rotations around $\unitvec{y}$ and $\unitvec{z}$. In order to generate the controlled gates $\Lambda^1 (\hat{U})$ and $\Lambda_1 (\hat{U})$ one needs, in addition, the controlled $\operatorname{NOT}\left(\Lambda^1 (\hat{X})\right)$.

<details>
<summary>Proof</summary>

From Proposition $\ref{proposition-4}$, we know that for any unitary operator $\hat{U}$ on ${}^\P \mathcal{H}$ there exists angles $\alpha,\beta,\gamma,\delta$, so that the operators

$$
\begin{equation}
\begin{split}
  \hat{A} :=& \hat{D}_{\unitvec{z}} (\beta) \hat{D}_{\unitvec{y}} \left(\frac{\gamma}{2}\right) \\
  \hat{B} :=& \hat{D}_{\unitvec{y}} \left(-\frac{\gamma}{2}\right) \hat{D}_{\unitvec{z}} \left(-\frac{\delta + \beta}{2}\right) \\
  \hat{C} :=& \hat{D}_{\unitvec{y}} \left(\frac{\delta - \beta}{2}\right) \\
\end{split}
\tag{\label{equation-17}}
\end{equation}
$$

satisfy $\hat{A}\hat{B}\hat{C} = \hat{I}$ and $\hat{U} = e^{i\alpha} \hat{A}\hat{\sigma}_x \hat{B}\hat{\sigma}_x \hat{C}$. From $\eqref{equation-17}$, it follows that

$$
  \hat{A},\hat{B},\hat{C}\in\mathcal{F}[\hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}]
$$

Furthermore, we have

$$
  \hat{X}= \hat{\sigma}_x \in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}]
$$

Combined, this implies

$$
  \hat{U}\in\mathcal{F}[\hat{U}\hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}]
$$

Since $\hat{P}(\alpha) \in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}},\hat{D}_{\unitvec{z}}]$, it follows that

$$
\begin{equation}
  \left(\hat{P}(\alpha) \otimes\hat{A}\right) \Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{B}) \Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{C}) \in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}},\Lambda^1 (\hat{X})]
\tag{\label{equation-18}}
\end{equation}
$$

Finally, we have

$$
\begin{align*}
  & \left(\hat{P}(\alpha) \otimes\hat{A}\right) \Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{B}) \Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{C}) \\
  =& \left(\hat{P}(\alpha) \otimes\hat{A}\right) \Lambda^1 (\hat{X}) (\hat{I}\otimes\hat{B}) \left(\ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{X}\right) (\hat{I}\otimes\hat{C}) \\
  =& \left(\hat{P}(\alpha) \otimes\hat{A}\right) \Lambda^1 (\hat{X}) \left(\ket{0}\bra{0}\otimes\hat{B}\hat{C} + \ket{1}\bra{1}\otimes\hat{B}\hat{X}\hat{C}\right) \\
  =& \left(\hat{P}(\alpha) \otimes\hat{A}\right) \left(\ket{0}\bra{0}\hat{I} + \ket{1}\bra{1}\otimes\hat{X} \right) \left(\ket{0}\bra{0}\otimes\hat{B}\hat{C} + \ket{1}\bra{1}\otimes\hat{B}\hat{X}\hat{C}\right) \\
  =& \left(\hat{P}(\alpha) \otimes\hat{A}\right) \left(\ket{0}\bra{0}\otimes\hat{B}\hat{C} + \ket{1}\bra{1}\otimes\hat{X}\hat{B}\hat{X}\hat{C}\right) \\
  =& \underbrace{\hat{P}(\alpha) \ket{0}\bra{0}}_{=\ket{0}\bra{0}} \otimes \underbrace{\hat{A}\hat{B}\hat{C}}_{=\hat{I}} + \underbrace{\hat{P}(\alpha) \ket{1}\bra{1}}_{=e^{i\alpha} \ket{1}\bra{1}} \otimes \hat{A}\hat{X}\hat{B}\hat{X}\hat{C} \\
  =& \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1} \otimes \underbrace{e^{i\alpha} \hat{A}\hat{X}\hat{B}\hat{X}\hat{C}}_{=\hat{U}} \\
  =& \ket{0}\bra{0}\otimes\hat{I} + \ket{1}\bra{1}\otimes\hat{U} \\
  =& \Lambda^1 (\hat{U})
\end{align*}
$$

and with $\eqref{equation-18}$ the claim follows for $\Lambda^1 (\hat{U})$. In order to prove this for $\Lambda_1 (\hat{U})$, we use the fact that

$$
  \hat{H} \in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}},\hat{D}_{\unitvec{z}}]
$$

Since $\Lambda_1 (\hat{X}) = \hat{H}^{\otimes 2} \Lambda^1 (\hat{X}) \hat{H}^{\otimes 2}$, it follows that

$$
  \Lambda_1 (\hat{X}) \in\mathcal{F}[\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]
$$

and in similar argument we can verify that

$$
  \Lambda^1 (\hat{U}) = \left(\hat{A}\otimes\hat{P}(\alpha)\right) \Lambda_1 (\hat{X}) (\hat{B}\otimes\hat{I}) \Lambda_1 (\hat{X}) (\hat{C}\otimes\hat{I})
$$
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
For an arbitrary unitary operator $\hat{U}: {}^\P \mathcal{H} \to {}^\P \mathcal{H}$ and $n\in\N_0$, we have

$$
  \hat{U}\in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}},\hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]
$$

<LatexFigure width={75} src='/fig/controlled_multi_gate.svg' alt=''
  caption='Generation of the controlled $\hat{U}$ gate $\Lambda^n (\hat{U})$ by $\hat{A},\hat{C},\hat{D}\in\mathcal{F}[\Lambda^{n-1} (\sqrt{\hat{U}}), \Lambda^{n-1}(\sqrt{\hat{U}^\dagger})]$ and $\hat{B}\in\mathcal{F}[\Lambda^1 (\hat{X})]$.'
>
```latex
\documentclass[tikz, border=1pt]{standalone}
\usepackage{quantikz}

\begin{document}
\begin{quantikz}[wire types={q,n,q,n,q,n,n,n,q,n,q}]
  \lstick{\ket{x_n}} &[0.1cm] \ctrl{2}\gategroup[11, style={draw=none}]{$\Lambda^n (U)$} &[0.1cm] \midstick[11, brackets=none]{$=$} &[0.1cm] \gategroup[11, style={draw=none,fill=gray!20},background]{$D$} &[0.5cm] \ctrl{2}\gategroup[11, style={draw=none,fill=gray!20},background]{$B$} &[0.5cm] \ctrl{2}\gategroup[11, style={draw=none,fill=gray!20},background]{$C$} &[0.5cm] \ctrl{2}\gategroup[11, style={draw=none,fill=gray!20},background]{$B$} &[0.5cm] \ctrl{4}\gategroup[11, style={draw=none,fill=gray!20},background]{$A$} & \\
  \lstick{\otimes} &&&&&&&& \\[-0.2cm]
  \lstick{\ket{x_{n-1}}} & \ctrl{2} & & \ctrl{2} & \gate{X} & \ctrl{2} & \gate{X} & &  \\[-0.2cm]
  \lstick{\otimes} &&&&&&&& \\
  \lstick{\ket{x_{n-2}}} & \ctrl{1} & & \ctrl{1} & & \ctrl{1} & & \ctrl{1} &  \\
  \lstick{\otimes} &&&&&&&& \\[-0.4cm]
  \lstick{\vdots} & \vdots & & \vdots & & \vdots & & \vdots & \\[-0.2cm]
  \lstick{\otimes} &&&&&&&& \\
  \lstick{\ket{x_1}} & \ctrl{-1} & & \ctrl{-1} & & \ctrl{-1} & & \ctrl{-1} & \\
  \lstick{\otimes} &&&&&&&& \\[-0.2cm]
  \lstick{\ket{x_0}} & \gate{U}\wire[u][2]{q} & & \gate{\sqrt{U}}\wire[u][2]{q} & & \gate{\sqrt{U^\dagger}}\wire[u][2]{q} & & \gate{\sqrt{U}}\wire[u][2]{q} &
\end{quantikz}
\end{document}
```
</LatexFigure>

<details>
<summary>Proof</summary>

We show this by induction. The base cases $n = 0$ and $n = 1$ follow from Proposition $\ref{proposition-5}$. For the inductive step, suppose $\Lambda^{n-1} (\hat{U}) \in \mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]$ holds for arbitrary $\hat{U}\in\mathcal{U}({}^\P \mathcal{H})$. First, we consider the gates $\hat{A},\hat{B},\hat{C},\hat{D}$ shown in 

$$
\begin{equation}
  \hat{A},\hat{B},\hat{C},\hat{D}\in\mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}},\hat{D}_{\unitvec{z}},\Lambda^1 (\hat{X})]
\tag{\label{equation-19}}
\end{equation}
$$

The action of these gates and that of $\Lambda^n (\hat{U})$ can be described in terms of the computational basis $\ket{x} = \bigotimes_{j=n}^n \ket{x_j}$ in ${}^\P \mathcal{H}^{\otimes n+1}$ as follows

$$
\begin{align*}
  \hat{D}\ket{x} =& \ket{x_n \dots x_1} \otimes \hat{U}^{\frac{1}{2}\prod_{j=1}^{n-1} x_j} \ket{x_0} \\
  \hat{B}\ket{x} =& \ket{x_n (x_n \overset{2}\oplus x_{n-1}) x_{n-2}\dots x_1} \otimes \ket{x_0} \\
  \hat{C}\ket{x} =& \ket{x_n \dots x_1} \otimes \hat{U}^{-\frac{1}{2}\prod_{j=1}^{n-1} x_j} \ket{x_0} \\
  \hat{A}\ket{x} =& \ket{x_n \dots x_1} \otimes \hat{U}^{x_n \frac{1}{2}\prod_{j=1}^{n-2} x_j} \ket{x_0} \\
  \Lambda^n (\hat{U}) \ket{x} =& \ket{x_n \dots x_1} \otimes \hat{U}^{-\frac{1}{2}\prod_{j=1}^n x_j} \ket{x_0}
\end{align*}
$$

This implies

$$
\begin{align*}
  \hat{A}\hat{B}\hat{C}\hat{B}\hat{D} =& \hat{A}\hat{B}\hat{C}\hat{B} \ket{x_n \dots x_1} \otimes \hat{U}^{\frac{1}{2}\prod_{j=1}^{n-1} x_j} \ket{x_0} \\
  =& \hat{A}\hat{B}\hat{C} \ket{x_n (x_n \overset{2}{\oplus} x_{n-1}) x_{n-2} \dots x_1} \otimes \hat{U}^{\frac{1}{2}\prod_{j=1}^{n-1} x_j} \ket{x_0} \\
  =& \hat{A}\hat{B} \ket{x_n (x_n \overset{2}{\oplus} x_{n-1}) x_{n-2} \dots x_1} \otimes \hat{U}^{\frac{1}{2}\left[x_{n-1} - (x_n \overset{2}{\oplus} x_{n-1}) \right]\prod_{j=1}^{n-2} x_j} \ket{x_0} \\
  =& \hat{A} \ket{x_n \underbrace{(x_n \overset{2}{\oplus} (x_n \overset{2}{\oplus} x_{n-1}))}_{=x_{n-1} - 1} x_{n-2} \dots x_1} \otimes \hat{U}^{\frac{1}{2}\left[x_{n-1} - (x_n \overset{2}{\oplus} x_{n-1}) \right]\prod_{j=1}^{n-2} x_j} \ket{x_0} \\
  =& \ket{x_n \dots x_1} \otimes \hat{U}^{\frac{1}{2} \overbrace{[x_n + x_{n-1} - (x_n \overset{2}{\oplus} x_{n-1})]} \prod_{j=1}^{n-2} x_j} \ket{x_0} \\
  =& \ket{x_n \dots x_1} \otimes \hat{U}^{\prod_{j=1}^n x_j} \ket{x_0} \\
  =& \Lambda^n (\hat{U}) \ket{x}
\end{align*}
$$

and thus because of $\eqref{equation-19}$

$$
  \Lambda^n (\hat{U}) = \hat{A}\hat{B}\hat{C}\hat{B}\hat{D} \in \mathcal{F}[\hat{M},\hat{D}_{\unitvec{y}},\hat{D}_{\unitvec{z}},\Lambda^1 (\hat{X})]
$$
</details>
</MathBox>

<MathBox title='Global swap operator' boxType='definition'>
For $n\in\N_+$ and $j,k\in\N_0$ with $k < j \leq n - 1$ we define on ${}^\P \mathcal{H}^{\otimes n}$

$$
\begin{align*}
  S_{jk}^{(n)} :=& \hat{I}^{\otimes n -1 - j} \otimes \ket{0}\bra{0} \otimes \ket{I}^{\otimes j - k - 1} \otimes \ket{0}\bra{0}\otimes \hat{I}^{\otimes k} \\
  &+ \hat{I}^{\otimes n -1 - j} \otimes \ket{1}\bra{1} \otimes \ket{I}^{\otimes j - k - 1} \otimes \ket{1}\bra{1}\otimes \hat{I}^{\otimes k} \\
  &+ \hat{I}^{\otimes n -1 - j} \otimes \ket{0}\bra{1} \otimes \ket{I}^{\otimes j - k - 1} \otimes \ket{1}\bra{0}\otimes \hat{I}^{\otimes k} \\
  &+ \hat{I}^{\otimes n -1 - j} \otimes \ket{1}\bra{0} \otimes \ket{I}^{\otimes j - k - 1} \otimes \ket{0}\bra{1}\otimes \hat{I}^{\otimes k}
\end{align*}
$$

It is also useful to define $S_{jj}^{(n)} = \hat{I}^{\otimes n}$. The *global swap* or *exchange operator* $\hat{S}^{(n)}$ on ${}^\P \mathcal{H}^{\otimes n}$ is defined as

$$
  \hat{S}^{(n)} := \prod_{j=0}^{\lfloor \frac{n}{2} \rfloor - 1} S_{n-1-j, j}^{(n)} 
$$
</MathBox>

With $S_{jk}^{(n)}$ the qubits in the factor spaces ${}^\P \mathcal{H}_j$ and ${}^\P \mathcal{H}_k$ inside the tensor products ${}^\P \mathcal{H}^{\otimes n}$ are swapped. With $S^{(n)}$ the sequence of factors in the tensor product is completely reversed.

<MathBox title='Properties of the global swap operator' boxType='proposition'>
Suppose $n\in\N_+$ and $j,k\in\N_0$ with $k < j < n - 1$ as well as $\bigotimes_{l=n-1}^0 \ket{\psi_l}\in {}^\P \mathcal{H}^{\otimes n}$. Then:
1.
$$
  S_{jk}^{(n)} \bigotimes_{l=n-1}^0 \ket{\psi_l} = \ket{\psi_{n-1} \dots \psi_{j+1} \psi_k \psi_{j-1} \dots \psi_{k+1} \psi_j \psi_{k-1} \dots \psi_0}
$$
2. 
$$
\begin{equation}
  \left(S_{jk}^{(n)}\right)^2 = \hat{I}_2^{\otimes n}
\tag{\label{equation-20}}
\end{equation}
$$
3. $[S_{jk}^{(n)}, S_{lm}^{(n)}] = 0$ for $j,k \notin\set{l, m}$
4. 
$$
  S^{(n)} \bigotimes_{l=n-1}^0 \ket{psi_l} = \bigotimes_{l=0}^{n-1} \ket{\psi_l} = \ket{\psi_0 \psi_1 \dots \psi_{n-2} \psi_{n-1}}
$$

<details>
<summary>Proof</summary>

**(1):**
Recall that any complex number $c\in\mathbb{C}$ can be multiplied to any factor in a tensor product, i.e.

$$
  \cdots\otimes c\ket{\psi}\otimes\cdots\otimes\ket{\varphi}\otimes\cdots = \cdots\otimes \ket{\psi}\otimes\cdots\otimes c\ket{\varphi}\otimes\cdots
$$

Expanding the tensor product, we obtain

$$
\begin{align*}
  & S_{jk}^{(n)} \bigotimes_{l=n-1}^0 \ket{\psi_l} \\
  =& \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{0}\braket{0|\psi_j} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{0}\braket{0|\psi_k}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{1}\braket{1|\psi_j} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{1}\braket{1|\psi_k}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{0}\braket{1|\psi_j} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{1}\braket{0|\psi_k}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{1}\braket{0|\psi_j} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{0}\braket{1|\psi_k}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  =& \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{0}\braket{0|\psi_k} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{0}\braket{0|\psi_j}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{1}\braket{1|\psi_k} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{1}\braket{1|\psi_j}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{0}\braket{0|\psi_k} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{1}\braket{1|\psi_j}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{1}\braket{1|\psi_k} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{0}\braket{0|\psi_j}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  =& \ket{\psi_{n-1} \dot \psi_{j+1}} \otimes \ket{0}\braket{0|\psi_k} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{\psi_j}\otimes\ket{\psi_{k-1}\dots\psi_0} \\
  &+ \ket{\psi_{n-1}\dots\psi_{j+1}} \otimes \ket{1}\braket{1|\psi_k} \otimes \ket{\psi_{j_1}\dots\psi_{k+1}} \otimes \ket{\psi_j}\ket{\psi_{k-1}\dots\psi_0} \\
  =& \ket{\psi_{n-1}\dots\psi_{j+1}} \otimes \ket{\psi_k} \otimes \ket{\psi_{j-1}\dots\psi_{k+1}} \otimes \ket{\psi_j} \otimes \ket{\psi_{k-1}\dots\psi_0}
\end{align*}
$$

**(2):** This follows from **(1)** since the second application of $S_{jk}^{(n)}$ reverses the exchange of the qubits $\ket{\psi_j}$ and $\ket{\psi_k}$.

**(3):** Since $S_{jk}^{(n)}$ acts only on the factor spaces ${}^\P \mathcal{H}_j$ and ${}^\P \mathcal{H}_k$, and $S_{lm}^{(n)}$ acts only on the factor spaces ${}^\P \mathcal{H}_l$ and ${}^\P \mathcal{H}_m$, it follows for $j,k \notin\set{l,m}$ that $S_{jk}^{(n)} S_{lm}^{(n)} = S_{lm}^{(n)} S_{jk}^{(n)}$.

**(4):** This follows directly form the succesive application of the $S_{n-1-j,j}^{(n)}$ in $S^{(n)}$.
</details>
</MathBox>

<MathBox title='' boxType='lemma'>
For any $\hat{U}\in\mathcal{U}({}^\P \mathcal{H})$ and $n_a, n_b \in \N_0$, we have

$$
\begin{equation}
  \Lambda_{n_b}^{n_a} (\hat{U}) = S_{n_b}^{(n_a + n_b + 1)} \Lambda^{n_a + n_b} (\hat{U}) S_{n_b 0}^{n_a + n_b + 1}
\tag{\label{equation-21}}
\end{equation}
$$

and thus

$$
\begin{equation}
  \Lambda_{n_b}^{n_a} (\hat{U}) \in\mathcal{F}[\Lambda^1 (\hat{X}), \Lambda_1 (\hat{X}), \Lambda^{n_a + n_b} (\hat{U})]
\tag{\label{equation-28}}
\end{equation}
$$

<LatexFigure width={75} src='/fig/controlled_swap_gate.svg' alt=''
  caption='Generation of the controlled $\hat{U}$ gate $\Lambda^n (\hat{U})$ from $S_{n_b 0}^{(n_a + n_b + 1}$ and $\Lambda^{n_a + n_b}$.'
>
```latex
\documentclass[tikz, border=1pt]{standalone}
\usepackage{quantikz}

\begin{document}
\begin{quantikz}[wire types={q,n,n,n,q,n,q,n,q,n,n,n,q}]
  \lstick{\ket{x_{n_a + n_b}}} &[0.1cm] \ctrl{1}\gategroup[13, style={draw=none}]{$\Lambda_{n_b}^{n_a} (U)$} &[0.1cm] \midstick[13, brackets=none]{$=$} &[0.5cm] \gategroup[13, style={draw=none, fill=gray!20, inner xsep=0.7cm},background]{$S_{n_b 0}^{(n_a + n_b + 1)}$} &[1.5cm] \ctrl{1}\gategroup[13, style={draw=none, fill=gray!20, inner xsep=0.5cm},background]{$\Lambda^{n_a + n_b} (U)$} &[1.5cm] \gategroup[13, style={draw=none, fill=gray!20, inner xsep=0.7cm},background]{$S_{n_b 0}^{(n_a + n_b + 1)}$} &[0.5cm] \\
  \lstick{\otimes} &&&&&& \\[-0.4cm]
  \lstick{\vdots} & \vdots & & & \vdots & & \\[-0.2cm]
  \lstick{\otimes} &&&&&& \\
  \lstick{\ket{x_{n_b + 1}}} & \ctrl{-1}\wire[d][4]{q} &&& \ctrl{-1}\wire[d][4]{q} && \\
  \lstick{\otimes} &&&&&& \\[-0.2cm]
  \lstick{\ket{x_{n_b}}} & \gate{U} && \swap{6} & \ctrl{0} & \swap{6} & \\
  \lstick{\otimes} &&&&&& \\
  \lstick{\ket{x_{n_b - 1}}} & \ctrl{1} &&& \ctrl{1} & & \\
  \lstick{\otimes} &&&&&& \\[-0.4cm]
  \lstick{\vdots} & \vdots & & & \vdots && \\[-0.2cm]
  \lstick{\otimes} &&&&&& \\
  \lstick{\ket{x_0}} & \ctrl{-1} && \targX{} & \gate{U}\wire[u][1]{q} & \targX{} &
\end{quantikz}
\end{document}
```
</LatexFigure>

<details>
<summary>Proof</summary>

Define $n = n_a + n_b$. From Definition $\ref{definition-3}$, we have

$$
\begin{align*}
  \Lambda_{n_b}^{n_a} (\hat{U}) =& \hat{I}_2^{\otimes n+1} + \ket{2^{n_a - 1}} \bra{2^{n_a} - 1} \otimes (\hat{U} - \hat{I}_2) \otimes \ket{2^{n_b} - 1} \bra{2^{n_b} - 1} \\
  \Lambda^n (\hat{U}) =& \hat{I}_2^{\otimes n+1} + \ket{2^n - 1}\bra{2^n - 1} \otimes (\hat{U} - \hat{I}_2)
\end{align*}
$$

By $\eqref{equation-20}$, this implies

$$
  S_{n_b 0}^{n+1} \Lambda^n (\hat{U}) S_{n_b 0}^{n+1} = \hat{I}_2^{\otimes n + 1} + S_{n_b 0}^{(n+1)} \left[\ket{2^n - 1} \bra{2^n - 1} \otimes (\hat{U} - \hat{I}_2) \right] S_{n_b 0}^{(n+1)}
$$

and to prove $\eqref{equation-21}$ it suffices to show that

$$
\begin{align*}
  &\ket{2^{n_a} - 1} \bra{2^{n_a} - 1} \otimes (\hat{U} - \hat{I}_2) \otimes \ket{2^{n_b} - 1} \bra{2^{n_b} - 1} \\
  =& S_{n_b 0}^{n+1} = \hat{I}_2^{\otimes n + 1} + S_{n_b 0}^{(n+1)} \left[\ket{2^n - 1} \bra{2^n - 1} \otimes (\hat{U} - \hat{I}_2) \right] S_{n_b 0}^{(n+1)} \tag{\label{equation-27}}
\end{align*}
$$

For this we consider an arbitary vector

$$
  \bigotimes_{j=n}^0 \ket{\psi_j} = \ket{\psi_n \dots \psi_0} \in {}^\P \mathcal{H}^{\otimes n + 1}
$$

Then it follows that

$$
\begin{equation}
\begin{split}
  &\left[\ket{2^{n_a} - 1} \bra{2^{n_a} - 1} \otimes (\hat{U} - \hat{I}_2) \otimes \ket{2^{n_b} - 1}\bra{2^{n_b} - 1} \right] \ket{\psi_n \dots\psi_0} \\
  =& \ket{2^{n_a} - 1}\braket{2^{n_a} - 1|\psi_n \dots\psi_{n - n_a + 1}} \\
  &\otimes (\hat{U} - \hat{I}) \ket{\psi_{n_b}} \otimes \ket{2^{n_b} - 1} \braket{2^{n_b} - 1| \psi_{n_b - 1} \dots \psi_0}
\end{split}
\tag{\label{equation-24}}
\end{equation}
$$

Here we have $n - n_a = n_b$ and

$$
\begin{align*}
  \ket{2^{n_a} - 1} \braket{2^{n_a} - 1|\psi_n \dots\psi_{n_b + 1}} =& \underbrace{\left[\bigotimes_{l=0}^{n_a - 1} \ket{1} \right]}_{\in {}^\P \mathcal{H}^{\otimes n_a}} \underbrace{\braket{1\dots 1|\psi_n \dots \psi_{n_b + 1}}}_{\in\mathbb{C}} \\
  =& \left[\prod_{j=n_b + 1}^n \braket{1|\psi_j} \right] \left[\bigotimes_{l=0}^{n_a - 1} \ket{1} \right] \tag{\label{equation-22}}
\end{align*}
$$

and analogously

$$
\begin{equation}
  \ket{2^{n_b} - 1} \braket{2^{n_b} - 1|\psi_{n_b - 1} \dots\psi_0} = \left[\prod_{j=0}^{n_b - 1} \braket{1|\psi_j} \right] \left[\bigotimes_{l=0}^{n_b - 1} \ket{1} \right]
\tag{\label{equation-23}}
\end{equation}
$$

With $\eqref{equation-22}$ and $\eqref{equation-23}$, then $\eqref{equation-24}$ becomes

$$
\begin{equation}
\begin{split}
  &\left[\ket{2^{n_a} - 1} \bra{2^{n_a} - 1} \otimes (\hat{U} - \hat{I}_2) \otimes \ket{2^{n_b} - 1}\bra{2^{n_b} - 1} \right] \ket{\psi_n \dots\psi_0} \\
  =& \left[\prod_{\substack{j=0 \\ j\neq n_b }}^n \braket{1|\psi_j} \right] \left[\bigotimes_{l=0}^{n_a - 1} \ket{1} \right] \otimes (\hat{U} - \hat{I}_2) \ket{\psi_{n_b}} \otimes \left[\bigotimes_{l=0}^{n_b - 1} \ket{1} \right]
\end{split}
\tag{\label{equation-25}}
\end{equation}
$$

On the other hand, we have

$$
\begin{align*}
  & S_{n_b 0}^{(n+1)} \left[\ket{2^n - 1} \bra{2^n - 1} \otimes (\hat{U} - \hat{I}_2) \right] S_{n_b 0}^{(n+1)} \ket{\psi_n \dots\psi_0} \\
  =& S_{n_b 0}^{(n+1)} \left[\ket{2^n - 1} \bra{2^n - 1} \otimes (\hat{U} - \hat{I}_2) \right] \ket{\psi_n \dots \psi_{n_b +1} \psi_0 \psi_{n_b - 1} \dots \psi_1 \psi_{n_b}} \\
  =& S_{n_b 0}^{(n+1)} [\ket{2^n - 1} \underbrace{\braket{2^n - 1|\psi_n \dots \psi_{n_b +1} \psi_0 \psi_{n_b - 1} \dots \psi_1 \psi_{n_b}}}_{\prod_{\substack{j=0 \\ j\neq n_b }}^n \braket{1|\psi_j}} \otimes (\hat{U} - \hat{I}_2)\ket{\psi_{n_b}}] \\
  =& \left[ \prod_{\substack{j=0 \\ j\neq n_b }}^n \braket{1|\psi_j} \right] S_{n_b 0}^{(n + 1)} \left[\bigotimes_{l=0}^{n-1} \ket{1} \otimes (\hat{U} - \hat{I}) \ket{\psi_{n_b}} \right] \\
  =& \left[ \prod_{\substack{j=0 \\ j\neq n_b }}^n \braket{1|\psi_j} \right] \left[\bigotimes_{l=n_b + 1}^n \ket{1} \otimes (\hat{U} - \hat{I}) \ket{\psi_{n_b}} \otimes \bigotimes_{l=0}^{n_b - 1} \ket{1} \right] \tag{\label{equation-26}}
\end{align*}
$$

From $\eqref{equation-25}$ and $\eqref{equation-26}$ follows $\eqref{equation-27}$ and thus the claim $\eqref{equation-21}$. In turn, this implies

$$
  \Lambda_{n_b}^{n_a} (\hat{U}) \in \mathcal{F}[S_{n_b 0}^{(n + 1)}, \Lambda^n (\hat{U})]
$$

Since $S_{n_b 0}^{(n + 1)} \in \mathcal{F}[S]$ and $S$ can be built from $\Lambda^1 (\hat{X})$ and $\Lambda_1 (\hat{X})$, the claim $\eqref{equation-28}$ follows.
</details>
</MathBox>

<MathBox title='' boxType='definition'>
Let $\hat{A}$ be an operator on ${}^\P \mathcal{H}$. For vectors $\ket{b}$ of the computational basis of ${}^\P \mathcal{H}^{\otimes n}$ we define

$$
  \hat{A}^{\otimes\ket{b}} := \hat{A}^{b_{n-1}} \otimes\cdots\otimes \hat{A}^{b_0}
$$

as well as

$$
  \ket{\lnot b} := \ket{\lnot b_{n-1} \cdots\lnot b_0} = \hat{X}\ket{b_{n-1}}\otimes\cdots\otimes\hat{X}\ket{b_0}
$$

where $\hat{X} = \hat{\sigma}_x$ is the NOT-operator and $\lnot b_j := 1 \overset{2}{\oplus} b_j$ is the classical negation.
</MathBox>

<MathBox title='' boxType='lemma'>
Let $n_a, n_b \in\N_0$ and $\ket{a}\in {}^\P \mathcal{H}^{\otimes n_a}$ and $\ket{b}\in {}^\P \mathcal{H}^{\otimes n_b}$ vectors of the respective computational basis as well as $\hat{U}$ a unitary operator on ${}^\P \mathcal{H}$. Then the following holds

$$
  \Lambda_{\ket{b}}^{\ket{a}} (\hat{U}) = \left(\hat{X}^{\otimes\ket{\lnot a}} \otimes\hat{I}_2 \otimes\hat{X}^{\otimes\ket{\lnot b}} \right) \Lambda_{n_b}^{n_a} (\hat{U}) \left(\hat{X}^{\otimes\ket{\lnot a}} \otimes\hat{I}_2 \otimes\hat{X}^{\otimes\ket{\lnot b}} \right)
$$

and thus

$$
  \Lambda_{\ket{b}}^{\ket{a}} (\hat{U}) \in \mathcal{F}[\hat{X}, \Lambda_{n_b}^{n_a} (\hat{U})]
$$

<details>
<summary>Proof</summary>

For $c_j \in\set{0,1}$ we have in general $\hat{X}^{\lnot c_j} \ket{c_j} = \ket{1}$ as well as $(\hat{X}^{\lnot c_j})^2 = \hat{X}^{2\lnot c_j} = \hat{I}_2$. Thus, for $c\in\set{a,b}$, we have the following identies:

1.
$$
\begin{align*}
  \hat{X}^{\otimes\ket{\lnot c}} \ket{c} =& \left(\hat{X}^{\lnot c_{n_c - 1}} \otimes\cdots\otimes \hat{X}^{\lnot c_0} \right) \ket{c_{n_c - 1}} \otimes\cdots\otimes\ket{c_0} \\
  =& X^{\lnot c_{n_c - 1}} \ket{c_{n_c - 1}} \otimes\cdots\otimes \hat{X}^{\lnot c_0} \ket{c_0} \\
  =& \bigotimes_{j=n_c - 1}^0 \ket{1} = \ket{2^{n_c} - 1}
\end{align*}
$$
2. $\left( \hat{X}^{\otimes \ket{\lnot c}} \right)^2 = \hat{I}_2^{\otimes n_c}$
3. $\hat{X}^{\otimes\ket{\lnot c}} \ket{2^{n_c} - 1} = \ket{c}$

With these, we obtain

$$
\begin{align*}
  &\left(\hat{X}^{\otimes\ket{\lnot a}} \otimes\hat{I}_2 \otimes\hat{X}^{\otimes\ket{\lnot b}} \right) \Lambda_{n_b}^{n_a} (\hat{U}) \left(\hat{X}^{\otimes\ket{\lnot a}} \otimes\hat{I}_2 \otimes\hat{X}^{\otimes\ket{\lnot b}} \right) \\
  =& \left(\hat{X}^{\otimes\ket{\lnot a}} \otimes\hat{I}_2 \otimes\hat{X}^{\otimes\ket{\lnot b}} \right) \\
  &\cdot \left(\hat{I}_2^{\otimes n_a + n_b + 1} + \ket{2^{n_a} - 1}\bra{2^{n_a} - 1} \otimes (\hat{U} - \hat{I}_2) \otimes\ket{2^{n_b} - 1} \bra{2^{n_b} - 1} \right) \\
  &\cdot \left(\hat{X}^{\otimes\ket{\lnot a}} \otimes\hat{I}_2 \otimes\hat{X}^{\otimes\ket{\lnot b}} \right) \\
  =& \left(\hat{X}^{\otimes\ket{\lnot a}} \right)^2 \otimes \hat{I}_2 \otimes \left(\hat{X}^{\otimes\ket{\lnot b}} \right)^2 \\
  &+ \underbrace{\hat{X}^{\otimes\ket{\lnot a}} \ket{2^{n_a} - 1} \bra{2^{n_a} - 1} \hat{X}^{\otimes\ket{\lnot a}}}_{=\ket{a}\bra{a}} \\
  &\otimes (\hat{U} - \hat{I}) \otimes \underbrace{\hat{X}^{\otimes\ket{\lnot b}} \ket{2^{n_b} - 1}\bra{2^{n_b} - 1} \hat{X}^{\otimes\ket{\lnot b}}}_{=\ket{b}\bra{b}} \\
  =& \hat{I}_2^{\otimes n_a + n_b + 1} + \ket{a}\bra{a} \otimes (\hat{U} - \hat{I}_2) \otimes \ket{b}\bra{b} \\
  =& \Lambda_{\ket{b}}^{\ket{a}} (\hat{U})
\end{align*}
$$

from which it follows that

$$
  \Lambda_{\ket{b}}^{\ket{a}} (\hat{U}) \in\mathcal{F}[\hat{X}, \Lambda_{n_b}^{n_a} (\hat{U})]
$$
</details>
</MathBox>

<MathBox title='Embedding operator' boxType='definition' tag='definition-4'>
Let $n, x, y\in\N_0$ with $0 \leq x < y < 2^n$ as well as $\hat{U}$ be a unitary operator on ${}^\P \mathcal{H}$ with the matrix representation

$$
  \mathbf{U} = \begin{bmatrix} u_{00} & u_{01} \\ u_{10} & u_{11} \end{bmatrix}
$$

in the basis $\set{\ket{0}, \ket{1}}$. In terms of the computational basis in ${}^\P \mathcal{H}^{\otimes n}$ we define the embedding operator $T_{\ket{x}\ket{y}} (\hat{U}): {}^\P \mathcal{H}^{\otimes n} \to {}^\P \mathcal{H}^{\otimes n}$ as follows

$$
\begin{align*}
  &T_{\ket{x}\ket{y}} (\hat{U}) \\
  :=& \sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} \ket{z}\bra{z} + u_{00} \ket{x}\bra{x} + u_{01} \ket{x}\bra{y} + u_{10} \ket{y}\bra{x} + u_{11} \ket{y}\bra{y} \\
  =& \hat{I}_2^{\otimes n} + (u_{00} - 1) \ket{x}\bra{x} + u_{01} \ket{x}\bra{y} + u_{10} \ket{y}\bra{x} + (u_{11} - 1) \ket{y}\bra{y}
\end{align*}
$$
</MathBox>

In the computational basis, the embedding operator $T_{\ket{x}\ket{y}} (\hat{V})$ has matrix representation

$$
  T_{\ket{x}\ket{y}} (\hat{V}) = \begin{array}{cc} 
    & \begin{matrix} \ket{0} & \hphantom{--} & \hphantom{--} & \ket{x} & \hphantom{--} & \hphantom{--} & \hphantom{--} & \ket{y} & \hphantom{1} & \hphantom{\ddots} & \hphantom{1} \end{matrix} \\
    \begin{matrix} \ket{0} \\ \vphantom{|} \\ \vphantom{|} \\ \ket{x} \\ \vphantom{|} \\ \vphantom{|} \\ \vphantom{|} \\ \ket{y} \\ \vphantom{1} \\ \vphantom{\ddots} \\ \vphantom{1} \end{matrix} & \begin{bmatrix}
      1 & & & | & & & & | & & & \\
      & \ddots & & | & & & & | & & & \\
      & & 1 & | & & & & | & & & \\
      -- & -- & -- & v_{00} & -- & -- & -- & v_{01} & & & \\
      & & & | & 1 & & & | & & & \\
      & & & | & & \ddots & & | & & & \\
      & & & | & & & 1 & | & & & \\
      -- & -- & -- & v_{10} & -- & -- & -- & v_{11} & & & \\
      & & & & & & & & 1 & & \\
      & & & & & & & & & \ddots & \\
      & & & & & & & & & & 1 \\
    \end{bmatrix}
  \end{array}
$$

<MathBox title='Properties of the embedding operator' boxType='definition'>
Let $n, x, y\in\N_0$ with $0 \leq x < y < 2^n$. For any unitary operators $\hat{V}, \hat{W}\in\mathcal{U}({}^\P \mathcal{H})$ the embedding operator $T_{\ket{x}\ket{y}} (\hat{U}): {}^\P \mathcal{H}^{\otimes n} \to {}^\P \mathcal{H}^{\otimes n}$ satisfies:
1. $T_{\ket{x}\ket{y}} (\hat{V}) T_{\ket{x}\ket{y}} (\hat{W}) = T_{\ket{x}\ket{y}} (\hat{V}\hat{W})$
2. $T_{\ket{x}\ket{y}}^\dagger (\hat{V}) = T_{\ket{x}\ket{y}} (\hat{V}^\dagger)$
3. **Unitarity:** $T_{\ket{x}\ket{y}} (\hat{V}) T_{\ket{x}\ket{y}}^\dagger (\hat{V}) = \hat{I}_2^{\otimes n}$

<details>
<summary>Proof</summary>

**(1):**
By definition $T_{\ket{x}\ket{y}} (\hat{V}) T_{\ket{x}\ket{y}} (\hat{W})$ is given by

$$
\begin{align*}
  &T_{\ket{x}\ket{y}} (\hat{V}) T_{\ket{x}\ket{y}} (\hat{W}) \\
  =& \left(\sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} \ket{z}\bra{z} + v_{00} \ket{x}\bra{x} + v_{01} \ket{x}\bra{y} + v_{10} \ket{y}\bra{x} + v_{11} \ket{y}\bra{y} \right) \\
  & \left(\sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} \ket{z}\bra{z} + w_{00} \ket{x}\bra{x} + w_{01} \ket{x}\bra{y} + w_{10} \ket{y}\bra{x} + w_{11} \ket{y}\bra{y} \right)
\end{align*}
$$

Since vectors of the computation basis $\ket{x}$ and $\ket{y}$ satisfy $\braket{x|y} = \delta_{xy}$, this becomes

$$
\begin{align*}
  T_{\ket{x}\ket{y}} (\hat{V}) T_{\ket{x}\ket{y}} (\hat{W}) =& \sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} \ket{z}\bra{z} \\
  &+ (v_{00} w_{00} + v_{01} w_{10}) \ket{x}\bra{x} + (v_{00} w_{01} + v_{01}w_{11}) \ket{x}\bra{y} \\
  &+ (v_{10} w_{00} + v_{11} w_{10}) \ket{y}\bra{x} + (v_{10} w_{01} + v_{11}w_{11}) \ket{y}\bra{y} \\
  =& \sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} \ket{z}\bra{z} \\
  &+ (VW)_{00} \ket{x}\bra{x} + (VW)_{01} \ket{x}\bra{y} \\
  &+ (VW)_{10} \ket{y}\bra{x} + (VW)_{11} \ket{y}\bra{y} \\
  =& T_{\ket{x}\ket{y}} (\hat{V}\hat{W}) 
\end{align*}
$$

**(2):** In the computation basis, the matrix representation of $\hat{V}^\dagger$ is

$$
  \hat{V}^\dagger = \begin{bmatrix} v_{00}^* & v_{01}^* \\ v_{10}^* & v_{11}^* \end{bmatrix}
$$

Since $\ket{a}\bra{b}^\dagger = \ket{b}\ket{a}$, we get

$$
\begin{align*}
  & T_{\ket{x}\ket{y}}^\dagger (\hat{V}) \\
  =& \sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} (\ket{z}\bra{z})^\dagger + (v_{00}\ket{x}\bra{y})^\dagger + (v_{01}\ket{x}\ket{y})^\dagger + (v_{10} \ket{y}\bra{x})^dagger + (v_{11} \ket{y}\bra{y})^\dagger \\
  =& \sum_{\substack{z=0 \\ z\neq x,y }}^{2^n - 1} \ket{z}\bra{z} \ket{z}\bra{z} v_{00}^* \ket{x}\bra{x} + v_{01}^* \ket{y}\bra{x} + v_{10}^* \ket{x}\ket{y} + v_{11}^* \ket{y}\bra{y} \\
  =& T_{\ket{x}\ket{y}} (\hat{V}^\dagger)
\end{align*}
$$

**(3):** From **(1)** and **(2)**, it follows that

$$
\begin{align*}
  T_{\ket{x}\bra{y}} (\hat{V}) T_{\ket{x}\ket{y}}^\dagger (\hat{V}) =& T_{\ket{x}\ket{y}} (\hat{V}) T_{\ket{x}\ket{y}} (\hat{V}^\dagger) = T_{\ket{x}\ket{y}} (\hat{V}\hat{V}^*) \\
  =& T_{\ket{x}\ket{y}} (\hat{I}_2) = \hat{I}^{\otimes n}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-3'>
Let $n\in\N_+$ and $N = 2^n - 1$ and $\hat{U}\in\mathcal{U}({}^\P \mathcal{H}^{\otimes n}$. Then there exist $\hat{V}^{(0)},\dots,V^{(N-1)} \in\mathcal{U}({}^\P \mathcal{H})$ such that the operator

$$
  \hat{U}^{(N)} := \hat{U}\hat{T}_{\ket{N-1}\ket{N}} \left(V^{(N-1)} \right) \cdots T_{\ket{0}\ket{N}} \left(V^{(0)} \right) \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})
$$

in the computational basis of ${}^\P \mathcal{H}^{\otimes n}$ has the matrix representation

$$
  \mathbf{U}^{(N)} = \left[\begin{array}{cc} 
    \mathbf{A}^{(N)} & \begin{matrix} 0 \\ \vdots \\ 0 \end{matrix} \\
    \begin{matrix} 0 & \cdots & 0 \end{matrix} & 1
  \end{array}\right]
$$

<details>
<summary>Proof</summary>

In general, we have

$$
\begin{equation}
\begin{split}
  \hat{U}\hat{T}_{\ket{x}\ket{y}} (\hat{V}) =& \left(\sum_{a,b=0}^N \mathbf{U}_{ab} \ket{a}\bra{b} \right) \\
  & \left(\sum_{\substack{z=0 \\ z\neq x,y }}^N \ket{z}\bra{z} + v_{00} \ket{x} \bra{x} + v_{01} \ket{x} \bra{y} + v_{10} \ket{y}\bra{x} + v_{11} \ket{y}\bra{y} \right) \\
  =& \sum_{\substack{z=0 \\ z\neq x,y }}^N \mathbf{U}_{az} \ket{a}\bra{z} \\
  &+ \sum_{a=0}^N \left(\mathbf{U}_{ax} v_{00} \ket{a}\bra{x} + \mathbf{U}_{ax} v_{01} \ket{a}\bra{y} + \mathbf{U}_{ay} v_{10} \ket{a}\bra{x} + \mathbf{U}_{ay} v_{11} \ket{a}\bra{y} \right)
\end{split}
\tag{\label{equation-29}}
\end{equation}
$$

We now consider $x = N - j$ and $y = N$ and define

$$
\begin{align*}
  \hat{\tilde{U}}^{(0)} :=& \hat{U} \\
  \hat{\tilde{U}}^{(j)} :=& \hat{\tilde{U}}^{(j-1)} \hat{T}_{\ket{N-j}\ket{N}} \left(\hat{V}^{(N - j)} \right)
\end{align*}
$$

where we shall make a suitable choice for the operators $\hat{V}^{(N-j)}$. For this we consider the $N$th row of the matrix $\hat{\tilde{U}}^{(j)}$ for which it follows from $\eqref{equation-29}$ that

$$
\begin{align*}
  \hat{\tilde{U}}^{(j)} =& \hat{\tilde{U}}^{(j-1)} \hat{T}_{\ket{N-j}\ket{N}} \left(\hat{V}^{(N - j)} \right) \\
  =& \sum_{a=0}^N \sum_{\substack{b=0 \\ b\neq N -j }}^{N-1} \tilde{\mathbf{U}}_{ab}^{(j - 1)} \ket{a} \bra{b} \\
  &+ \sum_{a=0}^N \left( \tilde{\mathbf{U}}_{a,N - j}^{(j - 1)} v_{00}^{(N - j)} + \tilde{\mathbf{U}}_{aN}^{(j - 1)} v_{10}^{(N - j)} \right) \ket{a} \bra{N - j} \\
  &+ \sum_{a=0}^N \left(\tilde{\mathbf{U}}_{a,N-j}^{(j - 1)} v_{01}^{(N - j)} + \tilde{\mathbf{U}}_{aN}^{(j-1)} v_{11}^{(N - j)} \right) \ket{a} \bra{N}
\end{align*}
$$

Thus, the matrix elements of $\tilde{\mathbf{U}}^{(j)}$ are

$$
\begin{equation}
\begin{split}
  \tilde{\mathbf{U}}_{Nb}^{(j)} =& \tilde{\mathbf{U}}_{Nb}^{(j-1)}, \; b\notin\set{N - j, N} \\
  \tilde{\mathbf{U}}_{N, N-j}^{(j)} =& \tilde{\mathbf{U}}_{N,N-j}^{(j-1)} v_{00}^{(N - j)} + \tilde{\mathbf{U}}_{NN}^{(j - 1)} v_{10}^{(N - j)} \\
  \tilde{\mathbf{U}}_{NN}^{(j)} =& \tilde{\mathbf{U}}_{N,N-j}^{(j-1)} v_{01}^{(N-j)} + \tilde{\mathbf{U}}_{NN}^{(j-1)} v_{11}^{(N-j)}
\end{split}
\tag{\label{equation-30}}
\end{equation}
$$

To choose $\mathbf{V}^{(N-j)}$ suitably, we distinguish two cases
1. If $\tilde{\mathbf{U}}_{N,N-j}^{(j-1)}$ and $\tilde{\mathbf{U}}_{NN}^{(j-1)}$ both vanish, then due to $\eqref{equation-30}$ also $\tilde{\mathbf{U}}_{N,N-j}^{(j)}$ and $\tilde{\mathbf{U}}_{NN}^{(j)}$ vanish, and we choose $\mathbf{V}^{(N-j)} = \mathbf{I}_2$.
2. Otherwise, we set
$$
  \mathbf{V}^{(N - j)} = \frac{1}{\sqrt{\left|\tilde{\mathbf{U}}_{N,N-j}^{(j-1)} \right|^2 + \left|\tilde{\mathbf{U}}_{NN}^{(j-1)} \right|^2}} \begin{bmatrix} \tilde{\mathbf{U}}_{NN}^{(j - 1)} & \left(\tilde{\mathbf{U}}_{N,N-j}^{(j-1)}\right)^* \\ -\tilde{\mathbf{U}}_{N,N-j}^{(j - 1)} & \left(\tilde{\mathbf{U}}_{NN}^{(j-1)}\right)^* \end{bmatrix}
$$

Then $\mathbf{V}$ is unitary, and one has

$$
\begin{equation}
\begin{split}
  \tilde{\mathbf{U}}_{N,N-j}^{(j)} =& \tilde{\mathbf{U}}_{N,N-j}^{(j-1)} v_{00}^{(N-j)} + \tilde{\mathbf{U}}_{NN}^{(j-1)} v_{10}^{(N-j)} = 0 \\
  \tilde{\mathbf{U}}_{NN}^{(j)} =& \tilde{\mathbf{U}}_{N,N-j}^{(j-1)} v_{01}^{(N-j)} + \tilde{\mathbf{U}}_{NN}^{(j-1)} v_{11}^{(N - j)} = \sqrt{\left|\tilde{\mathbf{U}}_{N,N-j}^{(j-1)} \right|^2 + \left|\tilde{\mathbf{U}}_{NN}^{(j-1)} \right|^2}
\end{split}
\tag{\label{equation-31}}
\end{equation}
$$

Starting with $j = 1$, in either case we thus obtain successively

$$
\begin{equation}
  \tilde{\mathbf{U}}_{N,N-j}^{(j)} = 0,\quad j\in\set{1,\dots,N}
\tag{\label{equation-32}}
\end{equation}
$$

For $b\in\set{0,\dots,N-j-1}$ we have, from $\eqref{equation-29}$ and $\eqref{equation-30}$, that $\tilde{\mathbf{U}}_{Nb}^{(j)} = \mathbf{U}_{Nb}$. With this and $\eqref{equation-31}$ it follows that

$$
  \tilde{\mathbf{U}}_{NN}^{(j)} = \sqrt{\sum_{l=0}^j \left| \tilde{\mathbf{U}}_{N,N-l}^{(0)} \right|^2} = \sqrt{\sum_{l=0}^j \left| \mathbf{U}_{N,N-l} \right|^2}
$$

Since $\mathbf{U}$ is assumed to be unitary, the square of the absolute values in each row have to add up to one. Thus, we finally obtain

$$
\begin{equation}
  \tilde{\mathbf{U}}_{NN}^{(j)} = \sqrt{\sum_{l=0}^j \left| \mathbf{U}_{N,N-l} \right|^2} = 1
\tag{\label{equation-33}}
\end{equation}
$$

By $\eqref{equation-31}$, $\eqref{equation-32}$ and $\eqref{equation-33}$ it follows that $\hat{\tilde{U}}^{(N)}$ has matrix representation

$$
  \mathbf{U}^{(N)} = \left[\begin{array}{cc} 
    A^{(N)} & \begin{matrix} b_0 \\ \vdots \\ b_{N-1} \end{matrix} \\
    \begin{matrix} 0 & \cdots & 0 \end{matrix} & 1
  \end{array}\right]
$$

Since $\hat{\tilde{U}}^{(N)}$ as a product of unitary operators has to be unitary, it follows that

$$
  \hat{\tilde{U}}^{(N)} (\hat{\tilde{U}}^{(N)})^\dagger = \hat{I}_2^{\otimes n}
$$

This implies $b_0 = \cdots = b_{N-1} = 0$, and thus that $\mathbf{A}^{(N)}$ is a $2^n - 1 = N$-dimensional unitary matrix
. Consequently, the matrix representation of $\hat{U}^{(N)} = \hat{\tilde{U}}^{(N)}$ is of the claimed form. 
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Let $n\in\N_+$ and $\hat{U}$ be a unitary operator on ${}^\P \mathcal{H}^{\otimes n}$. Then there exist $2^{n-1} (2^n - 1)$ unitary operators $\hat{W}^{(k, k-j)}$ on ${}^\P \mathcal{H}$ with $k\in\set{1,\dots,2^n - 1}$ and $j\in\set{1,\dots,k}$ such that

$$
  \hat{U} = \prod_{k=1}^{2^n - 1} \left(\prod_{j=1}^k \hat{T}_{\ket{j-1}\ket{k}} \left(\hat{W}^{(k, k-j)} \right) \right)
$$

and thus

$$
  \hat{U} \in \mathcal{F}[\hat{T}_{\ket{x}\ket{y}}(\hat{V})]
$$

for a suitably chosen $\hat{V}$.

<details>
<summary>Proof</summary>

Let $N = 2^n - 1$. From Lemma $\ref{lemma-3}$, we know that there exis unitary operators $V^{(N, j)} \in\mathcal{U}({}^\P \mathcal{H})$ such that

$$
  \hat{U}^{(N)} = \hat{U} \prod_{j=N}^1 \hat{T}_{\ket{j-1}\ket{N}} \left(\hat{V}^{(N, j-1)} \right)
$$

has the matrix representation

$$
  \mathbf{U}^{(N)} = \left[\begin{array}{cc} 
    \mathbf{A}^{(N)} & \begin{matrix} 0 \\ \vdots \\ 0 \end{matrix} \\
    \begin{matrix} 0 & \cdots & 0 \end{matrix} & 1
  \end{array}\right]
$$

We can now multiply $\hat{U}^{(N)}$ with $\hat{T}_{\ket{N-2}\ket{N-1}} \left(\hat{V}^{(N-1,N-2)} \right) \cdots \hat{T}_{\ket{0}\ket{N-1}} \left(\hat{V}^{(N-1,0)}\right)$ from the right and choose the $\hat{V}^{(N-1,N-2)},\dots,V^{(N-1,0)}$ according to the construction in the proof of Lemma $\ref{lemma-3}$ such that

$$
  \hat{U}^{(N-1)} = \hat{U} \prod_{j=N}^1 \hat{T}_{\ket{j-1}\ket{N-1}} \left(\hat{V}^{(N-1, j-1)} \right)
$$

has the matrix representation

$$
\begin{equation}
  \mathbf{U}^{(N)} = \left[\begin{array}{ccc} 
    \mathbf{A}^{(N-1)} & \begin{matrix} 0 \\ \vdots \\ 0 \end{matrix} & \begin{matrix} 0 \\ \vdots \\ 0 \end{matrix} \\
    \begin{matrix} 0 & \cdots & 0 \end{matrix} & 1 & 0 \\
    \begin{matrix} 0 & \cdots & 0 \end{matrix} & 0 & 1
  \end{array}\right]
\tag{\label{equation-34}}
\end{equation}
$$

where $\mathbf{A}^{(N-1)}$ is a unitary $(N-1) \times (N-1)$ matrix. In arriving at $\eqref{equation-34}$ we have also used the fact that the multiplication of $\mathbf{T}_{\ket{l}\ket{N-1}}$ with $\mathbf{U}^{(N)}$ leaves out the last row and column of $\mathbf{U}^{(N)}$. We continue these multiplications and, starting with $l = N$ and counting down unit $l = 2$, successively build the sequence of operators

$$
  \hat{U}^{(l)} = \hat{U}^{l + 1} \prod_{j=l}^1 \hat{T}_{\ket{j-1}\ket{l}} \left(\hat{V}^{(l,j-1)}\right)
$$

which have the matrix representations

$$
\mathbf{U}^{(l)} = \left[\begin{array}{cccc} 
    \mathbf{A}^{(l)} & \begin{matrix} 0 \\ \vdots \end{matrix} & \begin{matrix} \cdots \\ \end{matrix} & \begin{matrix} 0 \\ \vdots \end{matrix} \\
    \begin{matrix} 0 & \cdots & 0 \end{matrix} & 1 & & \\
    \begin{matrix} \vdots & & \vdots \end{matrix} & & \ddots & \\
    \begin{matrix} 0 & \cdots &  \end{matrix} & & 0 & 1
  \end{array}\right]
$$

The $\mathbf{A}^{(l)}$ are always unitary $l\times l$-matrices. Consequently, $\mathbf{A}^{(2)}$ in $\mathbf{U}^{(2)}$ is a $2\times 2$ matrix. In order to calculate $\mathbf{U}^{(l)}$ we thus set $\mathbf{V}^{(1,0)} = (\mathbf{A}^{(2)})^\dagger$. Then we have

$$
\begin{align*}
  \hat{I}_2^{\otimes n} =& \hat{U}^{(1)} = \hat{U}^{(2)} \hat{T}_{\ket{0}\ket{1}} \left(\hat{V}^{(1,0)}\right) = \cdots \\
  =& \hat{U} \prod_{l=N}^1 \left(\prod_{j=l}^1 \hat{T}_{\ket{j-1}\ket{l}} \left(\hat{V}^{(l,j-1)} \right) \right)
\end{align*}
$$

Solving for $\hat{U}$ yields

$$
\begin{align*}
  \hat{U} =& \left[\prod_{l=N}^1 \left(\prod_{j=l}^1 \hat{T}_{\ket{j-1}\ket{l}} \left(\hat{V}^{(l,j-1)} \right) \right)\right]^{-1} \\
  =& \left[\prod_{l=N}^1 \left(\prod_{j=l}^1 \hat{T}_{\ket{j-1}\ket{l}} \left(\hat{V}^{(l,j-1)} \right) \right)\right]^\dagger \\
  =& \prod_{l=N}^1 \left(\prod_{j=l}^1 \hat{T}_{\ket{j-1}\ket{l}} \left(\hat{V}^{(l,j-1)\dagger} \right) \right)
\end{align*}
$$

which is the claimed representation. The number of factors is

$$
  n_F = \sum_{l=1}^N l = \frac{(N + 1)N}{2} = \frac{2^n (2^n - 1)}{2} = 2^{n-1} (2^n - 1)
$$
</details>
</MathBox>

<MathBox title='Gray-coded transition' boxType='definition'>
Let $n\in\N$ and $x,y\in\N_0$ with $0\leq x < y < 2^n$. Moreover, let $\ket{x}$ and $\ket{y}$ be the corresponding vectors of the computational basis of ${}^\P \mathcal{H}^{\otimes n}$. A *Gray-coded* transition from $\ket{x}$ to $\ket{y}$ is defined as a finite sequence of vectors $\ket{g^0},\dots,\ket{g^{K+1}}$ of the computational basis having the following properties:
1.
$$
  \ket{g^0} = \ket{x},\quad \ket{g^{K+1}} = \ket{y}
$$
2. For all $l\in\set{1,\dots,K+1}$ there exist $n_{a^l}, n_{b^l}\in\N_0$ with $n_{a^l} + n_{b^l} + 1 = n$ and $n_{b^l} \neq n_{b^j}$ for all $l \neq j$ such that

$$
  \ket{g^l} = \hat{I}_2^{\otimes n_{a^l}} \otimes\hat{X}\otimes\hat{I}_2^{n_{b^l}} \ket{g^{l-1}}
$$

and

$$
\begin{equation}
  (g^K)_{n_{b^{K+1}}} = 0,\quad (g^{K+1})_{n_{b^{K+1}}} = 1
\tag{\label{equation-35}}
\end{equation}
$$

in terms of $\ket{g^{l-1}}$ we also define for $l\in\set{1,\dots,K+1}$

$$
\begin{equation}
\begin{split}
  \ket{a^l} :=& \ket{g_{n-1}^{l-1} \dots g_{n_{b^l} + 1}^{l - 1}} \in {}^\P \mathcal{H}^{\otimes n_{a^l}} \\
  \ket{b^l} :=& \ket{g_{n_{b^l}-1}^{l-1} \dots g_0^{l - 1}} \in {}^\P \mathcal{H}^{\otimes n_{b^l}}
\end{split}
\tag{\label{equation-36}}
\end{equation}
$$
</MathBox>

In a Gray-coded transition, two consecutive elements $\ket{g^{l-1}}$ and $\ket{g^l}$ only differ in the qubit in the factor space ${}^\P \mathcal{H}_{n_{b^l}}$ of ${}^\P \mathcal{H}^{\otimes n}$

$$
\begin{align*}
  \ket{g^l} =& \hat{I}_2^{\otimes n_{a^l}} \otimes\hat{X}\otimes \hat{I}^{\otimes n_{b^l}} \ket{g^{l-1}} \\
  =& \Ket{(g^{l-1})_{n-1} \dots (g^{l-1})_{n_{b^l} + 1} \lnot (g^{l-1})_{n_{b^l}} (g^{l-1})_{n_{b^l} - 1} \dots (g^{l-1})_0}
\end{align*}
$$

Furthermore, since $n_{b^l} \neq n_{b^j}$ for all $l\neq j$ it follows that $\ket{g^{l + k}} \neq \ket{g^l}$ if $k \geq 1$.

Gray-coded transitions are not unique. Between two vectors $\ket{x}$ and $\ket{y}$ ther can be several such transitions.

<MathBox title='Existence of Gray code transitions' boxType='proposition'>
Let $n\in\N_+$ and $x,y\in\N_0$ with $0 \leq x < y < 2^n$. Then there exists a Gray-coded transition from $\ket{x}$ to $\ket{y}$.

<details>
<summary>Proof</summary>

Let

$$
  x = \sum_{j=0}^{2^n - 1} x_j 2^j < \sum_{j=0}^{2^n - 1} y_j 2^j = y
$$

with $x_j, y_j \in\set{0,1}$ and

$$
\begin{align*}
  L_{01} :=& \Set{j\in\set{0,\dots,n-1}| x_j = 0,\; y_j = 1} = \set{h_1,\dots,h_{|L_{01}|}} \\
  L_{10} :=& \Set{j\in\set{0,\dots,n-1}| x_j = 1,\; y_j = 0} = \set{k_1,\dots,k_{|L_{10}|}}
\end{align*}
$$

The set $L_{01}$ cannot be empty since otherwise $x < y$ would not hold. Set $g^0 = x$ and for $l\in\set{1,\dots,|L_{10}|}$

$$
  \ket{g^l} = \hat{I}_2^{\otimes n - k_l} \otimes\hat{X}\otimes\hat{I}_2^{\otimes k_l - 1} \ket{g^{l-1}}
$$

Then set for $l\in\set{1,\dots,|L_{01}|}$

$$
  \ket{g^{l+ |L_{10}|}} = \hat{I}^{\otimes n - h_l} \otimes \hat{X} \otimes \hat{I}_2^{\otimes h_l - 1} \ket{g^{l + |L_{10}| - 1}}
$$

The sequence $\ket{g^l}$ begins with $\ket{x}$ and is constructed such that each consecutive element differs from the previous one by a change in a single qubit. This process continues until all qubits in which $\ket{x}$ differs from $\ket{y}$ have been adjusted to match $\ket{y}$. As a result, the final element in the sequence is $\ket{y}$. Consequently, $\ket{g^l}$ form a Gray-coded transition from $\ket{x}$ to $\ket{y}$.
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Let $n\in\N_+$ and $x,y\in\N_0$ with $0 \leq x < y < 2^n$, and suppose $\ket{x}$ and $\ket{y}$ are the corresponding vectors of the computational basis in ${}^\P \mathcal{H}^{\otimes n}$. Moreover, let $\hat{V}$ be a unitary operator on ${}^\P \mathcal{H}$. Then every Gray-coded transition $\ket{g^l}$ with $l\in\set{0,\dots,K+1}$ from $\ket{x}$ to $\ket{y}$ satisfies

1.
$$
  \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) = \sum_{\substack{z=0 \\ z\neq g^{l-1}, g^l }} \ket{z}\bra{z} + \ket{g^{l-1}}\bra{g^l} + \ket{g^l} \bra{g^{l-1}}
$$
2. $\hat{T}_{\ket{g^K}\ket{y}} (\hat{V}) = \Lambda_{\ket{b^{K+1}}}^{\ket{a^{K+1}}} (\hat{V})$
3. $\hat{T}_{\ket{g^{l-1}}\ket{y}} (\hat{V}) = \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \hat{T}_{\ket{g^l} \ket{y}} (\hat{V}) \Lambda_{\ket{b^l}}^{\ket{a^l}}$
4.
$$
  \hat{T}_{\ket{x}\ket{y}} (\hat{V}) = \left(\prod_{l=1}^K \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \right) \Lambda_{\ket{b^{K+1}}}^{\ket{a^{K+1}}} (\hat{V}) \left(\prod_{j=K}^l \Lambda_{\ket{b^j}}^{\ket{a^j}} (\hat{X}) \right)
$$

<details>
<summary>Proof</summary>

**(1):** From Definition $\ref{definition-3}$, we have

$$
  \Lambda_{\ket{b}^l}^{\ket{a^l}} (\hat{X}) = \hat{I}_2^{\otimes n_{a^l} + n_{b^l} + 1} + \ket{a^l} \bra{a^l} \otimes (\hat{X} - \hat{I}_2) \otimes \ket{b^l}\bra{b^l}
$$

With $n = n_{a^l} + n_{b^l} + 1$ and

$$
  \hat{X} - \hat{I}_2 = = \ket{0}\bra{1} + \ket{1}\bra{0} - \ket{0}\bra{0} - \ket{1}\bra{1}
$$

we get

$$
\begin{align*}
  \Lambda_{\ket{b}^l}^{\ket{a^l}} (\hat{X}) =& \hat{I}_2^{\otimes n} + \underbrace{\ket{a^l} \bra{a^l} \otimes (\ket{0}\bra{1} + \ket{1}\bra{0}) \otimes \ket{b^l} \bra{b^l}}_{=\ket{g^{l-1}}\bra{g^l} + \ket{g^l}\bra{g^{l-1}}} \\
  & -\underbrace{\ket{a^l}\bra{a^l} \otimes (\ket{0}\bra{0} + \ket{1}\bra{1}) \otimes \ket{b^l} \ket{b^l}}_{=-\ket{g^{l-1}} \ket{g^{l-1}} - \ket{g^l}\bra{g^l}} \\
  =& \sum_{\substack{z=0 \\ z\neq g^{l-1}, g^l }} \ket{z}\bra{z} + \ket{g^{l-1}}\bra{g^l} + \ket{g^l} \bra{g^{l-1}}
\end{align*}
$$

**(2):** From $\eqref{equation-35}$ and $\eqref{equation-36}$ it follows that

$$
\begin{align*}
  \ket{g^K} =& \ket{a^{K+1}} \otimes \ket{0} \otimes \ket{b^{K+1}} \\
  \ket{g^{K+1}} =& \ket{a^{K+1}} \otimes \ket{1} \otimes \ket{b^{K+1}} = \ket{y}
\end{align*}
$$

With Definition $\ref{definition-4}$ we then find

$$
\begin{align*}
  \hat{T}_{\ket{g^K} \ket{y}} =& \hat{I}_2^{\otimes n} + (v_{00} - 1)\ket{g^K} \bra{g^K} + v_{01} \ket{g^K}\bra{y} + v_{10}\ket{y}\bra{g^K} + (v_{11} - 1)\ket{y}\bra{y} \\
  =& \hat{I}_2^{\otimes n} \\
  &+ (v_{00} - 1) \left(\ket{a^{K+1}} \otimes\ket{0} \otimes\ket{b^{K+1}} \right)\left(\bra{a^{K+1}} \otimes\bra{0} \otimes\bra{b^{K+1}} \right) \\
  &+ v_{01} \left(\ket{a^{K+1}} \otimes\ket{0} \otimes\ket{b^{K+1}} \right)\left(\bra{a^{K+1}} \otimes\bra{1} \otimes\bra{b^{K+1}} \right) \\
  &+ v_{10} \left(\ket{a^{K+1}} \otimes\ket{1} \otimes\ket{b^{K+1}} \right)\left(\bra{a^{K+1}} \otimes\bra{0} \otimes\bra{b^{K+1}} \right) \\
  &+ (v_{11} - 1) \left(\ket{a^{K+1}} \otimes\ket{1} \otimes\ket{b^{K+1}} \right)\left(\bra{a^{K+1}} \otimes\bra{1} \otimes\bra{b^{K+1}} \right) \\
  =& \hat{I}_2^{\otimes n} \\
  &+ (v_{00} - 1) \ket{a^{K+1}} \bra{a^{K+1}} \otimes \ket{0}\bra{0} \otimes \ket{b^{K+1}}\bra{b^{K+1}} \\
  &+ v_{01} \ket{a^{K+1}} \bra{a^{K+1}} \otimes \ket{0}\bra{1} \otimes \ket{b^{K+1}}\bra{b^{K+1}} \\
  &+ v_{10} \ket{a^{K+1}} \bra{a^{K+1}} \otimes \ket{1}\bra{0} \otimes \ket{b^{K+1}}\bra{b^{K+1}} \\
  &+ (v_{11} - 1) \ket{a^{K+1}} \bra{a^{K+1}} \otimes \ket{1}\bra{1} \otimes \ket{b^{K+1}}\bra{b^{K+1}} \\
  =& \hat{I}_2^{\otimes n} \\
  &+ \ket{a^{K+1}}\bra{a^{K+1}} \otimes \big[ (v_{00} - 1) \ket{0}\bra{0} + v_{01} \ket{0}\bra{0} \\
  & \hphantom{+\ket{a^{K+1}}\bra{a^{K+1}} \otimes} + v_{10} \ket{1}\bra{0} + (v_{11} - 1) \otimes \ket{b^{K+1}}\bra{b^{K+1}} \big] \\
  =& \hat{I}_2^{\otimes b} + \ket{a^{K+1}}\bra{a^{K+1}} \otimes (\hat{V} - \hat{I}_2) \otimes \ket{b^{K+1}}\bra{b^{K+1}} \\
  =& \Lambda_{\ket{b^{K+1}}}^{\ket{a^{K+1}}} (\hat{V})
\end{align*}
$$

**(3):** From **(1)** and Definition $\ref{definition-4}$ we have

$$
\begin{align*}
  &\hat{T}_{\ket{g^l} \ket{y}} \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \\
  =& \left(\sum_{\substack{r=0 \\ r\neq g^{l-1}, g^l }} \ket{z}\bra{z} + v_{00} \ket{g^l} \bra{g^l} + v_{01} \ket{g^l} \bra{y} + v_{10} \ket{y} \bra{g^l} + v_{11} \ket{y}\bra{y} \right) \\
  &\times \left(\sum_{\substack{z=0 \\ z\neq g^l, y }} \ket{r}\bra{r} + \ket{g^{l-1}}\bra{g^l} + \ket{g^l} \bra{g^{l-1}} \right) \\
  =& \sum_{\substack{z=0 \\ z\neq g^{l-1}, y }}  \ket{z} \bra{z} + \ket{g^{l-1}} \ket{g^l} \\
  &+ v_{00} \ket{g^l} \bra{g^{l-1}} + v_{01} \ket{g^l} \bra{y} + v_{01} \ket{y} \bra{g^{l-1}} + v_{11} \ket{y}\bra{y}
\end{align*}
$$

and thus

$$
\begin{align*}
  &\Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \hat{T}_{\ket{g^l} \bra{y}} (\hat{V}) \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \\
  =& \left(\sum_{\substack{r=0 \\ r\neq g^{l-1}, g^l }} \ket{r}\bra{r} + \ket{g^{l-1}}\bra{g^l} + \ket{g^l} \bra{g^{l-1}} \right) \\
  &\times \left(\sum_{\substack{z=0 \\ z\neq g^{l-1}, y }}  \ket{z} \bra{z} + \ket{g^{l-1}} \ket{g^l} \right. \\
  &+ \left. v_{00} \ket{g^l} \bra{g^{l-1}} + v_{01} \ket{g^l} \bra{y} + v_{01} \ket{y} \bra{g^{l-1}} + v_{11} \ket{y}\bra{y} \right) \\
  =& \sum_{\substack{z=0 \\ z\neq g^{l-1}, y }} \ket{z}\bra{z} + v_{00} \ket{g^{l-1}} \bra{g^{l-1}} + v_{01} \ket{g^{l-1}}\bra{y} + v_{10} \ket{y}\bra{g^{l-1}} + v_{11} \ket{y}\bra{y} \\
  =& \hat{T}_{\ket{g^{l-1}}\ket{y}} (\hat{V}) 
\end{align*}
$$

**(4):** From **(2)** and **(3)** we have

$$
\begin{align*}
  \left(\prod_{l=1}^K \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \right) \Lambda_{\ket{b^{K+1}}}^{\ket{a^{K+1}}} (\hat{V}) \left(\prod_{j=K}^l \Lambda_{\ket{b^j}}^{\ket{a^j}} (\hat{X}) \right) =&  \left(\prod_{l=1}^K \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \right) \hat{T}_{\ket{g^K}\ket{y}} (\hat{V}) \left(\prod_{j=K}^l \Lambda_{\ket{b^j}}^{\ket{a^j}} (\hat{X}) \right) \\
  =& \left(\prod_{l=1}^{K-1} \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \right) \hat{T}_{\ket{g^{K-1}}\ket{y}} (\hat{V}) \left(\prod_{j={K-1}}^l \Lambda_{\ket{b^j}}^{\ket{a^j}} (\hat{X}) \right) \\
  \vdots& \\
  =& \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \hat{T}_{\ket{g^l}\ket{y}} (\hat{V}) \Lambda_{\ket{b^l}}^{\ket{a^l}} (\hat{X}) \\
  =& \hat{T}_{\ket{g^0} \ket{y}} (\hat{V}) = \hat{T}_{\ket{x}\ket{y}} (\hat{V})
\end{align*}
$$

where in the last step we used that $\ket{x} = \ket{g^0}$.
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
The set of quantum gates $G = \set{\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})}$ is universal, that is, for any $n\in\N_+$ and $\hat{U}\in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})$

$$
  \hat{U} \in\mathcal{F}[\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]
$$

meaning that any quantum gate $\hat{U}\in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})$ can be built with elements from $G$.

<details>
<summary>Proof</summary>

We apply the following previous results

$$
\begin{align*}
  \hat{U} \in& \mathcal{F}[\hat{T}_{\ket{x}\ket{y}} (\hat(V))] \\
  \hat{T}_{\ket{x}\ket{y}} (\hat{V}) \in& \mathcal{F}[\Lambda_{\ket{b}}^{\ket{a}} (\hat{V})] \\
  \Lambda_{\ket{b}}^{\ket{a}} (\hat{V}) \in& \mathcal{F}[\hat{X}, \Lambda_{n_b}^{n_a} (\hat{V})] \\
  \Lambda_{n_b}^{n_a} (\hat{V}) \in& \mathcal{F}[\Lambda_1 (\hat{X}), \Lambda^1 (\hat{X}), \Lambda^{n_a + n_b} (\hat{V})] \\
  \hat{X},\hat{V},\Lambda_1 (\hat{V}), \Lambda^m (\hat{V}) \in& \mathcal{F}[\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]
\end{align*}
$$

yielding

$$
\begin{align*}
  \hat{U} \in& \mathcal{F}[\hat{T}_{\ket{x}\ket{y}} (\hat(V))] \\
  \in& \mathcal{F}\left[\mathcal{F}[\Lambda_{\ket{b}}^{\ket{a}} (\hat{V})]\right] \\
  \vdots& \\
  \in& \mathcal{F}\left[\mathcal{F}[\mathcal{F}[\mathcal{F}[\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]]] \right] \\
  \in& \mathcal{F}[\hat{M}, \hat{D}_{\unitvec{y}}, \hat{D}_{\unitvec{z}}, \Lambda^1 (\hat{X})]
\end{align*}
$$
</details>
</MathBox>

# Quantum circuits

Quantum circuits are composed of quantum gates arranged to perform specific transformations on an input/output register $\mathcal{H}^\text{I/O} = {}^\P \mathcal{H}^{\otimes n}$. The following three types of circuits are commonly employed:
- **Plain circuits:** These are simple compositions of quatum gates acting solely on the input/output register.
- **Circuits with ancillas:** In this type, the input/output register is first extended by adding an auxiliary quantum system, called an *ancilla*. At the end the ancilla is discarded and only the original system is processed further. Unlike in classical circuits, any quantum entanglement between the ancilla and the main system has to be disentangled prior to discarding the ancilla, to ensure the remaining system remains in a valid quantum state.
- **Circuits with classical in/output and/or measurements:** These circuits involve classical data, either as input or output. The quantum system may be manipulated conditionally on classical input, subjected to measurements, and may produce partly classical output. In general, such operations are irreversible and may fundamentally alter the quantum state of the system.

<MathBox title='Plain quantum circuit' boxType='definition' tag='definition-5'>
Let $n, L\in\N$ and $\hat{U}_1,\dots,\hat{U}_L \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})$ be a set of quantum $n$-gates as given in Definition $\ref{definition-2}$. We call

$$
  \hat{U} = \hat{U}_L \cdots \hat{U}_1 \in\mathcal{U}({}^\P \mathcal{H}^{\otimes n})
$$

a plain quantum circuit with depth $L$ relative to the gate set $\set{U_i}_{i=1}^L$. When acting a system in state $\rho\in D(\mathcal{H})$, then plain circuit $\hat{U}$ transforms into it to a new state $\hat{U}\rho\hat{U}^\dagger$.
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-6'>
Let $\mathcal{H}^\text{I/O}$ and $\mathcal{H}^W$ be Hilbert spaces and let $\ket{\omega_i}, \ket{\omega_f} \in\mathcal{H}^W$ be such that $\norm{\omega_i} = 1 = \norm{\omega_f}$. Moreover, let $\hat{U}'\in\mathcal{U}(\mathcal{H}^\text{I/O} \otimes\mathcal{H}^W)$ be such that for all $\ket{\Psi}\in\mathcal{H}^\text{I/O}$

$$
\begin{equation*}
  \hat{U}'\ket{\Psi\otimes\omega_i} = (\hat{U}\ket{\Psi})\otimes\ket{\omega_f}
\tag{\label{equation-38}}
\end{equation*}
$$

and let $\rho_{\omega_i} = \ket{\omega_i}\bra{\omega_i}$ be the density operator of the pure state $\ket{\omega_i}\in\mathcal{H}^W$. Then $\hat{U}\in\mathcal{U}(\mathcal{H}^\text{I/O})$ and we have for any density operator $\rho\in D(\mathcal{H}^{I/O})$ that

$$
\begin{equation*}
  \rho\otimes\rho_{\omega_i} \in D(\mathcal{H}^\text{I/O} \otimes\mathcal{H}^W)
\tag{\label{equation-37}}
\end{equation*}
$$

as well as

$$
  \operatorname{tr}^W (\hat{U}' (\rho\otimes\rho_{\omega_i})\hat{U}'^\dagger) = \hat{U}\rho\hat{U}^\dagger
$$

that is, $\hat{U}$ is unitary and in a state $\hat{U}' (\rho\otimes\rho_{\omega_i}) \hat{U}'^\dagger$ of the composite system, the sub-system I/O is described by the state $\hat{U}\rho\hat{U}^\dagger$.

<details>
<summary>Proof</summary>

We show the unitarity of $\hat{U}$ first. Since $\ket{\omega_i}$ and $\ket{\omega_f}$ are normalized to $1$, on has for arbitrary $\ket{\Psi}\in\mathcal{H}^\text{I/O}$

$$
\begin{align*}
  \norm{\hat{U}\Psi}^2 =& \braket{\hat{U}\Psi|\hat{U}\Psi} = \ket{\hat{U}\Psi|\hat{U}\Psi} \underbrace{\braket{\omega_f|\omega_f}}_{=1} \\
  =& \braket{(\hat{U}\Psi) \otimes\omega_f | (\hat{U}\Psi) \otimes\omega_f} \\
  =& \braket{\hat{U}\ket{\Psi\otimes\omega_i}|\hat{U}|\ket{\Psi\otimes\omega_i}} \\
  =& \Norm{\hat{U}\ket{\Psi\otimes\omega_i}}^2 = \norm{\Psi\otimes\omega_i}^2 \\
  =& \norm{\Psi}^2 \underbrace{\omega_i}_{=1} \\
  =& \norm{\Psi}^2 
\end{align*}
$$

Hence, for all $\ket{\Psi}\in\mathcal{H}^\text{I/O}$ then $\norm{\hat{U}\Psi} = \norm{\Psi}$ holds, implying that $\hat{U}\in\mathcal{U}(\mathcal{H}^\text{I/O})$ is unitary.

Let now $\rho\in D(\mathcal{H}^{I/O})$ and $\rho_{\omega_i} = \bra{\omega_i}\ket{\omega_i} \in D(\mathcal{H}^W)$. Then $\eqref{equation-37}$ follows by properties of the density operator. Moreover, we know that there exist $p_j \in[0,1]$ and an orthonormal basis $\ket{\Psi_j}$ for $\mathcal{H}^\text{I/O}$ such that

$$
  \rho = \sum_j p_j \bra{\Psi_j}\ket{\Psi_j}
$$

Consequently, we have

$$
\begin{align*}
  \hat{U}' (\rho\otimes\rho_{\omega_i})\hat{U}'^\dagger =& \hat{U}'\left(\sum_j p_j \ket{\Psi_j}\bra{\Psi_j} \otimes \bra{\omega_i}\ket{\omega_i} \right)\hat{U}'^\dagger \\
  =& \sum_j p_j \hat{U}' (\ket{\Psi_j}\bra{\Psi_j} \otimes\ket{\omega_i}\bra{\omega_i}) \hat{U}'^\dagger \\
  =& \sum_j p_j \hat{U}' \ket{\Psi_j \otimes\omega_i} \bra{\Psi_j \otimes\omega_i} \hat{U}^\dagger  \tag{\label{equation-39}}
\end{align*}
$$

Using

$$
\begin{align*}
  \bra{\Psi_j \otimes\omega_i}\hat{U}'^\dagger =& \bra{\hat{U}' (\Psi_j \otimes\omega_i)} = \bra{(\hat{U}' \Psi_j)\otimes\omega_j} \\
  =& \bra{\hat{U}\Psi_j} \otimes\bra{\omega_f} = \bra{\Psi_j}\hat{U}^\dagger \otimes\bra{\omega_f}
\end{align*}
$$

and $\eqref{equation-38}$ in $\eqref{equation-39}$ we obtain

$$
\begin{align*}
  \hat{U}' (\rho\otimes\rho_{\omega_i})\hat{U}'^\dagger =& \sum_j p_j (\hat{U}\ket{\Psi_j} \otimes\ket{\omega_f})(\bra{\Psi_j} \hat{U}^\dagger \otimes\bra{\omega_f}) \\
  =& \sum_j p_j \hat{U}\ket{\Psi_j}\bra{\Psi_j}\hat{U}^\dagger \otimes\ket{\omega_f} \bra{\omega_f} \\
  =& \hat{U}\left(\sum_j p_j \ket{\Psi_j}\bra{\Psi_j} \right)\hat{U}^\dagger \otimes\ket{\omega_f}\bra{\omega_f} \\
  =& \hat{U}\rho\hat{U}^\dagger \otimes\ket{\omega_f}\bra{\omega_f}
\end{align*}
$$

such that finally

$$
\begin{align*}
  \operatorname{tr}^W \left(\hat{U}'(\rho\otimes\rho_{\omega_i})\hat{U}'^\dagger \right) =& \operatorname{tr}^W (\hat{U}\rho\hat{U}^\dagger \otimes\ket{\omega_f} \bra{\omega_f}) \\
  =& \operatorname{tr}(\ket{\omega_f}\bra{\omega_f}) \hat{U}\rho\hat{U}^\dagger = \hat{U}\rho\hat{U}^\dagger
\end{align*}
$$

where in the last equation we have used that

$$
\begin{align*}
  \operatorname{tr}(\ket{\omega_f}\bra{\omega_f}) =& \sum_j \braket{e_j|\omega_f} \braket{\omega_f|e_j} = \sum_j |\braket{e_j|\omega_f}|^2 \\
  =& \norm{\omega_f}^2 = 1
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Quantum circuit with ancilla' boxType='definition' tag='definition-6'>
Let $\mathcal{H}^\text{I/O} = {}^\P \mathcal{H}^{\otimes n}$ and $\mathcal{H}^W = {}^\P \mathcal{H}^{\otimes w}$. A circuit $\hat{U}$ on $\mathcal{H}^\text{I/O}$ is a circuit implemented with ancilla $\ket{\omega_i}$ in an auxilliary register $\mathcal{H}^W$ if there exists states $\ket{\omega_i}, \ket{\omega_f}\in\mathcal{H}^W$ and a plain circuit $\hat{U}'\in\mathcal{U}({}^\P \mathcal{H}^{\otimes n + w})$ on the composite system $\mathcal{H}^{I/O} \otimes\mathcal{H}^W$ such that for all $\ket{\Psi}\in\mathcal{H}^{I/O}$

$$
\begin{equation*}
  \hat{U}' \ket{\Psi\otimes\omega_i} = (\hat{U}\ket{\Psi}) \otimes\ket{\omega_f}
\tag{\label{equation-41}}
\end{equation*}
$$

The depth of $\hat{U}$ with respect to a given gate set is defined as the depth of the plain circuit $\hat{U}'$ as defined in Definition $\ref{definition-2}$. When acting on a system in the state $\rho\in D(\mathcal{H}^{I/O})$ the circuit transform it to a new state $\hat{U}\rho\hat{U}^\dagger = \operatorname{tr}^W (\hat{U}' (\rho\otimes\rho_{\omega_i}) \hat{U}'^\dagger)$.
</MathBox>

In Defintion $\ref{definition-6}$, the ancilla state $\ket{\omega_i}$ is a fixed initial state and $\ket{\omega_f}$ is a fixed final state of the auxilliary register. While both are often chosen to be $\ket{0}^w$, they need not be identical. In fact, one can always make them coincide through a suitable unitary transformation applied to $\ket{\omega_f}$.

Any plain circuit $\hat{U}\in\mathcal{U}(\mathcal{H}^\text{I/O})$ as defined in Definition $\ref{definition-5}$ can be implemented with an ancilla by simply taking $\hat{U}' = \hat{U}\otimes\hat{I} \in \mathcal{U}(\mathcal{H}^\text{I/O} \otimes\mathcal{H}^W)$. In this sense, circuits with ancillas are a superset of plain ciruits.

Ancilla registers are, as their name suggests, auxilliary subsystems $\mathcal{H}^W$ used to store intermediate information during a computation. This information may be recalled or processed at later stages, but the ancilla is not observed at the end of the computation. Throughout the circuit's execution, the ancilla register may become entangled with the input/output registers during successibe application of intermediate gates. Consequently, any measurement of the ancilla register during this process can disturb the input or output state.

Performing a measurement of an ancillary register can be necessary to reset the to a known initial state. However, to ensure that such operations do not alter the desired output, any entanglement between the ancilla and the input/output registers must be eliminated beforehand. This disentangling must be achieved via appropriate unitary transformations that restore the ancilla to a known final state while preserving the input/output state of the computation.

<LatexFigure width={75} src='/fig/ancilla_circuit.svg' alt=''
  caption='Generic quantum circuit with ancilla'
>
```latex
\documentclass[tikz, border=5pt]{standalone}
\usepackage{quantikz}

\begin{document}
\begin{quantikz}[wire types={q,n,n,n,q,n,n,n,n,n}]
  \lstick{\ket{\psi_{n-1}}} \gategroup[5, style={draw=none, xshift=-1cm}]{\textbf{Input} $\left({}^\P \mathcal{H}^{\otimes n}\right)$} &[2.5cm] \gategroup[10, steps=5, style={inner xsep=2.4cm, inner ysep=0.8cm}]{$\hat{U}$} & \gate[10]{U_1} \gategroup[10, steps=3]{$\hat{U}'$} & & & &[2.5cm] \rstick{\ket{\varphi_{n-1}}} \gategroup[5, style={draw=none, xshift=1.2cm}]{\textbf{Output} $\left({}^\P \mathcal{H}^{\otimes n}\right)$} \\[-0.3cm]
  \lstick{\otimes} &&&&&& \rstick{\otimes} \\[-0.4cm]
  \lstick{\vdots} &&& \ddots &&& \rstick{\vdots} \\[-0.2cm]
  \lstick{\otimes} &&&&&& \rstick{\otimes} \\[-0.3cm]
  \lstick{\ket{\psi_0}} &&&& \gate[2]{U_L} && \rstick{\ket{\varphi_{n-1}}} \\[0.1cm]
  & \lstick{\ket{\omega_i^{(w-1)}}} \gategroup[5, style={draw=none, xshift=-1.1cm}]{\textbf{Ancilla} $\left({}^\P \mathcal{H}^W\right)$} & \setwiretype{q} &&& \rstick{\ket{\omega_f^{(w-1)}}} \gategroup[5, style={draw=none, xshift=1.1cm}]{\textbf{Ancilla} $\left({}^\P \mathcal{H}^W\right)$} & \setwiretype{n} \\[-0.2cm]
  & \lstick{\otimes} &&&& \rstick{\otimes} & \\[-0.4cm]
  & \lstick{\vdots} && \ddots && \rstick{\vdots} & \\[-0.2cm]
  & \lstick{\otimes} &&&& \rstick{\otimes} & \\[-0.2cm]
  & \lstick{\ket{\omega_i^{(0)}}} & \setwiretype{q} &&& \rstick{\ket{\omega_f^{(0)}}} & \setwiretype{n}
\end{quantikz}
\end{document}
```
</LatexFigure>

From the right-hand side of $\eqref{equation-41}$, we observe that the result of applying $\hat{U}'$ decomposes into factors in $\mathcal{H}^\text{I/O}$ and $\mathcal{H}^W$. As shown in the proof of Proposition $\ref{proposition-6}$, this factorization ensures that an initial state $\rho\otimes\rho_{\omega_i}$ in the composite system $\mathcal{H}^\text{I/O} \otimes\mathcal{H}^W$ is then transformed by $\hat{U}'$ into the state $(\hat{U}\rho\hat{U}^\dagger)\otimes\rho_{\omega_f}$. Taking the partial trace of $\mathcal{H}^W$ yields the reduced state $\hat{U}\rho\hat{U}^\dagger$ in $\mathcal{H}^\text{I/O}$. This shows that any measurement or observation on the subsystem $\mathcal{H}^\text{I/O}$ depends only on the transformed state $\hat{U}\rho\hat{U}^\dagger$ and is independent of the final state of the the anicalla register $\mathcal{H}^W$. For this reason, the ancilla register can be safely after the application of $\hat{U}'$ in the implementation of $\hat{U}$.

<MathBox title='' boxType='corollary'>
A circuit $\hat{U}$ that has been implemented with the help of a unitary $\hat{U}$ and initial and final states $\ket{\omega_i}$ and $\ket{\omega_f}$ in the auxilliary register satisfies

$$
\begin{equation*}
  \hat{U}'^\dagger \ket{\Psi\otimes\omega_f} = (\hat{U}^\dagger \ket{\Psi}) \otimes\ket{\omega_i}
\tag{\label{equation-40}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-38}$ and the unitarity of $\hat{U}$ shown in Proposition $\ref{proposition-6}$, it follows that

$$
  \hat{U}'^\dagger (\hat{U}^\dagger \ket{\Psi} \otimes\ket{\omega_i}) = (\hat{U}\hat{U}^\dagger \ket{\Psi}) \otimes\ket{\omega_f} = \ket{\Psi}\otimes\ket{\omega_f}
$$

proving $\eqref{equation-40}$.
</details>
</MathBox>

## Quantum algorithms

<MathBox title='Factor-wise binary addition' boxType='definition'>
Using the binary addition from Definition $\ref{definition-8}$, we define the *factor-wise binary addition* $\boxplus: {}^\P \mathcal{H}^{\otimes m} \otimes {}^\P \mathcal{H}^{\otimes m} \to {}^\P \mathcal{H}^{\otimes m}$ 
for computational basis vectors $\ket{a}, \ket{b} \in {}^\P \mathcal{H}^{\otimes m}$ by

$$
\begin{equation*}
  \ket{a}\otimes\ket{b} \mapsto \ket{a}\boxplus\ket{b} := \bigotimes_{j=m-1}^0 \ket{a_j \overset{2}{\oplus} b_j}
\tag{\label{equation-50}}
\end{equation*}
$$

For convenience, this a written succinctly as

$$
  \ket{a\boxplus b} := \bigotimes_{j=m-1}^0 \ket{a_j \overset{2}{\oplus} b_j}
$$
</MathBox>

Let $f:\N_0 \to \N_0$ and $n,m\in\N_+$. Define the Hilbert spaces $\mathcal{H}^A := {}^\P \mathcal{H}^{\otimes n}$ and $\mathcal{H}^B := {}^\P \mathcal{H}^{\otimes m}$. We say that a quantum circuit described by the operator $\hat{U}_f: \mathcal{H}^A \otimes \mathcal{H}^B \to \mathcal{H}^A \otimes \mathcal{H}^B$ implements the function on $\mathcal{H}^A \otimes \mathcal{H}^B$ if

$$
  \ket{x}\otimes\ket{y} \mapsto \ket{x}\otimes \ket{y \boxplus f(x)}
$$

<details>
<summary>Proof</summary>

To prove the unitarity of $\hat{U}_f$, let

$$
  \ket{\Psi} = \sum_{x=0}^{2^n - 1} \sum_{y=0}^{2^m - 1} \Psi_{xy} \ket{x}\otimes\ket{y} \in\mathcal{H}^A \otimes \mathcal{H}^B
$$

be arbitrary. Then we have

$$
\begin{align*}
  \norm{\hat{U}_f} =& \braket{\hat{U}_f \Psi | \hat{U}_f \Psi} \\
  =& \Braket{\sum_{x,y} \Psi_{xy} \ket{x} \otimes \ket{y\boxplus f(x)}| \sum_{a,b} \Psi_{ab} \ket{a}\otimes\ket{b\boxplus f(a)}} \\
  =& \sum_{x,y,a,b} \Psi_{xy}^* \Psi_{ab} \Braket{\ket{x}\otimes\ket{y\boxplus f(x)}|\ket{a}\otimes\ket{b\boxplus f(a)}} \\
  =& \sum_{x,y,a,b} \Psi_{xy}^* \Psi_{ab} \underbrace{x|a}_{\delta_{xa}} \Braket{y\boxplus f(x)|b\boxplus f(a)} \\
  =& \sum_{x,y,b} \Psi_{xy}^* \Psi_{xb} \Braket{y\boxplus f(x) |b\boxplus f(x)}
\end{align*}
$$

From $\eqref{equation-50}$, we obtain

$$
\begin{align*}
  \braket{y\boxplus f(x)|b\boxplus f(x)} =& \Braket{\bigoplus_{j=n-1}^0 y_{n-1} \overset{2}{\oplus} f(x)_{n-1}| \bigoplus_{j=n-1}^0 b_{n-1} \overset{2}{\oplus} f(x)_{n-1}} \\
  =& \prod_{j=0}^{n-1} \underbrace{\Braket{y_j \overset{2}{\oplus} f(x)_j | b_j \overset{2}{\oplus} f(x)_j}}_{\delta_{y_j b_j}} \\
  =& \delta_{yb}
\end{align*}
$$

Hence, for any $\ket{\Psi}\in\mathcal{H}^A \otimes \mathcal{H}^B$

$$
  \norm{\hat{U}_f \Psi}^2 = \sum_{xy} |\Psi_{xy}|^2 = \norm{\Psi}^2
$$

implying that $\hat{U}_f$ is unitary.
</details>

In general, a quantum algorithm implementing a classical function $f$, consists of the following steps
1. Preparation of the input register
2. Implementation of classical functions $f$ by means of quantum circuits $\hat{U}_f$ on a suitable quantum register
3. Transformation of the quantum register by means of suitable quantum gates or circuits
4. Reading the result in the output register

### Preparation of input and use of auxiliary registers

Quite often the starting point of a quantum algorithm is the state in the input register $\mathcal{H}^\text{I/O} = {}^\P \mathcal{H}^{\otimes n}$ that is an equally weighted linear combination of all vectors of the computational basis

$$
  \ket{\Psi_0} = \frac{1}{2^{n/2}} \sum_{x=0}^{2^n - 1} \ket{x}^n \in \mathcal{H}^\text{I/O}
$$

With the Hadamard transformation $\hat{H}$ such a state $\ket{\Psi_0}$ can be generated by application of the $n$-fold tensor product of $\hat{H}$ on $\ket{0}^n \in\mathcal{H}^{I/O}$

$$
\begin{align*}
  \hat{H}^{\otimes n} \ket{0}^n =& \hat{H}^{\otimes n} \left(\bigotimes_{j=n-1}^0 \ket{0} \right) = \bigotimes_{j=n-1}^0 \hat{H}\ket{0} \\
  =& \bigotimes_{j=n-1}^0 \frac{\ket{0} + \ket{1}}{\sqrt{2}} \\
  =& \frac{1}{2^{n/2}} \left(\bigotimes_{j=n-1}^0 \ket{0} + \ket{1} \right) \\
  =& \frac{1}{2^{n/2}} (\underbrace{\ket{0\dots 0}}_{=\ket{0}^n} + \ket{0\dots 1}_{=\ket{1}^n} +\cdots+ \underbrace{\ket{1\dots 1}}_{=\ket{2^n - 1}^n}) \\
  =& \frac{1}{2^{n/2}} \sum_{x=0}^{2^n - 1} \ket{x}^n
\end{align*}
$$

### Implementation of functions and quantum parallelism

Using Definition $\ref{definition-8}$, we define the operator $\hat{U}_\boxplus : {}^\P \mathcal{H}^{\otimes m} \otimes {}^\P \mathcal{H}^{\otimes m} \to {}^\P \mathcal{H}^{\otimes m} \otimes {}^\P \mathcal{H}^{\otimes m}$ by

$$
\begin{equation*}
  \ket{a}\otimes\ket{b}\mapsto \ket{a}\otimes\ket{a\boxplus b}
\tag{\label{equation-54}}
\end{equation*}
$$

Since the result of bitwise addition satisfies $\sum_{j=0}^{m-1} (a_j \overset{2}{\boxplus} b_j) 2^j < 2^m$, it follows that $\ket{a\boxplus b}$ is also a computational basis vector in ${}^\P \mathcal{H}^{\otimes m}$.

<details>
<summary>Proof</summary>

To show that $\hat{U}_\boxplus$ is unitary, it suffices to prove that it is involutive, i.e. $\hat{U}_\boxplus^2 = \hat{I}$. For any basis vector $\ket{a}\otimes\ket{b} \in {}^\P \mathcal{H}^{\otimes m} \otimes {}^\P \mathcal{H}^{\otimes m}$, we have

$$
\begin{align*}
  \hat{U}_\boxplus (\ket{a}\otimes\ket{b}) =& \hat{U}_\boxplus (\ket{a}\otimes\ket{a\boxplus b}) \\
  =& \ket{a}\otimes \ket{a\boxplus (a\boxplus b)} \\
  =& \ket{a}\otimes \bigotimes_{j=m-1}^0 \ket{a_j \overset{2}{\oplus} \underbrace{(a\boxplus b)_j}_{=a_j \overset{2}{\oplus}b_j}} \\
  =& \ket{a} \otimes \bigotimes_{j=m-1}^0 \ket{\underbrace{a_j \overset{2}{\oplus} (a_j \overset{2}{\oplus} b_j)}_{=b_j}} \\
  =& \ket{a}\otimes\ket{b}
\end{align*}
$$

Hence, $\hat{U}_\boxplus^2 = \hat{I}$ and being both linear and invertible on an orthonormal basis, it follows that it is unitary.
</details>

<LatexFigure width={75} src='/fig/binary_addition_circuit.svg' alt=''
  caption='Quantum circuit to implement the operator $\hat{U}_\boxplus$ for the binary addition of two vectors $\ket{a},\ket{b} \in {}^\P \mathcal{H}^{\otimes m}$'
>
```latex
\documentclass[tikz, border=5pt]{standalone}
\usepackage{quantikz}
\usepackage{amssymb}

\begin{document}
\begin{quantikz}[wire types={q,n,n,n,q,n,q,n,n,n,q}]
  \lstick[5]{$\ket{b}^m$} & \ \ket{b_{m-1}}\ & \gategroup[11, steps=3]{$\hat{U}_\boxplus$} && \gate{X} & \ \ket{a_{m-1} \overset{2}{\oplus}b_{m-1}}\ & \rstick[5]{$\ket{a \boxplus b}^m$} \\[-0.5cm]
  & \otimes &&&& \otimes & \\[-0.5cm]
  & \vdots && \ddots && \vdots & \\[-0.3cm]
  & \otimes &&&& \otimes & \\[-0.4cm]
  & \ket{b_0} & \gate{X} &&& \ket{a_0 \overset{2}{\oplus} b_0} & \\[-0.3cm]
  \lstick{\otimes} &&&&&& \rstick{\otimes} \\[-0.2cm]
  \lstick[5]{$\ket{a}^m$} & \ \ket{a_{m-1}} \ &&& \ctrl{-6} & \ \ket{a_{m-1}}\ & \rstick[5]{$\ket{a}^m$} \\[-0.3cm]
  & \otimes &&&& \otimes & \\[-0.5cm]
  & \vdots && \ddots && \vdots & \\[-0.3cm]
  & \otimes &&&& \otimes & \\[-0.3cm]
  & \ \ket{a_0}\ & \ctrl{-6} &&& \ \ket{a_0}\ &
\end{quantikz}
\end{document}

```
</LatexFigure>

<MathBox title='' boxType='proposition'>
Let $f:\N_0 \to \N_0$ and $n,m\in\N_+$. Define the Hilbert spaces $\mathcal{H}^A := {}^\P \mathcal{H}^{\otimes n}$ and $\mathcal{H}^B := {}^\P \mathcal{H}^{\otimes m}$. Suppose $\hat{A}_f$ and $\hat{B}_f$ are quantum circuits on $\mathcal{H}^A \otimes \mathcal{H}^B$ and $\ket{\omega_i},\ket{\omega_f}\in\mathcal{H}^B$ are distinguished states, such that for any computational basis vector $\ket{x}\in\mathcal{H}^A$ there is a state $\ket{\psi(x)}\in\mathcal{H}^A$ satisfying

$$
\begin{align*}
  \hat{A}_f (\ket{x}\otimes\ket{\omega_i}) =& \ket{\psi(x)} \otimes\ket{f(x)} \\
  \hat{B}_f (\ket{\psi(x)} \otimes \ket{f(x)}) =& \ket{x}\otimes\ket{\omega_f}
\end{align*}
$$

Now define an operator $\hat{U}'_f$ on the extended space $\mathcal{H}^A \otimes \mathcal{H}^B \otimes \mathcal{H}^B$ by

$$
\begin{equation*}
  \hat{U}'_f := (\hat{I}^A \otimes \hat{S}^{B,B}) (\hat{B}_f \otimes \hat{I}^B) (\hat{I}^A \otimes \hat{U}_\boxplus) (\hat{A}_f \otimes \hat{I}^B) (\hat{I}^A \otimes \hat{S}^{B,B})
\tag{\label{equation-51}}
\end{equation*}
$$

where $\hat{S}^{B,B} \mathcal{H}^B \otimes\mathcal{H}^B to \mathcal{H}^B \otimes\mathcal{H}^B$ is the swap operator defined by

$$
  \hat{S}^{B,B} (\ket{b_1}\otimes\ket{b_2}) = \ket{b_2} \otimes\ket{b_1}  
$$

Then $\hat{U}'_f$ acts as follows on computational basis states:

$$
  \hat{U}'_f (\ket{x}\otimes\ket{y}\otimes\ket{\omega_i}) = \ket{x}\otimes\ket{y\boxplus f(x)} \otimes\ket{\omega_f}
$$

Hence, using $\hat{U}'_f$ we can implement the function-dependent transformation $\hat{U}_f : \mathcal{H}^A \otimes \mathcal{H}^B \to \mathcal{H}^A \otimes \mathcal{H}^B$ given by

$$
\begin{equation*}
  \ket{x}\otimes\ket{y} \mapsto \ket{y\boxplus f(x)}
\tag{\label{equation-53}}
\end{equation*}
$$

with the help of an auxiliary register and fixed ancilla states $\ket{\omega_i}$ and $\ket{\omega_f}$.

<details>
<summary>Proof</summary>

From $\eqref{equation-51}$, it follows that

$$
\begin{align*}
  &\hat{U}'_f (\ket{x}\otimes\ket{y}\otimes\ket{\omega_i}) \\
  =& (\hat{I}^A \otimes\hat{S}^{B,B})(\hat{B}_f \otimes\hat{I}^B)(\hat{I}^A \otimes\hat{U}_\boxplus)(\hat{A}_f \otimes\hat{I}^B)(\ket{x}\otimes\ket{\omega_i}\otimes\ket{y}) \\
  =& (\hat{I}^A \otimes\hat{S}^{B,B})(\hat{B}^f \times\hat{I}^B)(\hat{I}^A \otimes\hat{U}_\boxplus)(\ket{\psi(x)}\otimes \ket{f(x)}\otimes\ket{y}) \\
  =& (\hat{I}^A \otimes\hat{S}^{B,B})(\hat{B}^f \otimes\hat{I}^B)(\ket{\psi(x)}\otimes\ket{f(x)}\otimes\ket{y\boxplus f(x)}) \\
  =& (\hat{I}^A \otimes\hat{S}^{B,B}(\ket{x}\otimes\ket{\omega_f}\otimes\ket{y\boxplus f(x)})) \\
  =& \ket{x}\otimes\ket{y\boxplus f(x)} \otimes\ket{\omega_f} \tag{\label{equation-52}}
\end{align*}
$$

The claim $\eqref{equation-53}$ about $\hat{U}_f$ then follows from $\eqref{equation-52}$ and Definition $\ref{definition-6}$. 
</details>
</MathBox>

We extend the definition of $\hat{U}_f$ to arbitrary vectors $\ket{\Phi}\in\mathcal{H}^A \otimes \mathcal{H}^B$ by linearity:

$$
  \hat{U}_f \ket{\Phi} := \sum_{x=0}^{2^n - 1} \sum_{y=0}^{2^m - 1} \Phi_{xy} \ket{x}\otimes\ket{y \boxplus f(x)} 
$$

Applying $\hat{U}_f$ to the intial state 

$$
  \ket{\Psi_0} := (\hat{H}^n \ket{0}^n) \otimes\ket{0}^m \in \mathcal{H}^A \otimes \mathcal{H}^B
$$

we obtain

$$
\begin{align*}
  \hat{U}_f \ket{\Psi_0} =& \hat{U}_f \left((\hat{H}^n \ket{0}^n) \otimes\ket{0}^m \right) \\
  =& \frac{1}{2^{n/2}} \sum_{x=0}^{2^n - 1} \hat{U}_f (\ket{x}^n \otimes\ket{0}^m) \\
  =& \frac{1}{2^{n/2}} \sum_{x=0}^{2^n - 1} \underbrace{\ket{x}\otimes\ket{f(x)}}_{\in\mathcal{H}^A \otimes\mathcal{H}^B}
\end{align*}
$$

<LatexFigure width={75} src='/fig/function_circuit.svg' alt=''
  caption='Quantum circuit for the operator $\hat{U}_f$'
>
```latex
\documentclass[tikz, border=5pt]{standalone}
\usepackage{quantikz}
\usepackage{amssymb}

\begin{document}
\begin{quantikz}[wire types={b,b,b}]
  \lstick{\ket{x}} & \gategroup[3, steps=7]{$\hat{U}_f$} & \gate[2]{A_f} & \ \ket{\psi(x)}\ &&& \gate[2]{B_f} & \ \ket{x}\ & \rstick{\ket{x}} \\
  \lstick{\otimes} & \ket{\omega_i}\ \wireoverride{n} && \ \ket{f(x)}\ & \gate[2]{U_\boxplus} & \ \ket{f(x)}\ && \ \ket{\omega_f} & \wireoverride{n} \rstick{\otimes} \\
  \lstick{\ket{y}} &&&&& \ \ket{y \boxplus f(x)}\ &&& \rstick{\ket{y \boxplus f(x)}}
\end{quantikz}
\end{document}
```
</LatexFigure>

The resulting state is a coherent superposition of all computational basis states $\ket{x}\otimes\ket{f(x)}$ for $x\in\set{0,\dots,2^n - 1}$. This process, where all values $f(x)$ are encoded simultaneously into a single quantim state, is called *quantum parallelism*. 

Classically, generating the full evaluation table $(x,f(x))$ for all $x\in {0\dots 2^n - 1}$ would require $O(2^n)$ computational steps. In contrast, a single application of $\hat{U}_f$ yields a superposition of all possible $\ket{x}\otimes\ket{f(x)}$ at once. However, due to the nature of quantum measurement, it is not possible to extract all values $f(x)$ individually from the state $\hat{U}_f \ket{\Psi_0}$. Accessing information encoded in the linear combination of all $\ket{x}\otimes\ket{f(x)}$ in $\hat{U}_f \ket{\Psi_0}$, requires further transformations that exploit particular structure or symmetry properties of the function $f$.

### Reading the output register

According to Definition $\ref{definition-9}$, each qubit is associated with an observable $\hat{\sigma}_z$, whose measurement yields one of possible outcomes $\pm 1$, corresponding to the eigenvalues of $\hat{\sigma}_Z$. Such a measurement projects the qubit onto the corresponding eigenstate $\ket{0}$ or $\ket{1}$. 

In a composite system of $n$ qubits, described by states in ${}^\P \mathcal{H}^{\otimes n}$, measurements can be performed on each qubit. That is, for each tensor factor ${}^\P \mathcal{H}_j$ in ${}^\P \mathcal{H}^{\otimes n}$ corresponding to the $j$th qubit, we consider the observable

$$
  \hat{\Sigma}_z^j = \hat{I}_2^{\otimes n-1-j} \otimes\hat{\sigma}_z \otimes\hat{I}_2^{\otimes j},\; j\in\set{0,\dots,n-1}
$$

which acts as $\hat{\sigma}_z$ on the $j$th qubit and trivially on all others. Each $\Sigma_z^j$ therefore performs a projective measurment on a single qubit within the register. Since these observables act non-trivially on distinct, non-overlapping tensor factors, they commute pairwise, i.e.

$$
  [\hat{\Sigma}_z^j, \hat{\Sigma}_z^k] = 0,\; \forall j,k \in\set{0,\dots,n-1}
$$

Hence, the observables $\Sigma_z^j$ are mutually compatible and can all be measured sharply. This forms the basis of a readout operation on the full quantum register, allowing the measurement of all qubits in the computational basis.

<MathBox title='Measurement of quantum registers' boxType='definition'>
Let $n\in\N_+$ and for $j\in\set{0,\dots,n-1}$ and $\alpha\in\set{0,\dots,3}$, define

$$
  \sum_\alpha^j := \hat{I}_2^{\otimes n-1-j} \otimes \hat{\sigma}_\alpha \otimes\hat{I}^{\otimes j} \in \mathcal{B}({}^\P \mathcal{H}^{\otimes n})
$$

where $\hat{\sigma}_\alpha$ are the Pauli spin operators. An observation of a quantum state in the register ${}^\P \mathcal{H}^{\otimes n}$ is defined as the simultaneous measurement of all pairwise compatible observables

$$
  \hat{\Sigma}_z^j = \hat{I}^{\otimes n-1-j} \otimes \hat{\sigma}_z \otimes \hat{I}_2^{\otimes j}
$$

for $j\in\set{0,\dots,n-1}$ in the current state of the quantum register. This process corresponds to a projective measurement in the computational basis. Such an observation is also called *read-out* or measurement of the register.
</MathBox>

The read-out of the register ${}^\P \mathcal{H}^{\otimes n}$ yields $n$ observed values $(s_{n-1},\dots,s_0) \in\set{\pm 1}^n$ after measuring $\hat{\Sigma}_z^{n-1},\dots,\hat{\Sigma}_z^0$. We identify these observed values with corresponding classical bits $x_j \in\set{0,1}$, and use these classical bit values $(x_{n-1},\dots,x_0)$ for the binary representation $x = \sum_{j=0}^{n-1} x_j 2^j$ of a non-negative integer $x < 2^n$. The measurement of the observables $\hat{\Sigma}_z^j$ projects the state in factor space ${}^\P \mathcal{H}_j$ onto the eigenstate $\ket{0}$ or $\ket{1}$ corresponding to the observed value $s_j$. Altogether the read-out of the register ${}^\P \mathcal{H}^{\otimes n}$ therefore reveals a non-negative integer $x < 2^n$ and leaves the register in the computational basis state $\ket{x}$.

## Quantum circuit for modular exponentiation


<MathBox title='' boxType='corollary' tag='corollary-3'>
Let $b, n, m, N \in \N_+$ with $N < 2^m$ and define the function $f_{b,N} :\N_0 \to \N_0$ by $f_{b,N} (x) = b^x \bmod N$. 
Consider the following quantum registers:
- $\mathcal{H}^A = {}^\P \mathcal{H}^{\otimes n}$, the input register
- $\mathcal{H}^B = {}^\P \mathcal{H}^{\otimes m}$, the auxiliary register

Ket $\ket{\omega_i} = \ket{0}^{\otimes m} = \ket{\omega_f}$ be the initial and final states in the auxiliary register $\mathcal{H}^B$. Using these, we define a unitary operator $\hat{U}_{f_{b,N}} : \mathcal{H}^A \otimes \mathcal{H}^B \to \mathcal{H}^A \otimes \mathcal{H}^B$ implementing $f_{b,N}$ via

$$
  \ket{x}\otimes\ket{y} \mapsto\ket{x}\otimes\ket{y \boxplus f_{b,N} (x)}
$$

In particular, when then auxiliary register is initialized to $\ket{0}$, unitary implements function evaluation:

$$
  \hat{U}_{f_{b,N}} (\ket{x} \otimes \ket{0}) = \ket{x} \otimes\ket{f_{b,N} (x)}
$$

<details>
<summary>Proof</summary>

</details>
</MathBox>

# Quantum Fourier transform

<MathBox title='Quantum Fourier transform' boxType='definition'>
The quantum Fourier transform $\hat{F}$ on the $n$-qubit Hilbert space ${}^\P \mathcal{H}^{\otimes n}$ is defined as the operator

$$
\begin{equation*}
  \hat{F} := \frac{1}{\sqrt{2^n}} \sum_{x,y=0}^{2^n - 1} \exp\left(i2\pi \frac{xy}{2^n} \right) \ket{x}\bra{y}
\tag{\label{equation-42}}
\end{equation*}
$$

where $\ket{x}$ and $\ket{y}$ denote computational basis states of ${}^\P \mathcal{H}^{\otimes n}$. The inverse quantum Fourier transform is given by the Hermitian adjoint

$$
  \hat{F}^\dagger := \frac{1}{\sqrt{2^n}} \sum_{x,y=0}^{2^n - 1} \exp\left(-i2\pi \frac{xy}{2^n} \right) \ket{y}\bra{x}
$$
</MathBox>

By defining

$$
  \omega_n := \exp\left(\frac{2\pi i}{2^n}\right)
$$

the matrix representation of $\hat{F}$ in the computational basis can be given as

$$
  \mathbf{F} = \frac{1}{\sqrt{2^n}} \left[\omega_n^{jk} \right]_{j,k=0}^{2^n - 1} = \frac{1}{\sqrt{2^n}} \begin{bmatrix}
    1 & 1 & \cdots & 1 \\
    1 & \omega_n & \cdots & \omega_n^{2^n - 1} \\
    \vdots & \vdots & \ddots & \vdots \\
    1 & \omega_n^{(2^n - 1)} & \cdots & \omega_n^{(2^n - 1)^2} 
  \end{bmatrix}
$$

<MathBox title='Quantum Fourier transform is unitary' boxType='proposition'>
The quantum Fourier transform is unitary, i.e. $\hat{F}\in\mathcal{U}({}^\P \mathcal{H})$.

<details>
<summary>Proof</summary>

For any arbitrary vector $\ket{u}$ in the computational basis ${}^\P \mathcal{H}^{\otimes n}$, it follows from $\eqref{equation-42}$ that

$$
\begin{align*}
  \hat{F}\ket{u} =& \frac{1}{2^{n/2}} \sum_{x,y=0}^{2^n - 1} \exp\left(2\pi i \frac{xy}{2^n} \right) \ket{x} \underbrace{\braket{y|u}}_{=\delta_{yu}} \\
  =& \frac{1}{2^{n/2}} \sum_{x=0}^{2^n - 1} \exp\left(2\pi i \frac{xu}{2^n} \right) \ket{x}
\end{align*}
$$

For arbitrary vector $\ket{u}$ and $\ket{v}$ in the computational basis this implies

$$
\begin{align*}
  \braket{Fu|Fv} =& \frac{1}{2^n} \Braket{\sum_{x=0}^{2^n - 1} \exp\left(2\pi i \frac{xu}{2^n} \right)\ket{x}| \sum_{y=0}^{2^n - 1} \exp\left(2\pi i \frac{yv}{2^n} \right)\ket{y}} \\
  =& \frac{1}{2^n} \sum_{x,y=0}^{2^n - 1} \exp\left(2\pi i \frac{yv - xu}{2^n} \right) \underbrace{\braket{x|y}}_{=\delta_{xy}} \\
  =& \frac{1}{2^n} \sum_{x=0}^{2^n - 1} \exp\left(2\pi i x\frac{v - u}{2^n} \right) \\
  =& \frac{1}{2^n} \sum_{x=0}^{2^n - 1} \left(\exp\left(2\pi i \frac{v - u}{2^n} \right) \right)^x \\
  =& \begin{cases}
    1, \quad& u = v \\
    \frac{1 - \left(\exp\left(2\pi i \frac{v - u}{2^n} \right) \right)^{2^n}}{1 - \exp\left(2\pi i \frac{v - u}{2^n} \right)} = 0, \quad& u\neq v 
  \end{cases} \\
  =& \delta_{uv}
\end{align*}
$$

For arbitrary vectors

$$
\begin{align*}
  \ket{\varphi} =& \sum_{u=0}^{2^n - 1} \varphi_u \ket{u} \\
  \ket{\psi} =& \sum_{v=0}^{2^n - 1} \psi_v \ket{v}
\end{align*}
$$

in ${}^\P \mathcal{H}^{\otimes n}$ thus

$$
\begin{align*}
  \braket{\hat{F}\varphi|\hat{F}\psi} =& \sum_{u,v=0}^{2^n - 1} \varphi_u^* \psi_v \underbrace{\hat{F}u|\hat{F}v}_{\delta_{uv}} \\
  =& \sum_{u,v=0}^{2^n - 1} \varphi_u^* \psi_v = \braket{\varphi|\psi}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='lemma'>
Let $n, N\in\N_+$ with $N = 2^n$ and

$$
  \ket{\Psi} = \sum_{x=0}^{2^n - 1} \Psi_x \ket{x} \in {}^\P \mathcal{H}^{\otimes n}
$$

Moreover, let $\mathbf{c}\in\mathbb{C}^N$ be the vector with components $c_x = \Psi_x = \ket{x|\Psi}$ for $x\in{0,\dots,N - 1}$. Then we have

$$
  \braket{k|\hat{F}\Psi} = F_\text{d} (\mathbf{c})_k
$$

where $F_\text{d} :\mathbb{C}^N \to \mathbb{C}^N$ is the discrete Fourier transform defined component-wise by

$$
  F_\text{d} (\mathbb{c})_k = \frac{1}{\sqrt{N}} \sum_{l=0}^{N-1} \exp\left(\frac{2\pi i}{N} kl \right) c_l
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-42}$ we have

$$
\begin{align*}
  \hat{F}\ket{\Psi} =& \sum_{x=0}^{2^n - 1} \Psi_x \hat{F}\ket{x} =& \sum_{x=0}^{2^n - 1} \Psi_x \frac{1}{\sqrt{2^n}} \sum_{z,y=0}^{2^n - 1} \exp\left(2\pi i \frac{zy}{2^n} \right) \ket{z} \underbrace{\braket{y|x}}_{=\delta_{xy}} \\
  =& \frac{1}{\sqrt{2^n}} \sum_{x,z=0}^{2^n - 1} \Psi_x \exp\left(\frac{2\pi i}{2^n} zx \right) \ket{z} \\
  =& \frac{1}{\sqrt{N}} \sum_{x,z=0}^{N-1} c_x \exp\left(\frac{2\pi i}{N} zx \right) \ket{z}
\end{align*}
$$

and thus

$$
\begin{align*}
  \ket{k|\hat{F}\Psi} =& \frac{1}{\sqrt{N}} \sum_{x,z=0}^{N-1} c_x \exp\left(\frac{2\pi i}{N} zx \right) \underbrace{\braket{\delta_{kz}}} \\
  =& \frac{1}{\sqrt{N}} \sum_{x=0}^{N-1} c_x \exp\left(\frac{2\pi i}{N} kx \right) \\
  =& F_\text{d} (\mathbf{c})_z
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Binary fractions' boxType='definition' tag='definition-7'>
For binary numbers $a_1,\dots,a_m \in\set{0,1}$ we denote binary fractions by

$$
  0_{.a_1\dots a_m} := \frac{a_1}{2} + \frac{a_2}{4} +\cdots+ \frac{a_m}{2^m} = \sum_{l=1}^m a_l 2^{-l}
$$
</MathBox>

<MathBox title='' boxType='lemma'>
Let $n\in\N$ and

$$
\begin{equation*}
  x = \sum_{j=0}^{n-1} x_j 2^j
\tag{\label{equation-44}}
\end{equation*}
$$

where $x_j \in\set{0,1}$ for $j\in{0,\dots,n-1}$. Then the action of the quantum Fourier transform on any vector $\ket{x}$ of the computational basis of ${}^\P \mathcal{H}$ can be written as

$$
  \hat{F}\ket{x} = \frac{1}{\sqrt{2^n}} \bigotimes_{j=0}^{n-1} \left[ \ket{0} + e^{2\pi i 0_{.x_j \dots x_0}} \ket{1} \right]
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-42}$, we have

$$
\begin{align*}
  \hat{F}\ket{x} =& \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} \exp\left(\frac{2\pi i}{2^n} xy \right) \ket{y} \\
  =& \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} \exp\left(\frac{2\pi i}{2^n} x \sum_{j=0}^{n-1} y_j 2^j \right) \ket{y_{n-1} \dots y_0} \\
  =& \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} \prod_{j=0}^{n-1} \exp\left(\frac{2\pi i}{2^n} xy_j 2^j \right) \ket{y_{n-1}\dots y_0} \\
  =& \frac{1}{\sqrt{2^n}} \sum_{y_0 \dots y_{n-1} \in\set{0,1}} \prod_{j=0}^{n-1} \exp\left(\frac{2\pi i}{2^n} xy_k 2^k \right) \bigotimes_{k=n-1}^0 \ket{y_k} \\
  =& \frac{1}{\sqrt{2^n}} \sum_{y_0 \dots y_{n-1} \in\set{0,1}} \bigotimes_{k=n-1}^0 \exp\left(\frac{2\pi i}{2^n} xy_k 2^k \right) \ket{y_k} \\
  =& \frac{1}{\sqrt{2^n}} \bigotimes_{k=n-1}^0 \sum_{y_k \in\set{0,1}} \exp\left(\frac{2\pi i}{2^n} xy_k 2^k \right) \ket{y_k} \\
  =& \frac{1}{\sqrt{2^n}} \bigotimes_{k=n-1}^0 \left[\ket{0} + \exp\left(\frac{2\pi i}{2^n} x 2^k \right)\ket{1}\right] \tag{\label{equation-43}}
\end{align*}
$$

In the last equation we further use $\eqref{equation-44}$ and the binary fraction notation from Definition $\ref{definition-7}$ in order to obtain

$$
\begin{align*}
  \exp\left(\frac{2\pi i}{2^n} x2^k \right) =& \exp\left(2\pi i \sum_{l=0}^{n-1} x_l 2^{l+k-n} \right) \\
  =& \exp\left(2\pi i \left[\sum_{l=0}^{n-k-1} x_l 2^{l+k-n} + \sum_{l=n-k}^{n-1} x_l 2^{l+k-n}\right] \right) \\
  =& \exp\left(2\pi i \sum_{l=0}^{n-k-1} x_l 2^{l+k-n} \right) \\
  =& e^{2\pi i 0_{.x_{n-1-k} \dots x_0}} \tag{\label{equation-45}}
\end{align*}
$$

Substituting $\eqref{equation-45}$ into $\eqref{equation-43}$ yields

$$
\begin{align*}
  \hat{F}\ket{x} =& \frac{1}{\sqrt{2^n}} \bigotimes_{k=n-1}^0 \left[\ket{0} + e^{2\pi i 0_{.x_{n-1-k} \dots x_0}} \right] \\
  =& \frac{1}{\sqrt{2^n}} \bigotimes_{j=0}^{n-1} \left[\ket{0} + e^{2\pi i 0_{. x_j \dots x_0}} \ket{1}\right]
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='lemma'>
Let $n\in\N_+$ and $j\in\N_0$ with $j < n$ and let $\ket{x}$ be a vector in the computational basis in ${}^\P \mathcal{H}^{\otimes n}$. Then

$$
\begin{equation*}
  \hat{H}\ket{x_j} = \frac{\ket{0} + e^{2\pi i 0_{.x_j}} \ket{1}}{\sqrt{2}}
\tag{\label{equation-46}}
\end{equation*}
$$

holds, and with

$$
\begin{equation*}
  \hat{H}_j := \hat{I}_2^{\otimes (n-1-j)} \otimes \hat{H} \otimes\hat{I}_2^{\otimes j},\; j\in\set{0,\dots,n-1}
\tag{\label{equation-47}}
\end{equation*}
$$

we have

$$
\begin{equation*}
  \hat{H}_j \ket{x} = \ket{x_{n-1}}\otimes\cdots\otimes\ket{x_{j+1}} \otimes \frac{\ket{0} + e^{2\pi i 0_{.x_j}}\ket{1}}{\sqrt{2}} \otimes\ket{x_{j-1}} \otimes\cdots\otimes\ket{x_0}
\tag{\label{equation-48}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

We know that

$$
  \hat{H}\ket{x_j} = \frac{\ket{0} + e^{\pi i x_j} \ket{1}}{\sqrt{2}}
$$

Then $\eqref{equation-46}$ follows from Definition $\ref{definition-7}$ of the binary fraction. The action of $\hat{H}_j$ as claimed in $\eqref{equation-48}$ follows directly from $\eqref{equation-46}$ and $\eqref{equation-47}$.
</details>
</MathBox>

<MathBox title='Conditional phase shift' boxType='definition'>
Let $j,k\in\set{0,\dots,n-1}$ ith $j > k$ and define $\theta_{jk} := \frac{\pi}{2^{j-k}}$. The *conditional phase shift* is a linear transformation on ${}^\P \mathcal{H}^{\otimes n}$ defined as

$$
\begin{align*}
  \hat{P}_{jk} :=& \hat{I}_2^{\otimes(n-1-k)} \otimes \ket{0}\bra{0}\otimes\hat{I}_2^{\otimes k} \\
  &+ \hat{I}_2^{\otimes(n-1-j)} \otimes \left[\ket{0}\bra{0} + e^{i\theta_{jk}} \ket{1}\bra{1} \right] \otimes\hat{I}_2^{\otimes(j-k-1)} \otimes\ket{1}\bra{1}\otimes\hat{I}_2^{\otimes k}
\end{align*}
$$
</MathBox>

The action of $\hat{P}_{jk}$ is an application of $\hat{\Lambda}_{\ket{1}^1} (\hat{P}(\theta_{jk}))$ on the $(k+1)$th and $(j+1)$th factor space in ${}^\P \mathcal{H}^{\otimes n}$. This can be illustrated if we consider the restriction onto the respective subspaces. Let ${}^\P \mathcal{H}_k$ denote the $(k+1)$th factor spacec counted from the right and ${}^\P \mathcal{H}_j$ the $(j+1)$th factor space in ${}^\P \mathcal{H}^{\otimes n}$. Furthermore, let

$$
  \ket{0}_j \otimes \ket{0}_k,\quad \ket{1}_j \otimes\ket{0}_k,\quad \ket{0}_j \otimes\ket{1}_k,\quad \ket{1}_j \otimes\ket{1}_k
$$

be the four vectors of the computational basis in ${}^\P \mathcal{H}_j \otimes {}^\P \mathcal{H}_k$. Then the matrix representation of the restriction of these to factor spaces is given by

$$
  \hat{P}_{jk}|_{{}^\P \mathcal{H}_j \otimes {}^\P \mathcal{H}_k} = \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & e^{i\theta_{jk}}
  \end{bmatrix} = \Lambda_{\ket{1}^1} (\hat{P}(\theta_{jk}))
$$

The action of $\hat{P}_{jk}$ is thus only non-trivial if both states in the $(j+1)$th as well as the $(k+1)$th factor space each have a non-vanishing component along $\ket{1}$ in which case it consists of a multiplication with a phase factor $e^{i\theta_{jk}}$. Otherwise, $\hat{P}_{jk}$ leaves the total state unchanged, in other words, acts as the identity.

<MathBox title='' boxType='lemma' tag='lemma-4'>
Let $j,k\in\set{0,\dots,n-1}$ with $j > k$ and let $l\in\set{j+1,\dots,n-1}$. Moreover, let $\ket{\psi_l}\in {}^\P \mathcal{H}$ and $\psi_{0j}, \psi_{1j} \in\mathbb{C}$ as well as $x_0,\dots,x_{j-1} \in\set{0,1}$. Then we have

$$
\begin{align*}
  & \hat{P}_{jk} \left(\bigotimes_{l=n-1}^{j+1} \ket{\psi_l} \right) \otimes [\psi_{0j}\ket{0} + \psi_{1j} \ket{1}] \otimes\left(\bigotimes_{l=j-1}^0 \ket{x_l} \right) \\
  =& \left(\bigotimes_{l=n-1}^{j+1} \ket{\psi_l} \right) \otimes \left[\psi_{0j}\ket{0} + \psi_{1j} \exp\left(i\pi \frac{x_k}{2^{j-k}}\right) \ket{1}\right] \otimes \left(\bigotimes_{l=j-1}^0 \ket{x_l} \right)
\end{align*}
$$

In other words, the conditional phase gate $\hat{P}_{jk}$ applies a relative phase $e^{i \pi/ 2^{j-k}}$ to the to the $\ket{1}$-component of target qubit $j$ conditioned on the control qubit $k$ being in the state $\ket{1}$.

<details>
<summary>Proof</summary>

With $\ket{x_k} = (1 - x_k) \ket{0} + x_k \ket{1}$ and $\theta_{jk} = \frac{\pi}{2^{j-k}}$, we have

$$
\begin{align*}
  & \hat{P}_{jk} \left(\bigotimes_{l=n-1}^{j+1} \ket{\psi_l} \right) \otimes [\psi_{0j}\ket{0} + \psi_{1j} \ket{1}] \otimes\left(\bigotimes_{l=j-1}^0 \ket{x_l} \right) \\
  =& (1 - x_k) \left(\bigotimes_{l=n-1}^{j+1} \ket{\psi_l} \right) \otimes [\psi_{0j}\ket{0} + \psi_{1j} \ket{1}] \otimes\left(\bigotimes_{l=j-1}^0 \ket{x_l} \right) \\
  &+ x_k \left(\bigotimes_{l=n-1}^{j+1} \ket{\psi_l} \right) \otimes [\psi_{0j}\ket{0} + \psi_{1j} e^{i\theta_{jk}} \ket{1}] \otimes\left(\bigotimes_{l=j-1}^0 \ket{x_l} \right) \\
  =& \left(\bigotimes_{l=n-1}^{j+1} \ket{\psi_l} \right) \otimes \left[\psi_{0j}\ket{0} + \psi_{1j} \exp\left(i\pi \frac{x_k}{2^{j-k}}\right) \ket{1}\right] \otimes \left(\bigotimes_{l=j-1}^0 \ket{x_l} \right)
\end{align*}
$$
</details>
</MathBox>

<LatexFigure width={75} src='/fig/fourier_circuit.svg' alt=''
  caption='Quantum circuit for the quantum Fourier transform using Hadamard gates, conditional phase shift gates and swap gates'
>
```latex
\documentclass[tikz, border=5pt]{standalone}
\usepackage{quantikz}

\begin{document}
\begin{quantikz}[wire types={q,n,q,n,q,n,n,n,q,n,q}]
  \lstick{\ket{x_{n-1}}} & \gate{H} \gategroup[11, steps=18]{$F$} & \gate{P} & \gate{P} & \ \ldots\ & \gate{P} & \gate{P} &&& \ \ldots\ &&& \ \ldots\ &&&& \swap{10} &&& \rstick[11]{$\hat{F}\ket{x}^n$} \\
  \lstick{\otimes} &&&&&&&&&&&&&&&&&&& \\
  \lstick{\ket{x_{n-2}}} && \ctrl{-2} && \ \ldots\ &&& \gate{H} & \gate{P} & \ \ldots\ & \gate{P} & \gate{P} & \ \ldots\ &&&&& \swap{6} && \\
  \lstick{\otimes} &&&&&&&&&&&&&&&&&&& \\
  \lstick{\ket{x_{n-3}}} &&& \ctrl{-4} & \ \ldots\ &&&& \ctrl{-2} & \ \ldots\ &&& \ \ldots\ &&&&&& \swap{1} & \\
  \lstick{\otimes} &&&&&&&&&&&&&&&&&&& \\[-0.4cm]
  \lstick{\vdots} &&&&&&&&&&&&&&&&&& \ddots & \\[-0.2cm]
  \lstick{\otimes} &&&&&&&&&&&&&&&&&&& \\[-0.2cm]
  \lstick{\ket{x_1}} &&&& \ \ldots\ & \ctrl{-8} &&&& \ \ldots\ & \ctrl{-6} && \ \ldots\ & \gate{H} & \gate{P} &&& \targX{} && \\
  \lstick{\otimes} &&&&&&&&&&&&&&&&&&& \\
  \lstick{\ket{x_0}} &&&&&& \ctrl{-10} &&&&& \ctrl{-8} &&& \ctrl{-2} & \gate{H} & \targX{} &&&
\end{quantikz}
\end{document}
```
</LatexFigure>

<MathBox title='' boxType='theorem'>
The quantum Fourier transform can be constructed from the swap operator, Hadamard transforms and conditional phase shifts as follows

$$
\begin{equation*}
  \hat{F} = S^{(n)} \prod_{j=0}^{n-1} \left(\left[\prod_{k=0}^{j-1} \hat{P}_{jk} \right] \hat{H}_j \right) 
\tag{\label{equation-49}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-48}$, we obtain

$$
  \hat{H}_{n-1} \ket{x} = \frac{\ket{0} + e^{2\pi i0_{.x_{n-1}}} \ket{1}}{\sqrt{2}} \otimes \left(\bigotimes_{j=n-2}^0 \ket{x_j} \right)
$$

By Lemma $\ref{lemma-4}$, this implies

$$
\begin{align*}
  \hat{P}_{n-1, n-2} \hat{H}_{n-1} \ket{x} =& \frac{\ket{0} + \exp\left(2\pi i0_{.x_{n-1}} + i\pi \frac{x_{n-2}}{2}\right) \ket{1}}{\sqrt{2}} \otimes \left(\bigotimes_{j=n-2}^0 \ket{x_j} \right) \\
  =& \frac{\ket{0} + e^{2\pi i0_{.x_{n-1}x_{n-2}}} \ket{1}}{\sqrt{2}} \otimes \left(\bigotimes_{j=n-2}^0 \ket{x_j} \right)
\end{align*}
$$

and

$$
  \hat{P}_{n-1, 0} \cdots \hat{P}_{n-1, n-2} \hat{H}_{n-1} \ket{x} = \frac{\ket{0} + e^{2\pi i0_{.x_{n-1} \dots x_0}} \ket{1}}{\sqrt{2}} \otimes \left(\bigotimes_{j=n-2}^0 \ket{x_j} \right)
$$

Furthermore

$$
  \hat{H}_{n-2} \hat{P}_{n-1, 0} \cdots \hat{P}_{n-1, n-2} \hat{H}_{n-1} = \frac{\ket{0} + e^{2\pi i0_{.x_{n-1} \dots x_0}} \ket{1}}{\sqrt{2}} \otimes \frac{\ket{0} + e^{2\pi i0_{.x_{n-2}}} \ket{1}}{\sqrt{2}} \otimes \left(\bigotimes_{j=n-3}^0 \ket{x_j} \right)
$$

and

$$
\begin{align*}
  &\hat{P}_{n-2,0} \cdots \hat{P}_{n-2, n-3} \hat{H}_{n-2} \hat{P}_{n-1,0} \cdots \hat{P}_{n-1,n-2} \hat{H}_{n-1} \ket{x} \\
  =& \frac{\ket{0} + e^{2\pi i0_{.x_{n-1} \dots x_0}} \ket{1}}{\sqrt{2}} \otimes \frac{\ket{0} + e^{2\pi i0{.x_{n-2} \dots x_0}} \ket{1}}{\sqrt{2}} \otimes \left(\bigotimes_{j=n-3}^0 \ket{x_j} \right)
\end{align*}
$$

Similarly, a repeated application to the remaining tensor products $\bigotimes_{j=n-3}^0 \ket{x_j}$ yields

$$
  \prod_{j=0}^{n-1} \left(\prod_{k=0}^{j-1} (\hat{P}_{jk}) \hat{H}_j \right) \ket{x} = \frac{1}{\sqrt{2^n}} \bigotimes_{k=n-1}^0 \left[\ket{0} + e^{2\pi i0_{.x_k \dots x_0}} \ket{1} \right]
$$

This is $\hat{F}\ket{x}$ up to an inversion of the sequences of the factor spaces. Thus, we have

$$
\begin{align*}
  \hat{S}^{(n)} \prod_{j=0}^{n-1} \left(\prod_{k=0}^{j-1} (\hat{P}_{jk}) \hat{H}_j \right) \ket{x} =& \frac{1}{\sqrt{2^n}} \hat{S}^{(n)} \bigotimes_{k=n-1}^0 \left[\ket{0} + e^{2\pi i0_{.x_k \dots x_0}} \ket{1} \right] \\
  =& \frac{1}{\sqrt{2^n}} \bigotimes_{k=0}^{n-1} \left[\ket{0} + e^{2\pi i0_{.x_k \dots x_0}} \ket{1} \right] \\
  =& \hat{F}\ket{x}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
The inverse quantum Fourier transform can be constructed from the swap operator, Hadamard transforms and conditional phase shifts as follows

$$
\begin{equation*}
  \hat{F}^\dagger = (S^{(n)})^\dagger \prod_{j=0}^{n-1} \left(\left[\prod_{k=0}^{j-1} \hat{P}_{jk}^\dagger \right] \hat{H}_j \right) 
\tag{\label{equation-49}}
\end{equation*}
$$

</MathBox>

<MathBox title='' boxType='corollary' tag='corollary-2'>
Let $\hat{F}$ be the quantum Fourier transform on ${}^\P \mathcal{H}^{\otimes n}$. Then the number of required computational steps $S_F$ to perform $\hat{F}$ as a function of $n\in\N_+$ satisfies

$$
  S_F (n) \in O(n^2),\; n\to\infty
$$

<details>
<summary>Proof</summary>

The application of Hadamard gates $\hat{H}_j$ and conditional shift gates $\hat{P}_{jk}$ each requires a fixed number of computational steps independent of $n$, i.e. $S_{H_j} (n), S_{P_{jk}} (n) \in O(1)$. The application of swap gates $S^{(n)}$ requires instead $S_{S^{(n)}} \in O(n)$ steps for $n\to\infty$. From $\eqref{equation-49}$ we can perform $\hat{F}$ by
- an $n$-fold application of $\hat{H}_j$ for $j\in\set{0,\dots,n-1}$ with $S_H (n) \in O(n)$
- an $\frac{n(n-1)}{2}$-fold application of $\hat{P}_{jk}$ for $j\in\set{0,\dots,n-1}$ and $k\in\set{0,\dots,j-1}$ with $S_P (n) \in O(n^2)$
- a single application of $S^{(n)}$ with $S_{S^{(n)}} (n) \in O(n)$

Hence, we find for the number of computational steps $S_F$ to perform $\hat{F}$

$$
  S_F (n) = S_H (n) + S_P (n) + S_{S^{(n)}} \in O(n^2)
$$
</details>
</MathBox>

# Deutsch-Jozsa algorithm

<MathBox title="Deutsch's problem" boxType='definition' tag='definition-10'>
Let $n\in\N_+$ and $f:\set{0,1}^n \to\set{0,1}$ be a function that is either
- constant, i.e. $f(x) = c \in\set{0,1}$ for all $x\in\set{0,1}^n$
- balanced, i.e.
$$
  f(x) = \begin{cases}
    0 \text{ for one half of the } x\in\set{0,1}^n \\ 
    1 \text{ for the other half of the } x\in\set{0,1}^n
  \end{cases}
$$

Deutsch's problem is to find the most efficient ay to decide with certainty whether $f$ is constant or balanced.
</MathBox>

Classical applications to solve Deutsch's problem require at least $2^n + 1$ function calls. In contrast, the quantum algorithm devised by Deutsch and Josza, called the Deutsch-Jozsa algorithm, requires just one application of a suitably implemented unitary operator $\hat{U}_f$ of the form $\eqref{equation-54}$.

<MathBox title='' boxType='lemma'>
The application of the $n$-fold tensor product of the Hadamard gate on a computional basis vector $\ket{x}$ satisfy

$$
  \hat{H}^{\otimes n} \ket{x} = \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} (-1)^{x \overset{2}{\odot} y} \ket{y}
$$

where we set for the computational basis vectors $\ket{x}$ and $\ket{y}$

$$
  x \overset{2}{\odot} y := x_{n-1} y_{n-1} \overset{2}{\oplus}\cdots\overset{2}{\oplus} x_0 y_0
$$

<details>
<summary>Proof</summary>

This can be shown by induction. For the base case $n = 1$, we have

$$
\begin{align*}
  \hat{H}\ket{x} =& \hat{H}\ket{x_0} = \frac{1}{\sqrt{2}} (\ket{0} + (-1)^{x_0} \ket{1}) \\
  =& \frac{1}{\sqrt{2}} \sum_{y=0}^1 (-1)^{x \overset{2}{\odot} y} \ket{y} 
\end{align*}
$$

For the induction hypothesis, assume that

$$
  \hat{H}^{\otimes n} \ket{x} = \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} (-1)^{x \overset{2}{\odot} y} \ket{y}
$$

holds for a given $n$. For $\ket{x}\in {}^\P \mathcal{H}^{\otimes n + 1}$ we use the notation $\ket{x} = \ket{x_n \dots x_0} = \ket{x_n} \otimes \ket{\check{x}}$ where $\ket{\check{x}}\in {}^\P \mathcal{H}^{\otimes n}$. Then it follows that

$$
\begin{align*}
  \hat{H}^{\otimes n + 1} \ket{x} =& \hat{H}\ket{x_n} \otimes \hat{H}^{\otimes n} \ket{\check{x}} \\
  =& \hat{H}\ket{x_n} \otimes \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} (-1)^{\check{x} \overset{2}{\odot} y} \ket{y} \\
  =& \frac{1}{\sqrt{2}} (\ket{0} + (-1)^{x_n} \ket{1}) \otimes \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n - 1} (-1)^{\check{x} \overset{2}{\odot} y} \ket{y} \\
  =& \frac{1}{\sqrt{2^{n+1}}} \sum_{y=0}^{2^{n+1} - 1} \left[(-1)^{\check{x} \overset{2}{\odot} y} \ket{0 y_{n-1} \dots y_0} + (-1)^{x_n + \check{x} \overset{2}{\odot} y} \ket{1 y_{n-1} \dots y_0} \right] \\
  =& \frac{1}{\sqrt{2^{n+1}}} \sum_{y=0}^{2^{n+1} - 1} (-1)^{x_n y_n + \check{x} \overset{2}{\odot} y} \ket{y_n \dots y_0} \\
  =& \frac{1}{\sqrt{2^{n+1}}} \sum_{y=0}^{2^{n+1} - 1} (-1)^{x \overset{2}{\odot} y} \ket{y}
\end{align*}
$$

where in the last step we used that $a,b\in\set{0,1}$ implies $(-1)^{a+b} = (-1)^{a \overset{2}{\oplus} b}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $f$ be as in Definition $\ref{definition-10}$ and

$$
\begin{align*}
  \hat{U}_f: {}^\P \mathcal{H}^{\otimes n} \otimes {}^\P \mathcal{H} \to& {}^\P \mathcal{H}^{\otimes n} \otimes {}^\P \mathcal{H} \\
  \ket{x}\otimes\ket{y} \mapsto& \ket{x}\otimes\ket{y \overset{2}{\oplus} f(x)}
\end{align*}
$$

Then there is a quantum algorithm which uses only one application of $\hat{U}_f$ and solves Deutsch's problem.

<details>
<summary>Proof</summary>

We devise an algorithm that solves the problem with only one application of $\hat{U}_f$ as follows. Recall that the Hadamard transform satisfies

$$
  \hat{H}^{\otimes n} \ket{0} = \frac{1}{\sqrt{2^n}} \sum_{x=0}^{2^n - 1} \ket{x}
$$

The algorithm initially operates on the composite system $\mathcal{H}^A \otimes \mathcal{H}^B$, where $\mathcal{H}^A = {}^\P \mathcal{H}^{\otimes n}$ and $\mathcal{H}^B = {}^\P \mathcal{H}$ starts with the initial state

$$
  \ket{\Psi_0} = \ket{0}^n \otimes \frac{\ket{0} - \ket{1}}{\sqrt{2}} \in\mathcal{H}^A \otimes\mathcal{H}^B
$$

In the next step in the algorithm we apply $(\hat{H}^{\otimes n} \otimes\hat{I}_2) \hat{U}_f (\hat{H}^{\otimes n} \otimes\hat{I}_2)$ to obtain

$$
\begin{align*}
  \ket{\Psi_1} =& (\hat{\mathcal{H}}^{\otimes n} \otimes\hat{I}_2) \hat{U}_f (\hat{H}^{\otimes n} \otimes\hat{I}_2) \ket{\Psi_0} \\
  =& (\hat{\mathcal{H}}^{\otimes n} \otimes\hat{I}_2) \hat{U}_f (\hat{H}^{\otimes n} \ket{0} \otimes \frac{\ket{0} - \ket{1}}{\sqrt{2}}) \\
  =& (\hat{\mathcal{H}}^{\otimes n} \otimes\hat{I}_2) \hat{U}_f \left(\frac{1}{\sqrt{2^n}} \sum_{x=0}^{2^n - 1} \ket{x} \otimes \frac{\ket{0} - \ket{1}}{\sqrt{2}} \right) \\
  =& (\hat{\mathcal{H}}^{\otimes n} \otimes\hat{I}_2) \frac{1}{\sqrt{2^{n+1}}} \sum_{x=0}^{2^n - 1} \left(\hat{U}_f (\ket{x} \otimes\ket{0} - \ket{x}\otimes\ket{1}) \right) \\
  =& (\hat{\mathcal{H}}^{\otimes n} \otimes\hat{I}_2) \frac{1}{\sqrt{2^{n+1}}} \sum_{x=0}^{2^n - 1} \ket{x} \otimes (\ket{f(x)} - \ket{1 \overset{2}{\oplus} f(x)}) \\
  =& (\hat{\mathcal{H}}^{\otimes n} \otimes\hat{I}_2) \frac{1}{\sqrt{2^{n+1}}} \sum_{x=0}^{2^n - 1} \ket{x} \otimes (-1)^{f(x)} (\ket{0} - \ket{1}) \\
  =& \frac{1}{\sqrt{2^n}} \sum_{x=0}^{2^n - 1} (-1)^{f(x)} \hat{H}^{\otimes n} \ket{x} \otimes \frac{\ket{0} - \ket{1}}{\sqrt{2}} \\
  =& \frac{1}{2^n} \sum_{y,x=0}^{2^n - 1} (-1)^{f(x) + x \overset{2}{\odot} y} \ket{y} \otimes \frac{\ket{0} - \ket{1}}{\sqrt{2}}
\end{align*}
$$

Since $(\ket{0} - \ket{1})/\sqrt{2} = \ket{\downarrow_{\unitvec{x}}}$, we can write

$$
  \ket{\Psi_1} = \ket{\Psi_1^A} \otimes \ket{\downarrow_{\unitvec{x}}}
$$

where

$$
  \ket{\Psi_1^A} = \frac{1}{2^n} \sum_{x,y=0}^{2^n - 1} (-1)^{f(x) + x \overset{2}{\odot} y} \ket{y}
$$

Consequently, the density operator of the complete system is

$$
\begin{align*}
  \rho_{\Psi_1} =& \bra{\Psi_1} \ket{\Psi_1} \\
  =& \ket{\Psi_1^A \otimes \downarrow_{\unitvec{x}}} \bra{\Psi_1^A \otimes \downarrow_{\unitvec{x}}} \\
  =& \ket{\Psi_1^A}\bra{\Psi_1^A} \otimes \ket{\downarrow_{\unitvec{x}}} \otimes \bra{\downarrow_{\unitvec{x}}}
\end{align*}
$$

and the tensor product trace rule with $\operatorname{tr}(\ket{\downarrow_{\unitvec{x}}} \otimes \bra{\downarrow_{\unitvec{x}}}) = 1$ we have

$$
  \rho^A (\rho_{\Psi_1}) = \operatorname{tr}^B (\rho_{\Psi_1}) = \bra{\Psi_1^A} \ket{\Psi_1^A} = \rho_{\Psi_1^A}
$$

This shows that considered alone, the subsystem $A$ is described by the pure state

$$
  \ket{\Psi_1^A} = \frac{1}{2^n} \sum_{x=0}^{2^n - 1} (-1)^{f(x)} \ket{0} + \frac{1}{2^n} \sum_{y=1, x=0}^{2^n - 1} (-1)^{f(x) + x \overset{2}{\odot} y} \ket{y}
$$

The probability to find system $A$ in the state $\ket{0}\in\mathcal{H}^A$ is given by

$$
\begin{align*}
  |\braket{0|\Psi_1^A}|^2 =& \left(\frac{1}{2^n} \sum_{x=0}^{2^n - 1} (-1)^{f(x)} \right) \\
  =& \begin{cases}
    \left(\frac{1}{2^n} \sum_{x=0}^{2^n - 1} (-1)^c \right) = 1,\quad&  f \text{ is constant} \\
    \left(\frac{1}{2^n} (2^{n-1} - 2^{n-1} \right)^2 = 0,\quad& f \text{ is balanced}
  \end{cases}
\end{align*}
$$

Hence, measuring $P_\ket{0} = \bra{0}\ket{0}$ in the state $\ket{\Psi_1^A}$, which we have produced by only one application of $\hat{U}_f$, will reveal if $f$ is constant or balanced.
</details>
</MathBox>

# Quantum cryptography

<MathBox title='Cipher' boxType='definition'>
Let $M, C, K$ be finite sets representing the spaces of plaintexts (messages), ciphertexts, and keys, respectively. A *cipher* is a cryptographic protocol encrypting messages $m \in M$ with a key $k \in K$. It consists of two functions
- an *encryption* $e: K\times M \to C$ mapping a key-plaintext pair $(k,m)$ to some ciphertext $e(k,m)$, and 
- a *decryption* $d: K\times C \to M$ mapping a key-ciphertext pair $(k,c)$ to the original message $m = d(k,c)$ 

The cipher satisfies the correctness condition

$$
\begin{equation*}
  d(k, e(k,m)) = m,\; \forall m \in M, k \in K
\tag{\label{equation-55}}
\end{equation*}
$$

A cipher is *symmetric* if the same key $k\in K$ is used for encryption and decryption. It it *asymmetric* if the key is a pair $k = (k_\text{private}, k_\text{public}) \in K$, where encryption is performed using the public key:

$$
  m \mapsto e(k_\text{public}, m)
$$

and decryption is performed using the corresponding private key

$$
  c \mapsto d(k_\text{private}, c)
$$

<details>
<summary>Details</summary>

Effectively, $d$ is the inversion of $e$. Specifically, if we define

$$
\begin{align*}
  e_k (\cdot) :=& e(k, \cdot): M\to C \\
  d_k (\cdot) :=& d(k, \cdot): C\to M
\end{align*}
$$

then $\eqref{equation-55}$ implies that

$$
  d_k \circ e_k = \operatorname{id}_M
$$
</details>
</MathBox>

In digital communication, a message $m\in M$ can be represented as a binary string $(m_{n_M -1},\dots,m_0)$ of a fixed length $n_M$ with $m_j \in\set{0,1}$. Intepreting the message bits $m_j$ as coefficients in a binary expansion, each meassage corresponds to an natural number $m\in\N_0$ given by

$$
  m = \sum_{j=0}^{n_M - 1} m_j 2^j \in \set{0,\dots, 2^{n_M} - 1}
$$

Likewise, a ciphertext $c\in C$ can be represented as a binary string of length $n_C$ and a natural number $c \in \set{0, \dots, \leq 2^{n_C} - 1}$. In many ciphers the key $k \in K$ is also represented as a binary string of length $n_K$ and a natural number $k \in\set{0,\dots,2^{n_K} - 1}$.

<MathBox title='Vernam cipher' boxType='example'>
The Vernam cipher is a *symmetric* cipher in which the plaintext $m\in M$, key $k\in K$ and ciphertext $c\in C$ are all binary string with same length $n_M = n_K = n_C = n$. It offers absolute secresy in the sense that it is impossible to retrieve $m$ from $c$ without knowing $k$. This comes at the cost of requiring a new key for each new message. 

The key $k$ is a uniformly random bit string

$$
  k = (k_{n-1},\dots,k_0),\; k_j \in\set{0,1}
$$

Encryption is performed by bitwise addition modulo $2$ (XOR) of the plaintext $m = (m_{n-1},\dots,m_0)$ with the key:

$$
  e(k,m) = (k_{n-1} \overset{2}{\oplus} m_{n-1}, \dots k_0 \overset{2}{\oplus} m_0)
$$

The ciphertext $c = e(k,m)$ is a purely random sequence of bits and reveals no information of the original plaintext in the absence of the key $k$. With the key, decryption is conducted by applying XOR betwewen the key-bits and the ciphertext-bits:

$$
\begin{align*}
  d(k, e(k,m)) =& (k_{n-1} \overset{2}{\oplus} e(k,m)_{n-1}, \dots, k_0 \overset{2}{\oplus} e(k,m)_0) \\
  =& (k_{n-1} \overset{2}{\oplus} k_{n-1} \overset{2}{\oplus} m_{n-1},\dots, k_0 \overset{2}{\oplus} k_0 \overset{2}{\oplus} m_0) \\
  =& (m_{n-1}, \dots, m_0)
\end{align*}
$$

since $k_j \overset{2}{\oplus} k_j = 0$ and $0 \oplus m_j = m_j$ for all $j = 0,\dots, n-1$.

The security of the Vernam cipher comas at the cost of practicality: a new random key of length $n$ must be generated and securely shared for each mesagge. The Vernam cipher is therefore a concrete realization of the one-time pad cipher.
</MathBox>

## The BB84 protocol

In 1984, Bennett and Brassard proposed a method for securely distributing a random bit sequence that can serve as a key for the Vernam cipher. This protocol, known by the acronym BB84, is notable for being the first quantum key distribution (QKD) scheme. While it does not involve quantum entanglement, it exploits the projection postulate telling that measurements disturb the state of a quantum system. This property allows the communicating parties to detect the presence of any eavesdropper.

BB84 allows for two parties, traditionally called Alice and Bob, to establish a shared random bit sequence that is known only to them. Moreover, the protocol allows them to detect whether an eavesdropper (Eve) has intercepted the transmission. This is achieved as follows:

1. **Preparation and transmission:** Alice begins with a supply of qubits. For each qubit, she randomly chooses a basis, either the computational basis $\set{\ket{0},\ket{1}}$, corresponding to a measurement of the observable $\sigma_z$, or the Hadamard basis $\set{\ket{+},\ket{-}}$, corresponding to $\sigma_x$. She prepares the qubit in a state consistent with her chosen basis and records both the basis and the resulting bit (0 or 1). She then sends each qubit to Bob.
2. **Measurement by Bob**: Upon receiving each qubit, Bob independently and randomly selects a basis (either $\sigma_z$ or $\sigma_x$) and measures the qubit accordingly, recording both his chosen basis and the result.
3. **Public Basis Comparison:** After the transmission, Alice and Bob communicate over a public classical channel and compare the basis they used for each qubit—but not the measurement results. They discard all bits where their bases differed.
4. **Error checking and key Extraction:** From the remaining bits (those for which they used the same basis), Alice and Bob randomly select a subset to publicly compare. If the results agree with high probability, they infer that no eavesdropping occurred and keep the remaining undisclosed bits as their shared secret key. Otherwise, they abort the protocol and try again.

**Security against eavesdropping**

Suppose Eve attempts to intercept and measure the qubits en route from Alice to Bob. Her goal is to obtain the same random bit sequence that Alice and Bob are trying to share. However, since Eve does not know Alice's chosen basis for each qubit, she must randomly guess a basis for measurement.
- If Eve happens to choose the same basis as Alice, she obtains the correct bit value and sends on a qubit in the correct state. Bob will then receive and measure the correct result, assuming he also uses the same basis.
- However, if Eve chooses the wrong basis, her measurement disturbs the qubit due to the incompatibility of the observables $\sigma_z$ and $\sigma_x$ As a result, the qubit sent to Bob is no longer in the state prepared by Alice. If Bob happens to choose the correct basis (matching Alice's), his measurement will produce a random result, introducing detectable errors.

By publicly comparing a subset of their bits, Alice and Bob can estimate the error rate. A higher-than-expected error rate—beyond what can be attributed to noise or imperfect transmission—reveals the presence of an eavesdropper. In that case, they discard the key and restart the protocol.

## The EK91 protocol

In 1991, Ekert proposed a method for securely distributing keys without transmitting any qubits, which is known as the EK91 protocol. This protocol utilizes violations of teh CHSH form Bell's inequality to detect potential eavesdropping.

EK91 allows for two parties, Alice and Bob, to establish a shared random bit sequence that is known only to them, provided they each have a supply of single qubits that are part of a composite system in an entangled state.

Assume Alice and Bob share a sequence of entangled two-qubit systems, each prepared in the Bell state

$$
\begin{align*}
  \ket{\Psi_-} =& \frac{1}{\sqrt{2}} (\ket{0}\otimes\ket{1} - \ket{1}\otimes\ket{0}) \\
  =& \frac{1}{\sqrt{2}}  (\ket{\uparrow_{\unitvec{n}}}\otimes\ket{\downarrow_{\unitvec{n}}} - \ket{\downarrow_{\unitvec{n}}}\otimes\ket{\uparrow_{\unitvec{n}}})
\end{align*}
$$

for unit vector $\unitvec{n} \in \mathbb{S}^2 \subset\R^3$. These qubits are distributed such that Alice and Bob can independently retrieve their halves at times of their choosing.

Each party performs measurements on their qubits. For each qubit, Alice randomly selects a direction. Alice randomly selects a direction $\unitvec{n}_A \in \set{\unitvec{n}_1, \unitvec{n}_2, \unitvec{n}_4}$ and measures the observable $\Sigma_{\unitvec{n}_A}^A \unitvec{n}_A \cdot \boldsymbol{\sigma}$ on her qubits. Bob independently does the same, choosing randomly a direction $\unitvec{n}_B \in\set{\unitvec{n}_1, \unitvec{n}_2, \unitvec{n}_4}$ and measuring $\Sigma_{\unitvec{n}_B}^B$ on each of his qubits. 

After the measurements, Alice and Bob publicly communicate the directions $\unitvec{n}_A$ and $\unitvec{n}_B$ they have used for each entangled pair, keeping their measurement outcomes secret. They partition the measured qubit pairs into two disjoint sets
- *The key generation set* of pairs measured along the same direction, i.e. $\unitvec{n}_A = \unitvec{n}_B$
- *The security test set* of pairs measured in different directions, i.e. $\unitvec{n}_A \neq \unitvec{n}_B$

In the key generation set, the outcome pairs are anticorrelated due to the antisymmetry of $\ket{\Psi_-}$: whenever Alice observes $1$ for her qubit, Bob observes $-1$ for his and vice versa. To see this, suppose Alice measures the spin in the direction $\unitvec{n}_2$ and observes the value $1$. The projector onto the corresponding eigenspace in the composite system is

$$
  \hat{P}_{\unitvec{n}^2, 1} = \ket{\uparrow_{\unitvec{n}_2}} \bra{\uparrow_{\unitvec{n}_2}} \otimes \hat{I}_2
$$

From the projection postulate, we know that Alice's measurement projects the original state

$$
  \ket{\Psi_-} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{n}_2}}\otimes\ket{\downarrow_{\unitvec{n}_2}} - \ket{\downarrow_{\unitvec{n}_2}}\otimes\ket{\uparrow_{\unitvec{n}_2}})
$$  

onto

$$
\begin{align*}
  \ket{\Psi_{\unitvec{n}_2, 1}} :=& \frac{\hat{P}_{\unitvec{n}_2, 1} \ket{\Psi^-}}{\Norm{\hat{P}_{\unitvec{n}_2, 1} \ket{\Psi^-}}} \\
  =& \frac{(\ket{\uparrow_{\unitvec{n}_2}} \bra{\uparrow_{\unitvec{n}_2}} \otimes \hat{I}_2) \ket{\Psi_-}}{\Norm{(\ket{\uparrow_{\unitvec{n}_2}} \bra{\uparrow_{\unitvec{n}_2}} \otimes \hat{I}_2) \ket{\Psi_-}}} \\
  =& \ket{\uparrow_{\unitvec{n}_2}} \otimes \ket{\downarrow_{\unitvec{n}_2}}
\end{align*}
$$

where we used that

$$
\begin{align*}
  (\ket{\uparrow_{\unitvec{n}_2}} \bra{\uparrow_{\unitvec{n}_2}} \otimes \hat{I}_2) \ket{\Psi_-} =& \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{n}_2}} \underbrace{\braket{\uparrow_{\unitvec{n}_2} | \uparrow_{\unitvec{n}_2}}}_{=1} \otimes \ket{\downarrow_{\unitvec{n}_2}} \underbrace{\braket{\uparrow_{\unitvec{n}_2} | \downarrow_{\unitvec{n}_2}}}_{=1} \otimes \ket{\uparrow_{\unitvec{n}^2}}) \\
  =& \frac{1}{\sqrt{2}} \ket{\uparrow_{\unitvec{n}_2}} \otimes \ket{\downarrow_{\unitvec{n}_2}}
\end{align*}
$$

This means that Bob's system will be described by the reduced density operator

$$
\begin{align*}
  \rho_B (\ket{\Psi_{\unitvec{n}_2, 1}} \bra{\Psi_{\unitvec{n}_2, 1}}) =& \operatorname{tr}_A (\ket{\Psi_{\unitvec{n}_2, 1}} \bra{\Psi_{\unitvec{n}_2, 1}}) \\
  =& \operatorname{tr}_A \left[(\ket{\uparrow_{\unitvec{n}_2}} \otimes \ket{\downarrow_{\unitvec{n}_2}}) (\ket{\uparrow_{\unitvec{n}_2}} \otimes \ket{\downarrow_{\unitvec{n}_2}})\right] \\
  =& \operatorname{tr}_A \left(\ket{\uparrow_{\unitvec{n}_2}} \bra{\uparrow_{\unitvec{n}_2}} \otimes \ket{\downarrow_{\unitvec{n}_2}} \bra{\downarrow_{\unitvec{n}_2}}\right) \\
  =& \underbrace{\operatorname{tr}\left( \ket{\uparrow_{\unitvec{n}_2}} \bra{\uparrow_{\unitvec{n}_2}} \right)}_{=1} \ket{\downarrow_{\unitvec{n}_2}} \bra{\downarrow_{\unitvec{n}_2}} \\
  =& \ket{\downarrow_{\unitvec{n}_2}} \bra{\downarrow_{\unitvec{n}_2}}
\end{align*}
$$

which is the density operator of the pure state $\ket{\downarrow_{\unitvec{n}_2}}$. If Bob measures in the same direction $\unitvec{n}_2$, he will observe the value $-1$, since the state $\ket{\downarrow_{\unitvec{n}_2}}$ is an eigenvector of the observable $\Sigma_{\unitvec{n}_2}^B$ with eigenvalue $-1$. Analogously, we Bob will always observe $1$ for his qubit if Alice has measured the value $1$ on her qubit. Hence, in the set of identical measurement directions the measurement results of Alice and Bob are always (with certainty, that is) opposite to each other. Since the measurement results are only known to them, they can thus use this set of measurement results as a random and secret bit-sequence.

To ensure the security of the key, Alice and Bob use the security test set to check for the presence of an eavesdropper (Eve). Eavesdropping can be attempted in two principal ways:
1. *Intercept-resend attack*: Eve measures one or both qubits before Alice or Bob do, projecting the qubits in a separable state of the form $\ket{\uparrow_{\unitvec{n}}} \otimes \ket{\downarrow_{\unitvec{n}}}$
2. *Source tampering*: Eve replaces the entangled source with a separable state of the form $\ket{\varphi\otimes\psi}$, for which she knows the individual states

Hence, in both possible types of eavesdropping attacks that Eve can attempt, the composite system will be in a separable state $\ket{\varphi\otimes\psi}$ before Alice and Bob perform their measurements. In such cases, correlations in measurement outcomes satisfy the classical CHSH inequality:

$$
\begin{equation*}
  \left| \Braket{\Sigma_{\unitvec{n}_1}^A \otimes \Sigma_{\unitvec{n}_2}^B}_{\varphi\otimes\psi} - \Braket{\Sigma_{\unitvec{n}_1}^A \otimes \Sigma_{\unitvec{n}_3}^B}_{\varphi\otimes\psi} + \Braket{\Sigma_{\unitvec{n}_4}^A \otimes \Sigma_{\unitvec{n}_2}^B}_{\varphi\otimes\psi} + \Braket{\Sigma_{\unitvec{n}_4}^A \otimes \Sigma_{\unitvec{n}_3}^B}_{\varphi\otimes\psi} \right| \leq 2
\tag{\label{equation-56}}
\end{equation*}
$$

In contrast, for entangled states like $\ket{\Psi_-}$, quantum mechanics predicts a maximal violation:

$$
  \left| \Braket{\Sigma_{\unitvec{n}_1}^A \otimes \Sigma_{\unitvec{n}_2}^B}_{\Psi_-} - \Braket{\Sigma_{\unitvec{n}_1}^A \otimes \Sigma_{\unitvec{n}_3}^B}_{\Psi_-} + \Braket{\Sigma_{\unitvec{n}_4}^A \otimes \Sigma_{\unitvec{n}_2}^B}_{\Psi_-} + \Braket{\Sigma_{\unitvec{n}_4}^A \otimes \Sigma_{\unitvec{n}_3}^B}_{\Psi_-} \right| = 2\sqrt{2}
$$

Thus, Alice and Bob can test for eavesdropping by revealing the outcomes of the security test set. With the results $s_{\unitvec{n}_i}^X$, for $X\in\set{A,B}$ and $i\in\set{1,\dots,4}$, they calculate the empirical expectation values $\overline{\Sigma_{\unitvec{n}_i}^A \Sigma_{\unitvec{n}_j}^B}$. Consequently, Alice and Bob can conclude if eavesdropping has occured as follows

$$
  \left| \overline{\Sigma_{\unitvec{n}_1}^A \otimes \Sigma_{\unitvec{n}_2}^B} - \overline{\Sigma_{\unitvec{n}_1}^A \otimes \Sigma_{\unitvec{n}_3}^B} + \overline{\Sigma_{\unitvec{n}_4}^A \otimes \Sigma_{\unitvec{n}_2}^B} + \overline{\Sigma_{\unitvec{n}_4}^A \otimes \Sigma_{\unitvec{n}_3}^B} \right| = \begin{cases}
    \approx 2\sqrt{2} \implies \text{echange is secure}
    \leq 2 \implies \text{eavesdropping has occured}
  \end{cases}
$$

If the violation of the CHSH inequality is observed, the key bits from the identical-direction measurements are retained as a secure random key. If not, the protocol run is discarded, and Alice and Bob may attempt a new key exchange, potentially under a different setup.

# Quantum phase estimation

Quantum phase estimation (QPE) is an algorithm to estimate the phase $\phi\in [0,1)$ in the eigenvalue $e^{i2\pi\phi}$ of a unitary operator $\hat{U}\in\mathcal{U}(\mathcal{H})$. Since the eigenvalues of unitary operators have unit modulus and lie on the complex unit circle, they are characterized by their phase. If $\ket{u}\in\mathcal{H}$ is an eigenvector of $\hat{U}$, then it satisfies the eigenvalue equation

$$
  \hat{U}\ket{u} = e^{i2\pi\phi} \ket{u}
$$

The QPE algorithm uses two qubit registers initialized in the state $\ket{\Psi_0} = \ket{0}^{\otimes n} \otimes\ket{u}$:
1. The first register consists of $n\in \N_+$ qubits initialized in the zero state $\ket{0}^{\otimes n}$. The number of qubits $n$ determines the precision of the phase estimate and the probability for success.
2. The second register holds the eigenvector $\ket{u}$ of $\hat{U}$. If $\hat{U}$ is represented by an $\tilde{m}\times\tilde{m}$-matrix, then $\ket{u}$ belongs to an $\tilde{m}$-dimensional Hilbert space, requiring $m = \log_2 (\tilde{m})$ qubits

The phase estimation is performed in four steps:

1. **State preparation**

We first apply Hadamard gates $\hat{H}^{\otimes n}$ to each qubit in the first register $\ket{0}^{\otimes n}$, creating a uniform superposition

$$
\begin{align*}
  \ket{\Psi_1} =& (\hat{H}^{\otimes n} \otimes \hat{I}_m)\ket{\Psi_0} = \frac{1}{\sqrt{2^n}} (\ket{0} + \ket{1})^{\otimes n} \otimes \ket{u} \\
  =& \frac{1}{\sqrt{2^n}} \sum_{k=0}^{2^n - 1} \ket{k} \otimes\ket{u}
\end{align*}
$$

This step entangles the computational basis states $\ket{k}$ in the first register with the eigenstate $\ket{u}$ in the second.

2. **Controlled-$U$ operations**

Next, we apply a sequence of controlled unitary gates that implement $\hat{U}^{2^k}$ conditioned on the $k$-th qubit of the first register. The composition of controlled unitary gates can be expressed in the form

$$
  \hat{U}_\text{c} = \sum_{k=0}^{2^n - 1} \ket{k}\bra{k} \otimes \ket{U}^k
$$

Applying $\hat{U}_c$ to $\ket{\Psi_1}$ and using that $\hat{U}^k \ket{u} = e^{i2\pi\phi k} \ket{u}$, we obtain the state 

$$
\begin{align*}
  \ket{\Psi_2} =& \hat{U}_\text{c} \ket{\Psi_1} = \frac{1}{\sqrt{2^n}} \sum_{k=0}^{2^n - 1} \ket{k} \otimes \hat{U}^k \ket{u} \\
  =& \left(\frac{1}{\sqrt{2^n}} \sum_{k=0}^{2^n - 1} e^{i2\pi\phi k} \right) \otimes\ket{u} \\
  =& \frac{1}{\sqrt{2^n}} \left(\bigotimes_{k=0}^{2^n - 1} \ket{0} + e^{i2\pi 0_{.\phi_1,\dots,\phi_k}} \right)
\end{align*}
$$

From this point on, the second register remains unchanged. For convenience we write $\ket{\Psi_2} = \ket{\tilde{\Psi_2}} \otimes\ket{u}$, where the state of the first qubit register $\ket{\tilde{\Psi_2}}$ is the only we need to consider for the rest of the algorithm.

<details>
<summary>Details</summary>

Note that we can write $\hat{U}_C = \prod_{l=n-1}^0 \Lambda^l (\hat{U}^{2^l})$, where the action of each $\Lambda^l (\hat{U}^{2^l})$ is given by

$$
  \Lambda^l (\hat{U}^{2^l}) (\ket{j}\otimes\ket{u}) = \ket{j} \otimes \hat{U}^{j_l^k} \ket{u}
$$

The composition of these controlled gates thus gives

$$
  \prod_{l=n-1}^0 \Lambda^l (\hat{U}^{2^l}) (\ket{j}\otimes\ket{u}) = \ket{j} \otimes \hat{U}^{\sum_{l=n-1}^0 j_l 2^l} \ket{u}
$$
</details>

3. **Applying inverse quantum Fourier transform**

In the third step, we apply the inverse quantum Fourier transform $\hat{F}_{2^n}^\dagger$ to the first qubit register:

$$
\begin{align*}
  \ket{\tilde{\Psi_3}} =& \hat{F}^\dagger \ket{\tilde{\Psi_2}} = \frac{1}{\sqrt{2^n}} \sum_{k=0}^{2^n - 1} e^{i2\pi\phi k} \left(\frac{1}{\sqrt{2}} \sum_{j=0}^{2^n - 1} e^{-i2\pi kj/2^n} \ket{j} \right) \\
  =& \frac{1}{2^n} \sum_{j,k=0}^{2^n - 1} \exp\left(-i\frac{2\pi k}{2^n} (j - 2^n \phi) \right) \ket{j} \\
  =& \sum_{j=0}^{2^n - 1} c_j \ket{j}
\end{align*}
$$

Define $2^n \phi := b + 2^n \delta$, where $0 \leq b \leq 2^{n-1}$ is the integer such that $b/2^n = 0_{.b_{n-1},\dots,b_0}$ is the best $n$ bit approximation of $\phi$. The the amplitudes $c_j$ of each basis state $\ket{j}$ is

$$
\begin{align*}
  c_j :=& \frac{1}{2^n} \sum_{k=0}^{2^n - 1} \exp\left(-i\frac{2\pi k}{2^n} (j - 2^n \phi) \right) \\
  =& \frac{1}{2^n} \sum_{k=0}^{2^n - 1} \exp\left(-i\frac{2\pi k}{2^n} (j - b) \right) e^{i2\pi\delta k}
\end{align*}
$$

The difference $\delta = \phi - b/2^n$ satisfies $0 \leq\delta\leq 2^{-n}$. In particular, if $\delta = 0$, that is, when $\phi = b/2^n$ the probability amplitude becomes

$$
  c_j = \begin{cases}
    1,\quad& j = 2^n \phi \\
    0,\quad& j \neq 2^n \phi
  \end{cases}
$$

Since $\phi$ in this case is given by an $n$-bit binary fraction

$$
  \phi = \sum_{k=n-1}^0 \phi_k 2^{-(n - k + 1)}
$$

the inverse quantum Fourier transform yields $\ket{\tilde{\Psi}_3} = \ket{2^n \phi}$ with certainty. Thus, measuring $\ket{\tilde{\Psi}_3}$ in the computational basis returns $\ket{\phi_{n-1,\dots,\phi_0}}$, the $n$-bit binary representation of $\phi$ with probability $1$.

4. **Measurement:**

The final step involves measuring the first register $\ket{\tilde{\Psi_3}}$ in the computational basis. This yields an outcome $\ket{y}$ with probability

$$
  \Pr(y) = |c_y|^2 = \left| \frac{1}{2^n} \sum_{k=0}^{2^n - 1} \exp\left(-i\frac{2\pi k}{2^n} (j - b) \right) e^{i2\pi\delta k} \right|^2
$$

It follows that $\Pr(b) = 1$ if $\delta = 0$, that is, when $\phi = b/2^n$. If $\delta \neq 0$, the probability reads

$$
  \Pr(b) = \frac{1}{2^{2n}} \left| \sum_{k=0}^{2^n - 1} e^{2\pi i \delta k} \right|^2 = \frac{1}{2^{2n}} \left|\frac{1 - e^{i2\pi 2^n \delta}}{1 - e^{i2\pi\delta}} \right|^2
$$

From this expression we see that $\Pr(b) \geq 4/\pi^2$.

<details>
<summary>Proof</summary>

Recall that $|1 - e^{i2x}|^2 = 4|\sin(x)|^2$ since

$$
\begin{align*}
  |1 - e^{i2x}|^2 =& |1 - \underbrace{\cos(2x)}_{1 - \sin^2 (x)} - i\underbrace{\sin(2x)}_{2\sin(x)\cos(x)}|^2 \\
  =& 4|\sin^2 (x) - i\sin(x)\cos(x)|^2 = 4 |\sin(x)|^2 \cdot \underbrace{|\sin(x) - i\cos(x)|^2}_{=|e^{i(x - \pi/2)}|^2 = 1} \\
  =& 4 |\sin (x)|^2
\end{align*}
$$

To find a lower bound for $\Pr(b)$ we note that $|\delta| \leq 1/2^{n+1}$

$$
\begin{align*}
  \Pr(b) =& \frac{1}{2^{2n}} \left|\frac{1 - e^{i2\pi 2^n \delta}}{1 - e^{i2\pi\delta}} \right|^2 = \frac{1}{2^{2n}} \left|\frac{2\sin(\pi 2^n \delta)}{2\sin(\pi\delta)} \right|^2 \\
  =& \frac{1}{2^{2n}} \frac{|\sin(\pi 2^n \delta)|^2}{|\sin(\pi\delta)|^2}
\end{align*}
$$

Recall that
- $\sin(x) \leq x$ for small $x$
- $\sin(x) \geq \frac{2}{\pi} x$ for $x\in[0,\frac{\pi}{2}]$

Since $|\delta| \leq 1/2^{n+1}$ we find that
- $\sin(\pi) \leq \pi\delta$
- $\sin(\pi 2^n \delta) \geq \frac{2}{\pi} \pi 2^n \delta = 2^{n+1} \delta$

Hence, we obtain

$$
  \Pr(b) \geq \frac{1}{2^{2n}} \frac{|2^{n+1} \delta|^2}{|\pi\delta|^2} = \frac{4}{\pi}
$$
</details>

Let $e \in\N_+$ be the acceptable error tolerance for the estimation of $\phi$. The probability that the measurment $y$ deviates from $b$ by more than $e$, i.e $|y - b| > e$, is bounded by

$$
  \Pr(|y - b| > e) \leq \frac{1}{2(e - 1)}
$$

<details>
<summary>Proof</summary>

Let $\alpha_j$ be the amplitude of $\ket{(b + j) \bmod 2^n}$, i.e.

$$
  \alpha_j := \frac{1}{2^n} \sum_{k=0}^{2^n - 1} \left(e^{i2\pi(\phi - (b + j)/2^n)}\right)^k
$$

The probability of measuring a value $y$ such that $|y - b| > e$ is given by

$$
\begin{equation*}
  \Pr(|y - b| > e) = \sum_{-2^{n-1} < h \leq -(e+1)} |\alpha_j|^2 + \sum_{e + 1 \leq j \leq 2^{n-1}} |\alpha_j|^2 
\tag{\label{equation-57}}
\end{equation*}
$$

For any real $\phi\in\R$, we have $|1 - e^{i\phi}| \leq 2$, so

$$
  |\alpha_j| = \frac{2}{2^n |1 - e^{i2\pi (\delta - j/2^n)}}
$$

Whenever $\pi\in[-\pi, \pi]$, then $|1 - e^{i\phi}| \geq 2|\phi|/\pi$. For $-2^{n-1} < l \leq 2^{n-1}$ we have $-\pi \leq 2\pi(\delta - j/2^n) \leq \pi$. Thus

$$
\begin{equation*}
  |\alpha_j| \leq \frac{1}{2^{n+1} (\delta - j/2^n)}
\tag{\label{equation-58}}
\end{equation*}
$$

Combining $\eqref{equation-57}$ and $\eqref{equation-58}$ gives

$$
  \Pr(|y - b| > e) \leq \frac{1}{4} \left(\sum_{j=-2^{n-1} + 1}^{-(e+1)} \frac{1}{(j - 2^n \delta)^2} + \sum_{j=e+1}^{2^{n-1}} \frac{1}{(j - 2^n \delta)^2} \right)
$$

Recalling that $0 \leq 2^n \delta \leq 1$, we obtain

$$
\begin{align*}
  \Pr(|y - b| > e) \leq& \frac{1}{4} \left(\sum_{j=-2^{n-1} + 1}^{-(e+1)} \frac{1}{(j^2)} + \sum_{j=e+1}^{2^{n-1}} \frac{1}{(j - 1)^2} \right) \\
  \leq& \frac{1}{2} \sum_{l=e}^{2^{n-1} - 1} \frac{1}{j^2} \\
  \leq& \frac{1}{2} \int_{e-1}^{2^{n-1}- 1} \frac{\d j}{j^2} = \frac{1}{2(e - 1)}
\end{align*}
$$
</details>

To approximate $\phi$ to within $2^{-t}$ accuracy, we choose $e = 2^{n - t} - 1$. Then, the success probability is at least

$$
  \Pr\left(|\frac{y}{2^n} - \phi| \leq 2^{-t} \right) \geq 1 - \frac{1}{2(2^{n-t} - 2)}
$$

To ensure this success probability is least $1 - \epsilon$, we choose

$$
  n = t + \left\lceil \log_2 \left(2 + \frac{1}{2\epsilon} \right) \right\rceil
$$

This gives a relation between the number of qubits $n$, the desired presicion $t$ (number of bits of $\phi$), and the confidence level $1 - \epsilon$.

<LatexFigure width={75} src='/fig/quantum_phase_estimation.svg' alt=''
  caption='Quantum circuit for the quantum phase estimation algorithm'
>
```latex
\documentclass[tikz, border=5pt]{standalone}
\usepackage{quantikz}

\begin{document}
\begin{quantikz}[wire types={q,n,n,n,q,n,q,n,q}]
  \lstick[7]{$\ket{0}^{\otimes n}$} & \lstick{\ket{0}} \wireoverride{n} & \gate{H} &&& \ \ldots\ & \ctrl{8} & \ \frac{1}{\sqrt{2}}\left(\ket{0} + e^{i2\pi (2^{n-1} \phi)}\ket{1}\right) \ & \gate[7]{F^\dagger} & \meter{} \\[-0.2cm]
  & \lstick{\otimes} &&&&&&&& \\[-0.4cm]
  & \lstick{\vdots} &&&&&& \vdots && \\[-0.2cm]
  & \lstick{\otimes} &&&&&&&& \\[-0.2cm]
  & \lstick{\ket{0}} \wireoverride{n} & \gate{H} && \ctrl{4} & \ \ldots\ && \ \frac{1}{\sqrt{2}}\left(\ket{0} + e^{i2\pi (2^1 \phi)}\ket{1}\right) \ && \meter{} \\[-0.2cm]
  & \lstick{\otimes} &&&&&&&& \\[-0.2cm]
  & \lstick{\ket{0}} \wireoverride{n} & \gate{H} & \ctrl{2} && \ \ldots\ && \ \frac{1}{\sqrt{2}}\left(\ket{0} + e^{i2\pi (2^0 \phi)}\ket{1}\right) \ && \meter{} \\
  & \lstick{\otimes} &&&&&&& \\
  & \lstick{\ket{u}} \wireoverride{n} & \qwbundle{m}& \gate{U^{2^0}} & \gate{U^{2^1}} & \ \ldots\ & \gate{U^{2^{n-1}}} & \ \ket{u} & \setwiretype{n}
\end{quantikz}
\end{document}
```
</LatexFigure>

# Shor factorization algorithm

<MathBox title='Period of arithmetic functions' boxType='definition'>
The period $r\in\N_0$ of a function $f:N_0 \to \N_0$ is defined as

$$
  r := \min\set{m\in\N_0 | f(n + m) = f(n),\; \forall n\in\N_0}
$$
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-7'>
Let $b,N \in\N_0$ with $b < N$ and $\gcd(b,N) = 1$. Furthermore, let $r$ be the period of the function $f_{b,N} :\N_0 \to\N_0$ given by

$$
  f_{b,N} (n) := b^n \bmod N
$$

Then

$$
  r = \operatorname{ord}_N (b) = \min\set{m\in\N_+ | b^m \bmod N = 1}
$$

<details>
<summary>Proof</summary>

If $r$ is the period of $f$, it follows that $f_{b,N} (n + r) = f_{b,N} (n)$ for all $n\in\N_+$. In particular, for $n = 0$ it follows that

$$
\begin{equation*}
  b^r \bmod N = f_{b,N} (0 + r) = f_{b,N} (0) = 1
\tag{\label{equation-59}}
\end{equation*}
$$

By definition, the order $\operatorname{ord}_N (b)$ of $b$ modulo $N$ is the smallest number that satisfies $\eqref{equation-59}$. This implies

$$
  r \geq\operatorname{ord}_N (b)
$$

On the other hand, we have for all $n\in\N_0$ that

$$
\begin{align*}
  f_{b,N} (n + \operatorname{ord}_N (b)) =& b^{n + \operatorname{ord}_N (b)} \bmod N \\
  =& b^n (b^{\operatorname{ord}_N (b)} \bmod N) \bmod N \\
  =& b^n \bmod N \\
  =& f_{b,N} (n)
\end{align*}
$$

Since the period $r$ is the smallest number with the property $f_{b,N} (n + r) = f_{b,N} (n)$, it follows that

$$
  r \leq\operatorname{ord}_N (b)
$$

Consequently, it follows that $r = \operatorname{ord}_N (b)$.
</details>
</MathBox>

In 1994, Shor introduced a quantum algorithm for factoring an odd natural number $N\in\N_+$ with at least two distinct prime factors. The algorithm has a quantum computational complexity of

$$
  S_{\text{Shor}} (N) \in O(\log_2^3 (N) \log_2 (\log_2 (N))),\; N\to\infty
$$

which grows polynomially with the bit-length of the input. Shor's factorization algorithm for finding a non-trivial divisor of $N$ proceeds in the following three steps.

**Step 1: GCD test via Euclid's algorithm**

Choose a random integer $b\in\N_+$ with $b < N$. Using Euclid's algorithm we compute the greatest common divisor $\gcd(b, N)$. The number of arithmetic operations required scales as

$$
  S_\text{Shor1} \in O(\log_2^3 (N)),\; N\to\infty
$$

If $\gcd(b,N) > 1$, we have found a nontrivial factor of $N$, in which case the procedure is terminated with the factors $\gcd(b,N)$ and $N/\gcd(b,N)$. Otherwise for coprime $b$ and $N$ with $\gcd(b, N) = 1$, we proceed to the next step.

**Step 2: Quantum period finding**

Define the function $f_{b,N} :\N_0 \to\N_0$ given by

$$
  f_{b,N} (n) := b^n \bmod N
$$

If $\gcd(b, N) = 1$, Euler's theorem guarantees that $f_{b,N}$ is periodic with period $r \leq \phi(N) < \infty$, where $\phi:\N\to\N$ is Euler's totient function given by

$$
  \phi(n) := \left| \set{r\in{1,\dots,n-1} | \gcd(r,n) = 1} \right|
$$

In the second step we compute the period $r$ of $f_{b,N}$ using quantum phase estimation and continued fractions expansion. The nunmber of computational complexity of this step scales as

$$
  S_\text{Shor2} (N) \in O(\log_2^3 (N)),\; N\to\infty
$$

If $r$ is odd we repeat the first step with a different $b\in\N_+$. Otherwise if $r$ is even, we proceed to the next step.

**Step 3: Factoring via period doubling**

From Proposition $\ref{proposition-7}$, we have $r = \operatorname{ord}_N (b)$, which implies that $b^r \bmod N = 1$. By properties of modulus we have $(b^r - 1) \bmod N = 0$ or $N \mid b^r - 1$. If $r$ is even, we can factor $b^r - 1$ as a difference of squares, yielding

$$
\begin{equation*}
  (b^r - 1) \bmod N = 0 \iff N \mid (b^{r/2} + 1)(b^{r/2} - 1)
\tag{\label{equation-60}}
\end{equation*}
$$

which shows that $N$ shares common divisors with $b^{r/2} + 1$ or $b^{r/2} - 1$.

In the third step, we use Euclid's algorithm to compute either $\gcd(b^{r/2} - 1, N)$ or $\gcd(b^{r/2} + 1, N)$. The computational effort here also satisfies

$$
  S_\text{Shor3} (N) \in O(\log_2^3 (N)^3),\; N\to\infty
$$

By minimality of $r$, we exclude $\gcd(b^{r/2} - 1, N) = N$ as a possible solution. This would imply $b^{r/2} \bmod N = 1$, meaning that $r/2$ is a period of $f_{b,N}$, contradicting the assumption that $r$ is the smallest period. If $\gcd(b^{r/2} + 1, N) = N$, then $(b^{r/2} + 1) \bmod N = 0$, giving the trivial factor $N$. 

We succeed if $\gcd(b^{r/2} \pm 1, N) < N$, in which case $b$ is a nontrivial factor of $N$ and the procedure terminates with the factors $b$ and $N/b$.

Shor's algorithm can be summarized as follows:

- **Input:** An odd natural number $N\in\N_+$ that has at least two distinct prime factors
- **Step 1:** Choose $b\in\N_+$ with $b < N$ and determine $\gcd(b, N)$ using Euclid's algorithm with complexity. If
    - $\gcd(b,N) > 1$, then $\gcd(b, N)$ is a non-trivial factor of $N$ and we are done. Go to output and show $\gcd(b,N)$ and $N/\gcd(b,N)$
    - $\gcd(b, N) = 1$ then got to step 2
- **Step 2:** Determine the period $r$ of the function $f_{b,N}: \N_0 \to \N_0$ given by $f_{b,N} (n) = b^n \bmod N$. If
    - $r$ is odd, then start anew with step 1
    - $r$ is even, then go to step 3
- **Step 3:** Determine $\gcd(b^{r/2} + 1, N)$. If
    - $\gcd(b^{r/2} + 1, N) = N$, then start anew with step 1
    - $\gcd(b^{r/2} + 1, N) < N$, then we have found a non-trivial factor of $N$. Calculate $\gcd(b^{r/2} - 1, N)$ as a further factor of $N$. Go to output and show $\gcd(b^{r/2} \pm 1, N)$
- **Output:** Two nontrivial factors of $N$

## Quantum period-finding algorithm (step 2)

Quantum circuits can be used to determine the period of a function $f:\N_0 \to\N_0$ provided the following conditions are satifies
1. **Efficient unitary implementation:** The function $f$ can be implemented as a unitary operator $\hat{U}_f$ on a suitable Hilbert space, and the number of computational steps $S_{U_f}$ required to apply $\hat{U}_f$ is suitably bounded
2. **Period bound:** The period $r$ of $f$ is bounded above by 
$$
\begin{equation*}
  r < 2^{L/2}
\tag{\label{equation-75}}
\end{equation*}
$$
for some known number $L\in\N_+$.

3. **Injectivity within a period:** The function $f$ is injective on each period, i.e. $f(n) = f(m)$ implies $n \equiv m \bmod r$.

Given these conditions, the quantum period-finding algorithm proceeds in two main steps:
1. **Quantum phase estimation**

Apply quantum phase estimation using a unitary gate $\hat{U}_{f_{b,N}}$ that implements the function $f_{b,N} :\N_0 \to\N_0$ given by
$$
  f_{b, N} (n) = b^n \bmod N 
$$
for a randomly chonse base $b\in\set{2,\dots,N-1}$. The gate $\hat{U}_{f_{b,N}}$ acts on the initial state $\ket{0}^{\otimes 2n} \otimes \ket{1}$, where the second register $\ket{1}$ is expressible as a superposition of eigenvectors of $\hat{U}_{f_{b,N}}$. The phase estimation yields, with high probability, a measurement outcome close to a rational number of the form 
$$
  \frac{j}{r} 2^{2n}
$$ 
for some uniformly random $j\in\set{0,\dots, r - 1}$.

2. **Continued fractions algorithm** 

The measurement outcome is classically post-processed using the continued fractions algorithm to recover the unknown period $r$, provided $\gcd(j,r) = 1$. 

<MathBox title='' boxType='lemma' tag='lemma-5'>

$$
  \operatorname{tr}(\ket{\Psi}_3 \bra{\Psi}_3 (\ket{z}\bra{z} \otimes\hat{I}^{\otimes K})) = \Norm{(\ket{z}\bra{z} \otimes\hat{I}^{\otimes K})\ket{\Psi_3}}^2
$$

<details>
<summary>Proof</summary>

</details>
</MathBox>

<MathBox title="Rosser-Schoenfeld bound" boxType='theorem' tag='theorem-2'>
For $r \geq 3$, the following inequality holds

$$
  \frac{r}{\phi(r)} < e^\lambda \ln(\ln(r)) + \frac{2.50637}{\ln(\ln(r))}
$$

where $\gamma := 0.5772156649\dots$ denotes Euler's constant.
</MathBox>

<MathBox title='' boxType='theorem'>
Let $r, L, K\in\N_+$ such that $19 \leq r < 2^{L/2}$, and suppose $r$ is the period of a function $f:\N_0 \to\N_0$, which is is injective on each period and bounded by $f(x) < 2^K$ for all $x$. Furthermore, let $\hat{U}_f: {}^\P \mathcal{H}^{\otimes L} \otimes \mathcal{H}^{\otimes K} \to \mathcal{H}^{\otimes L} \otimes \mathcal{H}^{\otimes K}$ be a unitary operator implementing $f$ via the mapping

$$
  \ket{x}\times\ket{y} \mapsto \ket{x}\otimes \ket{y \boxplus f(x)}
$$

where $\boxplus$ denotes addition modulo $2^K$. Assume that the implementation of $\hat{U}_f$ requires $S_{U_f} (L) \in O(L^{K_f})$ computational steps as $L\to\infty$, for some $K_f \in\N_+$.

Then there exists a quantum algorithm $A$ that determines the period $r$ with success probability at least $1/10\ln(L)$, and whose computational complexity satisfies

$$
  S_A (L) \in O(L^{\max\set{K_f, 3}}),\; L\to\infty
$$

<details>
<summary>Proof</summary>

To find the computational complexity $S_A (L)$ for determining the period $r$ of $f$. We consider each of the five steps of $A$. 

1. **Preparation of the input register and the initial state**

Let $M := \max\set{f(x) | x\in\set{0,\dots, 2^L - 1}}$, choose $K\in\N_+$ such that $M < 2^k$. Define two qubit registers

$$
  \mathcal{H}^A := {}^\P \mathcal{H}^{\otimes L},\quad \mathcal{H}^B := {}^\P \mathcal{H}^{\otimes K} 
$$

where $\mathcal{H}^A$ is the input register and $\mathcal{H}^B$ is the output register used to store evaluations of $f$. The initial state of the system, $\ket{\Psi_0}\in\mathcal{H}^A \otimes \mathcal{H}^B$, is prepared in the zero computational basis state:

$$
  \ket{\Psi_0} := \ket{0}^A \otimes \ket{0}^B = \ket{0}^{\otimes L} \otimes \ket{0}^{\otimes K}
$$

Next, we apply the Hadamard transform, $\hat{H}^{\otimes L}$ to the input register $\mathcal{H}^A$, producing the state

$$
  \ket{\Psi_1} := \hat{H}^{\otimes L} \otimes \hat{I}^{\otimes K} \ket{\Psi_0} = \frac{1}{2^{L/2}} \sum_{x=0}^{2^L - 1} \ket{x}^{\otimes L} \otimes \ket{0}^{\otimes K}
$$

in which the input register is put in a uniform superposition entangled with the output register.

Since the application of $\hat{H}^L$ involves $L$ Hadamard gates, the computational steps of preparing $\ket{\Psi_1}$, denoted $S_0 (L)$, is proportional to $L$:

$$
  S_0 (L) \in O(L),\; L\to\infty
$$

2. **Exploiting massive quantum parallelism**

We now apply the unitary operator $\hat{U}_f \in\mathcal{U}(\mathcal{H}^A \otimes \mathcal{H}^B)$, which acts as follows

$$
\begin{align*}
  \hat{U}_f (\ket{x}^{\otimes L} \otimes \ket{y}^{\otimes K}) = \ket{x}^{\otimes L} \otimes \ket{y \boxplus f(x)}^{\otimes K} \\
  =& \ket{x}^{\otimes L} \otimes \bigotimes_{j=K-1}^0 \ket{y_j \overset{2}{\oplus} f(x)}_j
\end{align*}
$$

The number of computational steps for performing $\hat{U}_f$, denoted $S_{U_f} (L)$ satisfies

$$
  S_{U_f} (L) \in O(L^{K_f}),\; L\to\infty
$$

for some constant $K_f \in\N_+$. 

Applying $\hat{U}_f$ to $\ket{\Psi_1}$ yields

$$
\begin{align*}
  \ket{\Psi_2} :=& \hat{U}_f \ket{\Psi_1} \\
  =& \hat{U}_f \left(\frac{1}{2^{L/2}} \sum_{x=0}^{2^L - 1} \ket{x}^{\otimes L} \otimes\ket{0}^{\otimes K} \right) \\
  =& \frac{1}{2^{L/2}} \sum_{x=0}^{2^L - 1} \ket{x}^{\otimes L} \otimes \ket{f(x)}^{\otimes K}
\end{align*}
$$

This generates a superposition over all $2^L$ states $\ket{x}\otimes\ket{f(x)}$, which allows evaluation of exponentially many values of $f(x)$ simultaneously.

The period of $f$ can be determined by applying the quantum Fourier transform to $\ket{\Psi_2}$. We rewrite $\ket{\Psi_2}$ to reflect the periodicity of $f$. Let $r\in\N_+$ be the (unknown) period of $f$, and define

$$
\begin{align*}
  J := \left\lfloor\frac{2^L - 1}{r}\right\rfloor \tag{\label{equation-61}} \\
  R := (2^L - 1) \bmod r \tag{\label{equation-62}}
\end{align*}
$$

This partitions the domain $\set{0,\dots,2^L - 1}$ into $J$ complete periods and a final incomplete segment of length $R + 1$. Using this, we can regroup the terms in $\ket{\Psi_2}$ as

$$
\begin{align*}
  &\ket{\Psi_2} \\
  =& \frac{1}{2^{L/2}} \left[ \ket{0}^{\otimes L} \otimes \ket{f(0)}^{\otimes K} +\cdots+ \ket{r - 1}^{\otimes L} \otimes\ket{f(r - 1)}^{\otimes K} \right. \\
  &+ \ket{r}^{\otimes L} \otimes \underbrace{\ket{f(r)}^{\otimes K}}_{=\ket{f(0)}^{\otimes K}} +\cdots+ \ket{2r - 1}^{\otimes L} \otimes\underbrace{\ket{f(2r - 1)}^{\otimes K}}_{=\ket{f(r - 1)}^{\otimes K}} \\
  &\vdots \\
  &+ \ket{(J - 1)r}^{\otimes L} \otimes\underbrace{\ket{f((J-1)r)}^{\otimes K}}_{=\ket{f(0)}^{\otimes K}} +\cdots+ \ket{Jr - 1}^{\otimes L} \otimes\underbrace{\ket{f((Jr - 1))}^{\otimes K}}_{=\ket{f(r - 1)}^{\otimes K}} \\
  &+ \left. \ket{Jr}^{\otimes L} \otimes\underbrace{\ket{f(Jr)}^{\otimes K}}_{=\ket{f(0)}^{\otimes K}} +\cdots+ \ket{Jr + R}^{\otimes L} \otimes\underbrace{\ket{f(Jr + R)}^{\otimes K}}_{=\ket{f(R)}^{\otimes K}} \right] \\
  =& \frac{1}{2^{L/2}} \left[\sum_{j=0}^{J-1} \sum_{k=0}^{r - 1} \ket{jr + k}^{\otimes L} \otimes\ket{f(k)}^{\otimes K} + \sum_{k=0}^R \ket{Jr + k}^{\otimes L} \otimes\ket{f(k)}^{\otimes K} \right]
\end{align*}
$$

To further streamline notation, define for each $k\in\N_0$ the integer $J_k \in\N_0$ by

$$
\begin{equation*}
  J_k := \begin{cases}
    J,\quad& k \leq R \\
    J-1, \quad& k > R
  \end{cases}
\tag{\label{equation-63}}
\end{equation*}
$$

This allows us to express $\ket{\Psi_2}$ compactly as

$$
  \ket{\Psi_2} = \frac{1}{2^{L/2}} \sum_{k=0}^{r-1} \sum_{j=0}^{J_k} \ket{jr + k}^{\otimes L} \otimes\ket{f(k)}^{\otimes K}
$$

This representation makes the periodicity of $f$ explicit, as each value $f(k)$ appears in the second register, paired with inputs of the form $x = jr + k$ for suitable $j$. The structure of this state is key to the success of the quantum Fourier transform in revealing information about the unknown period $r$.

3. **Application of the quantum Fourier transform**

The quantum Fourier transform $\hat{F}:\mathcal{H}^A \to \mathcal{H}^A$ is given by

$$
  \ket{F}\ket{x} = \frac{1}{2^{L/2}} \sum_{y=0}^{2^L - 1} \exp\left(i2\pi \frac{xy}{2^L} \right) \ket{y}
$$

Applying $\hat{F}$ to the input register $\mathcal{H}^A$ of $\ket{\Psi_2}$, yields the state

$$
\begin{align*}
  \ket{\Psi_3} :=& (\hat{F}\otimes\hat{I}^{\otimes K}) \ket{\Psi_2} \\
  =& (\hat{F}\otimes\hat{I}^{\otimes K}) \left(\frac{1}{2^{L/2}} \sum_{k=0}^{r - 1} \sum_{j=0}^{J_k} \ket{jr + k}^{\otimes L} \otimes\ket{f(k)}^{\otimes K} \right) \\
  =& \frac{1}{2^{L/2}} \sum_{k=0}^{r-1} \sum_{j=0}^{J_k} \hat{F}\ket{jr + k}^{\otimes L} \otimes \ket{f(k)}^{\otimes K} \\
  =& \frac{1}{2^L} \sum_{k=0}^{r-1} \sum_{j=0}^{J_k} \sum_{l=0}^{2^L - 1} \exp\left(i2\pi \frac{l}{2^L} (jr + k) \right) \ket{l}^{\otimes L} \otimes\ket{f(k)}^{\otimes K}
\end{align*}
$$

The phase amplitudes of the states $\ket{l}^{\otimes L}$ reveal intereference patterns that encode information about the period $r$. Specifically, for fixed $k$, the sum over $j$ gives a geometric series in the phase factor $\exp(i2\pi lr/2^L)$, leading to constructive interference at certain values of $l$ that are close to integer multiples of $2^L /r$. These are the outcomes that are most likely to be observed upon measurement.

By Corollary $\ref{corollary-2}$, the quantum Fourier transform can be implemented with computational complexity

$$
  S_\text{F} (L) \in O(L^2),\; L\to\infty
$$

4. **Probability in measurement of the input register**

In the next step of the algorithm, we observe the input register $\mathcal{H}^A$, ignoring the subsystem $\mathcal{H}^B$. This measurement projects the superposition state $\ket{\Psi_3}$ onto a computational basis state $\ket{z}\in\mathcal{H}^A$ with value $z\in\set{0,\dots,2^L -1}$. The composite system is in the pure state $\ket{\Psi_3}$, whose associated density operator is

$$
  \hat{\rho}_{\Psi_3} = \ket{\Psi_3}\bra{\Psi_3}
$$

Focusing on the subsystem $\mathcal{H}^A$, its reduced state is given by taking the partial trace over $\mathcal{H}^B$:

$$
  \hat{\rho}^A (\hat{\rho}_{\Psi_3}) = \operatorname{tr}_B (\ket{\Psi_3}\bra{\Psi_3})
$$

The probability of observing a computational state $\ket{z}\in\mathcal{H}^A$ when measuring $\ket{\Psi_3}$, is given by

$$
\begin{align*}
  W(z) =& \operatorname{tr}(\hat{\rho}^A (\hat{\rho}_{\Psi_3}) \ket{z}\bra{z}) \\
  =& \operatorname{tr}\left(\operatorname{tr}_B (\ket{\Psi_3}\bra{\Psi_3}) \ket{z}\bra{z} \right) \\
  =& \operatorname{tr}(\ket{\Psi_3}\bra{\Psi_3}(\ket{z}\bra{z} \otimes\hat{I}^{\otimes K}))
\end{align*}
$$

Applying Lemma $\ref{lemma-5}$, we express this as the squared norm of the projected state:

$$
\begin{align*}
  W(z) =& \Norm{(\ket{z}\bra{z} \otimes\hat{I}^{\otimes K})\ket{\Psi}_3}^2 \\
  =& \Norm{\frac{1}{2^L} \sum_{k=0}^{r-1} \sum_{j=0}^{J_k} \exp\left(i2\pi\frac{z}{2^L} (jr + k)\right) \ket{z}^{\otimes L} \otimes\ket{f(k)}^{\otimes K}}^2 \\
  =& \frac{1}{2^L} \sum_{k_1, k_2 = 0}^{r-1} \sum_{j_1, j_2 = 0}^{J_{k_1}, J_{k_2}} \exp\left(i2\pi\frac{z}{2^L} [(j_2 - j_1)r + k_2 - k_1] \right) \underbrace{{}^{\otimes L} \braket{z|z}^{\otimes L}}_{=1} \underbrace{{}^{\otimes K} \braket{f(k_1)|f(k_2)}^{\otimes K}}_{=\delta_{k_1, k_2}} \\
  =& \frac{1}{2^L} \sum_{k=0}^{r-1} \left|\sum_{j=0}^{J_k} \exp\left(i2\pi \frac{zrj}{2^L} \right) \right|^2 \tag{\label{equation-74}}
\end{align*}
$$

Since $f$ is injective within each period, the states $\ket{k}$ are orthonormal for distinct $0 \leq k \leq r$, and so $\braket{f(k_1)|f(k_2)} = \delta_{k_1,k_2}$. Using the identity (for $a\in\mathbb{C}$)

$$
  \sum_{j=0}^D a^j = \begin{cases}
    D + 1,\quad& a=1 \\
    \frac{1 - a^{D+1}}{1-a},\quad a\neq 1
  \end{cases}
$$

the geometric series of $\eqref{equation-74}$ becomes

$$
  \sum_{j=0}^{J_k} \exp\left(i2\pi \frac{zrj}{2^L}\right) = \begin{cases}
    J_k + 1,\quad& \frac{zr}{2^L}\in\N_0 \\
    \frac{1 - \exp\left(i2\pi \frac{zr(J_k + 1)}{2^L} \right)}{1 - \exp\left(i2\pi\frac{zr}{2^L}\right)},\quad& \text{else}
  \end{cases}
$$

Substituting into $W(z)$, we find

$$
\begin{equation*}
  W(z) = \begin{cases}
    W_1 (z) := \frac{1}{2^{2L}} \sum_{k=0}^{r-1} (J_k + 1)^2,\quad \frac{zr}{2^L}\in\N_0 \\
    W_2 (z) := \frac{1}{2^{2L}} \sum_{k=0}^{r-1} \left|\frac{1 - \exp\left(i2\pi \frac{zr(J_k + 1)}{2^L} \right)}{1 - \exp\left(i2\pi\frac{zr}{2^L}\right)}\right|^2
  \end{cases}
\tag{\label{equation-64}}
\end{equation*}
$$

The success of the quantum phase estimation hinges on measuring a value $z$ such there there exists $l\in\N_0$ satisfying

$$
\begin{equation*}
  |zr - l2^L| \leq \frac{r}{2}
\tag{\label{equation-60}}
\end{equation*}
$$

To determine how often such a $z$ is observed, we seek a lower bound of $W(z)$ under this constraint.

**Case 1: $zr/2^L \in\N_0$**

In the case $zr/2^L \in\N_0$, where in addition $m =: 2^L/r \in\N_+$, we have 

$$
  W(z) = \begin{cases}
    \frac{1}{r},\quad& \frac{z}{m}\in\N_+ \\
    0,\quad& \text{else}
  \end{cases}
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-61}$, we obtain

$$
  J = \left\lfloor m - \frac{1}{r}\right\rfloor = m - 1
$$

and from $\eqref{equation-62}$, we fin

$$
\begin{align*}
  R =& 2^L - 1 \bmod r \\
  =& 2^L - 1 \left\lfloor\frac{2^L - 1}{r}\right\rfloor r \\
  =& 2^L - 1 - (m - 1)r = r - 1
\end{align*}
$$

Furthermore, with $\eqref{equation-63}$, we have for all $k\in\N_+$ with $0 \leq k < r-1 = R$ that

$$
  J_k = J = m - 1
$$

Inserting this into $\eqref{equation-64}$ yields

$$
\begin{align*}
  W(z) =& \begin{cases} 
    \frac{1}{2^{2L}} \sum_{k=0}^{r-1} m^2, \quad& \frac{z}{m}\in\N_+ \\
    \frac{1}{2^{2L}} \sum_{k=0}^{r-1} \left|\frac{1 - \exp\left(i2\pi \frac{z}{m}m \right)}{1 - \exp\left(i2\pi\frac{z}{m} \right)} \right|^2,\quad& \text{else}
  \end{cases} \\
  =& \begin{cases}
    \frac{1}{2^{2L}} \left(\frac{2^L}{r}\right)^2,\quad& \frac{z}{m}\in\N_+ \\
    0,\quad& \text{else}
  \end{cases} \\
  =& \begin{cases}
    \frac{1}{r},\quad& \frac{z}{m}\in\N_+ \\
    0,\quad& \text{else}
  \end{cases}
\end{align*}
$$
</details>

In contrast, if $2^L/r \notin\N_+$, then from $\eqref{equation-63}$, we obtain

$$
\begin{align*}
  \frac{1}{2^{2L}} \sum_{k=0}^{r-1} (J_k + 1)^2 =& \frac{1}{2^{2L}} \left(\sum_{k=0}^R (J_k + 1)^2 + \sum_{k=R+1}^{r-1} (J_k + 1)^2 \right) \\
  =& \frac{1}{2^{2L}} \left[(R + 1) \left(\left\lfloor\frac{2^L - 1}{r}\right\rfloor + 1\right)^2 + (r - 1 - R) \left\lfloor\frac{2^L - 1}{r}\right\rfloor^2 \right] \\
  \geq& \frac{1}{r}\left(\frac{r}{2^L} \left\lfloor\frac{2^L - 1}{r}\right\rfloor \right)^2
\end{align*}
$$

Note that

$$
\begin{align*}
  r - 1 \geq& (2^L - 1) \bmod r \\
  =& (2^L - 1) - \left\lfloor\frac{2^L - 1}{r}\right\rfloor r
\end{align*}
$$

implies that

$$
\begin{equation*}
\begin{split}
  \frac{r}{2^L} \left\lfloor\frac{2^L - 1}{r}\right\rfloor =& 1 - \frac{1 + (2^L - 1)\bmod r}{2^L} \\
  \geq& 1 - \frac{r}{2^L} > 1 - \frac{1}{2^{L/2}} 
\end{split}
\tag{\label{equation-65}}
\end{equation*}
$$

From $\eqref{equation-64}$, $\eqref{equation-60}$ and $\eqref{equation-65}$, we thus have for the case $zr/2^L \in\N_+$ that

$$
\begin{align*}
  W_1 (z) \geq& \frac{1}{r} (1 - \frac{1}{2^{L/2}})^2 \\
  >& \frac{1}{r}\left(1 - \frac{1}{2^{L/2 - 1}} \right)
\end{align*}
$$

**Case 2: $zr/2^L \notin\N_+$**

In the case $zr/2^L \notin\N_+$, then from $\eqref{equation-64}$ we express $W(z)$ as

$$
\begin{align*}
  W_2 (z) =& \frac{1}{2^{2L}} \sum_{k=0}^{r-1} \left|\frac{1 - \exp\left(i2\pi \frac{zr}{2^{L}} (J_k + 1) \right)}{1 - \exp(i2\pi \frac{zr}{2^L})}\right|^2 \\
  =& \frac{1}{2^{2L}} \sum_{k=0}{r-1} \left|\frac{1 - \exp\left(i2\pi \frac{zr - l2^L}{2^{L}} (J_k + 1) \right)}{1 - \exp(i2\pi \frac{zr}{2^L})}\right|^2 \\
  =& \frac{1}{2^{2L}} \sum_{k=0}^{r-1} \left(\frac{\sin\left(\pi \frac{zr - l2^L}{2^L} (J_k + 1) \right)}{\sin(\pi\frac{zr}{2^L})} \right)^2 \\
  =& \frac{1}{2^{2L}} \sum_{k=0}^{r-1} s(\alpha)^2
\end{align*}
$$

where

$$
\begin{align*}
  s(\alpha) :=& \frac{\sin(\alpha \tilde{J}_k)}{\sin(\alpha)} \\
  \alpha :=& \pi\frac{zr - l2^L}{2^L} \\
  \tilde{J}_k :=& J_k + 1
\end{align*}
$$

By $\eqref{equation-60}$, it follows that $\alpha$ satisfies

$$
\begin{equation*}
\begin{split}
  |\alpha| =& \frac{\pi}{2^L} (zr - l2^L) \\
  \leq& \frac{\pi}{2^L} \frac{r}{2} \\
  <& \frac{\pi}{2^L} 2^{L/2 - 1} \\
  =& \frac{\pi}{2^{L/2 + 1}} \ll \frac{\pi}{2}
\end{split}
\tag{\label{equation-66}}
\end{equation*}
$$

while $\tilde{J}_k$ satisfies

$$
\begin{align*}
  |\tilde{J}_k| =& J_k + 1 \leq J + 1 \\
  =& \left\lfloor\frac{2^L - 1}{r}\right\rfloor + 1 \\
  \leq& \frac{2^L - 1}{r} + 1 < \frac{2^L}{r} + 1
\end{align*}
$$

It follows that $\alpha \tilde{J}_k$ is bounded by

$$
\begin{equation*}
\begin{split}
  |\alpha\tilde{J}_k| <& \frac{\pi}{2^L} \frac{r}{2} \left(\frac{2^L}{r} + 1 \right) \\
  <& \frac{\pi}{2}\left(1 + \frac{1}{2^{L/2}} \right)
\end{split}
\tag{\label{equation-67}}
\end{equation*}
$$

To obtain a lower bound for the probability $W_2$, we determine a lower bound of the function $s(\alpha)$ for a suitable interval of $\alpha$.

If $|\alpha| \leq\alpha_\text{min}$ with $\alpha_\text{min} = \pi r/2^{L+1}$ then

$$
  s(\alpha)^2 \geq s(\alpha_\text{min})^2
$$

<details>
<summary>Proof</summary>

For $n\in\N_0$, Euler's formula gives

$$
\begin{align*}
  e^{in\alpha} =& \cos(n\alpha) + i\sin(n\alpha) \\
  =& (\cos (\alpha) + i\sin(\alpha))^n = (e^{i\alpha})^n
\end{align*}
$$

Equating the imaginary parts yields

$$
  \sin(n\alpha) = \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} \cos^{n-2l - 1} (\alpha) \sin^{2l + 1}(\alpha)
$$

Dividing by $\sin(\alpha)$, we obtain

$$
  \frac{\sin(n\alpha)}{\sin(\alpha)} = \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} \cos^{n-2l - 1} (\alpha) \sin^{2l}(\alpha)
$$

with first derivative

$$
\begin{align*}
  \left(\frac{\sin(n\alpha)}{\sin(\alpha)}\right)' =& \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} (n - 2l - 1) \cos^{n-2l - 2} (\alpha) \sin^{2l + 1}(\alpha) \\
  &+ \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} 2l \cos^{n-2l} (\alpha) \sin^{2l - 1} (\alpha) 
\end{align*}
$$

and second derivative

$$
\begin{align*}
  \left(\frac{\sin(n\alpha)}{\sin(\alpha)}\right)'' =& \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} (n - 2l - 1)(n - 2l - 2) \cos^{n-2l - 3} (\alpha) \sin^{2l + 2}(\alpha) \\
  &- \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} (n - 2l - 1)(2l + 1) \cos^{n-2l-1} (\alpha) \sin^{2l} (\alpha) \\
  &+ \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} 2l (2l - 1) \cos^{n - 2l + 1} (\alpha) \sin^{2l - 2} (\alpha) \\
  &- \sum_{l=0}^{\lfloor n/2 \rfloor} (-1)^l \binom{n}{2l + 1} 2l (n - 2l) \cos^{n - 2l - 1} (\alpha) \sin^{2l} (\alpha)
\end{align*}
$$

At $\alpha = 0$, we thus have

$$
\begin{align*}
  \left.\frac{\sin(n\alpha)}{\sin(\alpha)}\right|_{\alpha=0} =& n \\
  \left.\left(\frac{\sin(n\alpha)}{\sin(\alpha)}\right)' \right|_{\alpha=0} =& 0 \\
  \left.\left(\frac{\sin(n\alpha)}{\sin(\alpha)}\right)'' \right|_{\alpha=0} =& \frac{n}{3}(1 - n^2) \\
\end{align*}
$$

Now consider $s(\alpha) = \frac{\sin(\alpha\tilde{J}_k)}{\sin(\alpha)}$, where $\tilde{J}_k \in\N_+$. Assuming $L > 2$, we have

$$
\begin{align*}
  \tilde{J}_k =& J_k + 1 \geq \left\lfloor\frac{2^L - 1}{r}\right\rfloor \\
  >& \left\lfloor\frac{2^{L/2} - \frac{1}{r}}{r}\right\rfloor > 1
\end{align*}
$$

At $\alpha = 0$, we find

$$
\begin{align*}
  s(0) =& \tilde{J}_k \\
  s'(0) =& 0 \\
  s''(0) =& \frac{\tilde{J}_k}{3} (1 - \tilde{J}_k) < 0
\end{align*}
$$

This shows that $s$ has a strict local maximum at $\alpha = 0$. To prove that this is only maximum within the interval $[-\alpha_\text{min}, \alpha_\text{min}]$, we evaluate the derivate of $s(\alpha)$

$$
\begin{equation*}
  s'(\alpha) = \frac{\tilde{J}_k \cos(\alpha\tilde{J}_k) \sin(\alpha) - \sin(\alpha\tilde{J}_k) \cos(\alpha)}{\sin^2 (\alpha)}
\tag{\label{equation-68}}
\end{equation*}
$$

and show that $s'(\alpha) < 0$ for all $\alpha\in(0,\alpha_\text{min}]$. By the symmetry of $s$ about $\alpha = 0$, i.e. $s(-\alpha) = s(\alpha)$. It thus follows that $s'(\alpha) > 0$ for all $\alpha\in[-\alpha_\text{min}, 0)$.

Note that $s'(\alpha) < 0$ for $\alpha\tilde{J}_k = \frac{\pi}{2}$. Suppose now that $\alpha\in\left(0, \frac{\pi r}{2^{L+1}} \right)$ and $\alpha\tilde{J}_k \neq \frac{\pi}{2}$. From $\eqref{equation-66}$ and $\eqref{equation-67}$, we get the upper bounds

$$
\begin{align*}
  \alpha <& \frac{\pi}{2^{L/2 + 1}} \\
  \alpha\tilde{J}_k <& \frac{\pi}{2} + \frac{\pi}{2^{L/2 + 1}}
\end{align*}
$$

This implies that in the case $\alpha\tilde{J}_k < \frac{\pi}{2}$ as well as $\alpha\tilde{J}_k > \frac{\pi}{2}$, we have

$$
  \tan(\alpha) < \tan(\alpha\tilde{J}_k)
$$

so that

$$
\begin{align*}
  \tilde{J}_k \tan(\alpha)' =& \tilde{J}_k (1 + \tan^2 (\alpha)) \\
  <& \tilde{J}_k (1 + \tan^2 (\alpha\tilde{J}_k)) = \tan(\alpha\tilde{J}_k)'
\end{align*}
$$

This implies

$$
  \tilde{J}_k \cos(\alpha\tilde{J}_k) \sin(\alpha) < \sin(\alpha\tilde{J}_k) \cos(\alpha)
$$

and from $\eqref{equation-68}$, it follows that  $s'(\alpha) < 0$ for all $\alpha\in\left(0, \alpha_\text{min} \right]$. By symmetry, $s'(\alpha) > 0$ for $\alpha\in\left[-\frac{\pi r}{2^{L+1}}, 0 \right)$. Thus, $s(\alpha)$ strictly decreases away from $\alpha = 0$ in both directions within $[-\alpha_\text{min}, \alpha_\text{min}]$. Since $s(\alpha) \geq 0$ in this interval, it follows that $s(\alpha)^2 \geq s(\alpha_\text{min})^2$ for all $|\alpha| \leq\alpha_\text{min}$.
</details>

Thus,

$$
  s(\alpha)^2 \geq \frac{\sin^2 \left(\frac{\pi r}{2^{L + 1} (J_k + 1)} \right)}{\sin^2 \left( \frac{\pi r}{2^{L + 1}} \right)}
$$

and since $\sin^2 (x) \leq x$, it follows that

$$
  s(\alpha)^2 \geq \left(\frac{2^{L + 1}}{\pi r} \right)^2 \sin^2 \left(\frac{\pi r}{2^{L + 1} (J_k + 1)} \right)
$$

The definitions $\eqref{equation-61}$, $\eqref{equation-62}$ and $\eqref{equation-63}$ imply

$$
\begin{align*}
  \left\lfloor\frac{2^L - 1}{r}\right\rfloor \leq& J_k + 1 \\
  \implies \underbrace{\frac{r}{2^L} \left\lfloor\frac{2^L - 1}{r}\right\rfloor}_{=1 - \frac{R + 1}{2^L}} \leq& \frac{r}{2^L} (J_k + 1) \\
  \implies 1 - \frac{R + 1}{2^L} \leq& \frac{r}{2^L} (J_k + 1) \\
  \implies 1 - \frac{r}{2^L} \leq& \frac{r}{2^L} (J_k + 1)
\end{align*}
$$

such that

$$
  s(\alpha)^2 \geq \frac{2^{2L + 2}}{\pi^2 r^2} \sin^2 \left(\frac{\pi}{2}\left(1 - \frac{r}{2^L} \right) \right)
$$

Moreover, we have

$$
\begin{align*}
  \sin\left(\frac{\pi}{2}(1 + x) \right) =& \cos\left(\frac{\pi x}{2}\right) \\
  =& \sum_{j=0}^\infty \frac{(-1)^j}{(2j)!} \left(\frac{\pi x}{2} \right)^{2j} \\
  \leq& 1 - \frac{1}{2}\left(\frac{\pi x}{2}\right)^2
\end{align*}
$$

and thus

$$
\begin{align*}
  s(\alpha)^2 \geq& \frac{2^{2L + 2}}{\pi^2 r^2} \left(1 - \frac{1}{2} \left(\frac{\pi}{2} \frac{r}{2^L} \right)^2 \right)^2 \\
  \geq& \frac{2^{2L + 2}}{\pi^2 r^2} \left(1 - \left(\frac{\pi}{2} \frac{r}{2^L} \right)^2 \right) \\
  \geq& \frac{2^{2L + 2}}{\pi^2 r^2} \left(1 - \left(\frac{\pi}{2} \frac{1}{2^{L/2}} \right)^2 \right) \\
  =& \frac{2^{2L + 2}}{\pi^2 r^2} \left(1 - \frac{\pi^2}{2^{L+2}} \right)
\end{align*}
$$

Consequently, the lower bound of $W_2 (z)$ is

$$
\begin{align*}
  W_2 (z) \geq& \frac{1}{2^{2L}} \sum_{k=0}^{r-1} \frac{2^{2L + 2}}{\pi^2 r^2} \left(1 - \frac{\pi^2}{2^{L + 2}} \right) \\
  =& \frac{r}{2^{2L}} \frac{2^{2L + 2}}{\pi^2 r^2} \left(1 - \frac{\pi^2}{2^{L + 2}} \right) \\
  =& \frac{4}{\pi^2 r} \left(1 - \frac{\pi^2}{2^{L+2}} \right)
\end{align*}
$$

For $L \geq 4$, this lower bound ensures that the probability of measuring a value $z\in\set{0,\dots,2^L - 1}$ satisfying $\eqref{equation-60}$ is at least $\frac{4}{\pi^2}\left(1 - \frac{\pi^2}{2^{L + 2}} \right)$. To justify thus, observe that for $L \geq 4$

$$
  \frac{1}{2^{L/2 - 1}} \leq \frac{1}{2} < \frac{5}{9} < 1 - \frac{4}{\pi^2}
$$

which implies

$$
  \frac{1}{2^{L/2 - 1}} - \frac{1}{2^{2L}} < 1 - \frac{4}{\pi^2}
$$

Thus, the bounds

$$
  W_\text{min} := \frac{4}{\pi^2 r} \left(1 - \frac{\pi^2}{2^{L + 2}} \right) \leq W_2 (z) < W_1 (z) < \frac{1}{r}
$$

hold for all $z$ satisfying $\eqref{equation-60}$.

Now, for each $z\in\set{0,\dots,2^L - 1}$ there exists either none or exactly one number $l\in\N_0$ that satisfies $\eqref{equation-60}$. This uniqueness follows from the observation that if $l_1 \neq l_2$, then the distance between $l_2 2^L$ and $l_2 2^L$ is at least $2^L > r$. If both $l_1$ and $l_2$ satisfy $\eqref{equation-60}$ with the same $z$, their difference must be at most $r$, giving a contradiction. Since there are exactly $r$ such valid $l\in\set{0,\dots,r-1}$, it follows that there are precisely $r$ distinct values $z\in\set{0,\dots, 2^L - 1}$ satisfying $\eqref{equation-60}$.

Therefore, a measurement of the input register $\mathcal{H}^A$ results in a value $z\in\set{0,\dots,2^L - 1}$ for which either
- no $l\in\N_0$ satifies $\eqref{equation-60}$ or
- exactly one $l_z \in\set{0,\dots,r-1}$ satisfies $\eqref{equation-60}$

Let $l_z \in\set{0,\dots,r-1}$ denote this unique value corresponding to a given $z$. It then follows from the assumption $\eqref{equation-75}$ that

$$
\begin{equation*}
  \left|\frac{z}{2^L} - \frac{l_z}{r}\right| < \frac{1}{2r^2}
\tag{\label{equation-69}}
\end{equation*}
$$

Moreover, for any $j\in\set{0,\dots,r-1}$ there is exactly one $z\in\set{0,\dots,2^L - 1}$ such that $|zr - j2^L| \leq r/2$, meaning that $j = l_z$. Consequently, the probability that a given $j\in\set{0,\dots,r-1}$ corresponds to some $z$ (such that $l_z = j$) is at least the probability that $\eqref{equation-60}$ holds. This probability is bounded from below by $W_\text{min}$ such that we have for all $j\in\set{0,\dots,r-1}$ we have

$$
  \Pr(\exists z \in\set{0,\dots,2^L - 1} : l_z = j) \geq \frac{4}{\pi^2 r} \left(1 - \frac{\pi^2}{2^{L+2}} \right)
$$

5. **Probability of finding $r$ as the denominator in the continued fraction approximation**

The final step is to determine the period $r$ in $\eqref{equation-69}$, where the measurement outcome $z$ and register length $2^L$ are known. Continued fraction theory implies that if $\eqref{equation-69}$ holds, the reduced fraction $l_z / r$ must be a partial continued fraction approximation of $z / 2^L$. Since $z / 2^L \in\mathbb{Q}$, it follows that its continued fraction expansion is finite, i.e.

$$
  \frac{z}{2^L} = a_0 + \frac{1}{a_1 + \frac{1}{\ddots + \frac{1}{a_n}}} = [a_0;a_1\dots,a_n]
$$

Since we know $z$ and $2^L$, we can efficiently compute the coefficients $a_j$ with the continued fraction algorithm as follows.

Define initial values $r_{-1} := z$ and $r_0 := 2^L$ and for $j\in\N$ the recursive relation

$$
  r_j := r_{j-2} \bmod r_{j-1},\; r_{j-1} > 0
$$

The continued fraction coefficients $a_j$ for $j\in\set{1,\dots,n}$ are given by

$$
  a_j := \left\lfloor\frac{r_{j-1}}{r_j}\right\rfloor
$$

The number of computational steps required for this calculation is of the order $O(\log_2^2 (\max\set{r_{j-2}, r_{j-1}}))$. Since $r_{-1}, r_0 \leq 2^L$ and the $r_j$ decrease with increasing $j$, the number of computational steps required to compute one $r_j$ is of the order $O(L^2)$. The number of $r_j$, which we have to compute, grows as a function of $L$ as $2\min\set{\log_2 (2^L), \log_2 (z)} + 1 \leq 2L + 1$. The number of computational steps required to compute all $r_j$ is thus of the order $O(L^3)$. For the calculation of all $a_j$ we have to perform $O(L)$ divisions, each of which requires $O(L)$ steps. Hence, the $a_j$ can be calculated in $O(L^2)$ steps, given the $r_j$ have been computed before.

Using the coefficients $a_j$, we can calculate the partial continued fraction of $z/L$:

$$
  \frac{p_j}{q_j} := a_0 + \frac{1}{a_1 + \frac{1}{\ddots + \frac{1}{a_j}}},\quad j\in\set{0,\dots,n}
$$

For this we carry out $O(L)$ divisions, each of which requires $O(L)$ computational stpes. We denote the set of the partial continued fractions by

$$
  T\left(\frac{z}{2^L}\right) := \Set{\frac{p_j}{q_j}}_{j=0}^n
$$

Given the $a_j$, the computation of all elements in $T(z/2^L)$ thus requires a number of steps of the order $O(L^2)$. Altoghether, the growth of the number of computational steps needed to calculate the partial continued fractions $S_\text{PCF} (L)$ as a function of $L$ is of the order

$$
  S_\text{PCF} (L) \in O(L^3),\; L\to\infty
$$

By property, one of these partial continued fractions satisfies

$$
\begin{equation*}
  \frac{p_j}{q_j} = \frac{l_z}{r}
\tag{\label{equation-70}}
\end{equation*}
$$

and we know that the $p_j$ and $q_j$ are coprime, i.e. $\gcd(q_j, p_j) = 1$. To find $r$, we test each $p_j / q_j \in T(z/2^L)$ to check if $q_j$ is a period of $f$ by computing $f(q_j)$.

If $f(q_j) = 1$, then $q_j = vr$ for some $v\in\N$, and $\eqref{equation-70}$ implies $p_j = vl_z$. Since $\gcd(q_j, p_j) = 1$, it follows that $v = 1$ and $q_j = r$, indentifying the period of $f$.

If instead, $f(q_j) \neq 1$ for every $p_j / q_j \in T(z/2^L)$, then either
- the measurement outcome $z$ does not correspond to a fraction $l_z / r$ that satisfy $\eqref{equation-69}$ for any $l\in\N_0$ or
- the number $l_z$ satisfies $\gcd(l_z, r) > 1$, in which case $l_z / r$ would not appear in $T(z/2^L)$.

In the cases $f(q_j) \neq 1$, we repeat the algorithm: with the initial state $\ket{\Psi_0}$, measure again the input register to find a new $z$, determine the partial continued fractions of $z/2^L$, and check if now one of the new $q_j$ is the period of $f$. The necessity for this repetition increases with the probability that $\gcd(l_z, r) > 1$ for all possible $l_z \in\set{0,\dots,r-1}$. 

Let $E$ denote the that the measured value $z$ corresponds to a rational approximation $l_z /r$ with $\gcd(l_r, r) = 1$ and 

$$
  \left|\frac{z}{2^L} - \frac{l_z}{r} \right| < \frac{1}{2r^2}
$$

This guarantees that $r$ can be found from a partial continued fraction $p_j /q_j \in T(z/2^L)$. There are $\phi(r)$ numbers $l\in\set{0,\dots,r-1}$ with $\gcd(l,r) = 1$, where $\phi$ is the Euler totient function. For each such $l$, the probability that $l/r$ is approximated closely enough by $z/2^L$ is at least $W_\text{min}$. Summing over all $\phi(r)$ such $l$, the probability for $E$ has lower bound given by

$$
\begin{align*}
  \Pr(E_2) =& \sum_{\substack{l\in\set{0,\dots,r-1} \\ \gcd(l,r) = 1 }} \Pr(\exists z \in\set{0,\dots,2^L - 1} : l_z = l) \\
  \geq& \sum_{\substack{l\in\set{0,\dots,r-1} \\ \gcd(l,r) = 1 }} \frac{4}{\pi^2 r} \left(1 - \frac{\pi^2}{2^{L+2}} \right) \\
  =& \frac{4}{\pi^2 r} \left(1 - \frac{\pi^2}{2^{L+2}}\right) \underbrace{\sum_{\substack{l\in\set{0,\dots,r-1} \\ \gcd(l,r) = 1 }} 1}_{=\phi(r)} \\
  =& \frac{\phi(r)}{r} \frac{\pi}{\pi^2} \left(1 - \frac{\pi^2}{2^{L+2}} \right) \tag{\label{equation-71}}
\end{align*}
$$

We can estimate the totient ratio $\phi/r$ using the Rosser-Schoenfeld bound (Theorem $\ref{theorem-2}$), yielding

$$
\begin{align*}
  \frac{r}{\phi(r)} < g(r) :=& \exp(\gamma) \ln(\ln(r)) + \frac{2.50637}{\ln(\ln(r))} \\
  =& \underbrace{\left(\exp(\gamma) + \frac{2.50637}{\ln^2(\ln(r))}\right)}_{:= h(r)}
\end{align*}
$$

Since $g(r)$ is decreasing for large $r$, we define

$$
  h(\gamma) := \exp(\gamma) + \frac{2.50637}{\ln^2(\ln(r))}
$$

which is decreasing in $r$. Since $h(r) < 4$ for $r \geq 19$, we find

$$
  \frac{r}{\phi(r)} < g(r) < 4 \ln(\ln(r))
$$

Since $r < 2^{L/2}$ by assumption, it follow that

$$
\begin{equation*}
  \frac{r}{\phi(r)} < g(r) < 4\ln(\ln(2^{L/2})) < 4 \ln(L)
\tag{\label{equation-72}}
\end{equation*}
$$

or

$$
  \frac{\phi(r)}{r} > \frac{1}{4\ln(L)},\; r \geq 19
$$

To estimate $\frac{4}{\pi^2 (1 - \frac{\pi^2}{2^{L+2}})}$, note that $4/\pi^2 > 2/5$ and for $L\geq 15$ also

$$
\begin{equation*}
  \frac{4}{\pi^2} \left(1 - \frac{\pi^2}{2^{L+2}} \right) \geq \frac{2}{5}
\tag{\label{equation-73}}
\end{equation*}
$$

Since we are only interested in the asymptotic behaviour for $L \to\infty$, the restriction $L \geq 15$ is immaterial for us, and the estimate $\eqref{equation-73}$ suffices for our purposes.

From $\eqref{equation-71}$, $\eqref{equation-72}$ and $\eqref{equation-73}$ the success probability of measuring $z$ such that the period $r$ can be found as denominator of a partial continued fraction is

$$
\begin{equation*}
  \Pr(E_2) \geq \frac{2}{5}\frac{1}{4\ln(L)} = \frac{1}{10\ln(L)},\; L \geq 19
\tag{\label{equation-89}}
\end{equation*}
$$

6. **Aggregration of the number of computational steps**

By properties of the Landau big-O symbol, the computational complexity of the quantum algorithm $A$ is given by

$$
\begin{align*}
  S_A (L) \in& S_0 (L) + S_{U_f} (L) + S_{F} (L) + S_\text{PCF} (L) \\
  \in& O(L) + O(L^{K_f}) + O(L^2) + O(L^3) \\
  \in& O\left(L^{\max\set{K_f, 4}} \right),\; L\to\infty
\end{align*}
$$
</details>
</MathBox>

### Probability of selecting a suitable base $b\in\N_+$

<MathBox title='' boxType='lemma' tag='lemma-6'>
Let $p\in\N_+$ be an odd prime, $k\in\N_+$ and $s\in\N_0$. Consider a random element $b$ chosen uniformly from the set

$$
  \set{c\in\set{1,\dots,p^k - 1} | \gcd(p^k, c) = 1}
$$

with probability $1/\phi(p^k)$, where $\phi$ is Euler's totient function. Then, for a fixed triple $(p,k,s)$, the probability that the multiplicative order of $b$ modulo $p^k$ is of the form $\operatorname{ord}_{p^k} (b) = 2^s t$ with $t$ odd, satisfies

$$
  \Pr(\operatorname{ord}_{p^k} (b) = 2^s t \text{ with }t\text{ odd}) \leq \frac{1}{2}
$$

<details>
<summary>Proof</summary>

Since $p$ is an odd prime, it follows that

$$
  \phi(p^k) = p^{k-1} (p - 1)
$$

and since $p - 1$ is even, then $\phi(p^k)$ is and can be written as

$$
  \phi(p^k) = 2^u v
$$

for unique $u, v\in\N_+$ with $v$ odd.

Furthermore, since $p$ is an odd prime, there exist a primitive root $a\in\N_+$ modulo $p^k$ such that $\operatorname{ord}_{p^k} (a) = \phi(p^k)$. By property of primitive roots, we obtain

$$
  \set{b\in\set{1,\dots,p^k - 1} | \gcd(p^k, b) = 1} = \set{a^j \bmod p^k}_{j=1}^{\phi(p^k)}
$$

implying that $b = a^j \bmod p^k$. Because $b$ is chosen uniformly at random, the corresponding exponent $j \in\set{1,\dots,\phi(p^k)}$ is also uniformly random. The multiplicative order of $b$ modulo $p^k$ is therefore

$$
\begin{equation*}
  \operatorname{ord}_{p^k} (b) = \frac{\phi(p^k)}{\gcd(j, \phi(p^k))}
\tag{\label{equation-78}}
\end{equation*}
$$

Hence, requiring $\operatorname{ord}_{p^k} (b) = 2^s t$ with $t$ odd implies

$$
\begin{equation*}
  2^s t = \frac{2^u v}{\gcd(j, 2^u v)}
\tag{\label{equation-76}}
\end{equation*}
$$

Rewriting this as

$$
  v = 2^{s - u} t \gcd(j, 2^u v)
$$

we see that this only possible if $s \leq u$, because otherwise $2\mid v$, contradicting $v$ being odd. Thus, we have

$$
\begin{equation*}
  \Pr(\operatorname{ord}_{p^k} (b) = 2^s t, 2\nmid t \land s > u) = 0
\tag{\label{equation-81}}
\end{equation*}
$$

For the case $s \leq u$, we deduce that $j$ has to be of the form $j = 2^{u - s} x$, where $x$ is odd, as follows. Let

$$
  n = \prod_{p\in\operatorname{Pri}} p^\nu p,\quad m = \prod_{p\in\operatorname{Pri}} p^\mu p
$$

be the prime factorizations of $n, m\in\N$. Then, we obtain

$$
\begin{equation*}
  \gcd(n,m) = \prod_{p\in\operatorname{Pri}} p^{\min\set{\nu_p, \mu_p}}
\tag{\label{equation-77}}
\end{equation*}
$$

Suppose $j = 2^w x$ with $x$ odd. It then follows from $\eqref{equation-77}$ that

$$
\begin{equation*}
  \gcd(j, 2^u v) = 2^{\min\set{w,u}} \prod_{p\in\operatorname{Pri}\setminus\set{2}} p^{\kappa_p}
\tag{\label{equation-79}}
\end{equation*}
$$

with suitably chosen $\kappa_p$. In order to have $\operatorname{ord}_{p^k} (b) = 2^s t$, then $\eqref{equation-78}$ and $\eqref{equation-76}$ require

$$
\begin{equation*}
  \gcd(j, 2^u v) = 2^{u - s} \frac{v}{t}
\tag{\label{equation-80}}
\end{equation*}
$$

Since $v$ and $t$ are assumed odd, it follows that $v/t$ is odd. From $\eqref{equation-79}$ and $\eqref{equation-80}$ it follows that $\min\set{w,u} = u - s$ and thus $w = u - s$. Consequently, $j$ has to be of the form $j = 2^{u - s} x$ with odd $x$ and belong to $\set{1,\dots,\phi(p^k) = 2^u v}$. In this set there exist $2^s v$ multiples of $2^{u-s}$:

$$
  \set{2^{u-s} \cdot 1, 2^{u-s} \cdot 2,\cdots, 2^{u - s} \cdot 2^s v}
$$

of which only half are of the form $j = 2^{u-s} x$ with $x$ odd. The fact that all $j$ are uniformly chosen implies

$$
\begin{align*}
  \Pr(\operatorname{ord}_{p^k} (b) = 2^s t, 2\nmid t \land s > u) =& \frac{\frac{1}{2} 2^s v}{2^u v} \\
  =& 2^{s - u - 1} \leq \frac{1}{2}
\end{align*}
$$

since $s \leq u$. Together with $\eqref{equation-81}$ this yields

$$
\begin{align*}
  &\Pr(\operatorname{ord}_{p^k} (b) = 2^s t, 2\nmid t) \\
  =& \underbrace{\Pr(\operatorname{ord}_{p^k} (b) = 2^s t, 2\nmid t \land s > u)}_{=0} \\
  &+ \Pr(\operatorname{ord}_{p^k} (b) = 2^s t, 2\nmid t \land s \leq u) \\
  \leq& \frac{1}{2}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Let $N\in\N_+$ be odd with prime factorization $N = \prod_{j=1}^J p_j^{v_j}$ consisting of prime powers of $J$ different prime factors $p_1,\dots,p_J$ and let $b\in\set{c\in\set{0,\dots,N_1} | \gcd(c,N) = 1}$ be randomly chosen. Then

$$
  \Pr(2\nmid \operatorname{ord}_N (b) \land (b^{\operatorname{ord_N (b)}/2} + 1) \bmod N \neq 0) \geq 1 - \frac{1}{2^{J-1}}
$$

<details>
<summary>Proof</summary>

Since by assumption $N$ is odd, all its prime factors $p_1,\dots,p_J$ must be odd as well, and we can apply Lemma $\ref{lemma-6}$ for their powers $p_j^{v_j}$. Defining $r := \operatorname{ord}_N (b)$ we want to show

$$
  \Pr(2\nmid r \lor (b^{r/2} + 1) \bmod N = 0) \leq \frac{1}{2^{J-1}}
$$

We know that every $b\in\set{1,\dots,N-1}$ with $\gcd(b,N) = 1$ corresponds uniquely to a set of $b_j := b \bmod p_j^{v_j} \in\set{1,\dots, p_j^{v_j} - 1}$ with $\gcd(b_j, p_j^{v_j}) = 1$ for $j\in\set{1,\dots,J}$ and vice versa. An arbitrary selection of $b$ is therefore equivalent to an arbitrary selection of the tuple $(b_1 = b \bmod p_1^{v_1}, \dots, b_J = b \bmod p_J^{v_J})$. By definition of modular order, $r = \operatorname{ord}_N (b)$ satisfies

$$
  b^r \bmod N = 1
$$

From this it follows that there exist $z\in\Z$ such that 

$$
\begin{equation*}
  b^r = 1 + zN = 1 + z \prod_{j=1}^J p_j^{v_j}
\tag{\label{equation-84}}
\end{equation*}
$$

and thus also

$$
  b^r \bmod p_j^{v_j} = 1
$$

Furthermore, we set $r_j := \operatorname{ord}_{p_j^{v_j}} (b_j)$ for every $j\in\set{1,\dots,J}$. Then

$$
\begin{equation*}
\begin{split}
  1 =&  b_j^{r_j} \bmod p_j^{v_j} \\
  =& (b\bmod p_j^{v_j})^{r_j} \bmod p_j^{v_j} \\
  =& b^{r_j} \bmod p_j^{v_j}
\end{split}
\tag{\label{equation-82}}
\end{equation*}
$$

and for every $j\in\set{1,\dots,J}$ also

$$
\begin{equation*}
  b^{r_j} \bmod p_j^{v_j} = 1
\tag{\label{equation-83}}
\end{equation*}
$$

Since each $r_j$ is, by definition, the smallest positive number satisfying the first line in $\eqref{equation-82}$, it follows that it also is the smallest number satisfying $\eqref{equation-83}$. Together with $\eqref{equation-84}$, this implies that for each $j\in\set{1,\dots,J}$ there exists $k_j \in\N_+$ with $r = k_j r_j$. Conversely, every common multiple $k$ of the $r_j$ satisfies $b^k \bmod N = 1$ since

$$
  \frac{b^k - 1}{p_j^{v_j}} \in\Z,\; \forall j\in\set{1,\dots,J}
$$

implies, because of $\gcd(p_i, p_j) = 1$ for $i \neq j$, that also

$$
  \frac{b^k - 1}{\prod_{j=1}^J p_j^{v_j}} \in\Z
$$

such that $b^k \bmod N = 1$. Since $r$ is, by definition, the smallest number satisfying $b^r \bmod N = 1$, it follows that it is the smallest common multiple of the $r_j$, i.e.

$$
\begin{equation*}
  r = \operatorname{scm}(r_1,\dots,r_J)
\tag{\label{equation-85}}
\end{equation*}
$$

Now let $r = 2^s t$ and $r_j = 2^{s_j} t_j$ with $s, s_j \in\N_0$ and $t$ and $t_j$ odd. Because of $\eqref{equation-85}$, $r$ is odd (which is the same as $s = 0$) if and only if all $r_j$ are odd, which is the same as $s_j = 0$ for every $j\in\set{1\dots,J}$. Consequently, we have

$$
\begin{equation*}
  r \text{ odd} \iff s_j = 0,\; j\in\set{1,\dots,J}
\tag{\label{equation-94}}
\end{equation*}
$$

Furthermore, because of $\eqref{equation-85}$ we have for all $j\in\set{1,\dots,J}$

$$
  s_j \leq s
$$

Let us now consider the case where $r$ is even and $(b^{r/2} + 1) \bmod N = 0$, that is, where there is $l\in\N_+$ such that

$$
\begin{equation*}
  b^{r/2} + 1 = lN
\tag{\label{equation-86}}
\end{equation*}
$$

Since $N = \prod_{j=1}^J p_j^{v_j}$, it also follows that for every $j$ there is $l_j = lN/p_j^{v_j} \in\N_+$ such that

$$
\begin{equation*}
  b^{r/2} + 1 = l_j p_j^{v_j}
\tag{\label{equation-92}}
\end{equation*}
$$

We know already that we must have $s_j \leq s$ and now show that $\eqref{equation-86}$ also implies $s_j = s$. To see this, suppose there is some $j$ with $s_j < s$, the it follows from

$$
  2^s t = r = k_j r_j = k_j 2^{s_j} t_j
$$

that

$$
  k_j = 2^{s - s_j} \frac{t}{t_j} \in\N_+
$$

and thus

$$
  \frac{r}{2} = \underbrace{2^{s - s_j - 1} \frac{t}{t_j} r_j}_{:= z_j \in\N}
$$

since we are considering the case when $r$ is even. Thus, for some $j$ with $s_j < s$ there is $z_j \in\N_+$ satisfying

$$
  \frac{r}{2} = z_j r_j
$$

Together with $\eqref{equation-82}$, this implies

$$
\begin{align*}
  b^{r/2} \bmod p_j^{v_j} =& b^{z_j r_j} \bmod p_j^{v_j} \\
  =& \left(b^{r_j} \bmod p_j^{v_j} \right)^{z_j} \bmod p_j^{v_j} \\
  =& 1 \bmod p_j^{v_j}
\end{align*}
$$

However, this contradicts $\eqref{equation-92}$. Consequently, we have

$$
\begin{equation*}
  (b^{r/2} + 1) \bmod N = 0 \iff s_j = s,\; \forall j\in\set{1,\dots,J}
\tag{\label{equation-93}}
\end{equation*}
$$

Note that with our choice of notations we have for every $j\in\set{1,\dots,J}$

$$
  \operatorname{ord}_{p_j^{v_j}} \left(b \bmod p_j^{v_j} \right) = r_j = 2^{s_j} t_j
$$

where the $t_j$ are odd. Thus, a random selection of $b$ entails a random selection of the $s_j$, and for the set of events under consideration the statements $\eqref{equation-94}$ and $\eqref{equation-93}$ imply

$$
\begin{align*}
  \set{r \text{ odd}} \subset& \set{s_j = 0 \;\forall j} \\
  \set{r \text{ even} \land (b^{r/2} + 1) \bmod N = 0} \subset& \set{s_j = s \in\N\; \forall j}
\end{align*}
$$

and thus

$$
  \set{r \text{ odd} \lor (r \text{ even} \land (b^{r/2} + 1) \bmod N = 0)} \subset \set{s_j = s\in\N_0,\; \forall j}
$$

Since we can consider the choice of the $s_j$ as independent, we obtain

$$
\begin{align*}
  &\Pr(r \text{ odd} \lor [r \text{ even} \land (b^{r/2} + 1) \bmod N = 0]) \\
  \leq& \Pr(s_j = s\in\N_0 \;\forall j) = \sum_{s\in\N_0} \Pr(s_j = s \;\forall j) \\
  =& \sum_{s\in\N_0} \prod_{j=1}^J \Pr(s_j = s) \\
  =& \sum_{s\in\N_0} \Pr(s_1 = s) \prod_{j=2}^J \Pr(s_j = s) \\
  =& \sum_{s\in\N_0} \Pr(s_1 = s) \prod_{j=2}^J \underbrace{\Pr(r_j = 2^s t, 2\nmid t)}_{\leq 1/2} \\
  \leq& \underbrace{\sum_{s\in\N_0} \Pr(s_1 = s)}_{=1} \frac{1}{2^{J-1}} = \frac{1}{2^{J-1}} 
\end{align*}
$$

From this, we finally arrive at

$$
\begin{align*}
  &\Pr(r \text{ even} \land (b^{r/2} + 1) \bmod N = 0) \\
  =& 1 - \Pr(r \text{ odd} \lor [r \text{ even} \land (b^{r/2} + 1) \bmod N = 0]) \\
  \geq 1 - \frac{1}{2^{J-1}}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-8'>
For $f_{b,N} (x) = b^x \bmod N$ there exists a unitary operator $\hat{U}_{f_{b,N}}$ on $\mathcal{H}^A \otimes \mathcal{H}^B$ satisfying

$$
\begin{equation*}
  \hat{U}_{f_{b,N}} (\ket{x}^A \otimes \ket{0}^B) = \ket{x}^A \otimes \ket{f_{b,N}(x)}^B
\tag{\label{equation-87}}
\end{equation*}
$$

and the number of computational steps $S_{U_{f_{b,N}}}$ required for $U_{f_{b,N}}$ grows asymptotically with $L = \lfloor 2\log_2 (N) \rfloor + 1$ as

$$
\begin{equation*}
  S_{U_{f_{b,N}}} (L) \in O(L^3),\; L\to\infty
\tag{\label{equation-88}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Equation $\eqref{equation-87}$ follows directly from Corollary $\ref{corollary-3}$. To show $\eqref{equation-88}$, we analyze the quantum arithmetic components used to construct $\hat{U}_{f_{b,N}}$.

Let $a, b < 2^L$. A quantum adder $\hat{U}_+$, which computes $a+b$, need to execute $\hat{U}_s$, $\hat{U}_c$ and $\hat{U}_c^*$ each $O(L)$ times. Thus, the quantum adder satisfies 

$$
  S_{\hat{U}+} \in O(L),\; L\to\infty
$$

The same holds for the quantum subtractor $\hat{U}_-$, since it is the inverse of the adder.

A modular adder $\hat{U}_{+\bmod N}$ can be constructed using a fixed number of quantum adders and subtractors, independent of $a,b,N$, so its complexity scales as

$$
  $S_{U_{+\bmod N}} (L) \in O(L),\; L\to\infty
$$

To implement a modular multiplier $\hat{U}_{\times x\bmod N}$ for $a,b,c,N < 2^L$, we perform $O(L)$ additions, leading to

$$
  S_{U_{\times c\bmod N}} (L) \in O(L^2),\; L\to\infty
$$

For $x < 2^L$, the unitary $\hat{A}_{f_{b,N}}$ evaluates $f_{b,N} (x)$ by executing $O(L)$ quantum multipliers $\hat{U}_{\times\beta_j \bmod N}$, with constants $\beta_j = b^{2^j} \bmod N$ for $j\in\set{0,\dots,L_1}$. These constants can be precomputed classically using the recurrence

$$
  b^{2^j} \bmod N = \underbrace{(b^{2^{j-1}} \bmod N)^2}_{< N^2} \bmod N
$$

requiring $L$ modular reductions of the form $a\bmod N$ in $a < N^2$. Each such reduction requires $O(\log_2^2 (\max\set{a, N})) \in O(L^2)$ steps. The number of computational steps for $\hat{A}_{f_{b,N}}$ therefore scales scales as

$$
  S_{\hat{A}_{f_{b,N}}} (L) \in O(L^3),\; L\to\infty
$$

Since $\hat{U}_{f_{b,N}}$ is implemented by applyting $\hat{A}_{f_{b,N}}$ and $\hat{A}_{f_{b,N}}^\dagger$ a fixed number of times, which is independent of $N$, we conclude

$$
  S_{U_{f_{b,N}}} (L) \in O(L^3), L\to\infty
$$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
To factor an odd number $N\in\N_+$ that has at least two distinct prime factors using Shor's algorithm, the number of required computational steps, denoted $S_\text{Shor} (N)$, scales as

$$
  S_\text{Shor} (N) \in O(\log_2^3 (N) \log_2 (\log_2 (N))),\; N\to\infty
$$

<details>
<summary>Proof</summary>

First we adapt the estimate $\eqref{equation-89}$ to a statement using $N$ instead of $L$. Since $L = \lfloor 2\log_2 (N) \rfloor + 1$, we have

$$
\begin{equation*}
  2\log_2 (N) < L \leq 2\log_2 (N) + 1
\tag{\label{equation-90}}
\end{equation*}
$$

and thus

$$
\begin{equation*}
  \frac{1}{\ln(L)} \geq \frac{1}{\ln(2\log_2 (N) + 1)} 
\tag{\label{equation-91}}
\end{equation*}
$$

From $\eqref{equation-90}$, we have at least $\log_2 (N) \geq 7$ for $L \geq 15$. Such $N$ satisfy $\log_2^{17/12} (N) \geq 2\log_2(N) + 1$ and we have

$$
\begin{align*}
  \frac{1}{\ln(2\log_2(N) + 1)} \geq& \frac{1}{\frac{17}{12}\ln(\log_2(N))} \\
  =& \frac{1}{\frac{17}{12}\ln(2) \log_2(\log_2 (N))} \\
  >& \frac{1}{\log_2 (\log_2 (N))}
\end{align*}
$$

where in the last inequality we have used $\frac{17}{12} \ln(2) < 1$. Together with $\eqref{equation-91}$, this implies for $L\geq 15$

$$
  \frac{1}{\ln(L)} > \frac{1}{\log_2 (\log_2 (N))}
$$

and with $\eqref{equation-89}$, we have for $L \geq 15$ that

$$
  \Pr(E_2) > \frac{1}{10\log_2 (\log_2 (N))}
$$

As seen in table $ref{table-1}$, the probability that $b$ has been chosen such that the even $E_1 \cap E_2$ occurs and this factors of $N$ can be determined satisfies

$$
  P(E_1 \cap E_2) > \frac{1}{20 \log_2 (\log_2 (N))}
$$

To find suitable $b$ and $r$ with a probability close to $1$, it thus suffices to repeat steps $1$ to $3$ approximately $20\log_2 (\log_2 N)$ times.

Altogether, the number of computational steps needed to factorize $N$ with a success probability close to $1$ scales as

$$
\begin{align*}
  S_\text{Shor} (N) \in& (S_\text{Shor1} (N) + S_\text{Shor2} (N) + S_\text{Shor3} (N)) O(\log_2 (\log_2 (N))) \\
  \in& (O(\log_2^3 (N)) + O(\log_2^3 (N)) + O(\log_2^3 (N))) O(\log_2 (\log_2 (N))) \\
  \in& O(\log_2^3 (N) \log_2 (\log_2 (N))),\; N\to\infty
\end{align*}
$$
</details>
</MathBox>

<TableFigure caption="Relevant events in the Shor factorization alogrithm and their respective probabilities" tag="table-1">
| Step | Event | Description | Probability |
| --- | --- | --- | --- |
| 1 | $E_1$ | $b$ has been chosen such that $r$ is even and $(b^{r/2} + 1) \bmod N \neq 0$ | $\Pr(E_1) \geq 1/2$ |
| 2 | $E_2$ | Measurment of $\mathcal{H}^A$ yields a state $\ket{z}$ for some $z\in\set{0,\dots,2^L - 1}$, such that $\exists l_z \in\set{0,\dots,r-1}$ with $\left\lvert\frac{z}{2^L} - \frac{l_z}{r} \right\rvert < \frac{1}{2r^2}$ and $\gcd(l_z, r) = 1$ | $\Pr(E_2) > \frac{1}{10\log_2 (\log_2 (N))}$ for $r \geq 19$ |
| 2 | Follows from $E_2$ | A partial continued fraction $p_j/q_j$ of $z/2^L$ has a denominator $q_j = r$ which is a period of $f_{b,N}$ | $\Pr(E_1) \geq 1/2$ |
| 3 | $E_1 \cap E_2$ | A $b < N$ has been chosen such that an $r = q_j$ has been found that is an even period of $f_{b,N}$ and for which $(b^{r/2} + 1) \bmod N \neq 0$ | $\Pr(E_1) \geq 1/2$ |
</TableFigure>

# Grover search algorithm

# Variational quantum eigensolver (VQE)

The variational quantum eigensolver (VQE) is a hybrid classical-quantum alogorithm designed to estimate the ground state energy of a Hamiltonian. 

The energy levels of a quantum system $\mathcal{H}$ with Hamiltonian $\hat{H}$ are given by the time-independent Schrödinger equation

$$
  \hat{H}\ket{\psi} = E \ket{\psi}
$$

Since the Hamiltonian is Hermitian, it has a complete orthonormal eigenbasis $\set{\ket{q}_j}_{j=0}^n$, meaning that any state $\ket{\psi}\in\mathcal{H}$ can be expanded as

$$
  \ket{\psi} = \sum_{j=1}^n c_j \ket{\varphi_j}
$$

If $\hat{H}$ has non-degenerate eigenvalues $\set{E_j}_{j=1}^n$, the expectation value of $\hat{H}$ in terms of $\ket{\psi}$ is given by

$$
\begin{align*}
  \braket{\hat{H}}_\psi = \braket{\psi|\hat{H}|\psi} =& \sum_{j,k=1}^n c_j^* c_k \braket{\varphi_j|\hat{H}|\varphi_k} \\
  =& \sum_{j,k=1}^n c_j^* c_k E_j \overbrace{\braket{\varphi_j|\varphi_k}}^{=\delta_{jk}} \\
 =& \sum_{j=1}^n |c_j|^2 E_j \geq E_0 \overbrace{\sum_{j=1} |c_j|^2}^{=1} = E_0
\end{align*}
$$

By the Rayleigh-Ritz variational principle, this expectation value provides an upper bound for the ground state energy $E_0$

$$
  E_0 \leq \braket{\psi|\hat{H}|\psi} = \braket{\hat{H}}
$$

The objective of the VQE is therefore to find a parametrization of $\ket{\psi(\boldsymbol{\theta})}$, called an ansatz, that minimizes the expectation value $\braket{\hat{H}}_\psi$, where $\boldsymbol{\theta}\in\Theta$ is a vector of tunable parameters. To implement this on a quantum circuit, we express the ansatz $\ket{\psi}$ in terms of a generic parametrized unitary operator $\hat{U}(\boldsymbol{\theta})$ applied to an initial state $\ket{\psi_0}$:

$$
  \ket{\psi(\boldsymbol{\theta})} = \hat{U}(\boldsymbol{\theta}) \ket{\psi_0}
$$

The initial state is usually set as the computational basis $\ket{0}^{\otimes N} = \ket{\mathbf{0}}$. The VQE cost function is then defined as

$$
  \braket{\hat{H}(\boldsymbol{\theta})} = \braket{\psi(\boldsymbol{\theta})|\hat{H}|\psi(\boldsymbol{\theta})}
$$

For practical implementation using quantum circuits, the Hamiltionian must be expressed as a weighted sum of Pauli operators $\hat{P}_A \in \set{\hat{I}_2, \hat{X}, \hat{Y}, \hat{Z}}^{\otimes N}$:

$$
  \hat{H} = \sum_a^\mathcal{P} w_a \hat{P}_a
$$

Substituting this into the cost function yields the minimization problem

$$
  E_\text{VQE} = \argmin_{\boldsymbol{\theta}} \sum_a^\mathcal{P} w_a \braket{\psi(\boldsymbol{\theta})|\hat{P}_a|\psi(\boldsymbol{\theta})}
$$

Each term $E_{P_a} = \braket{\psi(\boldsymbol{\theta})|\hat{P}_a|\psi(\boldsymbol{\theta})}$ corresponds to the expectation value of a Pauli string $\hat{P}_a$, which can be measured on a quantum device, while the summation and parameter optimization $E(\boldsymbol{\theta}) = \argmin_{\boldsymbol{\theta}} \sum_a w_a E_{P_a}$ are performed using a classical optimization algorithm, making VQE a hybrid quantum-classical method.

## Measurements in the computational basis

Quantum circuits measure in the $\hat{Z}$-basis by default, so we express all Pauli operators in terms of $\hat{Z}$ using the basis transformations

$$
  \hat{Z} = \hat{HXH},\quad \hat{Z} = \hat{H}\hat{S}^\dagger \hat{Z}\hat{H}\hat{S}^\dagger
$$

In an $n$-qubit system, an arbitrary Pauli string $\hat{P}$ acting non-trivially on a subset $Q$ of qubit can be expressed as

$$
  \bigotimes_{p\in Q} \hat{\sigma}_p = \left(\bigotimes_{p\in Q} \hat{R}_{\sigma_p}^\dagger \hat{Z} \hat{R}_{\sigma_p}\right)
$$

The expectation value of $\hat{P}$ is given by a linear combination of probabilities:

$$
  \braket{\hat{P}}_\psi = \sum_{x\in\set{0,1}^n}(-1)^{\sum_{p\in Q} x_p} |\braket{x|\varphi}|^2
$$

<details>
<summary>Details</summary>

Computing $\braket{\hat{P}}_\psi$ gives

$$
\begin{align*}
  \braket{\hat{P}}_\psi =& \Braket{\psi|\bigotimes_{p\in Q} \hat{\sigma}_p\psi} \\
  =& \Braket{\psi|\left(\bigotimes_{p\in Q} \hat{\sigma}_p \right) \left(\bigotimes_{q\notin Q} \hat{I}_q \right)\psi} \\
  =& \Braket{\psi|\left(\bigotimes_{p\in Q} \hat{R}_{\sigma_p}^\dagger \hat{Z} \hat{R}_{\sigma_p}\right)\left(\bigotimes_{q\notin Q} \hat{I}_q \right)|\psi} \\
  =& \Braket{\psi|\left(\bigotimes_{p\in Q} \hat{R}_{\sigma_p}^\dagger \right)\left(\bigotimes_{p\in Q} \hat{Z}_p \right)\left(\bigotimes_{q\notin Q} \hat{I}_q \right)\left(\bigotimes_{p\in Q} \hat{R}_{\sigma_p} \right)|\psi}
\end{align*}
$$

Setting $\ket{\varphi} = \left(\bigotimes_{p\in Q} \hat{R}_{\sigma_p} \right)\ket{\psi}$, we get

$$
\begin{align*}
  \braket{\hat{P}}_\psi =& \Braket{\varphi|\left(\bigotimes_{p\in Q} \hat{Z}_p \right)\left(\bigotimes_{q\notin Q} \hat{I}_q \right)|\varphi} \\
  =& \Braket{\varphi|\left(\bigotimes_{p\in Q} \sum_{x_p \in\set{0_p, 1_p}} (-1)^{x_p} \ket{x_p} \bra{x_p} \right)\left(\bigotimes_{q\notin Q} \sum_{y_p \in\set{0_p, 1_p}} \ket{y_p} \bra{y_p} \right)|\varphi} \\
  =& \Braket{\varphi|\left(\sum_{x\in\set{0,1}^n} (-1)^{\sum_{p\in Q} x_p} \ket{x}\bra{x} \right)|\varphi} \\
  =& \sum_{x\in\set{0,1}^n}(-1)^{\sum_{p\in Q} x_p} |\braket{x|\varphi}|^2
\end{align*}
$$
</details>

The probability $\Pr(\ket{\varphi}\to\ket{x}) = |\braket{x|\varphi}|^2$ that the state $\ket{\varphi}$ collapses to the state $\ket{x}$ when measured is estimated statistically as

$$
  \Pr(\ket{\varphi}\to\ket{x}) \approx \sum_{m=1}^M \frac{x_m}{M}
$$

where $M\in\N_+$ is the number of measurements. By the law of large numbers, the approximation of $\Pr(\ket{\varphi}\to\ket{x})$ converges to its true value as $M\to\infty$.

For precision $\epsilon$, each expectation subroutine within VQE requires $O(1/\epsilon^2)$ samples from circuits with depth $O(1)$.

Given $M_0$ and $M_1$ as the number of $0$ and $1$ measurement outcomes, the expectation value of $\hat{P}_a$ approximated as

$$
  \braket{P}_\psi \approx \frac{M_0 - M_1}{M}
$$

<TableFigure caption="Quantum gates for two-qubit Pauli measurements">
| Pauli measurement | Quantum gate $\hat{U}$ |
| --- | --- |
| $\hat{Z}\otimes\hat{I}$ | $\hat{I}_2 \otimes\hat{I}_2$ |
| $\hat{X}\otimes\hat{I}$ | $\hat{H} \otimes\hat{I}_2$ |
| $\hat{Y}\otimes\hat{I}$ | $\hat{H}\hat{S}^\dagger \otimes\hat{I}_2$ |
| $\hat{I}\otimes\hat{Z}$ | $(\hat{I}_2 \otimes\hat{I}_2) \operatorname{SWAP}$ |
| $\hat{I}\otimes\hat{X}$ | $(\hat{H} \otimes\hat{I}_2) \operatorname{SWAP}$ |
| $\hat{I}\otimes\hat{X}$ | $(\hat{H}\hat{S}^\dagger \otimes\hat{I}_2) \operatorname{SWAP}$ |
| $\hat{Z}\otimes\hat{Z}$ | $\operatorname{CX}_{1,0}$ |
| $\hat{X}\otimes\hat{Z}$ | $\operatorname{CX}_{1,0} (\hat{H} \otimes\hat{I}_2)$ |
| $\hat{Y}\otimes\hat{Z}$ | $\operatorname{CX}_{1,0} (\hat{H}\hat{S}^\dagger \otimes\hat{I}_2)$ |
| $\hat{Z}\otimes\hat{X}$ | $\operatorname{CX}_{1,0} (\hat{I}_2 \otimes\hat{H})$ |
| $\hat{X}\otimes\hat{X}$ | $\operatorname{CX}_{1,0} (\hat{H} \otimes\hat{H})$ |
| $\hat{Y}\otimes\hat{X}$ | $\operatorname{CX}_{1,0} (\hat{H} \otimes\hat{H})$ |
| $\hat{Z}\otimes\hat{Y}$ | $\operatorname{CX}_{1,0} (\hat{I}_2 \otimes\hat{H}\hat{S}^\dagger)$ |
| $\hat{X}\otimes\hat{Y}$ | $\operatorname{CX}_{1,0} (\hat{H} \otimes\hat{H}\hat{S}^\dagger)$ |
| $\hat{Y}\otimes\hat{Y}$ | $\operatorname{CX}_{1,0} (\hat{H}\hat{S}^\dagger \otimes\hat{H}\hat{S}^\dagger)$ |
</TableFigure>

## Gradient of the expectation value

To apply gradient descent methods to optimize the ansatz state $\ket{\psi(\boldsymbol{\theta})} = \hat{U}(\boldsymbol{\theta})\ket{\psi_0}$, we need to compute the gradient of $\braket{\hat{H}(\boldsymbol{\theta})}$. Suppose the ansatz is composed of a sequence of unitary transformations,

$$
  \hat{U}(\boldsymbol{\theta}) = \prod_{\ell=1}^L \hat{U}_\ell (\theta_\ell) \hat{V}_\ell
$$

where $\hat{V}_\ell$ are fixed (non-parametrized) gates. To comptute the partial derivative of $\braket{\hat{H}(\boldsymbol{\theta})}$ with respect to $\theta_j$, we absorb all preceeding gates into the initial state:

$$
  \ket{\psi_{j-1}} = \left(\prod_{\ell=j-1}^1 \hat{U}(\theta_\ell) \hat{V}_\ell \right) \ket{\psi_0}
$$

Similarly, all subsequent gates are combined with the Hamiltonian $\hat{H}$:

$$
  \hat{H}_{i+1} = \left(\prod_{\ell=j+1}^1 \hat{V}_\ell^\dagger \hat{U}_\ell^\dagger(\theta_\ell) \right) \hat{H} \left(\prod_{\ell=1}^{j-1} \hat{U}_\ell (\theta_\ell) \hat{V}_\ell\right)
$$

Thus, the expecation value simplifies to

$$
  \braket{\hat{H}(\boldsymbol{\theta})} = \Braket{\psi_{j-1}|\hat{U}_j^\dagger (\theta_j) \hat{H}_{j+1} \hat{U}_j (\theta_j) |\psi_{j-1}}
$$

The partial derivative of $\braket{\hat{H}(\boldsymbol{\theta})}$ with respect to $\theta_j$ is given by the product rule

$$
\begin{align*}
  \frac{\partial}{\partial\theta_j} \braket{\hat{H}(\boldsymbol{\theta})} =& \Braket{\psi_{j-1}|\hat{U}_j^\dagger (\theta_j) \hat{H}_{j+1} \partial_{\theta_j} \left(\hat{U}_j (\theta_j)\right) |\psi_{j-1}} \\
  &+ \Braket{\psi_{j-1}|\partial_{\theta_j} \left(\hat{U}_j^\dagger (\theta_j)\right) \hat{H}_{j+1} \hat{U}_j (\theta_j) |\psi_{j-1}}
\end{align*}
$$

Assuming that every parametrized gate is in the exponential form $\hat{U}_j (\theta_j) = \exp(-i\theta_j \hat{P})$, where $\hat{P}^\dagger = \hat{P}$ is Hermitian, its partial derivatives with respect to $\theta_j$ is

$$
  \frac{\partial}{\partial\theta_j} \hat{U}(\theta_j) = -i\hat{P}e^{-i\theta_j \hat{P}} = -i\hat{P}\hat{U}_j (\theta_j)
$$

we get by absorbing $\ket{\psi'_{j-1}} = \hat{U}_j (\theta_j) \ket{\psi_{j-1}}$

$$
  \frac{\partial}{\partial\theta_j} \braket{\hat{H}(\boldsymbol{\theta})} = \Braket{\psi'_{j-1}| \hat{H}_{j+1} (-i\hat{P}) |\psi'_{j-1}} + \Braket{\psi_{j-1}'|i\hat{P}\hat{H}_{j+1}|\psi_{j-1}'}
$$

Using the identity

$$
  \hat{A}^{\dagger}\hat{B}\hat{C} + \hat{C}^{\dagger}\hat{B}\hat{A} = \frac{1}{2}\left[(\hat{A}+\hat{C})^{\dagger}\hat{B}(\boldsymbol{A}+\hat{C}) - (\hat{A}-\hat{C})^{\dagger} \hat{B}(\boldsymbol{A}-\hat{C})\right]
$$

with $\hat{A} = \hat{I}$, $\hat{B} = \hat{H}_{i+1}$ and $\hat{C} = -ir^{-1} \hat{P}$, we rewrite:

$$
\begin{align*}
  \frac{\partial}{\partial\theta_j} \braket{\hat{H}(\boldsymbol{\theta})} =& \frac{r}{2}\left(\Braket{\psi'_{j-1}|\left(\hat{I} - \frac{i}{r}\right)^\dagger \hat{H}_{j+1} \left(\hat{I} - \frac{i}{r}\right)|\psi'_{j-1}}\right. \\
  &- \left. \Braket{\psi'_{j-1}|\left(\hat{I} + \frac{i}{r}\right)^\dagger \hat{H}_{j+1} \left(\hat{I} + \frac{i}{r}\right)|\psi'_{j-1}} \right)
\end{align*}
$$
 
If the Hermitian generator $\hat{P}$ of the unitary operator $\hat{U}_j (\theta) = \exp(-i\theta \hat{P})$ has at most two unique eigenvalues $\pm r$, then

$$
  \hat{U} \left(\frac{\pi}{4r}\right) = \frac{1}{\sqrt{2}} \left(\hat{I} - \frac{i}{r} \hat{P}\right)
$$

<details>
<summary>Proof</summary>

If $\sigma(\hat{P}) = \set{\pm r}$, then $\hat{P}^2 = r^2 \hat{I}$. Thus, the Taylor expansion of $\hat{U}(\theta) = \exp(-i\theta \hat{P})$ simplifies to

$$
\begin{align*}
  e^{-i\theta \hat{P}} =& \sum_{k=0}^\infty \frac{(-i\theta)^k \hat{P}^k}{k!} \\
  =& \sum_{k=0}^\infty \frac{(-i\theta)^{2k} \hat{P}^{2k}}{(2k)!} + \sum_{k=0}^\infty \frac{(-i\theta)^{2k + 1} \hat{P}^{2k + 1}}{(2k + 1)!} \\
  =& \hat{I} \sum_{k=0}^\infty \frac{(-1)^k (r\theta)^{2k}}{(2k)!} - \frac{i}{r} \hat{G} \sum_{k=0}^\infty \frac{(-1)^k (r\theta)^{2k + 1}}{(2k + 1)!} \\
  =& \cos(r\theta) \hat{I} - \frac{i}{r} \sin(r\theta)\hat{G}
\end{align*}
$$
</details>

Thus, we obtain

$$
\begin{align*}
  \frac{\partial}{\partial\theta_j} \braket{H(\boldsymbol{\theta})} =& r\left(\Braket{\psi'_{j-1}|\hat{U}_j^\dagger \left(\theta_j + \frac{\pi}{4r} \right) \hat{H}_{j+1} \hat{U}_j \left(\theta_j + \frac{\pi}{4r} \right)|\psi'_{j-1}} \right. \\
  &- \left. \Braket{\psi'_{j-1}|\hat{U}_j^\dagger \left(\theta_j - \frac{\pi}{4r} \right) \hat{H}_{j+1} \hat{U}_j \left(\theta_j - \frac{\pi}{4r} \right)|\psi'_{j-1}} \right) \\
  =& r\left(\hat{H}\left(\boldsymbol{\theta} + \frac{\pi}{4r}\unitvec{e}_j \right) - \hat{H}\left(\boldsymbol{\theta} - \frac{\pi}{4r}\unitvec{e}_j \right) \right)
\end{align*}
$$

## Ansatz methods

- Hardware-Efficient Ansatz (HEA)
- Unitary Coupled Cluster (UCC)
    - Orbital-Optimized UCC (OO-UCC)
    - UCC with Generalized Singles and Doubles (UCCGSD)
    - Unitary pair CCGSD (k-UpCCGSD)
    - Pair-natural orbital UpCCGSD (PNO-UpCCGSD)
    - Double UCC (DUCC)
    - Unitary Selective CC (USCC)
- Symmetry-Preserving Ansatz (SPA)
  - Efficient SPA (ESPA)
- Hamiltonian Variational Ansatz (HVA)
  - Fourier-transform HVA (FTHVA)
  - Symmetry-breaking HVA

<TableFigure caption="Summary of circuit depth, parameters and entangling gates scaling across a selection of fixed structure ansätze. The scaling in the number of entangling gtes assumes full connectivity of the qubit lattice.">
| Method | Depth | Parameters | Entangling gates | Comment |
| --- | --- | --- | --- | --- |
| HEA | $O(L)$ | $O(NL)$ | $O((N - 1)L)$ | $L$ is an arbitrary number of layers, whose scaling for exact ground state is unknown and exponential in the worst case if the entire Hilbert space needs to be spanned to find the ground state |
| UCCSD | $O((N - m)^2 m\tau)$ | $O((N - m)^2 m^2 \tau)$ | $O(2(\bar{q} - 1)N^4 \tau)$ | $\bar{q}$ is the average Pauli weigh across the operators used to build the ansatz. As an indication, maximum Pauli weight under Jordan-Wigner is $N$, and $\ln(N)$ under Bravyi-Kitaev. $\tau$ is the number of Trotter steps used. |
| UCCGSD | $O(N^3 \tau)$ | $O(N^4 \tau)$ | $O(2(\bar{q} - 1)N^4 \tau)$ | |
| k-UpUCCGSD | $O(kN \tau)$ | $O(k\tau N^2 / 4)$ | $O(k\tau(\bar{q} - 1)N^2 / 2)$ | $k$ is an arbitrary constant which determines the accuracy of the result. Scaling is unknown. |
| OO-UCCD | $O((N - m)^2 m\tau)$ | $O((N - m)^2 m^2 \tau)$ | $O(2(\bar{q} - 1)N^4 \tau)$ | Same as UCCSD. It is worth noting that OO-UCCD is a nested loop between orbital (one-body terms) optimization, done on a conventional machine, and two-body terms optimization done on the quantum computer. |
| SPA | $O((N - 1)L)$ | $O(2(N - 1)L)$ | $O(3(N - 1)L)$ | This ansatz spans a wider range of the Hilbert space than the EPS. It is therefore likely it requires more circuit resources suggesting that $L$ grows exponentially in $N$ for exact resolution of the ground state. This logic also applies to HEA |
| ESPA | $O\left(2\binom{N-1}{m}\right)$ | $O\left(2\binom{N}{m} - 2\right)$ | $O\left(3\binom{N}{m}\right)$ | Scaling range from linear when $m = 1$ $m = N - 1$, to exponential if $m \sim N/2$ |
| HVA | $O(\tilde{C}L)$ | $O(\tilde{CL})$ | $O(2(\bar{q} - 1)CL)$ | $L$ is the number of repetition of the ansatz required to achieve the desired accuracy. $C$ is the number of terms in the Hamiltonian, and $\tilde{C}$ the number of commutative groups among these terms |
</TableFigure>

### Hardware-efficient ansatz (HEA)

A hardware-efficient ansatz (HEA) is a parameterized quantum circuit designed to be compatible with the native gate set of quantum hardware, reducing depth and error rates. Various HEA architectures have been proposed, but they all follow a common structure: the ansatz is constructed by repeating layers of interleaved single-qubit parametrized rotation gates, $\hat{U}_\text{r} (\theta)$, and entangling gates $\hat{U}_\text{e}$. Formally, an HEA of $N$ qubits and $L$ layers is expressed as

$$
  \ket{\psi(\boldsymbol{\theta})} = \left(\prod_{\ell = 1}^L \hat{U}_\text{r} (\theta_\ell) \times \hat{U}_\text{e}\right) \times \hat{U}_\text{r} (\theta_{L+1}) \ket{\psi_0}^{\otimes N}
$$

where the single-qubit rotation layer is defined as

$$
  \hat{U}_\text{r} (\theta_\ell) = \prod_{q=1}^N \prod_{p\in P} \hat{R}_p^{(q)} (\theta_\ell^{(pq)})
$$

Here, $q$ indexes qubits, and $p \in P \subseteq\set{\hat{X}, \hat{Y}, \hat{Z}}$ corresponds to the selected Pauli rotation axes. The set of rotation gates and entangling operations is hardware-dependent, adapting to the native gate set and circuit connectivity constraints.

The key advantage of HEAs is their hardware compatibility and expressiveness—they can efficiently explore the Hilbert space while conforming to device limitations. However, they also suffer from notable challenges. First, an HEA must span a sufficiently large region of the Hilbert space to accurately represent the ground state wavefunction, which can lead to inefficiency. In the worst case, an exponential circuit depth may be required. A direct consequence is the onset of barren plateaus, where gradient magnitudes vanish exponentially with system size, making optimization intractable.

## Single qubit system

For a single qubit system, the Hamiltonian $\hat{H} \in\mathcal{L}(\mathbb{C}^{2\times 2})$ can be expanded in terms of Pauli matrices as

$$
  \hat{H} = a\hat{I}_2 + b\hat{X} + c\hat{Y} + d\hat{Z}
$$

We define our ansatz state as

$$
  \ket{\psi} = \ket{\psi(\theta, \phi)} = \hat{R}_y (\phi) \hat{R}_x (\theta) \ket{0}
$$

Applying the identities $\hat{X} = \hat{H}\hat{Z}\hat{H}$ and $\hat{Y} = \hat{S}\hat{H}\hat{Z}\hat{H}\hat{S}^\dagger$, The expectation value of $\hat{H}$ in the state $\ket{\psi}$ in the $\hat{Z}$-basis is

$$
  \braket{\psi|\hat{H}|\psi} = a \underbrace{\braket{\psi|\hat{I}_2|\psi}}_{=1} + b \braket{\psi|\hat{H}\hat{Z}\hat{H}|\psi} + \braket{\psi|\hat{S}\hat{H}\hat{Z}\hat{H}\hat{S}^\dagger|\psi} + \braket{\psi|\hat{Z}|\psi}
$$

The partial derivatives of $\braket{\hat{H}(\phi, \theta)}_\psi$ can shown to given by

$$
  \frac{\partial}{\partial \gamma} \braket{\hat{H}(\phi,\theta)} = \frac{1}{2}\left[\Braket{\hat{H}\left(\phi + \frac{\pi}{2}\right)} - \Braket{\hat{H}\left(\phi + \frac{\pi}{2}\right)} \right], \; \gamma\in \set{\theta,\phi}
$$

<details>
<summary>Detail</summary>

Since $\hat{R}_j (\gamma) = e^{-i\gamma \hat{\sigma}_j/2}$ it follows that

$$
  \frac{\partial}{\partial\gamma} R_j (\gamma) = -\frac{i}{2} \hat{\sigma}_j e^{-i\gamma \hat{\sigma}_j/2} = -\frac{i}{2}\hat{\sigma}_i \hat{R}_i (\gamma)
$$

The expectation of the Hamiltonian is

$$
  \braket{\hat{H}(\phi,\theta)} = \braket{0|\hat{R}_x (\theta) \hat{R}_y(\phi) \hat{H} R_y (\phi) R_x (\theta)|0}
$$

The partial derivative is

$$
\begin{align*}
  \frac{\partial}{\partial\phi} =& \braket{0|\hat{R}_x (\theta) \hat{R}_y(\phi) \hat{H} R_y (\phi) R_x (\theta)|0}
\end{align*}
$$
</details>

## Lipkin-Meshkov-Glick (LMG) model

The Lipkin-Meshkov-Glick (LMG) model describes a many-body system of $N$ fermions occupying two distinct energy levels, each with $N$-fold degeneracy. Each level is associated with a quantum number $\sigma$, which takes the values $-1$ for the lower energy level and $1$ for the upper level. Within each energy level, the degeneracy is specified by a quantum number $p \in {1,\dots, N}$. The model considers only two-body interactions that scatter pairs of particles between the two energy levels without altering the value of $p$.

To construct the Hamiltonian of the system, we define the single particle states

$$
  \ket{u_{p, \sigma=-1}} = \hat{a}^\dagger_{p,-} \ket{0},\quad \ket{u_{p, \sigma = 1}} = \hat{a}^\dagger_{p,+} \ket{0}
$$

where $\hat{a}_{p,\pm}^\dagger$ and $\hat{a}_{p,\pm}$ are the fermion creation and annihilation operators, respectively, satisfying the anti-commutation relations

$$
\begin{align*}
  \{\hat{a}_l, \hat{a}_k \} =& 0 \\
  \{\hat{a}_l^\dagger, \hat{a}_k^\dagger \} =& 0 \\
  \{\hat{a}_l^\dagger, \hat{a}_k \} =& \delta_{lk}
\end{align*}
$$

The single particle states span an orthonormal basis for the system. The Hamiltonian of the system in second quantization is given by $\hat{H} = \hat{H}_0 + \hat{H}_1 + \hat{H}_2$ with the components

$$
\begin{align*}
  \hat{H}_0 =& \frac{1}{2} \varepsilon \sum_{p, \sigma} \sigma \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \\
  \hat{H}_1 =& -\frac{1}{2} V \sum_{\sigma, p, p'} \hat{a}_{p, \sigma}^\dagger \hat{a}_{\sigma, p'}^\dagger \hat{a}_{p', -\sigma} \hat{a}_{p,-\sigma} \\
  \hat{H}_2 =& -\frac{1}{2} W \sum_{\sigma, p, p'} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', -\sigma}^\dagger \hat{a}_{p', \sigma} \hat{a}_{p, -\sigma}
\end{align*}
$$

where $\varepsilon$ is the difference between upper and lower energy levels, and $V$ and $W$ are scattering constants. The operator $\hat{H}_1$ describes the scattering of pairs of fermions between the two energy levels. The operator $\hat{H}_2$ introduces a spin-exchange term, which transitions a pair of fermions from a state $(p\sigma, p' - \sigma)$ to a state $(p - \sigma, p' \sigma)$.

The Hamiltionian can be rewritten in terms of the quasispin operators

$$
\begin{align*}
  \hat{J}_\pm =& \sum_p \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} \\
  \hat{J}_z =& \frac{1}{2} \sum_{p,\sigma} \sigma \hat{a}_{p,\sigma}^\dagger \hat{a}_{p,\sigma} \\
  \hat{J}^2 =& \hat{J}_+ \hat{J}_- + \hat{J}_z^2 - \hat{J}_z
\end{align*}
$$

satisfying the commutator relations

1. $[\hat{J}_+, \hat{J}_\pm] = \pm\hat{J}_\pm$
2. $[\hat{J}_+, \hat{J}_] = \hat{J}_z$
3. $[\hat{J}^2, \hat{J}_\pm] = 0$
4. $[\hat{J}^2, \hat{J}_z] = 0$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  [\hat{J}_z, \hat{J}_\pm] =& \hat{J}_z \hat{J}_\pm - \hat{J}_\pm \hat{J}_z \\
  =& \left(\frac{1}{2} \sum_{p, \sigma} \sigma \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right) \left(\sum_{p'} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \right) - \left(\sum_{p'} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \right) \left(\frac{1}{2} \sum_{p, \sigma} \sigma \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right) \\
  =& \frac{1}{2} \sum_{p,p',\sigma} \sigma\left(\hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right)
\end{align*}
$$

Using the anti-commutation relations for the creation and annihilation operators, we can move the operators in the right-hand product to be in the same order as those in the left-hand product

$$
\begin{align*}
  [\hat{J}_z, \hat{J}_\pm] =& \frac{1}{2} \sum_{p,p',\sigma} \sigma\left(\hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger (\delta_{p' p} \delta_{\mp, \sigma} - \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \mp}) \hat{a}_{p, \sigma} \right) \\
  =& \frac{1}{2} \sum_{p,p',\sigma} \sigma\left(\hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \delta_{p',p} \delta_{\mp, \sigma} \hat{a}_{p, \sigma} + \hat{a}_{p', \pm}^\dagger \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \mp} \hat{a}_{p, \sigma} \right) \\
  =& \frac{1}{2} \sum_{p,p',\sigma} \sigma\left(\hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \delta_{p' p} \delta_{\mp, \sigma} \hat{a}_{p, \sigma} + \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \pm}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \mp} \right) \\
  =& \frac{1}{2} \sum_{p,p',\sigma} \sigma\left(\hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \delta_{p', p} \delta_{\mp, \sigma} \hat{a}_{p, \sigma} + \hat{a}_{p, \sigma}^\dagger (\delta_{p, p'} \delta_{\pm, \sigma} - \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger) \hat{a}_{p', \mp} \right) \\
  =& \frac{1}{2} \sum_{p,p',\sigma} \sigma\left(\hat{a}_{p, \sigma}^\dagger \delta_{p, p'} \delta_{\pm, \sigma} \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \delta_{p, p'} \delta_{\mp, \sigma} \hat{a}_{p, \sigma} \right)
\end{align*}
$$

which leads to

$$
\begin{align*}
  [\hat{J}_z, \hat{J}_\pm] =& \frac{1}{2} \left( (\pm 1) \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} - (\mp 1) \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} \right) \\
  =& \pm\frac{1}{2} \sum_p \left(\hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} + (\pm 1) \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} \right) \\
  =& \pm \sum_p \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} = \pm\hat{J}_{\pm}
\end{align*}
$$

**(2):**

$$
\begin{align*}
  [\hat{J}_+, \hat{J}_-] =& \hat{J}_+ \hat{J}_- - \hat{J}_- \hat{J}_+ \\
  =& \left(\sum_p \hat{a}_{p', +}^\dagger \hat{a}_{p, -} \right) \left(\sum_{p'} \hat{a}_{p', -}^\dagger \hat{a}_{p', +} \right) - \left(\sum_p \hat{a}_{p', -}^\dagger \hat{a}_{p', +} \right) \left(\sum_p \hat{a}_{p, +}^\dagger \hat{a}_{p, -} \right) \\
  =& \sum_{p,p'} \left(\hat{a}_{p', +}^\dagger \hat{a}_{p, -} \hat{a}_{p', -}^\dagger \hat{a}_{p'}^\dagger - \hat{a}_{p', -}^\dagger \hat{a}_{p', +} \hat{a}_{p, +}^\dagger \hat{a}_{p, -} \right) \\
  =& \sum_{p,p'} \left(\hat{a}_{p', +}^\dagger \hat{a}_{p, -} \hat{a}_{p', -}^\dagger \hat{a}_{p'}^\dagger - \hat{a}_{p', -}^\dagger (\delta_{++} \delta_{p, p'} - \hat{a}_{p, +}^\dagger \hat{a}_{p'}) \hat{a}_{p, -} \right) \\
  =& \sum_{p,p'} \left(\hat{a}_{p', +}^\dagger \hat{a}_{p, -} \hat{a}_{p', -}^\dagger \hat{a}_{p'}^\dagger - \hat{a}_{p', -}^\dagger \delta_{p, p'} \hat{a}_{p', -} + \hat{a}_{p', -}^\dagger \hat{a}_{p, +}^\dagger \hat{a}_{p', +} \hat{a}_{p, -} \right) \\
  =& \sum_{p,p'} \left(\hat{a}_{p', +}^\dagger \hat{a}_{p, -} \hat{a}_{p', -}^\dagger \hat{a}_{p'}^\dagger - \hat{a}_{p', -}^\dagger \delta_{p, p'} \hat{a}_{p', -} + \hat{a}_{p, +}^\dagger \hat{a}_{p', -}^\dagger \hat{a}_{p, -} \hat{a}_{p', +} \right) \\
  =& \sum_{p,p'} \left[\hat{a}_{p', +}^\dagger \hat{a}_{p, -} \hat{a}_{p', -}^\dagger \hat{a}_{p'}^\dagger - \hat{a}_{p', -}^\dagger \left(\delta_{-, -} \delta_{p, p'} - \hat{a}_{p, -} \hat{a}_{p', -}^\dagger\right) \hat{a}_{p', +} \right] \\
  =& \sum_{p, p'} \left(\hat{a}_{p, +}^\dagger \delta_{p, p'} \hat{a}_{p'+} - \hat{a}_{p', -}^\dagger \delta_{p, p'} \hat{a}_{p, -}\right) \\
  =& \sum_p \left(\hat{a}_{p, +}^\dagger \hat{a}_{p, +} - \hat{a}_{p, -}^\dagger \hat{a}_{p, -} \right) = 2\hat{J}_z
\end{align*}
$$

**(3):**

$$
\begin{align*}
  [\hat{J}^2, \hat{J}_\pm] =& [\hat{J}_+ \hat{J}_- + \hat{J}_z^2 - \hat{J}_z, \hat{J}_\pm] \\
  =& [\hat{J}_+ \hat{J}_-, \hat{J}_\pm] + [\hat{J}_z^2, \hat{J}_\pm] - [\hat{J}_z, \hat{J}_\pm]
\end{align*}
$$

Using the relations

$$
\begin{align*}
  [\hat{A}\hat{B}, \hat{C}] =& \hat{A}[\hat{B}, \hat{C}] + [\hat{A}, \hat{C}] \hat{B} \\
  [\hat{A}, \hat{B}\hat{C}] =& [\hat{A}, \hat{B}]\hat{C} + \hat{B}[\hat{A},\hat{C}]
\end{align*}
$$

we obtain

$$
  [\hat{J}^2, \hat{J}_\pm] = \hat{J}_+ [\hat{J}_-, \hat{J}_\pm] + [\hat{J}_+, \hat{J}_\pm] \hat{J}_- + \hat{J}_z [\hat{J}_z, \hat{J}_\pm] + [\hat{J}_z, \hat{J}_\pm]\hat{J}_z - [\hat{J}_z, \hat{J}_\pm]
$$

It follows that

$$
\begin{align*}
  [\hat{J}^2, \hat{J}_+] =& -2\hat{J}_+ \hat{J}_z + \hat{J}_z [\hat{J}_z, \hat{J}_+] + [\hat{J}_z, \hat{J}_+]\hat{J}_z - [\hat{J}_z \hat{J}_+] \\
  =& -2\hat{J}_+ \hat{J}_z + \hat{J}_z \hat{J}_+ + \hat{J}_+ \hat{J}_z - \hat{J}_+ \\
  =& -2\hat{J}_+ \hat{J}_z + \hat{J}_+ + \hat{J}_+ \hat{J}_z + \hat{J}_+ \hat{J}_z - \hat{J}_+ = 0
\end{align*}
$$

and

$$
\begin{align*}
  [\hat{J}^2, \hat{J}_-] =& -2\hat{J}_z \hat{J}_- + \hat{J}_z [\hat{J}_z, \hat{J}_-] + [\hat{J}_z, \hat{J}_-]\hat{J}_z - [\hat{J}_z \hat{J}_-] \\
  =& -2\hat{J}_z \hat{J}_- - \hat{J}_z \hat{J}_- + \hat{J}_- \hat{J}_z - \hat{J}_- \\
  =& \hat{J}_z \hat{J}_- - (\hat{J}_z \hat{J}_- + \hat{J}_-) + \hat{J}_- = 0
\end{align*}
$$

**(4)**

$$
\begin{align*}
  [\hat{J}^2, \hat{J}_z] =& [\hat{J}_+ \hat{J}_- + \hat{J}_z^2 - \hat{J}_z, \hat{J}_z] \\
  =& [\hat{J}_+ \hat{J}_-, \hat{J}_z] + [\hat{J}_z^2, \hat{J}_z] - [\hat{J}_z, \hat{J}_z] \\
  =& \hat{J}_+ [\hat{J}_-, \hat{J}_z] + [\hat{J}_+, \hat{J}_z] \hat{J}_- \\
  =& \hat{J}_+ \hat{J}_- - \hat{J}_+ \hat{J}_- = 0
\end{align*}
$$
</details>

In terms of the quasispin operators, the Hamiltonian components can be rewritten as
1. $\hat{H}_0 = \varepsilon\hat{J}_z$
2. $\hat{H}_1 = \frac{1}{2} -V (\hat{J}_+^2 + \hat{J}_-^2)$
3. $\hat{H}_2 = -\frac{1}{2} W (-\hat{N} + \hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+)$

where $\hat{N} = \sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma}$ is the number operator.

<details>
<summary>Proof</summary>

**(1):** This follows directly by substiting $\hat{J}_z$ into $\hat{H}_0$:
$$
  \hat{H}_0 = \frac{1}{2}\varepsilon \sum_{p, \sigma} \sigma \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} = \varepsilon\hat{J}_z
$$

**(2):** Using the anti-commutation relations of the creation and annihilation operators, we obtain

$$
\begin{align*}
  \hat{H}_1 =& -\frac{1}{2}V \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \sigma}^\dagger \hat{a}_{p',  -\sigma} \hat{a}_{p, -\sigma} \\
  =& -\frac{1}{2} V \sum_{p,p',\sigma} -\hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \sigma}^\dagger \hat{a}_{p, -\sigma} \hat{a}_{p', -\sigma} \\
  =& -\frac{1}{2} V \sum_{p,p',\sigma} -\hat{a}_{p, \sigma}^\dagger (\delta_{p,p'} \delta_{-\sigma, -\sigma} - \hat{a}_{p,-\sigma} \hat{a}_{p', \sigma}^\dagger) \hat{a}_{p', -\sigma} \\
  =& -\frac{1}{2} V \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, -\sigma} \hat{a}_{p', \sigma}^\dagger \hat{a}_{p', -\sigma}
\end{align*}
$$

Rewriting the sum over $\sigma$, we arrive at

$$
\begin{align*}
  \hat{H}_1 =& -\frac{1}{2} V \sum_{p,p'} \hat{a}_{p, +}^\dagger \hat{a}_{p, -} \hat{a}_{p', +}^\dagger \hat{a}_{p', -} + \hat{a}_{p, -}^\dagger \hat{a}_{p, +} \hat{a}_{p', -}^\dagger \hat{a}_{p', +} \\
  =& -\frac{1}{2}V \left[\sum_p \left( \hat{a}_{p, +}^\dagger \hat{a}_{p, -} \right) \sum_{p'} \left( \hat{a}_{p', +}^\dagger \hat{a}_{p', -} \right) + \sum_p \left( \hat{a}_{p, -}^\dagger \hat{a}_{p, +} \right) \sum_{p'} \left( \hat{a}_{p', -}^\dagger \hat{a}_{p', +} \right) \right] \\
  =& -\frac{1}{2} V (\hat{J}_+^2 + \hat{J}_-^2)
\end{align*}
$$

**(3):** Using the anti-commutation relations of the creation and annihilation operators, we obtain

$$
\begin{align*}
  \hat{H}_2 =& -\frac{1}{2} W \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', -\sigma}^\dagger \hat{a}_{p', \sigma} \hat{a}_{p, -\sigma} \\
  =& -\frac{1}{2} W \sum_{p,p',\sigma} -\hat{a}_{p, \sigma}^\dagger \hat{a}_{p', -\sigma}^\dagger \hat{a}_{p, -\sigma} \hat{a}_{p', \sigma} \\
  =& -\frac{1}{2} W \sum_{p,p',\sigma} -\hat{a}_{p, \sigma}^\dagger (\delta_{p, p'} \delta_{-\sigma,-\sigma} - \hat{a}_{p, -\sigma} \hat{a}_{p', -\sigma}^\dagger) \hat{a}_{p', \sigma} \\
  =& -\frac{1}{2} W \sum_{p,p',\sigma} -\hat{a}_{p, \sigma}^\dagger \delta_{p, p'} \hat{a}_{p', \sigma} + \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, -\sigma} \hat{a}_{p', -\sigma}^\dagger \hat{a}_{p', \sigma} \\
  =& -\frac{1}{2} W \left( -\sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} + \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, -\sigma} \hat{a}_{p', -\sigma}^\dagger \hat{a}_{p', \sigma} \right)
\end{align*}
$$

Rewriting the second sum over $\sigma$, we get

$$
\begin{align*}
  \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, -\sigma} \hat{a}_{p', -\sigma}^\dagger \hat{a}_{p', \sigma} =& \sum_{p, p'} \hat{a}_{p, +}^\dagger \hat{a}_{p, -} \hat{a}_{p', -}^\dagger + \hat{a}_{p, -}^\dagger \hat{a}_{p, +} \hat{a}_{p'+}^\dagger \hat{a}_{p', -} \\
  =& \sum_p \left(\hat{a}_{p, +}^\dagger \hat{a}_{p, -} \right) \sum_{p'} \left( \hat{a}_{p', -}^\dagger \hat{a}_{p', +} \right) + \sum_p \left(\hat{a}_{p, -}^\dagger \hat{a}_{p, +} \right) \sum_{p'} \left( \hat{a}_{p', +}^\dagger \hat{a}_{p', -} \right) \\
  =& \hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+
\end{align*}
$$

In terms of the number operator $\hat{N} = \sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma}$ we get

$$
  \hat{H}_2 = -\frac{1}{2} W (-\hat{N} + \hat{J}_+ \hat{J}_ + \hat{J}_- \hat{J}_+)
$$
</details>

The Hamiltonian commute with the quasispin operators. In particular, $[\hat{H}, \hat{J}^2] = 0$ means that $\hat{J}$ is a good quantum number, implying that the total spin is a conserved quntum number.

<details>
<summary>Proof</summary>

Expanding $[\hat{H}, \hat{J}^2]$ gives

$$
\begin{align*}
  [\hat{H}, \hat{J}^2] =& [\hat{H}_0 + \hat{H}_1 + \hat{H}_2, \hat{J}^2] \\
  =& [\hat{H}_0, \hat{J}^2] + [\hat{H}_1, \hat{J}^2] + [\hat{H}_2, \hat{J}^2] \\
  =& \varepsilon [\hat{J}_z, \hat{J}^2] - \frac{1}{2} V[\hat{J}_+^2 + \hat{J}_-^2, \hat{J}^2] - \frac{1}{2}W [-\hat{N} + \hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+, \hat{J}^2] \\
  =& -\frac{1}{2} V\left([\hat{J}_+^2, \hat{J}^2] + [\hat{J}_-^2, \hat{J}^2] \right) - \frac{1}{2} W\left(-[\hat{N}, \hat{J}^2] + [\hat{J}_+ \hat{J}_-, \hat{J}^2] + [\hat{J}_- \hat{J}_+, \hat{J}^2] \right)
\end{align*}
$$

Since $[\hat{J}_\pm, \hat{J}^2] = 0$, it follows that

$$
\begin{align*}
  [\hat{J}_\pm^2, \hat{J}^2] =& \hat{J}_\pm \underbrace{[\hat{J}_\pm, \hat{J}^2]}_{=0} + \underbrace{[\hat{J}_\pm, \hat{J}^2]}_{=0} \hat{J}_\pm = 0
  [\hat{J}_+ \hat{J}_-, \hat{J}^2] =& \hat{J}_+ \underbrace{[\hat{J}_-, \hat{J}^2]}_{=0} + \underbrace{[\hat{J}_+, \hat{J}^2]}_{=0} \hat{J}_- = 0 \\
  [\hat{J}_- \hat{J}_+, \hat{J}^2] =& \hat{J}_- \underbrace{[\hat{J}_+, \hat{J}^2]}_{=0} + \underbrace{[\hat{J}_-, \hat{J}^2]}_{=0} \hat{J}_+ = 0 \\
\end{align*}
$$

Thus, we are left with

$$
\begin{align*}
  [\hat{H}, \hat{J}^2] =& \frac{1}{2} W[\hat{N}, \hat{J}^2] \\
  =& \frac{1}{2} W \left(-[\hat{N}, \hat{J}_+ \hat{J}_-] - [\hat{N}, \hat{J}_z^2] + [\hat{N}, \hat{J}_z] \right) \\
  =& \frac{1}{2} W \left(-[\hat{N}, \hat{J}_+] \hat{J}_- - \hat{J}_+ [\hat{N}, \hat{J}_-] - [\hat{N}, \hat{J}_z] \hat{J}_z - \hat{J}_z [\hat{N}, \hat{J}_z] + [\hat{N}, \hat{J}_z] \right)
\end{align*}
$$

Evaluating $[\hat{N}, \hat{J}_\pm]$ gives

$$
\begin{align*}
  [\hat{N}, \hat{J}_\pm] =& \hat{N}\hat{J}_\pm - \hat{J}_\pm \hat{N} \\
  =& \left(\sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right) \left(\sum_{p'} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \right) - \left(\sum_{p'} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \right) \left(\sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right) \\
  =& \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \\
  =& \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \left(\delta_{\mp, \sigma} \delta_{p,p'} - \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \mp} \right) \hat{a}_{p, \sigma} \\
  =& \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} - \hat{a}_{p', \pm}^\dagger \delta_{\mp, \sigma} \delta_{p, p'} \hat{a}_{p, \sigma} + \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \mp} \hat{a}_{p, \sigma} \\
  =& \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} + \hat{a}_{p, \sigma}^\dagger \hat{a}_{p', \pm} \hat{a}_{p, \sigma} \hat{a}_{p', \mp} - \sum_p \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} \\
  =& \sum_{p,p',\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \hat{a}_{p', \mp} + \hat{a}_{p, \sigma}^\dagger \left(\delta_{p, p'} \delta_{\pm, \sigma} - \hat{a}_{p, \sigma} \hat{a}_{p', \pm}^\dagger \right) \hat{a}_{p', \mp} - \sum_p \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} \\
  =& \sum_p \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} - \sum_p \hat{a}_{p, \pm}^\dagger \hat{a}_{p, \mp} = 0
\end{align*}
$$

Evaluating $[\hat{N}, \hat{J}_z]$ yields

$$
\begin{align*}
  [\hat{N}, \hat{J}_z] =& \hat{N}\hat{J}_z - \hat{J}_z \hat{N} \\
  =& \left(\sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right) \left(\frac{1}{2} \sum_{p',\sigma} \sigma \hat{a}_{p', \sigma}^\dagger \hat{a}_{p', \sigma} \right) - \left(\frac{1}{2} \sum_{p',\sigma} \sigma \hat{a}_{p', \sigma}^\dagger \hat{a}_{p', \sigma} \right) \left(\sum_{p,\sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \right) \\
  =& \sum_{p,p',\sigma} \sigma \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} \hat{a}_{p', \sigma}^\dagger \hat{a}_{p', \sigma} - \sigma \hat{a}_{p', \sigma}^\dagger \hat{a}_{p', \sigma} \hat{a}_{p, \sigma}^\dagger \hat{a}_{p, \sigma} = 0
\end{align*}
$$

Hence $[\hat{H}, \hat{J}^2] = 0$.
</details>

To find the matrix representation of the LMG Hamiltonian, we use the spin operator equations

$$
\begin{align*}
  \hat{J}^2 \ket{j, j_z} =& j(j + 1) \ket{j, j_z} \\
  \hat{J}_z \ket{j, j_z} =& j_z \ket{j, j_z} \\
  \hat{J}_\pm \ket{j, j_z} =& \sqrt{j(j + 1) - j_z (j_z \pm 1)} \ket{j, j_z \pm 1} \\
  \hat{N} \ket{j, j_z} =& 2j \ket{j, j_z}
\end{align*}
$$

where $j$ denote the total spin and $j_z$ the $z$-projection of the spin. For a system with $N$ fermions, the total spin is $j = N/2$. The creation and annihilation structure of $\hat{J}_z$ reflects the number of fermions in the upper energy level relative to those in the lower level. Specifically, the eigenvalues of $\hat{J}_z$ correspond to half the difference between the number of particles in the upper level and the number in the lower level. When all $N$ particles occupy the upper level, the eigenvalue of $\hat{J}_z$ is $N/2$, while when all particles are in the lower level, the eigenvalue is $-N/2$. Between these extremes, the eigenvalues of $\hat{J}_z$ form a discrete sequence $j_z \in \set{-N/2, -N/2 + 1,\dots,N/2 - 1, N/2}$, which results in $N + 1$ possible states for the system.

To calculate the matrix elements of the Hamiltonian, we solve the time-independent Schrödinger equation $\hat{H}_j \ket{\psi_j} = E_{j, j_z}\ket{\psi_j}$, where 

$$
  \ket{\psi_j} = \sum_{j_z = -j}^j c_{j_z} \ket{j, j_z}
$$

Applying $\bra{j, j'_z}$ to both sides, we get

$$
  \sum_{j'_z, j_z=-N/2}^{N/2} c_{j_z} \braket{j, j'_z |\hat{H}_j |j, j_z} = \sum_{j'_z, j_z=-N/2}^{N/2} c_{j_z} E_{j, j_z} \underbrace{\braket{j, j'_z|j, j_z}}_{=\delta_{j_z j'_z}} = E_{j, j_z} c_{j_z}
$$

In terms of the quantum numbers, the non-zero matrix elements are

$$
\begin{align*}
  \braket{j, j_z |\hat{H}_j|j, j_z} =& j_z \epsilon - W [j^2 - j_z^2] \\
  \braket{j, j_z |\hat{H}_j|j, j_z + 2} =& -\frac{V}{2} \sqrt{[j(j + 1) - j_z (j_z - 1)][j(j + 1) - (j_z - 1)(j_z - 2)]} \\
  \braket{j, j_z + 2|\hat{H}_j|j, j_z} =& \braket{j, j_z|\hat{H}_j|j, j_z + 2}
\end{align*}
$$

<details>
<summary>Proof</summary>

The matrix elements of $\hat{H}$ in the $\ket{j,j_z}$ basis are given by

$$
  \braket{j, j'_z |\hat{H}_j |j, j_z} = \braket{j, j'_z |\hat{H}_{0,j} |j, j_z} + \braket{j, j'_z |\hat{H}_{1,j} |j, j_z} + \braket{j, j'_z |\hat{H}_{2,j} |j, j_z}
$$

The matrix elements of $\hat{H}_{0,j}$ are given by

$$
\begin{align*}
  \braket{j, j'_z |\hat{H}_{0,j} |j, j_z} =& \braket{j, j'_z | \varepsilon \hat{J}_z |j, j_z} \\
  =& \varepsilon j_z \braket{j, j'_z | j, j_z} \\
  =& \varepsilon j_z \delta_{j_z j'_z}
\end{align*}
$$

To find the matrix elements of $\hat{H}_{j,1}$, we evaluate

$$
\begin{align*}
  \braket{j, j'_z |\hat{H}_{1,j} |j, j_z} =& \Braket{j, j'_z | -\frac{1}{2} V (\hat{J}_+^2 + \hat{J}_-^2) |j, j_z} \\
  =& -\frac{1}{2} V \left( \braket{j, j'_z | \hat{J}_+^2 | j, j_z} + \braket{j, j'_z | \hat{J}_-^2 | j, j_z} \right) \\
\end{align*}
$$

Since 

$$
\begin{align*}
  \hat{J}_\pm^2 \ket{j, j_z \pm 1} =& \sqrt{j(j + 1) - j_z (j_z \pm 1)} \hat{J}_\pm \ket{j, j_z \pm 1} \\
  =& \sqrt{[j(j + 1) - j_z (j_z \pm 1)][j(j + 1) - (j_z \pm 1)(j_z \pm 2)]} \ket{j, j_z \pm 2}
\end{align*}
$$

we get 

$$
\begin{align*}
  \braket{j, j'_z |\hat{H}_{1,j} |j, j_z} =& -\frac{1}{2} V \left(\sqrt{[j(j + 1) - j_z (j_z + 1)][j(j + 1) - (j_z + 1)(j_z + 2)]} \braket{j, j'_z | j, j_z + 2} \right. \\
  &+ \left. \sqrt{[j(j + 1) - j_z (j_z - 1)][j(j + 1) - (j_z - 1)(j_z - 2)]} \braket{j, j'_z |j, j_z - 2} \right)
\end{align*}
$$

Using the orthonormality condition $\braket{j, j'_z | j, j_z + 2} = \delta_{j'_z, j_z + 2}$, the matrix elements are nonzero for $j'_z = j_z + 2$ and thus

$$
  \braket{j, j_z + 2 |\hat{H}_{1,} |j, j_z} = -\frac{1}{2} V \sqrt{[j(j + 1) - j_z (j_z + 1)][j(j + 1) - (j_z + 1)(j_z + 2)]}
$$

From the Hermiticity of $\hat{H}_{1,}$, we have 

$$
  \braket{j, j_z + 2|\hat{H}_{1,}|j, j_z} = \braket{j, j_z|\hat{H}_{1,}|j, j_z + 2}^* = \braket{j, j_z|\hat{H}_{1,j}|j, j_z + 2}
$$

To find the matrix elements of $\hat{H}_{2,j}$, we evaluate

$$
\begin{align*}
  \braket{j, j'_z |\hat{H}_{2,j} |j, j_z} =& \Braket{j, j'_z | -\frac{1}{2} W \left(-\hat{N} + \hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+ \right) |j, j_z} \\
  =& -\frac{1}{2} W \left( -\braket{j, j'_z | \hat{N}|j, j_z} + \braket{j, j'_z | \hat{J}_+ \hat{J}_-| j, j_z} + \braket{j, j'_z| \hat{J}_- \hat{J}_+ |j, j_z} \right)
\end{align*}
$$

Since $\hat{N} \ket{j, j_z} = 2j \ket{j, j_z}$, we get

$$
  \braket{j, j'_z | \hat{N}|j, j_z} = 2j \delta_{j_z, j'_z}
$$

Furthermore, we find that

$$
\begin{align*}
  \hat{J}_+ \hat{J}_- \ket{j, j_z} =& \sqrt{j(j + 1) - j_z (j_z - 1)} \hat{J}_+ \ket{j, j_z - 1} \\
  =& \sqrt{j(j + 1) - j_z (j_z - 1)}\sqrt{j(j + 1) - (j_z - 1)[(j_z - 1) + 1]} \ket{j, j_z} \\
  =& j(j + 1) - j_z (j_z - 1) \ket{j, j_z}
\end{align*}
$$

and similarly

$$
  \hat{J}_- \hat{J}_+ \ket{j, j_z} = j(j + 1) - j_z (j_z + 1) \ket{j, j_z}
$$

Thus,

$$
\begin{align*}
  \Braket{j, j'_z | \hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+ |j, j_z} =& j(j + 1) - j_z (j_z - 1) \braket{j, j'_z | j, j_z} \\
  &+ j(j + 1) - j_z (j_z + 1) \braket{j, j'_z | j, j_z} \\
  =& [j(j + 1) - j_z (j_z - 1) + j(j + 1) - j_z (j_z + 1)]\delta_{j_z, j'_z} \\
  =& 2[j(j + 1) - j_z^2] \delta_{j_z, j'_z}
\end{align*}
$$

Combining the results, we obtain

$$
\begin{align*}
  \braket{j, j'_z |\hat{H}_{2,j} |j, j_z} =& -W \left[-j + j(j + 1) - j_z^2 \right] \delta_{j_z, j'_z} \\
  =& -W (j^2 - j_z^2) \delta_{j_z, j_z'}
\end{align*}
$$
</details>

<MathBox title='LMG Hamiltonian for $j = 1$' boxType='example'>

Here we construct the LMG Hamiltonian matrix for a two-fermion system with spin $j = 1$. The diagonal elements are given by

$$
\begin{align*}
  H_{11} =& \braket{1,-1|\hat{H}|1,-1} = -1\varepsilon - W [1^2 - (-1)^2] = -\varepsilon \\
  H_{22} =& \braket{1,0|\hat{H}|1,0} = 0\varepsilon - W [1^2 - 0^2] = -W \\
  H_{33} =& \braket{1,-1|\hat{H}|1,-1} = 1\varepsilon - W[1^2 - 1^2] = \varepsilon
\end{align*}
$$

The nonzero off-diagonal elements are

$$
\begin{align*}
  H_{13} =& \braket{1,1|\hat{H}|1,3} = -\frac{V}{2} \underbrace{\sqrt{[1(1 + 1) - 1(1 - 1)][1(1 + 1) - (1 - 1)(1 - 2)]}}_{=2} = -V \\
  H_{31} =& \braket{1,3|\hat{H}|1,1} = \braket{1,1|\hat{H}|1,3} = -V
\end{align*}
$$

Thus, the Hamiltonian takes the form

$$
  \mathbf{H} = \begin{bmatrix}
    -\varepsilon & 0 & - V \\
    0 & -W & 0 \\
    -V & 0 & \varepsilon 
  \end{bmatrix}
$$

To diagonalize $\mathbf{H}$, we solve the characteristic equation

$$
  0 = \det(\mathbf{H} - \lambda\mathbf{I}) = \begin{vmatrix}
    -\varepsilon - \lambda & 0 & -V \\
    0 & -W - \lambda & 0 \\
    -V & 0 & \varepsilon - \lambda
  \end{vmatrix}
$$

Using cofactor expansion along the second column, we can write $\det(\mathbf{H} - \lambda\mathbf{I})$ as

$$
  (-W - \lambda) \begin{vmatrix} -\varepsilon & - V \\ -V & \varepsilon - \lambda \end{vmatrix}
$$

The determinant of the $2\times 2$ submatrix is

$$
\begin{align*}
  (-\varepsilon - \lambda)(\varepsilon - \lambda) - (-V)(-V) =& (\lambda + \varepsilon)(\lambda - \varepsilon) - V^2 \\
  =& \lambda^2 - \varepsilon^2 - V^2
\end{align*}
$$

The full characteristic eqution is thus

$$
  (-W - \lambda)(\lambda^2 - \varepsilon^2 - V^2) = 0
$$

The first factor $(-W - \lambda) = 0$ gives the eigenvalue $\lambda_1 = -W$. The quadratic equation $\lambda^2 - \varepsilon^2 - V^2 = 0$ has solutions

$$
  \lambda = \pm\sqrt{\varepsilon^2 + V^2}
$$

Thus, the eigenvalues of $\mathbf{H}$ are

$$
\begin{align*}
  \lambda_1 =& -W \\
  \lambda_2 =& \sqrt{\varepsilon^2 + V^2} \\
  \lambda_3 =& -\sqrt{\varepsilon^2 + V^2}
\end{align*}
$$
</MathBox>

### Quantum circuit encoding

There are multiple ways to encode the LMG model using quantum circuits, including
- Occupation number basis
- Individual spin basis

#### Occupation number basis

Since the LMG model describes a two energy level system with $N$-fold degeneracy, we express the states of the states of the system in terms of occupation numbers in Fock space. To encode the LMG Hamiltonian on a quantum computer, we can use the Jordan-Wigner transformation to convert the fermionic operators into qubit operators, such that

$$
  \hat{H}_F (\hat{a}^\dagger, \hat{a}) \mapsto \hat{H}_Q (\sigma^{\pm, \sigma^i})
$$

where $\sigma^i$ defines the Pauli matrices for $i = \set{0,1,2,3} \to \set{\hat{I}, \hat{X}, \hat{Y}, \hat{Z}}$ and $\sigma^{\pm} = \hat{X} \pm i\hat{Y}$. The corresponding basis states for the two-level LMG model after this mapping are given by

$$
  \ket{\eta_{N-} \cdots \eta_{1-}, \eta_{N+} \cdots \eta_{1+}} \mapsto \ket{q_{2N-1}\cdots q_0}
$$

with $\eta\in\set{0,1}$, which represents an empty or occupied fermionic state, and $q\in\set{0,1}$ represents a spin up or down qubit state. In this scheme, the Hamiltonian is encoded in the full Fock-space with a size of $2^{2N}$. Thus, many states are not used leading inefficient use of circuits.

#### Individual spin basis

Since the LMG Hamiltonian is invariant under the exchange of particles within the set of two levels, we can exploit this symmetry to reduce the number of states by a factor of two. This can be naturally seen by considering the basis of the individual spin $\ket{\hat{j}_1,\dots,\hat{j}_N}$ of the particles, where $\hat{j} = \pm 1/2$. This can be straighforward mapped to qubit basis. To transform the LMG Hamiltonian in linear products of Pauli matrices, we simply express it in the individual spin basis by applying the following conversion

$$
  \hat{J}_z = \frac{1}{2} \sum_p \hat{j}_z^{(p)}
$$

where

$$
  \hat{j}_z^{(p)} = \hat{a}_{p, +}^\dagger \hat{a}_{p, +} - \hat{a}_{p, -}^\dagger \hat{a}_{p-}
$$

and similarly

$$
  \hat{J}_+ = \sum_p \hat{j}_+^{(p)}, \quad \hat{J}_- = \hat{J}_+^\dagger
$$

where

$$
  \hat{j}_+^{(p)} = \hat{a}_{p, +}^\dagger \hat{a}_{p, -}, \quad \hat{j}_-^{(p)} = \hat{a}_{p, -}^\dagger \hat{a}_{p, +}
$$

In terms of the individual spin operators, the LMG Hamiltonian takes the form

$$
\begin{align*}
  \hat{H}_0 =& \frac{\varepsilon}{2} \sum_p \hat{j}_z^{(p)} \\
  \hat{H}_1 =& \frac{V}{2} \sum_{p\neq q} \left(\hat{j}_+^{(p)} \hat{j}_+^{(q)} + \hat{j}_-^{(q)} + \hat{j}_-^{(q)} \right) \\
  \hat{H}_2 =& \frac{W}{2} \sum_{p\neq q} (\hat{j}_+^{(p)} \hat{j}_-^{(q)} + \hat{j}_-^{(p)} \hat{j}_+^{(q)})
\end{align*}
$$

For spin-$1/2$ particles, the individual spin operators are related to the Pauli matrices via

$$
\begin{align*}
  \hat{j}_x^{(p)} =& \frac{1}{2}\hat{X}_n / 2 \\
  \hat{j}_y^{(p)} =& \frac{1}{2}\hat{Y}_n / 2 \\
  \hat{j}_z^{(p)} =& \frac{1}{2}\hat{Z}_n / 2
\end{align*}
$$

Here, each Pauli operator $\hat{\sigma}_p \in \set{\hat{X}_p, \hat{Y}_p, \hat{Z}_p}$ is embedded in the $N$-qubit Hilbert space as the tensor product:

$$
  \hat{\sigma}_p = \hat{I}_2^{\otimes (p-1)} \otimes \hat{\sigma} \otimes \hat{I}_2^{\otimes (N - p + 1)}
$$

This transforms the LMG Hamiltonian into

$$
\begin{align*}
  \hat{H}_0 =& \frac{\varepsilon}{2} \varepsilon \sum_p \hat{Z}_p \\
  \hat{H}_1 =& \frac{V}{2} \sum_{p < q} (\hat{X}_p \hat{X}_q - \hat{Y}_p \hat{Y}_q) \\
  \hat{H}_2 =& \frac{W}{2} \sum_{p < q} (\hat{X}_p \hat{X}_q - \hat{Y}_p \hat{Y}_q)
\end{align*}
$$

<details>
<summary>Proof</summary>

In terms of Pauli strings, the $\hat{H}_0$ term can be expressed as

$$
  \hat{H}_0 = \epsilon\hat{J}_z = \epsilon \sum_{p=1}^N \hat{j}_z^{(p)} = \frac{\epsilon}{2} \sum_{p=1}^N \hat{Z}_p
$$

For the $\hat{H}_1$ term, we need to expand the $\hat{J}_\pm^2$ operators:

$$
\begin{align*}
  \hat{J}_\pm^2 =& \left(\sum_{p=1}^N \hat{j}_x^{(p)} \pm i\hat{j}_y^{(p)} \right)^2 = \sum_{p,q=1}^N \left(\hat{j}_x^{(p)} \pm i\hat{j}_y^{(p)}\right) \left(\hat{j}_x^{(q)} \pm i\hat{j}_y^{(q)}\right) \\
  =& \sum_{p,q=1}^N \left(\hat{j}_x^{(p)} \hat{j}_x^{(q)} - \hat{j}_y^{(p)} \hat{j}_y^{(q)} \pm i\hat{j}_y^{(p)} \hat{j}_x^{(q)} \pm i\hat{j}_x^{(p)} \hat{j}_y^{(q)}\right)
\end{align*}
$$

We can thus write $\hat{J}_+^2 + \hat{J}_-^2$ as

$$
\begin{align*}
  \hat{J}_+^2 + \hat{J}_-^2 =& 2 \sum_{p,q=1}^N \left(\hat{j}_x^{(p)} \hat{j}_x^{(q)} - \hat{j}_y^{(p)} \hat{j}_y^{(q)}\right) \\
  =& 2 \sum_{p=1}^N \left[\left(\hat{j}_x^{(p)} \right)^2 - \left(\hat{j}_y^{(p)} \right)^2 \right] + 4 \sum_{p > q}^N \left(\hat{j}_x^{(p)} \hat{j}_x^{(q)} - \hat{j}_y^{(p)} \hat{j}_y^{(q)}\right) \\
  =& \frac{1}{2} \sum_{p=1}^N (\underbrace{\hat{X}_p^2}_{=\hat{I}} - \underbrace{\hat{Y}_p^2}_{=\hat{I}}) + \sum_{p > q}^N (\hat{X}_p \hat{X}_q - \hat{Y}_p \hat{Y}_q) \\
  =& \sum_{p > q}^N (\hat{X}_p \hat{X}_q - \hat{Y}_p \hat{Y}_q)
\end{align*}
$$

For the $\hat{H}_2$ term, we need to expand the $\hat{J}_\pm \hat{J}_\mp$ operators:

$$
\begin{align*}
  \hat{J}_\pm \hat{J}_\mp =& \sum_{p,q=1}^n \left(\hat{j}_x^{(p)} \pm i\hat{j}_y^{(p)}\right)\left(\hat{j}_x^{(q)} \mp i\hat{j}_y^{(q)}\right) \\
  =& \sum_{pq} \left(\hat{j}_x^{(p)} \hat{j}_x^{(q)} + \hat{j}_y^{(p)} \hat{j}_y^{(q)} \mp i\hat{j}_x^{(p)} \hat{j}_y^{(q)} \pm i\hat{j}_y^{(p)} \hat{j}_x^{(q)}\right)
\end{align*}
$$

We can thus express $\hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+$ as

$$
\begin{align*}
  \hat{J}_+ \hat{J}_- + \hat{J}_- \hat{J}_+ =& \sum_{p,q=1}^N \left(\hat{j}_x^{(p)} \hat{j}_x^{(q)} + \hat{j}_y^{(p)} \hat{j}_y^{(q)}\right) \\
  =& 2 \sum_{p=1}^N \left[\left(\hat{j}_x^{(p)}\right)^2 + \left(\hat{j}_y^{(p)}\right)^2 \right] + 4 \sum_{p > q}^N \left(\hat{j}_x^{(p)} \hat{j}_x^{(q)} + \hat{j}_y^{(p)} \hat{j}_y^{(q)}\right) \\
  =& \frac{1}{2} \sum_{p=1}^N (\underbrace{\hat{X}_p^2}_{=\hat{I}} + \underbrace{\hat{Y}_p^2}_{=\hat{I}}) + \sum_{p < q}^N (\hat{X}_p \hat{X}_q + \hat{Y}_p \hat{Y}_q) \\
  =& \underbrace{N\hat{I}}_{=\hat{N}} + \sum_{p < q}^N (\hat{X}_p \hat{X}_q + \hat{Y}_p \hat{Y}_q) 
\end{align*}
$$
</details>