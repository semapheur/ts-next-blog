---
title: 'Quantum Mechanics'
subject: 'Physics'
showToc: true
references:
  - book_auletta_etal_2009
  - book_bengtsson_zyczkowski_2017
  - book_bertlmann_friis_2023
  - book_das_2023
  - book_d√ºrr_lazarovici_2020
  - article_einstein_podolsky_rosen_1935
  - book_griffiths_schroeter_2018
---

# Linear algebra

## Dirac notation (bra-ket)

Let $V$ be an inner product space over a field $\mathbb{F}$ with dual space $V^*$. In Dirac notation:
- A *ket* $\ket{v}\in V$ denotes a vector representing the state of a quantum system
- A *bra* $\bra{f}\in V^*$ denotes a linear form $f : V \to\mathbb{F}$ and is a covector to $\ket{f}$
- A *bra-ket* $\braket{f|v} = \bra{f}(\ket{v})$ denotes an inner product $\braket{\cdot|\cdot}: V\times V \to\mathbb{F}$
- A *ket-bra* $\ket{v}\bra{f}$ denotes an outer product
- A *ket-ket* $\ket{v}\ket{w} = \ket{v}\otimes\ket{w}$ denotes a tensor product $\otimes: V \times V \to V \otimes V$

Bra-ket properties
- Conjugate symmetry: $\braket{\psi|\phi} = \braket{\phi|\psi}^*$
- Linearity in the second argument: $\braket{\psi | a_1\phi_1 + a_2 \phi_2} = a_1\braket{\psi|\phi_1} + a_2\braket{\psi|\phi_2}$
- Anti-linearity in the first argument: $\braket{a_1\psi_1 + a_2\psi_2 | \phi} = a_1^*\braket{\psi_1|\phi} + a_2^*\braket{\psi_2|\phi}$
- Positive definiteness: $\braket{\psi | \psi} \geq 0$ and $\braket{\psi|\psi} = 0 \iff \ket{\psi} = 0$
- Triangle inequality: $\sqrt{\braket{\psi + \phi | \psi + \phi}} \leq \sqrt{\braket{\psi|\psi}} + \sqrt{\braket{\phi|\phi}}$
- Schwarz inequality: $\left|\braket{\psi|\phi}\right|^2 \leq \braket{\psi|\psi} \braket{\phi|\phi}$
- Orthogonality: $\braket{\psi|\phi} = 0$ if and only if $\psi$ and $\phi$ are orthogonal
- Hermitian adjoint/conjugate: 
$$
\begin{align*}
  \ket{\psi}^\dagger &= \bra{\psi} \\
  \bra{\phi}^\dagger &= \ket{\phi}
\end{align*}
$$

## Hilbert space

<MathBox title='Hilbert space' boxType='definition'>
A *Hilbert space* $\mathcal{H}$ is a complete vector space over a field $\mathbb{F}$ equipped with an inner product $\braket{\cdot|\cdot}:\mathcal{H}\times\mathbb{H}\to\mathbb{F}$. The vector space structure of $\mathcal{H}$ ensures that for all $\ket{\psi},\ket{\varphi}\in\mathcal{H}$ and all scalars $a, b\in\mathbb{F}$, we have

$$
  a\ket{\psi} + b\ket{\varphi} \in\mathcal{H}
$$

For all $\ket{\psi}, \ket{\psi_1},\ket{\psi_2} \in\mathcal{H}$ and $a_1, a_2 \in\mathbb{F}$, the inner product satisfies
- **Positive definitess**: $\braket{\psi | \psi} \geq 0$ and $\braket{\psi|\psi} = 0 \iff \ket{\psi} = 0$
- **Linearity in the second argument:** $\braket{\psi | a_1\phi_1 + a_2 \phi_2} = a_1\braket{\psi|\phi_1} + a_2\braket{\psi|\phi_2}$ .
- **Conjugate symmetry:** $\braket{\psi|\phi} = \braket{\phi|\psi}^*$

By conjugate symmetry, the inner product is anti-linear in the first argument:

$$
  \braket{a_1\psi_1 + a_2\psi_2 | \phi} = a_1^*\braket{\psi_1|\phi} + a_2^*\braket{\psi_2|\phi}
$$

This inner product induces a norm $\norm{\cdot}:\mathcal{H}\to\R$ defined by $\norm{\psi} \mapsto \sqrt{\braket{\psi|\psi}}$. Completeness of $\mathcal{H}$ in the norm $\norm{\cdot}$ means that every Cauchy sequence $(\ket{\psi_n})_{n\in\N} \subset\mathcal{H}$, satisfying

$$
  \forall \epsilon > 0, \exists N\in\N: m,n \geq N \implies \norm{\ket{\psi_m} - \ket{\psi_n}} < \epsilon
$$

converges to an element $\ket{\psi}\in\mathcal{H}$.

A subset $\mathcal{H}' \subset\mathcal{H}$ which is a vector space and inherits the inner product and the norm from $\mathcal{H}$ is called a subspace of $\mathcal{H}$.
</MathBox>

Let $\d^3 \mathbf{x}$ denote the Lebesgue measure in $\R^3$. Then the set of square integrable functions

$$
  \mathcal{L}^2 (\R^3) := \Set{\psi\in\R^3 \to \mathbb{C} : \int_{\R^3} \norm{\psi(\mathbf{x})}^2 \;\d^3 \mathbf{x} < \infty}
$$

with the inner product

$$
  \braket{\psi|\varphi} := \int_{\R^3} \psi^*(\mathbf{x}) \varphi(\mathbf{x}) \;\d^3 \mathbf{x}
$$

is an infinite-dimensional Hilbert space.

<MathBox title='Normed and orthogonal vectors' boxType='definition'>
A vector $\ket{\psi}\in\mathcal{H}$ is *normed* if $\norm{\psi} = 1$. A normed vector is also called a *unit vector*. Two vectors $\ket{\psi},\ket{\varphi}\in\mathcal{H}$ are orthogonal if $\braket{\psi|\varphi} = 0$. The subspace in $\mathcal{H}$ of vector orthogonal to $\ket{\psi}$ is denoted

$$
  \mathcal{H}_{\psi^\perp} := \set{\varphi\in\mathcal{H} | \braket{\psi|\varphi} = 0}
$$
</MathBox>

<MathBox title='Ray' boxType='definition'>
Let $\mathcal{H}$ be a complex Hilbert space. For any normalized vector $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$, the *ray* associated with $\ket{\psi}$ is the set

$$
  S_\psi := \set{e^{i\alpha} \ket{\psi} | \alpha\in\R}
$$

That is, a ray $S_\psi$ consists of all vectors that differ from $\ket{\psi}$ by a global phase factor.
</MathBox>

Define the equivalence relation $\sim$ on the complex Hilbert space $\mathcal{H}$ such that for $\ket{\psi}, \ket{\varphi}\in\mathcal{H}$,

$$
  \ket{\psi}\sim\ket{\varphi} \iff \ket{\varphi} = e^{i\alpha} \ket{\psi},\; \alpha\in\R
$$

This relation satisfies
- **Reflexivity**: $\ket{\psi} = e^{i0}\ket{\psi}$, so $\ket{\psi}\sim\ket{\psi}$
- **Symmetry**: If $\ket{\psi}\sim\ket{\varphi}$, then $\ket{\varphi} = e^{i\alpha} \ket{\psi}$, and its inverse $\ket{\psi} = e^{-i\alpha} \ket{\varphi}$ also holds, implying $\ket{\varphi}\sim\ket{\psi}$

- **Transitivity:** If $\ket{\psi}\sim\ket{\varphi}$ and $\ket{\varphi}\sim\ket{\xi}$, then there exists $\alpha,\beta\in\R$ such that $\ket{\varphi} = e^{i\alpha}$ and $\ket{\xi} = e^{i\beta} \ket{\varphi}$. Thus,

$$
  \ket{\xi} = e^{i\beta} (e^{i\alpha}\ket{\psi}) = e^{i(\alpha + \beta)} \ket{\psi}
$$

so $\ket{\psi}\sim\ket{\varphi}$. 

The equivalence class of $\ket{\psi}\in\mathcal{H}$ under $\sim$ is precisely the ray associated with $\ket{\psi}$, i.e. $[\psi]_\sim = S_\psi$. The projective Hilbert space is the quotient space $\mathcal{PH} = \mathcal{H}/\sim$, which represents the space of quantum states modulo global phase factors.

## Basis

<MathBox title='Linear independence, span and basis' boxType='definition'>
Let $I\subseteq\N$ be an index set. A set of vectors $\set{\ket{\varphi_j}}_{j\in I} \subseteq\mathcal{H}$ is *linearly independent* if for every finite subset $\set{\ket{\varphi}_j}_{j=1}^n$ and $a_k \in\mathbb{F}$ with $k=1,\dots,n$

$$
  \sum_{j=1}^n a_i \varphi_i = 0
$$

holds only if all $a_k = 0$.

A Hilbert space $\mathcal{H}$ is finite-dimensional $\mathcal{H}$ contains at most $n = \dim(\mathcal{H}) < \infty$ linearly independent vectors. Otherwise $\mathcal{H}$ is called infinite-dimensional, i.e. $\dim(\mathcal{H}) = \infty$.

A set of vectors $\set{\ket{\varphi_j}}_{j\in I} \subseteq\mathcal{H}$ *spans* $\mathcal{H}$ if for every vector $\varphi\in\mathcal{H}$, there are $a_j \in\mathbb{F}$ with $j\in I$ such that

$$
  \varphi = \sum_{j\in I} a_j \varphi_j
$$

In this case we write

$$
  \mathcal{H} = \operatorname{span}\set{\ket{\varphi_j}}_{j\in I}
$$

A linearly independent set of vectors $\set{\ket{\varphi_j}}_{j\in I}$ spanning $\mathcal{H}$ is called a *basis* of $\mathcal{H}$ and the vectors $\varphi_j$ of this are called basis vectors. A basis $\set{\ket{e}_j}_{j\in I}\subset\mathcal{H}$ whose vectors satisfy

$$
  \braket{e_j|e_k} = \delta_{jk} := \begin{cases}
    0,\quad& j\neq k \\
    1,\quad& j = k
  \end{cases}
$$

is called an *orthonormal basis*. The Hilbert space $\mathcal{H}$ is separable if it has a countable basis.
</MathBox>

Let $\mathcal{H}$ be a Hilbert space with orthonormal basis $\set{\ket{e_j}}$. For $\ket{\psi}, \ket{\varphi} \in\mathcal{H}$ with $\psi_j = \braket{e_j|\psi}$ and $\varphi_j = \braket{e_j|\varphi}$, then

1. $\ket{\psi} = \sum_j \ket{e_j}\braket{e_j|\psi} = \sum_j \psi_j e_j$
2. $\braket{\varphi|\psi} = \sum_j \braket{e_j|\varphi}^* \braket{e_j|\psi} = \sum_j \braket{\varphi|e_j}\braket{e_j|\psi} = \sum_j \varphi_j^* \psi_j$
3. $\norm{\psi}^2 = \sum_j |\braket{e_j|\psi}|^2 = \sum_j |\psi_j|^2$
4. If $\varphi\in\mathcal{H}_{\psi^\perp}$, then $\norm{\varphi + \psi}^2 = \norm{\varphi}^2 + \norm{\psi}^2$

<details>
<summary>Proof</summary>

**(1):** If $\ket{\psi} = \sum_j a_j \ket{e_j}$, then

$$
\begin{align*}
  \braket{e_k|\psi} =& \Braket{e_k | \sum_j a_j e_j} \\
  =& \sum_j a_j \underbrace{\braket{e_k|e_j}}_{\delta_{kj}} \\
  =& a_k
\end{align*}
$$

and thus $\ket{\psi} = \sum_j \ket{e_j}\braket{e_j|\psi}$.

**(2):** From **(1)**, we have

$$
\begin{align*}
  \braket{\varphi} =& \Braket{\sum_j \varphi_j e_j | \sum_k \psi_k e_k} \\
  =& \sum_j \sum_k \varphi_j^* \psi_k \underbrace{\braket{e_j|e_k}}_{\delta_{jk}} \\
  =& \sum_j \varphi_j^* \psi_j = \sum_j \braket{e_j|\varphi}* \braket{e_j|\psi} \\
  =& \sum_j \braket{\varphi|e_j} \braket{e_j|\psi}
\end{align*}
$$

**(3):** Calculating $\norm{\psi}^2$

$$
  \norm{\psi}^2 = \braket{\psi|\psi} = \sum_j \braket{e_j|\psi}^* \braket{e_j|\psi} = \sum_j |\braket{e_j|\psi}|^2
$$
</details>

**(4):** For $\varphi\in\mathcal{H}_{\psi^\perp}$, we have

$$
  \braket{\psi|\varphi} = 0 = \braket{\psi|\varphi}^* = \braket{\varphi|\psi}
$$

such that

$$
\begin{align*}
  \norm{\varphi + \psi}^2 =& \braket{\varphi + \psi|\varphi + \psi} \\
  =& \braket{\varphi|\varphi} + \underbrace{\braket{\varphi|\psi}}_{=0} + \underbrace{\braket{\psi|\varphi}}_{=0} + \braket{\psi|\psi} \\
  =& \norm{\varphi}^2 + \norm{\psi}^2
\end{align*}
$$

### Pauli matrices

The Pauli matrices is a set of three complex $2\times 2$ matrices $\sigma_j \in\mathcal{M}_2 (\mathbb{C})$ defined as

$$
\begin{align*}
  \sigma_1 = \sigma_x = X :=& \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \\
  \sigma_2 = \sigma_y = Y :=& \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix} \\
  \sigma_3 = \sigma_z = Y :=& \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}
\end{align*}
$$

The Pauli matrices can be written in the general form 

$$
  \sigma_j = \begin{bmatrix} 
    \delta_{j3} & \delta_{j1} - i\delta_{j2} \\
    \delta_{j1} + i\delta_{j2} & -\delta_{j3}
  \end{bmatrix}
$$

where $\delta_{jk}$ is the Kronecker delta. The Hermitian adjoint of $\sigma_j$ is

$$
  \sigma_j^\dagger = \begin{bmatrix} 
    \delta_{j3} & \delta_{j1} + i\delta_{j2} \\
    \delta_{j1} - i\delta_{j2} & -\delta_{j3}
  \end{bmatrix}^\top = \sigma^j
$$

showing that the Pauli matrices are Hermitian.

The Paul matrices satisfy
1. $\sigma_j \sigma_k = \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l$ 
2. $[\sigma_j, \sigma_k] = \sigma_j \sigma_k - \sigma_k \sigma_j = 2i\varepsilon_{jkl} \sigma_l$
3. $[\sigma_j, \sigma_k]_+ = \sigma_j \sigma_k + \sigma_k \sigma_j = 2 \delta_{jk} I_2$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  \sigma_j \sigma_k =& \begin{bmatrix} 
    \delta_{j3} & \delta_{j1} - i\delta_{j2} \\
    \delta_{j1} + i\delta_{j2} & -\delta_{j3}
  \end{bmatrix} \cdot \begin{bmatrix} 
    \delta_{k3} & \delta_{k1} - i\delta_{k2} \\
    \delta_{k1} + i\delta_{k2} & -\delta_{k3}
  \end{bmatrix} \\
  =& \begin{bmatrix} 
    \delta_{j1}\delta_{k1} + \delta_{j2}\delta_{k2} + \delta_{j3}\delta_{k3} + i(\delta_{j1}\delta_{k2} - \delta_{j2}\delta_{k1}) & \delta_{j3}\delta_{k1} - \delta_{j1}\delta_{k3} + i(\delta_{j2}\delta_{k3} - \delta_{j3}\delta_{k2}) \\
    \delta_{j1}\delta_{k3} - \delta_{j3}\delta_{k1} + i(\delta_{j2}\delta_{k3} - \delta_{j3}\delta_{k2}) & \delta_{j1}\delta_{k1} + \delta_{j2}\delta_{k2} + \delta_{j3}\delta_{k3} - i(\delta_{j1}\delta_{k2} + \delta_{j2}\delta_{k1})
  \end{bmatrix} \\
  =& \begin{bmatrix}
      \delta_{jk} + i\varepsilon_{jkl}\delta_{l3} & \varepsilon_{jkl}\delta_{l1} - i\varepsilon_{jkl}\delta_{l2} \\
      \varepsilon_{jkl}\delta_{l1} + i\varepsilon_{jkl}\delta_{l2} & \delta_{jk} - i\varepsilon_{jkl}\delta_{l3}
    \end{bmatrix} \\
  =& \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l
\end{align*}
$$

**(2):** Using **(1)**, we have

$$
\begin{align*}
  [\sigma_j, \sigma_k] =& \sigma_j \sigma_k - \sigma_k \sigma_j \\
  =& \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l - (\underbrace{\delta_{kj}}_{=\delta_{kj}} I_2 + i\underbrace{\varepsilon_{kjl}}_{=-\varepsilon_{jkl}} \sigma_l) \\
   = 2i\varepsilon_{jkl} \sigma_l
\end{align*}
$$

**(3):** Using **(1)**, we have

$$
\begin{align*}
  [\sigma_j, \sigma_k]_+ =& \sigma_j \sigma_k + \sigma_k \sigma_j \\
  =& \delta_{jk} I_2 + i\varepsilon_{jkl} \sigma_l + \underbrace{\delta_{kj}}_{=\delta_{kj}} I_2 + i\underbrace{\varepsilon_{kjl}}_{=-\varepsilon_{jkl}} \sigma_l \\
   = 2 \delta_{jk} I_2
\end{align*}
$$
</details>

From the first property, we see that 

$$
  \sigma_j \sigma_j = \sigma_j^\dagger \sigma_j = \sigma_j \sigma_j^\dagger = \delta_{jj} I_2 = I_2
$$

meaning that the Pauli matrices are unitary. Additionally, for $\mathbf{a},\mathbf{b}\in\R^3$, the Pauli matrices satisfy the identity

$$
\begin{equation*}
  (\mathbf{a}\cdot\boldsymbol{\sigma})(\mathbf{b}\cdot\boldsymbol{\sigma}) = (\mathbf{a}\cdot\mathbf{b})I_2 + i(\mathbf{a} \times \mathbf{b})\cdot\boldsymbol{\sigma} 
\tag{\label{equation-109}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Recall that the cross-product of $\mathbf{a},\mathbf{b}\in\R^3$ can be written $\mathbf{a} \times \mathbf{b} = \sum_{j,k} a_j b_k \varepsilon_{jkl}$. Expanding the left-hand side of $\eqref{equation-109}$ gives

$$
\begin{align*}
  (\mathbf{a}\cdot\boldsymbol{\sigma})(\mathbf{b}\cdot\boldsymbol{\sigma}) =& \sum_{j,k} a_j b_k \sigma_j \sigma_k \\
  =& \sigma_{j,k} a_j b_k (\delta_{jk}\hat{I}_2 + i\varepsilon_{jkl}\sigma_l) \\
  =& \left(\sum_{j,k} a_j b_k \delta_{jk} \right)\hat{I}_2 + i \sum_{j,k} a_j b_k \varepsilon_{jkl} \sigma_l \\
  =& (\mathbf{a}\cdot\mathbf{b})I_2 + i(\mathbf{a} \times \mathbf{b})\cdot\boldsymbol{\sigma}
\end{align*}
$$
</details>

Actions on qubit basis vectors $\ket{0} = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right]$ and $\ket{1} = \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right]$:
- $\boldsymbol{\sigma}_x \ket{0} = \left[\begin{smallmatrix} 0 & 1 \\ 1 & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \ket{1}$
- $\boldsymbol{\sigma}_x \ket{1} = \left[\begin{smallmatrix} 0 & 1 \\ 1 & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \ket{0}$
- $\boldsymbol{\sigma}_y \ket{0} = \left[\begin{smallmatrix} 0 & -i \\ i & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 0 \\ i \end{smallmatrix}\right] = i\ket{1}$
- $\boldsymbol{\sigma}_y \ket{1} = \left[\begin{smallmatrix} 0 & -i \\ i & 0 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \left[\begin{smallmatrix} -i \\ 0 \end{smallmatrix}\right] = -i\ket{0}$
- $\boldsymbol{\sigma}_z \ket{0} = \left[\begin{smallmatrix} 1 & 0 \\ 0 & -1 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right] = \ket{0}$
- $\boldsymbol{\sigma}_z \ket{1} = \left[\begin{smallmatrix} 1 & 0 \\ 0 & -1 \end{smallmatrix}\right] \cdot \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right] = \left[\begin{smallmatrix} 0 \\ -1 \end{smallmatrix}\right] = -\ket{1}$

<MathBox title='Pauli matrices form a basis for $\mathbb{C}^{2\times 2}$' boxType='proposition'>
The set $\set{I_2, \sigma_x, \sigma_y, \sigma_z}$ is a basis for complex $2\times 2$ matrices, $\mathcal{M}_2 (\mathbb{C})$.

<details>
<summary>Proof</summary>

To show that $\set{\mathbf{I}_2, \boldsymbol{\sigma}_x, \boldsymbol{\sigma}_y, \boldsymbol{\sigma}_z}$ is a basis for $\mathcal{M}_2 (\mathbb{C})$, we need to verify:
1. The set is linearly independent
2. The set spans $\mathcal{M}_2 (\mathbb{C})$, i.e. $\operatorname{span}\set{\mathbf{I}_2, \boldsymbol{\sigma}_x, \boldsymbol{\sigma}_y, \boldsymbol{\sigma}_z} = \mathcal{M}_2 (\mathbb{C})$

To prove linear independence, we must show that for $c_0, c_1, c_2, c_3 \in\mathbb{C}$

$$
  c_0 I_2 + c_1 \sigma_x + c_2 \sigma_y + c_3 \sigma_z = \mathbf{0}_2
$$

implies $c_0 = c_1 = c_2 = c_3 = 0$. This gives the matrix equation

$$
\begin{bmatrix}
  c_0 + c_3 & c_1 - ic_2 \\
  c_1 + ic_2 & c_0 - c_3
\end{bmatrix} = \mathbf{0}_2
$$

and the matrix elements must satisfy

$$
\begin{align*}
  c_0 + c_3 =& 0 \\
  c_1 - ic_2 =& 0 \\
  c_1 + ic_2 =& 0 \\
  c_0 - c_3 =& 0
\end{align*}
$$

The first and fourth equations imply $c_0 = -c_3$ and $c_0 = c_3$, so $c_0 = c_3 = 0$. The second and third equations imply $c_1 = ic_2$ and $c_1 = -ic_2$, so $c_1 = c_2 = 0$.

An arbitrary complex $2\times 2$ matrix $A = \mathcal{M}_2 (\mathbb{C})$ is of the form

$$
  \mathbf{A} = \begin{bmatrix} a_{00} & a_{01} \\ a_{10} & a_{11} \end{bmatrix}
$$

We need to show that $\mathbf{A}$ can be written as a linear combination

$$
  \mathbf{A} = c_0 \mathbf{I}_2 + c_1 \boldsymbol{\sigma}_x + c_2 \boldsymbol{\sigma}_y + c_3 \boldsymbol{\sigma}_z
$$

where $c_0, c_1, c_2, c_3 \in\mathbb{C}$. This gives the matrix equation

$$
\begin{bmatrix}
  c_0 + c_3 & c_1 - ic_2 \\
  c_1 + ic_2 & c_0 - c_3
\end{bmatrix} = \begin{bmatrix} a_{00} & a_{01} \\ a_{10} & a_{11} \end{bmatrix}
$$

and the matrix elements must satisfy

$$
\begin{align*}
  c_0 + c_3 =& a_{00} \\
  c_1 - ic_2 =& a_{01} \\
  c_1 + ic_2 =& a_{10} \\
  c_0 - c_3 =& a_{11}
\end{align*}
$$

Adding the first and fourth equations gives

$$
  2c_0 = a_{00} + a_{11} \implies c_2 = \frac{1}{2}(a_{00} + a_{11})
$$

Adding the second and third equation gives

$$
  2c_1 = a_{01} + a_{10} \implies c_1 = \frac{1}{2}(a_{01} + a_{10})
$$

Subtracting the third equation from the second gives

$$
  -i2 c_2 = a_{01} - a_{10} \implies c_2 = i\frac{1}{2}(a_{01} - a_{10})
$$

Subtracting the first equation from the first gives

$$
  -2c_3 = a_{11} - a_{00} \implies c_3 = \frac{1}{2}(a_{00} - a_{11})
$$

Since $c_j$ exist for all $a_{kl}$, we conclude that any matrix in $\mathcal{M}_2 (\mathbb{C})$ can be written as a linear combination of $\mathbf{I}_2, \boldsymbol{\sigma}_x, \boldsymbol{\sigma}_y, \boldsymbol{\sigma}_z$.
</details>
</MathBox>

## Linear operators

<MathBox title='Linear operator' boxType='definition'>
A linear map $\hat{A}:\mathcal{H}\to\mathcal{H}$ is called an operator on the Hilbert space $\mathcal{H}$. The set of all operators on $\mathcal{H}$ is denoted by $\mathcal{L}(\mathcal{H})$. A linear map $\hat{T}:\mathcal{L}(\mathcal{H}) \to \mathcal{L}(\mathcal{H})$, that is, an operator acting on operators, is called a *super-operator*.

The operator norm of $\hat{A}\in\mathcal{L}(\mathcal{H})$ is given by

$$
\begin{equation*}
  \norm{\hat{A}} := \sup\Set{\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\ket{\psi}} = 1} 
\tag{\label{equation-107}}
\end{equation*}
$$

This norm measures the largest possible stretching effect that $\hat{A}$ can have on unit vectors in $\mathcal{H}$.

An operator $\hat{A}\in\mathcal{L}(\mathcal{H})$ is bounded if $\norm{\hat{A}} < \infty$. The set of bounded operators on $\mathcal{H}$ is denoted $\mathcal{B}(\hat{H})$.
</MathBox>

A linear operator is a mapping between two vector spaces that is preserved under vector addition and scalar multiplication

- Additivity: 
  - $\hat{A}\left(\ket{\phi_1} + \ket{\phi_2} \right) = \hat{A} \ket{\phi_1} + \hat{A} \ket{\phi_2}$
    - $\left( \bra{\psi_1} + \bra{\psi_2} \right)\hat{A} = \bra{\psi_1}\hat{A} + \bra{\psi_2}\hat{A}$
- Scalar multiplication
  - $\hat{A} \ket{a\phi} = a\hat{A} \ket{\phi}$
  - $ \left( \bra{\psi} a \right) \hat{A} = a \bra{\psi} \hat{A}$

The outer product $\ket{\psi}\bra{\phi}$ is a linear operator.

Operator properties
1. **Associativity:** $\hat{A}\hat{B}\hat{C} = \hat{A}\left(\hat{B}\hat{C}\right) = (\hat{A}\hat{B})\hat{C}$
2. **Power property:** $\left(\hat{A}\right)^n \left( \hat{A} \right)^m = \left(\hat{A}\right)^{n + m}$
3. **Inner product:** $\braket{\psi|\hat{A}|\phi} = \braket{\psi|\phi'} \in \mathbb{C}$ where $\ket{\phi'} = \hat{A}\ket{\phi}$
4. **Expectation:** $\langle\hat{A}\rangle_\psi = \frac{\braket{\psi | \hat{A} | \psi}}{\braket{\psi|\psi}}$

Bounded operator properties for $\hat{A},\hat{B}\in\mathcal{B}(\mathcal{H})$ and $a\in\mathbb{F}$
1. $\norm{\hat{A}\ket{\psi}} \leq \norm{\hat{A}}\cdot\norm{\ket{\psi}}$
2. $\norm{\hat{A}\hat{B}} \leq \norm{\hat{A}}\cdot\norm{\hat{B}}$
3. $\norm{\hat{A} + \hat{B}} \leq \norm{\hat{A}} + \norm{\hat{B}}$
4. $\norm{ a\hat{A}} = |a|\cdot\norm{\hat{A}}$

<details>
<summary>Proof</summary>

**(1):** Let $\ket{\psi}\in\mathcal{H}$ be nonzero. Then 

$$
  \norm{\frac{\psi}{\lVert\psi}}\rVert = 1
$$

and

$$
\begin{align*}
  \frac{1}{\norm{\psi}} \norm{ \cdot \lVert\hat{A}\psi} =& \norm{\hat{A}\frac{\psi}{\lVert\psi}}\rVert \\
  \leq& \sup\set{\norm{\hat{A}\varphi} : \ket{\varphi}\in\mathcal{H},\norm{\varphi} = 1} = \norm{\hat{A}} 
\end{align*}
$$

Hence,

$$
  \norm{\hat{A}\ket{\psi}} \leq \norm{\hat{A}}\cdot\norm{\ket{\psi}}
$$

**(2):** From the definition $\eqref{equation-107}$ and **(1)**, we have

$$
\begin{align*}
  \norm{\hat{A}\hat{B}} =& \sup\set{\norm{\hat{A}\hat{B}\psi} : \ket{\psi}\in\mathcal{H},\norm{\psi} = 1} \\
  =& \sup\set{\norm{\hat{A}}\cdot\norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  \leq& \norm{\hat{A}} \sup\set{\norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& \norm{\hat{A}}\cdot\norm{\hat{B}}
\end{align*}
$$

**(3):** From the definition $\eqref{equation-107}$, we have

$$
\begin{align*}
  \norm{\hat{A} + \hat{B}} =& \sup\set{\norm{(\hat{A} + \hat{B})\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  \leq& \sup\set{\norm{\hat{A}\psi} + \norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  \leq& \sup\set{\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H},\norm{\psi} = 1} \\
  &+ \sup\set{\norm{\hat{B}\psi} : \ket{\psi}\in\mathcal{H},\norm{\psi} = 1} \\
  =& \norm{\hat{A}} + \norm{\hat{B}}
\end{align*}
$$

**(4):** From the definition $\eqref{equation-107}$, we have

$$
\begin{align*}
  \norm{a\hat{A}} =& \sup\set{\norm{a\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& \sup\set{|a|\cdot\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& |a| \sup\set{\norm{\hat{A}\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1} \\
  =& |a|\cdot\norm{\hat{A}}
\end{align*}
$$
</details>

<MathBox title='Matrix representation of linear operators' boxType='definition'>
If $\mathcal{H}$ is a finite-dimensional Hilbert space with orthonormal basis $\set{\ket{e_j}}_{j=1}^{\dim\mathcal{H}}$, the matrix elements of a linear operator $\hat{A}$ on $\mathcal{H}$ is given by

$$
  A_{jk} := \braket{e_j | \hat{A}|e_k}
$$

The matrix representation of $\mathbf{A}$ in the basis $\set{\ket{e_j}}$ is the matrix

$$
  \mathbf{A} = (\mathbf{A}_{jk})_{j,k=1}^{\dim\mathcal{H}}
$$ 
</MathBox>

If $\set{\ket{e_j}}_{j=1}^{\dim\mathcal{H}}$ is a basis on a Hilbert space $\mathcal{H}$, a vector $\ket{\psi}\in\mathcal{H}$ can be expanded as 

$$
  \ket{\psi} = \sum_j \ket{e_j} \braket{e_j|\psi}
$$

Applying an operator $\hat{A}\in\mathcal{L}(\mathcal{H})$ on $\ket{\psi}$ gives

$$
\begin{align*}
  \hat{A}\ket{\psi} =& \ket{\hat{A}\psi} = \sum_j \ket{e_j} \braket{e_j|\hat{A}\psi} \\
  =& \sum_j \ket{e_j} \Braket{e_j|\hat{A}\sum_k|e_k \braket{e_k|\psi}} \\
  =& \sum_{j,k} \ket{e_j}\braket{e_j|\hat{A}|e_k} \braket{e_k|\psi}
\end{align*}
$$

Thus, we can express $\hat{A}$ in the form

$$
  \hat{A} = \sum_{j,k} \ket{e_j} \braket{e_j|\hat{A}|e_k}\bra{e_k} = \sum_{j,k} \ket{e_j} A_{jk} \bra{e_k} 
$$

### Rotation operators

<MathBox title='' boxType='proposition'>
If $\hat{A}\in\mathcal{L}(\mathcal{H})$ is an involuntary operator, i.e. $\hat{A}^2 = \hat{I}$, then

$$
  e^{i\theta \hat{A}} = \cos(\theta)\hat{I} + i\sin(\theta)\hat{A}
$$

<details>
<summary>Proof</summary>

Taking the Taylor series expansion of $e^{i\theta\hat{A}}$ and using the fact that $\hat{A}^2 = \hat{I}$ gives

$$
\begin{align*}
  e^{i\theta\hat{A}} =& \sum_{n=0}^\infty \frac{(i\theta \hat{A})^n}{n!} \\
  =& \hat{I} + i\theta \hat{A} - \frac{\theta^2 \hat{I}}{2!} - i\frac{\theta^3 \hat{A}}{3!} + \frac{\theta^4 \hat{I}}{4!} \\
  =& \left(\sum_{n=0}^\infty \frac{(-1)^n \theta^{2n}}{(2n)!} \right)\hat{I} + i \left(\sum_{n=1}^\infty \frac{(-1)^n \theta^{2n - 1}}{(2n - 1)!} \right)\hat{A} \\
  =& \cos(\theta)\hat{I} + i\sin(\theta)\hat{A}
\end{align*}
$$
</details>
</MathBox>

In terms of the Pauli matrices, any unitary operator $\hat{U}\in\mathrm{U}(2)$ takes the form

$$
  \mathbf{U} = u_0 \mathbf{I}_2 + i(u_x \boldsymbol{\sigma}_x + u_y \boldsymbol{\sigma}_y + u_z \boldsymbol{\sigma}_z) = u_0 \mathbf{I}_2 + i \mathbf{u}\cdot\boldsymbol{\sigma} 
$$

where $u_0^2 + |\mathbf{u}|^2 = 1$. This last restriction allows us to parametrize $u_0$ and $\mathbf{u}\in\R^3$ in terms of a real unit vector $\unitvec{n}\in\mathbb{S}^2 \subset\R^3$ parallel to $\mathbf{u}$ and a real number $\theta\in\R$ such that

$$
  \mathbf{U} = \cos\left(\frac{\theta}{2}\right)\mathbf{I}_2 - i\sin\left(\frac{\theta}{2}\right) \unitvec{n}\cdot\boldsymbol{\sigma} = e^{-i\theta \unitvec{n}\cdot\boldsymbol{\sigma} / 2}
$$

The unitary matrix $\mathbf{U}$ represents a counterclockwise rotation through an angle $\theta$ about $\unitvec{n}$. This operator is usually denoted 

$$
  \hat{R}_{\unitvec{n}}(\theta) = e^{-i\theta \unitvec{n}\cdot\boldsymbol{\sigma}}
$$

where $\boldsymbol{\sigma}$ are the Pauli matrices. Since the Pauli matrices are involuntary, i.e. $\hat{\sigma}_j = \hat{I}_2$, their exponentiation simplifies, allowing us to explicitly define the fundamental rotation operators about the Cartesian axes:

$$
\begin{align*}
  \hat{R}_x (\theta) =& e^{-i\theta\hat{\sigma}_x / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{\sigma}_x = \begin{bmatrix} \cos\left(\frac{\theta}{2}\right) & -i\sin\left(\frac{\theta}{2}\right) \\ -i\sin\left(\frac{\theta}{2}\right) & \cos\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  \hat{R}_y (\theta) =& e^{-i\theta\hat{\sigma}_y / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{\sigma}_y = \begin{bmatrix} \cos\left(\frac{\theta}{2}\right) & -\sin\left(\frac{\theta}{2}\right) \\ \sin\left(\frac{\theta}{2}\right) & \cos\left(\frac{\theta}{2}\right) \end{bmatrix} \\
  \hat{R}_z (\theta) =& e^{-i\theta\hat{\sigma}_z / 2} = \cos\left(\frac{\theta}{2}\right)\hat{I}_2 - i\sin\left(\frac{\theta}{2}\right)\hat{\sigma}_z = \begin{bmatrix} e^{-i\frac{\theta}{2}} & 0 \\ 0 & e^{i\frac{\theta}{2}} \end{bmatrix}
\end{align*}
$$

Let $V$ be a 3-dimensional vector space of $2\times 2$ Hermitian matrices with zero trace. Every such matrix $\mathbf{S}\in V$ can be written as $\mathbf{S} = \mathbf{s}\cdot\boldsymbol{\sigma}$, where $\mathbf{s}\in\R^3$ is a real vector. A unitary operator $\hat{U}\in\mathrm{U}(2)$ acts on $V$ by $\mathbf{S} \mapsto S' = \mathbf{USU}^\dagger$. In component form, this can be written as

$$
  \mathbf{s}\cdot\boldsymbol{\sigma} \mapsto \mathbf{s}' \cdot \boldsymbol{\sigma} = \mathbf{U}(\mathbf{s}\cdot\boldsymbol{\sigma}) \mathbf{U}^\dagger
$$

which defines a linear map $\hat{R}_U :\R^3 \to\R^3$. This is an isometry because it preserves the inner product. To verify this, consider $\mathbf{S} = \mathbf{s}\cdot\boldsymbol{\sigma}$ and $\mathbf{T} = \mathbf{t}\cdot\boldsymbol{\sigma}$ for $\mathbf{s},\mathbf{t}\in\R^3$. Then

$$
\begin{align*}
  \mathbf{s}'\cdot \mathbf{t}' =& \frac{1}{2}\operatorname{tr}(\mathbf{S}' \mathbf{T}') \\
  =& \frac{1}{2}\operatorname{tr}\left[(\mathbf{USU}^\dagger)(\mathbf{UTU}^\dagger) \right] \\
  =& \frac{1}{2}\operatorname{tr}(\boldsymbol{ST}) \\
  =& \mathbf{s}\cdot\mathbf{t}
\end{align*}
$$

This means that $\hat{R}_U \in \mathrm{SO}(3)$ represents a rotation in $\R^3$. We have thus establish a group homomorphism

$$
\begin{align*}
  \operatorname{U}(2)\to& \operatorname{SO}(3) \\
  \hat{U} \mapsto \hat{R}_U
\end{align*}
$$

### Trace

<MathBox title='Trace' boxType='definition'>
Let $\set{\ket{e_j}}_{j=1}^{n\in\N}$ be an orthonormal basis in a finite-dimensional Hilbert space $\mathcal{H}$. The trace is defined as the map $\operatorname{tr}: \mathcal{L}(\mathcal{H}) \to\mathbb{F}$ given by

$$
  \operatorname{tr}(\hat{A}) := \sum_{j=1}^n \braket{e_j |\hat{A}e_j} = \sum_{j=1}^n \mathbf{A}_{jj}
$$
</MathBox>

Properties of the trace
- Linearity: $\operatorname{tr}(\hat{A} + \hat{B}) = \operatorname{tr}(\hat{A}) + \operatorname{tr}(\hat{B})$
- Commutatitivity: $\operatorname{tr}(\hat{A}\hat{B}) = \operatorname{tr}(\hat{B}\hat{A})$
- $\operatorname{tr}(\hat{A}\hat{B}) = 0, \;\forall \hat{A}\in\mathcal{L}(\mathcal{H}) \iff \hat{B} = 0$

### Hermitian adjoint

<MathBox title='Hermitian adjoint' boxType='definition'>
The $\hat{A}:\mathcal{H}\to\mathcal{H}$ be a linear operator on a Hilbert space $\mathcal{H}$. The Hermitian adjoint $\hat{A}$ is the unique linear operator $\hat{A}^\dagger :\mathcal{H}\to\mathcal{H}$ that satisfies

$$
  \braket{\varphi|\hat{A}\psi} = \braket{\hat{A}^\dagger \varphi|\psi},\; \forall \ket{\psi},\ket{\varphi} \in\mathcal{H}
$$

Equivalently, using Dirac notation, this condition can be rewritten as 

$$
  \braket{\varphi|\hat{A}|\psi} = \braket{\psi|\hat{A}^\dagger |\varphi}^*
$$

An operator $\hat{A}$ is Hermitian (or self-adjoint) if it it equal to its own adjoint:

$$
  \hat{A} = \hat{A}^\dagger
$$

An operator $\hat{A}$ is anti-Hermitian if it is the negative of its own adjoint:

$$
  \hat{A} = -\hat{A}^\dagger
$$

A Hermitian operator $\hat{A}$ is *positive* if for all $\ket{\psi}\in\mathcal{H}$,

$$
  \braket{\psi|\hat{A}|\psi} \geq 0
$$

which is written $\hat{A}\geq 0$. The operator $\hat{A}$ is *strictly positive* if for all nonzero $\ket{\psi}\in\mathcal{H}\setminus\set{0}$

$$
  \braket{\psi|\hat{A}|\psi} > 0
$$

which is written $\hat{A} > 0$.
</MathBox>

Hermitian adjoint properties
1. $\left(\hat{A}^\dagger \right)^\dagger = \hat{A}$
2. $\left(\hat{A} + \hat{B}\right)^\dagger = \hat{A}^\dagger + \hat{B}^\dagger$
3. $\left(\hat{A}\hat{B} \right)^\dagger = \hat{B}^\dagger\hat{A}^\dagger$
4. $\left(\hat{A}\ket{\psi}\right)^\dagger = \ket{\psi}\hat{A}^\dagger$
5. $\left(\ket{\psi}\bra{\phi}\right)^\dagger = \ket{\phi}\bra{\psi}$
6. $\ket{a\hat{A}\psi} = a^* \ket{\psi}\hat{A}^\dagger$ for any $a\in\mathbb{F}$
7. $(\hat{A}\times\hat{B})^\dagger = -\hat{B}^\dagger \times\hat{A}^\dagger$
8. $\hat{A}^{\dagger}\hat{B}\hat{C} + \hat{C}^{\dagger}\hat{B}\hat{A} = \frac{1}{2}\left[(\hat{A}+\hat{C})^{\dagger}\hat{B}(\boldsymbol{A}+\hat{C}) - (\hat{A}-\hat{C})^{\dagger} \hat{B}(\boldsymbol{A}-\hat{C})\right]$

<details>
<summary>Proof</summary>

**(7):** In terms of the Levi-Civita symbol, $\varepsilon_{ijk}$, we can write

$$
  (\hat{A}\times\mathbf{B})_i = \varepsilon_{ijk} A_j B_k
$$

Thus,

$$
\begin{align*}
  (\hat{A} \times \hat{B})^\dagger =& (\varepsilon_{ijk} A_j B_k)^\dagger = \varepsilon_{ijk} (A_j B_k)^\dagger \\
  =& \varepsilon_{ijk} B_k^\dagger A_j^\dagger = -\varepsilon_{ikj} B_k^\dagger A_j^\dagger \\
  =& -(\hat{B}^\dagger \times\hat{A}^\dagger)_i
\end{align*}
$$

**(8):** We start by expanding the operator products on the right-hand side. For the first term we have

$$
\begin{align*}
  (\hat{A} + \hat{C})^\dagger \hat{B} (\hat{A} + \hat{C}) =& (\hat{A}^\dagger + \hat{C}^\dagger) \hat{B} (\hat{A} + \hat{C}) \\
  =& \hat{A}^\dagger \hat{B}\hat{A} + \hat{A}^\dagger \hat{B}\hat{C} + \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C} 
\end{align*}
$$

Similarly, for the second term

$$
\begin{align*}
  (\hat{A} - \hat{C})^\dagger \hat{B} (\hat{A} - \hat{C}) =& (\hat{A}^\dagger - \hat{C}^\dagger) \hat{B} (\hat{A} + \hat{C}) \\
  =& \hat{A}^\dagger \hat{B}\hat{A} - \hat{A}^\dagger \hat{B}\hat{C} - \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C} 
\end{align*}
$$

Subtracting the terms yields

$$
\begin{align*}
  & \hat{A}^\dagger \hat{B}\hat{A} + \hat{A}^\dagger \hat{B}\hat{C} + \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C} \\
  -& (\hat{A}^\dagger \hat{B}\hat{A} - \hat{A}^\dagger \hat{B}\hat{C} - \hat{C}^\dagger \hat{B} \hat{A} + \hat{C}^\dagger \hat{B} \hat{C}) \\
  =& 2(\hat{A}^\dagger \hat{B}\hat{C} + \hat{C}^\dagger \hat{B} \hat{A})
\end{align*}
$$

This shows that

$$
  \hat{A}^{\dagger}\hat{B}\hat{C} + \hat{C}^{\dagger}\hat{B}\hat{A} = \frac{1}{2}\left[(\hat{A}+\hat{C})^{\dagger}\hat{B}(\boldsymbol{A}+\hat{C}) - (\hat{A}-\hat{C})^{\dagger} \hat{B}(\boldsymbol{A}-\hat{C})\right]
$$
</details>

### Unitary operator

<MathBox title='Unitary operator' boxType='definition'>
A linear operator $\hat{U}:\mathcal{H}\to\mathcal{H}$ on a Hilbert space $\mathcal{H}$ is *unitary* if its Hermitian adjoint equals its inverse;

$$
  \hat{U}^\dagger = \hat{U}^{-1}
$$

This implies that

$$
  \hat{U}\hat{U}^\dagger = \hat{U}^\dagger \hat{U} = \hat{I}
$$

where $\hat{I}$ is the identity operator on $\mathcal{H}$. The set of all unitary operators on $\mathcal{H}$ is denoted $\mathcal{U}(\mathcal{H})$.
</MathBox>

A unitary operator $\hat{U}\in\mathcal{U}(\mathcal{H})$ on a Hilbert space $\mathcal{H}$ has the following properties:

- **Preservation of inner products:** 

$$
  \braket{\hat{U}\psi|\hat{U}\varphi} = \braket{\psi|\hat{U}^\dagger U|\varphi} = \braket{\psi|\varphi},\; \forall \ket{\psi},\ket{\varphi}\in\mathcal{H}
$$

- **Preservation of norm:**

$$
  \norm{ \hat{U}\ket{\psi}} = \sqrt{\braket{\hat{U}\psi|\hat{U}\psi}} = \sqrt{\braket{\psi|\hat{U}^\dagger \hat{U}|\psi}} = \sqrt{\braket{\psi|\psi}} = \norm{\ket{\psi}}
$$

- **Preservation of trace:** Any normal operator $\hat{Q}$ can be written in terms of a orthonormal eigenbasis $\set{\ket{q_j}}$ as

$$
  \hat{Q} = \sum_j q_j \ket{q_j} \bra{q_j}
$$

Under a unitary transformation $\hat{U}$, the transformed operator $\hat{Q}_U$ is given by

$$
  \hat{Q}\mapsto \hat{Q}_U = \sum_j q_j \hat{U} \ket{q} \bra{q}_k \hat{U}^\dagger = \hat{U} \hat{Q} \hat{U}^\dagger
$$

Consequently, the trace of $\hat{Q}_U$ remains unchanged:

$$
\begin{align*}
  \operatorname{tr}(\hat{Q}_U) = \operatorname{tr}(\hat{U}\hat{Q}\hat{U}^\dagger) = \operatorname{tr}(\hat{U}^\dagger \hat{U} \hat{Q}) = \operatorname{tr}(\hat{Q})
\end{align*}
$$

<MathBox title='' boxType='proposition'>
Let $\set{\ket{e_j}}_{j=1}^{n\in\N}$ be an orthonormal basis of an $n$-dimensional Hilbert space $\mathcal{H}$. For $\hat{A},\hat{U}\in\mathcal{L}(\mathcal{H})$, we have

1. $\set{\ket{\tilde{e}_j} = \hat{U}\ket{e_j}}$ is an orthonormal basis in $\mathcal{H}$ if an only if $\hat{U}\in\mathcal{U}(\mathcal{H})$ is unitary
2. 
$$
  \sum_{j=1}^n \braket{e_j|\hat{A}|e_j} = \sum_j \braket{\tilde{e}_j|\hat{A}|\tilde{e}_j}
$$

<details>
<summary>Proof</summary>

**(1):** To show $\implies$, let $\set{\ket{\tilde{e}_j} = \hat{U}\ket{e_j}}$ be an orthonormal basis in $\mathcal{H}$. If follows that $U_{jk} = \braket{e_j |\hat{U}|e_k} = \braket{e_j|\tilde{e}_k}$ and thus

$$
\begin{align*}
  (\mathbf{U}\mathbf{U}^\dagger)_{kl} =& \sum_{j=1}^n \mathbf{U}_{kj} \mathbf{U}_{jl}^* = \sum_{j=1}^n \mathbf{U}_{kj} \mathbf{U}_{jk} \\
  =& \sum_{j=1}^n \braket{e_k|\tilde{e}_j} \braket{e_l|\tilde{e}_j}^* = \sum_{j=1}^n \braket{e_k|\tilde{e}_j}\braket{\tilde{e}_j|e_l} \\
  =& \Braket{e_k | \sum_{j=1}^n \tilde{e}_j \braket{\tilde{e}_j | e_l}} = \braket{e_k|e_l} \\
  =& \delta_{kl}
\end{align*}
$$

such that $U\in\mathcal{U}(\mathcal{H})$.

To show $\impliedby$, let $U\in\mathcal{U}(\mathcal{H})$ and $\ket{\tilde{e}_j} = \hat{U}\ket{e_j}$. For any $\set{a_j}\subset\mathbb{F}$ it follows that

$$
\begin{align*}
  &\sum_{j=1}^n a_j \ket{\tilde{e}_j} = 0 \implies& \sum_{j=1}^n a_j \hat{U}\ket{e_j} = 0 \\
  \implies& \hat{U} \sum_{j=1}^m a_j \ket{e_j} = 0 \implies& \hat{U}^\dagger \hat{U} \sum_{j=1}^n a_j \ket{e_j} \\
  \implies& \sum_{j=1}^n a_j\ ket{e_j} = 0 \implies& a_j = 0, \; \forall j
\end{align*}
$$

such that the $\set{\tilde{e}_j} \subset\mathcal{H}$ are linearly independent. Moreover, we have for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \hat{U}^\dagger \ket{\psi} =& \sum_{j=1}^n \braket{e_j|\hat{U}^\dagger|\psi}\ket{e_j} = \sum_{j=1}^n \braket{\hat{U}e_j | \psi}\ket{e_j} \\
  =& \sum_{j=1}^n \braket{\tilde{e}_j |\psi} \ket{e_j}
\end{align*}
$$

This implies that

$$
\begin{align*}
  \ket{\psi} =& \hat{U}\hat{U}^\dagger \ket{\psi} = \sum_{j=1}^n \braket{\tilde{e}_j | \psi}\hat{U}\ket{e_j} \\
  =& \sum_{j=1}^n \braket{\tilde{e}_j|\psi} \ket{\tilde{e}_j}
\end{align*}
$$

showing that any vector in $\mathcal{H}$ can be written as a linear combination of $\set{\ket{\tilde{e}_j}}$. Finally, we have

$$
\begin{align*}
  \braket{\tilde{e}_j|\tilde{e}_k} =& \braket{\hat{U}e_j | \hat{U}e_k} = \braket{e_j | \hat{U}^\dagger \hat{U}| e_k} \\
  =& \braket{e_j|e_k} = \delta_{jk}
\end{align*}
$$

**(2):** We have that

$$
\begin{align*}
  \sum_j \braket{\tilde{e}_j|\hat{A}|\tilde{e}_j} =& \sum_j \braket{\hat{U}e_j|\hat{A}\hat{U}|e_j} = \sum_j \braket{e_j | \hat{U}^* \hat{A} \hat{U} e_j} \\
  =& \sum_j (\hat{U}^\dagger \hat{A} \hat{U})_{jj} \\
  =& \sum_{j,k,l} \mathbf{U}_{jk}^\dagger \mathbf{A}_{jk} \mathbf{U}_{lj} = \sum_{k,l} \mathbf{A}_{kl} \sum_j \mathbf{U}_{lj} \mathbf{U}_{jl}^\dagger \\
  =& \sum_{k,l} \mathbf{A}_{kl} \sum_j \underbrace{(\mathbf{U}\mathbf{U}^\dagger)_{lk}}_{\delta_{lk}} = \sum_k \mathbf{A}_{kk} \\
  =& \sum_k \braket{e_k |\hat{A}| e_k}
\end{align*}
$$
</details>
</MathBox>

<MathBox title="Stone's theorem" boxType='theorem'>
Let $(U_t)_{t\in\R}$ be a strongly continuous one-parameter group on a Hilbert space $\mathcal{H}$, satisfying
1. $\hat{U}(t)$ is unitary for all $t\in\R$
2. $\hat{U}(t + s) = \hat{U}(t) \hat{U}(s)$ for all $s,t \in \R$
3. $\lim_{t\to 0} \norm{\hat{U}(t) \psi - \psi} = 0$ for all $\psi\in\mathcal{H}$

Then there exists a unique Hermitian operator $\hat{O}$ on $\mathcal{H}$ such tahat

$$
  \hat{U} = e^{it\hat{O}},\; \forall t\in\R
$$

Conversely, if $\hat{O}$ is Hermitian, then $e^{it\hat{O}}$ defines a strongly continuous one-parameter unitary group.
</MathBox>

The Stone theorem ensures the existence of a Hermitian infinitesimal generator for an Abelian group of unitary transformations.

### Eigenvalues

<MathBox title='Eigenvalue, eigenvector, eigenspace and spectrum' boxType='definition'>
Let $\hat{A}$ be a linear operator on a Hilbert space $\mathcal{H}$. A nonzero vector $\ket{\psi}\in\mathcal{H}$ is an *eigenvector* of $\hat{A}$ with *eigenvalue* $a\in\mathbb{F}$ if it satisfies the eigenvalue equation

$$
  \hat{A}\ket{\psi} = a\ket{\psi}
$$

The *eigenspace* associated with an eigenvalue $a$ is the subspace spanned by all eigenvectors corresponding to $a$, given by

$$
  \operatorname{eig}(\hat{A}, a) = \set{\ket{\psi} \in \mathcal{H}\setminus\set{0} | \hat{A}\ket{\psi} = a\ket{\psi}}
$$

An eigenvalue $a$ is called non-degenerate if its eigenspace is one-dimensional, meaning it has only one linearly independent eigenvector. Otherwise, $a$ is called degenerate. 

The spectrum of $\hat{A}$, denoted $\sigma(\hat{A})$, is the set of all scalars $a\in\mathbb{F}$ for which the operator $(\hat{A} - a\hat{I})^{-1}$ does not, exist, i.e.

$$
  \sigma(\hat{A}) := \set{a\in\mathbb{F} | (\hat{A} - a\hat{I})^{-1} \text{ does not exist}}
$$
</MathBox>

Let $\hat{A}\in\mathcal{L}(\mathcal{H})$ be an operator in a Hilbert space $\mathcal{H}$, and let $a$ be an eigenvalue with eigenvector $\ket{\psi}$, so that

$$
  \hat{A}\ket{\psi} = a\ket{\psi}
$$

Taking the adjoint on both sides, we get

$$
\begin{align*}
  (\hat{A}\ket{\psi})^\dagger =& (a\ket{\psi})^\dagger \\
  \bra{\psi}\hat{A} =& a^* \bra{\psi}
\end{align*}
$$

To confirm the result, consider the inner product with $\ket{\varphi}\in\mathcal{H}$:

$$
  \braket{\psi|\hat{A}^\dagger|\varphi} = \braket{\hat{A}\psi|\varphi} \braket{a\psi|\varphi} = a^* \braket{\psi|\varphi}
$$

This verifies that

$$
  \bra{\psi}\hat{A} = a^* \bra{\psi}
$$

#### Eigenvalues of Hermitian operators

Let $\hat{A}$ be a Hermitian operator on a Hilbert space $\mathcal{H}$, and consider the eigenvalue equation

$$
  \hat{A} \ket{\psi_i} = a_i \ket{\psi_i}
$$

Taking the inner product with another eigenvector $\ket{\psi_j}$, we obtain

$$
\begin{gather*}
\begin{aligned}
  \braket{\psi_i | \hat{A} \psi_j} &= \braket{\hat{A} \psi_i | \psi_j} \\
  \lambda_i^* \braket{\psi_i | \psi_j} &= \lambda_i \braket{\psi_i | \psi_j}
\end{aligned}\\
  \implies \left( \lambda_j^* - \lambda_i \right) \braket{\psi_i | \psi_j} = 0
\end{gather*}
$$

This leads to two conclusions:
1. If $i = j$, then $\lambda_i = \lambda_i^*$, meaning that all eigenvalue of a Hermitian operator are real. 
2. If $i \neq j$, then $\braket{\psi_i | \psi_j} = 0$, meaning that the eigenvectors corresponding to distinct eigenvalues are orthogonal.

In the finite-dimensional case, the smallest and larget eigenvalues of a Hermitian operator $\mathbf{A}$ serve as lower and upper bound of the inner product of $\braket{\psi|\hat{A}\psi}$ for normalized $\ket{\psi}$.

#### Eigenvalues of unitary operators

Let $\hat{U}\in\mathcal{U}(\mathcal{H})$ be a unitary operator on the Hilbert space $\mathcal{H}$ and let $u$ be an eigenvalue with eigenvector $\ket{\psi}\in\mathcal{H}$. Since unitary operators preserve norms, we get

$$
  \norm{\psi} = \norm{ \hat{U}\psi} = \norm{ u\psi} = |u|\cdot\norm{\psi}
$$

and thus $|u| = 1$, meaning that the eigenvalues of a unitary operator always lie on the unit circle in the complex plane.

#### Spectral decomposition of operators

A Hermitian operator $\hat{A}$ is diagonalizable, meaning that there is an orthonormal basis consisting of eigenvectors $\set{\ket{e_{j,\alpha}}}$ of $\hat{A}$ such that

$$
  \hat{A}\ket{e_{j,\alpha}} = a_j \ket{e_{j,\alpha}}
$$

where $\alpha\in\set{1,\dots,d_j}$ indexes the eigenvectors associated with the possibly $d_j$-fold degerate eigenvalue $a_j$.

The matrix elements in this basis have the form $\mathbf{A}_{j,\alpha;k,\beta} = a_j \delta_{j,k} \delta_{\alpha,\beta}$ such that

$$
\begin{align*}
  \mathbf{A} =& \sum_{j,k\alpha,\beta} \ket{e_{j,\alpha}} a_j \delta_{j,k} \delta_{\alpha,\eta} \bra{e_{k,\beta}} \\
  =& \sum_{j,\alpha} a_j \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}
\end{align*}
$$

This is referred to as the spectral decomposition or the diagonal form of the operator.

##### Infinite-dimensional case

If $\hat{A}$ is an operator with a complete set of orthonormal eigenvectors, i.e.

$$
  \hat{A}\ket{e_n} = a_n \ket{e_n}, \; n\in\N
$$

then it can be written in terms of its spectral decomposition:

$$
  \hat{A} = \sum_{n\in\N} a_n \ket{e_n} \bra{e_n}
$$

<details>
<summary>Proof</summary>

By completeness of the orthonormal eigenvectors, any vector $\ket{\psi}$ can be expanded as a linear combination

$$
  \ket{\psi} = \sum_{n\in\N} \psi_n \ket{e_n}
$$

where $\psi_n$ is given by the inner product

$$
  \braket{e_i|\psi} = \ket{e_i} \sum_{n\in\N} \psi_n \ket{e_n} = \sum_{n\in\N} \psi_n \braket{e_i|e_n} = \sum_{n\in\N} \psi_n \delta_{in}
$$

Hence, $\psi_n = \braket{e_n | \psi}$. Applying $\hat{A}$ to $\ket{\psi}$ yields

$$
\begin{align*}
  \hat{A}\ket{\psi} =& \hat{\psi} \sum_{n\in\N} \psi_n \ket{e_n} = \sum_{n\in\N} \psi_n (\hat{A}\ket{e_n}) \\
  =& \sum_{n\in\N} \psi_n (a_n \ket{e_n}) = \sum_{n\in\N} (a_n \ket{e_n}) \psi_n \\
  =& \sum_{n\in\N} \psi_n \ket{e_n} \braket{e_n | \psi} = \left(\sum_{n\in\N} a_n \ket{e_n} \bra{e_n} \right)\ket{\psi}  
\end{align*}
$$
</details>

The spectral decomposition of the $k$th power of $\hat{A}$ is

$$
  \hat{A}^k = \sum_{n\in\N} a_n^k \ket{e_n} \bra{e_n}
$$

<details>
<summary>Proof</summary>

This can be shown by induction. For the base case $k=2$, we have

$$
\begin{align*}
  \hat{A}^2 =& \left(\sum_{m\in\N} a_m \ket{e_m}\bra{e_m} \right) \left(\sum_{n\in\N} a_n \ket{e_n}\bra{e_n} \right) \\
  =& \sum_{m,n\in\N} a_m a_n \ket{e_m} \underbrace{\braket{e_m|e_n}}_{\delta_{mn}} \bra{e_n} \\
  =& \sum_{m\in\N} a_m^2 \ket{e_m} \bra{e_m} 
\end{align*}
$$

Assuming

$$
  \hat{A}^{k-1} = \sum_{m\in\N} a_m^{k-1} \ket{e_n} \bra{e_n}
$$

it follows that the spectral decomposition of $\hat{A}^k$ is

$$
\begin{align*}
  \hat{A}^k =& \left(\sum_{m\in\N} a_m^{k-1} \ket{e_m}\bra{e_m} \right) \left(\sum_{n\in\N} a_n \ket{e_n}\bra{e_n} \right) \\
  =& \sum_{m,n\in\N} a_m^{k-1} a_n \ket{e_m} \underbrace{\braket{e_m|e_n}}_{\delta_{mn}} \bra{e_n} \\
  =& \sum_{m\in\N} a_m^k \ket{e_m} \bra{e_m} 
\end{align*}
$$
</details>

The spectral decomposition of the exponential of $\hat{A}$ is

$$
  e^{\hat{A}} = \sum_{n\in\N} e^{a_n} \ket{e_n} \bra{e_n}
$$

<details>
<summary>Proof</summary>

Computing $e^{\hat{A}}$ we find

$$
\begin{align*}
  e^{\hat{A}} =& \sum_{n\in\N} e^{a_n} \ket{e_n} \bra{e_n} \\
  =& \sum_{n\in\N} \left(\sum_{k=0}^\infty \frac{q_n^k}{k!} \right) \ket{e_n} \bra{e_n} \\
  =& \sum_{k=0}^\infty \frac{1}{k!} \left(\sum_{n=1}^\infty a_n^k \ket{e_n} \bra{e_n} \right) \\
  =& \sum_{k=0}^\infty \frac{1}{k!} \hat{A}^k
\end{align*}
$$
</details>

### Projection operator

<MathBox title='Projection' boxType='definition'>
Let $\mathcal{H}$ be a Hilbert space. A projection operator (or simply projector) is a linear operator $\hat{P}\in\mathcal{L}(\mathcal{H})$ that is idempotent, i.e. $\hat{P}^2 = \hat{P}$. If, in addition $\hat{P}$ is Hermitian, i.e. $\hat{P}^\dagger = \hat{P}$, then $\hat{P}$ is called an *orthogonal projection*.
</MathBox>

The complement of a projection $\hat{P}\in\mathcal{L}(\mathcal{H})$ on a Hilbert space $\mathcal{H}$ is the operator $\hat{Q} = \hat{I} - \hat{P}$, which is also a projection since it satisfies idempotency:

$$
\begin{align*}
  \hat{Q}^2 =& (\hat{I} - \hat{P})^2 \\
  =& \hat{I} - 2\hat{P} + \underbrace{\hat{P}^2}_{=\hat{P}} \\
  =& \hat{I} - \hat{P} = \hat{Q}
\end{align*}
$$

If $\hat{P}$ is Hermitian, then so is $\hat{Q}$ since

$$
  \hat{Q}^\dagger = (\hat{I} - \hat{P})^\dagger = \hat{I} - \underbrace{\hat{P}^\dagger}_{=\hat{P}} = \hat{Q}
$$

meaning that $\hat{Q}$ is an orthogonal projection. In this case $\hat{P}$ and $\hat{Q}$ are mutually orthogonal projectors, satisfying

$$
  \hat{P}\hat{Q} = \hat{Q}\hat{P} = 0
$$

Thus, $\hat{P}$ and $\hat{Q}$ define an orthogonal decomposition of $\mathcal{H}$ into two subspaces, i.e. $\mathcal{H} = \operatorname{ran}(\hat{P}) \oplus \operatorname{ran}(\hat{Q})$. This orthogonal decomposition allows us to express any vector $\ket{\psi}\in\mathcal{H}$ uniquely as a sum components in the ranges of $\hat{P}$ and $\hat{Q}$:

$$
  \ket{\psi} = \hat{P}\ket{\psi} + \hat{Q}\ket{\psi}
$$

#### Projections onto unit vectors

If $\ket{\psi}\in \mathcal{H}$ is a unit vector in the Hilbert space $\mathcal{H}$, i.e. $\braket{\psi|\psi} = 1$, the projection onto $\ket{\psi}$ is given by

$$
  \hat{P}_\psi = \ket{\psi}\bra{\psi}
$$

To see that $\hat{P}_\psi$ is a projection, we compute

$$
\begin{align*}
  \hat{P}_\psi^2 =& (\ket{\psi}\bra{\psi})(\ket{\psi}\bra{\psi}) \\
  =& \ket{\psi}(\underbrace{\braket{\psi|\psi}}_{=1})\bra{\psi} \\
  =& \ket{\psi}\bra{\psi} = \hat{P}_\psi
\end{align*}
$$

showing that $\hat{P}_\psi$ is idempotent as required. Additionally, $\hat{P}$ is Hermitian, since

$$
  \hat{P}_\psi^\dagger = (\ket{\psi}\bra{\psi})^\dagger = \ket{\psi}\bra{\psi} = \hat{P}_\psi
$$

The projection of $\ket{\varphi}\in\mathcal{H}$ onto $\ket{\psi}$ becomes

$$
  \hat{P}_\psi \ket{\varphi} = \ket{\psi}\braket{\psi|\varphi} = \braket{\psi|\varphi}\ket{\psi}
$$

Since $\braket{\psi|\varphi}\in\mathbb{F}$ is a scalar, this means that $\hat{P}_\psi \ket{\varphi}$ projects $\ket{\varphi}$ onto the one-dimensional subspace spanned by $\ket{\psi}$.

The find the eigenvalues of $\hat{P}_\psi$, we solve

$$
\begin{align*}
  \hat{P}_\psi \ket{\lambda} =& \lambda\ket{\lambda} \\
  \ket{\psi}\underbrace{\braket{\psi|\lambda}}_{=c\in\mathbb{F}} =& \lambda\ket{\lambda} \\
  c\ket{\psi} =& \lambda\ket{\lambda}
\end{align*}
$$

If $\ket{\lambda} = \ket{\psi}$, then $\lambda = \braket{\psi|\lambda} = \braket{\psi|\psi} = 1$. Otherwise, for $\ket{\lambda}\neq\ket{\psi}$ we have $\lambda = \braket{\psi|\lambda} = 0$, implying that $\ket{\lambda}$ and $\ket{\psi}$ are orthogonal. Thus, the eigenvalues of $\hat{P}_\psi$ are $0$ and $1$, with the eigenspace corresponding to $\lambda = 1$ being spanned by $\ket{\psi}$, and the eigenspace corresponding to $\lambda = 0$ being the ortogonal complement of $\ket{\psi}$.

In terms of $\hat{P}_\psi$, any vector $\ket{\varphi}\in\mathcal{H}$ can be uniquely decomposed as 

$$
\begin{align*}
  \ket{\varphi} =& \hat{I}\ket{\varphi} + \hat{P}_\psi \ket{\varphi} - \hat{P}_\psi \ket{\varphi} \\
  =& \hat{P}_\psi \ket{\varphi} + (\hat{I} - \hat{P})\ket{\varphi}
\end{align*}
$$

Since 

$$
  \hat{P}_\psi (\hat{P}_\psi \ket{\varphi}) = \hat{P}_\psi^2 \ket{\varphi} = \hat{P}_\psi \ket{\varphi}
$$

then $\hat{P}_\psi \ket{\varphi}$ is an eigenvector of $\hat{P}_\psi$ with eigenvalue $1$. Since

$$
  \hat{P}_\psi [(\hat{I} - \hat{P}_\psi)\ket{\varphi}] = (\hat{P}_\psi - \underbrace{\hat{P}_\psi^2}_{=\hat{P}_psi})\ket{\varphi} = 0 
$$

then $(\hat{I} - \hat{P}_\psi)\ket{\varphi}$ is an eigenvector of $\hat{P}_\psi$ with eigenvalue $0$.

In particular, if $\set{\ket{e}_n}_{n\in\N}$ is an orthonormal basis, i.e. $\braket{e_i | e_j} = \delta_{ij}$, then

$$
  \sum_{n\in\N} \ket{e_n} \bra{e_n} = 1
$$

defines the identity operator. If we let this operator act on any vector $\ket{v}$, we recover the expansion of $\ket{\psi}$ in the $\set{\ket{e}_n}_{n\in\N}$ basis:

$$
  \sum_{n\in\N} (\braket{e_n|\psi})\ket{e_n} = \ket{\psi}
$$

If $\mathcal{H}' \subset\mathcal{H}$ is an $n$-dimensional subspace with orthonormal basis $\set{\ket{e}_i}_{i=1}^n$, the projection onto $W$ is given by

$$
  \hat{P}_{\mathcal{H}'} = \sum_{i=1}^n \ket{e_i}\bra{e_i}
$$

#### Spectral decomposition of Hermitian operators

If $\hat{A}$ is a Hermitian operator on an finite-dimensional Hilbert space $\mathcal{H}$, its eigenvectors form an orthonormal basis. Let $\ket{e_{j,\alpha}}$ denote an eigenvector of $\hat{A}$ corresponding to the eigenvalue $a_j$, where $\alpha\in\set{1,\dots,d_j}$ indexes the possibly $d_j$-fold degenerate eigenvalue $a_j$ of $\hat{A}$. The orthogonal projection onto the eigenspace $\operatorname{eig}(\hat{A}, a_j)$ with $\dim[\operatorname{eig}(\hat{A}, d_j)] = d_j$ is given by

$$
  \hat{P}_j = \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}
$$

<details>
<summary>Proof</summary>

To verify that $\hat{P}_j$ is a projection, we check idempotency

$$
\begin{align*}
  \hat{P}_j^2 =& \left(\sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}\right)  \left(\sum_{\beta=1}^{d_j} \ket{e_{j,\beta}} \bra{e_{j,\beta}}\right) \\
  =& \sum_{\alpha=1}^{\d_j} \sum_{\alpha=1}^{\d_j} \ket{e_{j,\alpha}} \underbrace{\braket{e_{j,\alpha}|e_{j,\beta}}}_{=\delta_{\alpha\beta}} \bra{e_{j,\beta}} \\
  =& \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} = \hat{P}_j
\end{align*}
$$

Since $\hat{P}_j^2 = \hat{P}_j$, it is a projection. Next, we check that $\hat{P}_j$ is Hermitian taking its adjoint:

$$
\begin{align*}
  \hat{P}_j^\dagger =& \left(\sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}}\right)^\dagger \\
  =& \sum_{\alpha=1}^{d_j} (\ket{e_{j,\alpha}} \bra{e_{j,\alpha}})^\dagger \\
  =& \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} = \hat{P}_j
\end{align*}
$$

Since $\hat{P}_j^\dagger = \hat{P}_j$, the operator is self-adjoint. Because $\set{\ket{e_{j,\alpha}}|j\in I\subset\N, \alpha\in\set{1,\dots,d_j}}$ is an orthonormal eigenbasis of $\hat{A}$, any eigenvector $\operatorname{eig}(\hat{A}, a_j)$ can be written in the form

$$
  \ket{\psi} = \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \braket{e_{j,\alpha}|\psi} = \hat{P}_j \ket{\psi}
$$
</details>

A Hermitian operator $\hat{A}$ can be expressed in terms of its spectral projections as

$$
  \hat{A} = \sum_{j,\alpha} a_j \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} = \sum_j a_j \hat{P}_j
$$

In particular, since any orthonormal basis $\set{\ket{e_j}}$ constitutes an eigenbasis of the identity operator $\hat{I}$ with eigenvalue $1$, we have

$$
\begin{align*}
  \hat{I} =& \sum_{j,k} \ket{e_j} \braket{e_j|e_k} \bra{e_k} \\
  =& \sum_{j,k} \delta_{jk} \ket{e_j} \bra{e_k} \\
  =& \sum_j \ket{e_j} \bra{e_j} = \sum_j \hat{P}_j
\end{align*}
$$

which is known as the completeness relation. Moreover, the projection satisfy the orthogonality relation

$$
\begin{align*}
  \hat{P}_j \hat{P}_k =& \left(\sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} \right) \left(\sum_{\beta=1}^{d_j} \ket{e_{j,\beta}} \bra{e_{j,\beta}} \right) \\
  =& \sum_{\alpha=1}^{d_j} \sum_{\beta=1}^{d_k} \ket{e_{j,\alpha}} \braket{e_{j,\alpha}|e_{k,\beta}} \bra{e_{k,\beta}} \\
  =& \delta_{jk} \sum_{\alpha=1}^{d_j} \ket{e_{j,\alpha}} \bra{e_{j,\alpha}} \\
  =& \delta_{jk} \hat{P}_j
\end{align*}
$$

#### Continuous projectors

If $V$ is an infinite-dimensional space, the continuous projector satisfy

$$
  \int \hat{P}(v) \;\d v = \int \ket{v}\bra{v} \;\d v = 1
$$

and

$$
  \hat{P}(v) \hat{P}(v') = \delta(v - v') \hat{P}(v)
$$

where $\delta$ is the Dirac delta function. In particular, if $\set{\ket{e_x}}_{x\in\R}$ is a Dirac orthonormalized continuous basis, i.e. $\braket{e_x | e_{x'}} = \delta(x - x')$, then

$$
  \int_\R \ket{e_x} \bra{e_x} \;\d x = 1 
$$

### Commutator

The commutator of two operators $\hat{A}$ and $\hat{B}$ is written

$$
  [\hat{A}, \hat{B}] := \hat{A}\hat{B} - \hat{B}\hat{A}
$$

while the anticommutator is written 

$$
\{\hat{A}, \hat{B}\} := \hat{A}\hat{B} + \hat{B}\hat{A}
$$

Commutator properties
- Self-commution: $[\hat{A}, \hat{A}] = 0$
- Antisymmetry: $[\hat{A}, \hat{B}] = -[\hat{B}, \hat{A}]$
- Linearity: $[\hat{A}, \hat{B} + \hat{C}] = [\hat{A}, \hat{B}] + [\hat{A}, \hat{C}]$
- Hermitian conjugable: $[\hat{A}, \hat{B}]^\dagger = [\hat{A}^\dagger, \hat{B}^\dagger]$
- Distributivity:
$$
\begin{align*}
  [\hat{A}, \hat{B}\hat{C}] &= [\hat{A}, \hat{B} ]\hat{C} + \hat{B}[ \hat{A}, \hat{C}] \\
  [\hat{A}\hat{B}, \hat{C}] &= \hat{A}[\hat{B}, \hat{C}] + [ \hat{A}, \hat{C}]\hat{B}
\end{align*}
$$
- $[\hat{A}^2,\hat{B}] = \hat{A}[\hat{A},\hat{B}] + [\hat{A},\hat{B}]\hat{A}$
- Jacobi identity: $\left[\hat{A}, [\hat{B}, \hat{C}]\right] + \left[\hat{B}, [\hat{C}, \hat{A}]\right] + \left[\hat{C}, [\hat{A}, \hat{B}]\right] = 0$
- Operators commute with scalars
- If $\hat{A}$ and $\hat{B}$ Hermitian operators then
  * $[\hat{A}, \hat{B}]$ is anti-Hermitian
  * $\{\hat{A}, \hat{B}\}$ is Hermitian

The commutator gives an alternative expression for the dot product of two operators $\hat{A}$ and $\hat{B}$

$$
  \hat{A}\cdot\hat{B} = \hat{A}_i \hat{B}_i = (\hat{A}_i \hat{B}_i - \hat{B}_i \hat{A}_i) + \hat{B}_i \hat{A}_i = [\hat{A}_i, \hat{B}_i] + \hat{B}_i \hat{A}_i = [\hat{A}_i, \hat{B}_i] + \hat{B}\cdot\hat{A} 
$$

and likewise for their cross product

$$
  (\hat{A}\times\hat{B})_i = \varepsilon_{ijk} \hat{A}_j \hat{B}_k = \varepsilon_{ijk}[(\hat{A}_j \hat{B}_k - \hat{B}_k \hat{A}_j) + \hat{B}_k \hat{A}_j] = \varepsilon_{ijk}([\hat{A}_j, \hat{B}_k] + \hat{B}_k \hat{A}_j) = -\varepsilon_{ikj} \hat{B}_k \hat{A}_j + \varepsilon_{ijk} [\hat{A}_j, \hat{B}_k] = -(\hat{B} \times \hat{A})_i + \varepsilon_{ijk} [\hat{A}_j, \hat{B}_k]
$$
    
Two operators $\hat{A}$ and $\hat{B}$ are said to commute if $[ \hat{A}, \hat{B}] = 0$. Two commuting operators share the same eigenvectors. Suppose $\hat{A}$ and $\hat{B}$ commute with common eigenvectors

$$
  \hat{A}\phi_i (\mathbf{x}) = \lambda_i \phi_i (\mathbf{x}),\quad \hat{B}\phi_i (\mathbf{x}) = \mu_i \phi_i (\mathbf{x})
$$

then any function $\phi$ can be expanded in terms of these eigenstates $\psi = \sum_i a_i \phi_i$ giving

$$
  [\hat{A}, \hat{B}]\psi = \sum_i a_i [\hat{A}, \hat{B}]\phi_i = \sum_i a_i \left(\lambda_i \mu_i - \mu_i \lambda_i \right)\phi_i = 0 
$$

## Spectral theory

### Completeness relation

If $\hat{A}$ is a self-adjoint operator on a Hilbert space with spectrum $\sigma(\hat{A})$, there is a projection-valued measure $E(\lambda)$ such that

$$
  \hat{A} = \int_{\sigma(\hat{A})} \lambda\;\d E(\lambda)
$$

In particular, if $\hat{A}$ has both discrete and continuous spectra, i.e. $\sigma(\hat{A}) = \sigma_\text{d} (\hat{A}) \cup \sigma_\text{c} (\hat{A})$, where
- $\sigma_\text{d} (\hat{A}) = \Set{a_i}$ is the set of discrete eigenvalues with corresponding eigenvectors $\set{\ket{a_i}}$
- $\sigma_\text{c} (\hat{A})$ is the continuum of eigenvalues with corresponding eigenfunctions $\set{\ket{\lambda}}$

then the identity operator $\hat{I}$ can be decomposed as

$$
  \hat{I} = \sum_i \ket{a_i} \bra{a_i} + \int_{\sigma_{\text{c}}(\hat{A})} \ket{\lambda}\bra{\lambda}\;\d\lambda
$$

which is known as the completeness relation.

## Tensor products

Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be Hilbert spaces. For $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$, we define the map $\ket{\varphi}\otimes\ket{\psi}:\mathcal{H}_A \times \mathcal{H}_B \to \mathbb{C}$ as

$$
  (\xi, \eta) \mapsto \braket{\xi|\varphi}_{\mathcal{H}_A} \braket{\eta|\psi}_{\mathcal{H}_B}
$$

called a tensor product. This is map is continuous and anti-linear in both $\xi$ and $\eta$. The set of all such maps is denoted

$$
  \mathcal{H}_A \otimes \mathcal{H}_B : \set{\Psi : \mathcal{H}_A \times \mathcal{H}_B \to \mathbb{C} | \text{anti-linear and continuous}}
$$

This set forms a vector space over $\mathbb{C}$ since for $\Psi_1, \Psi_2 \in\mathcal{H}_A \otimes \mathcal{H}_B$ and $a, b \in\mathbb{C}$, the map defined by

$$
  (a\Psi_1 + b\Psi_2)(\xi, \eta) := a\Psi_1 (\xi,\eta) + b\Psi_2 (\xi,\eta)
$$

is also in $\mathcal{H}_A \otimes \mathcal{H}_B$. The zero map is the zero vector in this vector space, and for any $\Psi \in \mathcal{H}_A \otimes \mathcal{H}_B$, the map $-\Psi$ is its additive inverse. In other words, the tensor product $\ket{\varphi}\otimes\ket{\psi}$ is a vector in the vector space of the anti-linear and continuous maps $\mathcal{H}_A \otimes \mathcal{H}_B$ from $\mathcal{H}_A \times \mathcal{H}_B$ to $\mathbb{C}$. More compactly, we also write

$$
  \ket{\varphi\otimes\psi} := \ket{\varphi}\otimes\ket{\psi}
$$

The tensor product has the following properties:
1. **Homogeneity:**
$$
  (a\ket{\varphi})\otimes\ket{\psi} = \ket{\varphi}\otimes (a\ket{\psi}) = a(\ket{\varphi} \otimes\ket{\psi})
$$
2. **Distributivity over scalar multiplication:**
$$
  a(\ket{\varphi}\otimes\ket{\psi}) + b(\ket{\varphi} \otimes\ket{\psi}) = (a + b)\ket{\varphi} \otimes \ket{\psi}
$$
3. **Distributivity over vector addition in the first argument:**
$$
  (\ket{\varphi_1} \otimes \ket{\varphi_2}) \otimes \ket{\psi} = \ket{\varphi_1}\otimes\ket{\psi} + \ket{\psi_2}\otimes\ket{\psi}
$$
4. **Distributivity over vector addition in the second argument:**
$$
  \ket{\psi}\otimes(\ket{\psi_1} + \ket{\psi_2}) = \ket{\varphi}\otimes\ket{\psi_1} + \ket{\varphi}\otimes\ket{\psi_2}
$$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  [(a\ket{\varphi})\otimes\ket{\psi}](\xi,\eta) =& \braket{\xi|a\varphi} \braket{\eta|\psi} \\
  =& a\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& a(\ket{\varphi}\otimes\ket{\psi})(\xi,\eta)
\end{align*}
$$

Similarly,

$$
\begin{align*}
  [\ket{\varphi} \otimes(a\ket{\psi})](\xi,\eta) =& \braket{\xi|\varphi} \braket{\eta|a\psi} \\
  =& a\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& \braket{\xi|a\varphi} \braket{\eta|\psi} \\
  =& [(a\ket{\varphi})\otimes\ket{\psi}](\xi,\eta)
\end{align*}
$$

**(2):**

$$
\begin{align*}
  [a(\ket{\varphi}\otimes\ket{\psi}) + b(\ket{\varphi} \otimes\ket{\psi})](\xi,\eta) =& a(\ket{\varphi}\otimes\ket{\psi})(\xi,\eta) + b(\ket{\varphi}\otimes\ket{\psi})(\xi,\eta) \\
  =& a\braket{\xi|\varphi}\ket{\eta|\psi} + b\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& (a + b)\braket{\xi|\varphi}\braket{\eta|\psi} \\
  =& (a + b)(\ket{\varphi}\otimes(\ket{\psi}))(\xi,\eta)
\end{align*}
$$

**(3):**

$$
\begin{align*}
  [(\ket{\varphi_1}\otimes\ket{\varphi_2})\otimes\ket{\psi}](\xi, \eta) =& \bra{\xi}(\ket{\varphi_1} + \ket{\varphi_2})\braket{\eta|\psi} \\
  =& (\braket{\xi|\varphi_1} + \braket{\xi|\varphi_2})\braket{\eta|\psi} \\
  =& \braket{\xi|\varphi_1}\braket{\eta|\psi} + \braket{\xi|\varphi_2}\braket{\eta|\psi} \\
  =& (\ket{\varphi_1}\otimes\ket{\psi} + \ket{\varphi_2}\otimes\ket{\psi})(\xi,\eta)
\end{align*}
$$

**(4):**

$$
\begin{align*}
  [\ket{\varphi}\otimes(\ket{\psi_1} + \ket{\psi_2})](\xi,\eta) =& \braket{\xi|\varphi}\bra{\eta}(\ket{\psi_1} + \ket{\psi_2}) \\
  =& \braket{\xi|\varphi}(\braket{eta|\psi_1} + \braket{\eta|\psi_2})
  =& ket{\varphi}\otimes\ket{\psi_1} + \ket{\varphi}\otimes\ket{\psi_2} \\
  =& (\ket{\varphi}\otimes\ket{\psi_1} + \ket{\varphi}\otimes\ket{\psi_2})(\xi,\eta)
\end{align*}
$$
</details>

For vectors $\ket{\varphi_k}\otimes\ket{\psi_k}\in\mathcal{H}_A \otimes \mathcal{H}_B$ with $k\in\set{1,2}$ and $\ket{\varphi_k}\in\mathcal{H}_A$, $\ket{\psi_k}\in\mathcal{H}_B$, we define the inner product as

$$
  \braket{\varphi_1 \otimes \psi|\varphi_2 \otimes\psi_2} := \braket{\varphi_1|\varphi_2}_{\mathcal{H}_A} \braket{\psi_1|\psi_2}_{\mathcal{H}_B}
$$

This defines an inner product for simple tensor product vectors $\ket{\varphi}\otimes\ket{\psi}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$. To extend this to all vectors $\Psi\in\mathcal{H}_A \otimes\mathcal{H}_B$, we consider an orthonormal basis for each Hilbert subspace. Let $\set{\ket{e_a}}\subset\mathcal{H}_A$ be an orthonormal basis in $\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$ be an orthonormal basis in $\mathcal{H}_B$. The set $\set{\ket{e_a}\otimes\ket{f_b}}\subset \mathcal{H}_A \otimes \mathcal{H}_B$ then forms an orthonormal basis for $\mathcal{H}_A \otimes \mathcal{H}_B$ since

$$
  \braket{e_{a_1} \otimes f_{b_1}|e_{a_2} \otimes f_{b_2}} = \braket{e_{a_1}|e_{a_2}}\braket{f_{b_1}|f_{b_2}} = \delta_{a_1 a_2} \delta_{b_1 b_2}
$$

<details>
<summary>Details</summary>

To verify that $\set{\ket{e_a}\otimes\ket{f_b}}$ is linearly independent, suppose there exists coefficients $\Psi_{ab}\in\mathbb{C}$ such that

$$
  \sum_{a,b} \Psi_{ab} \ket{e_a \otimes e_b} = 0 \in \mathcal{H}_A \otimes \mathcal{H}_B
$$

Applying this to an arbitrary pair $(\xi,\eta)\in\mathcal{H}_A \times \mathcal{H}_B$, we obtain

$$
  \left(\sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b}\right)(\xi,\eta) = \sum_{a,b} \Psi_{ab} \braket{e_a|\xi} \braket{f_b|\eta} = 0
$$

and in particular for every $(\xi,\eta) = (e_{a'}, f_{b'})$, we get

$$
  0 = \sum_{a,b} \Psi_{ab} \underbrace{\braket{e_a|e_{a'}}}_{\delta_{a,a'}} \underbrace{\braket{f_b|f_{b'}}}_{\delta_{b,b'}} = \Psi_{a', b'} 
$$

Since this holds for all $a'$ and $b'$, it follows that $\Psi_{ab} = 0$ for all $a, b$, proving that $\set{\ket{e_a}\otimes\ket{f_b}}$ is linearly independent.
</details>

Equivalently, for linear functionals acting on tensor product states, we define

$$
  \braket{\varphi_1 \otimes \psi_1}(\ket{\varphi_2} \otimes \ket{\psi_2}) = \braket{\varphi_1 \otimes \psi_1 | \varphi_2 \otimes \psi_2} = \braket{\varphi_1|\varphi_2}\braket{\psi_1|\psi_2}
$$

so that

$$
  \bra{\varphi\otimes\psi} = \ket{\varphi}\otimes\ket{\psi}
$$

In terms of orthonormal bases $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$, we can expand an arbitrary vector $\Psi\in\mathcal{H}_A \otimes \mathcal{H}_B$ as

$$
\begin{align*}
  \Psi(\xi,\eta) =& \Psi\left(\sum_a \ket{e_a}\braket{e_a|\xi}, \sum_b \ket{f_b}\braket{f_b|\eta} \right) \\
  =& \sum_{a,b} \underbrace{\Psi(\ket{e_a},\ket{f_b})}_{=:\Psi_{ab}\in\mathbb{C}} \braket{\xi|e_a}\braket{\eta|f_b} \\
  =& \sum_{a,b} \Psi_{ab}(\ket{e_a}\otimes\ket{f_b})(\xi, \eta) \\
  =& \sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b}(\xi,\eta)
\end{align*}
$$

showing that every vector $\ket{\Psi}\in\mathcal{H}_A \otimes \mathcal{H}_B$ can be written as a linear combination

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b}
$$

Given another vector $\ket{\Phi} = \sum_{a,b} \Phi_{ab} \ket{e_a \otimes f_b}$, the inner product is defined as

$$
\begin{equation*}
\begin{split}
  \braket{\Psi|\Phi} =& \sum_{a_1,b_1} \sum_{a_2,b_2} \Psi_{a_1 b_1}^* \Phi_{a_2 b_2} \braket{e_{a_1} \otimes f_{b_1}|e_{a_2} \otimes f_{b_2}} \\
  =& \sum_{a,b} \Psi_{ab}^* \Phi_{ab}
\end{split}
\tag{\label{equation-110}}
\end{equation*}
$$

<details>
<summary>Details</summary>

To verify that $\eqref{equation-110}$ is positive-definite, consider an orthonormal basis $\set{\ket{e_a}}$ of $\mathcal{H}_A$ and $\set{\ket{f_b}}$ of $\mathcal{H}_B$. Then for any $\ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a \otimes e_b}$, we have

$$
  \braket{\Psi|\Psi} = \sum_{a,b} |\Psi_{ab}|^2 \geq 0
$$

and thus

$$
  \braket{\Psi|\Psi} = 0 \iff \Psi_{ab} = 0 \forall a,b \iff \ket{\Psi} = 0
$$

This shows that $\braket{\Psi|\Phi}$ defines a valid inner product.

To show that the inner product is independent of the choice of orthonormal basis, let $\set{\ket{\tilde{e}_a}} \subset\mathcal{H}_A$ and $\set{\ket{\tilde{f}_b}}\subset\mathcal{H}_B$ be alternative orthonormal bases, related to the original bases by unitary transformations

$$
\begin{align*}
  \ket{\tilde{e}_a} =& \hat{U}_A \ket{e_a} = \sum_{a_1} \braket{e_{a_1}|\hat{U}_A e_a} \ket{e_{a_i}} = \sum_{a_1} \mathbf{U}_{a_1 a}^{(A)} \ket{e_{a_1}} \\
  \ket{\tilde{b}_a} =& \hat{U}_B \ket{f_b} = \sum_{b_1} \braket{f_{b_1}|\hat{U}_B f_b} \ket{f_{b_i}} = \sum_{b_1} \mathbf{U}_{b_1 b}^{(B)} \ket{f_{b_1}}
\end{align*}
$$

Expanding $\ket{\Phi}$ in terms of the new basis, we have

$$
\begin{align*}
  \ket{\Phi} =& \sum_{a_1, b_1} \Phi_{a_1 b_1} \ket{e_{a_1} \otimes f_{b_1}} = \sum_{a,b} \tilde{\Phi}_{ab} \ket{\tilde{e}_a \otimes \tilde{f}_b} \\
  =& \sum_{a,b} \tilde{\Phi}_{ab} \sum_{a_1} \mathbf{U}_{a_1 a}^{(A)} \ket{e_{a_1}} \otimes \sum_{b_1} \mathbf{U}_{b_1 b}^{(B)} \ket{f_{b_1}} \\
  =& \sum_{a_1, b_1} \sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Phi}_{ab} \ket{e_{a_1} \otimes f_{b_1}}
\end{align*}
$$

from which it follows that

$$
  \Psi_{a_1, b_1} = \sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Phi}_{ab}
$$

Similarly, we obtain

$$
  \Psi_{a_1 b_1} = \sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Psi}_{ab}
$$

Substituting the expansions into the inner product yields

$$
\begin{align*}
  \sum_{a_1 b_1} \Psi_{a_1 b_1}^* \Phi_{a_1 b_1} =& \sum_{a_1, b_1} \left(\sum_{a,b} \mathbf{U}_{a_1 a}^{(A)} \mathbf{U}_{b_1 b}^{(B)} \tilde{\Phi}_{ab} \right)^* \sum_{a_2, b_2} \mathbf{U}_{a_1 a_2}^{(A)} \mathbf{U}_{b_1 b_2}^{(B)} \tilde{\Phi}_{a_2 b_2} \\
  =& \sum_{a, b} \sum_{a_2, b_2} \sum_{a_1, b_1} (\mathbf{U}_{a_1 a}^{(A)})^* \mathbf{U}_{a_1 a_2}^{(A)} (\mathbf{U}_{b_1 b}^{(B)})^* \mathbf{U}_{b_1 b_2}^{(B)} \tilde{\Psi}_{ab}^* \tilde{\Phi}_{a_2 b_2} \\
  =& \sum_{a, b} \sum_{a_2, b_2} \underbrace{\left(\sum_{a_1} (\mathbf{U}_{aa_1}^{(A)})^\dagger \mathbf{U}_{a_1 a_2}^{(A)}\right)}_{=\delta_{aa_2}} \underbrace{\left(\sum_{b_1} (\mathbf{U}_{bb_1}^{(B)})^\dagger \mathbf{U}_{b_1 b_2}^{(B)}\right)}_{=\delta_{bb_2}} \tilde{\Psi}_{ab} \tilde{\Phi}_{a_2 b_2} \\
  =& \sum_{a,b} \tilde{\Psi}_{ab}^* \tilde{\Phi}_{ab}
\end{align*}
$$

showing that $\braket{\Psi|\Phi}$ remains invariant under a change of basis.
</details>

The dual vector (covector) associated with $\ket{\Psi}$ is given by

$$
  \bra{\Psi} = \sum_{a,b} \Psi_{ab}^* \ket{e_a \otimes f_b}
$$

The norm of $\ket{\Psi}$ is follows from the inner product definition:

$$
  \norm{\Psi}^2 = \braket{\Psi|\Psi} = \sum_{a,b} |\Psi_{ab}|^2
$$

For any $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$, the norm of $\ket{\varphi}\otimes\ket{\psi}$ is

$$
\begin{align*}
  \norm{\varphi\otimes\psi} =& \sqrt{\braket{\varphi\otimes\psi|\varphi\otimes\psi}} \\
  =& \sqrt{\braket{\varphi|\varphi}\braket{\psi|\psi}} = \norm{\varphi}\cdot\norm{\psi}
\end{align*}
$$

This shows that $\mathcal{H}_A \otimes \mathcal{H}_B$ is a complex inner product space. For finite-dimensional subspaces, completeness in the induced norm follows, implying that $\mathcal{H}_A \otimes \mathcal{H}_B$ is a Hilbert space, known as the tensor product Hilbert space. Its dimension is given by

$$
  \dim(\mathcal{H}_A \otimes \mathcal{H}_B) = \dim(\mathcal{H}_A) \dim(\mathcal{H}_B)
$$

<details>
<summary>Proof</summary>

If $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$ are finite-dimensional orthonormal bases, then $\set{\ket{e_a \otimes f_b}}$ forms an orthonormal basis in the tensor product $\mathcal{H}_A \otimes \mathcal{H}_B$. The dimension of the tensor product is given by the number basis, which is the product of the which is the product of the dimensions of the individual subspaces
</details>

Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional complex Hilbert spaces with $\dim(\mathcal{H}_A) = n_A$ and $\dim(\mathcal{H}) = n_B$, respectively. Suppose they have orthonormal bases $\set{\ket{e_a}}_{a=1}^{n_A}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}_{b=1}^{n_B}$. The tensor product space $\mathcal{H}_A \otimes \mathcal{H}_B$ has an orthonormal basis $\set{\ket{e_a \otimes f_b}}$ and we establish the isomorphism $\mathcal{H}_A \otimes \mathcal{H}_B \cong \mathbb{C}^{n_A n_B}$ by identifying each basis with a standard basis vectors in $\mathbb{C}^{n_A n_B}$, i.e.

$$
  \ket{e_a \otimes f_b} = \mathbf{e}_{(a-1)n_B + b} \in\mathbb{C}^{n_A n_B}
$$

Conceptually, this partitions the $n_A n_B$ coordinates of a vector in $\mathbb{C}^{n_A n_B}$ into $n_A$ row-blocks of $n_B$ entries each. For a general vector $\ket{\Psi}\in\mathcal{H}_A \otimes \mathcal{H}_B$, we have

$$
  \ket{\Psi} = \sum_{a=1}^{n_A} \sum_{b=1}^{n_B} \Psi_{ab} \ket{e_a \otimes f_b} = \begin{matrix} 1 \\ \vdots \\ (a - 1)n_B + b \\ \vdots \\ n_A n_B \end{matrix} \begin{bmatrix} \Psi_{11} \\ \vdots \\ \Psi_{ab} \\ \vdots \\ \Psi_{n_A n_B} \end{bmatrix}
$$

For several tensor products, such as $\mathcal{H}_A \otimes \mathcal{H}_B \otimes \mathcal{H}_C$, associativity holds

$$
  (\mathcal{H}_A \otimes \mathcal{H}_B) \otimes \mathcal{H}_C = \mathcal{H}_A \otimes (\mathcal{H}_B \otimes \mathcal{H}_C) = \mathcal{H}_A \otimes \mathcal{H}_B \otimes \mathcal{H}_C
$$

and accordingly

$$
  \braket{\varphi_1 \otimes \psi_1 \otimes \chi_1 | \varphi_2 \otimes \psi_2 \otimes \chi_2} = \braket{\varphi_1|\varphi_2}\braket{\psi_1|\psi_2}\braket{\chi_1|\chi_2}
$$

Likewise, with orthonormal bases $\set{\ket{e_a}}\subset\mathcal{H}_A$, $\set{\ket{f_b}}\subset\mathcal{H}_B$ and $\set{\ket{g_c}}\subset\mathcal{H}_C$, a vector $\ket{\Psi}\in\mathcal{H}^A \otimes \mathcal{H}_B \otimes \mathcal{H}_C$ can be expanded as

$$
  \ket{\Psi} = \sum_{a,b,c} \Psi_{abc} \ket{\psi_a \otimes f_b \otimes g_c}, \; \Psi_{abc}\in\mathbb{C}
$$

### Operators on tensor products

Let $\hat{M}^X : \mathcal{H}_X \to\mathcal{H}_X$ be Hermitian operators for $X \in\set{A,B}$. The tensor product operator $\hat{M}_A \otimes \hat{M}_B$ act factor-wise on a tensor product $\ket{\varphi\otimes\psi} = \ket{\varphi}\otimes\ket{\psi}$:

$$
  (\hat{M}_A \otimes \hat{M}_B) \ket{\varphi\otimes\psi} = \underbrace{(\hat{M}_A \ket{\varphi})}_{\in\mathcal{H}_A} \otimes \underbrace{\hat{M}_B \ket{\psi}}_{\in\mathcal{H}_B}
$$

By linearity, for an arbitrary vector $\ket{\Phi}\in\mathcal{H}_A \otimes \mathcal{H}_B$ expanded as

$$
  \ket{\Phi} = \sum_{a,b} \Phi_{ab} \ket{e_a} \otimes \ket{f_b}
$$

the tensor product operator acts as

$$
  (\hat{M}_A \otimes \hat{M}_B)\ket{\Phi} = \sum_{a,b} \Phi_{ab} (\hat{M}_A \ket{e_a}) \otimes (M_B \ket{f_b}) \in \mathcal{H}_A \otimes \mathcal{H}_B
$$

The Hermitian adjoint of the tensor product operator is given by

$$
  (\hat{M}_A \otimes \hat{M}_B)^\dagger = \hat{M}_A^\dagger \otimes \hat{M}_B^\dagger
$$

If $\hat{M}_A$ and $\hat{M}_B$ are Hermitian, i.e. $\hat{M}_X^\dagger = \hat{M}_X$ for $X\in\set{A,B}$, it follows that their tensor product is also Hermitian:

$$
  (\hat{M}_A \otimes \hat{M}_B)^\dagger = \hat{M}_A \otimes \hat{M}_B
$$

<details>
<summary>Proof</summary>

For $i\in\set{1,2}$ let $\ket{\varphi_i} \in\mathcal{H}_A$ and $\ket{\psi_i}\in\mathcal{H}_B$. Then we have

$$
\begin{align*}
  \Braket{(\hat{M}_A \otimes \hat{M}_B)^\dagger \varphi_1 \otimes \psi_1 | \varphi_2 \otimes \psi_2} =& \Braket{\varphi_1 \otimes\psi |(\hat{M}_A \otimes \hat{M}_B)|\varphi_2 \otimes \psi_2} \\
  =& \Braket{\varphi_1 \otimes \psi_1 | \hat{M}_A \varphi_2 \otimes \hat{M}_B \psi_2} \\
  =& \braket{\varphi_1 | \hat{M}_A| \varphi_2} \braket{\psi_1 |\hat{M}_B|\psi_2} \\
  =& \braket{\hat{M}_A^\dagger \varphi_1 | \varphi_2} \braket{\hat{M}_B^\dagger \psi_1 | \psi_2} \\
  =& \Braket{\hat{M}_A^\dagger \varphi_1 \otimes \hat{M}_B^\dagger \psi_1 | \varphi_2 \otimes \psi_2} \\
  =& \Braket{(\hat{M}_A^\dagger \otimes \hat{M}_B^\dagger)\varphi_1 \otimes \psi_1 | \varphi_2 \otimes \psi_2}
\end{align*}
$$
</details>

Suppose the operators $\hat{M}_X : \mathcal{H}_X \to \mathcal{H}_X$ for $X\in\set{A,B}$ have matrices $\mathbf{M}_{ij}^{(X)}$ in the respective basis $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_n}}\subset\mathcal{H}_B$. To find the matrix for the tensor product $\hat{M}_A \otimes \hat{M}_B$ in the basis $\set{\ket{e_a \otimes f_b}}\subset \mathcal{H}_A \otimes \mathcal{H}_B$, we expand it as

$$
\begin{align*}
  \hat{M}_A \otimes \hat{M}_B =& \sum_{a,a'=1}^{n_A} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b} \Braket{e_a \otimes f_b |(\hat{M}_A \otimes \hat{M}_B)|e_{a'} \otimes f_{b'}} \bra{e_{a'} \otimes f_{b'}} \\
  =& \sum_{a,a'=1}^{n_A} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b} \Braket{e_a \otimes f_b |\hat{M}_A e_{a'} \otimes \hat{M}_B f_{b'}} \bra{e_{a'} \otimes f_{b'}} \\
  =& \sum_{a,a'=1}^{n_A} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b} \braket{e_a | \hat{M}_A | e_{a'}} \braket{f_b | \hat{M}_B f_{b'}} \bra{e_{a'} \otimes f_{b'}} \\
  =& \sum_{a,a'=1}^{n_A} \mathbf{M}_{aa'}^{(A)} \mathbf{M}_{bb'}^{(B)} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b}\bra{e_{a'} \otimes f_{b'}} \tag{\label{equation-111}}
\end{align*}
$$

so that

$$
  \mathbf{M}_{aa'}^{(A)} \mathbf{M}_{bb'}^{(B)} \sum_{b,b'=1}^{n_B} \ket{e_a \otimes f_b}\bra{e_{a'} \otimes f_{b'}} = 
  \overset{\begin{matrix} 1\hphantom{-} & \cdots & \hphantom{\mathbf{M}} k \hphantom{\mathbf{M_{bb'}^{(B)}}} & \cdots & n \end{matrix}}{
  \begin{matrix} 1 \\ \vdots \\ j \\ \vdots \\ n \end{matrix}\begin{bmatrix}
    \vphantom{1}\hphantom{1} & \hphantom{\cdots} & | & \hphantom{\cdots} & \hphantom{n} \\
    \vphantom{\vdots} & & | & &  \\
    -- & -- & \mathbf{M}_{aa'}^{(A)} \mathbf{M}_{bb'}^{(B)} & & \\
    \vphantom{\vdots} & & & & \\
    \vphantom{n} & & & & 
  \end{bmatrix}
  }
$$

where $j = (a - 1)n_B + b$ and $k = (a' - 1)n_B + b'$. Inserting this into the expansion $\eqref{equation-111}$ gives

$$
\begin{gather*}
  \mathbf{M}_A \otimes \mathbf{M}_B = \\
  \overset{\begin{matrix} 1 \hphantom{---} & \cdots & n_B \hphantom{--} & n_B + 1 \hphantom{-} & \cdots & 2n_B \hphantom{--} & \cdots & n_A n_B \hphantom{--} \end{matrix}}{
  \begin{matrix} 1 \\ \vdots \\ n_B \\ n_B + 1 \\ \vdots \\ 2n_B \\ \vdots \\ n_A n_B \end{matrix}\begin{bmatrix}
    \mathbf{M}_{11}^{(A)} \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{11}^{(M)} \mathbf{M}_{1 n_B}^{(B)} & \mathbf{M}_{12}^{(A)} \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{12}^{(A)} \mathbf{M}_{1n_B}^{(B)} & \cdots & \mathbf{M}_{1n_A}^{(A)} \mathbf{M}_{1n_B}^{(B)} \\
    \vdots & & \vdots & \vdots & & \vdots & & \vdots \\
    \mathbf{M}_{11}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{11}^{(M)} \mathbf{M}_{n_B n_B}^{(B)} & \mathbf{M}_{12}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{12}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} & \cdots & \mathbf{M}_{1n_A}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} \\
    \mathbf{M}_{21}^{(A)} \mathbf{M}_{1 1}^{(B)} & \cdots & \mathbf{M}_{21}^{(M)} \mathbf{M}_{1 n_B}^{(B)} & \mathbf{M}_{22}^{(A)} \mathbf{M}_{1 1}^{(B)} & \cdots & \mathbf{M}_{22}^{(A)} \mathbf{M}_{1 n_B}^{(B)} & \cdots & \mathbf{M}_{2n_A}^{(A)} \mathbf{M}_{1 n_B}^{(B)} \\
    \vdots & & \vdots & \vdots & & \vdots & & \vdots \\
    \mathbf{M}_{21}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{21}^{(M)} \mathbf{M}_{n_B n_B}^{(B)} & \mathbf{M}_{22}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{22}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} & \cdots & \mathbf{M}_{2n_A}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} \\
    \vdots & & \vdots & \vdots & & \vdots & & \vdots \\
    \mathbf{M}_{n_A 1}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_A 1}^{(M)} \mathbf{M}_{n_B n_B}^{(B)} & \mathbf{M}_{n_A 2}^{(A)} \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_A 2}^{(A)} \mathbf{M}_{n_B n_B}^{(B)} & \cdots & \mathbf{M}_{n_A n_A}^{(A)} \mathbf{M}_{n_B n_B}^{(B)}
  \end{bmatrix}
  }
\end{gather*}
$$

This can be factored as the block matrix

$$
  \mathbf{M}_A \otimes \mathbf{M}_B = \begin{bmatrix} 
    \mathbf{M}_{11}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\ 
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix} & \cdots & \mathbf{M}_{1n_A}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix} \\ 
    \vdots & & \vdots \\
    \mathbf{M}_{n_A 1}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\ 
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix} & \cdots & \mathbf{M}_{n_A n_A}^{(A)} \begin{bmatrix} 
      \mathbf{M}_{11}^{(B)} & \cdots & \mathbf{M}_{1n_B}^{(B)} \\ 
      \vdots & & \vdots \\
      \mathbf{M}_{n_B 1}^{(B)} & \cdots & \mathbf{M}_{n_B n_B}^{(B)} 
    \end{bmatrix}
  \end{bmatrix}
$$

<MathBox title='' boxType='proposition'>
For vectors $\ket{\varphi_1},\ket{\varphi_2}\in\mathcal{H}_A$ and $\ket{\psi_1}, \ket{\psi_2}\in\mathcal{H}_B$ in Hilbert spaces $\mathcal{H}_A$ and $\mathcal{H}_B$, then

$$
  \ket{\varphi_1 \otimes \psi_1}\bra{\varphi_2 \otimes \psi_2} = \ket{\varphi_1}\bra{\varphi_2} \otimes \ket{\psi_1}\bra{\psi_2}
$$

That is, the projection onto a tensor product of vectors is equal to the tensor product of projections onto the factor vectors.

<details>
<summary>Proof</summary>

For any $\ket{\xi_1},\ket{\xi_2}\in\mathcal{H}_A$ and $\ket{\zeta_1},\ket{\zeta_2}\in\mathcal{H}_B$, we have

$$
\begin{align*}
  \Braket{\xi_1 \otimes \zeta_1 |(\ket{\varphi_1 \otimes \psi_1}\bra{\varphi_2 \otimes \psi_2})| \xi_2 \otimes \zeta_2} =& \ \braket{\xi_1 \otimes \zeta_1 | \varphi_1 \otimes \psi_1} \braket{\varphi_2 \otimes \psi_2 | \xi_2 \otimes \zeta_2} \\
  =& \braket{\xi_1|\varphi_1}\braket{\zeta_1|\psi_1}\braket{\varphi_2|\zeta_2}\braket{\psi_2|\zeta_2} \\
  =& \braket{\xi_1|\varphi_1}\braket{\varphi_2|\xi_2}\braket{\zeta_1|\psi_1}\braket{\psi_2|\zeta_2} \\
  =& \Braket{\xi_1 \otimes \zeta_1|(\ket{\varphi_1}\bra{\varphi_2} \otimes \ket{\psi_1}\bra{\psi_2})|\xi_2 \otimes \zeta_2}
\end{align*}
$$
</details>
</MathBox>

### Partial trace

<MathBox title='Partial trace' boxType='definition'>
Let $\mathcal{H}^A$ and $\mathcal{H}^B$ be two finite-dimensional Hilbert spaces. The *partial trace* $\operatorname{tr}_B$ over $\mathcal{H}_B$ is defined as the map

$$
\begin{align*}
  \operatorname{tr}_B : \mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B) \to& \mathcal{L}(\mathcal{H}_A) \\
  \hat{M} \mapsto& \operatorname{tr}_B (\hat{M})
\end{align*}
$$

where $\operatorname{tr}_B (\hat{M}) \in\mathcal{H}_A$ is the unique operator that satisfies

$$
\begin{equation*}
  \operatorname{tr}\left(\hat{M}_A \operatorname{tr}_B (\hat{M}) \right) = \operatorname{tr}\left((\hat{M}_A \otimes \hat{I}_B)\hat{M}\right),\; \forall
\tag{\label{equation-145}}
\end{equation*}
$$

Similarly, the partial trace $\operatorname{tr}_A$ over $\mathcal{H}_B$ is defined as

$$
\begin{align*}
  \operatorname{tr}_A : \mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B) \to& \mathcal{L}(\mathcal{H}_B) \\
  \hat{M} \mapsto& \operatorname{tr}_A (\hat{M}) 
\end{align*}
$$

where $\operatorname{tr}_A (\hat{M}) \in\mathcal{H}_B$ is the unique operator that satisfies

$$
\begin{equation*}
  \operatorname{tr}\left(\hat{M}_B \operatorname{tr}_A (\hat{M}) \right) = \operatorname{tr}\left((\hat{I}_A \otimes \hat{M}_B)\hat{M}\right),\; \forall \hat{M}_B \in\mathcal{L}(\hat{H}_B)
\tag{\label{equation-146}}
\end{equation*}
$$
</MathBox>

<MathBox title='' boxType='proposition'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces with respective orthonormal bases $\set{\ket{e_a}}\subset\mathcal{H}_A$ and $\set{\ket{f_b}}\subset\mathcal{H}_B$. Consider an operator $\hat{M}\in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$, whose matrix elements in the orthonormal basis $\set{\ket{e_a \otimes f_b}}$ of $\mathcal{H}_A \otimes \mathcal{H}_B$ are given by $\mathbf{M}_{a_1 b_1, a_2 b_2}$.

In the given bases, the partial traces $\operatorname{tr}_A (\hat{M}) \in\mathcal{L}(\mathcal{H}_A)$ and $\operatorname{tr}(\mathcal{H}_B)$ are defined as

$$
\begin{align*}
  \operatorname{tr}_B (\hat{M}) =& \sum_{a_1,a_2,b} \mathbf{M}_{a_1, b, a_2, b} \ket{e_{a_1}} \bra{e_{a_2}} \\
  \operatorname{tr}_A (\hat{M}) =& \sum_{b_1,b_2,a} \mathbf{M}_{ab_1, ab_2} \ket{f_{b_1}} \bra{f_{b_2}}
\end{align*}
$$

The partial traces $\operatorname{tr}_B (\hat{M})$ and $\operatorname{tr}_A (\hat{M})$ do not depend on the choice of the orthonormal bases $\set{\ket{e_a}}$ and $\set{\ket{f_b}}$ and are the unique operators satisfying

$$
\begin{equation*}
\begin{split}
  \operatorname{tr}\left(\hat{M}_A \operatorname{tr}_B (\hat{M})\right) =& \operatorname{tr}\left((\hat{M}_A \otimes \hat{I})\hat{M}\right),\; \forall \hat{M}_A \in\mathcal{L}(\mathcal{H}_A) \\
  \operatorname{tr}\left(\hat{M}_B \operatorname{tr}_A (\hat{M})\right) =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{M}_B)\hat{M}\right),\; \forall \hat{M}_B \in\mathcal{L}(\mathcal{H}_B)
\end{split}
\tag{\label{equation-112}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

We show that $\operatorname{tr}_B (\hat{M})$ satisfy the first equation in $\eqref{equation-112}$. Let $\set{\ket{e_a}}$ be an orthonormal basis in $\mathcal{H}_A$ and $\set{\ket{f_b}}$ an orthonormal basis in $\mathcal{H}_B$. Suppose $\hat{M}\in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$ is given by

$$
  \hat{M} = \sum_{a_1, a_2, b_1, b_2} \mathbf{M}_{a_1 b_1, a_2, b_2} \ket{e_{a_1} \otimes f_{b_1}} \bra{e_{a_2} \otimes f_{b_2}}
$$

Furthermore, let

$$
  \hat{M}_A = \sum_{a_1, a_2} \mathbf{M}_{a_1 a_2}^{(A)} \ket{e_{a_1}} \bra{e_{a_2}}
$$

be an arbitrary operator in $\mathcal{L}(\mathcal{H}_A)$. Then

$$
\begin{align*}
  & \operatorname{tr}[(\hat{M}_A \otimes \hat{I}_B)\hat{M}] \\
  =& \sum_{a_3, b_3} \bra{e_{a_3} \otimes f_{b_3}} (\hat{M}_A \otimes \hat{I}_B) \sum_{a_1, a_2, b_1, b_2} \ket{e_{a_1} \otimes f_{b_1}} \mathbf{M}_{a_1 b_1, a_2 b_2} \braket{e_{a_2} \otimes f_{b_2}|e_{a_3} \otimes f_{b_3}} \\
  =& \sum_{a_1, a_2, b_1, b_2} \braket{e_{a_2} \otimes f_{b_2}|(\hat{M}_A e_{a_1}) \otimes f_{b_1}} \mathbf{M}_{a_1 b_1, a_2, b_2} \\
  =& \sum_{a_1, a_2, b_1, b_2} \braket{e_{a_2}|\hat{M}_A|e_{a_1}} \underbrace{\braket{f_{b_2}|f_{b_1}}}_{=\delta_{b_1 b_2}} \mathbf{M}_{a_1 b_1, a_2 b_2} \\
  =& \sum_{a_1, a_2, b} \mathbf{M}_{a_2 a_1}^{(A)} \mathbf{M}_{a_1 b, a_2 b} \\
  =& \sum_{a_1, a_2} \mathbf{M}_{a_2 a_1}^{(A)} \operatorname{tr}_B (\mathbf{M})_{a_1 a_2} = \sum_{a_2} [\mathbf{M}^A \operatorname{tr}_B (\mathbf{M})]_{a_2 a_2} \\
  =& \operatorname{tr}[\hat{M}_A \operatorname{tr}_B (\hat{M})]
\end{align*}
$$

**Uniqueness**

Next, we show uniqueness. Suppose there exists another operator $\tilde{\operatorname{tr}}_B (\hat{M})$ on $\mathcal{H}_A$ that also satisfies the first equation in $\eqref{equation-112}$. Then, for any $\mathbf{M}_A \in\mathcal{L}(\mathcal{H}_A)$

$$
\begin{align*}
  \operatorname{tr}\left(\hat{M}_A (\tilde{\operatorname{tr}}_B (\hat{M}) - \operatorname{tr}_B (\hat{M})) \right) =& \operatorname{tr}\left(\hat{M}_A \tilde{\operatorname{tr}}_B (\hat{M}) \right) - \operatorname{tr}\left(\mathcal{M}_A \operatorname{tr}(\hat{M}) \right) \\
  =& \operatorname{tr}\left((\hat{M}_A \otimes\hat{I}_B)\hat{M} \right) - \operatorname{tr}\left((\hat{M}_A \otimes\hat{I}_B)\hat{M} \right) \\
  =& 0
\end{align*}
$$

Since this holds for all $\hat{M}_A$, it follows that $\tilde{\operatorname{tr}}_B (\hat{M}) = \operatorname{tr}_B (\hat{M})$.

**Basis independence**

To show that $\operatorname{tr}_B (\hat{M})$ is independent of the choice of basis, let $\set{\ket{\tilde{e}_a}}\subset\mathcal{H}_A$ and $\set{\ket{\tilde{f}_b}}\subset\mathcal{H}_B$ be another set of orthonormal bases, related by unitary transformations

$$
\begin{align*}
  \ket{\tilde{e}_a} =& \hat{U}_A \ket{e_a} = \sum_{a'} \mathbf{U}_{a' a}^{(A)} \ket{e_{a'}} \\
  \ket{\tilde{f}_b} =& \hat{U}_B \ket{f_b} = \sum_{b'} \mathbf{U}_{b' b}^{(B)} \ket{f_{b'}}
\end{align*}
$$

Let $\tilde{\mathbf{M}}_{a_1 b_1, a_2 b_2}$ be the matrix of $\hat{M}$ in the orthonormal basis $\set{\ket{\tilde{e}_a \otimes\tilde{f}_b}}$ such that

$$
\begin{align*}
  \tilde{\mathbf{M}}_{a_1 b_1, a_2 b_2} =& \braket{\tilde{e}_{a_1} \otimes \tilde{f}_{b_1}|\hat{M}|\tilde{e}_{a_2} \otimes \tilde{f}_{b_2}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} \Braket{\mathbf{U}_{a'_1 a_1}^{(A)}  \ket{e_{a'_1}} \otimes \mathbf{U}_{b'_1 b_1}^{(B)} \ket{f_{b'_1}} |\hat{M}|\mathbf{U}_{a'_2 a_2}^{(A)} \ket{e_{a'_2}} \otimes \mathbf{U}_{b'_2 b_2}^{(B)} \ket{f_{b'_2}}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} (\mathbf{U}_{a'_1 a_1}^{(A)})^* (\mathbf{U}_{b'_1 b_1}^{(B)})^* \mathbf{U}_{a'_2 b_2}^{(A)} \mathbf{U}_{b'_2 b_2}^{(B)} \braket{e_{a'_1} \otimes f_{b'_1}|\hat{M}| e_{a'_2} \otimes f_{b'_2}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} (\mathbf{U}_{a'_1 a_1}^{(A)})^* (\mathbf{U}_{b'_1 b_1}^{(B)})^* \mathbf{U}_{a'_2 b_2}^{(A)} \mathbf{U}_{b'_2 b_2}^{(B)} \mathbf{M}_{a'_1 b'_1, a'_2 b'_2}
\end{align*}
$$

Using the fact that $(\mathbf{U}_{a'_1 a_1}^{(A)})^* (\mathbf{U}_{b'_1 b_1}^{(B)})^* = (\mathbf{U}_{a'_1 a_1}^{(A)})^\dagger (\mathbf{U}_{b'_1 b_1}^{(B)})^\dagger$, we obtain

$$
\begin{align*}
  & \sum_{a_1 a_2 b} \tilde{\mathbf{M}}_{a_1 b, a_2 b} \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}} \\
  =& \sum_{a_1 a_2 b a'_1 b'_1 a'_2 b'_2} (\mathbf{U}_{a'_1 a_1}^{(A)})^\dagger (\mathbf{U}_{b'_1 b_1}^{(B)})^\dagger \mathbf{U}_{a'_2 a_2}^{(A)} \mathbf{U}_{b'_2 b}^{(B)} \mathbf{M}_{a'_1 b'_1, a'_2 b'_2} \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}} \\
  =& \sum_{a'_1 b'_1 a'_2 b'_2} \left(\sum_b \mathbf{U}_{b'_2 b}^{(B)} (\mathbf{U}_{b b'_1}^{(B)})^\dagger \right) \mathbf{M}_{a'_1 b'_1, a'_2 b'_2} \left(\sum_{a_1} (\mathbf{U}_{a'_1 a_1}^{(A)})^\dagger \ket{\tilde{e}_{a_1}} \right) \left(\sum_{a_2} (\mathbf{U}_A^\dagger)_{a'_2 a_2} \bra{\tilde{e}_{a_2}} \right)
\end{align*}
$$

By unitarity of $\hat{U}_A$ and $\hat{U}_B$, we have

$$
  \sum_b \mathbf{U}_{b'_2 b}^{(B)} (\mathbf{U}_{b b'_1}^{(B)})^\dagger = \delta_{b_2 b_1}
$$

and

$$
\begin{align*}
  \sum_{a_1} (\mathbf{U}_{a_1 a'_1}^{(A)})^\dagger \ket{\tilde{e}_{a_1}} =& \sum_{a_1 a'} (\mathbf{U}_{a_1 a'_1}^{(A)})^\dagger \mathbf{U}_{a' a_1}^{(A)} \ket{e_{a'}} \\
  =& \sum_{a'} \underbrace{\left(\sum_{a_1} \mathbf{U}_{a' a_1}^{(A)} (\mathbf{U}_{a_1 a'_1}^{(A)})^\dagger \right)}_{=\delta_{a' a'_1}} \ket{e_{a'}} \\
  =& \ket{e_{a'}}
\end{align*}
$$

Likewise,

$$
\begin{align*}
  \sum_{a_2} \mathbf{U}_{a'_2 a_2}^{(A)} \bra{\tilde{e}_{a_2}} =& \sum_{a_2 a'} \mathbf{U}_{a'_2 a_2}^{(A)} (\mathbf{U}_{a'_2 a'}^{(A)})^\dagger \bra{e_{a'}} \\
  =& \sum_{a'} \underbrace{\left( \sum_{a_2} (\mathbf{U}_{a' a_2}^{(A)})^\dagger \mathbf{U}_{a_2 a'_2}^{(A)} \right)}_{=\delta_{a' a'_2}} \bra{e_{a'}} \\
  =& \bra{e_{a'_2}}
\end{align*}
$$

Substituting back gives

$$
\begin{align*}
  \sum_{a_1 a_2 b} \tilde{M}_{a_1 b, a_2 b} \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}} =& \sum_{a'_1 b'_1 a'_2 b'_2} \mathbf{M}_{a'_1 b'_1 a'_2 b'_2} \delta_{b'_1 b'_2} \ket{e_{a'_1}} \bra{e_{a'_2}} \\
  =& \sum_{a_1 a_2} \mathbf{M}_{a_1 b, a_2 b} \ket{e_{a_1}} \bra{e_{a_2}}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Properties of partial trace' boxType='proposition'>
Let $\mathcal{H}_A$ and $\mathcal{H}_B$ be finite-dimensional Hilbert spaces. For any operator $\hat{M}\in\mathcal{L}(\hat{H}_A \otimes \mathcal{H}_B)$, the partial traces satisfy

1. $\operatorname{tr}\left(\operatorname{tr}_B (\hat{M})\right) = \operatorname{tr}(\hat{M}) = \operatorname{tr}\left(\operatorname{tr}_A (\hat{M})\right)$

For any operator $\hat{M}_A \otimes \hat{M}_B \in\mathcal{L}(\mathcal{H}_A \otimes \mathcal{H}_B)$, the partial traces satisfy

2. $\operatorname{tr}(\hat{M}^A \otimes \hat{M}^B) = \operatorname{tr}(\hat{M}_A) \operatorname{tr}(\hat{M}_B)$
3. $\operatorname{tr}_B (\hat{M}^A \otimes \hat{M}^B) = \operatorname{tr}(\hat{M}_B) \hat{M}_A$
4. $\operatorname{tr}_A (\hat{M}^A \otimes \hat{M}^B) = \operatorname{tr}(\hat{M}_A) \hat{M}_B$
 
<details>
<summary>Proof</summary>

**(1):** From $\eqref{equation-145}$, we have

$$
\begin{align*}
  \operatorname{tr}\left(\operatorname{tr}_B (\hat{M}) \right) =& \operatorname{tr}\left(\hat{I}_A \operatorname{tr}_B (\hat{M}) \right) \\
  =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{I}_B)\hat{M} \right) = \operatorname{tr}(\hat{M})
\end{align*}
$$

and similarly from $\eqref{equation-146}$, we obtain

$$
\begin{align*}
  \operatorname{tr}\left(\operatorname{tr}_A (\hat{M})\right) =& \operatorname{tr}\left(\operatorname{tr}_A (\hat{M}) \hat{I}_B \right) \\
  =& \operatorname{tr}\left((\hat{I}_A \otimes \hat{I}_B)\hat{M} \right) = \operatorname{tr}(\hat{M})
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \operatorname{tr}(\hat{M}_A \otimes \hat{M}_B) =& \sum_{a,b} (\mathbf{M}_A \otimes \mathbf{M}_B)_{ab, ab} \\
  =& \left(\sum_a \mathbf{M}_{aa}^{(A)} \right) \left(\sum_b \mathbf{M}_{bb}^{(B)} \right) \\
  =& \operatorname{tr}(\hat{M}_A) \operatorname{tr}(\hat{M}_B)
\end{align*}
$$

**(3):** Expanding in terms of an orthonormal basis $\set{\ket{e_a}}\subset\mathcal{M}_A$, we find

$$
  \operatorname{tr}_B (\hat{M}_A \otimes \hat{M}_B) = \sum_{a_1, a_2} \left(\operatorname{tr}_B (\hat{M}_A \otimes\hat{M}_B)\right)_{a_1 a_2} \ket{e_{a_1}} \bra{e_{a_2}}
$$

where

$$
\begin{align*}
  \left(\operatorname{tr}_B (\hat{M}_A \otimes\hat{M}_B)\right)_{a_1 a_2} =& \sum_b (\hat{M}_A \otimes \hat{M}_B)_{a_1 b, a_2 b} \\
  =& \mathbf{M}_{a_1 a_2}^{(A)} \sum_b \mathbf{M}_{bb}^{(B)} \\
  =& \mathbf{M}_{a_1 a_2}^{(A)} \operatorname{tr}(\hat{M}_B)
\end{align*}
$$

so that
$$
  \operatorname{tr}_B (\hat{M}_A \otimes \hat{M}_B) = \hat{M}_A \operatorname{tr}(\hat{M}_B)
$$
</details>
</MathBox>

# Quantum formalism

## Postulates

1. **Description of quantum states** The state space of a quantum system is described a complex separable Hilbert space $\mathcal{H}$. The possible states of the system can be categorized into *pure states* and *mixed states*:

    - A pure state is described by a ray $[\psi]_\sim \in\mathcal{PH}$ in the projective Hilbert space $\mathcal{PH} = \mathcal{H}/\sim$, where vectors differing only by a global phase are equivalent. Formally, a pure state is given by an equivalence classes of normalized vectors $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$:
    $$
      [\psi]_\sim = \set{e^{i\phi} \ket{\psi} : \ket{\psi}\in\mathcal{H}, \norm{\psi} = 1, \phi\in\R}
    $$
    For convenience, the equivalence class notation is often omitted, as the the global phase has no physical significance.

    - A mixed state is described by a *density operator* $\hat{\rho}$, which is a positive semidefinite operator on $\mathcal{H}$ with unit trace, i.e. $\operatorname{tr}(\hat{\rho}) = 1$. The operator $\hat{\rho}$ represents a statistical mixture of pure states and can be expressed as
    $$
      \hat{\rho} = \sum_i p_i \ket{\psi_i} \bra{\psi_i}
    $$
    where $\set{\ket{\psi_i}}$ are pure states, $p_i$ are probabilities satisfying $p_i \geq 0$ and $\sum_i p_i = 1$.

2. **Description of system observables:** Each physical observable $A$ of a quantum system is associated with a Hermitian operator $\hat{A}$ acting on $\mathcal{H}$. Since $\hat{A}$ is Hermitian, its eigenvalues are real, and its eigenstates form a complete, orthonormal set that spans $\mathcal{H}$, provided that $\hat{A}$ has a discrete spectrum. If $\hat{A}$ has a continuous spectrum, its eigenstates form a generalized orthonormal basis, expressed using distribution functions. 
3. **Measurement of physical observables:** The possible measurable values of an observable $A$ corresponds to the spectrum of its associated operator $\hat{A}$. The probability of measuring an eigenvalue $\lambda$ of $\hat{A}$ depends on whether the system is in a pure state or a mixed state.
    - If the quantum system is in a pure state $\ket{\psi}\in\mathcal{H}$, the probability $\Pr_\psi (\lambda)$ of measuring $A$ and obtaining $\lambda$ is given by
    $$
      \Pr_\psi (\lambda) = \norm{\hat{P}_\lambda \ket{\psi}}
    $$
    where $\hat{P}_\lambda$ is the projection onto the eigenspace $\operatorname{eig}(\hat{A}, \lambda)$. The expectation value of $A$ is given by $\langle A \rangle = \braket{\psi|\hat{A}|\psi}$.
    - If the system is in a mixed state $\hat{\rho}$, the probability $\Pr_{\hat{\rho}} (\lambda)$ that a measurement of $A$ yields the eigenvalue $\lambda$ is given by
    $$
      \Pr_{\hat{\rho}} (\lambda) = \operatorname{tr}(\hat{\rho}\hat{P}_\lambda)
    $$
    The expectation values is given by $\braket{A}_{\hat{\rho}} = \operatorname{tr}(\hat{\rho}\hat{A})$.

4. **Effect of measurement on the state:** A measurement of an observable $A$ modifies the quantum state depending on whether the quantum system was initially in a pure state or a mixed state.
    - If the system initially exists in a pure state $\ket{\psi}$, measuring $A$ and obtaining eigenvalue $\lambda$ transforms the state to
    $$
      \ket{\psi'} = \frac{\hat{P}_\lambda \ket{\psi}}{\sqrt{\braket{\psi|\hat{P}_\lambda|\psi}}}
    $$
    where $\hat{P}_\lambda$ is the projection onto the eigenspace $\operatorname{eig}(\hat{A}, \lambda)$.

    - If the system is initially described by a mixed state $\hat{\rho}$, a measurement of $A$ yielding $\lambda$, projects the state to
    $$
      \hat{\rho}' = \frac{\hat{P}_\lambda \hat{\rho} \hat{P}_\lambda}{\operatorname{tr}(\hat{\rho}\hat{P}_\lambda)}
    $$
5. **Time evolution of a system:** In the Schr√∂dinger picture, any time evolution of a pure state $\ket{\psi(t)}\in\mathcal{H}$ that is not caused by a measurement is governed by a unitary evolution operator $\hat{U}(t, t_0)$ satisfying
$$
  \ket{\psi(t)} = U(t,t_0)\ket{\psi (t_0)}
$$
which is equivalent to the Schr√∂dinger equation
$$
  i\hbar\frac{\d}{\d t}\ket{\psi(t)} = \hat{H}\ket{\psi(t)}
$$
where $\hat{H}$ is the Hamiltonian of the quantum system.
    - For a mixed state $\hat{\rho}$, the time evolution is given by
    $$
      \hat{\rho}(t) = \hat{U}(t, t_0) \hat{\rho}(t_0) \hat{U}^\dagger(t, t_0)
    $$

6. **Description of composite systems:** The Hilbert space of a composite system that consists of the subsystems $\mathcal{H}_A$ and $\mathcal{H}_B$ is the tensor product $\mathcal{H}_A \otimes \mathcal{H}_B$.

### Time evolution pictures

| Evolution of | Schr√∂dinger $(S)$ | Heisenberg $(H)$ | Interaction $(I)$ |
| --- | --- | --- | --- |
| State vector | $\ket{\psi_s (t)} = e^{-i\hat{H}_S t/\hbar} \ket{\psi_S (0)}$ | constant | $\ket{\psi_I (t)} = e^{i\hat{H}_{0;S} t/\hbar} \ket{\psi_S (t)}$ |
| Observable | constant | $\hat{O}_H = e^{i\hat{H}_S t/\hbar} \hat{O}_S e^{-i\hat{H}_S t/\hbar}$ | $\hat{O}_I = e^{i\hat{H}_{0;S} t/\hbar} \hat{O}_S e^{-i\hat{H}_{0;S} t/\hbar}$ |
| Density matrix | $\rho_S (t) = e^{i\hat{H}_S t/\hbar} \rho_S (0) e^{-i\hat{H}_S t/\hbar}$ | constant | $\rho_I (t) = e^{i\hat{H}_{0;S} t/\hbar} \rho_S (t) e^{-i\hat{H}_{0;S} t/\hbar}$ |

## Quantum states and observables

The pure state of a quantum system is represented by a ray $[\ket{\psi}]_\sim \in \mathcal{PH}$, where $\mathcal{PH} = \mathcal{H}/\sim$ is the projective Hilbert space of a complex separable Hilbert space $\mathcal{H}$, and $\sim$ is an equivalence relation on $\mathcal{H}$. For $\ket{\psi},\ket{\varphi}\in\mathcal{H}$, this relation is defined as

$$
  \ket{\psi}\sim\ket{\varphi} \iff \ket{\varphi} = e^{i\alpha} \ket{\psi}, \alpha\in\R
$$

Each ray $S_\psi$ associated with a normalized vector $\ket{\psi}\in\mathcal{H}$, i.e. $\norm{\psi} = 1$, is the equivalence class

$$
  S_\psi = [\ket{\psi}]_\sim := \set{e^{i\alpha} \ket{\psi} | \alpha\in\R}
$$

representing a pure state of the quantum system. All vectors in $S_\psi$ differ only by a global phase factor and correspond to the same physical state.

For convenience, the global phase factor $e^{i\alpha}$ is typically ignored when dealing with pure states. In practice, we often identify a pure state with a normalized vector $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$, rather than considering the entire equivalence class of vectors that differ only by a global phase. This is because the global phase does not affect physical observables or measure quantities, which are invariant under such transformations. Thus, we can simplify the description of pure states by associating them directly with normalized vectors in $\mathcal{H}$, leaving the equivalence class formalism implicit.

The dimensionality of $\mathcal{H}$ is determined by the degrees of freedom of the system. Systems with continuous degrees of freedom (like position and momentum) have infinite-dimensional Hilbert spaces, while systems of discrete degrees of freedom have finite-dimensional Hilbert spaces. For instance, the Hilbert space for the position and momentum of a particle in $n$ dimensions is the space of square-integrable complex-valued function function $\mathcal{L}^2 (\R^n, \mathbb{C})$, while for a spin-$s$ particle it is the finite-dimensional complex vector space $\mathbb{C}^{2s + 1}$.

An observable refers to a physcial quantity that can be measured in a quantum system. All quantum observables are represented by Hermitian operators on $\mathcal{H}$. The possible values of an observable are given by the spectrum of the operator, which can be discrete (finite or infinite-dimensional), continuous or a combination of both. In general, systems with bound states (e.g., a particle confined in a potential well) have discrete spectra, corresponding to quantized energy levels. In contrast, for scattering states (e.g., a free particle or a particle with energy above a potential barrier), the spectrum is continuous, corresponding to a range of energies.

<details>
<summary>Details</summary>

For infinite-dimensional Hilbert spaces, we also require that a Hermitian operator $\hat{Q}$ is bounded. In this case, there exists a constant $c$ such that, for any non-zero vector $\ket{\psi}\in\mathcal{H}$, we have

$$
  \frac{\braket{\psi|\hat{Q}^\dagger \hat{Q}|\psi}}{\braket{\psi|\psi}} \leq c^2
$$

The operator norm of $\hat{Q}$ is defined as the lower bound of $c$.
</details>

The Hermiticity of a quantum operator ensures that its spectrum is real. Furthermore, the eigenvectors corresponding to distinct eigenvalues are orthogonal and can be normalized to form an orthonormal basis. In the case of degenerate eigenvalues, the corresponding eigenspace can be spanned by orthonormal eigenvectors. For continuous spectra, generalized eigenstates may be used.

### Discrete observables

A discrete quantum observable is represented by a Hermitian operator $\hat{Q}$ on a Hilbert space $\mathcal{H}$ with a discrete spectrum $\set{q_j}_j$. If $\hat{Q}$ has eigenbasis $\set{\ket{q_{j,\alpha}}}$, where $\alpha \in\set{1,\dots,d_j}$ denotes the degeneracy of $q_j$, i.e. $d_j = \dim[\operatorname{eig}(\hat{Q}, q_j)]$, the spectral representation of $\hat{Q}$ is

$$
  \hat{Q} = \sum_j q_j \hat{P}_j = \sum_j q_j \sum_{\alpha=1}^{d_j} \ket{q_{j,\alpha}} \bra{q_{j,\alpha}}
$$

where $\hat{P}_j$ is the projector onto the eigenspace $\operatorname{eig}(\hat{Q}, q_j)$. Since $\hat{Q}$ is Hermitian, the eigenbasis $\set{\ket{q_{j,\alpha}}}$ is orthonormal, i.e.

$$
  \braket{q_{j,\alpha}|a_{k,\beta}} = \delta_{jk} \delta_{\alpha\beta}
$$

From the spectral representation, we can derive the action of $\hat{Q}$ on the eigenvectors $\ket{q_{k,\beta}}$

$$
\begin{align*}
  \hat{Q}\ket{q_{k,\beta}} =& \sum_j q_{j,\alpha} \hat{P}_j \ket{q_{k\beta}} \\
  =& \sum_j q_j \sum_{\alpha=1}^{d_j} \ket{q_{j,\alpha}} \underbrace{\braket{q_{j,\alpha}|q_{k,\beta}}}_{\delta_{jk} \delta_{\alpha\beta}} \\
  =& q_k \ket{q_{k,\beta}}
\end{align*}
$$

The relation $\hat{Q}\ket{q_{k,\beta}} = q_k \ket{q_{k,\beta}}$ is the eigenvalue equation of $\hat{Q}$. 

If the spectrum of $\hat{Q}$ is finite-dimensional, the set of eigenvectors forms a complete orthonormal basis for $\mathcal{H}$, meaning that: 

$$
  \operatorname{span}(\set{\ket{q_{j,\alpha}}}_j) = \mathcal{H}
$$

Thus, the Hilbert space $\mathcal{H}$ is spanned by the eigenstates of $\hat{Q}$, and any state $\ket{\psi}\in\mathcal{H}$ can be expressed as a linear combination (or superposition):

$$
  \ket{\psi} = \sum_{j,\alpha} c_{j,\alpha} \ket{q_{j,\alpha}}
$$

where $c_{j,\alpha}$ are complex coefficients representing probability amplitudes. Applying $\bra{q_{k,\beta}}$ to $\ket{\psi}$ yields

$$
  \braket{q_{k,\beta} | \psi} = \sum_{j,\alpha} c_{j,\alpha} \underbrace{\braket{q_{k,\beta}|q_{j,\alpha}}}_{\delta_{kj}\delta_{\beta\alpha}} = c_{k,\beta}
$$

showing that $c_{k,\beta}$ is the projection of $\ket{\psi}$ onto $\ket{q_{k,\beta}}$.

#### Matrix representation of observables

The matrix representation of an observable $\hat{Q}$ with finite-dimensional discrete spectrum can be obtained by expanding $\mathbf{Q}$ in terms of an orthonormal basis $\set{\ket{b_j}}_j$. Using the completeness relation $\sum_j \ket{b_j}\bra{b_j} = \hat{I}$, we write

$$
  \hat{Q} = \sum_j \ket{b_j} \bra{b_j} \hat{Q} = \sum_{j,k} \ket{b_j} \braket{b_j|\hat{Q}|b_k} \bra{b_k}
$$

The matrix elements of $\hat{Q}$ in this basis are given by

$$
  \mathbf{Q}_{jk} = \braket{b_j|\hat{Q}|b_k}
$$

An observable $\hat{Q}$ with a non-degenerate spectrum $\set{q_j}_{j=1}^n$ can be diagonalized. The resulting matrix representation has diagonal elements corresponding to the eigenvalues of $\hat{Q}$:

$$
  \mathbf{Q}_{jk} = q_j \delta_{jk} 
$$

The $n\times n$ matrix $\mathbf{U}$ that diagonalizes $\hat{Q}$ is formed by using the eigenvectors $\ket{q_j}$ as its columns. In a basis $\set{\ket{b_k}}_k$, the eigenvector $\ket{q_j}$ can be expanded as

$$
  \ket{q_j} = \sum_k q_{jk} \ket{b_k}, \; q_{jk} = \braket{b_k | q_j}
$$

showing that $\mathbf{U}$ has matrix elements $\mathbf{U}_{jk} = q_{jk}$. Since the eigenbasis $\set{\ket{q_j}}_j$ is orthonormal, we have

$$
  \sum_\ell (q_{k\ell})^* q_{j\ell} = \braket{q_k | q_j} = \delta_{kj}
$$

This can be used to verify that $\mathbf{U}$ is unitary:

$$
\begin{align*}
  (\mathbf{U}^\dagger \mathbf{U})_{kj} =& \sum_\ell \mathbf{U}_{k\ell}^\dagger \mathbf{U}_{\ell j} = \sum_\ell \mathbf{U}_{\ell k}^* \mathbf{U}_{\ell j} \\
  =& \sum_\ell (q_{k\ell})^* q_{j\ell} = \braket{q_k | q_j} = \delta_{kj}
\end{align*}
$$

### Continuous observables and wavefunctions

A quantum observable $\hat{Q}$ with a continuous spectrum has spectral representation

$$
  \hat{Q} = \int q \hat{P}(q) \;\d q = \int q \ket{q}\bra{q} \;\d q
$$

where $q$ is a continuous eigenvalue, and $\ket{q}$ is the corresponding eigenfunction. These eigenvectors are not normalizable in the usual sense, but satisfy the orthogonality condition

$$
  \braket{q' | q} = \delta(q - q')
$$

where $\delta$ is the Dirac delta function. In this representation, any state vector $\ket{\psi}$ can be expanded as

$$
  \ket{\psi} = \int \psi(q) \ket{q} \; \d q
$$

where $\psi(q) = \braket{q|\psi}$ is called the wavefunction. The wavefunction $\psi(q)$ is the projection of $\ket{\psi}$ onto $\ket{q}$. It is describes how $\ket{\psi}$ is distributed over the eigenstates of $\hat{Q}$.

### Change of basis

If $\mathcal{H}$ is a finite-dimensional Hilbert space with orthonormal basis $\set{\ket{b_n}}_n$, a state vector $\ket{\psi}\in\mathcal{H}$ can be expanded as

$$
\begin{equation*}
  \ket{\psi} = \sum_k c_{b_k} \ket{b_k}, \; c_{b_k} = \braket{b_k | \psi} \in\mathbb{C} 
\tag{\label{equation-76}}
\end{equation*}
$$

We can expand $\ket{\psi}$ in terms of another orthonormal basis $\set{\ket{a_k}}_k$:

$$
\begin{equation*}
  \ket{\psi} = \sum_k c_{a_k} \ket{a_k}, \; c_{a_k} = \braket{a_k | \psi} 
\tag{\label{equation-77}}
\end{equation*}
$$

To find a relationship between the coefficients $\set{c_{b_k}}_k$ and $\set{c_{a_k}}_k$, we insert $\sum_j \ket{a_j} \bra{a_j} = 1$ into $\eqref{equation-76}$ to get

$$
\begin{align*}
  \ket{\psi} =& \sum_{j,k} c_{b_k} \ket{a_j} \braket{a_j | b_k} \\
  =& \sum_{j,k} \mathbf{U}_{j,k} c_{b_j} \ket{a_k}
\end{align*}
$$

with the matrix elements $\mathbf{U}_{j,k} = \braket{a_k | b_j}$. Equating this with $\eqref{equation-77}$, we find

$$
  c_{a_j} = \sum_{k} \mathbf{U}_{j, k} c_{b_k}
$$

or in matrix form

$$
  \mathbf{c}_a = \mathbf{Uc}_b
$$

A change of basis has the following properties:
1. The matrix $\mathbf{U}$ is unitary.
2. The inner product of $\mathcal{H}$ is preserved
3. The trace of an operator is preserved

<details>
<summary>Proof</summary>

**(1):** If $\mathbf{U}_{j,k} = \braket{a_j | b_k}$, then

$$
\begin{align*}
  (\mathbf{U}_{j,k})^* =& \braket{b_k | a_j} \\
  \mathbf{U}_{j,k}^\dagger =& \braket{b_j | a_k}
\end{align*}
$$

Consequently, we have

$$
\begin{align*}
  (\mathbf{UU}^\dagger)_{j,k} =& \sum_\ell \mathbf{U}_{j,\ell} U_{\ell, k} = \sum_\ell \braket{a_j | b_\ell} \braket{b_\ell | a_k} \\
  =& \braket{a_j | a_k} = \delta_{jk}
\end{align*}
$$

Similarly, we have

$$
\begin{align*}
  (\mathbf{U}^\dagger \mathbf{U})_{j,k} =& \sum_\ell \mathbf{U}_{j,\ell}^\dagger \mathbf{U}_{\ell,k} = \sum_\ell \braket{b_j | a_\ell}\braket{a_\ell | b_k} \\
  =& \delta_{jk}
\end{align*}
$$

Hence, it follows that $\mathbf{UU}^\dagger = \mathbf{U}^\dagger U = \mathbf{I}$.

**(2):** If $\set{\ket{b_j}}$ and $\set{\ket{a_j}}$ are two orthonormal bases on $\mathcal{H}$, then the two state vectors $\ket{\psi}, \ket{\phi}\in\mathcal{H}$ can be expanded as

$$
\begin{align*}
  \psi =& \sum_j c_{b_j} \ket{b_j} = \sum_j c_{a_j} \ket{a_j}
  \phi =& \sum_j d_{b_j} \ket{b_j} = \sum_j d_{a_j} \ket{a_j}
\end{align*}
$$

The inner product $\braket{\psi|\phi}$ in the basis $\set{\ket{b_j}}$ is

$$
  \braket{\phi|\psi} = \sum_{j,k} d_{b_j}^* c_{b_k} \underbrace{\braket{b_j | b_k}}_{\delta_{jk}} = \sum_j d_{b_j} c_{b_j}
$$

The inner product $\braket{\psi|\phi}$ in the basis $\set{\ket{a_j}}$ is

$$
\begin{equation*}
  \braket{\phi|\psi} = \sum_{j,k} d_{a_j}^* c_{a_k} \underbrace{\braket{a_j | a_k}}_{\delta_{jk}} = \sum_j d_{a_j} c_{a_j} 
\tag{\label{equation-78}}
\end{equation*}
$$

Substituting

$$
  c_{a_j} = \sum_k \mathbf{U}_{j,k} c_{b_j}
$$

and

$$
  d_{a_j}^* = \sum_k \mathbf{U}_{j,k}^* d_{b_k}^* = \sum_k d_{b_k}^* \mathbf{U}_{k,j}^\dagger
$$

into $\eqref{equation-78}$, we get

$$
\begin{align*}
  \braket{\phi|\psi} =& \sum_{j,k} d_{b_k}^* \mathbf{U}_{k,j}^\dagger \sum_\ell \mathbf{U}_{j,\ell} c_{b_\ell} \\
  =& \sum_{k,\ell} d_{b_k}^* \underbrace{\left(\sum_j \mathbf{U}_{k,j}^\dagger \mathbf{U}_{j, \ell} \right)}_{(\mathbf{U}^\dagger \mathbf{U})_{k,\ell} = \delta_{k,\ell}} c_{b_\ell} \\
  =& \sum_\ell d_{b_\ell}^* c_{b_\ell}
\end{align*}
$$

**(3):** Let $\hat{Q}$ be a linear operator on $\mathcal{H}$. The trace of $\hat{O}$ in the orthonormal basis $\set{\ket{a_j}}$ is given by

$$
  \operatorname{tr}(\hat{Q}) = \sum_j \braket{a_j |\hat{Q}| a_j}
$$

The trace of $\hat{Q}$ in the orthonormal basis $\set{\ket{b_j}}$ can be written

$$
\begin{align*}
  \operatorname{tr}(\hat{Q}) =& \sum_j \braket{b_j |\hat{Q}|b_j} \\
  =& \sum_{j,k,\ell} \braket{b_j | a_k} \braket{a_k | \hat{Q} | a_\ell} \braket{a_\ell | b_j} \\
  =& \sum_{j,k,\ell} \braket{a_\ell | b_j} \braket{b_j | a_k} \braket{a_k | \hat{Q} | a_\ell} \\
  =& \sum_{k, \ell} \braket{a_\ell | a_k} \braket{a_k |\hat{Q}| a_k} \\
  =& \sum_\ell \braket{a_\ell | \hat{Q} | a_\ell}
\end{align*}
$$
</details>

#### Infinite-dimensional case

If $\mathcal{H}$ is an infinite-dimensional Hilbert space with basis $\set{\ket{\xi}}$, then any state vector $\ket{\psi}\in\mathcal{H}$ can be expanded as

$$
  \ket{\psi} = \int \psi_\xi (\xi) \ket{\xi} \;\d \xi, \; \psi_\xi (\xi) = \braket{\xi|\psi}
$$

We can expand $\ket{\psi}$ in terms of another orthonormal basis $\set{\ket{\eta}}$ as

$$
  \ket{\psi} = \int \psi_\eta (\eta) \ket{\eta}, \; \psi_\eta (\eta) = \braket{\eta|\psi}
$$

Using the completeness relation of $\ket{\eta}$, we can express $\psi_\xi$ as

$$
\begin{align*}
  \psi_\xi (\xi) =& \braket{\xi|\psi} = \int \overbrace{\braket{\xi|\eta}}^{\phi_\eta (\xi)} \overbrace{\braket{\eta|\psi}}^{\psi_\eta (\eta)} \;\d\eta \\
  =& \int \phi_\eta (\xi) \psi_\eta (\eta) = \hat{U}(\eta,\xi) \psi(\eta)
\end{align*}
$$

In the following we show that the transformation

$$
  \hat{U}(\eta,\xi) = \int \phi_\eta (\xi) \;\d\eta
$$

is unitary. The scalar product of two wavefunctions $\psi_\eta$ and $\psi'_\eta$ in the $\eta$-representation is given by

$$
  \braket{\psi_\eta, \psi_\eta'} = \int \psi_\eta^* (\eta) \psi'_\eta (\eta) \;\d\eta
$$

Applying $\hat{U}$ to $\psi_eta$ and $\psi'_\eta$ and taking the scalar product yields

$$
\begin{align*}
  \braket{\hat{U}\psi_\eta, \hat{U} \psi'_\eta} =& \int \d\xi \left(\int \phi_\eta^* (\xi) \psi_\eta^* (\eta) \;\d\eta \right) \left(\int \phi_{\eta'} (\xi) \psi'_\eta (\eta') \;\d\eta' \right) \\
  =& \int \eta' \psi_\eta^* (\eta) \psi'_\eta (\eta') \;\d \int \phi_\eta^* (\eta) \phi_{\eta'} (\eta) \;\d\xi \tag{\label{equation-94}}
\end{align*}
$$

Since $\phi_\eta (\xi) = \braket{\xi|\eta'}$ and $\phi_\eta (\xi) = \braket{\xi|\eta}$, we obtain

$$
\begin{align*}
  \int \phi_\eta^* (\xi) \phi_{\eta'} (\xi) =& \int \braket{\eta|\xi}\braket{\xi|\eta'} \\
  =& \braket{\eta|\eta'} = \delta(\eta - \eta')
\end{align*}
$$

Substituting this into $\eqref{equation-94}$, we get

$$
\begin{align*}
  \braket{\hat{U}\psi, \hat{U}\psi'} =& \int \eta' \psi_\eta^* (\eta) \psi'_\eta (\eta') \delta(\eta - \eta') \\
  =& \int \psi_\eta^* (\eta) \psi_\eta (\eta) \;\d\eta = \braket{\psi,\psi'}
\end{align*}
$$

showing that $\hat{U}$ preserves the inner product. Hence, it follows that $\hat{U}$ is unitary.

## Measurements

Let $\hat{Q}$ be a Hermitian operator on $\mathcal{H}$ with a discrete spectrum $\set{q_j}_j$, and an orthonormal eigenbasis $\set{\ket{q_{j,\alpha}}}$, where $\alpha\in\set{1,\dots,d_j}$ denotes the degeneracy $q_j$, i.e. $d_j = \dim[\operatorname{eig}(\hat{Q}, q_j)]$. If $Q$ is the corresponding observable on a quantum system in state 

$$
  \ket{\psi} = \sum_{j,\alpha} c_{j,\alpha} \ket{q_{j,\alpha}}, \; c_{j,\alpha} = \braket{q_{j,\alpha} | \psi}
$$

then the probability of measuring the eigenvalue $q_j$ is given by

$$
  \Pr_\psi (q_j) = \norm{\hat{P}_j \ket{\psi}}^2 = \Norm{\sum_{\alpha=1}^{d_j} \ket{q_{j,\alpha}}\braket{q_{j,\alpha}|\psi}} = \sum_{\alpha=1}^{d_j} |\braket{q_{j,\alpha}|\psi}|^2 = \sum_{\alpha=1}^{d_j} |c_{j,\alpha}|^2
$$

This statistical interpretation of quantum observables is known as *Born's rule*, which states that the probability of obtaining an eigenvalue $q_j$ in a measurement of $Q$ is given by the square modulus of the projection of $\ket{\psi}$ onto the corresponding eigenspace.

To see that the map $\Pr_psi : \sigma(\hat{Q}) \to [0,1]$ defines a probability measure on $\sigma(\hat{Q})$, we note that $\Pr_\psi (q_j) \geq 0$ because square moduli are non-negative. Furthermore, since $\set{\ket{q_{j,\alpha}}}$ forms an orthonormal basis for $\mathcal{H}$ and $\ket{\psi}$ is normalized, it follows that

$$
  \sum_j \Pr_\psi (q_j) = \sum_j \norm{\hat{P}_{q_j} \ket{\psi}}^2 = \sum_j \sum_{\alpha=1}^{d_j} |\braket{q_{j,\alpha}|\psi}|^2 = \norm{\psi} = 1
$$

Thus, the normalization condition of quantum states ensures that the total probability sums to $1$, validating that $\Pr_\psi$ is a probability measure over the spectrum $\sigma(\hat{Q})$.

If a quantum system has been prepared in the state $\ket{\psi}\in\mathcal{H}$, the probability to observe it in the state $\ket{\varphi}\in\mathcal{H}$ is given by $\Pr(\varphi|\psi) = |\braket{\varphi|\psi}|^2$, assuming both states are normalized, i.e. $\norm{\psi}^2 = 1 = \norm{\varphi}$. To see this, note that the measurement corresponds to the observable given by the orthogonal projection $\hat{P}_\varphi = \ket{\varphi}\bra{\varphi}$ onto $\ket{\varphi}$. This operator has the eigenvalues $0$ and $1$. The eigenvalue $\lambda = 1$ is non-degenerate and its eigenspace is spanned by $\ket{\varphi}$. Hence, the projection onto the eigenspace for eigenvalue $\lambda = 1$ is given by

$$
\begin{align*}
  \Pr_\psi (\lambda = 1) =& \norm{\hat{P}_\varphi \ket{\psi}}^2 = \norm{\ket{\varphi}\braket{\varphi|\psi}}^2 \\
  =& |\braket{\varphi|\psi}|^2 \underbrace{\norm{\varphi}^2}_{=1} = |\braket{\varphi|\psi}|^2
\end{align*}
$$

### Expectation value

The expectation value of an observable $Q$ in the normalized state $\ket{\psi}\in\mathcal{H}$ is defined as

$$
  \braket{Q}_\psi := \frac{\braket{\psi|\hat{Q}|\psi}}{\braket{\psi|\psi}} = \braket{\psi|\hat{Q}|\psi}
$$

If $\hat{Q}$ has spectral decomposition

$$
  \hat{Q} = \sum_{j,\alpha} q_j \ket{q_{j,\alpha}}\bra{q_{j,\alpha}}
$$

the expectation value is given by

$$
\begin{align*}
  \braket{Q}_\psi =& \braket{\psi|\hat{Q}|\psi} = \Braket{\psi|\sum_{j,\alpha} q_j \ket{q_{j,\alpha}}\braket{q_{j,\alpha}|\psi}} \\
  =& \sum_{j,\alpha} q_j \braket{\psi|q_{j,\alpha}}\braket{q_{j,\alpha}|\psi} \\
  =& \sum_{j,\alpha} q_j |\braket{\psi|q_{j,\alpha}}|^2 = \sum_{j,\alpha} q_j |c_{j,\alpha}|^2
\end{align*}
$$

Properties of expectation values
1. $\braket{Q}_\psi \in\R$ is real since $\hat{Q}$ is Hermitian
2. **Invariance unde global phase:** For any global phase factor $e^{i\phi}$, where $\phi\in\R$, we have $\braket{Q}_{e^{i\phi} \psi} = \braket{Q}_\psi$
3. **Equality of observables:** Two observables $\hat{Q}$ and $\hat{Q}'$ are equal if and only if $\braket{\psi|\hat{Q}|\psi} = \braket{\psi|\hat{Q}'|\psi}$ for all $\ket{\psi}\in\mathcal{H}$

<details>
<summary>Proof</summary>

**(1):** Taking the complex conjugate of $\braket{Q}_\psi$, we find

$$
\begin{align*}
  \braket{Q}_\psi^* =& \braket{\psi|\hat{Q}|\psi}^* = \braket{\psi|\hat{Q}^\dagger|\psi} \\
  =& \braket{\psi|\hat{Q}|\psi} = \braket{Q}_\psi
\end{align*}
$$

Since $\braket{Q}_\psi^* = \braket{Q}_\psi$, it follows that $\braket{Q}_\psi \in\R$ is real.

**(2):** Calculating $\braket{Q}_{e^{i\phi}\psi}$, we find 

$$
\begin{align*}
  \braket{Q}_{e^{i\phi} \psi} =& \braket{e^{i\phi}\psi |\hat{Q}|e^{i\phi} \psi} = e^{-i\phi} e^{i\phi} \braket{\psi|\hat{Q}|\psi} \\
  =& \braket{\psi|\hat{Q}|\psi} = \braket{Q}_\psi
\end{align*}
$$
</details>

The expectation value of any observable $Q$ in the state $\ket{\psi}\in\mathcal{H}$ is unaffected under a global phase transformation $e^{i\phi} \ket{\psi}$. In an orthonormal basis $\set{\ket{q_j}}$, we have

$$
  |\braket{e^{i\phi}\psi|q_j}|^2 = |e^{-i\phi}|^2 \cdot |\braket{\psi|q_j}|^2 = |\braket{\psi|q_j}|
$$

showing that the measurement probabilities remain the same. This means that the states $e^{i\phi}\ket{\psi}$ and $\ket{\psi}$ are physically indistinguishable.

While global phase is physically irrelevant, relative phases between components in a quantum superposition can have physical consequences. Specifically, consider two orthonormal states $\ket{\eta},\ket{\psi}\in\mathcal{H}$ satisfying $\braket{\eta|\psi} = 0$. Then 

$$
\begin{align*}
  \ket{a} =& 2^{-1/2} (\ket{\eta} + \ket{\psi}) \\ 
  \ket{b} =& 2^{-1/2} (\ket{\eta} + e^{i\phi} \psi)
\end{align*}
$$

are normalized state vectors. However, while $\ket{\psi}$ and $e^{i\phi} \ket{\psi}$ represents the same state, the states $\ket{a}$ and $\ket{b}$ are physically distinct because they lead to different measurement outcomes. The expectation value of an observable $A$ in state $\ket{a}$ is

$$
\begin{align*}
  \braket{A}_{\ket{\eta} + \ket{\psi}/\sqrt{2}} =& \frac{1}{2} (\braket{\eta + \psi|\hat{A}|\varphi + \psi}) \\
  =& \frac{1}{2}(\braket{\eta|\hat{A}|\eta} + \braket{\psi|\hat{A}|\psi} + \braket{\eta|\hat{A}|\psi} + \underbrace{\braket{\psi|\hat{A}|\eta}}_{\braket{\hat{A}\psi|\eta}}) \\
  =& \frac{1}{2}(\braket{A}_\eta + \braket{A}_\psi) + \Re(\braket{\eta|\hat{A}|\psi})
\end{align*}
$$

where $\Re(\braket{\eta|\hat{A}|\psi})$ is called the interference terms, which arises du to quantum superposition. Similarly, for $\ket{b}$, we find

$$
\begin{align*}
  \braket{A}_{\ket{\eta} + e^{i\phi}\ket{\psi}/\sqrt{2}} =& \frac{1}{2} (\braket{\eta + e^{i\phi} \psi|\hat{A}|\varphi + e^{i\phi} \psi}) \\
  =& \frac{1}{2}(\braket{\eta|\hat{A}|\eta} + \braket{e^{i\phi} \psi|\hat{A}|e^{i\phi} \psi} + e^{i\phi} \braket{\eta|\hat{A}|\psi} + e^{-i\phi} \underbrace{\braket{\psi|\hat{A}|\eta}}_{\braket{\hat{A}\psi|\eta}}) \\
  =& \frac{1}{2}(\braket{A}_\eta + \braket{A}_\psi) + \Re(e^{i\phi} \braket{\eta|\hat{A}|\psi})
\end{align*}
$$

Thus, whenever $\braket{\eta|\hat{A}|\psi} \neq 0$ the real part of $\braket{\eta|\hat{A}|\psi}$ and of $e^{i\phi}\braket{\eta|\hat{A}|\psi}$ differ.

### Determinate states

The uncertainty of an observable $Q$ is state $\ket{\psi}\in\mathcal{H}$ is defined as

$$
  \Delta_\psi (Q) := \sqrt{\braket{\psi|(\hat{Q} - \braket{Q}_\psi \hat{I})^2|\psi}} = \sqrt{\braket{(\hat{Q} - \braket{Q}\hat{I})^2}}
$$

where $\hat{I}$ is the identity operator. If the uncertainty vanishes, i.e. $\Delta_\psi (Q) = 0$, the observable $Q$ in the state $\ket{\psi}$ is said to have a *sharp* value. This is the case if and only if $\ket{\psi}$ is an eigenvector of $\hat{Q}$, i.e.

$$
  \Delta_\psi (Q) = 0 \iff \hat{Q}\ket{\psi} = \braket{Q}_\psi \ket{\psi}
$$

Since $\hat{Q}$ is Hermitian, its expectation value $\braket{Q}_\psi \in\R$ is real, i.e. $\braket{Q}_\psi = \braket{Q}_\psi^*$. Consequently,

$$
  (\hat{Q} - \braket{Q}_\psi \hat{I})^\dagger = \hat{Q} - \braket{Q}_\psi \hat{I} 
$$

and thus

$$
\begin{align*}
  (\Delta_\psi (Q))^2 =& \braket{\psi|(\hat{Q} - \braket{Q}_\psi \hat{I})^2|\psi} \\
  =& \braket{(\hat{Q} - \braket{Q}_\psi \hat{I})\psi | (\hat{Q} - \braket{Q}_\psi \hat{I})\psi} \\
  =& \Norm{(\hat{Q} - \braket{Q}_\psi \hat{I})\psi}^2
\end{align*}
$$

This shows that

$$
  \Delta_\psi (Q) = 0 \iff \hat{Q}\ket{\psi} = \braket{Q}_\psi \ket{\psi}
$$

A state $\ket{\psi}$ that is an eigenvector of an operator associated with an observable is called an *eigenstate* of that operator.

### Continuous spectrum

Let $\hat{Q}$ be a Hermitian operator on the Hilbert space $\mathcal{H}$ with a continuous spectrum, and let $\ket{q}$ denote its eigenstates. The correspodning observable $Q$ in a quantum system described by the state vector $\ket{\psi}$ can be expanded as 

$$
  \ket{\psi} = \int \psi(q) \ket{q} \;\d q, \; \psi(q) = \braket{q|\psi}
$$

where $\psi(q) = \braket{q|\psi}$ is the wavefunction in the eigenbasis $\set{\ket{q}}$. By Born's rule, the probability of measuring $Q$ and finding the eigenvalue in the interval $(q, q + \d q)$ is given by the square modulus of the wavefunction, i.e. $|\psi(q)|^2 \d q$. Expanding the normalization condition on $\ket{\psi}$, we find

$$
\begin{align*}
  \braket{\psi|\psi} =& \int \braket{\psi|q} \braket{q|\psi} \;\d q \\
  =& \int \psi^* (q) \psi(q) \;\d q \\
  =& \int |\psi(q)|^2 \;\d q = 1
\end{align*}
$$

#### Generalized orthonormality condition

Let $\hat{O}$ be a one-dimensional observable with a continuous spectrum, and let $\set{\ket{o}}$ be its eigenbasis. The state vector $\ket{\psi}$ of the system can be expanded as

$$
  \ket{\psi} = \int c(o)\ket{o} \;\d o
$$

where $c(o) = \braket{o|\psi}$ is the projection of $\psi$ onto $\ket{o}$. If $\psi(q) = \ket{q|\psi}$ is a wavefunction in terms of another continuous eigenbasis $\set{\ket{q}}$, the normalization condition requires that

$$
  \int |c(o)|^2 \;\d o = \int |\psi(q)|^2 \;\d q 
$$

Substituting $\psi^* (q) = \braket{\psi|q}$ into the right hand side and applying the completeness relation $\int \ket{q}\bra{q} \;\d q = \hat{I}$ we obtain

$$
\begin{align*}
  \int c^* (o) c(o) \;\d o =& \int \d o \;c^* (o) \left(\int \d q \braket{o|q} \braket{q|\psi} \right) \\
  =& \int \d o\; c^*(o) \left(\int \d q\; \psi(q) \phi_{o}^* (q) \right)
\end{align*}
$$

where $\phi_o (q) = \braket{q|o}$, which yields

$$
  c(o) = \braket{o|\psi} = \int \psi(q) \phi_{o}^* (q) \;\d q
$$

Back-substituting $\psi(q) = \braket{q|\psi}$, we get

$$
\begin{align*}
  c(o) =& \int \d o'\; c(o') \left(\int \d q\; \phi_{o'} (q) \phi_o^* (q) \right) \\
  =& \int \d o'\; c(o') \left(\int \d q\; \braket{o|q} \braket{q|o'} \right) \\
  =& \int c(o') \braket{o|o'} \;\d o' 
\end{align*}
$$

from which it follows that

$$
  \braket{o|o'} = \left(\int \d q\; \phi_{o'} (q) \phi_o^* (q) \right) = \delta(o - o')
$$

### Mixed spectrum

Let $\hat{Q}$ be a Hermitian operator on the Hilbert space $\mathcal{H}$ with both a discrete and a continuous spectrum. In this case, the eigenvalues corresponding to the discrete spectrum are labeled by $q_n$, while the continuous spectrum is parametrized by $q$. Assuming that the continuous spectrum is in the range $q\in(\tilde{q},\infty)$, the projection operators for the discrete are continuous components are given by:

$$
\begin{align*}
  \hat{P}_\text{d} =& \sum_n \ket{q_n} \bra{q_n} \\
  \hat{P}_\text{c} =& \int_{\tilde{q}}^\infty \ket{q} \bra{q} \; \d q
\end{align*}
$$

These projection operators must satisfy the completeness relation 

$$
  \hat{P}_\text{c} + \hat{P}_\text{d} = \hat{I}
$$

where $\hat{I}$ is the identity operator on $\mathcal{H}$. In terms of this eigenbasis, a state vector $\ket{\psi}$ can be expanded as

$$
  \ket{\psi} = \sum_n c(q_n) \ket{q_n} + \int_{\tilde{q}}^\infty \psi(q) \ket{\psi} \; d q
$$

where
- $c(q_n) = \ket{q_n |\psi}$ is the expansion coefficient for the discrete eigenbasis $\set{\ket{q_n}}_n$
- $\psi(q) = \ket{q|\psi}$ is the wavefunction in the continuous eigenbasis $\set{\ket{q}}$

According to Born's rule, the probability of measuring $q_n$ in the discrete spectrum is given by $|c(q_n)|^2$, while the probability of measuring the eigenvalue in the interval $(q, q + \d q)$ is given by $|\psi(q)|^2 \d q$. The normalization condition implies that

$$
  \braket{\psi|\psi} = \sum_n |c(q_n)|^2 + \int_{\tilde{q}}^\infty |\psi(q)|^2 \;\d q = 1
$$

### Compatible observables

Two observables $P$ and $Q$ are compatible if they are simultaneously measurable with arbitrary precision. This means that there exists a common eigenbasis for their corresponding operators $\hat{P}$ and $\hat{Q}$, allowing them to be jointly diagonalized. This condition holds if and only if $\hat{P}$ and $\hat{Q}$ commute. In summary, the following statements are equivalent:
1. $P$ and $Q$ are compatible observables
2. $\hat{P}$ and $\hat{Q}$ have a common eigenbasis
3. $\hat{P}$ and $\hat{Q}$ commute, i.e. $[\hat{P}, \hat{Q}] = 0$

<details>
<summary>Proof</summary>

**(2) $\implies$ (3):**
Assuming $\hat{P}$ and $\hat{Q}$ have a common basis of eigenvectors, $\set{\ket{b_k}}_k$, we have

$$
  \hat{P}\ket{b_k} = p_k \ket{b_k}, \quad \hat{Q} \ket{b_k} = q_k \ket{b_k}
$$

It follows that

$$
\begin{align*}
  \hat{P}\hat{Q}\ket{b_k} = \hat{P} q_k \ket{b_k} = q_k \hat{P} \ket{b_k} = q_k p_k \ket{b_k}
  \hat{Q}\hat{P}\ket{b_k} = \hat{Q} p_k \ket{b_k} = p_k \hat{P} \ket{b_k} = p_k q_k \ket{b_k}
\end{align*}
$$

Since $p_k, q_k \in\mathbb{C}$ are scalars it follows that $\hat{P}\hat{Q} = \hat{Q}\hat{P}$.

**(3) $\implies$ (2):**
We now assume that $\mathbf{P}$ and $\mathbf{Q}$ commute. In a basis $\set{\ket{a_k}}$ we have

$$
\begin{equation*}
\begin{split}
  (\mathbf{P}\mathbf{Q})_{jk} =& \braket{a_j | \hat{P}\hat{Q} | a_k} \\
  =& \sum_\ell \braket{a_j | \hat{P} | a_\ell} \braket{a_\ell | \hat{Q} | a_k} \\
  =& \sum_\ell \mathbf{P}_{k\ell} \mathbf{Q}_{\ell j}
\end{split}
\tag{\label{equation-79}}
\end{equation*}
$$

If $\set{\ket{a_k}}_k$ is an eigenbasis of $\hat{P}$, we can rewrite $\eqref{equation-79}$ as

$$
\begin{align*}
  (\mathbf{P}\mathbf{Q})_{jk} =& \sum_\ell \braket{a_j | \hat{P} | a_\ell} \braket{a_\ell | \hat{Q} | a_k} \\
  =& \sum_\ell p_\ell \delta_{j\ell} \mathbf{Q}_{\ell k} = p_j \mathbf{Q}_{jk}
\end{align*}
$$

Inverting the orders of the operators, we have

$$
\begin{align*}
  (\mathbf{Q}\mathbf{P})_{jk} =& \sum_\ell \braket{a_j | \hat{Q} | a_\ell} \braket{a_\ell | \hat{P} | a_k} \\
  =& \sum_\ell \mathbf{Q}_{j\ell} p_k \delta_{\ell k} = p_k \mathbf{Q}_{jk}
\end{align*}
$$

Since $[\hat{P}, \hat{Q}] = 0$, we must have $(p_j - p_k) \mathbf{Q}_{jk} = 0$. This condition is trivially satisfied for $j = k$. In the non-degenerate case, if $p_k \neq p_j$ for $j \neq k$, it follows that $\mathbf{Q}_{jk} = 0$ for $j \neq k$, or equivalently $\mathbf{Q}_{jk} = \mathbf{Q}_{jj} \delta_{jk}$. This implies that the operator $\hat{Q}$ is diagonal in the eigenbasis of $\hat{P}$, proving the result.

In the degenerate case, where $p_j = p_k$ for $j \neq k$, we can consider the subspace spanned by the eigenvectors corresponding to the degenerate eigenvalues. Since $\hat{Q}$ is Hermitian and commutes with $\hat{P}$, we can diagonalize $\hat{Q}$ within this subspace, where $\hat{P} = p_k \hat{I}$. This shows that $\hat{P}$ and $\hat{Q}$ can be jointly diagonlized, and therefore, they share a common eigenbasis.
</details>

In general, a quantum system can be fully characterized by a set of mutually commuting observables, which collectively determine the eigenbasis describing the system's physical states. Such a set is called a *complete set of commuting observables* (CSCO). 

In the simplest case, an observable has a non-degenerate discrete spectrum, meaning each eigenvalue uniquely corresponds to a single eigenstate. In such cases, the observable itself is sufficient to form a CSCO. However, when the spectrum is degenerate, multiple eigenstates may correspond to the same eigenvalue. In such cases, additional commuting observables are needed to distinguish between the degenerate eigenvectors and uniquely specify the system's state.

For finite-dimensional Hilbert spaces, Schur's lemma guarantees that a complete set of commuting observables always exists. This means that in such systems, it is always possible to find a set of commuting operators whose eigenvalues uniquely determine the system's state. In infinite-dimensional systems, there is no universal guarantee for a CSCO, but in many cases - such as systems with continuous symmetries - there can still be a sufficient set of commuting variables to determine the quantum states.

<MathBox title='Complete set of commuting variables' boxType='definition'>
A set of observables $\mathcal{S} = \set{A, B, C, \dots}$ is a complete set of commuting observables (CSCO) if:
1. All the observables commute by pairs
2. Specifying the eigenvalues of all the operators in the CSCO identifies a unique common eigenvector
</MathBox>

## Uncertainty principle

Two quantum observables $P$ and $Q$ are incompatible if they cannot be simultaneously measurable with arbitrary precision. This implies that there is no common eigenbasis for the corresponding operators $\hat{P}$ and $\hat{Q}$. In this case, measuring one observable disturbs the system's state in such a way that it affects the measurement of the other observable. Incompatibility occurs if $\hat{P}$ and $\hat{Q}$ do not commute.

To quantify the uncertainty of an observable $Q$, we define the operator

$$
  \Delta_\psi \hat{Q} = \hat{Q} - \braket{\hat{Q}}_\psi
$$

as the deviation of $\hat{Q}$ from its expectation value in the state $\ket{\psi}$. The variance $\sigma_Q^2$ of $Q$ in the state $\ket{\psi}$ is given by $\sigma_Q^2 = \langle (\Delta_\psi \hat{Q})^2 \rangle$. Expanding this expression we get

$$
\begin{align*}
  \braket{(\Delta_\psi \hat{Q} )^2} &= \Braket{(\hat{Q} - \langle \hat{Q} \rangle_\psi )^2}_\psi \\
  &= \Braket{\hat{Q}^2 - 2 \braket{\hat{Q}}_\psi \hat{Q} + \braket{\hat{Q}}_\psi^2 }_\psi \\
  &= \braket{\hat{Q}^2}_\psi - \braket{\hat{Q}}_\psi^2 \\
  &= \braket{\psi|\hat{Q}^2|\psi} - \braket{\psi |\hat{Q}|\psi}^2
\end{align*}
$$

For two Hermitian operators $\hat{P}$ and $\hat{Q}$, the generalized uncertainty principle, also known as the Robertson-Schr√∂dinger uncertainty relation, states that

$$
\begin{align*}
  \sigma_P^2 \sigma_Q^2 \geq& \left|\frac{1}{2} \Braket{\{\hat{P},\hat{Q}\}} - \braket{\hat{P}} \braket{\hat{Q}} \right|^2 + \left|\frac{1}{2i}\Braket{[\hat{P},\hat{Q}]} \right|^2 \\
  =& |\operatorname{cov}(\hat{P}, \hat{Q})|^2 + \left|\frac{1}{2}\Braket{[\hat{P},\hat{Q}]} \right|^2
\end{align*}
$$

where $\operatorname{cov}(\hat{P}, \hat{Q})$ is the covariance of $\hat{P}$ and $\hat{Q}$. If $\operatorname{cov}(\hat{P}, \hat{Q}) = 0$, the uncertainty principle reduces to

$$
\begin{equation*}
  \sigma_P \sigma_Q \geq \frac{1}{2} \left|\Braket{[\hat{P},\hat{Q}]} \right| 
\tag{\label{equation-102}}
\end{equation*}
$$

which is known as the Heisenberg-Robertson uncertainty relation.

<details>
<summary>Proof</summary>

Let $\hat{P}$ and $\hat{Q}$ be Hermitian operators and define

$$
\begin{align*}
  \ket{f} :=& \Delta\hat{P}\ket{\psi} = (\hat{P} - \braket{\hat{P}})\ket{\psi} \\
  \ket{g} :=& \Delta\hat{Q}\ket{\psi} = (\hat{Q} - \braket{\hat{Q}})\ket{\psi}
\end{align*}
$$

By Hermiticity of $\hat{P}$ and $\hat{Q}$, it follows that $\braket{\hat{P}}, \braket{\hat{Q}}\in\R$ such that $\Delta\hat{P}$ and $\Delta\hat{Q}$ are also Hermitian. Thus,

$$
  \braket{f|f} = \braket{\psi|\Delta \hat{P}^\dagger \Delta\hat{P}|\psi} = \braket{\psi|(\Delta\hat{P})^2|\psi} = \sigma_P^2
$$

and similarly $\braket{g|g} = \sigma_Q^2$. Furthermore

$$
  \braket{f|g} = \braket{\psi|\Delta\hat{P}^\dagger \Delta\hat{Q}|\psi} = \braket{\psi|\Delta\hat{P} \Delta\hat{Q}|\psi} = \braket{\Delta\hat{P}\Delta\hat{Q}}
$$

To find $\braket{\Delta\hat{P}\Delta\hat{Q}}$ we decompose $\Delta\hat{P}\Delta\hat{Q}$ it into its commutator and anti-commutator:

$$
  \Delta\hat{P}\Delta\hat{Q} = \frac{1}{2}[\Delta\hat{P},\Delta\hat{Q}] + \frac{1}{2}\{\Delta\hat{P},\Delta\hat{Q}\}
$$

By Hermiticity, $[\Delta\hat{P},\Delta\hat{Q}]$ is anti-Hermitian and thus $\Braket{[\Delta\hat{P},\Delta\hat{Q}]}$ is purely imaginary. Meanwhile, $\{\Delta\hat{P},\Delta\hat{Q}\}$ is Hermitian and thus $\Braket{\{\Delta\hat{P},\Delta\hat{Q}\}}$ is real. This implies that $\braket{\Delta\hat{P}\Delta\hat{Q}}\in\mathbb{C}$ is a complex number with modulus given by

$$
  |\braket{\Delta\hat{P}\Delta\hat{Q}}|^2 = \left|\frac{1}{2}[\Delta\hat{P},\Delta\hat{Q}]\right|^2 + \left|\frac{1}{2}\{\Delta\hat{P},\Delta\hat{Q}\}\right|^2
$$

Computing $[\Delta\hat{P},\Delta\hat{Q}]$, we find

$$
\begin{align*}
  [\Delta\hat{P},\Delta\hat{Q}] =& (\hat{P} - \braket{\hat{P}})(\hat{Q} - \braket{\hat{Q}}) - (\hat{Q} - \braket{\hat{Q}})(\hat{P} - \braket{\hat{P}}) \\
  =& \hat{P}\hat{Q} - \braket{\hat{Q}}\hat{P} - \braket{\hat{P}}\hat{Q} + \braket{\hat{Q}}\braket{\hat{P}} \\
  &- \hat{Q}\hat{P} + \braket{\hat{P}}\hat{Q} + \braket{\hat{Q}}\hat{P} - \braket{\hat{P}}\braket{\hat{Q}} \\
  =& \hat{P}\hat{Q} - \hat{Q}\hat{P} = [\hat{P},\hat{Q}]
\end{align*}
$$

Computing $\braket{\{\Delta\hat{P},\hat{Q}\}}$, we find

$$
\begin{align*}
  \Braket{\{\Delta\hat{P},\hat{Q}\}} =& \Braket{(\hat{P} - \braket{\hat{P}})(\hat{Q} - \braket{\hat{Q}}) + (\hat{Q} - \braket{\hat{Q}})(\hat{P} - \braket{\hat{P}})} \\
  =& \left\langle \hat{P}\hat{Q} - \braket{\hat{Q}}\hat{P} - \braket{\hat{P}}\hat{Q} + \braket{\hat{Q}}\braket{\hat{P}} \right. \\
  &\left. +\hat{Q}\hat{P} - \braket{\hat{P}}\hat{Q} - \braket{\hat{Q}}\hat{P} + \braket{\hat{P}}\braket{\hat{Q}} \right\rangle \\
  =& \braket{\hat{P}\hat{Q} + \hat{Q}\hat{P}} - 4\braket{\hat{P}}\braket{\hat{Q}} + 2\braket{\hat{P}}\braket{\hat{Q}} \\
  =& \Braket{\{\hat{P}, \hat{Q}\}} - 2\braket{\hat{P}}\braket{\hat{Q}}
\end{align*}
$$

Combining the results, we obtain

$$
\begin{align*}
  |\braket{\Delta\hat{P}\Delta\hat{Q}}|^2 =& \left|\frac{1}{2}\Braket{[\Delta\hat{P},\Delta\hat{Q}]}\right|^2 + \left|\frac{1}{2}\Braket{\{\Delta\hat{P},\Delta\hat{Q}\}}\right|^2 \\
  =& \left|\frac{1}{2}\Braket{[\hat{P},\hat{Q}]}\right|^2 + \left|\frac{1}{2}\Braket{\{\hat{P},\hat{Q}\}} - \braket{\hat{P}}\braket{\hat{Q}}\right|^2
\end{align*}
$$

Invoking the Cauchy-Schwarz inequality, we get

$$
\begin{align*}
  \braket{f|f}\braket{g|g} \geq& |\braket{f|g}|^2 \\
  \sigma_P^2 \sigma_Q^2 \geq& |\braket{\Delta\hat{P}\Delta\hat{Q}}|^2
\end{align*}
$$

from which it follows that

$$
  \sigma_P^2 \sigma_Q^2 \geq \left|\frac{1}{2}\Braket{[\hat{P},\hat{Q}]}\right|^2 + \left|\frac{1}{2}\Braket{\{\hat{P},\hat{Q}\}} - \braket{\hat{P}}\braket{\hat{Q}}\right|^2
$$
</details>

## Schr√∂dinger equation

The time evolution of a state vector $\ket{\psi}$ is given by the Schr√∂dinger equation

$$
\begin{equation*}
  i\hbar \frac{\partial}{\partial t}\ket{\psi} = \hat{H} \ket{\psi} 
\tag{\label{equation-98}}
\end{equation*}
$$

If $\ket{\psi}$ can be expanded in a continuous eigenbasis $\ket{q}$ as

$$
  \ket{\psi} = \int \psi(q,t)\ket{q} \;\d q, \; \psi(q,t) = \braket{q|\psi}
$$

then taking the scalar product of both sides of the Schr√∂dinger equation with $\ket{q}$ gives

$$
\begin{align*}
  \Braket{q|i\hbar \frac{\partial}{\partial t}|\psi(t)} =& \braket{q|\hat{H}|\psi} \\
  i\hbar \frac{\partial}{\partial t} \psi(q, t) =& \braket{q|\hat{H}|\psi}
\end{align*}
$$

If $\hat{H}$ has eigenstates $\ket{q}$, then

$$
  \braket{q|\hat{H}|\psi} = \hat{H}\psi(q,t)
$$

This leads to the Schr√∂dinger equation for the wavefunction $\psi(q,t)$ in the eigenbasis of $\hat{q}$:

$$
  i\hbar \frac{\partial}{\partial t} \psi(q, t) = \hat{H} \psi(q, t)
$$

### Derivation of the Sch√∂dinger equation

In general, an evolution equation must conform to the fundamental principles of quantum mechanics. We begin by assuming that the evolution of the state vector is deterministic. This implies that the state at a given time $t_0$ is sufficient to determine the state at any later time. 

Next, we note that the evolution equation can only contain the first time derivative of the state vector. If it were of higher order, the solution would require knowledge of the higher time derivatives of the state at $t_0$, violating the requirement that the state vector encodes all the information about the quantum system.

The superposition principle tells that any linear combination of states must also be a solution to the evolution equation. Consequently, the equation must be linear and homogenous. The most general form of such an equation is

$$
  \frac{\partial}{\partial t} \ket{\psi} = \hat{Q}\ket{\psi}
$$

where $\hat{Q}$ is a linear operator to be determined.

The equation implies that $\hat{Q}$ must correspond to the generator of time translations, or equivalently, to a quantity conserved under time translations. We know from classical mechanics that the generator of time translations is the energy of the system, represented by the Hamiltonian. By the correspondence principle, we deduce that the operator $\hat{Q}$ is a function of the Hamiltonian operator $\hat{H}$:

$$
  \frac{\partial}{\partial t} \ket{\psi} = f(\hat{H})\ket{\psi}
$$

Next, we consider a composite system made of two subsystems with Hamiltonians $\hat{H}_1$ and $\hat{H}_2$, respectively. Since total Hamiltonian is $\hat{H} = \hat{H}_1 + \hat{H}_2$, we require that $f$ must be linear, i.e.

$$
  f(\hat{H}_1 + \hat{H}_2) = f(\hat{H}_1) + f(\hat{H}_2) 
$$

The only form that satisfies this in the most general case is

$$
  f(\hat{H}) = a\hat{H}
$$

where $a \in\mathbb{C}$ is a complex constant with dimension of inverse action. To determine $a$, we use the fact that the normalization condition $\braket{\psi|\psi} = 1$ is preserved during time evolution. Thus, the time derivative of $\braket{\psi|\psi}$ must vanish:

$$
\begin{equation*}
  \frac{\partial}{\partial t} \braket{\psi|\psi} = \frac{\partial\bra{\psi}}{\partial t} \ket{\psi} + \bra{\psi} \frac{\partial\ket{\psi}}{\partial t} = 0 
\tag{\label{equation-80}}
\end{equation*}
$$

Taking the Hermitian adjoint of $\frac{\partial}{\partial t}\ket{\psi} = a\hat{H}\ket{\psi}$ and noting that $\hat{H}$ is Hermitian, we find

$$
  \frac{\partial}{\partial t} \bra{\psi} = \bra{\psi} a^* \hat{H}
$$

Substuting this into $\eqref{equation-80}$, we obtain

$$
  \Braket{\psi|(a^* \hat{H} + a\hat{H})|\psi} = 0
$$

For this to hold for any $\ket{\psi}$, we require $a^* = -a$, meaning that $a$ is purely imaginary. Since $a$ has the dimension of inverse action, it must be proportional to $\hbar$. If we choose $1/a = i\hbar$, we retrieve the Schr√∂dinger equation:

$$
  i\hbar \frac{\partial}{\partial t}\ket{\psi} = \hat{H} \ket{\psi}
$$

### Time symmetry

The Schr√∂dinger equation is invariant under time reversal transformations $t \mapsto -t$, provided we also exchange kets with bras, i.e. $\ket{\psi} \to \bra{\psi}$. Taking the Hermitian conjugate of the Schr√∂dinger equation $\eqref{equation-98}$ yields

$$
  -i\hbar\frac{\partial}{\partial t} \bra{\psi} = \bra{\psi}\hat{H}
$$

or equivalently

$$
  i\hbar\frac{\partial}{\partial(-t)} \bra{\psi} = \bra{\psi}\hat{H}
$$

### Preservation of probability

The Schr√∂dinger equation preserves the Born rule if $\hat{H}$ is Hermitian. To prove this, note that probility is conserved, if the norm of $\ket{\psi}$ remains constant over time

$$
  \frac{\d}{\d t} \braket{\psi(t)|\psi(t)} = 0
$$

Applying the product rule to the left-hand side gives

$$
  \frac{\d}{\d t} \braket{\psi|\psi} = \frac{\d}{\d t}(\bra{\psi})\ket{\psi} + \ket{\psi} \frac{\d}{\d t}(\ket{\psi})
$$

Taking the Hermitian adjoint of the equation yields

$$
  -i\hbar\frac{\d}{\d t}\bra{\psi(t)} = \bra{\psi(t)}\hat{H}^\dagger 
$$

Substituting the Schr√∂dinger equation and its conjugate gives

$$
\begin{align*}
  \frac{\d}{\d t} \braket{\psi|\psi} =& \left(-\frac{i}{\hbar}\bra{\psi}\hat{H}^\dagger \right)\ket{\psi} + \bra{\psi}\left(\frac{i}{\hbar}\hat{H}\ket{\psi} \right) \\
  =& \frac{i}{\hbar}\left(\braket{\psi|\hat{H}|\psi} - \braket{\psi|\hat{H}^\dagger|\psi} \right) = 0
\end{align*}
$$

This expression vanishes if and only if $\braket{\psi|\hat{H}|\psi} = \braket{\psi|\hat{H}^\dagger|\psi}$. Since this must hold for any arbitrary state $\ket{\psi(t)}$, it follows that $\hat{H} = \hat{H}^\dagger$.

### Stationary states

If the Hamiltonian operator has a time-independent potential, the solution to the Schr√∂dinger equation is obtained by integrating $\eqref{equation-98}$, giving

$$
  \ket{\psi(t)} = e^{-i\hat{H}t/\hbar} \ket{\psi(0)}
$$

where $\ket{\psi(0)}$ is the state vector at time $t_0 = 0$. If the initial state vector is an eigenstate of the Hamiltonian, i.e.

$$
  \hat{H} \ket{\psi(0)} = E\ket{\psi(0)}
$$

where $E$ is the corresponding eigenvalue of $\hat{H}$, then the action of the operator $e^{i\hat{H}t/\hbar}$ on the state vector $\ket{\psi(0)}$ becomes trivial. In this case, the state vector at time $t$ is simply

$$
  \ket{\psi(t)} = e^{-iEt/\hbar} \ket{\psi(0)}
$$

Consequently, an energy eigenstate does not evolve with time since the phase factor $e^{-iEt/\hbar}$ is irrelevant for the physical state. In order to find a time-evolved state vector $\ket{\psi(t)}$, we first need to solve the eigenvalue equation for the Hamiltonian, called the time-independent Schr√∂dinger equation. In the case of a discrete spectrum, this reads

$$
  \hat{H}\ket{\psi_n} = E_n \ket{\psi_n}
$$

where $\ket{\psi_n}$ are the stationary states and $E_n$ are the corresponding eigenvalues, representing the energy levels of the system. Next, we expand the intial state vector $\ket{\psi(0)}$ in terms of the basis $\set{\ket{\psi_n}}$ by determining the complex coefficients $c_n^(0)$ such that

$$
  \ket{\psi(0)} = \sum_n c_n^{(0)} \ket{\psi_n}
$$

The time-evolved state is the given by

$$
  \ket{\psi(t)} = \sum_n e^{-iE_nt/\hbar} c_n^{(0)} \ket{\psi_n}
$$

For a continuous spectrum, the eigenvalue equation becomes

$$
  \hat{H}\ket{\psi_E} = E\ket{\psi_E}
$$

and the expansion of $\ket{\psi(0)}$ onto the continuous basis $\ket{\psi_E}$ is 

$$
  \ket{\psi(0)} = \int c^{(0)} (E) \ket{\psi_E} \;\d E
$$

The time-evolved state is then

$$
  \ket{\psi(t)} = \int e^{-iEt/\hbar} c^{(0)} (E) \ket{\psi_E} \;\d E
$$

Taking the expectation value of $\hat{H}$ with respect to an initial eigenstate $\ket{\psi(0)}$, we get

$$
\begin{align*}
  \braket{\hat{H}}_\psi =& \braket{\psi|\hat{H}|\psi} = E\underbrace{\braket{\psi|\psi}}_{=1} = E
\end{align*}
$$

Since

$$
  \hat{H}^2 \ket{\psi} = \hat{H}(\hat{H}\ket{\psi}) = \hat{H}(E\ket{\psi}) = E(\hat{H}\ket{\psi}) = E^2 \ket{\psi}
$$

it follows that $\braket{\hat{H}^2} = E^2$. Thus, the variance of $H$ is

$$
  \sigma_H^2 = \braket{H^2} - \braket{H}^2 = E^2 - E^2 = 0
$$

showing that the total energy is a determinate state.

#### Wavefunction formulation

In terms of a wavefunction $\psi(x,t)$, the Schr√∂dinger equation for a time-independent potential can be solved by separation of variables. Assuming a wavefunction of the form $\Psi(\mathbf{x},t) = \psi(\mathbf{x})\phi(t)$ with partial derivatives

$$
  \frac{\partial\Psi}{\partial t} = \psi \frac{\d\phi}{\d t}, \quad \nabla^2 \Psi = (\nabla^2 \psi) \phi
$$

the Schr√∂dinger equation reads

$$
\begin{align*}
  i\hbar \psi \frac{\d\phi}{\partial t} =& -\frac{\hbar^2}{2m} (\nabla^2 \psi)\phi + V\psi\phi \\
  i\hbar \frac{1}{\phi} \frac{\d\phi}{\d t} =& -\frac{\hbar^2}{2m} \frac{1}{\psi} \nabla^2 \psi + V
\end{align*}
$$

The equation holds if both sides equal a separation constant, which in this case corresponds with the systems total energy $E$. This results in the temporal equation

$$
  \frac{\d\phi}{\d t} = -\frac{iE}{\hbar} \phi
$$

and the spatial equation

$$
\begin{align*}
  -\frac{\hbar^2}{2m} \nabla^2 \psi + V\psi =& E\psi \\
  \hat{H}\psi =& E\psi 
\end{align*}
$$

which is called the time-independent Schr√∂dinger equation. The temporal equation has general solution

$$
  \phi(t) = C e^{-iEt/\hbar}
$$

Absorbing the normalization constant $C$ into $\psi$, the wavefunction becomes

$$
  \Psi(\mathbf{x}, t) = \psi(\mathbf{x}) e^{-iEt/\hbar}
$$

Although $\Psi$ depends on $t$, the probability density

$$
  |\Psi(\mathbf{x},t)|^2 = \Psi^* \Psi = \psi^* e^{iEt/\hbar} \psi e^{-iEt/\hbar} = |\psi(x)|^2
$$

is time-independent.

### Degenerate eigenvalues

Energy eigenstate can be degenerate, in which case two or more eigenstates share the same eigenvalue. A neccessary and sufficient condition for energy degeneracy is that an observable $\hat{Q}$ commutes with the Hamiltonian, and is not the identity operator. Specifically, if

$$
  [\hat{H}, \hat{Q}] = 0
$$

and $\hat{Q}$ is not a function of $\hat{H}$ alone, then

$$
  \hat{H}\hat{Q} \ket{\psi_j} = \hat{Q}\hat{H}\ket{\psi_j} = E_j \hat{Q} \ket{\psi_j}
$$

which shows that $\hat{Q}\ket{\psi_j}$ is an eigenvector of $\hat{H}$ with eigenvalue $E_j$. Moreover, $\hat{Q}\ket{\psi_j}$ cannot be proportional to $\ket{\psi_j}$. In other words, it cannot be written as $\hat{Q}\ket{\psi_j} = f(E_j) \ket{\psi_j}$, where $f(E_j)$ is a function of the $j$-th energy eigenvalue. If this were the case, $\hat{Q}$ would be equal to $f(\hat{H})$, which contradicts the assumptions that $\hat{Q}$ is not a function of $\hat{H}$.

Let us prove that degeneracy implies commutativity in the case of a discrete spectrum. If degeneracy exists, the whole Hilbert space $\mathcal{H}$ can always be partitioned into subspaces $\mathcal{H}_k$ for $k\in\N_+$, each of which is associated with a constant energy eigenvalue $E_k$. In this case, we can write

$$
  \mathcal{H} = \bigoplus_k \mathcal{H}_k
$$

For any $\ket{\varphi}\in\mathcal{H}_k$, we have

$$
  \hat{H}\ket{\varphi} = E_k \ket{\varphi}
$$

Thus, within each subspace $\mathcal{H}_k$, the Hamiltonian $\hat{H}_k$ acts as multiple of the identity, i.e. $\hat{H}_k = E_k \hat{I}$. The dimension of $\mathcal{H}_k$ is equal to the degeneracy of the eigenvalue $E_k$. Next, we can define a Hermitian operator $\hat{Q}$

$$
  \hat{Q} = \bigotimes_n \hat{Q}_n
$$

where $\hat{Q}_k$ is an arbitrary operator acting within $\mathcal{H}_k$. Furthermore, since $\hat{H}_k = E_k \hat{I}$, it follows that $[\hat{Q}_k, \hat{H}_k] = 0$. This implies that $\hat{Q}$ commutes with $\hat{H}$, i.e. $[\hat{Q},\hat{H}] = 0$.

## Time evolution operator

A time evolution operator $\hat{U}$ translates a state vector $\ket{\psi(t)}$ from time $t_a$ to $t_b$ by

$$
  \hat{U}(t_b,t_a)\ket{\psi(t_a)} = \ket{\psi(t_b)}
$$

with the initial condition $\hat{U}(t_a, t_a) = \hat{I}$.

If the Hamiltonian is time-independent, the time evolution operator is obtainable from the Schr√∂dinger equation

$$
  i\hbar\frac{\partial}{\partial t_b}(\hat{U}(t_b,t_a)\ket{\psi(t_a)}) = \hat{H}\hat{U}(t_b,t_a)\ket{\psi(t_a)} 
$$

Since $\ket{\psi(t_a)}$ is indepedent of $t_b$, we can factor it out from the partial time derivative

$$
  i\hbar\frac{\partial\hat{U}(t_b,t_a)}{\partial t_b}\ket{\psi(t_a)} = \hat{H}\hat{U}(t_b,t_a)\ket{\psi(t_a)} 
$$

This equation must hold for any initial state $\ket{\psi(t_a)}$ giving a first-order differential equation for $\hat{U}(t_b,t_a)$

$$
  i\hbar\frac{\partial\hat{U}(t_b,t_a)}{\partial t_b} = \hat{H}\hat{U}(t_b,t_a)
$$

with solution

$$
  \hat{U}(t_b,t_a) = e^{i\hat{H}(t_a - t_b)/\hbar}
$$

Its inverse is obtained by interchanging the order of $t_a$ and $t_b$

$$
  \hat{U}^{-1}(t_b,t_a) = e^{-i\hat{H}(t_a - t_b)/\hbar}
$$

Since $\hat{H}$ is Hermitian, $\hat{U}$ is unitary because

$$
\begin{equation*}
\begin{split}
  \hat{U}^\dagger (t_b,t_a) =& e^{i(t_b - t_a)\hat{H}^\dagger /\hbar} \\
  =& e^{i(t_b - t_a)\hat{H} /\hbar} \\
  =& \hat{U}^{-1}(t_b,t_a)
\end{split}
\tag{\label{equation-6}}
\end{equation*}
$$

If the Hamiltonian depends explicitly on time, the time evolution operator can be found iteratively. The time interval $[t_a, t_b]$ with $t_a < t_b$ is partitioned into $N + 1$ subintervals of length $\epsilon = (t_b - t_a)/(N + 1)$, such that $t_n = t_a + n\epsilon$ for $n=0,\dots,N+1$. Schr√∂dinger's equation approximates the time evolution at each step $\epsilon$

$$
\begin{align*}
  \ket{\psi(t_a + \epsilon)} \approx& \left(1 - \frac{i}{\hbar} \int_{t_a}^{t_a + \epsilon} \hat{H}(t)\;\d t \right)\ket{\psi(t_a)} \\
  \ket{\psi(t_a + 2\epsilon)} \approx& \left(1 - \frac{i}{\hbar} \int_{t_a}^{t_a + 2\epsilon} \hat{H}(t)\;\d t \right)\ket{\psi(t_a + \epsilon)} \\
  \vdots& \\
  \ket{\psi(t_a + (N+1)\epsilon)} \approx& \left(1 - \frac{i}{\hbar} \int_{t_a}^{t_a + (N+1)\epsilon} \hat{H}(t)\;\d t \right)\ket{\psi(t_a + N\epsilon)} 
\end{align*}
$$

Combining the equation, the time evolution operator is approximated as

$$
  \hat{U}(t_b, t_a) \approx \prod_{n=0}^{N} \left(\int_{t_n}^{t_{n+1}} \hat{H}(t'_{n+1})\;\d t'_{n+1} \right)
$$

Expanding the product and taking the limit $N\to\infty$ gives the series

$$
\begin{align*}
  \hat{U}(t_b, t_a) =& 1 - \frac{1}{\hbar} \int_{t_a}^{t_b} \d t'_1 \;\hat{H}(t'_1) \\
  &+ \left(\frac{-i}{\hbar}\right) \int_{t_a}^{t_b} \d t'_n \int_{t_a}^{t_n} \d t'_{n-1} \cdots \int_{t_a}^{t'_2} \d t'_1 \;\hat{H}(t'_n)\hat{H}(t'_{n-1})\cdots\hat{H}(t'_1)
\end{align*}
$$

known as the *Neumann-Liouville expansion* or *Dyson series*. Note that each integral has the time arguments in the Hamilton operators ordered causally since the operators are ordered descending in time. It is useful to introduce a time-ordering operator, which when applied to an arbitrary product of operators

$$
  \hat{O}_n (t_n) \cdots\hat{O}_1 (t_1)
$$

reorders the times successivelse, i.e.

$$
  \hat{T}(\hat{O}_n (t_n)c\dots\hat{O}_1 (t_1)) := \hat{O}_{i_n} (t_{i_n})\cdots\hat{O}_{i_1} (t_{i_1})
$$

where $t_{i_n},\dots,t_{i_1}$ are the times $t_n,\dots,t_1$ relabeled in the causal order, so that

$$
  t_{i_n} > t_{i_{n-1}} >\cdots> t_{i_1}
$$

With this operator, the Neumann-Liouville expansion can be written more compactly. Consider the third term of the series

$$
\begin{equation*}
  \int_{t_a}^{t_b} \d t_2 \int_{t_a}^{t_2} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1)
\tag{\label{equation-1}}
\end{equation*}
$$

The integration covers the triangle above the diagonal in the square $t_1, t_2 \in [t_a, t_b]$ in the $(t_1, t_2)$ plane. Comparing this the with the remaining integral over the lower triangle

$$
\begin{equation*}
  \int_{t_a}^{t_b} \d t_2 \int_{t_2}^{t_b} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1)
\tag{\label{equation-2}}
\end{equation*}
$$

we see that the two expressions coincide except for the order of the operators. Applying the time-ordering operator to $\eqref{equation-2}$, gives

$$
  \hat{T} \int_{t_a}^{t_b} \d t_2 \int_{t_2}^{t_b} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1)
$$

which is equal to $\eqref{equation-1}$ because $\eqref{equation-2}$ can be rewritten as

$$
\begin{equation*}
  \int_{t_a}^{t_b} \d t_2 \int_{t_2}^{t_b} \d t_1 \; \hat{H}(t_1)\hat{H}(t_2) = \int_{t_a}^{t_b} \d t_1 \int_{t_a}^{t_1} \d t_2 \; \hat{H}(t_1)\hat{H}(t_2) 
\tag{\label{equation-3}}
\end{equation*}
$$

where the order of integration is changed in the last step. Apart from the dummy integration variables $t_2 \leftrightarrow t_1$, the double integral $\eqref{equation-3}$ coincides with $\eqref{equation-1}$. Since the time arguments are properly ordered, the time-ordering operator can be applied to $\eqref{equation-1}$ to give

$$
  \frac{1}{2}\hat{T}\int_{t_a}^{t_b} \d t_2 \int_{t_a}^{t_b} \d t_1 \; \hat{H}(t_2)\hat{H}(t_1) = \frac{1}{2}\hat{T}\left(\int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)^2
$$

Similarly, we may rewrite the $n$-th order term of the Neumann-Liouville expansion as

$$
\begin{align*}
  &\frac{1}{n!} \hat{T} \int_{t_a}^{t_b} \d t_n \int_{t_a}^{t_b} \d t_{n-1} \cdots \int_{t_a}^{t_b} \d t_1 \; \hat{H}(t_n)\hat{H}(t_{n-1})\cdots\hat{H}(t_1) \\
  =& \frac{1}{n!} \hat{T}\left(\int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)^n 
\end{align*}
$$

The time evolution operator $\hat{U}(t_b, t_a)$ has therefore the series expansion

$$
\begin{align*}
  \hat{U}(t_b, t_a) = \sum_{n=0}^\infty \frac{1}{n!}\left(\frac{-i}{\hbar}\right)^n \hat{T}\left(\int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)^n
\end{align*}
$$

which we recognize as the power series expansion of the exponential, giving

$$
\begin{equation*}
  \hat{U}(t_b, t_a) = \hat{T}\exp\left(-\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)
\tag{\label{equation-5}}
\end{equation*}
$$

Note that a small variation $\delta\hat{H}(t)$ of $\hat{H}(t)$ changes $\hat{U}(t_b, t_a)$ by

$$
\begin{align*}
  \delta\hat{U}(t_b, t_a) =& -\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{T}\exp\left(-\frac{i}{h} \int_{t'}^{t_b} \hat{H}(t)\; \d t \right) \delta\hat{H}(t') \hat{T}\exp\left(-\frac{i}{\hbar} \int_{t_a}^{t'} \hat{H}(t)\;\d t \right)\; \d t'\\
  =& -\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{U}(t_b, t') \delta\hat{H} (t') \hat{U}(t', t_a)\; \d t'
\end{align*}
$$

### Properties of the time evolution operator

#### Fundamental composition law

If two time translation are performed successively, the corresponding operators $\hat{U}$ are related by

$$
\begin{equation*}
  \hat{U}(t_c, t_a) = \hat{U}(t_c, t_b)\hat{U}(t_b, t_a),\; t_b \in(t_a, t_c)
\tag{\label{equation-4}}
\end{equation*}
$$

This composition law makes the operators $\hat{U}$ a representation of the Abelian group of time translations. For time-independent Hamiltonians the composition law $\eqref{equation-4}$ is trivial. In the general case with $\hat{U}(t_b, t_a)$ given by $\eqref{equation-5}$, the composition law follows from the additivity rule of the exponential

$$
\begin{align*}
  &\hat{T}\exp\left(-\frac{i}{\hbar} \int_{t'}^{t_b} \hat{H}(t)\;\d t \right)\hat{T} \exp\left(\int_{t_a}^{t'} \hat{H} (t) \;\d t \right) \\
  =& \hat{T}\left[\exp\left(-\frac{i}{\hbar} \int_{t'}^{t_b} \hat{H}(t)\;\d t \right) \exp\left(-\frac{i}{\hbar} \int_{t_a}^{t'} \hat{H}(t)\;\d t \right) \right] \\
  =& \hat{T}\exp\left(-\frac{i}{\hbar} \left[ \int_{t'}^{t_b} \hat{H}(t)\;\d t + \int_{t_a}^{t'} \hat{H}(t)\;\d t \right]\right) \\
  =& \hat{T}\exp\left(-\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}(t)\;\d t \right)
\end{align*}
$$

#### Unitarity (time reversal)

The inverse of the time evolution operator $\hat{U}(t_b, t_a)$ is obtained by interchanging the order of $t_a$ and $t_b$, which gives its anticasual form, i.e.

$$
  \hat{U}(t_b, t_a) = \hat{U}(t_a, t_b)^{-1}
$$

<details>
<summary>Proof</summary>

The time-reversal invertibility of $\hat{U}(t_b, t_a)$ follows by setting $t_b = t_a$ in $\eqref{equation-4}$ resulting in

$$
  \hat{I} = \hat{U}(t_a, t_a) = \hat{U}(t_a, t_b) \hat{U}(t_b, t_a)
$$

so that

$$
  \hat{U}(t_b, t_a)^{-1} = \hat{U}(t_a, t_b)
$$
</details>

This implies that $\hat{U}$ is unitary. The unitarity was already established for time independent Hamiltonians in $\eqref{equation-6}$. In the general case, a direct solution of the Schr√∂dinger equation shows that the operator $\hat{U}(t_b, t_a)$ for $t_b < t_a$ has a representation just like $\eqref{equation-5}$, except for a reversed time order of its argument, written as

$$
  \hat{U}(t_b, t_a) = \hat{\bar{T}} \exp\left(\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}(t) \;\d t \right)
$$

where $\hat{\bar{T}}$ denotes the time-antiordering operator, which satisfies

$$
  \left[\hat{T}\left(\hat{O}_1 (t_1)\cdots \hat{O}_n (t_n) \right) \right]^\dagger = \hat{\bar{T}} \left(\hat{O}_n^\dagger (t_n)\cdots \hat{O}_1^\dagger (t_1) \right)
$$

It follows that

$$
\begin{align*}
  \hat{U}^\dagger (t_b, t_a) =& \left[\hat{T} \exp\left(\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H} (t) \;\d t \right)\right]^\dagger \\
  =& \hat{\bar{T}} \exp\left(\frac{i}{\hbar} \int_{t_a}^{t_b} \hat{H}^\dagger (t) \;\d t \right) \\
  =& \hat{T} \exp\left(-\frac{i}{\hbar} \int_{t_b}^{t_a} \hat{H} (t) \;\d t \right) \\
  =& \hat{U}(t_a, t_b) = \hat{U}^{-1} (t_b, t_a)
\end{align*}
$$

#### Transition amplitudes

The transition amplitude between an initial state $\ket{\phi}$ at time $t_a$ and a final state $\ket{\psi}$ at time $t_b$ is given by $\braket{\psi|\hat{U}(t_b, t_a)|\phi}$. Taking the complex congujate of the expectation value we obtain

$$
  \left(\braket{\psi|\hat{U}(t_b, t_a)|\phi}\right)^* = \braket{\phi|\hat{U}(t_a, t_b)|\psi}
$$

which represents the probability amplitude for evolving $\ket{\psi}$ backward from $t_b$ to $t_a$. In this context, kets may viewed as input states and bras as output states of a unitary evolution. 

In particular, the amplitude $\braket{\psi|\hat{U}(t_b, t_a)|\psi}$ is the autocorrelation amplitude, giving the overlap of the evolved state with the initial state. Its squared modulus

$$
  C(t_b, t_a) = |\braket{\psi|\hat{U}(t_b, t_a)|\psi}|^2
$$

is the autocorrelation function, which measures the probability that the state $\ket{\psi}$ remains unchanged under time evolution.

#### Time evolution for $\hat{U}(t_b, t_a)$

Since the time-evolution operator $\hat{U}(t_b, t_a)$ gives the relation between arbitrary wavefunctions at different times

$$
  \ket{\psi(t_b)} = \hat{U}(t_b, t_a) \ket{\psi(t_a)}
$$

the Schr√∂dinger equation implies that the operator $\hat{U}(t_a, t_b)$ satisfies

$$
\begin{equation*}
\begin{split}
  i\hbar\frac{\partial}{\partial t} \hat{U}(t, t_a) =& \hat{H}\hat{U}(t, t_a) \\
  i\hbar\frac{\partial}{\partial t} \hat{U}^{-1} (t, t_a) =& -\hat{U}(t, t_a)^{-1} \hat{H}
\end{split}
\tag{\label{equation-8}}
\end{equation*}
$$

with the initial condition $\hat{U}(t_a, t_a) = 1$.

### Green's function

If the Hamiltonian admits a discrete spectrum, the elements of the time-evolution matrix can be written as

$$
  \Braket{k|e^{-i\hat{H}(t - t_0)/\hbar}|j} = i G(j, t_0; k, t)
$$

here $\ket{j}$ and $\ket{k}$ are state vectors, and $G$ denotes the Green's function. 

For a wavefunction in position space, we can derive an analogous expression by multiplying the time-independent Schr√∂dinger equation

$$
  \ket{\psi(t')} = e^{-i\hat{H}(t' - t)/\hbar}\ket{\psi(t)}
$$

with the position bra $\bra{\mathbf{r}'}$ and use the completeness relation $\hat{I} = \int \ket{\mathbf{r}}\bra{\mathbf{r}} \;\d\mathbf{r}$. This gives

$$
  \psi(\mathbf{r}',t) = i\int G(\mathbf{r}', t'; \mathbf{r}, t) \psi(\mathbf{r}, t) \;\d\mathbf{r}
$$

This equation reflects an instance of Huygens' principle: if the wwave function $\psi(\mathbf{r},t)$ is known at a time $t$, it can be determined at any later time $t'$ by considering each point $\mathbf{r}$ at time $t$ is a source of waves propagating outward. The amplitude of the wave arriving at point $\mathbf{r}'$ at time $t'$ from the point $\mathbf{r}$ is proportional to the original wave amplitude $\psi(\mathbf{r},t)$, with proportionality constant given by $iG(\mathbf{r}', t'; \mathbf{r}, t)$.

Green's functions are related to the resolvent of the Hamiltonian as the latter is the Fourier transform of the relative unitary operator, i.e.

$$
  \hat{R}_{\hat{H}}(\eta) = i \int_0^\infty e^{-\eta\tau} e^{-i\hat{H}\tau/\hbar} \;\d\tau
$$

where $\tau = t' - t$. For a linear operator $\hat{Q}$ on the Hilbert space $\mathcal{H}$, the resolvent $\hat{R}_{\hat{Q}}(\eta)$ is the operator-valued function

$$
  \hat{R}_{\hat{Q}}(\eta) = (\hat{Q} - \eta)^{-1s}
$$

which is defined for all complex values of $\eta$ where $(\hat{Q} - \eta)^{-1}$ exists. For the case of the Hamiltonian, we can use the projectors $\hat{P}_j$ onto the eigenvalues $E_j$ of $\hat{H}$. This gives the relation:

$$
  \hat{R}_{\hat{H}} (\eta) \hat{P}_j = \frac{\hat{P}_j}{E_j - \eta}
$$

This allows us to interpret the projectors $\hat{P}_j$ as the residues of the closed contour $f_j$ in the complex plane, enclosing the point $E_j$ on the real axis of the complex plane, i.e.

$$
  \hat{P}_j = \frac{1}{2\pi i} \oint_{f_j} \hat{R}_{\hat{H}} (\eta) \;\d\eta
$$

For the continuous part of the spectrum, we have

$$
  \hat{P}(\Delta j) = \frac{1}{2\pi i} \oint_{f(\Delta j)} \hat{R}_{\hat{H}} (\eta) \;\d\eta
$$

where $\hat{P}(\Delta j)$ is a projector on a small interval around the continuous eigenvalue $E_j$. 

In the case of a free particle, the Hamiltonian has a pure continuous spectrum in the iterval $[0,\infty)$. The resolvent of the free particle Hamiltonian $\hat{H}_0$ is

$$
  \hat{R}_{\hat{H}_0} (\eta) = \frac{1}{\hat{H}_0 - \eta}
$$

which is defined for all $\eta$ outside the spectrum. This resolvent is a bounded operator on the entire Hilbert space when $\Re(\eta) < 0$ or $\Im(\eta) \neq 0$, i.e. when the argument of $\eta$ is within the open interval $(0,2\pi)$. Using Green's functions, the evolution of a free particle in space and time takes the form

$$
  \psi(\mathbf{r}', t') = i\int G_0 (\mathbf{r}', t'; \mathbf{r}, t) \psi(\mathbf{r},t) \;\d\mathbf{r}
$$

for $t' > t$ and for all values $0 < \eta < 2\pi$. Here $G_0$ is called the free Green's function and its explicit expression is

$$
  G_0 (\mathbf{r}', t'; \mathbf{r}, t) = -i\left(\frac{m}{2\pi i \hbar(t' - t)} \right)^{3/2} \exp\left( i\frac{m|\mathbf{r}' - \mathbf{r}|^2}{2\hbar (t' - t)} \right)
$$

## Propagator

The matrix elements of the time evolution operator in the localized basis states $\set{\ket{\mathbf{x}}}_{\mathbf{x}\in\R^3}$ defines a function

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) := \braket{\mathbf{x}_b|\hat{U}(t_b,t_a)|\mathbf{x}_a}
$$

called the *propagator* of a quantum system. The propagator gives an alternate representation for the wavefunction of a quantum particle. In the position basis $\set{\ket{\mathbf{x}}}_{\mathbf{x}\in\R^3}$, the completeness relation gives

$$
  \int_{\R^3} \ket{\mathbf{x}}\bra{\mathbf{x}}\;\d^3 x = 1
$$

The time evolution of a state vector $\ket{\psi(t)}$ from $t=0$ to $t$ can be written as

$$
\begin{align*}
  \ket{\psi(t)} =& \hat{U}(t,0)\ket{\psi(0)} = \int_{\R^3} \hat{U}(t,0) \ket{\mathbf{y}}\braket{\mathbf{y}|\psi(0)}\; \d^3 y \\
  =& \int_{\R^3} \hat{U}(t,0)\ket{\mathbf{y}} \psi(\mathbf{y}, 0)\;\d^3 y
\end{align*}
$$

The wavefunction $\psi(\mathbf{x},t) = \braket{\mathbf{x}|\psi(t)}$ thus takes the form

$$
\begin{align*}
  \psi(\mathbf{x},t) =& \braket{\mathbf{x}|\psi(t)} = \int_{\R^3} \braket{\mathbf{x}|\hat{U}(t,0)|\mathbf{y}}\psi(\mathbf{y},0)\; d^3 y \\
  =& \int_{\R^3} (\mathbf{x},0|\mathbf{y},t)\psi(\mathbf{y}, 0)\; \d^3 y
\end{align*}
$$

We can recover the time evolution operator from the propagator by

$$
  \hat{U}(t) = \int (\mathbf{x},0|\mathbf{y},t) \ket{\mathbf{x}}\bra{\mathbf{y}}\; \d^3 x\;\d^3 y
$$

The propagator and the time evolution operator both completely describe the behaviour a the system. One can intuitively think of the propagator $K(\mathbf{x}_a, t_a \mathbf{x}_b; t_b)$, as the probability amplitude for a particle to travel from $\mathbf{x}_a$ to $\mathbf{x}_b$ in time $t_b - t_a$ with $t_b > t_a$. The propagator is therefore also referred to as *time evolution amplitude*.

From the operator equations $\eqref{equation-8}$, the propagator satisfies the Schr√∂dinger equation

$$
  i\hbar \frac{\partial}{\partial t_b} (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) = H(-i\hbar\nabla_{\mathbf{x}_b}, \mathbf{x}_b,t_b) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)
$$

When dealing with non-relativistic particles, it is customary to introduce a casual/retarded time evolution operator

$$
  \hat{U}_R (t_b,t_a) = \begin{cases}
    \hat{U}(t_b,t_a),\quad& t_b \geq t_a \\
    0,\quad& t_b < t_a
  \end{cases}
$$

and the associated casual/retarded time evolution amplitude

$$
  (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)_R := \braket{\mathbf{x}|\hat{U}_R (t_b,t_a)|\mathbf{y}}
$$

The retarded time evolution operator can be expressed in terms of the Heaviside step function

$$
  \Theta(t) := \begin{cases}
    1,\quad& t > 0 \\
    0,\quad& t \leq 0
  \end{cases}
$$

giving

$$
\begin{align*}
  \hat{U}_R (t_b,t_a) =& \Theta(t_b - t_a) \hat{U}(t_b, t_a) \\
  (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)_R =& \Theta(t_b - t_a) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b)
\end{align*}
$$

Note that the derivative of the Heaviside function is given by Dirac's delta function, i.e.  $\frac{\d}{\d t}\Theta(t) = \delta(t)$. In terms of the Heaviside function, the retarded propagator satisfies the Schr√∂dinger equations

$$
  \left[H_R(-i\hbar\nabla_{\mathbf{x}_b},\mathbf{x}_b,t_b) - i\hbar\frac{\partial}{\partial t_b}\right] (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) = -i\hbar \delta(t_b - t_a) \delta(\mathbf{x}_b - \mathbf{x}_a)
$$

The nonzero right-hand side arises from the extra term

$$
\begin{align*}
  -i\hbar \left(\frac{\partial}{\partial t_b}\Theta(t_b - t_a)\right) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) =& -i\hbar\delta(t_b - t_a) (\mathbf{x}_a,t_a|\mathbf{x}_b,t_b) \\
  =& -i\hbar (\mathbf{x}_a,t_a|\mathbf{x}_b,t_a)
\end{align*}
$$

and the initial condition $K(\mathbf{x}_a,t_a;\mathbf{x}_b,t_a) = \braket{\mathbf{x}_b|\mathbf{x}_a}$ since $\hat{U}(t_a, t_a) = 1$.

If the Hamiltonian does not depend on time, the propagator depends only on the time difference $t = t_b - t_a$. The retarded propagator vanishes for $t < 0$. This property leads to a class of functions $f(t)$ with a characteristic Fourier transform of the form

$$
  \tilde{f}(E) = \int_0^\infty f(t) e^{iEt/\hbar} \;\d t
$$

which is analytic in the upper half of the complex energy plane. This analyticity property is necessary and sufficient to produce a factor $\Theta(t)$ in the inverse Fourier transform

$$
  f(t) = \frac{1}{2\pi\hbar} \int_{-\infty}^\infty \tilde{f}(E) e^{-iEt/\hbar}\;\d E 
$$

For $t < 0$, the contour integration may be closed by an infinite semicircle in the upper half-plane at no extra cost. Since the contour encloses no singularities, it can be contracted to a point, yielding $f(t) = 0$.

### Fixed-energy amplitude

The *fixed-energy amplitude* of a quantum system is defined by the Fourier transform of the retarded time evolution amplitude

$$
\begin{equation*}
\begin{split}
  (\mathbf{x}_b,\mathbf{x}_a)_E =& \int_{-\infty}^\infty e^{iE(t_b - t_a)/\hbar} (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a)_R \;\d t_b \\
  =& \int_{t_a}^\infty e^{iE(t_b - t_a)/\hbar} (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) \;\d t_b
\end{split}
\tag{\label{equation-11}}
\end{equation*}
$$

If the Hamiltonian is time-independent, the propagator takes the form

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) = \braket{\mathbf{x}_b|e^{-i\hat{H}(t_b - t_a)/\hbar}|\mathbf{x}_a}
$$

In this case, the fixed-energy amplitudes are matrix element

$$
  (\mathbf{x}_b,\mathbf{x}_a)_E = \braket{\mathbf{x}_b |\hat{R}(E)|\mathbf{x}_a}
$$

of the *resolvent operator*

$$
  \hat{R}(E) = \frac{i\hbar}{E - \hat{H} + i\eta}
$$

which is the Fourier transform of the retarded time evolution operator

$$
\begin{align*}
  \hat{R}(E) =& \int_{-\infty}^\infty e^{iE(t_b - t_a)/\hbar} \hat{U}_R (t_b, t_a)\;\d t_b \\
  =& \int_{t_a}^\infty e^{iE(t_b - t_a)/\hbar} \hat{U}(t_b, t_a) \;\d t_0
\end{align*}
$$

If $\hat{H}$ has a discrete spectrum $\sigma(\hat{H}) = \Set{E_n}_{n\in\N}$ with corresponding eigenstates $\set{\ket{\psi_n}}_{n\in\N}$, the propagator has the following spectral representation

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) = \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) e^{-iE_n (t_b - t_a)/\hbar}
$$

where $\psi_n (\mathbf{x}) = \braket{\mathbf{x}|n}$ is the wavefunction associated with the eigenstate $\ket{\psi_n}$. Applying the Fourier transform $\eqref{equation-11}$, we obtain the fixed-energy amplitude

$$
\begin{equation*}
\begin{split}
  (\mathbf{x}_b|\mathbf{x}_a)_E =& \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) R_n (E) \\
  =& \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) R_n (E) \frac{i\hbar}{E - E_n + i\eta}
\end{split}
\tag{\label{equation-12}}
\end{equation*}
$$

The time evolution amplitude is recovered by the inverse Fourier transform

$$
  (\mathbf{x}_b,t_b|\mathbf{x}_a,t_a) = \frac{1}{2\pi\hbar}\int_{-\infty}^\infty e^{-iE(t_b - t_a)/\hbar} (\mathbf{x}_a|\mathbf{x}_b)_E \;\d E
$$

The small $i\eta$-shift in the energy $E$ in $\eqref{equation-12}$ can be thought of as being attached to each of the energies $E_n$, which are thus placed by an infinitesimal piece below the real energy axis. This makes the exponential behaviour of the wavefunctions slighty damped, vanishing at infinite time, i.e. $e^{-i(E_n - i\eta)t/\hbar} \xrightarrow{t\to\infty} 0$.

If the eigenstates are nondegenerate, the residues at the poles of $\eqref{equation-12}$ render directly the products of eigenfunctions (barring degeneracies, which must be discussed separately). For a system with a continuum of energy eigenvalues, there is a cut in the complex energy plane which may be thought of as a closely spaced sequence of poles. In general, the wavefunctions are recovered from the discontinuity of the amplitudes $(\mathbf{x}_b|\mathbf{x}_a)_E$ across the cut, using the formula

$$
\begin{align*}
  \operatorname{disc}\left(\frac{i\hbar}{E - E_n}\right) =& \frac{i\hbar}{E - E_n + i\eta} - \frac{i\hbar}{E - E_n - i\eta} \\
  =& 2\pi\hbar\delta(E - E_n)
\end{align*}
$$

This follows from Sochocki's formula, valid inside integrals over $E$

$$
  \frac{1}{E - E_n \pm i\eta} = \frac{\mathcal{P}}{E - E_n} \mp i\pi\delta(E - E_n)
$$

where $\mathcal{P}$ indicates that the principal value of the integral has to be taken.

The energy integral over the discontinuity of the fixed-energy amplitude $\eqref{equation-12}$ reproduces the completeness relation taken between the local states $\bar{\mathbf{x}_b}$ and $\ket{\mathbf{x}_a}$

$$
\begin{equation*}
\begin{split}
  \int_{-\infty}^\infty \frac{\d E}{2\pi\hbar} \operatorname{disc}(\mathbf{x}_b|\mathbf{x}_a)_E =& \sum_{n\in\sigma(\hat{H})} \psi_n (\mathbf{x}_b) \psi_n^* (\mathbf{x}_a) \\
  =& \braket{\mathbf{x}_b|\mathbf{x}_a} = \delta^(3) (\mathbf{x}_b - \mathbf{x}_a)
\end{split}
\tag{\label{equation-13}}
\end{equation*}
$$

The completeness relation reflects the following property of the resolvent operator

$$
  \int_{-\infty}^\infty \frac{\d E}{2\pi\hbar} \operatorname{disc}\left(\hat{R}(E)\right) = \hat{I}
$$

If the system also possesses a continuous spectrum, the completeness relation has the form

$$
  \sum_{n\in\sigma(\hat{H})} \ket{\psi_n}\bra{\psi_n} + \int \ket{\psi_\nu}\bra{\psi_\nu}\;\d\nu = 1
$$

The continuum causes a branch cut along in the complex energy plan, such that $\eqref{equation-13}$ also includes an integral over the discontinuity along the cut.

## Time-evolution pictures

### Heisenberg picture

The Heisenberg picture offers an alternate formulation of quantum mechanics that is more closely related to classical mechanics than the Schr√∂dinger picture. In the Heisenberg picture, the time dependence is entirely transferred from the state vector to the observable.

In the Schr√∂dinger picture the expectation value of an arbitrary observable $\hat{O}$ is given by

$$
  {}_\text{S}\braket{\psi(t)|\hat{O}^\text{S}|\psi(t)}_\text{S}
$$

Applying the time evolution operator $\hat{U}_t$, this expectation value can be written as

$$
\begin{equation*}
\begin{split}
  {}_\text{S}\braket{\psi(t)|\hat{O}^\text{S}|\psi(t)}_\text{S} =& {}_\text{S}\braket{\psi(0)|\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t|\psi(0)}_\text{S} \\
  =& {}_\text{H}\braket{\psi|\hat{O}^\text{H} (t)|\psi}_\text{H}
\end{split}
\tag{\label{equation-99}}
\end{equation*}
$$

where $\ket{\psi}_\text{H} = \ket{\psi(0)}_\text{S}$ is the state vector in the Heisenberg picture, and $\hat{O}^\text{H} (t) = \hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t$ is the time-dependent observable in the Heisenberg picture. Since the transformation from the Schr√∂dinger to the Heisenberg picture is unitary, the Hamiltonian is invariant, i.e.

$$
  \hat{H}^\text{H} = \hat{H}^\text{S} = \hat{H}
$$

To find the equation of motion for an observable, we take the time derivative of $\eqref{equation-99}$:

$$
\begin{align*}
  &\frac{\d}{\d t} \left({}_\text{S}\braket{\psi(t)|\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t|\psi(t)}_\text{S} \right) \\
  =& {}_\text{S}\Braket{\psi(0)|\left(\frac{i}{\hbar}\hat{H}\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t - \frac{i}{\hbar}\hat{U}_t^\dagger \hat{O}^\text{S} \hat{U}_t \hat{H} + \hat{U}_t^\dagger \frac{\partial\hat{O}^\text{S}}{\partial t} \hat{U}_t \right)|\psi(0)}_\text{S} \\
  =& {}_\text{H} \Braket{\psi|\left(\frac{i}{\hbar}[\hat{H},\hat{O}^\text{H}] + \frac{\partial}{\partial t} \hat{O}^\text{H} (t) \right)|\psi}_\text{H}
\end{align*}
$$

Since the expectation value of an observable is idependent of the time-evolution picture, this must equal the time derivative of the expectation value in the Heisenberg picture, i.e.

$$
  \frac{\d}{\d t} {}_\text{H}\braket{\psi|\hat{O}^\text{H} (t)|\psi}_\text{H}
$$

Thus, we obtain the Heisenberg equation of motion

$$
  i\hbar \frac{\d}{\d t} \hat{O}^\text{H} (t) = i\hbar \frac{\partial}{\partial t} \hat{O}^\text{H} (t) + [\hat{O}^\text{H}, \hat{H}]
$$

If the operator $\hat{O}$ does not explicitly depend on time in the Schr√∂dinger picture, this simplifies to

$$
\begin{equation*}
  i\hbar \frac{\d}{\d t} \hat{O}^\text{H} (t) = [\hat{O}^\text{H} (t), \hat{H}]
\tag{\label{equation-104}}
\end{equation*}
$$

which is the Heisenberg equation. This equation shows that an observable that does not explicitly on time and commutes with the Hamiltonian is a conserved quantity, or a constant of motion. 

In Hamiltonian mechanics, an observable function $O(\mathbf{p}(t), \mathbf{x}(t), t)$, satisfies the equation of motion

$$
\begin{align*}
  \frac{\d O}{\d t} =& \nabla_\mathbf{p} H \cdot\nabla_\mathbf{x} O - \nabla_\mathbf{p} O \cdot\nabla_\mathbf{x} H + \frac{\partial O}{\partial t} \\
  =& \{H, O\} + \frac{\partial O}{\partial t}
\end{align*}
$$

If $O$ is time-independent, this reduces to

$$
  \frac{\d O}{\d t} = \{H, O\}
$$

This shows that the Heisenberg equation can be retrived by the substitution

$$
  \{H,O\} \to \frac{1}{i\hbar}[\hat{H},\hat{O}]
$$

This can be seen as a formal rule for transitioning from classical to quantum mechanics. Specifically, in classical mechanics, if the Poisson bracket between a classical variable and the Hamiltonian is zero, this variable is conserved. Similarly, the Heisenberg evolution is formally analogous to classical time evolution. In fact, in classical mechanics, there is no direct analogue to the Schr√∂dinger evolution. More accurately, the classical time evolution coincides with the "Heisenberg evolution" in quantum mechanics, since in classical mechanics, the state is simply a set of properties, and thus it itself can be considered an observable.

In terms of expectation values, the Heisenberg equation of motion becomes

$$
\begin{equation*}
  i\hbar \frac{\d}{\d t} \Braket{\hat{O}^\text{H} (t)} = i\hbar \Braket{\frac{\partial}{\partial t} \hat{O}^\text{H} (t)} + \Braket{[\hat{O}^\text{H}, \hat{H}]}
\tag{\label{equation-105}}
\end{equation*}
$$

### Dirac's interaction picture

Dirac's interaction picture is an intermediate representation between the Heisenberg and Schr√∂dinger pictures, where both the state vectors and the operators carry part of the time dependence of observables. The interaction picture is formed by splitting the Hamiltonian operator in the Schr√∂dinger picture into two contributions

$$
  \hat{H} = \hat{H}_0 + \hat{V}
$$

where $\hat{H}_0$ is the unperturbed Hamiltonian, whose eigenvalues satisfy the time-independent Schr√∂dinger equation, and $\hat{V}$ is a (possibly time-dependent) interaction potential which perturbs these solutions.

To transition to the interaction picture, we remove the time evolution associated with the unperturbed Hamiltionian and the define the transformed state as

$$
\begin{equation*}
  \ket{\psi(t)}_\text{I} = \hat{U}_{H_0, t}^\dagger \ket{\psi(t)}_\text{S}
\tag{\label{equation-100}}
\end{equation*}
$$

where the unitary operator

$$
  \hat{U}_{H_0, t}^\dagger = e^{i\hat{H}_0 t/\hbar}
$$

accounts for the free evolution generated by $\hat{H}_0$. In order to establish the corresponding transformation for observables, we apply $\hat{U}_{H_0, t}^\dagger$ to the expectation value of an arbitrary observable $\hat{Q}$:

$$
\begin{align*}
  {}_\text{S} \braket{\psi(t)|\hat{Q}^\text{S}|\psi(t)}_\text{S} =& {}_\text{I} \braket{\psi(t)|\hat{U}_{H_0, t}^\dagger \hat{Q}^\text{S} \hat{U}_{H_0, t}|\psi(t)}_\text{I} \\
  =& {}_\text{I} \braket{\psi(t)|\hat{Q}^\text{I} (t)|\psi(t)}_\text{I}
\end{align*}
$$

This relation implies that the observable in the interaction picture is obtained from its counterpart in the Schr√∂dinger picture by the unitary transformation

$$
\begin{equation*}
  \hat{Q}^\text{I} (t) = \hat{U}_{H_0, t}^\dagger \hat{Q}^\text{S} \hat{U}_{H_0, t}
\tag{\label{equation-101}}
\end{equation*}
$$

It follows that the free part of the Hamiltonian is invariant under the transformation to the interaction picture, i.e.

$$
  \hat{H}_0^\text{I} = \hat{H}_0^\text{S} = \hat{H}_0
$$

whereas in the Heisenberg picture, the transformation generally modifies $\hat{H}_0^\text{I}$:

$$
  \hat{H}_0^\text{H} = \hat{U}_t^\dagger \hat{H}_0 \hat{U}_t
$$

Differentiating $\eqref{equation-100}$, we obtain the evolution equation for the state in the Dirac picture:

$$
  i\hbar \frac{\d}{\d t} \ket{\psi(t)}_\text{I} = \hat{V}^\text{I} (t) \ket{\psi(t)}_\text{I}
$$

where the interaction Hamiltonian in the interaction picture is given by

$$
  \hat{V}^\text{I} = e^{i\hat{H}_0 t/\hbar} \hat{H}_\text{I} e^{-i\hat{H}_0 t/\hbar}
$$

Similarly, differentiating $\eqref{equation-101}$, we obtain the equation of motion for the observable in the Dirac picture:

$$
  i\hbar \frac{\d}{\d t} \hat{Q}^\text{I} (t) = i\hbar \frac{\partial}{\partial t} \hat{Q}^\text{I} (t) + [\hat{Q}^\text{I} (t), \hat{H}_0]
$$

where the partial time derivative transforms as

$$
  \frac{\partial}{\partial t} \hat{Q}^\text{I} (t) = \hat{U}_{H_0, t}^\dagger \left( \frac{\partial}{\partial t} \hat{Q}^\text{S} \right) \hat{U}_{H_0, t}
$$

#### Perturbed equation of motion

In the interaction picture, state vectors evolve according to

$$
  \ket{\psi (t_b)}_\text{I} = \hat{U}_\text{I} (t_b, t_a) \ket{\psi (t_a)}_\text{I}
$$

where $\hat{U}_\text{I}$ is the time evolution operator given by

$$
\begin{equation*}
  \hat{U}_\text{I} (t_b, t_a) = e^{i\hat{H}_0 t_b /\hbar} e^{-i\hat{H}(t_b - t_a)/\hbar} e^{-i \hat{H}_0 t_a /\hbar}
\tag{\label{equation-10}}
\end{equation*}
$$

If $\hat{V} = 0$, the states $\ket{\psi (t_b)}_\text{I}$ are time-independent and coincide with the Heisenberg states of the operator $\hat{H}_0$. The operator $\hat{U}_\text{I} (t_b, t_a)$ satisfies the equation of motion

$$
  i\hbar\frac{\partial}{\partial t_b} \hat{U}_\text{I} (t_b, t_a) = \hat{V}_\text{I} (t_b) \hat{U}_\text{I} (t_b, t_a)
$$

where $\hat{V}_\text{I} = e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar}$ is the potential in the interaction picture. This differential equation can be turned into an integral equation

$$
\begin{align*}
  \hat{U}_\text{I} (t_b, t_a) =& 1 - \frac{i}{\hbar} \int_{t_a}^{t_b} \hat{V}_\text{I} \hat{U}_\text{I} (t, t_a)\;\d t \\
  =& 1 - \frac{i}{\hbar} \int_{t_a}^{t_b} e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar} \hat{U}_\text{I} (t, t_a)\;\d t
\end{align*}
$$

This equation can be iterated to find a perturbation expansion for the operator $\hat{U}_\text{I} (t_b, t_a)$ in powers of the interaction potential

$$
\begin{align*}
  \hat{U}_\text{I} (t_b, t_a) =& 1 - \frac{i}{\hbar} \int_{t_a}^{t_b} e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar} \\
  &+ \left(-\frac{i}{\hbar}\right)^2 \int_{t_a}^{t_b} \d t \int_{t_a}^t \d t' e^{i\hat{H}_0 t/\hbar}\hat{V}e^{-i\hat{H}_0 (t - t')/\hbar} \hat{V} e^{-i\hat{H}_0 t'/\hbar} + \cdots
\end{align*}
$$

Inserting $\eqref{equation-10}$ on the left-hand side and multiplying the equation from the left by $e^{-i\hat{H}_0 t_b/\hbar}$ and from the right by $e^{i\hat{H}_0 t_a/\hbar}$, this can be rewritten as

$$
\begin{align*}
  e^{-i\hat{H}_0 (t_b - t_a)/\hbar} =& e^{-i\hat{H}_0 (t_b - t_a)/\hbar} - \frac{i}{\hbar}\int_{t_a}^{t_b} \d t e^{-i\hat{H}_0 (t_b - t)/\hbar} \hat{V} e^{-i\hat{H}_0 (t-t_a)/\hbar} \\
  &+ \left(-\frac{i}{\hbar}\right)^2 \int_{t_a}^{t_b} \d t \int_{t_a}^t \d t' e^{i\hat{H}_0 (t_b - t)/\hbar}\hat{V}e^{-i\hat{H}_0 (t - t')/\hbar} \hat{V} e^{-i\hat{H}_0 (t' - t_a)/\hbar} + \cdots
\end{align*}
$$

This expansion is recognized as the recursive solution of the integral equation

$$
  e^{-i\hat{H}_0 (t_b - t_a)/\hbar} = e^{-i\hat{H}_0 (t_b - t_a)/\hbar} - \frac{i}{\hbar}\int_{t_a}^{t_b} e^{-i\hat{H}_0 (t_b - t)/\hbar} \hat{V} e^{-i\hat{H}_0 (t-t_a)/\hbar} \;\d t
$$

In terms of a time-ordering operator $\hat{T}$, the expansion can also be written as

$$
  e^{-i\hat{H}_0 (t_b - t_a)/\hbar} = e^{-i\hat{H}_0 t_b/\hbar} \hat{T} \exp\left(-\frac{i}{\hbar} \int_{t_a}^{t_b} e^{i\hat{H}_0 t/\hbar} \hat{V} e^{-i\hat{H}_0 t/\hbar}\;\d t\right)e^{i\hat{H}t_a/\hbar}
$$

which can be represented as a mathematical operator formula

$$
  e^{T(\hat{A} + \hat{B})} = \hat{T}\exp\left(\int_0^T e^{(T - t)\hat{A}} \hat{B} e^{t\hat{A}} \; \d t \right) = e^{T\hat{A}}\hat{T} \exp\left(\int_0^T e^{-t\hat{A}} \hat{B} e^{t\hat{A}} \;\d t \right)
$$

Due to the time-ordering operator, the right-hand side cannot be evaluated using Lie's expansion formula (Hadamard's lemma). Instead, the proper formulation requires the use Campbell-Baker-Hausdorff expansion.

## Time-derivatives of observables

The most natural way to define the time derivative $\hat{\dot{Q}}$ of a quantum mechanical observable $\hat{Q}$ in the Schr√∂dinger picture is to assume that its expectation value $\braket{\hat{\dot{Q}}}$ is equal to the time derivative of the expectation value of $\hat{Q}$, i.e.

$$
  {}_\text{S} \braket{\psi|\hat{\dot{Q}}^\text{S}|\psi}_\text{S} = \frac{\d}{\d t} \left({}_\text{S} \braket{\psi|\hat{Q}^\text{S}|\psi}_\text{S} \right)
$$

Appying the Schr√∂dinger equation and its Hermitian adjoint to the right-hand side, we obtain

$$
\begin{align*}
  \frac{\d}{\d t} \left({}_\text{S} \braket{\psi|\hat{Q}^\text{S}|\psi}_\text{S} \right) =& {}_\text{S} \Braket{\psi|\left(\frac{i}{\hbar} \hat{H}\hat{Q}^\text{S} - \frac{i}{\hbar} \hat{Q}^\text{S} \hat{H} + \frac{\partial}{\partial t} \hat{Q}^\text{S} \right)|\psi} \\
  =& {}_\text{S} \Braket{\psi|\left(\frac{i}{\hbar}[\hat{H}, \hat{Q}] + \frac{\partial}{\partial t} \hat{Q}^\text{S} \right)|\psi}
\end{align*}
$$

Hence,

$$
\begin{equation*}
  \braket{\hat{\dot{Q}}} = \frac{i}{\hbar} \braket{[\hat{H},\hat{Q}]} + \Braket{\frac{\partial}{\partial t} \hat{Q}}
\tag{\label{equation-81}}
\end{equation*}
$$

which is known as Ehrenfest's theorem.

## Density operator

In the most general sense, quantum systems can exist in mixed states, which include pure states as a special case. A quantum system is described by a mixed state when it is in one of a set of possible states $\set{\ket{\psi_j}}$, each occuring with probability $p_j$. Unlike a pure state, which represents a coherent quantum superposition, a mixed state represents a statistical ensemble of quantum states. This contrasts with a pure state $\ket{\psi} = \sum_j \sqrt{p_j} \ket{\psi_j}$, where the quantum system exists in a coherent superposition of the $\ket{\psi_j}$. In this case, the system is described entirely by $\ket{\psi}$, rather than by a statistical mixture of the $\ket{\psi_j}$.

A mixed state is represented by a density operator (or density matrix) $\hat{\rho}$ on a Hilbert space $\mathcal{H}$, which satisfies the properties
1. **Hermiticity:** $\hat{\rho}^\dagger = \hat{\rho}$
2. **Positive semidefiniteness:** $\braket{\psi|\hat{\rho}|\psi} \geq 0$ for all $\ket{\psi}\in\mathcal{H}$
3. **Unit trace:** $\operatorname{tr}(\hat{\rho}) = 1$

The set of all density operators on $\mathcal{H}$ is denoted $\mathcal{D}(\mathcal{H})$, that is

$$
  \mathcal{D}(\mathcal{H}) := \set{\hat{\rho}\in\mathcal{L}(\mathcal{H}) | \hat{\rho}^\dagger = \hat{\rho}, \hat{\rho}\geq 0, \operatorname{tr}(\hat{\rho}) = 1}
$$

and is a convex set.

<details>
<summary>Details</summary>


Convexity of $\mathcal{D}(\mathcal{H})$ means that for every $\hat{\rho}_1, \hat{\rho}_2 \in\mathcal{D}(\mathcal{H})$ and $u\in[0,1]\subset\R$, we have

$$
  u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \in \mathcal{D}(\mathcal{H})
$$

Since $\hat{\rho}_1$ and $\hat{\rho}_2$ are Hermitian it follows that

$$
  \left(u\hat{\rho}_1 + (1 - u)\hat{\rho}\right)^\dagger = u\hat{\rho}_1^\dagger + (1 - u)\hat{\rho}_2^\dagger = u\hat{\rho}_1 + (1 - u)\hat{\rho}_2
$$

Since $\hat{\rho}_1$ and $\hat{\rho}_2$ are positive semi-definite, it follows that for every $\ket{\psi}\in\mathcal{H}$

$$
  \braket{\psi|u\hat{\rho}_1 + (1 - u)\hat{\rho}_2|\psi} = u\underbrace{\braket{\psi|\hat{\rho}_1|\psi}}_{\geq 0} + (1 - u)\underbrace{\braket{\psi|\hat{\rho}_2|\psi}} \geq 0 
$$

Since $\hat{\rho}_1$ and $\hat{\rho}_2$ have unit trace, it follows that

$$
  \operatorname{tr}\left(u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \right) = u\underbrace{\operatorname{tr}(\hat{\rho}_1)}_{=1} + (1- u) \underbrace{\boldsymbol{tr}(\hat{\rho}_2)}_{=1} = 1
$$

This verifies that $u\hat{\rho}_1 + (1 - u)\hat{\rho}_2 \in \mathcal{D}(\mathcal{H})$.
</details>

If $\hat{U}\in\mathcal{U}(\mathcal{H})$ is a unitary operator, then $\hat{U}\hat{\rho}\hat{U}\in\mathcal{D}(\mathcal{H})$ is a density operator.

<details>
<summary>Proof</summary>

Since $\hat{\rho}^\dagger = \hat{\rho}$, we have

$$
  (\hat{U}\hat{\rho}\hat{U}^\dagger)^\dagger = (\hat{U}^\dagger)^\dagger \hat{\rho}^\dagger \hat{U}^\dagger = \hat{U}\hat{\rho}\hat{U}
$$

Since $\braket{\psi|\hat{\rho}|\psi} \geq 0$, we have

$$
  \braket{\psi|\hat{U}\hat{\rho}\hat{U}^\dagger|\psi} = \braket{\hat{U}^\dagger \psi|\hat{\rho}\hat{U}^\dagger \psi} \geq 0
$$

Since $\operatorname{tr}(\hat{\rho}) = 1$ and using the commutativity of trace, we have

$$
  \operatorname{tr}(\hat{U}\hat{\rho}\hat{U}^\dagger) = \operatorname{tr}(\hat{U}^\dagger \hat{U} \rho) = \operatorname{tr}(\hat{\rho}) = 1
$$

Hence, $\hat{U}\hat{\rho}\hat{U}^\dagger \in\mathcal{D}(\mathcal{H})$.
</details>

Let $\set{\ket{\psi_j}}$ be an orthonormal basis of a Hilbert space $\mathcal{H}$. Since a density operator $\rho$ is Hermitian, it admits a diagonal spectral decomposition

$$
  \hat{\rho} = \sum_j p_j \ket{\psi_j} \bra{\psi_j} = \sum_j p_j \hat{P}_{\psi_j}
$$

where $p_j$ are the eigenvalues of $\hat{\rho}$ and $\hat{P}_{\psi_j}$ are the associated rank-one projectors. The density operator satisfies:
1. **Probability conditions:** $p_j \geq 0$ and $\sum_j p_j = 1$
2. **Positivity constraint:** $0 \leq \hat{\rho}^2 \leq \hat{\rho}$
3. **Operator norm bound:** $\norm{\rho}\leq 1$

<details>
<summary>Proof</summary>

**(1):** Since $\hat{\rho}$ is Hermitian, its eigenvalues $p_j$ are real. By the positivity of $\hat{\rho}$, we have for any $\ket{\psi}\in\mathcal{H}$

$$
  0 \leq \braket{\psi|\hat{\rho}|\psi} = \sum_j p_j \braket{\psi|\psi_j} \braket{\psi_j|\psi} = \sum_j p_j |\braket{\psi_j|\psi}|^2
$$

Since $\operatorname{tr}(\rho) = 1$, we have

$$
\begin{align*}
  1 =& \operatorname{tr}(\hat{\rho}) = \sum_k \braket{\psi_k|\hat{\rho}|\psi_k} \\
  =& \sum_{k,j} p_j \underbrace{\braket{\psi_k|\psi_j}}_{=\delta_{kj}} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \\
  =& \sum_k p_k
\end{align*}
$$

**(2):** The positivity of $\hat{\rho}^2$ follows from the fact that for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \braket{\psi|\hat{\rho}^2|\psi} =& \braket{\hat{\rho}^\dagger \psi|\hat{\rho} \psi} \\
  =& \braket{\hat{\rho}\psi|\hat{\rho}\psi} = \norm{\hat{\rho}\ket{\psi}}^2 \geq 0
\end{align*}
$$

Since $0 \leq p_j \leq 1$, it follows that $p_j^2 \leq p_j$ and

$$
\begin{align*}
  \hat{\rho}^2 =& \left(\sum_j p_j \ket{\psi_j} \bra{\psi_j} \right)^2 \\
  =& \sum_{j,k} p_j p_k \ket{\psi_j} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \bra{\psi_k} \\
  =& \sum_j p_j^2 \ket{\psi_j} \bra{\psi_j}
\end{align*}
$$

and thus for any $\ket{\psi}\in\mathcal{H}$

$$
\begin{align*}
  \braket{\psi|\hat{\rho} - \hat{\rho}^2|\psi} =& \bra{\psi} \sum_j (p_j - p_j^2) \ket{\psi_j}\braket{\psi_j|\psi} \\
  =& \sum_j (p_j - p_j^2) \braket{\psi|\psi_j}\braket{\psi_j|\psi} \\
  =& \sum_j \underbrace{(p_j - p_j^2)}_{\geq 0} \underbrace{|\braket{\psi_j|\psi}|^2}_{\geq 0} \geq 0
\end{align*}
$$

Hence, $0 \leq \hat{\rho^2} \leq \rho$.

**(3):** From **(2)** it follows that

$$
\begin{align*}
  \norm{\hat{\rho}}^2 =& \braket{\hat{\rho}|\hat{\rho}} = \braket{\hat{\rho}^\dagger \psi|\hat{\rho}\psi} \\
  =& \braket{\psi|\hat{\rho}^2|\psi} = \braket{\psi|\hat{\rho}|\psi} \\
  \leq& \norm{\psi}\cdot\norm{\hat{\rho} \psi}
\end{align*}
$$

which implies

$$
  \frac{\norm{\hat{\rho}\ket{\psi}}}{\norm{\psi}} \leq 1 \implies \norm{\hat{\rho}} \leq 1
$$
</details>

If $\set{\ket{\psi_j}}_j$ is an orthonormal basis on $\mathcal{H}$, the density matrix is defined as

$$
\begin{align*}
  \hat{\rho} =& \sum_j \sum_k \ket{\psi_j}\braket{\psi_j|\hat{\rho}|\psi_k}\bra{\psi_k} \\
  =& \sum_{j,k} \boldsymbol{\rho}_{jk} \ket{\psi_j}\bra{\psi_k}
\end{align*}
$$

where $\boldsymbol{\rho}_{jk} = \braket{\psi_j|\hat{\rho}|\psi_k}$ are the matrix elements of $\hat{\rho}$. This definition utilizes the fact that

$$
  \sum_j \ket{\psi_j}\bra{\psi_k} = \hat{I} \left(\sum_k \ket{\psi_k}\bra{\psi_k} \right)
$$

In a mixture described by $\hat{\rho} = \sum_j p_j \ket{\psi_j} \bra{\psi_j}$ the relative phases of the $\ket{\psi_j}$ are not physically observable. This is because for $\phi_j \in\R$, we have

$$
\begin{align*}
  \sum_j p_j \ket{e^{i\phi_j} \psi_j} \bra{e^{i\phi_j} \psi_j} =& \sum_j p_j e^{-i\phi_j} e^{i\phi_j} \ket{\psi_j} \bra{\psi_j} \\
  =& \sum_j p_j \ket{\psi_j} \bra{\psi_j} = \hat{\rho}
\end{align*}
$$

showing that the states $e^{i\phi_j} \ket{\psi_j}$ generate the same mixture as the $\ket{\phi_j}$.

<MathBox title='' boxType='proposition'>
Let $\mathcal{H}$ be a finite-dimensional Hilbert space and $\hat{\rho}\in\mathcal{D}(\mathcal{H})$ be a density operator with diagonal form

$$
  \hat{\rho} = \sum_{i=1}^n p_j \ket{\psi_j} \bra{\psi_j}
$$

where $p_j \in (0,1]$ for $j\in\set{1,\dots,n}$ with $n \leq \dim(\mathcal{H})$ are the nonzero eigenvalues of $\hat{\rho}$ and $\set{\ket{\psi_j}}_{j=1}^{\dim(\mathcal{H})}$ is an orthonormal eigenbasis. For $m\leq\dim(\mathcal{H})$, suppose we have normalized states $\set{\ket{\varphi_i}}_{i=1}^m \subset\mathcal{H}$ and probabilities $q_i \in (0,1]$ such that $\sum_{j=1}^m q_i = 1$. Then,

$$
  \hat{\rho} = \sum_{j=1}^m q_i \ket{\varphi_i} \bra{\varphi_i}
$$

if and only if $m \geq n$ and there is a unitary matrix $\mathbf{U} \in\mathrm{U}(m)$ such that

$$
  \sqrt{q_i} \ket{\varphi_i} = \sum_{j=1}^n \mathbf{U}_{ij} \sqrt{p_j} \ket{\psi_j}, \; i \in\set{1,\dots,m}
$$

<details>
<summary>Proof</summary>

**($\implies$):**

Since $\set{\ket{\psi_j}}_{j=1}^n$ is an orthonormal eigenbasis, the range of $\hat{\rho}$ has dimension

$$
  \dim[\operatorname{ran}(\hat{\rho})] = \dim\left(\operatorname{span}\set{ket{\psi_j}}_{j=1}^n \right) = n
$$

On the other hand, $\hat{\rho}[\mathcal{H}] \subseteq \operatorname{span}\set{\ket{\psi_i}}_{i=1}^m$ such that

$$
  \dim[\operatorname{ran}(\hat{\rho})] \leq \dim\left(\operatorname{span}\set{ket{\varphi_i}}_{i=1}^n \right) \leq m
$$

and it follows that $n \leq m$. By assumption, the eigenvectors of $\hat{\rho}$ for the eigenvalue $0$ are given by $\ket{\psi_k}$, where $k \in \set{n+1,\dots,\dim(\mathcal{H})}$. They satisfy

$$
  0 = \braket{\psi_k | \psi_k} = \sum_{i=1}^m q_i |\braket{\psi_k|\varphi_i}|^2
$$

which implies $\braket{\psi_k|\varphi_i} = 0$ for all $k\in\set{n+1,\dots,\dim(\mathcal{H})}$ and $i\in\set{1,\dots,m}$. We can thus expand $\ket{\varphi_i}$ as

$$
  \ket{\varphi_i} = \sum_{k=1}^{\dim(\mathcal{H})} \braket{\psi_k|\varphi_i} \ket{\psi_k} = \sum_{k=1}^n \braket{\psi_k | \varphi_i} \ket{\psi_k}
$$

Since $\hat{\rho}$ is unchanged under either decomposition, we must have

$$
  \sum_{j=1}^n p_j \ket{\varphi_j} \bra{\varphi_j} = \sum_{i=1}^m q_i \ket{\varphi_i} \bra{\varphi_i}
$$

Next, we define the $m\times n$ matrix $\mathbf{V}\in\mathcal{M}_{m,n} (\mathbf{C})$ by

$$
  \mathbf{V}_{ij} = \sqrt{\frac{q_i}{p_j}} \braket{\psi_j|\varphi_i}
$$

for $i\in\set{1,\dots,m}$ and $j\in\set{1,\dots,n}$ such that

$$
  \sum_{j=1}^n \mathbf{V}_{ij} \sqrt{p_j} \ket{\psi_j} = \sum_{j=1}^n \sqrt{q_i} \braket{\psi_j|\varphi_i} \ket{\psi_j} = \sqrt{q_i} \ket{\varphi_i}
$$

We proceed to show that we can extend $\mathbf{V}\in\mathcal{M}_{m,n} (\mathbb{C})$ to a unitary $m\times m$ matrix $\mathbf{U}$. For this, we first note that

$$
  \mathbf{V}_{ji}^\dagger = \mathbf{V}_{ij}^* = \sqrt{\frac{q_i}{p_j}} \braket{\psi_j|\varphi_i}^* = \sqrt{\frac{q_i}{p_j}} \braket{\varphi_i|\psi_j}
$$

and thus for $i,j\in\set{1,\dots,n}$

$$
\begin{align*}
  \sum_{i=1}^m \mathbf{V}_{ji}^\dagger \mathbf{V}_{ik} =& \frac{1}{\sqrt{p_j p_k}} \sum_{i=1}^m q_i \braket{\psi_j|\varphi_i} \braket{\varphi_i|\psi_k} \\
  =& \frac{1}{\sqrt{p_j p_k}} \braket{\psi_j |\hat{\rho}|\psi_k} \\
  =& \frac{1}{\sqrt{p_j p_k}} \bra{\psi_j} \sum_{l=1}^n p_l \ket{\psi_l} \braket{\psi_l|\psi_k} \\
  =& \sum_{l=1}^n \frac{p_l \delta_{jl} \delta_{lk}}{\sqrt{p_j p_k}} = \delta_{jk}
\end{align*}
$$

We have specified $\mathbf{V} \in\mathcal{M}_{m,n} (\mathbb{C})$, where $n\leq m$, such that $\mathbf{V}^\dagger \mathbf{V} = \mathbf{I}_n$. This means that the $n$ column vectors of $\mathbf{V}$ viewed as vectors in $\mathbb{C}^m$ are mutually orthogonal and normalized to $1$. Applying the Gram-Schmidt orthogonalization procedure, we can add $m - n$ orthonormal columns vectors such that all $m$ column vectors of the resulting $m\times m$ matrix $\mathbf{U}$ form a basis in $\mathbb{C}^m$. By this procedure, we extend $\mathbf{V}$ to form a unitary matrix $\mathbf{U} \in\mathrm{U}(m)$ such that $\mathbf{U}_{ij} = \mathbf{V}_{ij}$ for $j\in\set{1,\dots,n}$.

**($\impliedby$):**

Let $m \geq n$ and $\mathbf{U} \in\mathrm{U}(m)$ be a unitary matrix such that for $j\in\set{1,\dots,m}$

$$
  \sqrt{q_i} \ket{\varphi_i} = \sum_{j=1}^n \mathbf{U}_{ij} \sqrt{p_j} \ket{\psi_j}
$$

This implies

$$
\begin{align*}
  \sum_{i=1}^m q_i \ket{\varphi_i} \bra{\varphi_i} =& \sum_{j=1}^m q_i \left(\frac{1}{\sqrt{q_i}} \sum_{j=1}^n \mathbf{U}_{ij} \sqrt{p_j} \ket{\psi_j} \right) \left(\frac{1}{\sqrt{q_i}} \sum_{k=1}^n \mathbf{U}_{ik}^* \sqrt{p_k} \ket{\psi_k} \right) \\
  =& \sum_{j,k=1}^n \sqrt{p_j p_k} \left(\sum_{i=1}^m \mathbf{U}_{ki}^\dagger \mathbf{U}_{ij} \right) \ket{\psi_j} \bra{\psi_k} \\
  =& \sum_{j,k=1}^n \sqrt{p_j p_k} \underbrace{(\mathbf{U}^\dagger \mathbf{U})_{ij}}_{=\delta_{ij}} \ket{\psi_j} \bra{\psi_k} \\
  =& \sum_{j=1}^n p_j \ket{\psi_j} \bra{\psi_j} = \hat{\rho}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Qubit' boxType='example'>
A two-state quantum system is known as a qubit. It is represented by a two-dimensional Hilbert space. An arbitrary mixed state for a qubit can be written as a linear combination

$$
  \rho = \frac{1}{2} \begin{bmatrix} 
    1 + r_z & r_x - i r_y \\
    r_x + i r_y & 1 - r_z 
  \end{bmatrix} = \frac{1}{2} (1 + \mathbf{r}\cdot\boldsymbol{\sigma})
$$

where $\mathbf{r} = (r_x, r_y, r_z)$ is a Bloch vector and $\boldsymbol{\sigma}$ are the Pauli matrices. The density matrix $\rho$ represents a pure state if and only if $\rVert\mathbf{r}\rVert = 1$. For a mixed state we have $\norm{\mathbf{r}} < 1$.

<details>
<summary>Proof</summary>

Since $\rho\in\mathcal{M}_2 (\mathbb{C})$ is a complex $2\times 2$ matrix, it can be written as a linear combination

$$
\begin{align*}
  \rho =& c_0 I_2 + c_x \sigma_x + c_y \sigma_y + c_z \sigma_z = c_0 I_2 + \mathbf{c}\cdot\boldsymbol{\sigma} \\
  =& \begin{bmatrix}
    c_0 + c_z & c_x - i c_y \\
    c_x + i c_y & c_0 - c_z
  \end{bmatrix}
\end{align*}
$$

By Hermiticity, the diagonal elements of $\rho$ are real, while the off-diagonal elements are complex conjugates. Since $\operatorname{tr}(\rho) = 1$, it follows that

$$
  1 = (c_0 + c_z) + (c_0 + c_z) = 2c_0 \iff c_0 = \frac{1}{2}
$$

Since $\rho$ is semi-definite, its determinant is positive 

$$
  \det(\rho) = c_0^2 - c_z^2 - |c_x + ic_y|^2 = c_0^2 - c_x^2 - c_y^2 - c_z^2 \geq 0
$$

This implies that

$$
  \norm{ \mathbf{c} } \leq |c_0| = \frac{1}{2}
$$

Writing $\mathbf{r} = \frac{1}{2}\mathbf{c}$, we get that

$$
  \rho = \frac{1}{2} (I_2 + \mathbf{r}\cdot\boldsymbol{\sigma})
$$

with $\norm{ \mathbf{r} } \leq 1$.

If $\rho$ describes a pure state, then $\rho^2 = \rho$. Calculating $\rho^2$ yields

$$
\begin{align*}
  \rho^2 =& \frac{1}{4}[I_2 + 2\mathbf{r}\cdot\boldsymbol{\sigma} + (\mathbf{r}\cdot\boldsymbol{\sigma})^2] \\
  =& \frac{1}{4}(I_2 + 2\mathbf{r}\cdot\boldsymbol{\sigma} + \mathbf{r}^2 I_2) \\
  =& \frac{1}{4}[(1 + \mathbf{r}^2) I_2 + 2\mathbf{r}\cdot\boldsymbol{\sigma}] \\
\end{align*}
$$

where we have used the fact that $\sigma_i \sigma_j = \delta_{ij} I_2 + i\epsilon_{ijk} \sigma_k$. We see that $\rho^2 = \rho$ if and only if $\mathbf{r}^2 = \norm{\mathbf{r}}^2 = 1$.
</details>
</MathBox>

### Density operator for pure states

A pure state $\ket{\psi}\in\mathcal{H}$ can be represented by the rank-one projector $\hat{P}_\psi = \ket{\psi}\bra{\psi}$. Since $\operatorname{tr}(\hat{P}_\psi) = 1$ and $\hat{P}_\psi^2 = \hat{P}_\psi$, pure states can be viewed as a special case of mixed states with density operator

$$
  \hat{\rho}_\psi := \hat{P}_\psi = \ket{\psi}\bra{\psi}
$$

Thus, the density operator formalism generalizes the description of quantum states, encompassing both pure states and statistical mixtures.

<details>
<summary>Details</summary>

To show that the density operator for a pure state $\ket{\psi}\in\mathcal{H}$ given by $\rho_\psi = \ket{\psi}\bra{\psi}$ satisfies the quantum postulates for mixed states, we verify the following properties.

**Expectation value**

Consider an observable $A$ with spectral decomposition

$$
  \hat{A} = \sum_j \lambda_j \ket{e_j} \bra{e_j} 
$$

where $\set{\lambda}_j$ are the eigenvalues of $\hat{A}$ and $\set{\ket{e_j}}$ is an orthonormal basis of $\mathcal{H}$. The expectation value of $\hat{A}$ in the state $\hat{\rho}_\psi$ is

$$
\begin{align*}
  \braket{A}_{\rho_\psi} =& \operatorname{tr}(\rho_\psi \hat{A}) = \operatorname{tr}(\ket{\psi}\braket{\psi|\hat{A}}) \\
  =& \operatorname{tr}\left(\ket{\psi}\bra{\psi} \sum_j \lambda_j \ket{e_j} \bra{e_j} \right) \\
  =& \sum_j \lambda_j \operatorname{tr}(\ket{\psi}\braket{\psi|e_j}\bra{e_j}) \\
  =& \sum_{j,k} \lambda_j \braket{e_j|\psi}\braket{\psi|e_j}\underbrace{\braket{e_j|e_k}}_{=\delta_{jk}} \\
  =& \sum_j \lambda_j \braket{\psi|e_j} \braket{e_j|\psi} \\
  =& \braket{\psi} \sum_j \lambda_j \ket{e_j} \braket{e_j|\psi} \\
  =& \braket{\psi|\hat{A}|\psi} = \braket{\hat{A}}_\psi
\end{align*}
$$

**Measurement probability**

The probability of measuring an eigenvalue $\lambda$ associated with the projector $\hat{P}_\lambda$ is given by

$$
\begin{align*}
  \Pr_{\rho_\psi} (\lambda) =& \operatorname{tr}(\hat{\rho}\hat{P}_\lambda) = \operatorname{tr}(\ket{\psi}\bra{\psi}\hat{P}_\lambda) \\
  =& \operatorname{tr}(\ket{\psi}\bra{\psi}\hat{P}_\lambda^2) = \operatorname{tr}(\hat{P}_\lambda \ket{\psi}\braket{\psi|\hat{P}_\lambda}) \\
  =& \sum_j \braket{e_j|\hat{P}_\lambda|\psi} \braket{\psi|\hat{P}_\lambda|e_k} \\
  =& \sum_j \braket{e_j|\hat{P}_\lambda|\psi} \braket{\hat{P}_\lambda \psi|e_j} \\
  =& \braket{\hat{P}_\lambda \psi} \underbrace{\sum_j \ket{e_j} \braket{e_j|\hat{P}_\lambda|\psi}}_{=\hat{P}_\lambda \ket{\psi}} \\
  =& \braket{\hat{P}_\lambda \psi| \hat{P}_\lambda \psi} = \norm{\hat{P}_\lambda \ket{\psi}}^2 = \Pr_\psi (\lambda) 
\end{align*}
$$

**Projection**

If a measurement of an observable $A$ yields the eigenvalue $\lambda$, the post-measurement state is given by the normalized projection of $\rho_\psi$:

$$
\begin{align*}
  \frac{\hat{P}_\lambda \hat{\rho}_\psi \hat{P}_\lambda}{\operatorname{tr}(\hat{\rho}_\psi \hat{P}_\lambda)} =& \frac{\hat{P}_\lambda \ket{\psi}\bra{\psi} \hat{P}_\lambda}{\norm{\hat{P}_\lambda \ket{\psi}}^2} = \frac{\hat{P}_\lambda \ket{\psi}\bra{\psi} \hat{P}_\lambda^\dagger}{\norm{\hat{P}_\lambda \ket{\psi}}^2} \\
  =& \frac{\hat{P}_\lambda \ket{\psi} \bra{\hat{P}_\lambda \psi}}{\norm{\hat{P}_\lambda \ket{\psi}}^2} = \frac{\hat{P}_\lambda \ket{\psi}}{\norm{\hat{P}_\lambda \ket{\psi}}} \frac{\bra{\hat{P}_\lambda \psi}}{\norm{\hat{P}_\lambda \ket{\psi}}} \\
  =& \hat{\rho}_{\hat{P}_\lambda \ket{\psi} / \norm{\hat{P}_\lambda \ket{\psi}}}
\end{align*}
$$

Thus, $\frac{\hat{P}_\lambda \hat{\rho}_\psi \hat{P}_\lambda}{\operatorname{tr}(\hat{\rho}_\psi \hat{P}_\lambda)}$ os the density operator of the pure state $\hat{\rho}_{\hat{P}_\lambda \ket{\psi} / \norm{\hat{P}_\lambda \ket{\psi}}}$.

**Time evolution**

Let $\hat{\rho} (t_0) = \rho_{\psi(t_0)} = \ket{\psi(t_0)}\bra{\psi(t_0)}$ be the initial state and $\hat{\rho}(t)$ be the state at time $t$. Then

$$
\begin{align*}
  \hat{\rho}(t) =& \hat{U}(t, t_0) \hat{\rho} (t_0) \hat{U}^\dagger (t, t_0) \\
  =& \hat{U}(t, t_0) \ket{\psi(t_0)} \bra{\psi(t_0)} \hat{U}^\dagger (t, t_0) \\
  =& \ket{\hat{U}(t, t_0) \psi(t_0)} \bra{\hat{U}(t, t_0) \psi(t_0)} \\
  =& \hat{\rho}_{\hat{U}(t, t_0)\ket{\psi(t_0)}} \\
  =& \rho_\psi (t)
\end{align*}
$$
</details>

A density operator $\hat{\rho}$ describes a pure state if and only it is a projector, i.e. $\hat{\rho}^2 = \hat{\rho} = \ket{\psi}\bra{\psi}$ for some normalized $\ket{\psi}\in\mathcal{H}$ with $\norm{\psi} = 1$.

<details>
<summary>Proof</summary>

**($\implies$): If $\hat{\rho}$ describes a pure state, then $\hat{\rho}^2 = \hat{\rho}$**

By definition, a pure state is represented by a rank-one density operator $\hat{\rho} = \ket{\psi}\bra{\psi}$ for $\ket{\psi}\in\mathcal{H}$. If $\set{\ket{e_j}}$ is an orthonormal basis of $\mathcal{H}$, then since $\operatorname{tr}(\hat{\rho}) = 1$, we have

$$
\begin{align*}
  1 =& \operatorname{tr}(\hat{\rho}) = \operatorname{tr}(\ket{\psi}\bra{\psi}) \\
  =& \sum_j |\braket{e_j|\psi}|^2 = \norm{\psi}^2
\end{align*}
$$

verifying that $\ket{\psi}$ is normalized. It follows that

$$
  \hat{\rho}^2 = \ket{\psi}\underbrace{\braket{\psi|\psi}}_{=\norm{\psi}^2}\bra{\psi} = \ket{\psi}\bra{\psi} = \hat{\rho}
$$

**($\impliedby$): If $\hat{\rho}$ satisfies $\hat{\rho}^2 = \hat{\rho}$, it is a pure state**

Since $\hat{\rho}$ is a density operator, it admits a spectral decomposition in an orthonormal basis $\set{\ket{\psi_j}}$

$$
  \hat{\rho} = \sum_j p_j \ket{\psi_j} \bra{\psi_j}
$$

where $p_j \geq 0$ are real eigenvalues summing to $1$. Calculating $\hat{\rho}^2$, we obtain

$$
\begin{align*}
  \hat{\rho}^2 =& \left(\sum_j p_j \ket{\psi_j} \bra{\psi_j} \right) \left(\sum_k p_k \ket{\psi_k} \bra{\psi_k} \right) \\
  =& \sum_{j,k} p_j p_k \ket{\psi_j} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \bra{\psi_k} \\
  =& \sum_j p_j^2 \ket{\psi_j} \bra{\psi_j} 
\end{align*}
$$

Using idempotency, $\hat{\rho}^2 = \hat{\rho}$, we find that $p_j^2 = p_j$. Taking the expectation of $\hat{\rho}^2 - \hat{\rho}$ in $\ket{\psi_k} \in\mathcal{H}$, we get

$$
\begin{align*}
  0 =& \braket{\psi_k|\hat{\rho}^2 - \hat{\rho}|\psi_k} \\
  =& \bra{\psi_k} \sum_j (p_j^2 - p_j) \ket{\psi_j} \underbrace{\braket{\psi_j|\psi_k}}_{=\delta_{jk}} \\
  =& p_k^2 - p_k = p_k (p_k - 1)
\end{align*}
$$

Consequently, $p_j = 1$ or $p_j = 0$ for each $j$. Since $\sum_j p_j = 1$, exactly one $p_j$ is equal to $1$, while all others are $0$. If $\check{\jmath}$ is the index where $p_j = 1$, then

$$
  \hat{\rho} = \ket{\psi_{\check{\jmath}}}\bra{\psi_{\check{\jmath}}}
$$

describes a pure state.
</details>

A density operator $\hat{\rho}$ describe a true mixture if and only if $\hat{\rho}^2 < \hat{\rho}$. This means that mixed states satisfy $\hat{\rho}^2 \neq \hat{\rho}$.

<details>
<summary>Proof</summary>

We prove the statement by contraposition, showing that $\hat{\rho}^2 = \hat{\rho}$ if and only if there exists $\ket{\psi}\in\mathcal{H}$ such that for every Hermitian operator $\hat{A}\in\mathcal{B}(\mathcal{H})$, we have $\braket{A}_\psi = \braket{A}_\rho$. 

**($\implies$): If $\hat{\rho}^2 = \hat{\rho}$, then $\hat{\rho}$ represents a pure state**

Consider an orthonormal basis $\set{\ket{e_j}}$ in $\mathcal{H}$ and let $\ket{\psi}\in\mathcal{H}$ be such that $\hat{\rho} = \ket{\psi}\bra{\psi}$. Expanding $\ket{\psi}$ as

$$
  \ket{\psi} = \sum_j \ket{e_j} \braket{e_j|\psi}
$$

the expectation value of an Hermitian operator $\mathcal{A}\in\mathcal{B}(\mathcal{H})$ is

$$
\begin{align*}
  \braket{A}_\rho =& \operatorname{tr}(\hat{\rho}\hat{A}) = \sum_j \braket{e_j}\ket{\psi}\braket{\psi|\hat{A}|e_j} \\
  =& \Braket{\psi|\hat{A}| \sum_j \braket{e_j|\psi} e_j} = \braket{\psi|\hat{A}|\psi} \\
  =& \braket{A}_\psi
\end{align*}
$$

Hence, $\hat{\rho}$ is indistinguishable from the pure state $\ket{\psi}$.

**($\impliedby$): If $\braket{A}_\rho = \braket{A}_\psi$, then $\hat{\rho}^2 = \hat{\rho}$**

Suppose $\hat{\rho}$ has the form

$$
  \hat{\rho} = \sum_{j_1, j_2} \rho_{j_1 j_2} \ket{e_{j_1}} \bra{e_{j_2}}
$$

If there exists a state $\ket{\psi} = \sum_j \psi_j \ket{e_j}\in\mathcal{H}$ is such that $\braket{A}_\rho = \braket{A}_\psi$ for all Hermitian operators $\hat{A}\in\mathcal{B}(\mathcal{H})$, then

$$
\begin{align*}
  \braket{A}_\rho =& \operatorname{tr}(\hat{\rho}\hat{A}) = \sum_j \braket{e_j|\hat{\rho}\hat{A}|e_j} \\
  =& \sum_j \ket{e_j} \sum_{j_1, j_2} \rho_{j_1, j_2} \ket{e_{j_1}} \braket{e_{j_2} |\hat{A}| e_{j_1}} \\
  =& \sum_{j_1, j_2} \hat{\rho}_{j_1, j_2} \sum_j \underbrace{\braket{e_j | e_{j_1}}}_{\delta_{j j_1}} A_{j_2 j} \\
  =& \sum_{j_1, j_2} \rho_{j_1, j_2} A_{j_2 j_1}
\end{align*}
$$

and

$$
\begin{align*}
  \braket{A}_\psi =& \braket{\psi|\hat{A}|\psi} = \Braket{\sum_{j_2} \psi_{j_2} e_{j_2}|\hat{A}| \sum_{j_1} \psi_{j_1} e_{j_1}} \\
  =& \sum_{j_1, j_2} \psi_{j_2}^* \psi_{j_1} \braket{e_{j_2}|\hat{A}|e_{j_1}} \\
  =& \sum_{j_1, j_2} \psi_{j_2}^* \psi_{j_1} A_{j_2 j_1}
\end{align*}
$$

Since $\braket{A}_\psi = \braket{A}_\psi$ for all $\hat{A}$, the matrix elements of $\hat{\rho}$ must be of the form $\rho_{j_1 j_2} = \psi_{j_1} \psi_{j_2}^*$. Consequently,

$$
  \hat{\rho} = \sum_{j_1,j_2} \psi_{j_1} \psi_{j_2}^* \ket{e_{j_1}} \bra{e_{j_2}} = \ket{\psi}\bra{\psi}
$$

which is equivalent to $\hat{\rho}^2 = \hat{\rho}$.
</details>

### Measurement

<MathBox title="Gleason's theorem" boxType='theorem'>
Let $\mathcal{H}$ be a Hilbert space with finite dimension $\dim(\mathcal{H}) \geq 3$. Any map $\Pr$ that assigns probabilities to the orthogonal projections of $\mathcal{H}$ and satisfies

- $\Pr(\hat{0}) = 0$
- $\Pr(\hat{I}) = 1$
- $\hat{P}_1 \hat{P}_2 = 0 \implies \Pr(\hat{P}_1 + \hat{P}_2) = \Pr(\hat{P}_1) + \Pr(\hat{P}_2)$ for any orthogonal projections $\hat{P}_1, \hat{P}_2$ 

must be of the form

$$
  \Pr (\hat{P}) = \operatorname{tr}(\hat{\rho}\hat{P})
$$

where $\hat{\rho}$ is a unique positive semidefinite, Hermitian operator $\hat{\rho}$ with $\operatorname{tr}(\hat{\rho}) = 1$.
</MathBox>

In terms of a density operator $\hat{\rho}$, the expectation value of an observable $\hat{Q}$ is defined as

$$
\begin{equation*}
  \braket{\hat{Q}}_\rho = \operatorname{tr}(\hat{\rho} \hat{Q})
\tag{\label{equation-96}}
\end{equation*}
$$

The probability that a measurement of $\hat{Q} = \sum_j \lambda_j \ket{q_j} \bra{q_j}$ yields an eigenvalue $\lambda_j$ corresponding to the eigenstate $\ket{q_j}$ is given by

$$
\begin{align*}
  \Pr_\rho (\lambda) =& \braket{P_{q_j}}_\rho = \operatorname{tr}(\rho \hat{P}_{q_j}) \\
  =& \operatorname{tr}(\hat{\rho}\ket{q_j}\bra{q_j}) \\
  =& \sum_{k,l} p_j \braket{q_l|\psi_k} \braket{\psi_k|q_j} \underbrace{\braket{q_j|q_l}}_{\delta_{jl}} \\
  =& \sum_k p_k |\braket{e_j|\psi_k}|^2 
\end{align*}
$$

If the system is in a pure state, $\hat{\rho} = \ket{\psi}\bra{\psi}$, the probability of measuring the eigenvalue $\lambda_j$ of $Q$ is

$$
\begin{align*}
  \braket{P_{q_j}}_{\rho_\psi} =& \operatorname{tr}(\hat{\rho}_\psi \hat{P}_{q_j}) = \operatorname{tr}(\ket{\psi}\braket{\psi|q_j}\bra{q_j}) \\
  =& \sum_k \braket{q_k|\psi} \braket{\psi|q_j}\underbrace{\braket{q_j|q_k}}_{=\delta_{jk}} \\
  =& |\braket{q_j|\psi}|^2
\end{align*}
$$

The expectation value of $Q$ in this case is

$$
\begin{align*}
  \braket{Q}_{\rho_\psi} =& \operatorname{tr}(\hat{\rho}_\psi \hat{Q}) \\
  =& \sum_{j,k} \braket{q_k|\psi}\braket{\psi|q_j}\lambda_j \underbrace{\braket{q_j|q_k}}_{=\delta_{jk}} \\
  =& \sum_j \lambda_j |\braket{q_j|\psi}|^2 
\end{align*}
$$

For a pure state $\ket{\psi}$, the expectation value can be written

$$
  \braket{\hat{Q}}_\psi = \sum_j \braket{q_j | \hat{\rho} \hat{Q} | q_j} = \sum_j \braket{q_j | \psi} \braket{\psi|\hat{Q}|q_j}
$$

Let $\set{\ket{\psi_j}}_{j\in I\subset\N}$ be an orthonormal basis of a Hilbert space $\mathcal{H}$. If the density operator is $\hat{\rho} = \sum_{j\in I} p_j \ket{\psi_j} \bra{\psi_j}$ and the state $\ket{\psi}\in\mathcal{H}$ is given by 

$$
  \ket{\psi} = \sum_{j\in I} \sqrt{p_j} \ket{\psi_j}
$$

then for any observable $Q$, the expectation value is

$$
  \braket{Q}_\psi = \braket{Q}_\rho 0 \sum_{j,k\in I:j\neq k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k}
$$

<details>
<summary>Proof</summary>

The expectation value of $Q$ in terms of $\hat{rho}$ is

$$
\begin{align*}
  \braket{Q}_\rho =& \operatorname{tr}(\hat{\rho}\hat{Q}) = \operatorname{tr}\left(\sum_j p_j \ket{\psi_j} \bra{\psi_j} \right) \\
  =& \sum_j p_j \operatorname{tr}(\ket{\psi_j} \bra{\psi_j}\hat{Q}) \\
  =& \sum_j p_j \sum_k \underbrace{\braket{\psi_k|\psi_j}}_{=\delta_{jk}} \braket{\psi_j|\hat{Q}|\psi_k} \\
  =& \sum_j p_j \braket{\psi_j|\hat{Q}|\psi_j}
\end{align*}
$$

and thus

$$
\begin{align*}
  \braket{Q}_\psi =& \braket{\psi|\hat{Q}|\psi} = \Braket{\sum_j \sqrt{p_j}\psi_j|\hat{Q}|\sum_k \sqrt{p_k} \psi_k} \\
  =& \sum_{j,k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k} \\
  =& \sum_j p_j \braket{\psi_j|\hat{Q}|\psi_j} + \sum_{j\neq k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k} \\
  =& \braket{Q}_\rho + \sum_{j\neq k} \sqrt{p_j p_k} \braket{\psi_j|\hat{Q}|\psi_k}
\end{align*}
$$
</details>

### Time-evolution

For a state $\ket{\psi(t)}$, the density matrix can be written as $\hat{\rho}(t) = \ket{\psi(t)} \bra{\psi(t)}$. For a pure state under unitary evolution, the time derivative of the density matrix is

$$
\begin{align*}
  \frac{\d\hat{\rho}}{\d t} =& \frac{\hat{H}}{i\hbar} \ket{\psi(t)} \bra{\psi(t)} + \ket{\psi(t)} \bra{\psi(t)} \frac{\hat{H}}{-i\hbar} \\
  =& \frac{i}{\hbar} \left(\hat{\rho}\hat{H} - \hat{H}\hat{\rho} \right) = \frac{i}{\hbar} [\hat{\rho}, \hat{H}]
\end{align*}
$$

or, equivalently

$$
  i\hbar\frac{\d\hat{\rho}}{\d t} = [\hat{H}, \hat{\rho}]
$$

This is the von Neumann equation, which describes the evolution of the density matrix for pure states under Schr√∂dinger evolution. It shows that pure states evolve into pure states in this framework.

To express this evolution in the Heisenberg picture, we use the fact that the state in the Schr√∂dinger picture is related to the state in the Heisenberg picture by $\ket{\psi(t)}_\text{S} = \hat{U}_t \ket{\psi(0)}_\text{S}$, where $\hat{U}_t$ is the time evolution operator. Thus, the density matrix in the Schr√∂dinger picture at time $t$ can be written

$$
  \hat{\rho}_\text{S} (t) = \hat{U}_t \ket{\psi}_\text{H} \bra{\psi}_\text{H} \hat{U}_t^\dagger = \hat{U}_t \hat{\rho}_\text{H} \hat{U}_t^\dagger
$$

In the Heisenberg picture, the density matrix evolves as

$$
  \hat{\rho}_\text{H} = \hat{U}_t^\dagger \hat{\rho}_\text{S} \hat{U}_t = \hat{\rho}_\text{S} (0)
$$

In the Dirac interaction picture, the density matrix evolves as

$$
  \hat{\rho}_\text{I} = \hat{U}_{H_0, t}^\dagger \hat{\rho}_\text{S} \hat{U}_{H_0, t}
$$

where $\hat{U}_{H_0, t}$ is the evolution operator in the interaction picture corresponding to the free Hamiltonian $\hat{H}_0$.

## Composite systems

The quantum state space of composite system formed of $n\in\N_+$ sub-system $\mathcal{H}_{A_j}$ for $j\in\set{1,\dots,n}$ is given by the Hilbert tensor product

$$
  \bigotimes_{j=1}^n \mathcal{H}_{A_j}
$$

States of the composite system are generally represented by density operators $\hat{\rho}$ on $\bigotimes_{j=1}^n \mathcal{H}_{A_j}$, which take the form

$$
  \hat{\rho} = \sum_{j\in I} p_j \ket{\Psi_j} \bra{\Psi_j}
$$

where $\set{\ket{\Psi_j}}_{j\in I}$ is an orthonormal basis of $\bigotimes_{j=1}^n \mathcal{H}_{A_j}$.

<MathBox title='Alice and Bob' boxType='remark'>
For a bipartite quantum system $\mathcal{H}_A \otimes \mathcal{H}_B$, it is common to refer to subsystem $A$ as *Alice* and subsystem $B$ as *Bob* for notational convenience.
</MathBox>

### Pure states of bipartite systems

Consider a bipartite system $\mathcal{H}_A \otimes \mathcal{H}_B$ with a density operator $\hat{\rho}\in\mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B)$ describing its state. Measurement of an observable on subsystem $A$, represented by the operator $\hat{M}_A$, corresponds to measuring the composite system with the operator $\hat{M}_A \otimes \hat{I}_B$. Similarly, measurements on subsystem $B$ are represented by operators of the form $\hat{1}^A \otimes \hat{M}_B$. 

For a pure state of the composite system

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a} \otimes \ket{f_b} \in\mathcal{H}_A \otimes \mathcal{H}_B
$$

where $\set{\ket{e_a}}$ and $\set{\ket{f_b}}$ are orthonormal bases of $\mathcal{H}_A$ and $\mathcal{H}_B$, respectively, the expectation value of the observable $M^A$ on subsystem $A$ is given by

$$
\begin{align*}
  \braket{\mathbf{M}_A \otimes \hat{I}_B}_\Psi =& \braket{\Psi|\hat{M}_A \otimes \hat{I}|\Psi} \\
  =& \sum_{a_1, b_1} \sum_{a_2, b_2} \Psi_{a_2 b_2}^* \Psi_{a_1 b_1} \braket{e_{a_2} \otimes f_{b_2}|\hat{M}_A|e_{a_1} \otimes f_{b_1}} \\
  =& \sum_{a_1, b_1} \sum_{a_2, b_2} \Psi_{a_2 b_2}^* \Psi_{a_1 b_1} \braket{e_{a_2}|\hat{M}_A|e_{a_1}} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{=\delta_{b_1 b_2}} \\
  =& \sum_{a_2, a_1, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \bra{e_{a_2}|\hat{M}_A|e_{a_1}}
\end{align*}
$$

This expectation value remains unchanged if subsystem $A$ were in the mixed state:

$$
  \hat{\rho}_A (\Psi) := \sum_{a_2, a_1, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \ket{e_{a_1}} \bra{e_{a_2}}
$$

For observables of the form $\hat{M}_A$, the state $\hat{\rho}_A (\psi)$ reproduces the expectation values of $\hat{M}_A \otimes \hat{I}_B$ in the composite state $\ket{\Psi}$. Computing the expectation of $M_A$ with respect to $\hat{\rho}_A (\Psi)$ gives

$$
\begin{align*}
  \braket{\hat{M}_A}_{\rho_A (\Psi)} =& \operatorname{tr}(\hat{\rho}_A (\Psi) \hat{M}_A) \\
  =& \sum_a \braket{e_a|\hat{\rho_A} (\Psi) \hat{M}_A e_a} \\
  =& \sum_{a, a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \braket{e_a|e_{a_1}} \braket{e_{a_2}|\hat{M}_A|e_a} \\
  =& \sum_{a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \braket{e_{a_2}|\hat{M}_A|e_{a_1}} \\
  =& \braket{\hat{M}_A \otimes \hat{I}}_\Psi
\end{align*}
$$

Every measurement performed on subsystem $A$, which is a part of a composite system in state $\ket{\Psi}$, suggests that subsystem $A$ is in the mixed state $\hat{\rho}_A (\Psi)$. This means that if the composite system is in the pure state $\ket{\Psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$, described by the density operator $\hat{\rho} = \ket{\Psi}\bra{\Psi}$ on $\mathcal{H}_A \otimes \mathcal{H}_B$, then the reduced state of subsystem $A$ is given by

$$
  \hat{\rho}_A (\Psi) = \sum_{a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \ket{e_{a_1}}\bra{e_{a_2}}
$$

Similarly, for subsystem $B$, the expectation values of observables $\hat{M}_B$ in the pure state $\ket{\Psi}$ are given

$$
  \braket{\hat{I}_A \otimes \hat{M}_B} = \sum_{b_1, b_2, a} \Psi_{ab_1} \Psi_{ab_2}^* \braket{f_{b_2}|\hat{M}_B|f_{b_1}}
$$

where the reduced density operator for subsystem $B$ is

$$
  \hat{\rho}_B (\Psi) = \sum_{b_1, b_2, a} \Psi_{ab_2}^* \Psi_{ab_1} \ket{f_{b_1}} \bra{f_{b_2}} 
$$

which satisfies

$$
  \braket{\hat{M}_B}_{\rho_B (\Psi)} = \braket{\hat{I}_A \otimes \hat{M}_B}_\Psi
$$

<details>
<summary>Details</summary>

We verify that $\hat{\rho}_A (\Psi)$ has all properties of a density operator.

**Hermiticity:** Taking the Hemitian adjoint of $\hat{\rho}_A (\Psi)$ gives
$$
\begin{align*}
  \hat{\rho}_A^\dagger (\Psi) =& \sum_{a_1, a_2, b} (\Psi_{a_2 b}^*)^* \Psi_{a_1 b}^* \underbrace{(\ket{e_{a_1}}\bra{e_{a_2}})^\dagger}_{=\ket{e_{a_2}}\bra{e_{a_1}}} \\
  =& \sum_{a_1, a_2, b} \Psi_{a_1 b}^* \Psi_{a_2 b} \ket{e_{a_2}} \bra{e_{a_1}} \\
  =& \hat{\rho}_A (\Psi)
\end{align*}
$$

showing that $\hat{\rho}_A (\Psi)$ is Hermitian.

**Positive semi-definiteness:** For any $\varphi\in \mathcal{H}_A \otimes \mathcal{H}_B$, we have

$$
\begin{align*}
  \braket{\varphi|\hat{\rho}_A (\Psi)|\varphi} =& \sum_{a_1, a_2, b} \Psi_{a_2 b}^* \Psi_{a_1 b} \braket{\varphi|e_{a_1}} \braket{e_{a_2}|\varphi} \\
  =& \sum_b \left(\sum_{a_1} \Psi_{a_1 b} \braket{\varphi|e_{a_1}}\right)\left(\sum_{a_2} \Psi_{a_2 b} \braket{\varphi|e_{a_2}} \right)^* \\
  =& \sum_b \left| \sum_a \Psi_{ab} \braket{\varphi|e_a} \right|^2 \geq 0
\end{align*}
$$

**Unit trace:** Taking the trace of $\hat{\rho}_A (\Psi)$ gives

$$
\begin{align*}
  \operatorname{tr}(\hat{\rho}_A (\Psi)) =& \sum_{a_3, a_1, a_2, b} \Psi_{a_2}^* \Psi_{a_1 b} \braket{e_{a_3}|e_{a_1}} \braket{e_{a_2}|e_{a_3}} \\
  =& \sum_{a,b} |\Psi_{ab}|^2 = \norm{\Psi}^2 = 1
\end{align*}
$$
</details>

### Mixed states of bipartite systems
Consider a bipartite system $\mathcal{H}_A \otimes \mathcal{H}_B$ and let $\hat{\rho}\in\mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B)$ be a density operator describing the state of the system. The reduced density operator $\hat{\rho}_A (\hat{\rho})$ on $\mathcal{H}_A$, which describes the state if the subsystem $A$ alone is observed, is given by the partial trace

$$
  \operatorname{\rho}_A (\hat{\rho}) := \operatorname{tr}_B (\hat{\rho})
$$

For any observable $\hat{M}_A$ in $A$, the density operator $\hat{\rho}_A (\hat{\rho})$ satisifes

$$
  \braket{\hat{M}_A}_{\hat{\rho}_A (\hat{\rho})} = \braket{\hat{M}_A \otimes \hat{I}_B}_{\hat{\rho}}
$$

<details>
<summary>Details</summary>

$$
\begin{align*}
  \braket{\hat{M}_A \otimes \hat{I}_B}_{\hat{\rho}} =& \operatorname{tr}\left((\hat{M}_A \otimes \hat{I}_B)\hat{\rho} \right) \\
  =& \operatorname{tr}\left(\hat{M}_A \operatorname{tr}_B (\hat{\rho}) \right) \\
  =& \operatorname{tr}\left(\hat{M}_A \hat{\rho}_A (\rho) \right) \\
  =& \braket{\hat{M}_A \otimes \hat{I}_B}_{\hat{\rho}}
\end{align*}
$$
</details>

If $\boldsymbol{\rho}_{a_1 b_1, a_2 b_2}$ is the matrix of $\hat{\rho}$ in the orthonormal basis $\set{\ket{e_a \otimes f_b}}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$, then the matrix of $\hat{\rho}_A (\hat{\rho})$ in the orthonormal basis $\set{\ket{e_a}} \subset\mathcal{H}_A$ is given by

$$
  \boldsymbol{\rho}_A (\hat{\rho})_{a_1 a_2} = \sum_b \boldsymbol{\rho}_{a_1 b, a_2 b}
$$

<details>
<summary>Details</summary>

We verify that $\hat{\rho}_A (\hat{\rho})$ has all properties of a density operator.

**Hermiticity:** To prove that $\hat{\rho}_A (\hat{\rho})$ is Hemitian, it suffices to show $\boldsymbol{\rho}_A^\dagger (\hat{\rho})_{a_1 a_2} = \boldsymbol{\rho}_A (\hat{\rho})_{a_1 a_2}$ in an arbitrary orthonormal basis $\set{\ket{e_a}} \subset\mathcal{H}_A$

$$
\begin{align*}
  \boldsymbol{\rho}_A^\dagger {\hat{\rho}}_{a_1 a_2} =& \boldsymbol{\rho}_A^* (\hat{\rho})_{a_1 a_2} = \left(\sum_b \boldsymbol{\rho}_{a_2 b, a_1 b} \right)^* \\
  =& \sum_b \boldsymbol{\rho}_{a_2 b, a_1 b}^* = \sum_b \boldsymbol{\rho}_{a_1 b, a_2 b} \\
  =& \boldsymbol{\rho}_A (\hat{\rho})_{a_1 a_2}
\end{align*}
$$

**Positive semi-definiteness:** Let $\set{\ket{f_b}}$ be an orthonormal basis of $\mathcal{H}_B$ and $\ket{\varphi}\in\mathcal{H}_A$ be arbitrary. Since $\hat{\rho} \geq 0$, it follows that

$$
\begin{align*}
  \braket{\varphi|\hat{\rho}_A (\hat{\rho})|\varphi} =& \sum_{a_1, a_2} \boldsymbol{\varphi}_{a_1}^* \boldsymbol{\rho}_A (\hat{\rho})_{a_1, a_2} \boldsymbol{\varphi}_{a_2} \\
  =& \sum_{a_1, a_2} \boldsymbol{\varphi_{a_1}}^* \sum_b \boldsymbol{\rho}_{a_1 b, a_2 b} \boldsymbol{\varphi}_{a_2} \\
  =& \sum_{a_1, a_2, b} \boldsymbol{\varphi}_{a_1}^* \boldsymbol{\rho}_{a_1 b, a_2 b} \boldsymbol{\varphi}_{a_2} \\
  =& \sum_b \braket{\varphi\otimes f_b|\hat{\rho}|\varphi\otimes f_b} \geq 0
\end{align*}
$$

**Unit trace:** Since $\boldsymbol{tr}(\hat{\rho}) = 1$, it follows that

$$
\begin{align*}
  \operatorname{tr}\left(\hat{\rho}_A (\hat{\rho}) \right) =& \sum_a \boldsymbol{\rho}_A (\hat{\rho})_{aa} \\
  =& \sum_a \sum_b \boldsymbol{\rho}_{ab, ab} = \operatorname{tr}(\hat{\rho}) = 1
\end{align*}
$$
</details>

Similarly, the reduced density operator $\hat{\rho}_B (\hat{\rho})$ on $\mathcal{H}_B$ is given by the partial trace

$$
  \hat{\rho}_B (\hat{\rho}) := \operatorname{tr}_A (\hat{\rho}) 
$$

For any observable $\hat{M}_B$ in $A$, the density operator $\hat{\rho}_B (\hat{\rho})$ satisifes

$$
  \braket{\hat{M}_B}_{\hat{\rho}_B (\hat{\rho})} = \braket{\hat{I}_A \otimes \hat{M}_B}_{\hat{\rho}}
$$

If $\boldsymbol{\rho}_{a_1 b_1, a_2 b_2}$ is the matrix of $\hat{\rho}$ in the orthonormal basis $\set{\ket{e_a \otimes f_b}}$ in $\mathcal{H}_A \otimes \mathcal{H}_B$, then the matrix of $\hat{\rho}_B (\hat{\rho})$ in the orthonormal basis $\set{\ket{f_b}}\subset\mathcal{H}_B$ is given by

$$
  \boldsymbol{\rho}_B (\hat{\rho})_{b_1 b_2} = \sum_a \boldsymbol{\rho}_{a b_1, a b_2}
$$

### Schmidt decomposition of pure states

Schmidt decomposition provides a way to express a pure states $\ket{\Psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$ in terms of the eigenvectors of the reduced density operators. Let

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{a,b} \ket{e_a \otimes f_b}
$$

be a pure state in the composite Hilbert space $\mathcal{H}_A \otimes \mathcal{H}_B$ and let

$$
  \hat{\rho}_A (\Psi) = \sum_{a_1, a_2, b} \Psi_{a_1 b} \Psi_{a_2 b}^* \ket{e_{a_1}} \bra{e_{a_2}}
$$

be the corresponding reduced density operator for subsystem $A$. Since $\hat{\rho}_A (\Psi)$ is a Hermitian and positive operator on $\mathcal{H}_A$, there exists an orthonormal basis $\set{\ket{\tilde{e}_a}}$ in $\mathcal{H}_A$ consisting of eigenvector of $\hat{\rho}_A (\Psi)$ such that

$$
  \hat{\rho}^A (\Psi) = \sum_{a} q_a \ket{\tilde{e}_a} bra{\tilde{e}_a}
$$

where $q_a \geq 0$ are the eigenvalues. The othornormal bases $\set{\ket{\tilde{e}_a}}$ and $\set{\ket{\tilde{e}_a}}$ are related by a unitary operator $\hat{U}\in\mathcal{U}(\mathcal{H}_A)$

$$
  \ket{\tilde{e}_a} = \hat{U}\ket{e_a} = \sum_{a_1} \ket{e_{a_1}} \underbrace{\braket{e_{a_1}|\hat{U}|e_a}}_{=\mathbf{U}_{a_1 a}}
$$

Defining the transformed coefficients

$$
  \tilde{\Psi}_{ab} := \sum_{a_1} \mathbf{U}_{a a_1} \Psi_{a_1 b}
$$

we find

$$
  \ket{\Psi} = =\sum_{a, b} \tilde{\Psi}_{ab} \ket{\tilde{e}_a \otimes f_b}
$$

This imples that the reduced density matrix takes the form

$$
  \hat{\rho}_A (\Psi) = \sum_{a_1, a_2, b} \tilde{\Psi}_{a_1 b} \tilde{\Psi}_{a_2 b}^* \ket{\tilde{e}_{a_1}} \bra{\tilde{e}_{a_2}}
$$

By comparing the eigenvalue coefficients of $\hat{\rho}_A (\Psi)$, we deduce that

$$
  \sum_b \tilde{\Psi}_{a_1 b} \Psi_{a_2 b}^* = \delta_{a_1 a_2} q_{a_2}
$$

In particular,

$$
  q_a = 0 \iff \Psi_{ab}^* = 0, \; \forall b
$$

For $q_a > 0$ we define the vectors

$$
  \ket{\tilde{f}_a} := \frac{1}{\sqrt{q_a}} \sum_b \tilde{\Psi}_{ab} \ket{f_b} \in\mathcal{H}_B
$$

The set $\set{\ket{\tilde{f}_a}}$ forms an orthonormal basis in $\mathcal{H}_B$ since

$$
\begin{align*}
  \braket{\tilde{f}_{a_1}|\tilde{f}_{a_2}} =& \frac{1}{\sqrt{q_{a_1} q_{a_2}}} \sum_{b_1, b_2} \tilde{\Psi}_{a_1 b_1}^* \tilde{\Psi}_{a_2 b_2} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{\delta_{b_1 b_2}} \\
  =& \frac{1}{\sqrt{q_{a_1} q_{a_2}}} \sum_b \tilde{\Psi}_{a_1 b}^* \tilde{\Psi}_{a_2 b} \\
  =& \delta_{a_1 a_2}
\end{align*}
$$

Thus, we obtain

$$
\begin{align*}
  \ket{\Psi} =& \sum_{a,b} \tilde{\Psi}_{ab} \ket{\tilde{e}_a \otimes f_b} \\
  =& \sum_{q_a \neq 0} \ket{\tilde{e}_a} \otimes \underbrace{\sum_{b} \tilde{\Psi}_{ab} \ket{f_b}}_{=\sqrt{q_a}\ket{f_b}} + \sum_{q_a = 0} \sum_b \underbrace{\tilde{\Psi}_{ab}}_{=0} \ket{\tilde{e}_a \otimes f_b} \\
  =& \sum_{q_a \neq 0} \sqrt{q_a} \ket{\tilde{e}_a \otimes \tilde{f}_b}
\end{align*}
$$

which is the Schmidt decomposition

$$
  \ket{\Psi} = \sum_a \sqrt{q_a} \ket{\tilde{e}_a \otimes \tilde{f}_a}
$$

The orthonormal bases $\set{\ket{\tilde{e}_a}}$ and $\set{\ket{\tilde{f}_b}}$ depend on $\ket{\Psi}$. In terms of the Schmidt decomposition, the reduced density operators can be written as

$$
\begin{align*}
  \hat{\rho}_A (\Psi) =& \sum_a q_a \ket{\tilde{e}_a} \bra{\tilde{e}_a}
  \hat{\rho}_B (\Psi) =& \sum_{b} q_b \ket{\tilde{f}_b} \bra{\tilde{f}_b}
\end{align*}
$$

The Schmidt bases $\set{\ket{\tilde{e}_a}}$ and $\set{\ket{\tilde{f}_b}}$ are unique only if all nonzero eigenvalues of $\hat{\rho}_A (\Psi)$ (or equivalently, $\hat{\rho}_B (\Psi)$) are non-degenerate. If a nonzero eigenvalue $q_{\bar{a}} \neq 0$ of $\hat{\rho}_A (\Psi)$ has degeneracy $d_{\bar{a}} > 1$, then the corresponding eigenspace allows for an arbitrary choice of orthonormal basis. For $k\in\set{1,\dots,d_{\bar{a}}}$ let $\ket{\tilde{e}_{\bar{a}, k}}$ be the eigenvectors associated with $q_{\bar{a}}$. Then

$$
\begin{align*}
  \hat{\rho}_A (\Psi) =& \sum_{a \neq \bar{a}} q_a \ket{\tilde{e}_a} \bra{\tilde{e}_a} + q_{\bar{a}} \sum_{k=1}^{d_{\bar{a}}} \ket{\tilde{e_{\bar{a}, k}}} \bra{\tilde{e}_{\bar{a}, k}} \\
  =& \sum_{a \neq \bar{a}} q_a \ket{\tilde{e}_a} \bar{\tilde{e}_a} + q_{\bar{a}} \sum_{k=1}^{d_{\bar{a}}} {\ket{\tilde{\tilde{e}}}_{\bar{a}, k}} \bra{\tilde{\tilde{e}}_{\bar{a}, k}}
\end{align*}
$$

with

$$
  {\ket{\tilde{\tilde{e}}}_{\bar{a}, k}} = \sum_{l = 1}^{d_{\bar{a}}} \mathbf{U}_{kl}^{\bar{a}} \ket{\tilde{e}_{\bar{a},l}}
$$

where $\mathbf{U}_{kl}^{\bar{a}}$ is the matrix of an arbitrary unitary transformation in the eigenspace for $q_{\bar{a}}$. This shows that $\ket{\Psi}$ has the following equivalent Schmidt decompositions 

$$
\begin{align*}
  \ket{\Psi} =& \sum_{a \neq \bar{a}} \sqrt{q_a} \ket{\tilde{e}_a \otimes \tilde{f}_b} + \sqrt{q_{\bar{a}}} \sum_{k=1}^{d_{\bar{a}}} \ket{\tilde{e}_a \otimes \tilde{f}_b} \\
  =& \sum_{a \neq \bar{a}} q_a \ket{\tilde{e}_a \otimes \tilde{f}_b} + q_{\bar{a}} \sum_{k=1}^{d_{\bar{a}}} \ket{\tilde{\tilde{e}}_a \otimes \tilde{\tilde{f}}_b}
\end{align*}
$$

## Entanglement

A state $\hat{\rho}\in\mathcal{D}(\mathcal{H}_A \otimes \mathcal{H}_B)$ in a composite system $\mathcal{H}_A \otimes \mathcal{H}_B$ is *separable* with respect to the subsystems $\mathcal{H}_A$ and $\mathcal{H}_B$ if there exists states $\hat{\rho}_j^{(A)} \in\mathcal{D}(\mathcal{H}_A)$ and $\hat{\rho}_j^B \in\mathcal{D}(\mathcal{H}_B)$ for $I\subset\N_+$, along with real numbers $p_j > 0$ satisfying $\sum_{j\in I} p_j = 1$, such that

$$
  \hat{\rho} = \sum_{j\in I} p_j \hat{\rho}_j \hat{\rho}_j^{(A)} \otimes \hat{\rho}_j^{(B)}
$$

Separable states are also known as *product-states*. States that cannot be written in this form are *entangled*. A pure state $\ket{A}$ in the tensor product of identical Hilbert spaces $\mathcal{H}_A$ is *maximally intangled* if

$$
  \hat{\rho}_A (\Psi) = \lambda\hat{I}, \; 0 < \lambda < 1
$$

<details>
<summary>Details</summary>

To verify that the tensor product of two density matrices is itself a valid density matrix, consider $\hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)$ and $\hat{\rho}_B \in\mathcal{D}(\mathcal{H}_B)$. We need to check that $\hat{\rho}_A \otimes \hat{\rho}_B \in\mathcal{D}(\mathcal{H}_A \otimes\mathcal{H}_B)$, which requires that it is Hermitian, positive semi-definite, and has unit trace.

**Hermiticity:** Since $\hat{\rho}_A$ and $\hat{\rho}_B$ are Hermitian then so is $\hat{\rho}_A \otimes\hat{\rho}_B$. 


**Positivity:** In order to show the positivity of $\hat{\rho}_A \otimes \hat{\rho}_B$ note first that

$$
\begin{align*}
  \hat{\rho}_A \otimes \hat{\rho}_B =& (\hat{\rho}_A \otimes\hat{I}_B)(\hat{I}\otimes\hat{\rho}_B) \\
  =& (\hat{I}_A \otimes\hat{\rho}_B)(\hat{\rho}_A \otimes\hat{I}_B)
\end{align*}
$$

where also

$$
  (\hat{\rho}_A \otimes\hat{I}_B)^\dagger = \hat{\rho}_A \otimes\hat{I}_B, \quad (\hat{I}_A \otimes\hat{\rho}_B)^\dagger = \hat{I}_A \otimes\hat{\rho}_B
$$

Both $\hat{\rho}_A \otimes\hat{I}_B$ and $\hat{I}_A \otimes\hat{\rho}_B$ are positive because for an arbitrary vector

$$
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a} \otimes\ket{f_b} \in\mathcal{H}_A \otimes\mathcal{H}_B
$$

and positivity of $\hat{\rho}_A$ we find that

$$
\begin{align*}
  \braket{\Psi|\hat{\rho}_A \otimes\hat{I}_B|\Psi} =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \Braket{e_{a_1} \otimes f_{b_1}|\hat{\rho}_A \otimes\hat{I}_B|e_{a_2} \otimes f_{b_2}} \\
  =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \braket{e_{a_1}|\hat{\rho}_A|e_{a_2}} \underbrace{\braket{f_{b_1}|f_{b_2}}}_{=\delta_{b_1 b_2}} \\
  =& \sum_{a_1 a_2, b} \Psi_{a_1 b}^* \Psi_{a_2 b} \braket{e_{a_1}|\hat{\rho}_A|e_{a_2}} \\
  =& \sum_b \Braket{\sum_{a_1} \Psi_{a_1 b} e_{a_1}|\hat{\rho}_A| \sum_{a_2} \Psi_{a_2 b} e_{a_2}} \\
  =& \sum_b \braket{\psi_b |\hat{\rho}_A|\psi_b} \geq 0
\end{align*}
$$

Similarly, by positivity of $\hat{\rho}_B$ we find that

$$
\begin{align*}
  \braket{\Psi|\hat{I}_A \otimes\hat{\rho}_B|\Psi} =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \Braket{e_{a_1} \otimes f_{b_1}|\hat{I}_A \otimes\hat{P}_B|e_{a_2} \otimes f_{b_2}} \\
  =& \sum_{a_1 a_2, b_1 b_2} \Psi_{a_1 b_1}^* \Psi_{a_2 b_2} \underbrace{\braket{e_{a_1}|e_{a_2}}}_{=\delta_{a_1 a_2}} \braket{f_{b_1}|\hat{\rho}_B|f_{b_2}} \\
  =& \sum_{a, b_1 b_2} \Psi_{a b_1}^* \Psi_{a b_2} \braket{f_{b_1}|\hat{\rho}_B|f_{b_2}} \\
  =& \sum_a \Braket{\sum_{b_1} \Psi_{a b_1} f_{b_1}|\hat{\rho}_B| \sum_{b_2} \Psi_{a b_2} f_{b_2}} \\
  =& \sum_a \braket{\psi_a |\hat{\rho}_B|\psi_a} \geq 0
\end{align*}
$$

Since $\hat{\rho}_A \otimes\hat{I}_B$ and $\hat{I}_A \otimes\hat{\rho}_B$ commute, and are Hermitian and posite, it follows that for every pair $\hat{\rho}_A \otimes\hat{I}_B$, $\hat{I}_A \otimes\hat{\rho}_B$ there exists an orthonormal basis $\ket{e_a \otimes f_b}$ in which both are diagonal, i.e.

$$
\begin{align*}
  \hat{\rho}_A \otimes\hat{I}_B =& \sum_{a,b} \lambda_{a,b}^{(A)} \ket{e_a \otimes f_b} \bra{e_a \otimes f_b} \\
  \hat{I}_A \otimes\hat{\rho}_B =& \sum_{a,b} \lambda_{a,b}^{(B)} \ket{e_a \otimes f_b} \bra{e_a \otimes f_b}
\end{align*}
$$

where due to positivity we also have $\lambda_{a,b}^{(A)} \geq 0$ and $\lambda_{a,b}^{(B)} \geq 0$, so that

$$
  \hat{\rho}_A \otimes \hat{\rho}_B = \sum_{a,b} \lambda_{a,b}^{(A)} \lambda_{a,b}^{(B)} \ket{e_a \otimes f_b} \bra{e_a \otimes f_b}
$$

and since $\lambda_{a,b}^{(A)}\lambda_{a,b}^{(B)} \geq 0$, it follows that $\hat{\rho}_A \otimes\hat{\rho}_B$ is positive.

**Unit trace:** Since $\hat{\rho}_A$ and $\hat{\rho}_B$ have unit trace, it follows that

$$
  \operatorname{tr}(\hat{\rho}_A \otimes\hat{\rho}_B) = \operatorname{tr}(\hat{\rho}_A)\operatorname{tr}(\hat{\rho}_B) = 1
$$
</details>

<MathBox title='Separability criterion for pure states' boxType='theorem' tag='theorem-1'>
A pure state $\ket{\psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$ is separable if and only if there exists pure states $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$ such that

$$
\begin{equation*}
  \ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}
\tag{\label{equation-113}}
\end{equation*}
$$

Otherwise, $\ket{\psi}$ is entangled.

<details>
<summary>Proof</summary>

**Sufficiency**

First we show that $\eqref{equation-113}$ is sufficient for separability. Suppose we have $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi} \in\mathcal{H}_A \otimes\mathcal{H}_B$. Then it follows that

$$
\begin{align*}
  \hat{\rho}(\Psi) =& \ket{\Psi}\bra{\Psi} = \ket{\varphi\otimes\psi}\bra{\varphi\otimes\psi} \\
  =& \ket{\psi}\bra{\psi} \otimes\ket{\varphi}\bra{\varphi}
\end{align*}
$$

Setting $\hat{\rho}^A = \ket{\varphi}\bra{\varphi}$ and $\hat{\rho}^B = \ket{\psi}\bra{\psi}$, we see that $\eqref{equation-113}$ holds.

**Necessity**
To show that $\eqref{equation-113}$ is also necessary, let $\hat{\rho}$ be a pure separable state. Then its density matrix $\hat{\rho} = \ket{\Psi}\bra{\Psi}$ must be of the form

$$
  \hat{\rho} = \sum_{j\in I} p_j \hat{\rho}_j^{(A)} \otimes \hat{\rho}_j^{(B)}, \; I\subset\N_+
$$

where $p_j > 0$ with $\sum_{j\in I} p_j = 1$, and $\hat{\rho}_j^{(A)}\in\mathcal{D}(\mathcal{H}_A)$, $\hat{\rho}_j^{(B)}\in\mathcal{D}(\mathcal{H}_B)$.

We show that there exists $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$ such that $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}$. For all $j\in I$ we set

$$
  \hat{\rho}_j = \hat{\rho}_j^{(A)} \otimes\hat{\rho}_j^{(B)} \in\mathcal{D}(\mathcal{H}_A \otimes\mathcal{H}_B)
$$

which define density operators in $\mathcal{H}_A \otimes \mathcal{H}_B$. From properties of density operators, there exists $p_{j,k}\in (0,1]$ for every $j\in I$ with $k \in I_j \subset \N_+$ satisfying $\sum_{k\in I_j} p_{j,k} = 1$, and an orthonormal basis $\set{\ket{\Omega_{j,k}}}_{k=1}^{\dim(\mathcal{H}_A \otimes\mathcal{H}_B)}$ of $\mathcal{H}_A \otimes \mathcal{H}_B$ such that

$$
\begin{equation*}
  \hat{\rho}_j = \sum_{k\in I_j} p_{j,k} \ket{\Omega_{j,k}} \bra{\Omega_{j,k}}
\tag{\label{equation-114}}
\end{equation*}
$$

We extend $\ket{\Psi}$ to another orthonormal basis $\set{\ket{\Psi}, \ket{\Psi_l}}_{l=1}^{\dim(\mathcal{H}_A \otimes\mathcal{H}_B) - 1}$ of $\mathcal{H}_A \otimes\mathcal{H}_B$. It follows that

$$
  0 = |\braket{\Psi_l|\Psi}|^2 = \braket{\Psi_l|\hat{\rho}|\Psi_l} = \sum_{j\in I} p_j \braket{\Psi_l|\hat{\rho}_j|\Psi_l}
$$

and since $p_j > 0$, we must have $\braket{\Psi_l|\hat{\rho}_j|\Psi_l} = 0$ for all $j\in I$ and $l\in\set{1,dots,\dim(\mathcal{H}_A \otimes \mathcal{H}_B) - 1}$. Together with $\eqref{equation-114}$ this implies

$$
  \sum_{k\in I_j} p_{j,k} |\braket{\Psi_l |\Omega_{j,k}}|^2 = 0
$$

and thus, again because $p_{j,k} > 0$ for all $l\in\set{1,\dots,\dim(\mathcal{H}_A \otimes \mathcal{H}_B - 1)}$, $j\in I$ and $k\in I_j$, we have

$$
  \braket{\Psi|\Omega_{j,k}} = 0
$$

Thus, for every $j\in I$ and $k\in I_j$ the basis vector $\ket{\Omega_{j,k}}$ is orthogonal to all $\ket{\Psi_l}$. Consequently, every $\ket{\Psi_{j,k}}$ is in the ray of $\ket{\Psi}$ and there exist $\alpha_{j,k} \in\R$ such that

$$
  \ket{\Omega_{j,k}} = e^{i\alpha_{j,k}} \ket{\Psi}
$$

This implies

$$
\begin{align*}
  \hat{\rho}_j^{(A)} \otimes\hat{\rho}_j^{(B)} =& \hat{\rho}_j = \sum_{k \in I_j} p_{j,k} e^{i\alpha_{j,k}} \ket{\Psi}\bra{\Psi} e^{-i\alpha_{j,k}} \\
  =& \underbrace{\sum_{k\in I_j} p_{j,k}}_{=1} \ket{\Psi}\bra{Psi} = \ket{\Psi}\bra{\Psi} \\
  =& \hat{\rho}
\end{align*}
$$

and thus there are $\hat{\rho}_A \in\mathcal{D}(\mathcal{H}_A)$ and $\hat{\rho}_B \in\mathcal{H}_B$ such that for all $j\in I$

$$
  \hat{\rho}_j = \hat{\rho}_A \otimes\hat{\rho}_B = \hat{\rho}
$$

Using the Schmidt decomposition, we can find $q_a \in (0,1]$ and orthonormal bases $\set{e_a}_{a=1}^{\dim(\mathcal{H}_A)}$ and $\set{f_b}_{b=1}^{\dim(\mathcal{H}_B)}$ such that we can write

$$
\begin{equation*}
  \ket{\Psi} = \sum_a \sqrt{q_a} \ket{e_a} \otimes\ket{f_b}
\tag{\label{equation-115}}
\end{equation*}
$$

This implies

$$
\begin{align*}
  \hat{\rho}_A \otimes\hat{\rho}_B =& \hat{\rho} = \ket{\Psi}\bra{\Psi} \\
  =& \sum_{a,b} \sqrt{q_a q_b} \ket{e_a}\bra{e_a} \otimes \ket{f_b} \bra{f_b}
\end{align*}
$$

such that in the orthonormal basis $\set{\ket{e_a}\otimes\ket{f_b}}$ of $\mathcal{H}_A \otimes\mathcal{H}_B$ we see that $\hat{\rho}$ has the matrix

$$
\begin{align*}
  \boldsymbol{\rho}_{a_1 a_2}^{(A)} \boldsymbol{\rho}_{b_1 b_2}^{(B)} = \mathbf{\rho}_{a_1 b_1, a_2 b_2} \\
  =& \sqrt{q_{a_1} q_{a_2}} \delta_{a_1 b_1} \delta_{a_2 b_2}
\end{align*}
$$

From this it follows that

$$
\begin{equation*}
\begin{split}
  \hat{\rho}_A =& \operatorname{tr}_B (\hat{\rho}) = \sum_a q_a \ket{e_a}\bra{e_a} \\
  \hat{\rho}_B =& \operatorname{tr}_A (\hat{\rho}) = \sum_b q_b \ket{f_b}\bra{f_b}
\end{split}
\tag{\label{equation-118}}
\end{equation*}
$$

Now, by unit trace of $\hat{\rho}$

$$
\begin{align*}
  1 =& \operatorname{tr}(\hat{\rho}) = \operatorname{tr}(\hat{\rho}^2) \\
  =& \operatorname{tr}(\hat{\rho}_A^2 \otimes \hat{\rho}_B^2) \\
  =& \sum_{c, d} \braket{e_c \otimes f_d |\sum_{a,b} q_a^2 q_b^2 \ket{e_a \otimes f_b} \bra{e_a \otimes f_b} | e_c \otimes f_d} \\
  =& \sum_{a, b, c, d} q_a^2 q_b^2 \delta_{ca} \delta_{db} = \sum_{a,b} q_a^2 q_b^2 \\
  =& \left(\sum_a q_a^2 \right)^2 \tag{\label{equation-116}}
\end{align*}
$$

where $q_a \in [0,1]$ for all $a$. On the other hand, it follows from $\eqref{equation-115}$ that

$$
\begin{equation*}
  \sum_a q_a = \norm{\Psi} = 1
\tag{\label{equation-117}}
\end{equation*}
$$

Together, $\eqref{equation-116}$ and $\eqref{equation-117}$ imply that there can be only on $\bar{a} = 1$ with $q_{\bar{a}} = 1$ and else $q_a = 0$ for all $a \neq \bar{a}$ must hold. Consequently, $\eqref{equation-118}$ becomes

$$
  \hat{\rho}_A = \ket{e_{\bar{a}}} \bra{e_{\bar{a}}}, \quad \hat{\rho}_B = \ket{f_{\bar{a}}}\bra{f_{\bar{a}}}
$$

and $\eqref{equation-115}$ implies $\ket{\Psi} = \ket{e_{\bar{a}}}\otimes\ket{f_{\bar{a}}}$.
</details>
</MathBox>

<MathBox title='Separability criterion for pure states' boxType='theorem'>
A pure state $\ket{\Psi}\in\mathcal{H}_A \otimes\mathcal{H}_B$ is separable if and only if $\hat{\rho}_X (\Psi)$ is pure for all $X\in\set{A,B}$. Or, equivalently, $\ket{\Psi}$ is entangled if and only if $\hat{\rho}_X (\Psi)$ is a true mixture for any $X\in\set{A,B}$.

<details>
<summary>Proof</summary>

It suffices to prove only the first statement, since the second is equivalent.

**($\implies$):** Let $\ket{\Psi}$ be separable. Then we know from Theorem $\ref{theorem-1}$ that there exist $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$ with $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}$. Because

$$
\begin{align*}
  1 =& \norm{\Psi} = \sqrt{\braket{\Psi|\Psi}} \\
  =& \sqrt{\braket{\varphi|\varphi}}\sqrt{\braket{\psi|\psi}} \\
  =& \norm{\varphi}\cdot\norm{\psi}
\end{align*}
$$

we must have $\norm{\varphi} \neq 0 \neq \norm{\psi}$. We define the unit vectors $\ket{e_0} := \frac{\ket{\varphi}}{\norm{\varphi}}$ and $\ket{f_0} := \frac{\ket{\psi}}{\norm{\psi}}$ and augment them by suitable vectors in order to form the orthornomal bases

$$
\begin{align*}
  &\Set{\ket{e_0} := \frac{\ket{\varphi}}{\norm{\varphi}}, \ket{e_1}, \dots} \subset\mathcal{H}_A \\
  &\Set{\ket{f_0} := \frac{\ket{\psi}}{\norm{\psi}}, \ket{f_1}, \dots} \subset\mathcal{H}_B \\
\end{align*}
$$

such that

$$
\begin{align*}
  \ket{\Psi} =& \ket{\varphi}\otimes\ket{\psi} \\
  =& \norm{\varphi}\cdot\norm{\psi} \ket{e_0} \otimes\ket{f_0} \\
  =& \sum_{a,b} \Psi_{a,b} \ket{e_a} \otimes\ket{f_b}
\end{align*}
$$

where

$$
  \Psi_{ab} = \begin{cases}
    \norm{\varphi}\cdot\norm{\psi} = 1, \quad& a = 0 = b \\
    0, \quad& \text{else}
  \end{cases}
$$

Thus, we have

$$
\begin{align*}
  \hat{\rho}_A (\Psi) =& \sum_{a_1, a_2, b} \Psi_{a_1 b} \Psi_{a_2 b}^* \ket{e_{a_2}} \bra{e_{a_1}} \\
  =& \norm{\varphi}\cdot\norm{\psi} \ket{e_0} \bra{e_0} \\
  =& \ket{e_0} \bra{e_0}
\end{align*}
$$

which as a rank-one projection onto a one-dimensional subspace is a pure state. Consequently, it satisfies $\hat{\rho}_A (\Psi)^2 = \ket{e_0}\braket{e_0|e_0}\bra{e_0} = \hat{\rho}_A (\Psi)$. Similarly, it follows that $\hat{\rho}_B (\Psi) = \ket{f_0} \bra{f_0}$, proving that $\hat{\rho}_B (\Psi)$ is a pure state as well.

**($\impliedby$):** Let $\hat{\rho}_A (\Psi)$ be a pure state. Then there exists a unit vector $\ket{\varphi}\in\mathcal{H}_A$ such that $\hat{\rho}_A (\Psi) = \ket{\varphi}\bra{\varphi}$. This density operator $\hat{\rho}_A (\Psi)$ has a single eigenvector with eigenvalue $1$ and a degenerate eigenvalue $0$. According to the Schmidt decomposition, the vector $\ket{\Psi}$ then has the form $\ket{\Psi} = \ket{\varphi}\otimes\ket{\psi}$ with unit vectors $\ket{\varphi}\in\mathcal{H}_A$ and $\ket{\psi}\in\mathcal{H}_B$. The same argument apply if $\hat{\rho}_B (\Psi)$ is assumed as a pure state.
</details>
</MathBox>

Two systems $\mathcal{S}_1$ and $\mathcal{S}_2$ are entangled with respect to a certain degree of freedom if their total state $\ket{\Psi}_{12}$, relative to that degree of freedom, cannot be factored into a product of individual states, i.e. $\ket{\Psi}_{12} = \ket{\psi}_1 \otimes\ket{\varphi}_2$.

In simpler terms, an entangled state describes a situation where the quantum state of the entire system cannot be separated into independent states for each subsystem. This means that the subsystems are not probabilistically independent, and the measurement outcomes of one system can affect the other, even when they are spatially separated.

It's important to note that entanglement implies superposition, but the reverse is not true. In other words, while entangled states always involve superposition, not all superpositions are necessarily entangled.

On the other hand, a state $\hat{\rho}$ is separable (i.e., non-entangled) if it can be written as a statistical mixture of product states:

$$
  \hat{\rho} = \sum_j w_j \hat{\rho}_1^{(j)} \otimes \hat{\rho}_2^{(j)}
$$

where $w_j \geq 0$ and $\sum_j w_j = 1$ with the $w_j$ representing probabilities of the different product states $\hat{\rho}_1^{(j)}$ and $\hat{\rho}_2^{(j)}$ for subsystems $\mathcal{S}_1$ and $\mathcal{S}_2$ respectively. In such a separable state, the subsystems are described by independent statistical mixtures, and no non-classical correlations (like entanglement) exist between them.

### Bell basis

The Bell basis forms an orthonormal basis for the four-dimensional Hilbert space ${}^\P \mathcal{H}^{\otimes 2}$ and consists of the Bell states

$$
\begin{align*}
  \ket{\Phi^\pm} :=& \frac{1}{\sqrt{2}} \left(\ket{00} \pm \ket{11}\right) \\
  \ket{\Psi^\pm} :=& \frac{1}{\sqrt{2}} \left(\ket{01} \pm \ket{10}\right) 
\end{align*}
$$

The Bell basis describe a maximally entangled system.

<details>
<summary>Details</summary>

To see that the Bell basis orthonormal we verify that the basis vectors are normalized and orthogonal.

**Normalization**

Computing the norm of $\ket{\Phi^\pm}$

$$
\begin{align*}
  \braket{\Phi^\pm |\Phi^\pm} =& \frac{1}{2} \braket{00 \pm 11|00 \pm 11} \\
  =& \frac{1}{2} \left(\braket{00|00} \pm \braket{11|00} \pm \braket{00|11} + \braket{11|11}\right) \\
  =& \frac{1}{2} (\underbrace{\braket{0|0}}_{=1}\braket{0|0} \pm \underbrace{\braket{1|0}}_{=0} \braket{1|0} \pm \underbrace{\braket{0|1}}_{=0} \braket{0|1} + \underbrace{\braket{1|1}}_{=1} \braket{1|1}) \\
  =& 1
\end{align*}
$$

Computing the norm of $\ket{\Psi^\pm}$

$$
\begin{align*}
  \braket{\Psi^\pm |\Psi^\pm} =& \frac{1}{2} \braket{01 \pm 10|01 \pm 10} \\
  =& \frac{1}{2} \left(\braket{01|01} \pm \braket{01|10} \pm \braket{10|01} + \braket{10|10}\right) \\
  =& \frac{1}{2} (\underbrace{\braket{0|0}\braket{1|1}}_{=1} \pm \underbrace{\braket{0|1} \braket{1|0}}_{=0} \pm \underbrace{\braket{1|0}\braket{0|1}}_{=0} + \underbrace{\braket{1|1}\braket{0|0}}_{=1}) \\
  =& 1
\end{align*}
$$

**Orthogonality**

Computing the inner product of $\braket{\Phi^+|\Phi^-}$

$$
\begin{align*}
  \braket{\Phi^+|\Phi^-} =& \frac{1}{2}\braket{00 + 11|00 - 11} \\
  =& \frac{1}{2}\left(\braket{00|00} - \braket{00|11} + \braket{11|00} - \braket{11|11}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{0|0}}_{=1} - \underbrace{\braket{0|1}\braket{0|1}}_{=0} + \underbrace{\braket{1|0}\braket{1|0}}_{=0} - \underbrace{\braket{1|1}\braket{1|1}}_{=1}) \\
  =& 0
\end{align*}
$$

Computing the inner product $\braket{\Psi^+|\Psi^-}$

$$
\begin{align*}
  \braket{\Psi^+|\Psi^-} =& \frac{1}{2}\braket{01 + 10|01 - 10} \\
  =& \frac{1}{2}\left(\braket{01|01} - \braket{01|10} + \braket{10|01} - \braket{10|10}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{1|1}}_{=1} - \underbrace{\braket{0|1}\braket{1|0}}_{=0} + \underbrace{\braket{1|0}\braket{0|1}}_{=0} - \underbrace{\braket{1|1}\braket{0|0}}_{=1}) \\
  =& 0
\end{align*}
$$

Computing the inner product $\braket{\Phi^\pm|\Psi^\pm}$

$$
\begin{align*}
  \braket{\Phi^\pm|\Psi^\pm} =& \frac{1}{2}\braket{00 \pm 11|01 \pm 10} \\
  =& \frac{1}{2}\left(\braket{00|01} \pm \braket{00|10} \pm \braket{11|01} + \braket{11|10}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{0|1}}_{=0} \pm \underbrace{\braket{0|1}\braket{0|0}}_{=0} \pm \underbrace{\braket{1|0}\braket{1|1}}_{=0} + \underbrace{\braket{1|1}\braket{1|0}}_{=0}) \\
  =& 0
\end{align*}
$$

Computing the inner product of $\braket{\Phi^\mp|\Psi^\pm}$

$$
\begin{align*}
  \braket{\Phi^\mp|\Psi^\pm} =& \frac{1}{2}\braket{00 \mp 11|01 \pm 10} \\
  =& \frac{1}{2}\left(\braket{00|01} \pm \braket{00|10} \mp \braket{11|01} - \braket{11|10}\right) \\
  =& \frac{1}{2}(\underbrace{\braket{0|0}\braket{0|1}}_{=0} \pm \underbrace{\braket{0|1}\braket{0|0}}_{=0} \mp \underbrace{\braket{1|0}\braket{1|1}}_{=0} - \underbrace{\braket{1|1}\braket{1|0}}_{=0}) \\
  =& 0
\end{align*}
$$
</details>

The spin operators $\hat{\sigma}_j^{(A)} \otimes \hat{\sigma}_j^{(B)}$ act on the Bell basis of the composite system ${}^\P \mathcal{H}_{AB} = {}^\P \mathcal{H} \otimes {}^\P \mathcal{H}$ in the following way

$$
\begin{align*}
  (\hat{\sigma}_x \otimes \hat{\sigma}_x) \ket{\Phi^\pm} =& \pm\ket{\Phi}, \quad (\hat{\sigma}_x \otimes \hat{\sigma}_x) \ket{\Psi^\pm} =& \pm\ket{\Psi} \\
  (\hat{\sigma}_x \otimes \hat{\sigma}_y) \ket{\Phi^\pm} =& -\ket{\Phi^\mp}, \quad (\hat{\sigma}_x \otimes \hat{\sigma}_y) \ket{\Psi^\pm} =& \pm\ket{\Psi^\pm} \\
  (\hat{\sigma}_z \otimes \hat{\sigma}_z) \ket{\Phi^\pm} =& \ket{\Phi}, \quad (\hat{\sigma}_z \otimes \hat{\sigma}_z) \ket{\Psi^\pm} =& -\ket{\Psi}
\end{align*}
$$

<details>
<summary>Details</summary>

Calculating $(\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Phi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Phi^\pm} =& (\hat{\sigma}_x \otimes \hat{\sigma}_x) \frac{1}{\sqrt{2}}(\ket{00} \pm\ket{11}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \otimes \hat{\sigma}_x)(\ket{0} \otimes \ket{0} \pm \ket{1} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \ket{0} \otimes \hat{\sigma}_x \ket{0} \pm \hat{\sigma}_x \ket{1} \otimes \hat{\sigma}_x \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\ket{1} \otimes \ket{1} \pm \ket{0} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\ket{11}\pm\ket{00}) = \pm\ket{\Phi}
\end{align*}
$$

Calculating $(\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Psi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_x \otimes \hat{\sigma}_x)\ket{\Psi^\pm} =& (\hat{\sigma}_x \otimes \hat{\sigma}_x) \frac{1}{\sqrt{2}}(\ket{01} \pm\ket{10}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \otimes \hat{\sigma}_x)(\ket{0} \otimes \ket{1} \pm \ket{1} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_x \ket{0} \otimes \hat{\sigma}_x \ket{1} \pm \hat{\sigma}_x \ket{1} \otimes \hat{\sigma}_x \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\ket{1} \otimes \ket{0} \pm \ket{0} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\ket{10}\pm\ket{01}) = \pm\ket{\Phi^\pm}
\end{align*}
$$

Calculating $(\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Phi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Phi^\pm} =& (\hat{\sigma}_y \otimes \hat{\sigma}_y) \frac{1}{\sqrt{2}}(\ket{00} \pm\ket{11}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \otimes \hat{\sigma}_y)(\ket{0} \otimes \ket{0} \pm \ket{1} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \ket{0} \otimes \hat{\sigma}_y \ket{0} \pm \hat{\sigma}_y \ket{1} \otimes \hat{\sigma}_y \ket{1}) \\
  =& \frac{1}{\sqrt{2}} [i\ket{1} \otimes i\ket{1} \pm (-i\ket{0}) \otimes (-i\ket{0})] \\
  =& \frac{1}{\sqrt{2}} (-\ket{11} \mp \ket{00}) = -\ket{\Phi^\mp}
\end{align*}
$$

Calculating $(\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Psi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_y \otimes \hat{\sigma}_y)\ket{\Psi^\pm} =& (\hat{\sigma}_y \otimes \hat{\sigma}_y) \frac{1}{\sqrt{2}}(\ket{01} \pm\ket{10}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \otimes \hat{\sigma}_y)(\ket{0} \otimes \ket{1} \pm \ket{1} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_y \ket{0} \otimes \hat{\sigma}_y \ket{1} \pm \hat{\sigma}_y \ket{1} \otimes \hat{\sigma}_y \ket{0}) \\
  =& \frac{1}{\sqrt{2}} [i\ket{1} \otimes (-i\ket{0}) \pm (-i\ket{0}) \otimes i\ket{1}] \\
  =& \frac{1}{\sqrt{2}} (\ket{10} \pm \ket{01}) = \pm\ket{\Psi^\pm}
\end{align*}
$$

Calculating $(\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Phi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Psi^\pm} =& (\hat{\sigma}_z \otimes \hat{\sigma}_z) \frac{1}{\sqrt{2}}(\ket{00} \pm\ket{11}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \otimes \hat{\sigma}_z)(\ket{0} \otimes \ket{0} \pm \ket{1} \otimes \ket{1}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \ket{0} \otimes \hat{\sigma}_z \ket{0} \pm \hat{\sigma}_z \ket{1} \otimes \hat{\sigma}_z \ket{1}) \\
  =& \frac{1}{\sqrt{2}} [\ket{0} \otimes \ket{0} \pm (-\ket{1}) \otimes (-\ket{1})] \\
  =& \frac{1}{\sqrt{2}} (\ket{00} \pm \ket{11}) = \ket{\Psi^\pm}
\end{align*}
$$

Calculating $(\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Psi^\pm}$:

$$
\begin{align*}
  (\hat{\sigma}_z \otimes \hat{\sigma}_z)\ket{\Psi^\pm} =& (\hat{\sigma}_z \otimes \hat{\sigma}_z) \frac{1}{\sqrt{2}}(\ket{01} \pm\ket{10}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \otimes \hat{\sigma}_z)(\ket{0} \otimes \ket{1} \pm \ket{1} \otimes \ket{0}) \\
  =& \frac{1}{\sqrt{2}} (\hat{\sigma}_z \ket{0} \otimes \hat{\sigma}_z \ket{1} \pm \hat{\sigma}_z \ket{1} \otimes \hat{\sigma}_z \ket{0}) \\
  =& \frac{1}{\sqrt{2}} [\ket{0} \otimes (-\ket{1}) \pm (-\ket{1}) \otimes \ket{0}] \\
  =& \frac{1}{\sqrt{2}} (-\ket{01} \mp \ket{10}) = -\ket{\Psi^\pm}
\end{align*}
$$
</details>

In the Bell basis, the operators $\hat{\sigma}_x \otimes \hat{\sigma}_x$ and $\hat{\sigma}_z \otimes \hat{\sigma}_z$ have matrix representations

$$
  \hat{\sigma}_x \otimes \hat{\sigma}_x = \left[\begin{smallmatrix} 
    1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{smallmatrix}\right]
  ,\quad 
  \hat{\sigma}_z \otimes \hat{\sigma}_z = \left[\begin{smallmatrix} 
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & -1 & 0 \\
    0 & 0 & 0 & -1
  \end{smallmatrix}\right]
$$

from which it is evident that these operators commute, i.e. $[\hat{\sigma}_x \otimes \hat{\sigma}_x, \hat{\sigma}_z \otimes \hat{\sigma}_z] = 0$.

In a composite system ${}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$, the Bell basis vectors have partial traces

$$
  \hat{\rho}_A (\Phi^\pm) = \hat{\rho}_A (\Psi^\pm) = \frac{1}{2}(\ket{0}_A \bra{0} + \ket{1}_A \bra{1}) = \frac{1}{2}\hat{I}_A
$$

and

$$
  \hat{\rho}_B (\Phi^\pm) = \hat{\rho}_A (\Psi^\pm) = \frac{1}{2}(\ket{0}_B \bra{0} + \ket{1}_B \bra{1}) = \frac{1}{2}\hat{I}_B
$$

<details>
<summary>Details</summary>

In the Bell basis, the partial trace coefficients are

$$
\begin{align*}
  \Phi_{00}^\pm = \pm\Phi_{11}^\pm = \Psi_{01}^\pm = \pm\Psi_{10}^\pm =& \frac{1}{\sqrt{2}} \\
  \Phi_{01}^\pm = \pm\Phi_{10}^\pm = \Psi_{00}^\pm = \pm\Psi_{11}^\pm =& 0
\end{align*}
$$

The partial trace of $\ket{\Phi^\pm}$ over $\mathcal{H}_X$ for $X\in\set{A,B}$ is

$$
\begin{align*}
  \hat{\rho}_X (\ket{\Phi^\pm}) =& (\overline{\Phi_{00}^\pm} \Phi_{00}^\pm + \underbrace{\overline{\Phi_{01}^\pm} \Phi_{01}^\pm}_{=0}) \ket{0}^X \bra{0} \\
  +& (\overline{\Phi_{00}^\pm} \underbrace{\Phi_{10}^\pm}_{=0} + \underbrace{\overline{\Phi_{01}^\pm}}_{=0} \Phi_{11}^\pm) \ket{1}^X \bra{0} \\
  +& (\underbrace{\overline{\Phi_{10}^\pm}}_{=0} \Phi_{00}^\pm + \overline{\Phi_{11}^\pm} \underbrace{\Phi_{01}^\pm}_{=0}) \ket{0}^X \bra{1} \\
  +& (\underbrace{\overline{\Phi_{10}^\pm} \Phi_{10}^\pm}_{=0} + \overline{\Phi_{11}^\pm} \Phi_{11}) \ket{1}^X \bra{1} \\
  =& \frac{1}{2}(\ket{0}^X \bra{0} + \ket{1}^X \bra{1})
\end{align*}
$$

The partial trace of $\ket{\Psi^\pm}$ over $\mathcal{H}_X$ for $X\in\set{A,B}$ is

$$
\begin{align*}
  \hat{\rho}_X (\ket{\Psi^\pm}) =& (\underbrace{\overline{\Psi_{00}^\pm} \Psi_{00}^\pm}_{=0} + \overline{\Psi_{01}^\pm} \Psi_{01}^\pm) \ket{0}^X \bra{0} \\
  +& (\overline{\underbrace{\Psi_{00}^\pm}}_{=0} \Psi_{10}^\pm + \overline{\Psi_{01}^\pm} \underbrace{\Psi_{11}^\pm}_{=0}) \ket{1}^X \bra{0} \\
  +& (\overline{\Psi_{10}^\pm} \underbrace{\Psi_{00}^\pm}_{=0} + \underbrace{\overline{\Psi_{11}^\pm}}_{=0} \Psi_{01}^\pm) \ket{0}^X \bra{1} \\
  +& (\overline{\Psi_{10}^\pm} \Psi_{10}^\pm + \underbrace{\overline{\Psi_{11}^\pm} \Psi_{11}}_{=0}) \ket{1}^X \bra{1} \\
  =& \frac{1}{2}(\ket{0}^X \bra{0} + \ket{1}^X \bra{1})
\end{align*}
$$
</details>

If $\unitvec{n}\in \mathbb{S}^2 \subset\R^3$ is unit vector, then $\ket{\Psi^-}$ can be expressed as

$$
\begin{equation*}
  \ket{\Psi^-} = \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{n}}} \otimes \ket{\downarrow_{\unitvec{n}}} - \ket{\downarrow_{\unitvec{n}}} \otimes \ket{\uparrow_{\unitvec{n}}})
\tag{\label{equation-120}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Recall that in the basis $\Set{\ket{0} = \left[\begin{smallmatrix}1 \\ 0 \end{smallmatrix}\right], \ket{1} = \left[\begin{smallmatrix}0 \\ 1 \end{smallmatrix}\right]}$, a qubit $\ket{\psi}\in {}^\P \mathcal{H} \cong\mathbb{C}^2$ has the general form

$$
  \ket{\psi(\theta,\phi)} := e^{-i\phi/2} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\phi/2} \sin\left(\frac{\theta}{2}\right)
$$

so that

$$
\begin{align*}
  \ket{\uparrow_{\unitvec{n}}} =& e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right)
  \ket{\downarrow_{\unitvec{n}}} =& -e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right)
\end{align*}
$$

Thus

$$
\begin{align*}
  &\ket{\uparrow_{\unitvec{n}}} \otimes \ket{\downarrow_{\unitvec{n}}} - \ket{\downarrow_{\unitvec{n}}} \otimes \ket{\uparrow_{\unitvec{n}}} \\
  =& \left[e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right)\right] \otimes \left[-e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \right] \\
  &- \left[-e^{-i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right)\right] \otimes \left[e^{-i\frac{\phi}{2}} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\frac{\phi}{2}} \sin\left(\frac{\theta}{2}\right) \right] \\
  =& e^{-i\varphi} \cos\left(\frac{\theta}{2}\right) \sin\left(\frac{\theta}{2}\right) \ket{00} + \cos^2\left(\frac{\theta}{2}\right) \ket{01} - \sin^2\left(\frac{\theta}{2}\right) \ket{10} + e^{i\varphi} \cos\left(\frac{\theta}{2}\right)\sin\left(\frac{\theta}{2}\right) \ket{11} \\
  &- \left[-e^{-i\varphi} \cos\left(\frac{\theta}{2}\right) \sin\left(\frac{\theta}{2}\right) \ket{00} - \sin^2\left(\frac{\theta}{2}\right) \ket{01} + \cos^2\left(\frac{\theta}{2}\right) \ket{10} + e^{i\varphi} \cos\left(\frac{\theta}{2}\right)\sin\left(\frac{\theta}{2}\right) \ket{11}\right] \\
  =& \left(\sin^2\left(\frac{\theta}{2}\right) + \cos^2\left(\frac{\theta}{2}\right)\right)\ket{01} - \left(\sin^2\left(\frac{\theta}{2}\right) + \cos^2\left(\frac{\theta}{2}\right)\right)\ket{10} \\
  =& \ket{01} - \ket{10} = \sqrt{2}\ket{\Psi^-}
\end{align*}
$$
</details>

### Entanglement swapping

Entanglement swapping is a phenomenon in which quantum systems become entangled without direct interaction between them. This can be illustrated as follows.

Consider a four-qubit state

$$
  \ket{\Phi}_{ABCD} \in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B \otimes {}^\P \mathcal{H}_C \otimes {}^\P \mathcal{H}_D =: \mathcal{H}_{ABCD}
$$

prepared as a separable product-state of two entangled two-qubit Bell states $\ket{\Psi^-}_{AB} \in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B =: \mathcal{H}_{AB}$ and $\ket{\Psi^-}_{CD} \in {}^\P \mathcal{H}_C \otimes {}^\P \mathcal{H}_D =: \mathcal{H}_{CD}$ such that

$$
\begin{align*}
  \ket{\Phi}_{ABCD} =& \ket{\Psi^-}_{AB} \otimes\ket{\Psi^-}_{CD} \\
  =& \frac{1}{\sqrt{2}}(\ket{01}_{AB} - \ket{10}_{AB}) \otimes \frac{1}{\sqrt{2}}(\ket{01}_{CD} - \ket{10}_{CD}) \\
  =& \frac{1}{2}(\ket{0101} - \ket{0110} - \ket{1001} + \ket{1010}) \\
  =& \frac{1}{2}(\ket{\Psi^+}_{AD} \otimes \ket{\Psi^+}_{BC} - \ket{\Psi^-}^{AD} \otimes \ket{\Psi^-}_{BC} \\
  &- \ket{\Phi^+}_{AD} \otimes \ket{\Phi^+}_{BC} + \ket{\Phi^-}_{AD} \otimes \ket{\Phi^-}_{BC}) 
\end{align*}
$$

Here, systems $A$ and $B$ may have interacted in some way to form the entangled state $\ket{\Psi^-}_{AB}$. Likewise, systems $C$ and $D$ may have interacted to form the entangled state $\ket{\Psi^-}_{CD}$. However, it is possible to prepare the entangled states $\ket{\Psi^-}_{AB}$ and $\ket{\Psi^-}_{CD}$ such that system $A$ has never interacted with either $C$ or $D$. Nevertheless, by suitable measurement in the state $\ket{\Phi}_{ABCD}$ it is possible to create entangled states in the system $AD$ composed of the subsystems $A$ and $D$. 

Since $[\hat{\sigma}_z \otimes \hat{\sigma}_z, \hat{\sigma}_x \otimes \hat{\sigma}_x] = 0$, it follows that the operators

$$
\begin{align*}
  \hat{\Sigma}_z^{(BC)} := \hat{I}_A \otimes \hat{\sigma}_z \otimes \hat{\sigma}_z \otimes \hat{I}_D \\
  \hat{\Sigma}_x^{(BC)} := \hat{I}_A \otimes \hat{\sigma}_x \otimes \hat{\sigma}_x \otimes \hat{I}_D
\end{align*}
$$

commute. Consequently, the corresponding observables, $BC$-spin in the $z$-direction and $BC$-spin in the $x$-direction, can both be measured sharply in a given state. The measurement of the these observables in the state $\ket{\Phi}_{ABCD}$ collapses the $BC$-state state to one of the states $\ket{\Psi^\pm}_{BC}$ or $\ket{\Phi^\pm}_{BC}$, depending on the values observed.

After measurement, the composite system of subsystems $AD$ and $BC$ will always be separable in the Bell basis states in $\mathcal{H}_{AD}$ and $\mathcal{H}_{BC}$. The observed $BC$-state is determined by the pair of measured values for $\hat{\Sigma}_z^{(BC)}$ and $\hat{\Sigma}_x^{(BC)}$, while the qubit-pair $AD$ becomes entangled with the observed $BC$-state. As a result, the qubits $A$ and $D$ are entangled even though they have never interacted directly.

<TableFigure caption="Determination of post-measurement state by measurement of $\hat{\Sigma}_z^{(BC)}$ and $\hat{\Sigma}_x^{(BC)}$ on $\ket{\Phi}_{ABCD}$">
| Measured value of $\hat{\Sigma}_z^{(BC)}$ | Measured value of $\hat{\Sigma}_x^{(BC)}$ | Composite state after measurement | State of subsystem $AD$ after measurement |
| --- | --- | --- | --- |
| $1$ | $1$ | $\ket{\Phi^+}_{AD} \otimes \ket{\Phi^+}_{BC}$ | $\ket{\Phi^+}_{AD}$ |
| $1$ | $-1$ | $\ket{\Phi^-}_{AD} \otimes \ket{\Phi^-}_{BC}$ | $\ket{\Phi^-}_{AD}$ |
| $-1$ | $1$ | $\ket{\Psi^+}_{AD} \otimes \ket{\Psi^+}_{BC}$ | $\ket{\Psi^+}_{AD}$ |
| $-1$ | $-1$ | $\ket{\Phi^-}_{AD} \otimes \ket{\Phi^-}_{BC}$ | $\ket{\Phi^-}_{AD}$ |
</TableFigure>

### Einstein-Podolsky-Rosen (EPR) paradox

In 1935, Albert Einstein, Boris Podolsky and Nathan Rosen (EPR) published a seminal paper arguing that quantum mechanics is incomplete by refuting the following claim:

> **EPR Claim 1:** The quantum mechanical description of a system by its state vector is complete (quantum mechanics is complete).

According to EPR, a physical theory is complete if every element of physical reality has a counterpart in the theory. In other words, physical quantities describing a physical system must correspond to pre-existing elements of reality. In their definition a physical quantity is an element of reality of a system if the value of this quantity can be predicted with certainty without having to interact with the system. From this, they concluded that *incompatible observables* cannot both be elements of reality, because their values cannot be simultaneously predicted with certainty. This statement can be formulated as:

> **EPR Claim 2:** The physical quantities of a system corresponding to two incompatible observables cannot jointly be elements of reality for that system (the values of incompatible observables are not jointly real).

EPR then showed by contraposition that the completeness of a quantum mechanics (*Claim 1*) implies that the values of incompatible observables are not jointly real (*Claim 2*). They argue that if the negation of *Claim 2* were true, the physical quantities corresponding to two incompatible observables of a system were both elements of reality of that system and thus could both be predicted with certainty, implying that quantum mechanics is incomplete, i.e.

$$
  \lnot\text{Claim 2} \implies \lnot\text{Claim 1}
$$

which is logically equivalent to the contraposition

$$
  \text{Claim 1} \implies \text{Claim 2}
$$

EPR then proceeded to prove with the help of entangled states and a 'reasonable definition of reality' that *Claim 1* actually implies the negation *Claim 2*, i.e.

$$
\begin{equation*}
  \text{Claim 1} \implies \lnot\text{Claim 2}
\tag{\label{equation-119}}
\end{equation*}
$$

This contradiction is the EPR paradox. Since both implications cannot be simultaneously true, EPR concluded that *Claim 1* must be false, meaning that quantum mechanics is incomplete. However, repeated experiments have demonstrated that $\eqref{equation-119}$ does not hold, suggesting that the reality of the considered system is 'unreasonable' in the classical sense.

#### Bohm's version of the EPR thought experiment

The following is Bohm's version of the EPR thought experiment used prove $\eqref{equation-119}$. Consider a pair of qubits in described by the entangled Bell state in ${}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$

$$
  \ket{\Phi^+} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{z}}}_A \otimes \ket{\uparrow_{\unitvec{z}}}_B + \ket{\downarrow_{\unitvec{z}}}_A \otimes \ket{\downarrow_{\unitvec{z}}}_B) = \frac{1}{\sqrt{2}}(\ket{00} + \ket{11})
$$

where qubit $A$ is accessible to Alice and qubit $B$ to Bob. Assuming that quantum mechanics is complete (*Claim 1* holds), all predictions can be obtained from the state $\ket{\Phi^+}$. Since

$$
  \ket{\uparrow_{\unitvec{x}}}_A \otimes \ket{\uparrow_{\unitvec{x}}}_B + \ket{\downarrow_{\unitvec{x}}}_A \otimes \ket{\downarrow_{\unitvec{x}}}_B = \ket{00} + \ket{11}
$$

It follows that

$$
\begin{align*}
  \ket{\Phi}^+ =& ket{\uparrow_{\unitvec{z}}}_A \otimes \ket{\uparrow_{\unitvec{z}}}_B + \ket{\downarrow_{\unitvec{z}}}_A \otimes \ket{\downarrow_{\unitvec{z}}}_B \\
  \ket{\uparrow_{\unitvec{x}}}_A \otimes \ket{\uparrow_{\unitvec{x}}}_B + \ket{\downarrow_{\unitvec{x}}}_A \otimes \ket{\downarrow_{\unitvec{x}}}_B
\end{align*}
$$

If Alice measures the observable $\hat{\sigma}_z$ in her subsystem, she effectively measures of $\hat{\sigma}_z \otimes \hat{I}_B$ in the composite system. The eigenvalues of this composite observables are $\pm 1$ with corresponding degenerate eigenspaces

$$
\begin{align*}
  \operatorname{eig}(\hat{\sigma}_z, 1) =& \operatorname{span}\set{\ket{\uparrow_{\unitvec{z}}} \otimes\ket{\psi} : \ket{\psi}\in {}^\P \mathcal{H}_B} \\
  \operatorname{eig}(\hat{\sigma}_z, -1) =& \operatorname{span}\set{\ket{\downarrow_{\unitvec{z}}} \otimes\ket{\psi} : \ket{\psi}\in {}^\P \mathcal{H}_B}
\end{align*}
$$

The projections onto these eigenspaces are

$$
\begin{align*}
  \hat{P}_{z,1} = \ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}} \otimes \hat{I}_B \\
  \hat{P}_{z,-1} = \ket{\downarrow_{\unitvec{z}}} \bra{\downarrow_{\unitvec{z}}} \otimes \hat{I}_B
\end{align*}
$$

which satisfy

$$
\begin{align*}
  \hat{P}_{z,1} =& \ket{\Phi^+} = \frac{1}{\sqrt{2}}\left((\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\otimes\hat{I}_B)(\ket{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}} + \ket{\downarrow_{\unitvec{z}}}\otimes\ket{\downarrow_{\unitvec{z}}}) \right) \\
  =& \frac{1}{\sqrt{2}}(\ket{\uparrow_{\unitvec{z}}} \underbrace{\braket{\uparrow_{\unitvec{z}}|\uparrow_{\unitvec{z}}}}_{=1} \otimes \ket{\uparrow_{\unitvec{z}}} + \ket{\uparrow_{\unitvec{z}}}\underbrace{\braket{\uparrow_{\unitvec{z}}|\downarrow_{\unitvec{z}}}}_{=0} \otimes\ket{\downarrow_{\unitvec{z}}}) \\
  =& \frac{1}{\sqrt{2}} \ket{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}}
\end{align*}
$$

and similarly

$$
  \hat{P}_{z,-1} = \ket{\Phi^+} = \frac{1}{\sqrt{2}}\ket{\downarrow_{\unitvec{z}}}\otimes\ket{\downarrow_{\unitvec{z}}}
$$

with norm

$$
  \norm{\hat{P}_{z,\pm 1}} = \frac{1}{\sqrt{2}}
$$

If Alice measures $\hat{\sigma}_z$ in her subsystem and obtains $1$, the composite system collapses to

$$
\begin{align*}
  \ket{\Psi_{z,1}} :=& \frac{\hat{P}_{z,1}\ket{\Phi^+}}{\norm{\hat{P}_{z,1}\ket{\Phi^+}}} \\
  =& \frac{(\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}{\Norm{(\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}} \\
  =& \ket{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}}
\end{align*}
$$

This means that Bob's qubit is in state

$$
\begin{align*}
  \hat{\rho}_B (\ket{\Psi_{z,1}}\bra{\Psi_{z,1}}) =& \operatorname{tr}_A (\ket{\Psi_{z,1}}\bra{\Psi_{z,1}}) \\
  =& \operatorname{tr}\left((\ket{\uparrow_{\unitvec{z}}} \otimes \ket{\uparrow_{\unitvec{z}}})(\ket{\uparrow_{\unitvec{z}}} \otimes \ket{\uparrow_{\unitvec{z}}}) \right) \\
  =& \operatorname{tr}\left(\ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}}\otimes\ket{\uparrow_{\unitvec{z}}}\bra{\uparrow_{\unitvec{z}}}\right) \\
  =& \underbrace{\operatorname{tr}(\ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}})}_{=1}\ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}} \\
  =& \ket{\uparrow_{\unitvec{z}}} \bra{\uparrow_{\unitvec{z}}}
\end{align*}
$$

which is the density operator of the pure state $\ket{\uparrow_{\unitvec{z}}}$. Hence, after a measurement of $\hat{\sigma}_z$ in which Alice observes the value $1$, Bob's system has to be in the state $\ket{\uparrow_{\unitvec{z}}}$ with sharp eigenvalue $1$. Analogously, if Alice measures $\hat{\sigma}_z$ on her qubit and observes the value $-1$, then the composite system collapses to

$$
\begin{align*}
  \ket{\Psi_{z,-1}} :=& \frac{\hat{P}_{z,1}\ket{\Phi^+}}{\norm{\hat{P}_{z,1}\ket{\Phi^+}}} \\
  =& \frac{(\ket{\downarrow_{\unitvec{z}}}\bra{\downarrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}{\Norm{(\ket{\downarrow_{\unitvec{z}}}\bra{\downarrow_{\unitvec{z}}}\otimes\hat{I}_B)\ket{\Phi^+}}} \\
  =& \ket{\downarrow_{\unitvec{z}}}\otimes\ket{\downarrow_{\unitvec{z}}}
\end{align*}
$$

In this case, Bob's system has to be in the state $\ket{\downarrow_{\unitvec{z}}}$ with eigenvalue $-1$. Consequently,the spin in $z$-direction is an element of reality for Bob's qubit.

If, however, Alice chooses instead to measure $\hat{\sigma}_x$ and observes the value $1$, then the composite system collpases to 

$$
\begin{align*}
  \ket{\Psi_{x,-1}} :=& \frac{\hat{P}_{x,1}\ket{\Phi^+}}{\norm{\hat{P}_{x,1}\ket{\Phi^+}}} \\
  =& \frac{(\ket{\downarrow_{\unitvec{x}}}\bra{\downarrow_{\unitvec{x}}}\otimes\hat{I}_B)\ket{\Phi^+}}{\Norm{(\ket{\downarrow_{\unitvec{x}}}\bra{\downarrow_{\unitvec{x}}}\otimes\hat{I}_B)\ket{\Phi^+}}} \\
  =& \ket{\downarrow_{\unitvec{x}}}\otimes\ket{\downarrow_{\unitvec{x}}}
\end{align*}
$$

In this case Bob's qubit will be in the state $\ket{\uparrow_{\unitvec{x}}}$ with sharp eigenvalue $1$. Similarly, if Alice measures $\hat{\sigma}_x$ and observes the value $-1$, then Bob's qubit after a measurement will be in the state $\ket{\downarrow_{\unitvec{x}}}$ with sharp eigenvalue $-1$. Thus, if Alice measures $\hat{\sigma}_x$ on her qubit, then for Bob's qubit, the spin in $x$-direction is an element of reality.

Regardless in which direction Alice measures the spin of her qubit, the corresponding spin component of Bob's qubit can always be predicted with certainty. This means that Alice's choice of measuring the spin of her qubit in $z$- or $x$-direction determines whether the spin in $z$- or $x$-direction is an element of its reality for Bob's qubit. Importantly, this also holds when Alice and Bob are separated in such a way that no signal from Alice traveling at the speed of light could inform Bob's qubit of Alice's measurement choice in time. 

EPR argued that noe reasonable definition of reality should permit measurement choices at one loccation to instantenously determine elements of reality at another, spatially separated location. If one accepts this argument then $\eqref{equation-119}$ would be proven, implying that quantum mechanics is incomplete. One resolution could be the existence of hidden variables, additional parameters determining the system's behaviour but not reveal by a quantum state vector.

However, experiments have shown that the physical reality behaves in an 'unreasonable' manner according to EPR's crieria. Specifically, local measurements by Alice do appear to influence Bob's system instantaneously, even though no signal is transmitted. This phenomenon, called quantum non-locality, suggests that nature does not adhere to classical locality constraints, challenging the classical notion of independent reality.

### Bell inequality

Bell's inequality is based on the assumption that the results of spin measurements on two qubits can be represented as discrete random variables of a joint distribution. This implies that the observed spin values are predetermined by hidden variables. However, Bell's inequality is violated for certain entangled states. Consequently, the assumption of a joint distribution for spin values of two qubits in certain entangled states is invalid, which invalidates the equivalent assumption of hidden variables.

Consider a pair of qubits in the Hilbert space ${}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$ prepared in the Bell state

$$
  \ket{\Psi^-} = \frac{1}{\sqrt{2}}(\ket{01} - \ket{10})
$$

where qubit $A$ is sent to Alice and qubit $B$ to Bob. Alice and Bob can perform a spin measurement in any direction they choose, represented by a unit vector $\unitvec{n}\in\mathbb{S}^2 \subset \R^3$ given by

$$
  \unitvec{n}(\theta, \phi) = \begin{bmatrix} 
    \sin(\theta)\cos(\phi) \\ 
    \sin(\theta)\sin(\phi) \\
    \cos(\theta)
  \end{bmatrix}
$$

On their respective qubits, Alice and Bob measures the observables

$$
\begin{align*}
  \hat{\Sigma}_{\unitvec{n}_A}^{(A)} =& \unitvec{n}_A \cdot\boldsymbol{\sigma} \\
  \hat{\Sigma}_{\unitvec{n}_B}^{(B)} =& \unitvec{n}_B \cdot\boldsymbol{\sigma}
\end{align*}
$$

The respective measurement results, denoted $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$, are discrete random variables parametrized by $\hat{\mathbf{n}_A}$ and $\hat{\mathbf{n}_B}$, respectively, which can only take values in $\set{\pm 1}$.

The expectation value of the joint measurement $\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}$ in the Bell state $\ket{\Psi^-}$ is given by

$$
\begin{equation*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} = -\unitvec{n}_A \cdot \unitvec{n}_B
\tag{\label{equation-129}}
\end{equation*}
$$

<details>
<summary>Details</summary>

From $\eqref{equation-120}$, we can write $\ket{\Psi^-}$ as

$$
  \ket{\Psi^-} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}})
$$

with $\hat{\Sigma}_{\unitvec{n}_A}^{(A)} = \unitvec{n}_A \cdot\boldsymbol{\sigma}$ and $\hat{\Sigma}_{\unitvec{n}_B}^{(B)} = \unitvec{n}_B \cdot\boldsymbol{\sigma}$ it then follows that

$$
\begin{align*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} =& \braket{\Psi^- |\unitvec{n}_A \cdot\boldsymbol{\sigma} \otimes \unitvec{n}_B \cdot \boldsymbol{\sigma}|\Psi^-} \\
  =& \frac{1}{\sqrt{2}} \braket{\Psi^- | \underbrace{\unitvec{n}\cdot\boldsymbol{\sigma} \ket{\uparrow}_{\unitvec{n}_A}}_{=\ket{\uparrow_{\unitvec{n}_A}}} \otimes \unitvec{n}_B \cdot\boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}_A}} - \underbrace{\unitvec{n}_A \cdot \boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}}}_{=-\ket{\downarrow_{\unitvec{n}_A}}} \otimes \unitvec{n}_B \cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}} \\
  =& \frac{1}{\sqrt{2}} \Braket{\Psi^-|(\ket{\uparrow_{\unitvec{n}_A}} \otimes \unitvec{n}_B \cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}} + \ket{\downarrow_{\unitvec{n}_A}} \otimes \unitvec{n}_B \cdot \ket{\uparrow_{\unitvec{n}_A}})}
\end{align*}
$$

In the last term we can use the identity $\eqref{equation-109}$ to get

$$
\begin{align*}
  \unitvec{n}_B \cdot\boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}_A}} =& \unitvec{n}_B \cdot (-\unitvec{n}_A \cdot\boldsymbol{\sigma}) \ket{\downarrow_{\unitvec{n}_A}} \\
  =& -(\unitvec{n}_B \cdot\boldsymbol{\sigma})(\unitvec{n}_A \cdot\boldsymbol{\sigma}) \ket{\downarrow_{\unitvec{n}_A}} \\
  =& -\left((\unitvec{n}_B \cdot \unitvec{n}_A)\mathbf{I}_2 + i(\unitvec{n}_A \times \unitvec{n}_B) \cdot \boldsymbol{\sigma} \right)\ket{\downarrow_{\unitvec{n}_A}}
\end{align*}
$$

Analogously, we show that

$$
  \unitvec{n}_B \cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}_A}} = \left((\unitvec{n}_B \cdot \unitvec{n}_A)\mathbf{I}_2 + i(\unitvec{n}_A \times \unitvec{n}_B) \cdot \boldsymbol{\sigma} \right)\ket{\uparrow_{\unitvec{n}_A}}
$$

Substituting back gives

$$
\begin{align*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} =& \frac{-\unitvec{n}_B \cdot\unitvec{n}_A}{\sqrt{2}} \Braket{\Psi^-|(\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}})} \\
  &- \frac{i}{\sqrt{2}} \Braket{\Psi^- |(\ket{\uparrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}})} \\
  +& \frac{i}{\sqrt{2}} \Braket{\Psi^- |(\ket{\downarrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}})} \\
  =& -\unitvec{n}_B \cdot \unitvec{n}^A \underbrace{\braket{\Psi^-|\Psi^-}}_{=1} \\
  &- \frac{i}{2} \Braket{\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}} | \ket{\uparrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}_A}}} \\
  &+ \frac{i}{2} \Braket{\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}} | \ket{\downarrow_{\unitvec{n}_A}} \otimes (\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}} \\
  =& -\unitvec{n}_B \cdot \unitvec{n}_A \\
  &- \frac{i}{2} \left(\Braket{\ket{\downarrow_{\unitvec{n}_A}}|(\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}_A}}} + \Braket{\ket{\uparrow_{\unitvec{n}_A}}|(\unitvec{n}_B \times \unitvec{n}_A)\cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}_A}}} \right)
\end{align*}
$$

To prove $\Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} = -\unitvec{n}_B \cdot \unitvec{n}_A$, we show that in general for $\unitvec{m}, \unitvec{n} \in\mathbb{S}^2 \subset\R^3$

$$
\begin{equation*}
  \braket{\downarrow_{\unitvec{n}} |\unitvec{m} \cdot\boldsymbol{\sigma} |\downarrow_{\unitvec{n}}} + \braket{\uparrow_{\unitvec{n}} |\unitvec{m} \cdot\boldsymbol{\sigma} |\downarrow_{\unitvec{n}}} = 0
\tag{\label{equation-121}}
\end{equation*}
$$

Consider first $\unitvec{m}\cdot\ket{\uparrow_{\unitvec{n}}}$ in the orthonormal basis $\set{\ket{\uparrow_{\unitvec{n}}}, \ket{\downarrow_{\unitvec{n}}}}$:

$$
\begin{equation*}
  \unitvec{m} \cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}}} = a_{\unitvec{m}} \ket{\uparrow_{\unitvec{n}}} + b_{\unitvec{m}} \ket{\downarrow_{\unitvec{n}}}
\tag{\label{equation-124}}
\end{equation*}
$$

If $b_{\unitvec{m}} = 0$, it follows that

$$
\begin{equation*}
  \unitvec{m} \cdot \ket{\uparrow_{\unitvec{n}}} = a_{\unitvec{m}} \ket{\uparrow_{\unitvec{n}}}
\tag{\label{equation-122}}
\end{equation*}
$$

and $a_{\unitvec{m}}$ is an eigenvalue of $\unitvec{m}\cdot\boldsymbol{\sigma}$ with eigenvector $\ket{\uparrow_{\unitvec{n}}}$. From $\eqref{equation-109}$, it follows that $(\unitvec{m}\cdot\boldsymbol{\sigma})^2 = \mathbf{I}_2$, and thus the eigenvalues of $\unitvec{m}\cdot\boldsymbol{\sigma}$ are $\pm 1$. The eigenspace for the eigenvalue $-a_{\unitvec{m}}$ is one-dimensional and orthogonal to the eigenvector $\ket{\downarrow_{\unitvec{n}}}$ for the eigenvalue $a_{\unitvec{m}}$. Hence,

$$
\begin{equation*}
  \unitvec{m} \cdot \boldsymbol{\sigma} \ket{\downarrow_{\unitvec{n}}} = -a_{\unitvec{m}} \ket{\downarrow_{\unitvec{n}}}
\tag{\label{equation-123}}
\end{equation*}
$$

and $\eqref{equation-121}$ follows from $\eqref{equation-122}$ and $\eqref{equation-123}$. In case $b_{\unitvec{m}} \neq 0$, we obtain $\eqref{equation-124}$ because of $\braket{\ket{\downarrow_{\unitvec{n}}}|\ket{\uparrow_{\unitvec{n}}}} = 0$ giving

$$
\begin{equation*}
  \braket{\downarrow_{\unitvec{n}}|\unitvec{m}\cdot\boldsymbol{\sigma}|\downarrow_{\unitvec{n}}}
\tag{\label{equation-125}}
\end{equation*}
$$

On the other hand, because of $(\unitvec{m}\cdot\boldsymbol{\sigma})^2 = \mathbf{I}_2$ it follows from $\eqref{equation-124}$ also that

$$
\begin{align*}
  \ket{\uparrow_{\unitvec{n}}} =& a_{\unitvec{m}} \unitvec{m}\cdot\boldsymbol{\sigma} \ket{\uparrow_{\unitvec{n}}} + b_{\unitvec{m}} \unitvec{m}\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}}} \\
  =& a_{\unitvec{m}} \left(a_{\unitvec{m}} \ket{\uparrow_{\unitvec{n}}} + b_{\unitvec{m}} \right) + b_{\unitvec{m}} \unitvec{m}\cdot\boldsymbol{\sigma}\ket{\downarrow_{\unitvec{n}}}
\end{align*}
$$

Taking the inner product on both side with $\bra{\downarrow_{\unitvec{n}}}$ yields

$$
\begin{equation*}
  \braket{\downarrow_{\unitvec{n}}|\unitvec{m}\cdot\boldsymbol{\sigma}|\downarrow_{\unitvec{n}}} = -a_{\unitvec{m}}
\tag{\label{equation-126}}
\end{equation*}
$$

since $\braket{\downarrow_{\unitvec{n}}|\uparrow_{\unitvec{n}}} = 0$. From $\eqref{equation-125}$ and $\eqref{equation-126}$ follows $\eqref{equation-121}$.
</details>

In particular, when Alice and Bob measure along the same direction $\unitvec{n}_A = \unitvec{n} = \unitvec{n}_B$, the expectation value becomes

$$
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_B}^{(B)}}_{\Psi^-} = -1
$$

Now, suppose now that the properties of each qubit are determined by a hidden variable $\omega\in\Omega$. We assume that this hidden variable provides a complete description of the qubits, meaning that the measured spin values $s_{\unitvec{n}_A}^{(A)} (\omega)$ and $s_{\unitvec{n}_B}^{(B)} (\omega)$ in any directions $\unitvec{n}_A$ and $\unitvec{n}_B$ are fully determined by $\omega$. 

If Alice knew the value of $\omega$ for her qubit, she could determine the function $s_{\unitvec{n}_A}^{(A)} (\omega)$ by sufficient measurements, thereby predicting the result of spin measurements on her qubit. The same applies for Bob. However, since $\omega$ is uknown, it is referred to as a hidden variable. We assume that each value of $\omega\in\Omega$ occurs with a probability $0 \leq \mathbb{P}(\omega) \leq 1$, satisfying

$$
  \mathbb{P}(\Omega) = \sum_\Omega \d\mathbb{P}(\omega) = 1
$$

Altogether, this means that the spin measurement values $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$ are random variables on a probability space $(\Omega, \mathscr{A}, \mathbb{P})$, parametrized by unit vectors $\unitvec{n}_A$ and $\unitvec{n}_B$. These random variables depend on the quantum state, which in our case is $\ket{\Psi^-}$. Since we consider $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$ as the measured spin values for the particles in the state $\ket{\Psi^-}$, we require that their expectation value satisfies

$$
  \mathbb{E}(s_{\unitvec{n}_A}^{(A)} s_{\unitvec{n}_B}^{(B)}) = \sum_{(s_1,s_2)\in\set{\pm 1, \pm 1}} s_1 s_2 \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = s_1 \land s_{\unitvec{n}_B}^{(B)} = s_2} = -1
$$

<MathBox title="Bell's inequality" boxType='theorem'>
Let $s_{\unitvec{n}}^{(A)}$ and $s_{\unitvec{n}}^{(B)}$ be two discrete random variables on a probability space $(\Omega,\mathscr{A},\mathbb{P})$ that are parametrized by unit vectors $\unitvec{n}\in\R^3$ and take values in $\set{\pm 1}$, i.e. for $X \in \set{A,B}$

$$
\begin{align*}
  s^{(X)} : \mathbb{S}^2 \times \Omega \to& \set{\pm 1} \\
  (\unitvec{n}, \omega) \mapsto& s_{\unitvec{n}}^{(X)}
\end{align*}
$$

and which additionally satisfy

$$
\begin{equation*}
  \mathbb{E}\left(s_{\unitvec{n}}^{(A)} s_{\unitvec{n}}^{(B)}\right) = -1,\; \forall \unitvec{n}\in\mathbb{S}^2 \subset\R^3
\tag{\label{equation-127}}
\end{equation*}
$$

Then for arbitrary unit vectors $\unitvec{n}^{(i)}$ with $i\in\set{1,2,3}$ the Bell inequality

$$
\begin{equation*}
  \left|\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(B)}\right) - \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right)\right| - \mathbb{E}\left(s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right) \leq 1
\tag{\label{equation-128}}
\end{equation*}
$$

holds.

<details>
<summary>Proof</summary>

From $\eqref{equation-127}$ it follows for arbitrary directions $\unitvec{n}$ that

$$
\begin{align*}
  -1 =& \mathbb{E}\left(s_{\unitvec{n}}^{(A)} s_{\unitvec{n}}^{(B)}\right) = \underbrace{\mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = s_{\unitvec{n}}^{(B)}}}_{1 - \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}}} - \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}} \\
  =& 1 - 2\mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}}
\end{align*}
$$

and thus

$$
  \mathbb{P}\Set{s_{\unitvec{n}}^{(A)} = -s_{\unitvec{n}}^{(B)}} = 1
$$

Furthermore, we get

$$
\begin{align*}
  \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(B)}\right) - \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right) =& -\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)}\right) + \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right) \\
  =& \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} (s_{\unitvec{n}^{(3)}}^{(A)} - s_{\unitvec{n}^{(2)}}^{(A)})\right) \\
  \underbrace{=}_{(s_{\unitvec{n}^{(2)}}^{(A)})^2 = 1}& \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} \left[(s_{\unitvec{n}^{(3)}}^{(A)})^2 s_{\unitvec{n}^{(2)}}^{(A)} - s_{\unitvec{n}^{(2)}}^{(A)}\right]\right) \\
  =& \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)} (s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1)\right)
\end{align*}
$$

This implies the claimed inequality as follows:

$$
\begin{align*}
  \left|\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(B)}\right) - \mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right)\right| =& \left|\mathbb{E}\left(s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)} (s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1 )\right)\right| \\
  \leq& \mathbb{E}\left(\left|s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)} (s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1)\right|\right) \\
  =& \mathbb{E}\left(\left|s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)}\right|\cdot\left|s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} - 1)\right|\right) \\
  \underbrace{=}_{|s_{\unitvec{n}^{(1)}}^{(A)} s_{\unitvec{n}^{(2)}}^{(A)}| = 1}& \mathbb{E}\left(\left|1 - s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right|\right) \\
  \underbrace{=}_{s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)} \leq 1}& \mathbb{E}\left(1 - s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right) \\
  =& 1 - \mathbb{E}\left(s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(A)}\right) \\
  =& 1 + \mathbb{E}\left(s_{\unitvec{n}^{(2)}}^{(A)} s_{\unitvec{n}^{(3)}}^{(B)}\right)
\end{align*}
$$
</details>
</MathBox>

If we measure the spin in the directions

$$
  \unitvec{n}^{(1)} = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}, \quad \unitvec{n}^{(2)} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ 0 \\ \frac{1}{\sqrt{2}} \end{bmatrix}, \quad \unitvec{n}^{(3)} = \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}
$$

and substitute the corresponding quantum mechanical expectation values into $\eqref{equation-128}$, we obtain

$$
\begin{align*}
  &\left| \Braket{\hat{\Sigma}_{\unitvec{n}^{(1)}}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}^{(2)}}^{(B)}}_{\Psi^-} - \Braket{\hat{\Sigma}_{\unitvec{n}^{(1)}}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}^{(3)}}^{(B)}}_{\Psi^-}  \right| - \Braket{\hat{\Sigma}_{\unitvec{n}^{(2)}}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}^{(3)}}^{(B)}}_{\Psi^-} \\
  =& |\unitvec{n}^{(1)} \cdot \unitvec{n}^{(3)} - \unitvec{n}^{(1)} \cdot \unitvec{n}^{(3)}| + \unitvec{n}^{(2)} \cdot \unitvec{n}^{(3)} \\
  =& \left|-\frac{1}{\sqrt{2}}\right| + \frac{1}{\sqrt{2}} = \sqrt{2} > 1
\end{align*}
$$

which means that quantum mechanics predicts a violation of the Bell inequality for the state $\ket{\Psi^-}$ in the given directions.

Since hidden variable theories rely on joint probability distributions, it is natural to analyze correlations. For arbitrary unitvectors $\unitvec{n}_A$ and $\unitvec{n}_B$ we find that

$$
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{I}_B}_{\Psi^-} = 0 = \Braket{\hat{I}_A \otimes \hat{\Sigma}_{\unitvec{n}_A}^{(A)}}
$$

<details>
<summary>Proof</summary>

From $\eqref{equation-120}$, we express $\ket{\Psi^-}$ in terms of the basis defined by $\unitvec{n} = \unitvec{n}_A$

$$
  \ket{\Psi^-} = \frac{1}{\sqrt{2}} = \frac{1}{\sqrt{2}} (\ket{\uparrow_{\unitvec{n}_A}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \ket{\downarrow_{\unitvec{n}_A}} \otimes \ket{\uparrow_{\unitvec{n}_A}})
$$

With $\hat{\Sigma}_{\unitvec{n}_A}^{(A)} = \unitvec{n}_A \cdot\boldsymbol{\sigma}$ we have

$$
\begin{align*}
  \Braket{\hat{\Sigma}_{\unitvec{n}_A}^{(A)} \otimes \hat{I}_B}_{\Psi^-} =& \braket{\Psi^- |\unitvec{n}_A \cdot\boldsymbol{\sigma} \otimes \hat{I}_B |\Psi^-} \\
  =& \frac{1}{\sqrt{2}} \braket{\Psi^-|\underbrace{\unitvec{n}_A \cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}}_{=\ket{\uparrow_{\unitvec{n}_A}}} \otimes \ket{\downarrow_{\unitvec{n}_A}} - \underbrace{\unitvec{n}_A \cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{n}_A}}}_{=-\ket{\downarrow_{\unitvec{n}_A}}} \otimes \ket{\uparrow_{\unitvec{n}_A}}} \\
  =& \frac{1}{\sqrt{2}} \braket{\Psi^-| \uparrow_{\unitvec{n}_A} \otimes \downarrow_{\unitvec{n}_A} + \downarrow_{\unitvec{n}_A} \otimes \uparrow_{\unitvec{n}_A}} \\
  =& \frac{1}{2} \braket{\uparrow_{\unitvec{n}_A} \otimes \downarrow_{\unitvec{n}_A} - \downarrow_{\unitvec{n}_A} \otimes \uparrow_{\unitvec{n}_A} | \uparrow_{\unitvec{n}_A} \otimes \downarrow_{\unitvec{n}_A} + \downarrow_{\unitvec{n}_A} \otimes \uparrow_{\unitvec{n}_A}} \\
  =& 0
\end{align*}
$$

where we used $\braket{\uparrow_{\unitvec{n}_A} | \uparrow_{\unitvec{n}_A}} = 1$ and $\braket{\uparrow_{\unitvec{n}_A} | \downarrow_{\unitvec{n}_A}} = 0$ in the last step. A similar argument shows that

$$
  \Braket{\hat{I}_A \otimes \hat{\Sigma}_{\unitvec{n}_A}^{(A)}}_{\Psi^-} = 0
$$
</details>

For the hidden variables $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$, the corresponding expectation value must satisfy

$$
  \mathbb{E}\left(s_{\unitvec{n}_A}^{(A)}\right) = 0 = \mathbb{E}\left(s_{\unitvec{n}_A}^{(A)}\right)
$$

Thus, the correlation between $s_{\unitvec{n}_A}^{(A)}$ and $s_{\unitvec{n}_B}^{(B)}$ is given by

$$
  \operatorname{cor}\left(s_{\unitvec{n}_A}^{(A)}, s_{\unitvec{n}_A}^{(A)}\right) = \mathbb{E}\left(s_{\unitvec{n}_A}^{(A)}, s_{\unitvec{n}_A}^{(A)}\right)
$$

The correlations arising from entangled states are known as EPR-correlations.

### CHSH generalization of the Bell inequality

Just as the original Bell inequality, the generalization derived by Clause, Horne, Simony and Holt (CHSH) also considers a pair of particles on which individual measurements yielding possible values in $\set{\pm 1}$ can be performed. The key distinction is that, unlike in Bell's original derivation, no requirement of the form $\eqref{equation-127}$ needs to be made. Additionally it establishes an upper bound for expectation values of products of observable single-particle measurements.

Consider a pair of particles, one accessible to Alice and the other to Bob. Unlike in Bell's original formulation, the observables they measure are not restricted to those identified by a direction $\unitvec{n}\in\R^3$. Instead, Alice and Bob can choose their measurement using (possibly multi-dimensional) parameters $\mathbf{p}_A \in P_A$ and $\mathbf{p}_B \in P_B$, respectively. This means they measure respective observables $\hat{S}_{\mathbf{p}_A}^{(A)}$ and $\hat{S}_{\mathbf{p}_B}^{(B)}$, each taking values $\pm 1$. 

Now, suppose each particle is completely described by a hidden variable $\omega\in\Omega$, which determine the measurement outcomes $s_{\mathbf{p}_A}^{(A)}$ and $s_{\mathbf{p}_B}^{(B)}$. These outcomes, corresponding to the chosen measurement settings $\mathbf{p}_A$ and $\mathbf{p}_B$ are treated as parametrized random variables with a joint distribution on a probability space $(\Omega,\mathscr{A},\mathbb{P})$.

<MathBox title='' boxType='lemma' tag='lemma-1'>
Let $s_i: \Omega\to\set{\pm 1}$ for $i\in{1,2,3,4}$ be four discrete random variables on a probability space $(\Omega,\mathscr{A},\mathbb{P})$ that can take only the values in $\set{\pm 1}$. Then the following inequality holds

$$
  \left|\mathbb{E}(s_1 s_2) - \mathbb{E}(s_1 s_3) + \mathbb{E}(s_2 s_3) + \mathbb{E}(s_3 s_4) \right| \leq 2
$$

<details>
<summary>Proof</summary>

Since $s_i (\omega) \in\set{\pm 1}$ for all $\omega\in\Omega$ and $i\in\set{1,2,3,4}$, it follows that either

$$
  s_2 (\omega) - s_3(\omega) \implies s(\omega) + s_3 (\omega) = \pm 2
$$

or

$$
  s_2 (\omega) + s_3(\omega) \implies s(\omega) - s_3 (\omega) = \pm 2
$$

an

$$
  s_1 (\omega) [s_2 (\omega) - s_3 (\omega)] + s_4 (\omega) [s_2 (\omega) + s_3 (\omega)] = \pm 2
$$

This implies

$$
  |s_1 (\omega) [s_2 (\omega) - s_3 (\omega)] + s_4 (\omega) [s_2 (\omega) + s_3 (\omega)]| \leq 2
$$

and by linearity of expectation it follows that

$$
\begin{align*}
  &\left|\mathbb{E}(s_1 s_2) - \mathbb{E}(s_1 s_3) + \mathbb{E}(s_2 s_3) + \mathbb{E}(s_3 s_4) \right| \\
  &=|\mathbb{E}\left(s_1 (\omega) [s_2 (\omega) - s_3 (\omega)] + s_4 (\omega) [s_2 (\omega) + s_3 (\omega)]\right)| \leq 2
\end{align*}
$$
</details>
</MathBox>

<MathBox title='CHSH inequality' boxType='theorem'>
Let $s_\mathbf{p}^{(A)}$ and $s_\mathbf{p}^{(B)}$ be two discrete random variables on a probability space $(\Omega,\mathscr{A},\mathbb{P})$, taking values in $\set{\pm 1}$ and parametrized by $\mathbf{p}\in P$, i.e. for $X \in\set{A,B}$

$$
\begin{align*}
  s^X : P\times\Omega \to& \set{1 \pm} \\
  (\mathbf{p},\omega) \mapsto& s_\mathbf{p}^{(X)}
\end{align*}
$$

Then for arbitrary parameters $\mathbf{p}_1,\dots,\mathbf{p}_4 \in P$ the following generalization of the Bell inequality holds

$$
\begin{equation*}
  \left|\mathbb{E}(s_{\mathbf{p}_1}^{(A)} s_{\mathbf{p}_2}^{(B)}) - \mathbb{E}(s_{\mathbf{p}_1}^{(A)} s_{\mathbf{p}_3}^{(B)}) + \mathbb{E}(s_{\mathbf{p}_4}^{(A)} s_{\mathbf{p}_2}^{(B)}) + \mathbb{E}(s_{\mathbf{p}_4}^{(A)} s_{\mathbf{p}_3}^{(B)}) \right| \leq 2
\tag{\label{equation-130}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

This follows immediately from Lemma $\ref{lemma-1}$ by setting $s_i = s_{\mathbf{p}_i}^{(A)}$ for $i\in\set{1,4}$ and $s_i = s_{\mathbf{p}_i}^{(B)}$ for $i\in\set{2,3}$.
</details>
</MathBox>

Consider two particles in the entangled Bell state $\ket{\Psi^-}$. Let the observables $\hat{S}_{\mathbf{p}_i}^{(X)}$ correspond to the spin observables along directions $\unitvec{n}_X$, defined as

$$
  \hat{\Sigma}_{\unitvec{n}_i}^{(X)} = \unitvec{n}_X \cdot\boldsymbol{\sigma}, \; X\in\set{A,B},\; i\in{1,\dots,4}
$$

We choose measurement directions in the $(x,z)$-plane, given by

$$
  \unitvec{n}_i = \begin{bmatrix} \cos(\nu_i) \\ 0 \\ \sin(\nu_i) \end{bmatrix} \in \mathbb{S}^2, \; i\in\set{1,\dots,4}
$$

From $\eqref{equation-129}$, it follows that

$$
\begin{align*}
  &\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-} \\
  =& -\cos(\nu_1 - \nu_2) + \cos(\nu_1 - \nu_3) - \cos(\nu_4 - \nu_2) - \cos(\nu_4 - \nu_3)
\end{align*}
$$

Choosing the specific directions

$$
  \nu_1 = \frac{3\pi}{4}, \quad \nu_2 = \frac{\pi}{2}, \quad \nu_3 = 0, \quad \nu_4 = \frac{\pi}{4}
$$

we obtain

$$
\begin{equation*}
  \left|\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\Psi^-} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\Psi^-}\right| = 2\sqrt{2} > 2
\tag{\label{equation-131}}
\end{equation*}
$$

which contradicts the CHSH inequality $\eqref{equation-130}$. 

#### Aspect, Dalibard and Roger experiment

An experiment conducted by Aspect, Dalibard and Roger confirmed the violation of the CHSH inequality. Their setup involved a source emitting two entangled photons via a cascade transition, with one photon sent to Alice and the other to Bob. The photons traveled for approximately $40$ ns before reaching their respective measurement devices. During this travel time
- Alice independently choose to measure either $\hat{\Sigma}_{\unitvec{n}_1}^{(A)}$ or $\hat{\Sigma}_{\unitvec{n}_4}^{(A)}$. The switching time between these observables was at most $10$ ns.
- Bob independently choose to measure either $\hat{\Sigma}_{\unitvec{n}_2}^{(B)}$ or $\hat{\Sigma}_{\unitvec{n}_3}^{(B)}$.

A coincidence filter ensured that only photon pairs originating from the same cascade were considered. The detectors registered one of the two possible outcomes, $\pm 1$, for each photon.

Let $M_{i,j}^{A,B}$ for $i,j\in\set{1,\dots,4}$ be the set of measurements where $\hat{\Sigma}_{\unitvec{n}_i}^{(A)}$ and $\hat{\Sigma}_{\unitvec{n}_j}^{(B)}$ were measured. Define $N_{i,j}^{A,B}$ as the number of such measurements, and let $s_{\unitvec{n}_i}^{(X)} (l)$ for $X\in\set{A,B}$ denote the observed outcome in measurement $l\in M_{i,j}^{A,B}$. The empirical expectation values, denoted $\overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}}$, are computed as

$$
  \overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}} = \frac{1}{N_{i,j}^{A,B}} \sum_{l\in M_{i,j}^{A,B}} s_{\unitvec{n}_i}^{(A)} (l) s_{\unitvec{n}_j}^{(B)} (l)
$$

Inserting the empirical expectation values $\overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}}$ as approximations of the quantum mechanical expectation values $\Braket{\hat{\Sigma}_{\unitvec{n}_i}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_j}^{(B)}}_{\Psi^-}$ confirms $\eqref{equation-131}$, and thus the quantum mechanical prediction. However, inserting $\overline{\hat{\Sigma}_{\unitvec{n}_i}^{(A)}\hat{\Sigma}_{\unitvec{n}_j}^{(B)}}$ into the classical expectation $\mathbb{E}[s_{\unitvec{n}_i}^{(A)} s_{\unitvec{n}_j}^{(B)}]$ reveals a violation of the Bell inequality.

Each measurement of $\hat{\Sigma}_{\unitvec{n}_i}^{(X)}$ for $X\in\set{A,B}$ and $i\in\set{1,\dots,4}$ consitently yields a value in $\set{\pm 1}$. It may seem reasonable to assume that these observables always possess definite values before measurement. If that were the case, every pair of observables $(\hat{\Sigma}_{\unitvec{n}_i}^{(A)}, \hat{\Sigma}_{\unitvec{n}_j}^{(B)})$ for $i,j\in\set{1,\dots,4}$ would always predetermined values in $\set{\pm 1, \pm 1}$, thereby ensuring the validity of the CHSH inequality. However, as shown in $\eqref{equation-131}$, this assumption is violated by quantum mechanics.

This contradiction implies that $\hat{\Sigma}_{\unitvec{n}_i}^{(A)}$ and $\hat{\Sigma}_{\unitvec{n}_j}^{(B)}$ cannot simultaneously posess definite values, even though each can be individually measured with definite outcomes. In other words, while these observables yield $\pm 1$ when measured separately, their joint values do not preexist independently of the measurement process.

Quantum mechanics predicts Bell inequality violations only for entangled states and specific measurement directions. For example, in $\ket{\Psi^-}$, if we choose spin measurements along $\unitvec{n}_2 = \unitvec{n}_3$, the quantum mechanical predicition yields $-\sqrt{2}$, satisfying the CHSH inequality. Furthermore, for separable (i.e., non-entangled) states, quantum mechanical predictions always satisfy the Bell inequality.

<MathBox title='' boxType='proposition'>
In any separable state $\ket{\varphi}\otimes\ket{\psi}\in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$ the expectation values of spin observables $\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_1}^{(B)}$ in arbitrary spin directions $\unitvec{n}_i$ with $i\in\set{1,\dots,4}$ satisfy the CHSH variant of the Bell inequality, i.e.

$$
  \left|\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi}\right| \leq 2
$$

holds.

<details>
<summary>Proof</summary>

Generally, the expectation values of products of observables $\hat{M}_A \otimes \hat{M}_B$ factorize in separable states $\ket{\varphi}\otimes\ket{\psi} \in {}^\P \mathcal{H}_A \otimes {}^\P \mathcal{H}_B$, i.e.

$$
\begin{align*}
  \braket{\hat{M}_A \otimes \hat{M}_B} =& \braket{\varphi\otimes\psi|\hat{M}_A \otimes \hat{M}_B|\varphi\otimes\psi} \\
  =& \braket{\varphi\otimes\psi|\hat{M}_A \varphi \otimes \hat{M}_B \psi} \\
  =& \braket{\varphi|\hat{M}_A|\varphi}\braket{\psi|\hat{M}_B|\psi} \\
  =& \braket{\hat{M}_A}_\varphi \braket{\hat{M}_B}_\psi \tag{\label{equation-132}}
\end{align*}
$$

An arbitrary state $\ket{\varphi}\in {}^\P \mathcal{H}_A$ can be given in the form

$$
  \ket{\varphi} = e^{i\alpha} \cos(\beta)\ket{0} + e^{i\gamma} \sin(\beta)\ket{1}
$$

The spin-up state for a spin in the direction $\unitvec{n}(\theta,\phi)$ is given by

$$
  \ket{\uparrow_{\unitvec{n}(\theta,\phi)}} = e^{-i\phi/2} \cos\left(\frac{\theta}{2}\right) \ket{0} + e^{i\phi/2} \sin\left(\frac{\theta}{2}\right)\ket{1}
$$

such that we can write $\ket{\varphi}$ with the help of a unit vector $\unitvec{n}_\varphi := \unitvec{n}(2\beta, \frac{\gamma - \alpha}{2})$ in the form

$$
  \ket{\varphi} = e^{i(\alpha + \gamma)/2} \ket{\uparrow_{\unitvec{n}_\varphi}}
$$

The same holds for $\ket{\psi} = e^{i\delta} \ket{\uparrow_{\unitvec{n}_\psi}}$ with suitably chosen $\delta$ and $\unitvec{n}_\psi$.

Next, we show that

$$
\begin{equation*}
  \braket{\hat{\sigma}_{\unitvec{n}}}_{\uparrow_{\unitvec{m}}} = \unitvec{n}\cdot\unitvec{m}
\tag{\label{equation-133}}
\end{equation*}
$$

Since

$$
\begin{align*}
  \hat{\Sigma}_{\unitvec{n}} =& \unitvec{n}\cdot\boldsymbol{\sigma} \\
  \unitvec{m}\cdot\boldsymbol{\sigma}\ket{\uparrow_{\unitvec{m}}} =& \ket{\uparrow_{\unitvec{m}}} \\
  (\unitvec{m}\cdot\boldsymbol{\sigma})^\dagger =& \unitvec{m}\cdot\boldsymbol{\sigma}
\end{align*}
$$

if follows that

$$
\begin{align*}
  \braket{\hat{\sigma}_{\unitvec{n}}}_{\uparrow_{\unitvec{m}}} =& \braket{\uparrow_{\unitvec{m}}|\unitvec{n}\cdot\boldsymbol{\sigma}|\uparrow_{\unitvec{m}}} \\
  =& \frac{1}{2}\left[\Braket{(\unitvec{m}\cdot\boldsymbol{\sigma}) \uparrow_{\unitvec{m}}|(\unitvec{n}\cdot\boldsymbol{\sigma})\uparrow_{\unitvec{m}}} + \Braket{\uparrow_{\unitvec{m}}|(\unitvec{n}\cdot\boldsymbol{\sigma})(\unitvec{m}\cdot\boldsymbol{\sigma})|\uparrow_{\unitvec{m}}}\right] \\
  =& \frac{1}{2}\Braket{\uparrow_{\unitvec{m}}|(\unitvec{m}\cdot\boldsymbol{\sigma})(\unitvec{n}\cdot\boldsymbol{\sigma}) + (\unitvec{n}\cdot\boldsymbol{\sigma})(\unitvec{m}\cdot\boldsymbol{\sigma})|\uparrow_{\unitvec{m}}} \\
  =& \frac{1}{2}\Braket{\uparrow_{\unitvec{m}}|(\unitvec{m}\cdot\unitvec{n})\mathbf{I} + i((\unitvec{m}\times\unitvec{n})\cdot\boldsymbol{\sigma}) + (\unitvec{n}\cdot\unitvec{m})\mathbf{I} + i((\unitvec{n}\times\unitvec{m})\cdot\boldsymbol{\sigma})|\uparrow_{\unitvec{m}}} \\
  =& \unitvec{n}\cdot\unitvec{m} + \frac{i}{2}\braket{\uparrow_{\unitvec{n}}|\underbrace{(\unitvec{m}\times\unitvec{n} + \unitvec{n}\times\unitvec{m})}_{=0} \cdot\boldsymbol{\sigma}|\uparrow_{\unitvec{m}}} \\
  =& \unitvec{n}\cdot\unitvec{m}
\end{align*}
$$

Combining $\eqref{equation-132}$ and $\eqref{equation-133}$ yields

$$
\begin{align*}
  \braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_1}^{(B)}}_{\varphi\otimes\psi} =& \braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)}}_\varphi \braket{\hat{\Sigma}_{\unitvec{n}_1}^{(B)}}_\psi \\
  =& (\unitvec{n}_i \cdot \unitvec{n}_\varphi) (\unitvec{n}_j \cdot \unitvec{n}_\psi)
\end{align*}
$$

and thus

$$
\begin{align*}
  & \left|\Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} - \Braket{\hat{\Sigma}_{\unitvec{n}_1}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_2}^{(B)}}_{\varphi\otimes\psi} + \Braket{\hat{\Sigma}_{\unitvec{n}_4}^{(A)} \otimes \hat{\Sigma}_{\unitvec{n}_3}^{(B)}}_{\varphi\otimes\psi}\right| \\
  =& \left| \unitvec{n}_1 \cdot \unitvec{n}_\varphi (\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi) + \unitvec{n}_4 \cdot \unitvec{n}_\varphi (\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi) \right| \\
  \leq& \left| \unitvec{n}_1 \cdot \unitvec{n}_\varphi\right|\cdot \left|\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi \right| + \left|\unitvec{n}_4 \cdot \unitvec{n}_\varphi\right|\cdot \left|\unitvec{n}_2 \cdot \unitvec{n}_\psi - \unitvec{n}_3 \cdot \unitvec{n}_\psi) \right| \\
  \leq& \left|(\unitvec{n}_2 - \unitvec{n}_3)\cdot\unitvec{n}_\psi \right| + \left|(\unitvec{n}_2 + \unitvec{n}_3)\cdot\unitvec{n}_\psi \right|
\end{align*}
$$

For arbitrary $x,y \in\R$, we have

$$
  |x| + |y| = \begin{cases}
    |x + y|, \quad& xy \geq 0 \\
    |x - y|, \quad& xy < 0
  \end{cases}
$$

and thus

$$
  \left|(\unitvec{n}_2 - \unitvec{n}_3)\cdot\unitvec{n}_\psi \right| + \left|(\unitvec{n}_2 + \unitvec{n}_3)\cdot\unitvec{n}_\psi \right| = 2\max\Set{\left\lvert\unitvec{n}_2 \cdot \unitvec{n}_\psi \right\rvert, \left\lvert\unitvec{n}_3 \cdot \unitvec{n}_\psi \right\rvert} \leq 2
$$
</details>
</MathBox>

### Bell telephone

The seemingly 'unreasonable' behavior of quantum mechanics, where Alice's measurement appears to instantaneously affect the state of Bob's particle‚Äîhas led some to speculate about the possibility of superluminal communication. This hypothetical communication device, often referred to as the Bell telephone, would allow Alice to send information to Bob faster than the speed of light. However, as we will now show, such a device cannot be used to transmit any information at all, not even at subluminal speeds.

The proposed Bell telephone operates as follows: Suppose Alice and Bob each possess a particle that together form the Bell state $\ket{\Phi^+}$. Alice can choose to measure her particle along different bases, thereby influencing Bob's state. Specifically:
- If Alice measures $\hat{\sigma}_z$, she projects Bob's particle into $\ket{0} = \ket{\uparrow_{\unitvec{z}}}$ or $\ket{1} = \ket{\downarrow_{\unitvec{z}}}$.
- If Alice measures $\hat{\sigma}_x$, she projects Bob's particle into $\ket{+} = \ket{\uparrow_{\unitvec{z}}}$ or $\ket{1} = \ket{\downarrow_{\unitvec{z}}}$.

Alice's idea is to send a message to Bob by encoding bits according to the measurement she performs, as outlined in the table below.

<TableFigure caption="Protocol for the Bell telephone">
| Agreed bit value | Alice measures | Bob's qubit value in the state |
| --- | --- | --- |
| $0$ | $\hat{\sigma}_z$ | $\ket{0}$ or $\ket{1}$ |
| $1$ | $\hat{\sigma}_x$ | $\ket{+}$ or $\ket{-}$ |
</TableFigure>

Bob is supposed to determine the bit Alice intended to send by checking whether his particle is in $\set{\ket{0},\ket{1}}$ or $\set{\ket{+},\ket{-}}$. However, this scheme fails because, from Bob's perspective, his particle is always in a mixed state after Alice's measurement. Mathematically, this mixed state can be expressed using either the $\set{\ket{0},\ket{1}}$ basis or $\set{\ket{+},\ket{-}}$ basis. Regardless of which observable Alice measures, Bob's reduced density matrix remains unchanged. Consequently, Bob has no way of distinguishing between the two cases, meaning he cannot infer the bit Alice intended to send.
 
Bob might attempt to determine the state of his particle by measuring either $\hat{\sigma}_z$ or $\hat{\sigma}_x$. Suppose he measures $\hat{\sigma}_z$ and observes the value $1$. He still cannot conclude that his particle was in state $\ket{0}$, since the probability to observed the value $1$ when measuring $\hat{\sigma}_z$ is also different in the states $\ket{+}$ and $\ket{-}$:

$$
  |\braket{0|+}|^2 = \frac{1}{2} = |\braket{0|-}|^2
$$

Consider a bipartite quantum system where Alice and Bob control subsystems $\mathcal{H}_A$ and $\mathcal{H}_B$, respectively. Alice has access to two distinct observables $\hat{M}_A$ and $\hat{\tilde{M}}_A$, each with a purely discrete spectrum. She encodes the classical bits $0$ nad $1$ by chooseing to measure either $\hat{M}_A$ or $\hat{\tilde{M}}$.

For simplicity, assume that the eigenvalues $\lambda_a \in\sigma(\hat{M}_A)$ and $\tilde{\lambda}_a \in\sigma(\hat{\tilde{M}}_A)$ are all non-degenerate in $\mathcal{H}_A$. The argument extends to degenerate eigenvalues, but with more cumbersome notation.

The observables $\hat{M}_A$ and $\hat{\tilde{M}}_A$ have respective orthonormal eigenbases $\set{\ket{\tilde{e}_a}| \ket{e_a} \in \operatorname{eig}(\hat{M}_A, \lambda_a)}$ and $\set{\ket{\tilde{e}_a}| \ket{\tilde{e}_a} \in \operatorname{eig}(\hat{\tilde{M}}_A, \tilde{\lambda}_a)}$ in $\mathcal{H}_A$, which are related by a unitary transformation $\hat{U}\in\mathcal{U}(\mathcal{H})$ such that

$$
\begin{equation*}
\begin{split}
  \ket{\tilde{e}_a} =& \hat{U}\ket{e_a} \\
  =& \sum_{a_1} \braket{e_{a_1}|\hat{U}|e_{a_1}}\ket{e_{a_1}} \\
  =& \sum_{a_1} \hat{U}_{a_1 a} \ket{e_{a_1}}
\end{split}\
\tag{\label{equation-138}}
\end{equation*}
$$

For Bob's system let $\set{\ket{f_b}}$ be an orthonormal basis of $\mathcal{H}_B$. The composite system $\mathcal{H}_A \otimes \mathcal{H}_B$ has orthornomal eigenbases $\set{\ket{e_a \otimes f_b}}$ corresponding to $\hat{M}_A \otimes \hat{I}_B$, and $\set{\ket{\tilde{e}_a} \otimes \ket{f_b}}$ corresponding to $\hat{\tilde{M}}_A \otimes \hat{I}_B$, so that

$$
\begin{align*}
  (\hat{M}_A \otimes \hat{I}_B) \ket{e_a \otimes f_b} =& \lambda_a \ket{e_a \otimes f_b} \\
  (\hat{\tilde{M}}_M \otimes \hat{I}_B) \ket{\tilde{e}_a \otimes f_b} =& \tilde{\lambda}_a \ket{\tilde{e}_a \otimes f_b}
\end{align*}
$$

such that $\sigma(\hat{M}_A \otimes \hat{I}_B) = \sigma(\hat{M}_A)$ as well as $\sigma(\hat{\tilde{M}}_A \otimes\hat{I}_B) = \sigma(\hat{\tilde{M}}_A)$. As an eigenvalue of the observable $\hat{M}_A \otimes\hat{I}_B$ each of these eigenvalues is $\dim(\mathcal{H}_B)$-fold degenerate, i.e. $\dim[\operatorname{eig}(\hat{M}\times\hat{I}_B), \lambda_A] = \dim(\mathcal{H}_B)$. A general eigenstate of $\hat{M}_A \otimes \hat{I}_B$ is of the form

$$
  \ket{e_a \otimes \varphi} = \sum_b \varphi_b \ket{e_a \otimes f_b}
$$

and similar statements hold for $\hat{\tilde{M}}_A \otimes\hat{I}_B$.

Let the composite system initially be prepared in the pure state

$$
\begin{equation*}
  \ket{\Psi} = \sum_{a,b} \Psi_{ab} \ket{e_a \otimes f_b} = \sum_{a,b} \tilde{\Psi}_{ab} \ket{\tilde{e}_a \otimes f_b}
\tag{\label{equation-137}}
\end{equation*}
$$

If Alice measures $\hat{M}_A$ to send bit $0$, the composite system collapses into

$$
  \hat{\rho}_{\lambda_a} := \frac{\hat{P}_{\lambda_a} \hat{\rho}_\Psi \hat{P}_{\lambda_a}}{\operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a})}
$$

where $\hat{P}_{\lambda_a} = \ket{e_a} \otimes \bra{e_a}\otimes\hat{I}_B$ is the projector onto the eigenspace $\operatorname{eig}(\hat{M}_A \otimes \hat{I}_B, \lambda_a)$ and $\hat{\rho}_\Psi = \ket{\Psi}\bra{\Psi}$ is the density operator of the original pure state.

The probability to observe $\lambda_a$ and thus to end up in the state $\hat{\rho}_{\lambda_a}$, is given by $\operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a})$. For an observer unaware of the measurement outcome, including Bob, the post-measurement composite system is then described by the mixed state $\hat{\rho}$ which is a statistical ensemble of state $\hat{\rho}_{\lambda_a}$ each occuring with a probability $\operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a})$, i.e.

$$
\begin{equation*}
  \hat{\rho} = \sum_a \operatorname{tr}(\hat{\rho}\hat{P}_{\lambda_a}) = \sum_a \hat{P}_{\lambda_a} \hat{\rho}_\Psi \hat{P}_{\lambda_a}
\tag{\label{equation-136}}
\end{equation*}
$$

The mixed state, which describes Bob's sub-system after Alice's measurement of the observable $\hat{M}_A$ is given by the partial trace operator

$$
\begin{equation*}
  \hat{\rho}_B (\hat{\rho}) = \sum_{b_1, b_2} \sum_a \Psi_{ab_1} \Psi_{ab_2}^* \ket{f_{b_1}}\bra{f_{b_1}}
\tag{\label{equation-134}}
\end{equation*}
$$

<details>
<summary>Details</summary>

To derive $\eqref{equation-134}$, we have

$$
\begin{align*}
  \hat{P}_{\lambda_a}\ket{\Psi} =& (\ket{e_a}\bra{e_a} \otimes\hat{I}_B) \sum_{a_1,b} \Psi_{a_1 b} \ket{e_{a_1}} \otimes \ket{f_b} \\
  =& \sum_{a_1, b} \Psi_{a_1 b} \ket{e_a} \underbrace{\braket{e_a|e_{a_1}}}_{=\delta_{aa_1}} \otimes\ket{f_b} \\
  =& \sum_b \Psi_{ab} \ket{e_a} \otimes \ket{f_b} 
\end{align*}
$$

which implies

$$
\begin{align*}
  \hat{P}_{\lambda_a} \ket{\Psi}\bra{\Psi} \hat{P}_{\lambda_a} =& \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a} \otimes \bra{f_{b_1}} \ket{e_{a_1}} \otimes \ket{f_{b_2}} \\
  =& \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a} \bra{e_a} \otimes \ket{f_{b_1}} \bra{f_{b_2}} \tag{\label{equation-135}}
\end{align*}
$$

Inserting $\eqref{equation-135}$ into $\eqref{equation-136}$ yields

$$
  \hat{\rho} = \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a}\bra{e_a}\otimes\ket{f_{b_1}}\bra{f_{b_2}}
$$

for the density operator of the composite system. The reduced density operator for the subsystem $\mathcal{H}_B$ is given by

$$
\begin{align*}
  \hat{\rho}_B (\hat{\rho}) =& \operatorname{tr}_A (\hat{\rho}) \\
  =& \operatorname{tr}_A \left( \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \ket{e_a}\bra{e_a}\otimes\ket{f_{b_1}}\bra{f_{b_2}} \right) \\
  =& \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \operatorname{tr}_A \left(\ket{e_a}\bra{e_a}\otimes\ket{f_{b_1}}\bra{f_{b_2}}\right) \\
  =& \sum_a \sum_{b_1, b_2} \Psi_{ab_1} \Psi_{ab_2}^* \underbrace{\operatorname{tr}(\ket{e_a}\bra{e_a})}_{=1} \ket{f_{b_1}}\bra{f_{b_2}} \\
  =& \sum_{b_1, b_2} \sum_a \Psi_{ab_1} \Psi_{ab_2}^* \ket{f_{b_1}}\bra{f_{b_1}} 
\end{align*}
$$
</details>

Similarly, if Alice measures the observable $\hat{\tilde{M}}_A$ to send bit $1$, Bob's subsystem is in the mixed state

$$
\begin{equation*}
  \hat{\rho}_B (\hat{\tilde{\rho}}) = \sum_{b_1, b_2} \sum_a \tilde{\Psi}_{ab_1} \tilde{\Psi}_{ab_2}^* \ket{f_{b_1}}\bra{f_{b_2}}
\tag{\label{equation-139}}
\end{equation*}
$$

From $\eqref{equation-138}$ and $\eqref{equation-137}$ it follows that

$$
  \Psi_{ab} = \sum_{a_1} \mathbf{U}_{aa_1} \tilde{\Psi}_{a_1 b}
$$

and thus

$$
\begin{align*}
  \sum_a \Psi_{ab_1} \Psi_{ab_2}^* =& \sum_{a, a_1, a_2} \mathbf{U}_{aa_1} \tilde{\Psi}_{a_1 b_1} \mathbf{U}_{aa_2}^* \tilde{\Psi}_{a_2 b_2}^* \\
  =& \sum_{a, a_1, a_2} \mathbf{U}_{aa_1} \mathbf{U}_{a_2 a}^\dagger \tilde{\Psi}_{a_1 b_1} \tilde{\Psi}_{a_2 b_2}^* \\
  =& \sum_{a_1, a_2} \underbrace{(\mathbf{U}^\dagger \mathbf{U})_{a_1 a_1}}_{=\delta_{a_2 a_1}} \tilde{\Psi}_{a_1 b_1} \tilde{\Psi}_{a_2 b_2}^* \\
  =& \sum_a \tilde{\Psi}_{ab_1} \tilde{\Psi}_{ab_2}^* \tag{\label{equation-140}}
\end{align*}
$$

From $\eqref{equation-134}$ and $\eqref{equation-139}$ together with $\eqref{equation-140}$, it follows that

$$
  \hat{\rho}_B (\hat{\rho}) = \hat{\rho}_B (\hat{\tilde{\rho}})
$$

which means that Bob's subsystem is always in the same mixed state regardless of which observable Alice measures. This means that Bob has no way to infer whether Alice intended to send bit $0$ or $1$, proving that classical information cannot be transmitted in this manner.

### Perfect quantum copier

The fact that a quantum-copier does not exist, or as formulated alternatively, that quantum states cannot be cloned, is due to the linear structure of the Hilbert space $\mathcal{H}$ containing the state vectors. Given
- an arbitrary state $\ket{\psi}\in\mathcal{H}$ to be copied and
- a state $\ket{\omega}\in\mathcal{H}$ to emerge as a copy

A quantum copier $\hat{K}$ is a linear transformation that leaves the original state $\ket{\psi}$ unchanged and transforms the white-page state $\ket{\omega}$ such that it becomes the original state $\ket{\psi}$, i.e. $\hat{K}: \mathcal{H}^{\otimes 2}\to \mathcal{H}^{\otimes 2}$ is given by

$$
  \ket{\psi}\otimes\ket{\omega} \mapsto \ket{\psi}\otimes\ket{\psi}
$$

for arbitrary $\ket{\psi}\in\mathcal{H}$ and a given fixed $\ket{\omega}\in\mathcal{H}$.

<MathBox title='Quantum no-cloning theorem' boxType='theorem'>
A quantum copier cannot exist.

<details>
<summary>Proof</summary>

It suffices to consider qubits, i.e. $\mathcal{H} = {}^\P \mathcal{H}$ and the action of a quantum-copier on the qubit-states $\ket{0}$, $\ket{1}$ and $\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$. Per definition, $\hat{K}$, has to satisfy

$$
\begin{align*}
  \hat{K}(\ket{0}\otimes\ket{\omega}) =& \ket{0}\otimes\ket{0} \\
  \hat{K}(\ket{1}\otimes\ket{\omega}) =& \ket{1}\otimes\ket{1} \\
  \hat{K}\left(\frac{\ket{0} + \ket{1}}{\sqrt{2}} \otimes\ket{\omega}\right) =& \frac{\ket{0} + \ket{1}}{\sqrt{2}}\otimes\frac{\ket{0} + \ket{1}}{\sqrt{2}} \\
\end{align*}
$$

Since $\hat{K}$ is supposed to be linear, we find instead that 

$$
\begin{align*}
  \hat{K}\left(\frac{\ket{0} + \ket{1}}{\sqrt{2}} \otimes\ket{\omega}\right) =& \hat{K}\left(\frac{1}{\sqrt{2}}(\ket{0}\otimes\ket{\omega}) + \frac{1}{\sqrt{2}}(\ket{1}\otimes\ket{\omega})\right) \\
  =& \frac{1}{\sqrt{2}}\left(\hat{K}(\ket{0}\otimes\ket{\omega}) + \hat{K}(\ket{1}\otimes\ket{\omega})\right) \\
  =& \frac{1}{\sqrt{2}} (\ket{0}\otimes\ket{0} + \ket{1}\otimes\ket{1}) \\
  \neq& \frac{\ket{0} + \ket{1}}{\sqrt{2}}\otimes\frac{\ket{0} + \ket{1}}{\sqrt{2}}
\end{align*}
$$
</details>
</MathBox>

It is worth noting that there can be devices that copy particular states. The quantum no-cloning theorem only makes the statement that there is no device which does that for all states.

# Matter wave formulation

A free particle moving in a $3$-dimensional Euclidean space with momentum $\mathbf{p}$ is described by a plane wave $\psi_\mathbf{p}: \R^3 \times\R\to\mathbb{C}$, which in Cartesian coordinates takes the form

$$
  \psi_\mathbf{p}(\mathbf{x}, t) = N e^{i(\mathbf{k}\cdot\mathbf{x} - \omega t)}
$$

where
- $\mathbf{x}\in\R^3$ is the position of the particle
- $\mathbf{k}$ is the wave vector pointing in the same direction as a $\mathbf{p}$
- $\omega$ is the wave frequency
- $N$ is a normalization constant

The square norm of the wavefunction describes the probability density of the particle at $\mathbf{x}$, i.e. $|\psi(\mathbf{x}, t)|^2 \;\d^3 x$ gives the probability of finding the particle in the volume element $\d^3 x$ around $\mathbf{x}$. Thus, the square norm of the wavefunction is normalized to unity

$$
  \int |\psi(\mathbf{r}, t)|^2 \;\d^3 x = 1
$$

The de Broglie equations relate the wavelength $\lambda$ of the particle to the modulus of the momentum $|\mathbf{p}| = mv$, and the frequency $f$ of the particle to the energy $E$

$$
\begin{align*}
  \lambda =& \frac{2\pi}{|\mathbf{k}|} = \frac{h}{p} = \frac{h}{mv} \\
  f =& \frac{\omega}{2\pi} = \frac{E}{p}
\end{align*}
$$

where $h$ is the Planck constant. Introducing the reduced Planck constant $\hbar = h/2\pi$, the equations can be written as

$$
\begin{align*}
  \mathbf{p} =& \hbar\mathbf{k} \\
  E =& \hbar\omega
\end{align*}
$$

In terms of momentum and energy, the plane wave takes the alternative form

$$
  \psi(\mathbf{x},t) = N e^{i(\mathbf{p}\cdot\mathbf{x} - E_\mathbf{p})/\hbar}
$$

The energy $E_\mathbf{p}$ depends on the momentum of the particle in the following ways
- non-relativistic particles: $E_\mathbf{p} = \mathbf{p}^2 / 2m$
- relativistic particles: $E_\mathbf{p} = c\sqrt{\mathbf{p}^2 + m^2 c^2}$
- massless particles: $E_\mathbf{p} = c|\mathbf{p}|$

In an infinite volume, the normalization constant makes the wavefunction vanish. This can be avoided by introducing the *current density* of the particle probability

$$
  \mathbf{j}(\mathbf{x}, t) := -i\frac{\hbar}{2m} \psi^* (\mathbf{x}, t) \overset{\leftrightarrow}{\nabla} \psi(\mathbf{x},t)
$$

where $\overset{\leftrightarrow}{\nabla}$ is short notation for the difference between forward- and backward-gradients

$$
\begin{align*}
  \psi^* (\mathbf{x}, t) \overset{\leftrightarrow}{\nabla} \psi(\mathbf{x},t) :=& \psi^* (\mathbf{x}, t) \overset{\rightarrow}{\nabla} \psi(\mathbf{x},t) - \psi^* (\mathbf{x}, t) \overset{\leftarrow}{\nabla} \psi(\mathbf{x},t) \\
  =& \psi^* (\mathbf{x}, t) \nabla \psi(\mathbf{x},t) - [\nabla\psi^* (\mathbf{x}, t)]\psi(\mathbf{x}, t)
\end{align*}
$$

A particle wave can be expressed as a superposition of plane waves in the form of a Fourier transform

$$
  \psi(\mathbf{x},t) = \frac{1}{(2\pi\hbar)^3} \int f(\mathbf{p})e^{i(\mathbf{p}\cdot\mathbf{x} - E_\mathbf{p})/\hbar}\;\d^3 p
$$

The momentum wavefunction $f(\mathbf{p})$ is given by the inverse Fourier transform

$$
  f(\mathbf{p}) = \int e^{i\mathbf{p}\cdot\mathbf{x}/\hbar} \psi(\mathbf{x},0)\;\d^3 r
$$

By the uncertainty principle of Fourier transformations, the position and momentum wavefunctions cannot both be concentrated. In general the variances of the particles position and momentum distributions are related by

$$
  \Delta\mathbf{x} \Delta\mathbf{p} \geq \frac{\hbar}{2}
$$

which is known as Heisenberg's uncertainty principle.

## Schr√∂dinger equation

The energy of a nonrelativistic particle with momentum $\mathbf{p}$ and mass $m$ is equal to its Hamiltonian

$$
  H(\mathbf{p}) = E_\mathbf{p} = \frac{\mathbf{p}^2}{2m}
$$

This gives the following identity for the wavefunction $\psi_\mathbf{p}(\mathbf{x},t)$ in Cartesian coordinates

$$
  \frac{1}{(2\pi\hbar)^3} \int f(\mathbf{p})[H(\mathbf{p} - E_\mathbf{p})]e^{i(\mathbf{p}\cdot\mathbf{x} - E_\mathbf{p}t)/\hbar} \;\d^3 p = 0
$$

Substituting for the operators

$$
\begin{align*}
  \unitvec{p} =& -i\hbar\nabla \\
  \hat{E} =& i\hbar\frac{\partial}{\partial t}
\end{align*}
$$

we get the differential equation

$$
  \left[H(-i\hbar\nabla) - i\hbar\frac{\partial}{\partial t}\right] \psi(\mathbf{p},t) = 0
$$

which is the Schr√∂dinger equation for the wavefunction of a free particle. For an arbitrary Hamiltonian $\hat{H} := H(-i\hbar\nabla,\mathbf{x},t)$, the equation takes the general form

$$
  \left(\hat{H} - i\hbar\frac{\partial}{\partial t}\right)\psi(\mathbf{x},t) = 0
$$

The rule of quantizing the classical Hamiltonian $H(\mathbf{p},\mathbf{x},t)$ by the substitution $\mathbf{p}\to\unitvec{p} = -i\hbar\nabla$ is called the correspondence principle.

### Deriving the Schr√∂dinger equation from the classical wave equation

The scalar wave displacement $\Psi(\mathbf{x},t)$ of a non-relativistic particle with mass $m$ and speed $v$ is given by the second-order linear partial differential equation 

$$
\begin{equation*}
  \frac{\partial^2 }{\partial t^2}\Psi(\mathbf{x},t) = v^2 \nabla^2 u(\mathbf{x}, t)
\tag{\label{equation-10}}
\end{equation*}
$$

The wave equation can be solved by separation of variables. Assuming a solution of the form $\Psi(\mathbf{x},t) = \psi(\mathbf{x})g(t)$, equation $\eqref{equation-1}$ can be written as

$$
\begin{align*}
  \frac{\partial^2}{\partial t^2} \psi(\mathbf{x})g(t) =& v^2 \nabla^2 \psi(\mathbf{x})g(t) \\
  \psi(\mathbf{x}) \frac{\partial^2}{\partial t^2} g(t) =& v^2 g(t) \nabla^2 \psi(\mathbf{x}) \\
  \frac{1}{v^2 g(t)} \frac{\partial^2}{\partial t^2} g(t) =& \frac{1}{\psi(\mathbf{x})} \nabla^2 \psi(\mathbf{x}) \tag{\label{equation-9}}
\end{align*}
$$

The separated equation $\eqref{equation-9}$ holds if and only if both sides are equal to a constant $\alpha\in\R$, i.e.

$$
\begin{aligned}
  \frac{1}{v^2 g(t)} \frac{\partial^2}{\partial t^2} g(t) =& \alpha \\
  \frac{\partial^2}{\partial t^2} g(t) =& \alpha v^2 g(t)
\end{aligned}
\quad
\begin{aligned}
  \frac{1}{\psi(\mathbf{x})} \nabla^2 \psi(\mathbf{x}) =& \alpha \\
  \nabla^2 \psi(\mathbf{x}) = \alpha \psi(\mathbf{x})
\end{aligned}
$$

The spatial equation is an eigenvalue problem with real solutions for negative eigenvalues $\alpha = -k^2$, where $k = \frac{2\pi}{\lambda}$ is the wavenumber. Using the de Broglie relation $\lambda = \frac{h}{mv}$ and the energy relation $K = \frac{1}{2}mv^2 = E -V(\mathbf{x})$, assuming energy conservation, the spatial equation can be written

$$
\begin{align*}
  \nabla^2 \psi(\mathbf{x}) =& -k^2 \psi(\mathbf{x}) \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{4\pi^2}{\lambda^2} \tag{$k = \frac{2\pi}{\lambda}$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{4\pi^2 m^2 v^2}{h^2} \psi(\mathbf{x}) \tag{$\lambda = \frac{h}{mv}$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{8\pi^2 m K}{h^2}\psi(\mathbf{x}) \tag{$K = \frac{1}{2}mv^2$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{8\pi^2 m}{h^2} [E - V(\mathbf{x})]\psi(\mathbf{x}) \tag{$K = E - V(\mathbf{x})$} \\
  \nabla^2 \psi(\mathbf{x}) =& -\frac{2m}{\hbar^2} [E - V(\mathbf{x})] \psi(\mathbf{x}) \tag{$\hbar = \frac{h}{2\pi}$} \\
\end{align*}
$$

Reordering the equation and introducing the Hamiltonian operator $\hat{H} = -\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{x})$, we obtain the time-independent Schr√∂dinger equation

$$
\begin{align*}
  -\frac{\hbar^2}{2m} \nabla^2 \psi(\mathbf{x}) + V(\mathbf{x})\psi(\mathbf{x}) =& E \psi(\mathbf{x}) \\
  \left(-\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{x}) \right)\psi(\mathbf{x}) =& E \psi(\mathbf{x}) \\
  \hat{H}\psi(\mathbf{x}) =& E \psi(\mathbf{x}) \tag{\label{equation-17}}
\end{align*}
$$

Noting that $\omega = kv$, the time equation takes the form

$$
  \frac{\partial^2}{\partial^2 t} g(t) = -\omega^2 g(t)
$$

with general solution $e^{-i\omega t}$. The solution to $\eqref{equation-10}$ therefore takes the form $\Psi(\mathbf{x}, t) = \psi(\mathbf{x}) e^{-i\omega t}$. Using the Planck-Einstein relation $E = hf = h\frac{\omega}{2\pi}$ and taking the partial time derivative yields

$$
\begin{align*}
  \Psi(\mathbf{x}, t) =& \psi(\mathbf{x})e^{-i\omega t} \\
  \Psi(\mathbf{x}, t) =& \psi(\mathbf{x})e^{-i2\pi Et/h} \tag{$\omega = \frac{2\pi E}{h}$} \\
  \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& -i\frac{2\pi E}{h} \psi(\mathbf{x})e^{-i2\pi Et/h} \\
  \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& -i\frac{2\pi E}{h} \Psi(\mathbf{x}, t) \\
  i\frac{h}{2\pi} \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& E\Psi(\mathbf{x}, t) \\
  i\hbar \frac{\partial}{\partial t}\Psi(\mathbf{x}, t) =& E\Psi(\mathbf{x}, t) \tag{$\hbar = \frac{h}{2\pi}$}
\end{align*}
$$

Inserting the time-independent equation $\eqref{equation-17}$, we get

$$
  i\hbar \frac{\partial\Psi}{\partial t} = {H}\Psi
$$

# Quantum operators

## Position operator

In quantum mechanics, the position operator $\unitvec{x}$ is defined by the eigenvalue equation

$$
\begin{equation*}
  \unitvec{x} \ket{\mathbf{x}} = \mathbf{x} \ket{\mathbf{x}}
\tag{\label{equation-91}}
\end{equation*}
$$

where $\mathbf{x}$ is the eigenvalue corresponding to the position of the particle, and $\ket{\mathbf{x}}$ is the corresponding eigenstate. The eigenstates $\ket{x}$ satisfy the Dirac orthonormalization:

$$
  \braket{\mathbf{x}'|\mathbf{x}} = \delta(\mathbf{x} - \mathbf{x}')
$$

Writing the Hermitian adjoint of $\eqref{equation-91}$, i.e.

$$
  \bra{\mathbf{x}} \unitvec{x} = \bra{\mathbf{x}} \mathbf{x}
$$

and taking the scalar product with a generic state $\ket{\psi}$ we obtain

$$
  \unitvec{x} \psi(\mathbf{x}) = \mathbf{x}\psi(\mathbf{x})
$$

where $\psi(\mathbf{x}) = \braket{\mathbf{x}|\psi}$ is the wavefunction in position space. The modulus squared of the wavefunction 

$$
  P(\mathbf{x}) = |\psi(\mathbf{x})|^2
$$

represents the probability density for measuring the position in the interval $(\mathbf{x}, \mathbf{x} + \d\mathbf{x})$. In terms of the wavefunction, the state vector $\ket{\psi}$ is expended as

$$
  \ket{\psi(t)} = \int_{\R^3} \psi(\mathbf{x},t)\ket{\mathbf{x}}\;\d^3 x
$$

The expectation of $\unitvec{x}$ is given by

$$
\begin{equation*}
  \braket{\unitvec{x}}_\psi = \braket{\psi|\unitvec{x}|\psi} = \int_{\R^3} \braket{\psi\mathbf{x}}\braket{\mathbf{x}|\unitvec{x}|\psi} \;\d^3 x
\tag{\label{equation-92}}
\end{equation*}
$$

Likewise, we have

$$
\begin{equation*}
\begin{split}
  \braket{\mathbf{x}}_\psi =& \int_{\R^3} \mathbf{x}| \psi(\mathbf{x})|^2 \;\d^3 x = \int_{\R^3} \psi^*(\mathbf{x}) \psi (\mathbf{x}) \mathbf{x} \;\d^3 x \\
  =& \int_{\R^3} \braket{\psi|\mathbf{x}}\braket{\mathbf{x}|\psi} \;\d^3 x = \mathbf{x}\braket{\psi|\psi}
\end{split}
\tag{\label{equation-93}}
\end{equation*}
$$

Comparing $\eqref{equation-92}$ and $\eqref{equation-93}$, we find

$$
  \braket{\psi|\unitvec{x}|\psi} = \mathbf{x}\braket{\psi|\psi}
$$

The position operator $\unitvec{x}$ can be shown to be Hermitian by noting that

$$
\begin{align*}
  \braket{\psi|\unitvec{x}|\phi} =& \int_{\R^3} \psi^*(\mathbf{x}) \mathbf{x} \phi(\mathbf{x}) \;\d^3 x = \int_{\R^3} \phi(\mathbf{x}) \mathbf{x} \psi^*(\mathbf{x}) \;\d^3 x \\
  =& \left(\int_{\R^3} \phi^*(\mathbf{x}) \mathbf{x} \psi(\mathbf{x}) \;\d^3 x\right)^* = \braket{\phi|\unitvec{x}|\psi}^*
\end{align*}
$$

### Schr√∂dinger equation in position space

In position space, the Schr√∂dinger equation describes the time evolution of the wavefunction $\psi(\mathbf{x},t)$ by the differential equation

$$
  i\hbar \frac{\partial}{\partial t}\psi(\mathbf{x},t) = \hat{H}\psi(\mathbf{x},t)
$$

where $\hat{H}$ is the Hamiltonian operator of the system. In Cartesian coordinates, $\hat{H}$ is derived from the classical Hamiltonian $H(\mathbf{p},\mathbf{x},t)$ by the substitution

$$
  \mathbf{p} \to\unitvec{p} = -i\hbar\nabla
$$

For a non-relativistic particle with mass $m$ subject to a potential $V(\mathbf{x},t)$, the Hamiltonian takes the form

$$
  \hat{H} = -\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{x},t)
$$

### Conservation of probability

The Schr√∂dinger equation ensures that probability is conserved for a quantum system. The partial time derivative of the probability density is

$$
  \frac{\partial P}{\partial t}(\mathbf{x},t) = \frac{\partial}{\partial t}|\psi(\mathbf{x},t)|^2 = \psi^* \frac{\partial\psi}{\partial t} + \frac{\partial\psi^*}{\partial t}\psi
$$

Applying the Schr√∂dinger equation with Hamiltonian $\hat{H} = -\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{x})$ on the partial time derivatives gives

$$
\begin{align*}
  \frac{\partial P}{\partial t} &= -\psi^* \frac{i}{\hbar}\left( -\frac{\hbar^2}{2m}\nabla^2 + V \right)\psi + \psi^* \frac{i}\psi \left(-\frac{\hbar^2}{2m}\nabla^2 + V \right)\psi^* \\
  &= \frac{i\hbar}{2m}\left( \psi^* \nabla^2 \psi - \psi\nabla^2 \psi^* \right) + \frac{i}{\hbar}V\left(\psi\psi^* - \psi^*\psi \right) \\
  &= \frac{i\hbar}{2m}\nabla \cdot \left( \psi^* \nabla \psi - \psi\nabla \psi^* \right)
\end{align*}
$$

If we define the probability current

$$
  \mathbf{J} = -\frac{i\hbar}{2m} \left( \psi^* \nabla \psi - \psi\nabla \psi^* \right)
$$

we get the continuity equation

$$
  \frac{\partial P}{\partial t} + \nabla \cdot \mathbf{J} = 0
$$

To see that this gives a conservation law, consider a volume $V\subseteq\R^3$ enclosed by a surface $S$. The probability that the particle lies in this region is given by

$$
  P_V (t) = \int_V P(\mathbf{x},t)\;\d^3 x
$$

The continuity equation tells us that this probability changes as

$$
  \frac{\partial P_V}{\partial t} = - \int_V \nabla\cdot\mathbf{J}\;\d^3 x = - \int_S \mathbf{J}\cdot\d\mathbf{S}
$$

where the final step follows from the divergence theorem. This shows that a change in $P_V$ produces a flow of probability through $S$.

In the special case $V = \R^3$, then $P = \int_{\R^3} |\psi(\mathbf{x},t)|^2 \; \d^3 x = 1$. The change in probability is

$$
  \frac{\partial P}{\partial t} = - \int_{S_\infty^2} \mathbf{J}\cdot\d\mathbf{S}
$$

where $S_\infty^2$ is the asymptotic $2$-sphere at the infinity of $\R^3$. However, any normalized wavefunction vanishes asymptotically, i.e. $\psi \xrightarrow{|\mathbf{x}|\to\infty} 0$. Consequently, we have $\mathbf{J}\xrightarrow{|\mathbf{x}|\to\infty} 0$. Furthermore, we can check that $\mathbf{J}$ falls off quickly enough so that $\frac{\partial P}{\partial t} = 0$.

## Momentum operator

In classical mechanics, momentum is defined as the quantity which is conserved under global spatial translation, or alternatively, as the generator of spatial translation. Let us consider a system of $N$ partical described by the wavefunction $\psi(\mathbf{x}_1,\dots,\mathbf{x}_N)$. A rigid translation by $\mathbf{a}$ of this system will change $\psi$ into

$$
\begin{align*}
  \psi(\mathbf{x}_1 + \mathbf{a},\dots,\mathbf{x}_N + \mathbf{a}) =& \sum_{j=0}^\infty \sum_{n=1}^N \frac{\mathbf{a}^j}{j!} \cdot \nabla_n^j \psi(\mathbf{x}_1,\dots,\mathbf{x}_N) \\
  =& \exp\left(\mathbf{a} \cdot \sum_{n=1}^N \nabla_n \psi(\mathbf{x}_1,\dots,\mathbf{x}_N) \right) = \hat{U}_a \psi(\mathbf{x}_1,\dots,\mathbf{x}_N)
\end{align*}
$$

where $\hat{U}_\mathbf{a}$ is the unitary translating operator acting on the wavefunction. The translation operator $\hat{U}_\mathbf{x}$ for an arbitrary displacement $\mathbf{x}$ can be written as

$$
  \hat{U}_\mathbf{x} = e^{i\mathbf{x} \cdot \hat{G}}
$$

where $\hat{G}$ is the generator of spatial translation. Consequently, $\hat{G}$ can be identified as

$$
  \hat{G} = -i \sum_{n=1}^N \nabla_n
$$

Thus, $\hat{G}$ represents, up to a constant factor, the total quantum mechanical momentum operator of the $N$-particle system. For dimensional reasons, and following the correspondence principle, this constant is taken to be $\hbar$, so that the momentum operator for a single particle is

$$
  \unitvec{p} = -i\hbar\nabla
$$

To find the eigenfunctions of $\unitvec{p}$, we have to solve the eigenvalue equation

$$
  \unitvec{p} \phi (\mathbf{x}) = \mathbf{p} \phi (\mathbf{x})
$$

where $\phi(\mathbf{x}) = \braket{\mathbf{x}|\mathbf{p}}$ is the eigenfunctions position space, and $\mathbf{p}$ is the eigenvalue corresponding to the. Inserting $\unitvec{p} = i\hbar\nabla$ gives the first-order partial differential equation

$$
  \nabla \phi(\mathbf{x}) = \frac{i}{\hbar} \mathbf{p} \phi(\mathbf{x})
$$

with solution

$$
  \phi_\mathbf{p} (\mathbf{x}) = C e^{\frac{i}{\hbar} \mathbf{p}\cdot\mathbf{x}}
$$

for some integration constant $C$. Using the de Broglie relation, linking the momentum $\mathbf{p}$ to the wave vector $\mathbf{k}$,

$$
  \mathbf{p} = \hbar \mathbf{k}
$$

the eigenfunctions can be rewritten as

$$
  \phi_\mathbf{k} (\mathbf{x}) = C e^{i \mathbf{k} \cdot \mathbf{x}}
$$

which represents spherical waves with wave vector $\mathbf{k}$.

Since $\unitvec{p}$ has a continuous spectrum, the eigenfunctions $\phi_\mathbf{k}$ are not normalizable in the usual sence. Using the following identity for the Dirac delta function 

$$
  \frac{1}{2\pi} \int_{-\infty}^\infty e^{i\alpha x} \;\d x = \delta(\alpha)
$$

we find that

$$
\begin{align*}
  \braket{\phi_\mathbf{k}|\phi_{\mathbf{k}'}} =& \int_{\R^3} \phi_\mathbf{k}^* (\mathbf{x}) \phi_{\mathbf{k}'} (\mathbf{x}) \;\d^3 x \\
  =& |C|^2 \int_{\R^3} e^{i(\mathbf{k}' - \mathbf{k})\cdot\mathbf{x}} \;\d x \\
  =& (2\pi)^3 |C|^2 \delta(\mathbf{k}' - \mathbf{k})
\end{align*}
$$

showing that $\phi_\mathbf{k}$ are normalized in the distributional sense. To ensure that the eigenfunctions satisfy the generalized orthonormality condition, we choose $C = (2\pi)^{-3/2}$ so that

$$
  \braket{\phi_\mathbf{k}|\phi_{\mathbf{k}'}} = \delta(\mathbf{k} - \mathbf{k}')
$$

Thus, the eigenfunctions become

$$
  \phi_\mathbf{k} (\mathbf{x}) = \frac{1}{\sqrt{8\pi^3}} e^{i\mathbf{k}\cdot\mathbf{x}}
$$

### Momentum representation

In momentum space, a state vector $\ket{\psi}$ is expanded in terms of the momentum eigenbasis $\ket{\mathbf{p}}$ with wavefunctions $\tilde{\psi}(\mathbf{p}) = \braket{\mathbf{p}|\psi}$. In the momentum representation, the momentum operator act as a multiplication operator, and the eigenvalue equation for $\tilde{\psi}(\mathbf{p})$ is:

$$
  \unitvec{p} \tilde{\psi}(\mathbf{p}) = \mathbf{p}\tilde{\psi}(\mathbf{p})
$$

To find the connection between the momentum and position representation of the wavefunction, we use that completeness relation of the momentum eigenstates $\ket{\mathbf{p}}$ and express the position-space wavefunction $\psi(\mathbf{x})$ as

$$
  \psi(\mathbf{x}) = \int \braket{\mathbf{x}|\mathbf{p}}\braket{\mathbf{p}|\psi} \;\d^3 p = \int \phi_\mathbf{p} (\mathbf{x}) \tilde{\psi}(\mathbf{p}) \;\d^3 p
$$

Recalling that

$$
  \phi_\mathbf{p} (\mathbf{x}) = \frac{1}{\sqrt{8\pi^3}} e^{\frac{i}{\hbar}\mathbf{p}\cdot\mathbf{x}}
$$

we obtain

$$
  \psi(\mathbf{x}) = \frac{1}{\sqrt{8\pi^3}} \int e^{\frac{i}{\hbar}\mathbf{p}\cdot\mathbf{x}} \tilde{\psi}(\mathbf{p}) \;d^3 p
$$

which is the inverse Fourier transform of $\tilde{\psi}(\mathbf{p})$. Thus, the momentum representation of the wavefunction is related to the position representation by the Fourier transform:

$$
  \tilde{\psi}(\mathbf{p}) = \frac{1}{\sqrt{8\pi^3}} \int e^{-\frac{i}{\hbar} \mathbf{p}\cdot\mathbf{x}} \psi(\mathbf{x}) \;\d^3 x
$$

Using the completeness relation of the position eigenbasis $\ket{\mathbf{x}}$, we can write $\tilde{\psi}(\mathbf{p})$ as

$$
  \tilde{\psi}(\mathbf{p}) = \int \braket{\mathbf{p}|\mathbf{x}}\braket{\mathbf{x}|\psi} \;\d^3 x = \braket{\mathbf{p}|\mathbf{x}} \psi(\mathbf{x}) \;\d^3 x
$$

From the Bessel-Parseval relationship it follows that

$$
  \int_{\R^3} |\psi(\mathbf{x})|^2 \;\d^3 x = 1 \implies \int_{\R^3} |\tilde{\psi}(\mathbf{p})|^2 \;\d^3 x = 1
$$

In the momentum representation, it can be shown that the position operator is given by

$$
  \unitvec{x} = i\hbar \nabla_\mathbf{p}
$$

### Canonical commutation relations

In Cartesian coordinates, the commutation relations of $\unitvec{x} = (\hat{x}_x, \hat{x}_y, \hat{x}_z)$ and $\unitvec{p} = (\hat{p}_x, \hat{p}_y, \hat{p}_z)$ are

$$
\begin{equation*}
  [\hat{x}_i, \hat{x}_j] = [\hat{p}_i, \hat{p}_j] = 0, \quad [\hat{x}_i, \hat{p}_i] = i\hbar\delta_{ij}
\tag{\label{equation-95}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

The canonical commutation relations follows directly from the definitions

$$
  \hat{x}_i = x_i,\quad \hat{p}_i = -i\hbar\frac{\partial}{\partial x_i}
$$

The commutation of position operators is

$$
  [\hat{x}_i, \hat{x}_j]\psi(\mathbf{x}) = \underbrace{(x_i x_j - x_j x_i)}_{=0} \psi(\mathbf{x}) = 0, \;\forall\psi(\mathbf{x})
$$

By equality of mixed partials, the commutation of momentum operators is

$$
  [\hat{p}_i, \hat{p}_j]\psi(\mathbf{x}) = -i\hbar\left(\frac{\partial}{\partial x_i}\frac{\partial}{\partial x_j} - \frac{\partial}{\partial x_j}\frac{\partial}{\partial x_i}\right)\psi(\mathbf{x}) = 0, \;\forall\psi(\mathbf{x})
$$

Finally,

$$
\begin{align*}
  [\hat{x}_i, \hat{p}_j]\psi(\mathbf{x}) =& -i\hbar\left(x_i \frac{\partial}{\partial x_j} - \frac{\partial}{\partial x_j} x_i \right)\psi(\mathbf{x}) \\
  =& -i\hbar\left(x_i \frac{\partial\psi(\mathbf{x})}{\partial x_j} - \psi(\mathbf{x})\frac{\partial x_i}{\partial x_j} - x_i \frac{\partial \psi(\mathbf{x})}{\partial x_j} \right) \\
  =& i\hbar\psi(\mathbf{x}) \frac{\partial x_i}{\partial x_j} = i\hbar_{ij} \psi(\mathbf{x}), \;\forall\psi(\mathbf{x})
\end{align*}
$$
</details>

where $\delta_{ij}$ is the Kronecker delta. These are known as the *canonical commutation relations*. From $\eqref{equation-95}$, we have eight complete sets of commuting observables:

$$
\begin{align*}
  &\set{\hat{x},\hat{y},\hat{z}}, &\set{\hat{x}, \hat{p}_y, \hat{p}_z}, & \set{\hat{x}, \hat{p}_y, \hat{z}}, & \set{\hat{x}, \hat{y}, \hat{p}_z} \\
  &\set{\hat{p}_x, \hat{p}_y, \hat{p}_z}, & \set{\hat{p}_x, \hat{y}, \hat{z}}, & \set{\hat{p}_x, \hat{y}, \hat{p}_z}, & \set{\hat{p}_x, \hat{p}_y, \hat{z}}
\end{align*}
$$

<MathBox title="Unitary operators are analogous to canonical transformations" boxType="remark">
In classical mechanics, canonical transformations are phase-space transformations $(q, p) \mapsto (q', p')$ that preserve the Poisson bracket structure:

$$
  \{q', p'\} = \{q, p\} = 1
$$

In quantum mechanics, unitary operators play the same role of canonical transformation in classical mechanics, since they leave the canonical commutation relations invariant. Let 

$$
  \hat{q}' = \hat{U}\hat{q}\hat{U}^\dagger,\quad \hat{p}' = \hat{U}\hat{p}\hat{U}^\dagger
$$

be unitary transformations of the canonical observables $\hat{q}$ and $\hat{p}$, satisfying the canonical commutation relation $[\hat{q}, \hat{p}] = i\hbar\hat{I}$. Then

$$
\begin{align*}
  [\hat{q}', \hat{p}'] =& \hat{U}\hat{q}\hat{U}^\dagger \hat{U}\hat{p}\hat{U}^\dagger - \hat{U}\hat{p}\hat{U}^\dagger \hat{U}\hat{q}\hat{U}^\dagger \\
  =& \hat{U}\hat{q}\hat{p}\hat{U}^\dagger - \hat{U}\hat{p}\hat{q}\hat{U}^\dagger\\
  =& \hat{U}[\hat{q},\hat{p}]\hat{U}^\dagger
  =& i\hbar\hat{I}
\end{align*}
$$
</MathBox>

### Position-momentum uncertainty relation

From the uncertainty principle $\eqref{equation-102}$ and the canonical commutation relations $\eqref{equation-95}$, we find the position-momentum uncertainty relation

$$
  \Delta x \Delta_\psi p_x \geq \frac{\hbar}{2}
$$

This result can also be derived as follows. Without loss of generality, consider a normalized wavefunction $\psi(x)$ for which both the position and position mean values are zero, i.e.

$$
\begin{align*}
  \braket{\hat{x}}_\psi =& \braket{\psi|\hat{x}|\psi} = 0 \\
  \braket{\hat{p}_x}_\psi =& \braket{\psi|\hat{p}_x|\psi} = 0
\end{align*}
$$

This normalization condition excludes the case of eigenfunctions of position and momentum. We define the standard deviations of position and momentum as

$$
\begin{align*}
  \Delta_\psi x =& \Braket{(\hat{x} - \braket{\hat{x}})^2}^{1/2} = [\braket{\psi|(\hat{x} - \braket{\psi|\hat{x}|\psi})^2|\psi}]^{1/2} \\
  \Delta_\psi p_x =& \Braket{(\hat{p}_x - \braket{\hat{p}})^2}^{1/2} = [\braket{\psi|(\hat{p}_x - \braket{\psi|\hat{p}_x|\psi})^2|\psi}]^{1/2}
\end{align*}
$$

as the standard deviations. For any wavefunction $\psi(x)$, we must have

$$
\begin{equation*}
  \int_{-\infty}^\infty \left|ax\psi(x) + \frac{\d\psi(x)}{\d x}\right|^2 \;\d x \geq 0
\tag{\label{equation-103}}
\end{equation*}
$$

where $a$ is an arbitrary real constant. Expanding the the square modulus inside the integral, we obtain

$$
\begin{align*}
  \left|ax\psi(x) + \frac{\d\psi(x)}{\d x}\right|^2 =& a^2 x^2 |\psi(x)|^2 \\
  &+ ax\left(\psi(x) \frac{\d \psi^* (x)}{\d x} + \psi^* (x) \frac{\d\psi(x)}{\d x} \right) \\
  &+ \frac{\d\psi(x)}{\d x}\frac{\d\psi^* (x)}{\d x}
\end{align*}
$$

Integrating the first term yields

$$
  a^2 \int_{-\infty}^\infty x^2 |\psi(x)|^2 = a^2 (\Delta_\psi x)^2
$$

Integrating by parts the second term gives

$$
\begin{align*}
  & a\int_{-\infty}^\infty \left(\psi(x) \frac{\d\psi^* (x)}{\d x} + \psi^* (x) \frac{\d\psi(x)}{\d x} \right) \;\d x \\
  =& a\int_{-\infty}^\infty \frac{\d|\psi(x)|^2}{\d x} x \;\d x \\
  =& a\left[x|\psi(x)|^2\right]_{-\infty}^\infty - a\int_{-\infty}^\infty |\psi(x)|^2 \;\d x \\
  =& -a \int_{-\infty}^\infty |\psi(x)|^2 = -a
\end{align*}
$$

where we have used the fact that

$$
  \lim_{x\to\pm\infty} x|\psi(x)|^2 = 0
$$

due to the normalization of $\psi(x)$. Integrating by parts the last term, we have

$$
\begin{align*}
  \int_{-\infty}^\infty \frac{\d\psi(x)}{\d x}\frac{\d\psi^*(x)}{\d x} \;\d x =& \left[\psi^* (x) \frac{\d\psi(x)}{\d x}\right]_{-\infty}^\infty - \int_{-\infty}^\infty \psi^* (x) \frac{\d^2 \psi(x)}{\d x^2} \;\d x \\
  =& \hbar^{-2} \int_{-\infty}^\infty \psi^* (x) \hat{p}_x^2 \psi(x) \;\d x \\
  =& \hbar^{-2} (\Delta_\psi p_x)^2
\end{align*}
$$

where have used the fact that

$$
  \lim_{x\to\pm\infty} \psi^* (x) \frac{\d\psi(x)}{\d x} = 0
$$

because $\braket{\hat{p}_x}_\psi = 0$ and

$$
  \frac{\d}{\d x} = \frac{i}{\hbar} \hat{p}_x
$$

Thus, $\eqref{equation-103}$ evaluates to a quadratic inequality in $a$:

$$
  a^2 (\Delta_\psi x)^2 - a + \hbar^{-2} (\Delta_\psi p_x)^2 \geq 0
$$

In order to satisfy this condition, the discriminant must be negative, i.e.

$$
  1 - 4\hbar^{-2} (\Delta_\psi x)^2 (\Delta_\psi p_x)^2 \leq 0
$$

Rearranging, we get the position-momentum uncertainty relation

$$
  \Delta x \Delta p_x \geq \frac{\hbar}{2}
$$

### Quantum virial theorem

Consider a system of $N$ particles with momentum $\unitvec{p}_a$ and position $\unitvec{r}_a$. If the system is bound by a conservative force with Hamiltonian

$$
  \hat{H} = \hat{T} + \hat{V} = \sum_{a=1}^N \frac{\unitvec{p}^2}{2m_a} + \hat{V}(\mathbf{r}_1, \dots,\mathbf{r}_N)
$$

the quantum virial theorem states that 

$$
  \hat{T} = \frac{1}{2} \Braket{\sum_a \unitvec{r}_a \cdot \nabla_a V(\mathbf{r}_a)}
$$

If $V$ is a power-law potential satisfying

$$
  V(\lambda \mathbf{r}_1,\dots,\lambda\mathbf{r}_N) = \lambda^s V(\mathbf{r}_1,\dots,\mathbf{r}_N)
$$

then Euler's theorem on homogenous functions implies

$$
  \sum_a \mathbf{r}_a \cdot \nabla_a V = sV
$$

and the virial theorem reduces to

$$
  \braket{T} = \frac{s}{2} \braket{V}
$$

<details>
<summary>Proof</summary>

Consider the conserved observable

$$
  \hat{Q} := \sum_a \unitvec{r}_a \cdot \unitvec{p}_a
$$

with no explicit time dependence such that

$$
  \frac{\partial}{\partial t} \hat{Q} = 0 
$$

By Ehrenfest's theorem $\eqref{equation-81}$, we obtain

$$
\begin{equation*}
  \frac{d}{\d t} \braket{\hat{Q}} = \frac{i}{\hbar} \braket{[\hat{H}, \hat{Q}]}
\tag{\label{equation-173}}
\end{equation*}
$$

We evaluate $[\hat{H}, \hat{Q}]$ term by term, using the canonical commutation relations $\eqref{equation-95}$

1. **Kinetic term:** For a single particle
$$
\begin{align*}
  [\hat{\mathbf{p}}^2, \hat{\mathbf{r}}\cdot\hat{\mathbf{p}}] =& \sum_j [\hat{p}_k \hat{p}_k, \hat{r}_j \hat{p}_j] \\
  =& \sum_j (\underbrace{[\hat{p}_k \hat{p}_k, \hat{r}_j]}_{=-2i\hbar} \hat{p}_j + \hat{r}_j \underbrace{[\hat{p}_k \hat{p}_k, \hat{p}_j]}_{=0}) \\
  =& -2i\hbar\unitvec{p}^2
\end{align*}
$$

2. **Potential term:**
$$
\begin{align*}
  [V, \hat{\mathbf{r}}\cdot\mathbf{p}] =& \sum_j \hat{r}_j [V, \hat{p}_j] = \sum_j \hat{r}_j (i\hbar\delta_j V) \\
  =& i\hbar\unitvec{r} \cdot \nabla V
\end{align*}
$$

Combining both contributions gives

$$
  [\hat{H}, \hat{Q}] = -2i\hbar\hat{T} + i\hbar\sum_a \unitvec{r}_a \cdot \nabla_a V
$$

Substituting into $\eqref{equation-173}$, we get

$$
  \frac{\d}{\d t} \braket{\hat{Q}} = 2\braket{\hat{T}} - \Braket{\sum_a \unitvec{r}_a \cdot\nabla_a V}
$$

Taking the average over a time interval $\tau$, we obtain

$$
  \frac{1}{\tau} \int_0^{\tau} \frac{\d}{\d t} \braket{\hat{Q}} \;\d t = \frac{1}{\tau} \int_0^\tau \left(2\braket{T} - \Braket{\sum_a \unitvec{r}_a \cdot\nabla_a V} \right) \d t
$$

Because the expectation values on the right are independent of time

$$
  \frac{1}{\tau} \braket{Q}|_0^\tau = 2\braket{T} - \Braket{\sum_a \unitvec{r}_a \cdot\nabla_a V}
$$

For a bound system, the expectation value of $\hat{Q}$ remains finite, and either
- for periodic motion, we may choose $\tau$ as the period, or
- for non-periodic motion, $\braket{\hat{Q}}_\tau - \braket{\hat{Q}}_0$ is bounded while $\tau\to\infty$
so that the left-hand side vanishes in the long-time average. Hence,

$$
  \braket{\hat{T}} = \frac{1}{2} \Braket{\sum_a \unitvec{r}_a \cdot\nabla_a V}
$$
</details>

## Energy

### Energy-time uncertainty relation

To derive the uncertainty relation between energy and time, we begin by appling the generalize uncertainty principle $\eqref{equation-102}$ for the Hamiltonian $\hat{H}$ and an orbitrary observable $\hat{O}$

$$
  \Delta_\psi E \cdot \Delta_\psi O \geq \frac{1}{2}\left|\braket{\psi|[\hat{H},\hat{O}]|\psi}\right|
$$

Next, we use the Heisenberg equation of motion for expectation $\eqref{equation-105}$ to relate the commutator $[\hat{O}(t), \hat{H}]$ to the rate of change of the mean value of $\hat{O}$:

$$
  \braket{\psi|[\hat{O}(t),\hat{H}]|\psi} = i\hbar \frac{\d}{\d t} \braket{\psi|\hat{O}(t)|\psi}
$$

where the time evolution is taken in the Heisenberg picture. Substituting this into the uncertainty relation, we get

$$
  \Delta_\psi E \cdot \Delta_\psi O \geq \frac{\hbar}{2}\left|i\frac{\d}{\d t}\braket{\psi|\hat{O}(t)|\psi}\right|
$$

Diving both sides by the absolute value of the rate of change of $\braket{\psi|\hat{O}(t)|\psi}$, we obtain

$$
  \Delta_\psi \frac{\Delta_\psi O}{\left|\frac{\d}{\d t}\braket{\psi|\hat{O}(t)|\psi}\right|} \geq \frac{\hbar}{2}
$$

Now, we define the time $\Delta_\psi t$ as the time required for $\braket{\psi|\hat{O}|\psi}$ to change from by a small amount $\Delta_\psi O$. Assuming a linear change and neglecting higher-order terms in the Taylor expansion of $\hat{O}(t)$, this time is given by

$$
  \Delta_\psi t = \left. \frac{\Delta_\psi O}{\frac{\d}{\d t}\braket{\psi|\hat{O}(t)|\psi}}\right|_{t=t_0}
$$

where we assume that

$$
  \frac{\d}{\d t}\braket{\psi|\hat{O}(t)|\psi} > 0
$$

Finally, we arrive at the uncertainty relation

$$
  \Delta E \delta_t \geq \frac{\hbar}{2}
$$

This inequality can be applied to describe the lifetime-width relation for unstable systems. These systems are not stationary and do not correspond to a well-defined value of the energy, but rather to an energy spectrum with certain spread $\Delta E$, called the level width. The mean lifetime $\tau$ os the stable state represents the average time it takes for the system to undergo a significant change in its properties. Thus, we can relate the lifetime of the state to the energy uncertainty through the following relation

$$
  \tau \Delta E \simeq \hbar
$$

This relation highlights the inverse relationship between the lifetime of the state and the widt of the energy distribution: a shorter lifetime corresponds to a broader energy spread, and vice versa.

### Time-of-arrival operator

A condition that one may reasonably impose on a time operator $\hat{t}$ is

$$
  \braket{\psi(t_1)|\hat{t}|\psi(t_1)} - \braket{\psi(t_2)|\hat{t}|\psi(t_2)} = t_1 - t_2
$$

for any $\ket{\psi(t_1)}$ and $\ket{\psi(t_2)}$. However, Pauli demonstrated that it is impossible to define a time operator $\hat{t}$ that satisfies the commutation relation $[\hat{t},\hat{H}] = -i\hbar$, where time and energy are conjugate observables. This follows from the requirement that energy must be bounded from below. Pauli's argument proceeds as follows. Let $\ket{\psi_E}$ be an eigenstate of the Hamiltonian $\hat{H}$, such that

$$
  \hat{H}\ket{\psi_E} = E\ket{\psi_E}
$$

Applying the Schr√∂dinger equation, we also have

$$
  \hat{H} e^{i\alpha\hat{t}} \ket{\psi_E} = (E - \alpha\hbar) e^{i\alpha\hat{t}} \ket{\psi_E}
$$

where $\alpha$ is an arbitrary constant. As a consequence, also $e^{i\alpha\hat{t}} \ket{\psi_E}$ is an eigenstate of the energy with eigenvalue $E - \alpha\hbar$, and the spectrum of $\hat{H}$ cannot be bounded if $[\hat{t},\hat{H}] = -i\hbar$ must hold.

A way to circumvent this issue is to consider alternative formulations of a time operator. One such approach involves the time-of-arrival operator, which describes the time at which a particle arrives at a fixed detector position $X$, linking an observable property of the system with an operational measurement procedure.

A key difficulty in defining a time operator $\hat{t}$ arises from its spectral decomposition. For an arbitrary self-adjoint operator $\hat{O}$, completeness implies

$$
  \int_{-\infty}^\infty \hat{P}(o) \;\d o = \hat{I}
$$

However, for a time operator, this does not necessarily hold. Not all states of a system will be detected at some time, mean that the spectral familty $\hat{P}(t)$ is incomplete. Instead, $\hat{P}_{\hat{t}}$ only projects onto the subspace $\mathcal{H}_\text{D} \subseteq\mathcal{H}$, formed by states detected at position $X$. If we define $\hat{P}(t)$ over the entire Hilbert space, we lose the ability to distinguish between undetectable initial states ($\hat{P}(t = 0)$) and states in $\mathcal{H}_\text{D}^c$ that are never detected.

For a classical free particle in one dimension, the time-of-arrival at $X$ with initial position $x^0$ and momentum $p_x^0$ is

$$
  t(X) = \frac{m(X - x^0)}{p_x^0}
$$

which follows from the classical equation of motion

$$
  x(t; x^0, p_x^0) = \frac{p_x^0}{m}t + x^0
$$

Note that, except for the problem at $p_x^0 = 0$, the particle is always detected. In the quantum case, we define a time-of-arrival operator in the Heisenberg picture as

$$
  \hat{t}(X) = \frac{m(X - \hat{x}^0)}{\hat{p}_x^0}
$$

which is of course problematic because $\hat{x}^0$ and $\hat{p}_x^0$ do not commute. To address this, we impose a symmetric ordering

$$
\begin{align*}
  \hat{t}(X) =& \frac{mX}{\hat{p}_x^0} - m\frac{1}{\sqrt{\hat{p}_x^0}} \hat{x}_0 \frac{1}{\sqrt{\hat{p}_x^0}} \\
  =& -t \frac{m}{\hbar}\frac{1}{\sqrt{k_x}} \frac{\d}{\d k_x} \frac{1}{\sqrt{k_x}} + \frac{m}{\hbar} \frac{X}{k_x}
\end{align*}
$$

where $\sqrt{k_x} = i\sqrt{|k_x|}$ for $k < 0$. The operator family $\hat{t}(X)$ is unitarily related via

$$
  \hat{t}(X) = e^{ik_x X} \hat{t}(0) e^{-ik_x X}
$$

where $e^{-ik_x X}$ is the space counterpart of $\hat{U}_t$. Thus, without loss of generality, it suffices to study the operator $\hat{t}(0)$ with the detector placed at the origin ($X = 0$), dropping the explicit $X$-dependence:

$$
  \hat{t} = -i \frac{m}{\hbar} \frac{1}{\sqrt{k_x}} \frac{\d}{\d k_x} \frac{1}{\sqrt{k_x}}
$$

where the $\hat{t}$ satisfies the eigenvalue equation

$$
  \hat{t}\ket{t} = t\ket{t}
$$

with eigenvectors $\ket{t}$. In the momentum representation, this translates to

$$
  \hat{t}\braket{k_x | t} = \left(-i\frac{m}{\hbar}\frac{1}{\sqrt{k_x}}\frac{\d}{\d k_x} \frac{1}{\sqrt{k_x}}\right) \braket{k_x|t} = t\braket{k_x|t}
$$

A major issue with this time operator is the singularity at $k_x = 0$. To resolve this, we introduce family of real bounded continuous odd functions $f_\epsilon (k)$ which approach $1/k_x$ pointwise for $\epsilon > 0$:

$$
\begin{equation*}
  f_\epsilon (k_x) = \begin{cases}
    \frac{1}{k_x}, \quad& |k_x| > \epsilon \\
    \epsilon^{-2} k_x, \quad& |k_x| < \epsilon
  \end{cases}
\tag{\label{equation-106}}
\end{equation*}
$$

The regularized time-of-arrival operator becomes

$$
  \hat{t}_\epsilon = -i\frac{m}{\hbar}\sqrt{f_\epsilon (k_x)} \frac{\d}{\d k_x} \sqrt{f_\epsilon (k_x)}
$$

This yields the modified commutation relation

$$
  [\hat{t}_\epsilon, \hat{H}] = -i\hbar (\hat{I} - g_\epsilon (k_x))
$$

where

$$
  g_\epsilon (k_x) = 1 - k_x f_\epsilon (k)
$$

Since $g_\epsilon (k_x)$ vanishes for $|k_x| > \epsilon$, and remains bounded in the small interval where it has support, the energy-time uncertainty relation for a s tate $\ket{\psi}$ is

$$
  \Delta t_\epsilon \Delta E \geq \frac{\hbar}{2} (1 - \braket{\psi|g_\epsilon (k_x)|\psi})^2
$$

For sufficiently small $\epsilon$ and states with support away from $k_x$, this implies 

$$
  \Delta t_\epsilon \Delta E \geq \hbar/2
$$

Thus, by regularizing the singularity at $k_x = 0$, we recover the energy-time uncertainty relation.

## Orbital angular momentum

In classical mechanics, the angular momentum of a particle with momentum $\mathbf{p}$ is given by $\mathbf{L} = \mathbf{r}\times\mathbf{p}$ with respect to the origin. The corresponding quantum operator is obtained by substituting $\mathbf{p} \to -i\hbar\nabla$, giving

$$
  \unitvec{L} = \unitvec{r} \times \unitvec{p} = -i\hbar(\mathbf{r} \times\nabla)
$$

Since both $\unitvec{r}$ and $\unitvec{p}$ are Hermitian it follows that

$$
\begin{align*}
  \mathbf{L}^\dagger =& (\unitvec{r} \times \unitvec{p})^\dagger = -\unitvec{p}^\dagger \times \unitvec{r}^\dagger \\
  =& -\unitvec{p} \times \unitvec{r} = \unitvec{r} \times \unitvec{p} = \mathbf{L}^\dagger
\end{align*}
$$

showing that $\mathbf{L}$ is Hermitian. In Cartesian coordinates $\mathbf{r} = (x,y,z)$, the components of $\unitvec{L}$ are given by

$$
\begin{align*}
  \hat{L}_x =& \hat{y}\hat{p}_z - \hat{p}_y \hat{z} = -i\hbar\left(y \frac{\partial}{\partial z} - z \frac{\partial}{\partial y}\right) \\
  \hat{L}_y =& \hat{z}\hat{p}_x - \hat{p}_z \hat{x} = -i\hbar\left(z \frac{\partial}{\partial x} - x \frac{\partial}{\partial z}\right) \\
  \hat{L}_z =& \hat{x}\hat{p}_y - \hat{p}_x \hat{y} = -i\hbar\left(x \frac{\partial}{\partial y} - y \frac{\partial}{\partial x}\right) 
\end{align*}
$$

Using the Levi-Civita symbol, $\varepsilon_{ijk}$, this can be compactly written as

$$
  \hat{L}_i = (\unitvec{r} \times\unitvec{p})_i = \varepsilon_{ijk} \hat{r}_j \hat{p}_k = -i\hbar \varepsilon_{ijk} r_j \frac{\partial}{\partial r_k}
$$

The angular momentum operator obeys the commutation relations

$$
\begin{align*}
  [\hat{L}_i, \hat{L}_j] =& i\hbar\varepsilon_{ijk} L_k \\
  [\hat{L}_i, \hat{r}_j] =& i\hbar\varepsilon_{ijk}\hat{r}_k \\
  [\hat{L}_i, \hat{p}_j] =& i\hbar\varepsilon_{ijk}\hat{p}_k
\end{align*}
$$

<details>
<summary>Details</summary>

Noting that $[\hat{r}_i, \hat{p}_j] = i\hbar\delta_{ij}$ and $\varepsilon_{ijk}\varepsilon_{klm} = \delta_{il} \delta_{jm} - \delta_{im} \delta_{jl}$, we obtain

$$
\begin{align*}
  [\hat{L}_i, \hat{L}_j] =& [\varepsilon_{ikl} \hat{r}_k \hat{p}_l, \varepsilon_{jmn} \hat{r}_m \hat{p}_n] = \varepsilon_{ikl} \varepsilon_{jmn}[\hat{r}_k \hat{p}_l, \hat{r}_m \hat{p}_n] \\
  =& \varepsilon_{ikl} \varepsilon_{jmn} (\hat{r}_k [\hat{p}_l, \hat{r}_m \hat{p}_n] + [\hat{r}_k, \hat{r}_m \hat{p}_n] p_l) \\
  =& \varepsilon_{ikl} \varepsilon_{jmn} (\hat{r}_k \underbrace{[\hat{p}_l, \hat{r}_m]}_{-i\hbar\delta_{lm}} \hat{p}_n + \hat{r}_m \underbrace{[\hat{r}_k, \hat{p}_n]}_{i\hbar\delta_{kn}}\hat{p}_l) \\
  =& \varepsilon_{ikl} \varepsilon_{jmn} (-i\hbar\delta_{lm} \hat{r}_k \hat{p}_n + i\hbar\delta_{kn} \hat{r}_m \hat{p}_l) \\
  =& -i\hbar \varepsilon_{ikl} \varepsilon_{jlm} \hat{r}_k \hat{p}_m + i\hbar \varepsilon_{ikl} \varepsilon_{jmk} \hat{r}_m \hat{p}_k \\
  =& -i\hbar \varepsilon_{ikl} \varepsilon_{ljm} \hat{r}_k \hat{p}_n - i\hbar \varepsilon_{jmk} \varepsilon_{kil} \hat{r}_m \hat{p}_k \\
  =& i\hbar(\delta_{ij}\delta_{kn} - \delta_{in}\delta_{jk})\hat{r}_k \hat{p}_n - i\hbar(\delta_{ji}\delta_{ml} - \delta_{jl}\delta_{mi}) \hat{r}_m \hat{p}_l \\
  =& i\hbar (\delta_ij \hat{r}_k \hat{p}_k - \hat{r}_j \hat{p}_i) - i\hbar(\delta_{ij} \hat{x}_l \hat{p}_l - \hat{r}_i \hat{p}_j) \\
  =& i\hbar (\hat{r}_i \hat{p}_j - \hat{r}_j \hat{p}_j) = i\hbar \varepsilon_{ijk} (\unitvec{r} \times \unitvec{p})_k  \\
  =& i\hbar \varepsilon_{ijk} \hat{r}_j \hat{p}_k = i\hbar \varepsilon_{ijk} L_k
\end{align*}
$$

Similarly,

$$
  [\hat{L}_i, \hat{r}_j] = [\varepsilon_{ikl} \hat{r}_k \hat{p}_l, \hat{r}_j] = \varepsilon_{ikl} \hat{r}_k \underbrace{[\hat{p}_l, \hat{r}_j]}_{-i\hbar\delta_{lj}} = -\varepsilon_{ikj} \hat{r}_k = \varepsilon_{ijk} \hat{r}_k
$$

and 

$$
  [\hat{L}_i, \hat{p}_j] = [\varepsilon_{ikl} \hat{r}_k \hat{p}_l, \hat{p}_j] = -\varepsilon_{ikl} [\hat{p}_l \hat{r}_k, \hat{p}_j] = \varepsilon_{ilk} \hat{p}_k \underbrace{[\hat{r}_l, \hat{p}_j]}_{i\hbar\delta_{lj}} = \varepsilon_{ijk} \hat{p}_k
$$
</details>

The components of $\unitvec{L}$ are incompatible observables with uncertainty

$$
  \sigma_{\hat{L}_i} \sigma_{\hat{L}_j} \geq \left(\frac{1}{2i} \langle [\hat{L}_i, \hat{L}_j] \rangle \right) = \left(\frac{1}{2i} \langle i\hbar\hat{L}_k \rangle \right) = \frac{\hbar}{2} \langle \hat{L}_k \rangle
$$

The cross product of $\unitvec{L}$ with itself is 

$$
\begin{align*}
  (\unitvec{L}\times\unitvec{L})_i =& -(\unitvec{L}\times\unitvec{L})_i + \varepsilon_{ijk} [\hat{L}_j, \hat{L}_k] \\
  =& \frac{i\hbar}{2} \varepsilon_{jki} \varepsilon_{jkm} \hat{L}_m \\
  =& \frac{i\hbar}{2}(\delta_{kk}\delta_{im} - \delta_{km} \delta_{ik}) \hat{L}_m \\
  =& \frac{i\hbar}{2}(\hat{L}_i - \delta_{ik} \hat{L}_k) \\
  =& i\hbar\hat{L}_i 
\end{align*}
$$

or

$$
  \unitvec{L}\times\unitvec{L} = i\hbar\unitvec{L}
$$

The square of the total angular momentum operator $\unitvec{L}^2 = \unitvec{L}\cdot\unitvec{L} = \sum_{i=1}^3 \hat{L}_i^2$ is a Hermitian operator that commutes with any one of the components of $\unitvec{L}$

$$
  [\unitvec{L}^2, \hat{L}_i] = 0
$$

<details>
<summary>Proof</summary>

The momentum squared is $\unitvec{L}^2 = \unitvec{L}\cdot\unitvec{L}$ and therefore

$$
\begin{align*}
  [\unitvec{L}^2, \hat{L}_j] =& [\hat{L}_i \hat{L}_i, \hat{L}_j] \\
  =& \hat{L}_i [\hat{L}_i, \hat{L}_j] + [\hat{L}_i, \hat{L}_j]\hat{L}_i \\
  =& i\hbar\varepsilon_{ijk}\hat{L}_i \hat{L}_k + i\hbar\varepsilon_{ijk}\hat{L}_k \hat{L}_i
\end{align*}
$$

Since

$$
  \varepsilon_{ijk} \hat{L}_k \hat{L}_i = \varepsilon_{kji} \hat{L}_i \hat{L}_k = \varepsilon_{ijk}\hat{L}_i \hat{L}_k
$$

It follows that

$$
  [\unitvec{L}^2, \hat{L}_j] = 0
$$
</details>

This means that $\unitvec{L}^2$ is compatible with any one of the components of $\unitvec{L}$. 

### Generator of rotations

Consider the action a unitary rotation operator on a generic state vector $\ket{\psi}$. A finite rotation by an angle $\theta$ about an axis defined by a unit vector $\mathbf{n}$ is given by

$$
\begin{equation*}
  \hat{U}_\mathbf{n} (\theta) = e^{i\theta\mathbf{n}\cdot\unitvec{L}/\hbar} = e^{i\theta\mathbf{n}\unitvec{l}}
\tag{\label{equation-161}}
\end{equation*}
$$

where

$$
  \unitvec{l} = \frac{\unitvec{L}}{\hbar} = \unitvec{r}\times\unitvec{k}
$$

and $\unitvec{k} = \unitvec{p}/\hbar = -i\nabla$ is the propagation vector. For an infinitesimal angle $\delta\theta \to 0$, a first-order Taylor series expansion of $\eqref{equation-161}$ yields

$$
  \hat{U}_\mathbf{n} (\delta\theta) \simeq 1 + i\delta\theta \mathbf{n}\cdot\unitvec{l} = 1 + i\delta\theta\hat{R}
$$

where $\hat{R} = \mathbf{n}\cdot\unitvec{l}$ is the generator of rotations about $\mathbf{n}$. The unitary transformation induced by $\hat{U}_\mathbf{n} (\delta\theta)$ acts on a generic operator $\hat{O}$ as

$$
\begin{align*}
  \hat{O} \mapsto \hat{O}' =& \hat{U}_\mathbf{n} (\delta\theta) \hat{O} \hat{U}_\mathbf{n}^\dagger (\delta\theta) \\
  =& (1 + i\delta\theta\hat{R})\hat{O}(1 - i\delta\theta\hat{R}) \\
  =& \hat{O} + \delta\hat{O}
\end{align*}
$$

Expanding to the first order in $\delta\theta$ gives

$$
  \hat{O}' \simeq \hat{O} + i\delta\theta[\hat{R}, \hat{O}] = \hat{O} + \delta\hat{O}
$$

so that

$$
\begin{equation*}
  \delta\hat{O} \simeq i\delta\theta[\hat{R}, \hat{O}]
\tag{\label{equation-162}}
\end{equation*}
$$

An operator $\hat{O}$ is called a scalar under rotations if it remains invariant under all such transformations, i.e.

$$
  \hat{U}_\mathbf{n} (\theta) \hat{O} \hat{U}_\mathbf{n}^\dagger (\theta) = \hat{O}, \forall \theta, \mathbf{n}
$$

From $\eqref{equation-162}$ this is equivalent to the commutation relation

$$
  [\hat{R}, \hat{O}] = 0
$$

Since the generator $\hat{R}$ is the projection of $\unitvec{L}$ along the direction $\mathbf{n}$, it follows that each component of $\unitvec{L}$ commutes with $\unitvec{L}^2$, $\hat{R}^2$ and $\unitvec{p}^2$, all of which are scalars for the rotations.

In spherically symmetric systems, the Hamiltonian is invariant under rotations

$$
  \hat{U}_\mathbf{n} (\theta) \hat{H} \hat{U}_\mathbf{n}^\dagger = \hat{H}
$$

Equivalently, $[\hat{H}, \unitvec{L}] = 0$, meaning that $\mathbf{L}$ is conserved.

### Eigenvalues

To find the eigenvalues of $\unitvec{L}$, we have to choose a complete set of angular momentum observables. Since different components of the angular momentum do not commute with each other, we have to choose a pair of commuting observables we wish to jointly diagonalize, say $\unitvec{L}^2$ and $\hat{L}_z$. First we note that we must have $\unitvec{L}^2 - \hat{L}_z^2 = \hat{L}_x^2 +\hat{L}_y^2 \geq 0$. For our Hilbert space basis, we choose a set of states $\ket{\ell, m_\ell}$ that have definite values of $\unitvec{L}^2$ and $\hat{L}_z$. In this context, $\ket{\ell, m_\ell}$ is an eigenstate of both $\unitvec{L}^2$ and $\hat{L}_z$, where $m_\ell$ is the eigenvalue of $\hat{L}_z$. We then have

$$
  \braket{\ell, m_\ell | \unitvec{L}^2 - \hat{L}_z^2 | l, m_\ell} = \braket{\ell, m_\ell | \hat{L}_x^2 + \hat{L}_y^2 | l, m_\ell} \geq 0
$$

This means that the eigenvalues of $\hat{L}_z^2$ cannot exceed the eigenvalues of $\unitvec{L}^2$, i.e. once the eigenvalue of $\unitvec{L}^2$ is fixed, $\hat{L}_z^2$ is bounded. Let us denote by $\ell$ the maximal eigenvalue of $\hat{L}_z$, that is

$$
  - \ell \leq m_\ell \leq \ell
$$

where $\ell$ is the azimuthal quantum number, while $m_\ell$ is the magnetic quantum number, so that we can write

$$
  \hat{L}_z \ket{\ell, m_\ell} = m_\ell \ket{\ell, m_\ell}
$$

In order to investigate the algebra of angular momentum, it is convenient to introduce raising and lowering operators

$$
  \hat{L}_\pm = \hat{L}_x \pm i \hat{L}_y
$$

which satisfy

$$
  \hat{L}_- = \hat{L}_+^\dagger
$$

and the commutation relations
1. $[\unitvec{L}^2, \hat{L}_\pm] = 0$
2. $[\hat{L}_+, \hat{L}_-]= 2\hat{L}_z$
2. $[\hat{L}_z, \hat{L}_\pm] = \pm\hbar\hat{L}_\pm$
3. $[\hat{L}_z, \hat{L}_\pm^2] = \pm 2\hbar\hat{L}_\pm^2$

<details>
<summary>Proof</summary>

**(1):** Since both $\hat{L}_x$ and $\hat{L}_y$ commute with $\unitvec{L}^2$, it follows that

$$
\begin{equation*}
  [\unitvec{L}^2, \hat{L}_\pm] = \underbrace{[\unitvec{L}^2, \hat{L}_x]}_{=0} + i\underbrace{[\unitvec{L}^2, \hat{L}_y]}_{=0} = 0
\tag{\label{equation-22}}
\end{equation*}
$$

**(3):** The commutation of $\hat{L}_\pm$ with $\hat{L}_z$ is

$$
\begin{equation*}
\begin{split}
  [\hat{L}_z, \hat{L}_{\pm}] =& [\hat{L}_z, \hat{L}_x] \pm i[\hat{L}_z, \hat{L}_y] \\
  =& i\hbar\hat{L}_y \pm i(-i\hbar\hat{L}_x) \\
  =& \pm\hbar (\hat{L}_x \pm i\hat{L}_y) = \pm\hbar\hat{L}_\pm 
\end{split}  
\tag{\label{equation-23}}
\end{equation*}
$$

**(4):** The commutation of $\hat{L}_\pm^2$ with $\hat{L}_z$ is

$$
  [\hat{L}_z, \hat{L}_\pm^2] = \hat{L}_\pm [\hat{L}_z, \hat{L}_\pm] + [\hat{L}_z, \hat{L}_\pm]\hat{L}_\pm = \pm 2\hbar\hat{L}_\pm^2
$$
</details>

From **(4)** it follows inductively that

$$
\begin{equation*}
  [\hat{L}_z, \hat{L}_\pm^k] = \pm k\hbar\hat{L}_\pm^k,\; k\in\N_+
\tag{\label{equation-24}}
\end{equation*}
$$

Furthermore, the ladder operators satisfy

$$
\begin{align*}
  \hat{L}_\pm \hat{L}_\mp =& (\hat{L}_x \pm i\hat{L}_y)(\hat{L}_x \mp i\hat{L}_y) \\
  =& \hat{L}_x^2 + \hat{L}_y^2 \mp i(\hat{L}_x \hat{L}_y - \hat{L}_y \hat{L}_z) \\
  =& \unitvec{L}^2 - \hat{L}_z \mp i[\hat{L}_x, \hat{L}_y] = \unitvec{L}^2 - \hat{L}_z \mp i\hbar\hat{L}_z
\end{align*}
$$

or

$$
\begin{equation*}
  \unitvec{L}^2 = \hat{L}_\pm \hat{L}_\mp + \hat{L}_z^2 \mp \hbar\hat{L}_z
\tag{\label{equation-26}}
\end{equation*}
$$

Since each $\hat{L}_i$ and $\unitvec{L}^2$ are compatible, we can simultaneously diagonalize them. If $\ket{\psi}$ is a simulatenous eigenstate of $\unitvec{L}^2$ and $\hat{L}_z$, we get the eigenvalue equations

$$
  \unitvec{L}^2 \ket{\psi} = \lambda\ket{\psi},\quad \hat{L}_z \ket{\psi} = \mu\ket{\psi}
$$

requiring

$$
\begin{equation*}
\begin{split}
  \lambda =& \langle L^2 \rangle = \underbrace{\langle L_x^2 \rangle}_{\geq 0} + \underbrace{\langle L_y^2 \rangle}_{\geq 0} + \underbrace{\langle L_z^2 \rangle}_{=\mu^2} \\
  =& \langle L_x^2 \rangle + \langle L_y^2 \rangle + \mu^2 \geq \mu^2
\end{split}
\tag{\label{equation-25}}
\end{equation*}
$$

Letting $\hat{L}_\pm$ act on $\ket{\psi}$ and applying $\eqref{equation-22}$ we find 

$$
  \unitvec{L}^2 (\hat{L}_\pm \ket{\psi}) = \hat{L}_\pm (\unitvec{L}^2 \ket{\psi}) = \hat{L}_\pm (\lambda\ket{\psi}) = \lambda (\hat{L}_\pm \ket{\psi})
$$

showing that $\hat{L}_\pm \ket{\psi}$ is an eigenfunction of $\unitvec{L}^2$ sharing the same eigenvalue $\lambda$. Similarly, applying $\eqref{equation-23}$ we obtain

$$
\begin{align*}
  \hat{L}_z (\hat{L}_\pm \ket{\psi}) =& \underbrace{(\hat{L}_z \hat{L}_\pm - \hat{L}_\pm \hat{L}_z)}_{=[\hat{L}_z, \hat{L}_+]} \ket{\psi} + \hat{L}_\pm \hat{L}_z \ket{\psi} \\
  =& \pm\hbar\hat{L}_\pm \ket{\psi} + \hat{L}_\pm (\mu\ket{\psi}) \\
  =& (\mu \pm \hbar)(\hat{L}_\pm \ket{\psi})
\end{align*}
$$

showing that $\hat{L}_\pm$ raises or lowers the the eigenvalue of $\hat{L}_z$ by one unit of $\hbar$. In general, from $\eqref{equation-24}$ we see that

$$
\begin{align*}
  \hat{L}_z (\hat{L}_\pm^k \ket{\psi}) =& \hat{L}_\pm^k (\hat{L}_z \ket{\psi}) \pm k\hbar \hat{L}_\pm^k \ket{\psi} \\
  =& (\mu\pm k\hbar) \hat{L}_\pm^k \ket{\psi}
\end{align*}
$$

This shows that $\hat{L}_\pm^k \ket{\psi}$ is a simultaneous eigenfunction of both $\unitvec{L}^2$ and $\hat{L}_z$ with corresponding eigenvalues $\lambda$ and $\mu\pm k\hbar$. Thus, starting from a state $\ket{\psi}$ with a $\unitvec{L}^2$ eigenvalue $\lambda$ and a $\hat{L}_z$ eigenvalue $\mu$, we can repeatedly apply $\hat{L}_+$ to construct an ascending sequence of eigenstates with $\hat{L}_z$ eigenvalues $\mu, \mu + \hbar, \mu + 2\hbar, \dots$. Similarly, we can apply $\hat{L}_-$ to construct a descending sequence $\mu, \mu - \hbar, \mu - 2\hbar$. Since the $\unitvec{L}^2$ eigenvalue is preserved, it follows from $\eqref{equation-25}$ that both sequences must terminate.

If we let the upper and lower $\hat{L}_z$ eigenvalue be $\hbar m_\text{u}$ and $\hbar m_\text{l}$, respectively, we have

$$
  \hat{L}_z \ket{\psi_\text{u}} = \hbar m_\text{u} \ket{\psi_\text{u}},\quad \hat{L}_z \ket{\psi_\text{l}} = -\hbar m_\text{l} \ket{\psi_\text{l}}
$$

with

$$
\begin{equation*}
  \hat{L}_+ \ket{\psi_\text{u}} = 0 = \hat{L}_- \ket{\psi_\text{l}}
\tag{\label{equation-27}}
\end{equation*}
$$

From $\eqref{equation-25}$, we must have $m_\text{u}^2 \leq \lambda$ and $m_\text{l}^2 \leq \lambda$. By construction, there must be a natural number $M\in\N$ of steps from $-m_\text{l}$ ot $m_\text{u}$, i.e.

$$
\begin{equation*}
  m_\text{l} + m_\text{u} = M \in\N
\tag{\label{equation-28}}
\end{equation*}
$$

Applying $\eqref{equation-26}$ for $\hat{L}_- \hat{L}_+$, we obtain

$$
  \unitvec{L}^2 \ket{\psi_\text{u}} = \hat{L}_- \hat{L}_+ \ket{\psi_\text{u}} + (\hat{L}_z^2 + \hbar\hat{L}_z)\ket{\psi_\text{u}}
$$

Then by $\eqref{equation-27}$, this becomes

$$
  \lambda \ket{\psi_\text{u}} = \hbar^2 m_\text{u} (m_\text{u} + 1) \ket{\psi_\text{u}} \implies \lambda = \hbar^2 m_\text{u} (m_\text{u} + 1)
$$

Similarly, applying $\eqref{equation-26}$ for $\hat{L}_+ \hat{L}_-$, we obtain

$$
  \unitvec{L}^2 \ket{\psi_\text{l}} = \hat{L}_+ \hat{L}_- \ket{\psi_\text{l}} + (\hat{L}_z^2 - \hbar\hat{L}_z) \ket{\psi_\text{l}}
$$

or

$$
  \lambda \ket{\psi_\text{l}} = \hbar^2 m_\text{l} (m_\text{l} + 1) \ket{\psi_\text{l}} \implies \lambda = \hbar^2 m_\text{l} (m_\text{l} + 1)
$$

Equating both equations for $\lambda$ and using $\eqref{equation-28}$, we conclude that

$$
  m_\text{u} = m_\text{l} = \frac{M}{2} := \ell \in \N/2
$$

where $\ell$ is either integral or half-integral, depending on whether $N$ is even or odd. In either case, we finally arrive at $\lambda = \hbar^2 \ell(\ell + 1)$ where the eigenvalues of $\hat{L}_z$ range from $-\hbar\ell$ to $\hbar\ell$ in integral steps of $\hbar$. Relabeling the simultaneous eigenstates as $\ket{\ell, m_\ell}$, the eigenvalue equations can be witten

$$
\begin{align*}
  \unitvec{L}^2 \ket{\ell, m_\ell} =& \hbar^2 \ell(\ell + 1) \ket{\ell, m_\ell} \\
  \hat{L}_z \ket{\ell, m_\ell} =& \hbar m_\ell \ket{\ell, m_\ell}
\end{align*}
$$

Using $\eqref{equation-26}$, we have

$$
\begin{align*}
  \Braket{\ell, m_\ell | \hat{L}_\mp \hat{L}_\pm | \ell, m_\ell } =& \Braket{\ell, m_\ell | \unitvec{L}^2 - \hat{L}_z^2 \mp \hbar\hat{L}_z | \ell, m_\ell} \\
  =& \hbar^2 [\ell(\ell + 1) - m_\ell^2 \mp m_\ell] \Braket{\ell, m_\ell | \ell, m_\ell} \\
  =& \hbar^2 [\ell(\ell + 1) - m_\ell (m_\ell \pm 1)] \Braket{\ell, m_\ell | \ell, m_\ell}
\end{align*}
$$

We know that $\hat{L}_\pm \ket{\ell, n}$ is proportional to $\ket{\ell, n\pm 1}$. If we assume that the $\ket{\ell, n}$ are normalized, then this equation implies that

$$
\begin{equation*}
  \hat{L}_\pm \ket{\ell, n} = \hbar\sqrt{\ell(\ell + 1) - n(n \pm 1)} \ket{\ell, n\pm 1}
\tag{\label{equation-28}}
\end{equation*}
$$

Starting at the top state $\ket{\ell, \ell}$, we can construct all of the states $\ket{\ell,n}$ by repeatedly applying $\hat{L}_-$. We could equally start from $\ket{\ell, -\ell}$ and repeatedly apply $\hat{L}_z$ to construct the states. From $\eqref{equation-28}$, we have

$$
\begin{gather*}
  \hat{L}_- \ket{\ell,\ell} = \hbar\sqrt{\ell(\ell + 1) - \ell(\ell - 1)} \ket{\ell, \ell-1} = \hbar\sqrt{2\ell} \ket{\ell,\ell-1} \\
  \ket{\ell,\ell - 1} = \hbar^{-1} \frac{1}{\sqrt{2\ell}} \hat{L}_- \ket{\ell,\ell}
\end{gather*}
$$

Applying $\hat{L}_-$ once more

$$
\begin{align*}
  \hat{L}_-^2 \ket{\ell,\ell} =& \hbar^2 \sqrt{2\ell}\sqrt{\ell(\ell+1) - (\ell - 1)(\ell-2)}\ket{\ell,\ell-2} \\
  =& \hbar^2 \sqrt{2\ell(2\ell - 1)2}\ket{\ell,\ell-2}
\end{align*}
$$

or

$$
  \ket{\ell,\ell-2} = \hbar^{-2} \frac{1}{\sqrt{(\ell(2\ell - 1)2}} \hat{L}_-^2 \ket{\ell,\ell}
$$

Applying $\hat{L}_-$ a third time gives

$$
\begin{align*}
  \hat{L}_-^3 \ket{\ell,\ell} =& \hbar^3 \sqrt{2\ell(2\ell - 1)2}\sqrt{\ell(\ell+1) - (\ell-2)(\ell-3)} \ket{\ell,\ell-3} \\
  =& \hbar^3 \sqrt{2\ell(2\ell - 1)(2\ell - 2)2\cdot 3} \ket{\ell,\ell-3}
\end{align*}
$$

or

$$
  \ket{\ell,\ell-3} = \hbar^{-3} \sqrt{1}{\sqrt{2\ell (2\ell - 1)(2\ell -2)3!}} \hat{L}_-^3 \ket{\ell, \ell}
$$

Noting that $m_\ell = \ell - 3$ so that $3! = (\ell - m_\ell)!$ and $2\ell - 3 = 2\ell - (\ell - m_\ell) = \ell + m_\ell$, we have shown that

$$
  \ket{\ell,m_\ell} = \hbar^{m_\ell - \ell} \sqrt{\frac{(\ell + m_\ell)!}{(2\ell)!(\ell - m_\ell)!}} \hat{L}_-^{\ell - m_\ell} \ket{\ell,\ell}
$$

Starting with $\ket{\ell,-\ell}$ and repeatedly applying $\hat{L}_+$ we can show analogously that

$$
  \ket{\ell,m_\ell} = \hbar^{-m_\ell -\ell} \sqrt{\frac{(\ell - m_\ell)!}{(2\ell)!(\ell + m_\ell)!}} \hat{L}_+^{\ell + m_\ell} \ket{\ell,-\ell}
$$

### Eigenfunctions

In spherically symmetric systems, $\unitvec{L}$ is rotational invariant and its wavefunctions therefore only has angular dependence. In an angular representation, the wavefunctions $\braket{\theta, \phi|\ell, m_\ell} = Y_\ell^{m_\ell} (\theta, \phi)$ are the spherical harmonics. The see this we start by writing $\unitvec{L}$ in spherical coordinates due to the rotational invariance

$$
\begin{aligned}
  x =& r \sin(\theta) \cos(\phi) \\
  y =& r \sin(\theta) \sin(\theta) \\
  z =& r \cos(\theta)
\end{aligned}
\quad
\begin{aligned}
  r =& \sqrt{x^2 + y^2 + z^2} \\
  \theta =& \arctan\left(\frac{x^2 + y^2}{z} \right) \\
  \phi =& \arctan\left(\frac{y}{x}\right)
\end{aligned}
$$

The gradient in spherical coordinates is given by

$$
  \nabla = \unitsym{r}\frac{\partial}{\partial r} + \hat{\boldsymbol{\theta}} \frac{1}{r}\frac{\partial}{\partial\theta} + \hat{\boldsymbol{\phi}}\frac{1}{r\sin(\theta)}\frac{\partial}{\partial\phi}
$$

Since $\unitvec{r} = r \unitsym{r}$, the angular momentum operator $\hat{L}$ becomes

$$
\begin{align*}
  \unitvec{L} =& \unitvec{r}\times\unitvec{p} = -i\hbar\unitvec{r}\times\nabla \\
  =& -i\hbar r \left(\unitsym{r}\times\unitsym{r} \frac{\partial}{\partial r} + \unitvec{r}\times\hat{\boldsymbol{\theta}} \frac{1}{r}\frac{\partial}{\partial\theta} + \unitvec{r}\times\hat{\boldsymbol{\phi}} \frac{1}{r\sin(\theta)} \frac{\partial}{\partial\phi} \right) \\
  =& i\hbar\left(\hat{\boldsymbol{\phi}}\frac{\partial}{\partial\theta} - \hat{\boldsymbol{\theta}} \frac{1}{\sin(\theta)} \frac{\partial}{\partial\phi} \right)
\end{align*}
$$

showing that $\unitvec{L}$ has only angular dependence. The spherical unit vectors can be refactored in terms of their Cartesian components

$$
\begin{align*}
  \hat{\boldsymbol{\theta}} =& \cos(\theta)\sin(\phi)\unitsym{x} + \cos(\theta)\sin(\phi) \unitsym{y} - \sin(\phi)\unitsym{z} \\
  \hat{\boldsymbol{\phi}} =& -\sin(\phi) \unitsym{x} + \cos(\phi) \unitsym{y}
\end{align*}
$$

Substituting into $\unitvec{L}$ gives

$$
\begin{align*}
  \unitvec{L} =& -i\hbar\left([-\sin(\phi)\unitsym{x} + \cos(\phi)\unitsym{y}) \frac{\partial}{\partial\theta} \right. \\
  &- \left. [\cos(\theta) \cos(\phi)\unitsym{x} + \cos(\theta)\sin(\phi)\unitsym{y} - \sin(\theta)\unitsym{z}) \frac{1}{\sin(\theta)} \frac{\partial}{\partial\phi} \right)
\end{align*}
$$

with componentwise operators

$$
\begin{align*}
  \hat{L}_x =& i\hbar \left(\sin(\phi)\frac{\partial}{\partial\theta} + \cot(\theta)\cos(\phi) \frac{\partial}{\partial\phi} \right) \\
  \hat{L}_y =& i\hbar \left(\cot(\theta)\sin(\phi)\frac{\partial}{\partial\phi} - \cos(\phi)\frac{\partial}{\partial\theta} \right) \\
  \hat{L}_z =& -i\hbar \frac{\partial}{\partial\phi}
\end{align*}
$$

In spherical coordinates, the ladder operators become

$$
\begin{align*}
  \hat{L}_\pm =& \hat{L}_x \pm i\hat{L}_y \\
  =& -i\hbar\left([-\sin(\phi) \pm i\cos(\phi)]\frac{\partial}{\partial\theta} - [\cos(\theta) \pm i\sin(\phi)]\cot(\theta) \frac{\partial}{\partial\phi} \right) \\
  =& \pm\hbar e^{\pm i\phi}\left(\frac{\partial}{\partial\theta} \pm \cot(\theta) \frac{\partial}{\partial\phi}\right) \tag{\label{equation-30}}
\end{align*}
$$

Furthermore,

$$
  \hat{L}_+ \hat{L}_- = -\hbar^2 \left(\frac{\partial^2}{\partial\theta^2} + \cot(\theta)\frac{\partial}{\partial\theta} + \cot^2 (\theta) \frac{\partial^2}{\partial\phi^2} + i\frac{\partial^2}{\partial\phi^2} \right)
$$

such that from $\eqref{equation-26}$ we find

$$
\begin{equation*}
  \unitvec{L}^2 = -\hbar^2 \left[\frac{1}{\sin(\theta)}\frac{\partial}{\partial\theta} \left(\sin(\theta) \frac{\partial}{\partial\theta} \right) + \frac{1}{\sin^2 (\theta)}\frac{\partial^2}{\partial\phi^2} \right]
\tag{label{equation-82}}
\end{equation*}
$$

The eigenfunctions $Y_\ell^{m_\ell} (\theta, \phi)$ can be determined from the eigenvalue equations

$$
\begin{align*}
  \unitvec{L}^2 Y_\ell^{m_\ell} =& \hbar^2 \ell (\ell + 1) Y_\ell^{m_\ell} \\
  \hat{L}_z Y_\ell^{m_\ell} =& \hbar m_\ell Y_\ell^{m_\ell}
\end{align*}
$$

In spherical coordinates, the $\hat{L}_z$ equation takes the form

$$
\begin{align*}
  -i\hbar \frac{\partial Y_\ell^{m_\ell}}{\partial\phi} =& \hbar m_\ell Y_\ell^{m_\ell} \\
  -i \frac{\partial Y_\ell^{m_\ell}}{\partial\phi} =& Y_\ell^{m_\ell}
\end{align*}
$$

Assuming a separable solution $Y_\ell^{m_\ell} (\theta, \phi) = \Theta_\ell^n(\theta) \Phi_n(\phi)$ and dividing by $\Theta$, gives the ordinary differential equation

$$
  -i \frac{\partial \Phi_{m_\ell}}{\partial\phi} = \Phi^{m_\ell}
$$

with solution

$$
  \Phi_{m_\ell} (\phi) = \frac{1}{\sqrt{2\pi}} e^{i m_\ell \phi}
$$

Because $Y_\ell^{m_\ell}$ must be single valued, we required that $\Phi_{m_\ell} (\phi + 2\pi) = \Phi_{m_\ell} (\phi)$. This imposes the cyclic boundary condition

$$
  \frac{1}{\sqrt{2\pi}} e^{im_\ell \phi} = \frac{1}{\sqrt{2\pi}} e^{im_\ell \phi} e^{i2\pi m_\ell}
$$

which implies $e^{i2\pi m_\ell} = 1$. This is satisfied for integer $m_\ell \in\Z$.

In spherical coordinates, the $\unitvec{L}^2$ equation takes the form

$$
\begin{align*}
  -\hbar^2 \left[\frac{1}{\sin(\theta)}\frac{\partial}{\partial\theta} \left(\sin(\theta) \frac{\partial}{\partial\theta} \right) + \frac{1}{\sin^2 (\theta)}\frac{\partial^2}{\partial\phi^2} \right] Y_\ell^{m_\ell} =& \hbar^2 \ell(\ell + 1) Y_\ell^{m_\ell} \\
  \left[\frac{1}{\sin(\theta)}\frac{\partial}{\partial\theta} \left(\sin(\theta) \frac{\partial}{\partial\theta} \right) + \ell(\ell + 1)+ \frac{1}{\sin^2 (\theta)}\frac{\partial^2}{\partial\phi^2} \right] Y_\ell^{m_\ell} =& 0
\end{align*}
$$

which can be solved by separation of variables. Assuming a separable solution $Y_\ell^{m_\ell} (\theta, \phi) = \Theta_\ell^{m_\ell} (\theta) \Phi_{m_\ell} (\phi)$, dividing by $\Phi_{m_\ell}$ and noting that

$$
\begin{align*}
  \frac{\d^2 \Phi_{m_\ell}}{\d\phi^2} =& \frac{1}{\sqrt{2\pi}} \frac{\d^2}{\d\phi^2} e^{im_\ell \phi} \\
  =& -\frac{m_\ell^2}{\sqrt} e^{im_\ell \phi} = -m_\ell^2 \Phi_{m_\ell}
\end{align*}
$$

the equation can be refactored as

$$
\begin{equation*}
  \left[\frac{1}{\sin\theta}\frac{\partial}{\partial\theta} \left(\sin\theta \frac{\partial}{\partial\theta} \right) + \ell(\ell + 1)- \frac{m_\ell^2}{\sin^2 \theta} \right] \Theta_\ell^{m_\ell} = 0
\tag{\label{equation-83}}
\end{equation*}
$$

This equation can be solved by substituting $w = \cos(\theta) \in [-1, 1]$ and $P_\ell^{m_\ell} (w) = \Theta_\ell^{m_\ell} (\theta)$ with 

$$
  \frac{\d}{\d\theta} = \frac{\d}{\d w}\frac{\d w}{\d \theta} = -\sin(\theta) \frac{\d}{\d w}
$$

Because $\sin^2 (\theta) = 1 - \cos^2 (\theta) = 1 - w^2$, we can rewrite

$$
\begin{align*}
  \frac{1}{\sin(\theta)}\frac{\d}{\d\theta}\left(\sin(\theta) \frac{\d}{\d\theta}\right) =& \frac{\d}{\d w} \left(\sin^2 (\theta) \frac{\d}{\d w} \right) \\
  =& \frac{\d}{\d w} \left[(1 - w^2)\frac{\d}{\d w}\right] \\
  =& (1 - w^2) \frac{\d^2}{\d w^2} - 2w^2 \frac{\d}{\d w}
\end{align*}
$$

Using these substitutions, $\eqref{equation-83}$ becomes

$$
\begin{equation*}
  \left[(1 - w^2) \frac{\d^2}{\d w^2} - 2w \frac{\d}{\d w} + \ell(\ell + 1) - \frac{m_\ell^2}{1 - w^2} \right] P_\ell^{m_\ell} (w) = 0
\tag{\label{equation-84}}
\end{equation*}
$$

which is known as Legendre's associated differential equation. 

<details>
<summary>Details</summary>

For the axially symmetric case $m_\ell = 0$, equation $\eqref{equation-84}$ reduces to the Legendre differential equation

$$
\begin{equation*}
  \left[(1 - w^2) \frac{\d^2}{\d w^2} - 2w \frac{\d}{\d w} + \ell(\ell + 1)\right] P_\ell (w) = 0
\tag{\label{equation-89}}
\end{equation*}
$$

Inserting a power series solution

$$
  P_\ell (w) = \sum_{k=0} a_k w^{k + s},\; a_0 \neq 0
$$

and collecting the coefficients of $w$ we get the recurrence relation

$$
\begin{equation*}
  a_{k+2} = \frac{(k + s)(k + s + 1) - \lambda}{(k + s + 1)(k + s + 2)}a_k
\tag{\label{equation-90}}
\end{equation*}
$$

Equation $\eqref{equation-89}$ is invariant under parity $w \to -w$. Thus, $P_\ell$ must be either even or odd. Choosing $a_1 = 0$, all the odd subscripted coefficients vanish. Then $s \in \set{0,1}$, respectively give the even and odd functions. If the series does not terminate, the ratio of successive terms of tail part of series for $w = \pm 1$ is

$$
\begin{align*}
  \lim_{k\to\infty} \frac{t_{1 + k/2}}{t_{k/2}} =& \lim_{k\to\infty} \frac{a_{k+2}}{a_k} w^2 \\
  =& \frac{k}{k + 2} = \frac{k/2}{1 + k/2}
\end{align*}
$$

This ratio is the same as that of the series $\sum_j 1/j$, which diverges. Thus, if the series for $P_\ell (w)$ does not terminate, it diverges for $w = \pm$, or $\theta \in \set{0, \pi}$, which is not permissible as an eigenfunction. Consequently, the the series must terminate to polynomial. From $\eqref{equation-90}$, when $\lambda = \ell(\ell + 1)$, wehere $\ell = k + s$, then $a_{k+2} = 0$, while $a_k \neq 0$, and all higher coefficients vanish. It follows that $\ell$ is a positive integer (even for $s = 0$ and odd for $s = 1$, since $k$ is always even).

The solution of $\eqref{equation-89}$, denoted $P_\ell (w)$, is a polynomial of degree $\ell$ and has parity $(-1)^\ell$. This is called the Legendre polynomial and is determined from its generating function

$$
  (1 - 2wv + v^2)^{-1/2} = \sum_{\ell=0}^\infty P_\ell (w) v^\ell
$$

An alternative form is Rodrigues' formula

$$
\begin{equation*}
  P_\ell (w) = \frac{1}{2^\ell \ell!} \left(\frac{\d}{\d w} \right)^\ell (w^2 - 1)^\ell
\tag{\label{equation-97}}
\end{equation*}
$$

The Legendre polynomials satisfy the orthonormality relation

$$
  \int_{-1}^1 P_\ell (w) P_{\ell'} (w) \;\d w = \frac{2}{2\ell + 1} \delta_{\ell, \ell'}
$$
</details>

The solutions to $\eqref{equation-84}$ are given by the associated Legendre functions $P_\ell^{m_\ell} (w)$ defined by

$$
  P_\ell^{m_\ell} (w) = (1 - w^2)^{|m_\ell|/2} \left(\frac{\d}{\d w}\right)^{|m_\ell|} P_\ell (w)
$$

where $P_\ell (w)$ is the $\ell$-th Legendre polynomial given by the Rodrigues formula $\eqref{equation-97}$. Since $(w^2 - 1)$ is a polynomial in $w$ of degree $2\ell$, differentiating it more than $2\ell$ times with respect to $w$ gives zero. Thus, for non-trivial $P_\ell^{m_\ell} (w)$, we must have $|m_\ell| \leq \ell$.

<details>
<summary>Details</summary>

Legendre's associated differential equation $\eqref{equation-84}$, can be solved by substituting

$$
  P(w) = (1 - w^2)^{|m_\ell|/2} G(w)
$$

which leads to the following differential equation for $G$

$$
  (1 - w^2) G'' - 2(|m_\ell| + 1)wG' + [k - |m_\ell| (|m_\ell| + 1)] G = 0
$$

where $\lambda = \ell(\ell + 1)$. Inserting a power series solution of the form

$$
  G = \sum_{k=0}^\infty a_k w^k
$$

and collecting the coefficients of $w$ we get

$$
  \sum_{k=0}^\infty (k+1)(k+2) a_{k+2} + \{[\lambda - |m_\ell| (|m_\ell| + 1)] - 2k(|m_\ell| + 1) - k(k-1)\}a_k = 0
$$

This results in the recursion relation

$$
  a_{k+2} = \frac{(k + |m_\ell|)(k + |m_\ell| + 1) - \lambda}{(k+1)(k+2)} a_k
$$

A power series based on this relation diverges for $w = \pm 1$, so there must be a restriction that ensures that the series terminates after a finite number of terms. This restriction implies that there must be a value of $k \in\N_0$ for which

$$
  \lambda = (k + |m_\ell|)(n + |m_\ell| + 1)
$$

Introducing the quantum number $\ell = k + |m_\ell|$, we retrieve $\lambda = \ell(\ell + 1)$.
</details>

Using the Rodrigues formula and integrating by parts, we can show that the associated Legendre's functions $P_\ell^{m_\ell}$ are orthogonal to each other

$$
  \int_{-1}^1 P_\ell^{|m_\ell|} (w) P_{\ell'}^{|m_\ell|}(w) \;\d w = \frac{2}{2\ell + 1} \frac{(\ell + |m_\ell|)!}{(\ell - |m_\ell|)!} \delta_{\ell\ell'}
$$

The corresponding physical solutions $\Theta_\ell^{m_\ell} (\theta)$ are given by

$$
  \Theta_\ell^{m_\ell} (\theta) = \begin{cases}
    (-1)^{m_\ell} \sqrt{\frac{(2\ell + 1)}{2} \frac{(\ell - m_\ell)!}{(\ell + m_\ell)!}} P_\ell^{m_\ell} (\cos\theta),\quad& m_\ell \geq 0 \\
    (-1)^{m_\ell} \Theta_\ell^{|m_\ell|} (\theta), \quad& m_\ell < 0
  \end{cases}
$$

which are orthonormal

$$
  \int_0^\pi (\Theta_{\ell'}^{m_\ell})^*(\theta) \Theta_\ell^{m_\ell} (\theta) \sin(\theta)\;\d\theta = \delta_{\ell\ell'}
$$

Combining the solutions for $\Theta_\ell^{m_\ell}$ and $\Phi_{m_\ell}$, we arrive at the eigenfunctions

$$
  Y_\ell^{m_\ell} (\theta, \phi) = \begin{cases}
    (-1)^{m_\ell} \sqrt{\frac{(2\ell + 1)}{4\pi} \frac{(\ell - m_\ell)!}{(\ell + m_\ell)!}} P_\ell^{m_\ell} (\cos(\theta)) e^{i m_\ell \phi},\quad& m_\ell \geq 0 \\
    (-1)^{m_\ell} (Y_\ell^{-m_\ell})^* (\theta), \quad& m_\ell < 0
  \end{cases}
$$

which are known as spherical harmonics. These are normalized to unity on a unit sphere and are orthogonal:

$$
\begin{align*}
  & \int (Y_{\ell'}^{m_\ell'})^* (\theta,\phi) Y_\ell^{m_\ell} (\theta) \;\d\Omega \\
  =& \int_0^{2\pi} \d\phi \int_0^\pi (Y_{\ell'}^{m'_\ell})^* (\theta,\phi) Y_\ell^{m_\ell} (\theta, \phi) \sin(\theta) \;\d\theta \\
  =& \delta_{\ell\ell'} \delta_{m_\ell m'_\ell}
\end{align*}
$$

#### Derivation using ladder operators

We can also find the eigenfunctions $Y_\ell^{m_\ell} (\theta, \phi)$ using ladder operators. Starting from the definition $\hat{L}_+ Y_\ell^\ell = 0$, we have

$$
  \frac{\partial Y_\ell^\ell}{\partial\theta} + i\cot(\theta) \frac{\partial Y_\ell^\ell}{\partial\phi} = 0
$$

Using separation of variables with $Y_\ell^\ell (\theta,\phi) = \Theta(\theta)\Phi(\phi)$ the equation can refactored as

$$
\begin{align*}
  \Phi\frac{\partial \Theta}{\partial\theta} =& -i \Theta \cot(\theta) \frac{\partial \Phi}{\partial\phi} \\
  \frac{1}{\Theta\cot(\theta)} \frac{\partial \Theta}{\partial\theta} =& -i\frac{1}{\Phi}\frac{\partial \Phi}{\partial\phi}
\end{align*}
$$

The separated equations hold if both sides equal some constant, say $k$. In this case, the zenital equation becomes

$$
  \frac{\d \Phi}{\Phi} = ik\d\phi
$$

which has solution $\Phi(\phi) = e^{ik\phi}$ up to normalization. Since $Y_\ell^\ell$ is an eigenfunction of $L_3 = -i\hbar (\partial/\partial\phi)$ with eigenvalue $\ell\hbar$, then so is $\Phi(\phi)$ (where $\Theta(\theta)$ just cancels out). This means that

$$
  -i\hbar\frac{\partial e^{ik\phi}}{\partial\phi} = k\hbar e^{ik\phi} := \ell\hbar e^{ik\phi}
$$

showing that we must have $k = \ell$ so that, up to normalization

$$
  Y_\ell^\ell = e^{il\phi} \Theta(\theta)
$$  

With $k = \ell$, the azimuthal equation becomes

$$
  \frac{\d\Theta}{\Theta} = \ell\cot(\theta) \;\d\theta = \ell\frac{\cos(\theta)}{\sin(\theta)} \;\d\theta = \ell\frac{\d\sin(\theta)}{\sin(\theta)}
$$

which has solution $\Theta(\theta) = \sin^\ell (\theta)$ up to normalization. Thus, we can write

$$
  Y_\ell^\ell = c_\ell^\ell \sin^\ell (\theta) e^{il\phi},
$$

where $c_\ell^\ell$ is a normalization constant, fixed by the requirement that

$$
\begin{equation*}
  \int |Y_\ell^\ell|^2 \;\d\Omega = 2\pi |c_\ell^\ell|^2 \int_0^\pi \sin^{2\ell} (\theta) \sin(\theta) \;\d\theta = 1 
\tag{\label{equation-29}}
\end{equation*}
$$

where $\d\Omega = \sin(\theta) \;\d\theta \;\d\phi$. To solve the integral, we use the relation

$$
  \int \sin^n x \;\d x = -\frac{1}{n} (\sin x)^{n-1} \cos x + \frac{n - 1}{n} \int (\sin x)^{n-2} \;\d x
$$

Since the limits of integration are $0$ and $\pi$, the first term on the right side always vanishes. With $n = 2\ell + 1$ we find

$$
\begin{align*}
  \int_0^\pi (\sin x)^{2\ell + 1} \;\d x =& \frac{2\ell}{2\ell + 1} \int_0^\pi (\sin x)^{2\ell - 1} \;\d x \\
  =& \left(\frac{2\ell}{2\ell + 1}\right)\left(\frac{2\ell - 2}{2\ell - 1}\right) \int_0^\pi (\sin x)^{2\ell - 3} \;\d x \\
  =& \cdots \\
  =& \left(\frac{2\ell}{2\ell + 1}\right) \left(\frac{2\ell - 2}{2\ell - 1}\right) \left(\frac{2\ell - 4}{2\ell - 3}\right) \\
  &\times\cdots\times \left(\frac{2\ell - (2\ell - 2)}{2\ell - (2\ell - 3)} \right) \underbrace{\int_0^\pi \sin x \;\d x}_{=2} \\
  =& \frac{2^\ell \ell (\ell - 1)(\ell - 2)\cdots (\ell - (\ell - 1))}{(2\ell + 1)!!} 2 \\
  =& 2\frac{2^\ell \ell!}{(2\ell + 1)!!} = 2\frac{(2^\ell \ell!)^2}{(2\ell + 1)!}
\end{align*}
$$

where we have used the fact that

$$
\begin{align*}
  n!! =& \prod_{j=0}^{(n-1)/2} 2j + 1 = \frac{\prod_{j=0}^n j}{\prod_{j=0}^{(n-1)/2} 2j} \\
  =& \frac{\prod_{j=0}^n j}{2^{(n-1)/2} \prod_{j=0}^{(n-1)/2} j} \\
  =& \frac{n!}{2^{(n-1)/2} \left(\frac{n-1}{2}\right)!}
\end{align*}
$$

Substituting $n = 2\ell + 1$ yields

$$
  (2\ell + 1)!! = 2\frac{(2^\ell \ell!)^2}{(2\ell + 1)!}
$$

Using the results, $\eqref{equation-29}$ becomes

$$
\begin{gather*}
  4\pi |c_\ell^\ell|^2 \frac{(2^\ell \ell!)^2}{(2\ell + 1)!} = 1 \\
  c_\ell^\ell = (-1)^\ell \left[\frac{(2\ell + 1)!}{4\pi} \right]^{1/2} \frac{1}{2^\ell \ell!}
\end{gather*}
$$

where we included a conventional arbitrary phase factor $(-1)^\ell$. Putting this all together, the top orbital angular momentum becomes

$$
  Y_\ell^\ell (\theta, \phi) = (-1)^\ell \left[\frac{(2\ell + 1)!}{4\pi}\right]^{1/2} \frac{1}{2^\ell \ell!} \sin^\ell (\theta) e^{i\ell\phi}
$$

To construct the rest of the states $Y_\ell^{m_\ell}$, we repeatedly apply $\eqref{equation-30}$ for $\hat{L}_-$ to finally obtain

$$
\begin{align*}
  Y_\ell^{m_\ell} (\theta, \phi) =& (-1)^\ell \left[\frac{(2\ell + 1)!}{4\pi}\right]^{1/2} \frac{1}{2^\ell \ell!} \left[\frac{(\ell + m_\ell)!}{(2\ell)!(\ell - n)!} \right]^{1/2} \\
  &\times e^{i m_\ell \phi} \sin^{-n} (\theta) \frac{\d^{\ell - m_\ell}}{\d(\cos\theta)^{\ell - m_\ell}} \sin^{2\ell} (\theta)
\end{align*}
$$

| $\ell$ | $m_\ell$ | $Y_\ell^{m_\ell} (\theta, \phi)$ |
| --- | --- | --- |
| $0$ | $0$ | $Y_0^0 = \frac{1}{\sqrt{4\pi}}$ |
| $1$ | $0$ | $Y_1^0 = \left(\frac{3}{8\pi}\right)^{1/2} \cos\theta$ |
| $1$ | $\pm 1$ | $Y_1^{\pm 1} = \mp \left(\frac{3}{8\pi}\right)^{1/2} \cos(\theta) e^{\pm i\phi}$ |
| $2$ | $0$ | $Y_2^0 = \mp \left(\frac{5}{16\pi}\right)^{1/2} [3\cos^2 (\theta) - 1]$ |
| $2$ | $\pm 1$ | $Y_2^{\pm 1} = \mp \left(\frac{15}{8\pi}\right)^{1/2} \sin(\theta) \cos(\theta) e^{\pm i\phi}$ |
| $2$ | $\pm 2$ | $Y_2^{\pm 2} = \mp \left(\frac{15}{32\pi}\right)^{1/2} \sin^2(\theta) e^{\pm i2\phi}$ |
| $3$ | $0$ | $Y_3^0 = \mp \left(\frac{7}{16\pi}\right)^{1/2} [5\cos^3(\theta) - 3\cos(\theta)]$ |
| $3$ | $\pm 1$ | $Y_3^{\pm 1} = \mp \left(\frac{21}{64\pi}\right)^{1/2} \sin(\theta)[5\cos^2(\theta) - 1] e^{\pm i\phi}$ |
| $3$ | $\pm 2$ | $Y_3^{\pm 2} = \mp \left(\frac{105}{32\pi}\right)^{1/2} \sin^2(\theta) \cos(\theta) e^{\pm i2\phi}$ |
| $3$ | $\pm 3$ | $Y_3^{\pm 3} = \mp \left(\frac{35}{64\pi}\right)^{1/2} \sin^3(\theta) e^{\pm i3\phi}$ |

## Spin

In addition to orbital angular momentum, elementary particles also carry intrinsic angular momentum, called spin. This was originally thought be analogous to classical spin angular momentum, $\mathbf{S} = I\boldsymbol{\omega}$, associated with motion about the senter of mass. However, experiments have shown that spin is a purely quantum phenomena without a classical analogue.

The algebraic theory of the spin is the same as for orbital angular momentum operator. This means that the spin operator $\unitvec{S}$ obeys the commutation relations

$$
  [\hat{S}_i, \hat{S}_j] = i\hbar\varepsilon_{ijk} \hat{S}_k
$$

and that the eigenvectors of $\hat{S}^2$ and $\hat{S}_z$ satisfy

$$
\begin{align*}
  \unitvec{S}^3 \ket{s, n_s} =& \hbar^2 s(s + 1)\ket{s, n_s} \tag{\label{equation-31}} \\
  \hat{S}_z \ket{s, n_s} =& \hbar n_s \ket{s, n_s} \tag{\label{equation-32}}
\end{align*}
$$

We can also define spin ladder operators $\hat{S}_\pm = \hat{S}_x \pm i\hat{S}_y$ satisfying

$$
\begin{equation*}
  \hat{S}_\pm \ket{s, n_s} = \hbar\sqrt{s(s+1) - n_s(n_s \pm 1)} \ket{s, n_s\pm 1} 
\tag{\label{equation-33}}
\end{equation*}
$$

### Spin 1/2

For particles with spin $s = 1/2$, each component of $\unitvec{S}$ can take two eigenstates

- Spin up: $\Ket{\frac{1}{2}, \frac{1}{2}} = \ket{\chi_+} = \ket{\uparrow}$
- Spin down: $\Ket{\frac{1}{2}, -\frac{1}{2}} = \ket{\chi_-} = \ket{\downarrow}$

An arbitrary spin state $\ket{\chi}\in\mathbb{C}^2$, called a spinor, is of the form

$$
  \ket{\chi} = a \ket{\chi_+} + b\ket{\chi_-}
$$

Because spin-1/2 particles have two possible eigenstates, a matrix representation of $\unitvec{S}$ forms a two-dimensional space. By convention, the eigenvectors of $\hat{S}_z$ is set as the standard basis

$$
  \ket{\chi_+}_z = \left[\begin{smallmatrix} 1 \\ 0 \end{smallmatrix}\right], \quad \ket{\chi_-}_z = \left[\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right]
$$

To find the matrix representation of $\hat{S}_z$, we know from $\eqref{equation-32}$

$$
  \hat{S}_z \ket{\chi_\pm}_3 = \pm \frac{\hbar}{2} \ket{\chi_\pm}_3
$$

so that $\hat{S}_z \in \R^{2\times 2}$ is represented by the $2\times 2$ matrix 

$$
  \hat{S}_z = \frac{\hbar}{2} \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix} = \frac{\hbar}{2} \sigma_3
$$

To find the matrix representation of $\hat{S}_x$ and $\hat{S}_y$, we know from $\eqref{equation-33}$

$$
  \hat{S}_\pm \Ket{\frac{1}{2}, n_s} = \hbar\sqrt{3/4 - n_s (n_s \pm 1)} \Ket{\frac{1}{2}, n_s \pm 1}
$$

giving

$$
\begin{aligned}
  \hat{S}_+ \ket{\chi_+}_z =& 0 \\
  \hat{S}_+ \ket{\chi_-}_z =& \hbar\ket{\chi_+}_z
\end{aligned}
\quad
\begin{aligned}
  \hat{S}_- \ket{\chi_+}_z =& \hbar\ket{\chi_-}_z \\
  \hat{S}_- \ket{\chi_-}_z =& 0
\end{aligned}
$$

Thus, the only non-zero entry in $\hat{S}_+$ is $\braket{\chi_+ | \hat{S}_+ | \chi_-}$ and the only non-zero entry in $\hat{S}_-$ is $\braket{\chi_- | \hat{S}_- | \chi_+}$, resulting in

$$
  \hat{S}_+ = \hbar\begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix}, \quad \hat{S}_- = \hbar\begin{bmatrix} 0 & 0 \\ 1 & 0 \end{bmatrix}
$$

From $\hat{S}_\pm = \hat{S}_x \pm i\hat{S}_y$ we find

$$
  \hat{S}_x = \frac{\hbar}{2} \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} = \frac{\hbar}{2} \sigma_1,\quad \hat{S}_y = \frac{\hbar}{2} \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix} = \frac{\hbar}{2} \sigma_2
$$

With the components representation we find from $\hat{S}^2 = \hat{S}_x^2 + \hat{S}_y^2 + \hat{S}_z^2$ that

$$
  \hat{S}^2 = \frac{3}{4}\hbar^2 \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
$$

<details>
<summary>Details</summary>

The matrix representation of $\hat{S}^2$ can also be determined from $\eqref{equation-31}$ giving

$$
  \hat{S}^2 \ket{\chi_\pm} = \frac{3}{4}\hbar^2 \ket{\chi_\pm}
$$

If we write $\hat{S}^2 = \left[\begin{smallmatrix} c & d \\ e & f \end{smallmatrix}\right]$ as a matrix with undetermined elements, the first equation says

$$
\begin{gather*}
  \begin{bmatrix} c & d \\ e & f \end{bmatrix} \cdot \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \frac{3}{4}\hbar^2 \begin{bmatrix} 1 \\ 0 \end{bmatrix} \\
  \implies \begin{bmatrix} c \\ e \end{bmatrix} = \begin{bmatrix} \frac{3}{4}\hbar^2 \\ 0 \end{bmatrix}
\end{gather*}
$$

The second equation says

$$
\begin{gather*}
  \begin{bmatrix} c & d \\ e & f \end{bmatrix} \cdot \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \frac{3}{4}\hbar^2 \begin{bmatrix} 0 \\ 1 \end{bmatrix} \\
  \implies \begin{bmatrix} d \\ f \end{bmatrix} = \begin{bmatrix} 0 \\ \frac{3}{4}\hbar^2 \end{bmatrix}
\end{gather*}
$$

Hence,

$$
  \hat{S}^2 = \frac{3}{4}\hbar^2 \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
$$
</details>

Here we choose to represent the general spin $\ket{\chi}$ in terms of eigenvectors of $\hat{S}_z$, but can equally well choose another component, say $\hat{S}_x$. In this case, we diagonalize $\hat{S}_x$ and use its eigenvectors as a new basis for the spinor space. The eigenvalue equation is $(\hat{S}_x - \lambda I)\ket{\chi_+}_x = \mathbf{0}$, so in order to have a nontrivial solution, we must have

$$
\begin{align*}
  \det(\hat{S}_x - \lambda I) =& \begin{vmatrix} -\lambda & \hbar/2 \\ \hbar/2 & -\lambda \end{vmatrix} \\
  =& -\lambda^2 - \hbar^2 / 4 = 0 \iff \lambda_\pm = \pm \hbar/2
\end{align*}
$$

To find the eigenvector corresponding to $\lambda_+ = \hbar/2$, we solve

$$
  (\hat{S}_x - \lambda_+ I) \ket{\chi_+}_x = \frac{\hbar}{2} \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix}\cdot\begin{bmatrix} a \\ b \end{bmatrix} = 0
$$

so that $a = b$ and the normalized eigenvector is

$$
  \ket{\chi_+}_x = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 \\ 1 \end{bmatrix}
$$

For $\lambda_- = -\hbar/2$ we have

$$
  (\hat{S}_x - \lambda_- I) \ket{\chi_-}_x = \frac{\hbar}{2} \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix}\cdot\begin{bmatrix} c \\ d \end{bmatrix} = 0
$$

so that $c = -d$ and the normalized eigenvector is (choosing $c = 1$)

$$
  \ket{\chi_-}_x = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 \\ -1 \end{bmatrix}
$$

Suppose we have spin state $\ket{\chi} = \left[\begin{smallmatrix} \alpha \\ \beta \end{smallmatrix}\right]$ with $\braket{\chi|\chi} = |\alpha|^2 + |\beta|^2 = 1$. In terms of the eigenspace of $\hat{S}_z$, we can write

$$
  \ket{\chi} = \alpha \ket{\chi_+}_z + \beta \ket{\chi_-}_z = \alpha\begin{bmatrix} 1 \\ 0 \end{bmatrix} + \beta\begin{bmatrix} 0 \\ 1 \end{bmatrix}
$$

so that the probability is $|\alpha|^2$ that we will measure the $z$-component of spin to be $\hbar/2$ and $|\beta|^2$ that we will measure it to be $-\hbar/2$. Alternatively, we can express $\ket{\chi}$ in terms of the eigenspace of $\hat{S}_x$

$$
  \begin{bmatrix} \alpha \\ \beta \end{bmatrix} = \frac{a}{\sqrt{2}}\begin{bmatrix} 1 \\ 1 \end{bmatrix} + \frac{b}{\sqrt{2}} \begin{bmatrix} 1 \\ -1 \end{bmatrix} = \frac{1}{\sqrt{2}}\begin{bmatrix} a + b \\ a - b \end{bmatrix}
$$

or

$$
\begin{align*}
  \alpha =& \frac{1}{\sqrt{2}}(a + b) + \frac{b}{\sqrt{2}} \\
  \beta =& \frac{1}{\sqrt{2}}(a - b)
\end{align*}
$$

Solving for $a$ and $b$, we obtain

$$
\begin{align*}
  a =& \frac{1}{\sqrt{2}} (\alpha + \beta) \\
  b =& \frac{1}{\sqrt{2}} (\alpha - \beta)
\end{align*}
$$

so that

$$
  \ket{\chi} = \frac{\alpha + \beta}{\sqrt{2}} \ket{\chi_+}_x + \frac{\alpha - \beta}{\sqrt{2}} \ket{\chi_-}_x
$$

Thus, the probability of measuring the $x$ component of spin to be $\hbar/2$ is $|\alpha + \beta|^2 / 2$ and the probability of measuring the value to be $-\hbar/2$ is $|\alpha - \beta|^2 / 2$.

In terms of the standard basis, it is conventional to write $\unitvec{S}$ in terms of the Pauli matrices $\boldsymbol{\sigma}$ defined by

$$
  \unitvec{S} = \frac{\hbar}{2}\boldsymbol{\sigma}
$$

where

$$
  \sigma_1 = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}, \quad \sigma_2 = \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix}, \quad \sigma_2 = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}
$$

## Total angular momentum

The total angular momentum of a quantum particle, $\unitvec{J}$, is the sum of its orbital angular momentum $\unitvec{L}$ and spin $\unitvec{S}$, i.e.

$$
  \unitvec{J} = \unitvec{L} + \unitvec{S}
$$

The total angular momentum has the same algebraic properties as $\unitvec{L}$ and $\unitvec{S}$.

### Composition of angular momentum

Suppose we have two particles with independent total angular momentum $\unitvec{J}_1$ and $\unitvec{J}_2$. The resulting angular momentum of the system is $\unitvec{J} = \unitvec{J}_1 + \unitvec{J}_2$. Each particle's angular momentum operator satifies the commutation relation

$$
  [\hat{J}_{ai}, \hat{J}_{aj}] = i\hbar\varepsilon_{ijk} J_{ak},\; a\in\set{1,2}
$$

with corresponding eigenstate $\ket{j_a, n_a}$. Since we assume that $[\unitvec{J}_1, \unitvec{J}_2] = 0$, it follows that $\unitvec{J}$ obeys the commutation relation 

$$
\begin{align*}
  [\hat{J}_i, \hat{J}_j] =& [\hat{J}_{1i} + \hat{J}_{2i}, \hat{J}_{1j} + \hat{J}_{2j}] = [\hat{J}_{1i}, \hat{J}_{1j}] + [\hat{J}_{2i}, \hat{J}_{2j}] \\
  =& i \varepsilon_{ijk} \hat{J}_{1k} + i \varepsilon_{ijk} \hat{J}_{2k} = i \varepsilon_{ijk} (\hat{J}_{1k} + \hat{J}_{2k}) \\
  =& i \varepsilon_{ijk} \hat{J}_k
\end{align*}
$$

showing that $\unitvec{J}$ is an angular momentum operator with eigenstates $\ket{j,n}$ satisfying 

$$
\begin{align*}
  \hat{J}^2 \ket{j, n} =& \hbar^2 j(j + 1)\ket{j, n} \\
  \hat{J}_z \ket{j, n} =& \hbar n \ket{j, n} \\
  \hat{J}_\pm \ket{j, n} =& \hbar\sqrt{j(j + 1) - n(n \pm 1)} \ket{j, n \pm 1}
\end{align*}
$$

From $[\unitvec{J}_1, \unitvec{J}_2] = 0$, it follows that $[\unitvec{J}_1^2, \unitvec{J}_2^2] = 0$, and since $[\hat{J}_a^2, \hat{J}_{az}] = 0$, we see that we can choose our states to be simultaneous eigenstates of $\hat{J}_1^2$, $\hat{J}_2^2$, $\hat{J}_{1z}$ and $\hat{J}_{2z}$. An obvious basis for the resulting product space is given by

$$
  \ket{j_1 j_2, n_1, n_2} := \ket{j_1, n_1} \otimes \ket{j_2, n_2}
$$

Alternatively, we can choose our states to be simultaneous eigenstates of $\hat{J}^2$, $\hat{J}_1^2$, $\hat{J}_2^2$ and $\hat{J}_z$. Since $\unitvec{J}$ is an angular momentum operator, it follows that $[\hat{J}^2, \hat{J}_z] = 0$. The fact that $[\hat{J}_a^, \hat{J}_z] = 0$ follows because $\unitvec{J}_a$ is an angular momentum operator, $\hat{J}_z = \hat{J}_{1z} + \hat{J}_{2z}$ and $[\unitvec{J}_1, \unitvec{J}_2] = 0$. To show that $[\hat{J}^2, \hat{J}_a^2] = 0$, we note that

$$
\begin{align*}
  \hat{J}^2 =& (\unitvec{J}_1 + \unitvec{J}_2)^2 \\
  =& \hat{J}_1^2 + \hat{J}_2^2 + 2\unitvec{J}_1 \cdot \unitvec{J}_2 \\
  =& \hat{J}_1^2 + \hat{J}_2^2 + 2(\hat{J}_{1x} \hat{J}_{2x} + \hat{J}_{1y} \hat{J}_{2y} + \hat{J}_{1z} \hat{J}_{2z})
\end{align*}
$$

It follows that $[\hat{J}^2, \hat{J}_a^2] = 0$ because $[\unitvec{J}_1, \unitvec{J}_2] = 0$ and $[\hat{J}_a^2, \hat{J}_{ai}] = 0$ for $i = x,y,z$. We denote these simultaneous eigenstates by $\ket{j_1 j_2 j n}$. Although $[\hat{J}^2, \hat{J}_z] = 0$, we have on the other hand $[\hat{J}^2, \hat{J}_{az}] \neq 0$. This means that we cannot specify $\hat{J}^2$ in the states $\ket{j_1 j_2, n_1, n_2}$ and we cannot specify either $\hat{J}_{1z}$ or $\hat{J}_{2z}$ in the states $\ket{j_1 j_2 j n}$.

<details>
<summary>Details</summary>

Written as a tensor product, the total angular momentum operator takes the form

$$
  \unitvec{J} = \unitvec{J}_1 \otimes \mathbf{1}_2 + \unitvec{1}_1 \otimes \unitvec{J}_2
$$

Letting $\hat{J}_z$ act on the two-particle sates, we get

$$
\begin{align*}
  \hat{J}_z (\ket{j_1, n_1} \otimes \ket{j_2, n_2}) =& [\hat{J}_{1z} \otimes 1 + 1 \otimes \hat{J}_{2z}](\ket{j_1, n_1} \times \ket{j_2, n_2}) \\
  =& J_{1z} \ket{j_1, n_1} \otimes\ket{j_2, n_2} + \ket{j_1, n_2} \otimes\hat{J}_{2z} \ket{j_2, n_2} \\
  =& \hbar(n_1 + n_2) (\ket{j_1, n_1}\otimes\ket{j_2, n_2})
\end{align*}
$$
</details>

To find the interval of possible $j$ valies, we know that $n_1 \leq |j_1|$ and $n_2 \leq |j_2|$. Thus, from $n = n_1 + n_2$, the maximum value of $n$ must be $j_1 + j_2$. Since $n \leq |j|$, it follows that the maximum value of $j$ is $j_1 + j_2$. Corresponding to this maximum value $j_1 + j_2$ of $j$, we have a multiplet of $2(j_1 + j_2) + 1$ vales of $n$, i.e. $n \leq |j_1 + j_2|$. The total number of possible $n_1 + n_2 = n$ values is $(2j_1 + 1)(2j_2 + 1)$. For each natural number $k\in\N$, the state with $j = j_1 + j_2 - k$ contains $2(j_1 + j_2 - k) + 1$ values of $n$, subject to the constraint

$$
\begin{equation*}
  \sum_{k=0}^b [2(j_1 + j_2 - k) + 1] = (2j_1 + 1)(2j_2 + 1) 
\tag{\label{equation-36}}
\end{equation*}
$$

where the minimum value is $j_\text{min} = j_1 + j_2 - b$. Recalling the formula

$$
  \sum_{k=n}^m k = \frac{m - n + 1}{2}(m + n)
$$

we have

$$
\begin{align*}
  \sum_{k=0}^b [2(j_1 + j_2 - k) + 1] =& 2(j_1 + j_2)(b + 1) - 2\sum_{k=0}^b k + (b + 1) \\
  =& 2(j_1 + j_2)(b + 1) - (b + 1)b + (b + 1) \\
  =& (b + 1)[2(j_1 + j_2) + 1 - b]
\end{align*}
$$

Then $\eqref{equation-36}$ becomes

$$
\begin{gather*}
  (b + 1)[2(j_1 + j_2) + 1 - b] = (2j_1 + 1)(2j_2 + 1) \\
  \implies b^2 - 2(j_1 + j_2)b + 4j_1 j_2 = 0
\end{gather*}
$$

Solving for $b$ using the quadratic formula yields

$$
\begin{align*}
  b =& (j_1 + j_2) \pm \sqrt{(j_1 + j_2)^2 - 4j_1 j_2} \\
  =& (j_1 + j_2) \pm (j_1 - j_2)
\end{align*}
$$

so that $b = 2j_1$ or $b = 2j_2$ giving $j_\text{min} = j_2 - j_1$ or $j_\text{min} = j_1 - j_2$. If $j_1 \neq j_2$, then one of these is negative and must be rejected, and hence we conclude that $j_\text{min} = |j_1 - j_2|$. Consequently

$$
\begin{equation*}
  |j_1 - j_2| \leq j \leq j_1 + j_2 
\tag{\label{equation-37}}
\end{equation*}
$$

### Clebsch-Gordan coefficients

If we denote the two individual momentum states by $\ket{j_a, n_a}$ for $a\in{1,2}$, then the two-particle basis states are given as the tensor product

$$
  \ket{j_1 j_2, n_1 n_2} = \ket{j_1, n_1} \ket{j_2, n_2} = \ket{j_1, n_1} \otimes \ket{j_2, n_2}
$$

In this notation, we have

$$
  (\bra{j_1, n_1}\otimes\bra{j_2, n_2})(\ket{j'_1 n'_1} \otimes \ket{j'_2, n'_2}) = \braket{j_1, n_1 | j'_1, n'_1} \braket{j_2, n_2 | j'_2, n'_2}
$$

Since these two-particle states form a complete set, we can write the total combined angular momentum states of both particles as

$$
\begin{equation*}
  \ket{j_1 j_2 j n} = \sum_{\substack{j'_1 j'_2 \\ n'_1 n'_2}} \ket{j'_1 j'_2 n_1 n_2} \braket{j'_1 j'_2 n_1 n_2|j_1 j_2 j n}
\tag{\label{equation-34}}
\end{equation*}
$$

We now show that many of the matrix elements $\braket{j'_1 j'_2, n_1 n_2 | j_1 j_2 j n}$ vanish. For our two-particle operators with $a\in\set{1,2}$ we have

$$
\begin{align*}
  \hat{J}_a^2 \ket{j_1 j_2, n_1 n_2} =& \hbar^2 j_a (j_a + 1) \ket{j_1 j_2, n_1 n_2} \\
  \hat{J}_{az}^2 \ket{j_1 j_2, n_1 n_2} =& \hbar n_a \ket{j_1 j_2, n_1 n_2}
\end{align*}
$$

Taking the matrix element of $\hat{J}_1^2$ acting to both the left and right, we see that

$$
\begin{align*}
  \braket{j'_1 j'_2, n_1 n_2|\hat{J}_1^2 | j_1 j_2 j n} =& \hbar^2 j'_1 (j'_1 + 1) \braket{j'_1 j'_2, n_1 n_2 | j_1 j_2 j n} \\
  =& \braket{j'_1 j'_2, n_1 n_2| j_1 j_2 j n} \hbar^2 j_1 (j_1 + 1)
\end{align*}
$$

or

$$
  [j'_1 (j'_1 + 1) - j_1 (j_1 + 1)] \braket{j'_1 j'_2, n_1 n_2 | j_1 j_2 j n} = 0
$$

Since this result clearly applies to $\hat{J}_2^2$ as well, we must have

$$
  \braket{j'_1 j'_2, n_1 n_2 | j_1 j_2 n} = 0, \; j'_1 \neq j_1 \lor j'_2 \neq j_2
$$

This simplifies $\eqref{equation-34}$ to

$$
  \ket{j_1 j_2 j n} = \sum_{n_1 n_2} \ket{j_1 j_2, n_1 n_2} \braket{j_1 j_2, n_1 n_2|j_1 j_2 j n}
$$

From $\hat{J}_z = \hat{J}_{1z} + \hat{J}_{2z}$, we can let $\hat{J}_{1z} + \hat{J}_{2z}$ act to the left and $\hat{J}_z$ act to the right so that

$$
\begin{align*}
  \braket{j_1 j_2, n_1 n_2 | \hat{J}_z | j_1 j_2 j n} =& \hbar(n_1 + n_2) \braket{j_1 j_2, n_1 n_1 | j_1 j_2 j n} \\
  =& \braket{j_1 j_2, n_1 n_2|j_1 j_2 j n} \hbar n
\end{align*}
$$

This shows that $\braket{j_1 j_2, n_1 n_2 | j_1 j_2 j n = 0}$ unless $n = n_1 + n_1$. This simplifies $\eqref{equation-34}$ to

$$
  \ket{j_1 j_2 j n} = \sum_{\substack{n_1 n_2 \\ n_1 + n_2 = n}} \ket{j_1 j_2, n_1 n_2} \braket{j_1 j_2, n_1 n_2|j_1 j_2 j n}
$$

If we regard the values of $j_1$ and $j_2$ as fixed, we can simply write the total angular momentum state as

$$
\begin{equation*}
  \ket{j, n} = \sum_{\substack{n_1 n_2 \\ n_1 + n_2 = n}} \ket{n_1 n_2}\braket{n_1 n_2| j n}
\tag{\label{equation-35}}
\end{equation*}
$$

The complex numbers $\braket{n_1 n_2| j m}\in\mathbb{C}$ are called *Clebsch-Gordan coefficients*. Since normalized eigenfunction corresponding to distinct eigenvalues of a Hermitian opreator are orthonormal, we know that

$$
\begin{align*}
  \braket{j', n|j, n} =& \delta_{jj'} \delta_{nn'} \\
  \braket{n'_1 n'_2 | n_1 n_2} =& \delta_{n_1 n'_1} \delta_{n_2 n'_2}
\end{align*}
$$

Thus, taking the inner product of $\eqref{equation-35}$ with itself, we see that

$$
\begin{equation*}
  \sum_{\substack{n_1 n_2 \\ n_1 + n_2 = n}} |\braket{n_1 n_2 | j n}|^2 = 1
\tag{\label{equation-38}}
\end{equation*}
$$

A general formula for the Clebsch-Gordan coefficients is

$$
  \braket{j_1 j_2, n_1 n_2} = (-1)^{j_1 - j_2 + n} \sqrt{2j + 1} \binom{j_1 \; j_2 \; j}{n_1 \; n_2 \; -n}
$$

where

$$
\begin{align*}
  &\binom{j_2 \; j_2 \; j_3}{n_1 \; n_2 \; n_3} = \sqrt{\frac{(j_1 + j_2 - j_3)! (j_1 - j_2 + j_3)! (-j_1 + j_2 + j_3)!}{(j_1 + j_2 + j_3 + 1)!}} \\
  &\times \sqrt{(j_1 + n_1)! (j_1 - n_1)! (j_2 + n_2)! (j_2 - n_2)! (j_3 + n_3)! (j_3 - n_3)!} \\
  &\times \sum_{z\in\N} \frac{(-1)^{z + j_1 - j_2 - n_3}}{z! (j_1 + j_2 - j_3 - z)! (j_1 - m_1 - z)! (j_2 + n_2 - z)!} \\
  &\times \frac{1}{(j_3 - j_2 + n_1 + z)! (j_3 - j_1 - n_2 + z)!}
\end{align*}
$$

are the so-called $3j$-symbols. The sum is in principle infinite. However, since $j_1$, $j_2$ and $j_3$ are finite numbers, the sum truncated due to the fact that the factorial of a negative number in the term $(j_1 + j_2 - j_3 - z)!$ is infinite.

<MathBox title='Two spin-1/2 particles' boxType='example'>
Consider the case of two spin-1/2 particles with $j_1 = j_2 = 1/2$. In this case, we have $n_1 = n_2 = \pm 1/2$, so according to $\eqref{equation-37}$ we have $0 \leq j \leq 1$. For $j_\text{max} = 1$, the top state occurs for $n_1 + n_2 = 1$. Using $\eqref{equation-35}$ we get 

$$
\begin{equation*}
  \ket{j=1, m=1} = \Ket{n_1=\tfrac{1}{2},n_2=\tfrac{1}{2}}\Braket{n_1=\tfrac{1}{2},n_2=\tfrac{1}{2}|j=1, n=1} 
\tag{\label{equation-39}}
\end{equation*}
$$

and by $\eqref{equation-38}$, we must have

$$
  \left|\Braket{\tfrac{1}{2},\tfrac{1}{2}|1, 1}\right|^2 = 1
$$

This specifies the topmost state up to a phase factor. Choosing this phase to be $1$, known as the Condon-Shortley convention, $\eqref{equation-39}$ becomes

$$
\begin{equation*}
  \ket{1, 1} = \Ket{\tfrac{1}{2},\tfrac{1}{2}} = \ket{\uparrow\uparrow} 
\tag{\label{equation-40}}
\end{equation*}
$$

To construct the next lowest state, we act on the left side of $\eqref{equation-40}$ with $\hat{J}_-$ and on the right side with $\hat{J}_- = \hat{J}_{1-} + \hat{J}_{2-}$

$$
\begin{align*}
  \sqrt{2}\ket{1, 0} =& \sqrt{\frac{3}{4} + \frac{1}{4}}\left(\Ket{-\tfrac{1}{2},\tfrac{1}{2}} + \Ket{\tfrac{1}{2},-\tfrac{1}{2}} \right) \\
  \ket{1, 0} =& \frac{1}{\sqrt{2}}\left(\Ket{-\tfrac{1}{2},\tfrac{1}{2}} + \Ket{\tfrac{1}{2},-\tfrac{1}{2}} \right) \tag{\label{equation-41}}
\end{align*}
$$

Since by $\eqref{equation-35}$

$$
  \ket{1, 0} = \Ket{\tfrac{1}{2},-\tfrac{1}{2}}\Braket{\tfrac{1}{2}, -\tfrac{1}{2}|1,0} + \Ket{-\tfrac{1}{2},\tfrac{1}{2}}\Braket{-\tfrac{1}{2},\tfrac{1}{2}|1,0}
$$

we see that

$$
  \Braket{\tfrac{1}{2},-\tfrac{1}{2}|1,0} = \Braket{-\tfrac{1}{2},\tfrac{1}{2}|1,0} = \frac{1}{\sqrt{2}}
$$

Acting on $\eqref{equation-41}$ with $\hat{J}_- = \hat{J}_{1-} + \hat{J}_{2-}$ yields

$$
\begin{align*}
  \sqrt{2}\ket{1,-1} =& \frac{1}{\sqrt{2}}\left[\sqrt{\frac{3}{4} + \frac{1}{4}}\left(\Ket{-\tfrac{1}{2},-\tfrac{1}{2}} + \Ket{-\tfrac{1}{2},-\tfrac{1}{2}} \right)\right] \\
  =& \frac{1}{\sqrt{2}}\left(\ket{\downarrow\uparrow} + \ket{\uparrow\downarrow} \right)
\end{align*}
$$

or

$$
  \ket{1, -1} = \Ket{-\tfrac{1}{2},-\tfrac{1}{2}} = \ket{\downarrow\downarrow}
$$

This completes the $j=1$ multiplet, which are called the triplet states:

$$
  j = 1 : \begin{cases}
    \ket{1, 1} = \ket{\uparrow\uparrow} \\
    \ket{1, 0} = \frac{1}{\sqrt{2}}\left(\ket{\downarrow\uparrow} + \ket{\uparrow\downarrow} \right) \\
    \ket{1, -1} = \ket{\downarrow\downarrow}
  \end{cases}
$$

The triplet states are symmetric because interchanging the two particles leaves the states unchanges. For $j_\text{min} = 0$, we get from $\eqref{equation-35}$ that

$$
\begin{align*}
  \ket{0,0} =& \Ket{\tfrac{1}{2},-\tfrac{1}{2}}\overbrace{\Braket{\tfrac{1}{2},-\tfrac{1}{2}|0,0}}^{a} + \Ket{-\tfrac{1}{2},\tfrac{1}{2}}\overbrace{\Braket{-\tfrac{1}{2},\tfrac{1}{2}|0,0}}^{b} \\
  =& \Ket{\tfrac{1}{2},-\tfrac{1}{2}}a + \Ket{-\tfrac{1}{2},\tfrac{1}{2}}b
\end{align*}
$$

To solve for $a$ and $b$, we first see from $\eqref{38}$ that $a^2 + b^2 = 1$. Since $\ket{j=1,n=0}$ is orthogonal to $\ket{j=0,n=0}$, we get

$$
  0 = \ket{1,0|0,0} = \frac{1}{\sqrt{2}}(a + b) \iff a = -b
$$

Thus, $2a^2 = 1$ so that $a = -b = 1/\sqrt{2}$ giving

$$
  \ket{0,0} = \frac{1}{\sqrt{2}}\left(\Ket{\tfrac{1}{2}, \tfrac{1}{2}} - \Ket{-\tfrac{1}{2},\tfrac{1}{2}} \right) = \frac{1}{\sqrt{2}}\left(\ket{\uparrow\downarrow} - \ket{\downarrow\uparrow} \right)
$$

which is called the singlet state. Interchanging the two particles changes the overall sign of the singlet states, showing that it is antisymmetric.
</MathBox>

# Perturbations and approximation methods

Perturbation theory is a rather general approximation method that may be applied when a small additional force (the perturbation) acts on a system (the unperturbed system), whose quantum dynamics is fully known. If the disturbance is small, it modifies both the energy levels and the stationary states. This allows us to make an expansion in power series of a perturbation parameter, which is assumed to be small. Perturbation theory may be applied both to the case where the additional force is time-independent, as well as to the case where it explicitly depends on time. In the former case we consider the perturbation as causing a modification of the states of the motion of the unperturbed system. In the latter, the perturbed system makes transitions from one state to another under the influence of the perturbation.

## Stationary perturbation theory

Stationary perturbation theory aims to find the changes in the discrete energy levels and eigenstates of a system when a small disturbance is applied. Our procedure is to split the total Hamiltonian into unperturbed and perturbated parts, according to the Dirac picture, so that we have

$$
  \hat{H} = \hat{H}_0 + \xi \hat{H}',\quad \hat{H}_0 \ket{\psi_n} = E_n^{(0)} \ket{\psi_n},\quad \hat{H}\ket{\varphi_n} = E_n \ket{\varphi_n}
$$

Here $\hat{H}_0$ is the Hamiltonian of the unperturbed system, with known eigenstates $\ket{\psi_n}$ and corresponding eigenvalues $E_n^{(0)}$. The pertubation is given by $\hat{H}'$, and $\xi >= 0$ is a real parameter that controls the strength of the perturbation, ensuring hat $\hat{H}$ remains a well-defined operator.

We assume that the solutions to the unperturbed stationary Schr√∂dinger equation are known, i.e. the sets $\set{\ket{\psi_n}}$ and $\set{E_n^{(0)}}$. Our goal is to find the perturbed states $\set{\ket{\varphi_n}}$ and their corresponding energy levels $\set{E_n}$.

### Non-degenerate case

In many cases, the perturbed energy levels $E_n (\xi)$ can be expanded in a Taylor power series about $\xi = 0$, where each power of $\xi$ correspond to the order of perturbation. If $\xi$ is small, and if the energy distance between the discrete unperturbed states are large compared to the energy shifts caused by the perturbation, then the higher terms in the expansion become increasingly negligible. The existence of all derivatives of $E_n (\xi)$ at $\xi = 0$ does not guarantee that $E_n (\xi)$ is analytic there. If this is not the case, the Taylor series is not convergent, but rather asymptotic, i.e.

$$
  \sum_{k=0}^N \xi^k E_n^{(k)} - E_n (\xi) = O(\xi^{N+1})
$$

Since the unperturbed eigenstates form an orthonormal basis of the Hilbert space, we can expand the perturbed eigenstates $\ket{\varphi_n}$ in terms of the eigenstates $\ket{\psi_j}$ of $\hat{H}_0$ as

$$
\begin{equation*}
  \ket{\varphi_n} = \sum_j c_{n,j} \ket{\psi_j}
\tag{\label{equation-147}}
\end{equation*}
$$

We now expand the coefficients $c_{n,j}$ and the eigenvalues $E_n$ as Taylor series about $\xi = 0$, i.e.

$$
\begin{align*}
  c_{n,j} =& \sum_{k=0}^\infty c_{n,j}^{(k)} \xi^j \tag{\label{equation-148}} \\
  E_n =& \sum_{k=0}^\infty E_n^{(k)} \xi^j
\end{align*}
$$

Substituting $\eqref{equation-148}$ into $\eqref{equation-147}$ yields

$$
  \ket{\varphi_n} = \sum_{k=0}^\infty \xi^k \sum_j c_{n,j}^{(k)} \ket{\psi_j}
$$

Taking the limit $\xi\to 0$ recovers the unperturbed state, i.e. $\ket{\varphi_n} \xrightarrow{\xi\to\infty} \ket{\psi_n}$, which in turn implies that $c_{n,j}^{(0)} = \delta_{n,j}$. We can then write

$$
\begin{equation*}
  \ket{\varphi_n} = \sum_{k=0}^\infty \xi^k \ket{\varphi_n^{(0)}}
\tag{\label{equation-149}} 
\end{equation*}
$$

with

$$
\begin{align*}
  \ket{\varphi_n^{(0)}} =& \ket{\psi_n} \\
  \ket{\varphi_n^{(k)}} =& \sum_j c_{n,j}^{(k)} \ket{\varphi_j^{(0)}} \tag{\label{equation-155}}
\end{align*}
$$

Inserting the expansion $\eqref{equation-149}$ into the perturbed stationary Schr√∂dinger equation, we obtain

$$
  (\hat{H}_0 + \xi\hat{H}')\left(\sum_{k=0}^\infty \xi^k \ket{\varphi_n^{(k)}} \right) = \left(\sum_{k=0}^\infty E_n^{(k)} \right)\left(\sum_{k=0}^\infty \xi^k \ket{\varphi_n^{(k)}} \right)
$$

Collecting the terms of equal power of $\xi$, e get the recursive system of equations:

$$
\begin{align*}
  (E_n^{(0)} - \hat{H}_0)\ket{\varphi_n^{(0)}} =& 0 \\
  (E_n^{(0)} - \hat{H}_0)\ket{\varphi_n^{(1)}} + E_n^{(1)} \ket{\varphi_n^{(0)}} =& \hat{H}' \ket{\varphi_n^{(0)}} \tag{\label{equation-153}} \\
  (E_n^{(0)} - \hat{H}_0)\ket{\varphi_n^{(2)}} + E_n^{(1)} \ket{\varphi_n^{(1)}} + E_n^{(2)} \ket{\varphi_n^{(0)}} =& \hat{H}' \ket{\varphi_n^{(0)}} \tag{\label{equation-158}} \\
  \vdots& \\
  (E_n^{(0)} - \hat{H}_0)\ket{\varphi_n^{(m)}} + \sum_{k=1}^m E_n^{(k)} \ket{\varphi_n^{(m - k)}} =& \hat{H}' \ket{\varphi_n^{(m-1)}} \tag{\label{equation-151}} \\
  \vdots&
\end{align*}
$$

The first equation confirms that the unperturbed eigenvector $\ket{\varphi_n^{(0)}}$ is an eigenvector of $\hat{H}_0$ with eigenvalue $E_n^{(0)}$, as expected. Since the homogenous term in each equation is proportional to $\ket{\varphi_n^{(0)}}$ we are free to add a multiple $\eta\ket{\varphi_n^{(0)}}$ for abitrary $\eta\in\mathbb{C}$ to each $\ket{\varphi_n^{(j)}}$. This freedom reflects the ambiguity in defining the perturbed eigenstates up to normalization and global phase. To simplify calculations we can choose the arbitrary term in such a way that higher-order corrections are orthogonal to the unperturbed eigenvector, i.e.

$$
\begin{equation*}
  \braket{\varphi_n^{(0)}|\varphi_n^{(j)}} = 0,\; \forall j
\tag{\label{equation-159}}
\end{equation*}
$$

This implies that the sum for $\ket{\varphi_n^{(j)}}$ in $\eqref{equation-155}$ runs over $j \neq n$. Assuming the unperturbed level $E_n^{(0)}$ is non-degenerate, we can project $\eqref{equation-151}$ onto $bra{\varphi_n^{(0)}}$ to obtain the general expression for the $m$-th order correction to the energy:

$$
\begin{equation*}
  E_n^{(m)} = \Braket{\varphi_n^{(0)}|\hat{H}'| \varphi_n^{(m-1)}},\; m > 0
\tag{\label{equation-152}}
\end{equation*}
$$

which shows that the calculation of any $E_n$ to a given order $\xi$ requires the knowledge of the eigenvectors of $\hat{H}'$ to the next lower order. In particular, the first-order correction to the energy is

$$
  E_n^{(1)} = \Braket{\varphi_n^{(0)}|\hat{H}'|\varphi_n^{(0)}} = \Braket{\psi_n|\hat{H}'|\psi_n} = \mathbf{H}'_{nn}
$$

This is the expectation value of the perturbation $\hat{H}'$ in the unperturbed state $\ket{\psi_n}$, which is equal to the diagonal matrix element of $\mathbf{H}'_{nn}$.

From $\eqref{equation-150}$, the first-order correction to the perturbed eigenstate, $\ket{\varphi_n^{(1)}}$, is given by

$$
\begin{equation*}
  \ket{\varphi_n^{(1)}} = \sum_{j\neq n} c_{n,j}^{(1)} \ket{\psi_j}
\tag{\label{equation-156}}
\end{equation*}
$$

Substituting this into $\eqref{equation-153}$ and rearranging the terms, we obtain

$$
  \sum_{j\neq n} c_{n,j}^{(1)} (E_n^{(0)} - E_j^{(0)}) \ket{\psi_j} = (\hat{H}' - E_n^{(1)})\ket{\psi}_n
$$

Projecting onto $\ket{\psi_k}$ with $k \neq n$, we find

$$
\begin{equation*}
  c_{n,k}^{(1)} = \frac{\Braket{\psi_k|\hat{H}'|\psi_n}}{E_n^{(0)} - E_k^{(0)}}
\tag{\label{equation-154}}
\end{equation*}
$$

which gives the off-diagonal coefficients of the perturbed perturbed eigenstate to first order. Moreover, $\eqref{equation-154}$ determines the range of validity of the perturbation expansion: in order for $\xi c_{n,k}^{(1)}$ to be small, we must have

$$
  \xi\Braket{\psi_k |\hat{H}'|\psi_n} \ll E_n^{(0)} - E_k^{(0)}
$$

Thus, the energy levels must be well-separated relative to the energy changes induced by the perturbation for the series to be a good approximation.

The second-order correction to the energy can be determined by inserting $\eqref{equation-156}$ and $\eqref{equation-154}$ into $\eqref{equation-152}$, giving

$$
\begin{align*}
  E_n^{(2)} =& \sum_{j\neq n} c_{n,j}^{(1)} \braket{\psi_n |\hat{H}'|\psi_j} \\
  =& \sum_{j\neq n} \frac{|\braket{\psi_n |\hat{H}'|\psi_j}|^2}{E_n^{(0)} - E_j^{(0)}}
\end{align*}
$$

From $\eqref{equation-150}$, the second-order correction to the perturbed eigenstate, $\ket{\varphi_n^{(1)}}$, is given by

$$
\begin{equation*}
  \ket{\varphi_n^{(2)}} = \sum_{j\neq n} c_{n,j}^{(2)} \ket{\psi_j}
\tag{\label{equation-157}}
\end{equation*}
$$

Substituting $\eqref{equation-157}$ and $\eqref{equation-156}$ into $\eqref{equation-158}$, we obtain

$$
  \sum_{j\neq n} c_{n,j}^{(2)} (E_n^{(0)} - \hat{H}_0) \ket{\psi_j} + \sum_{j\neq n} c_{n,j}^{(1)} E_n^{(1)} \ket{\psi_j} + E_n^{(2)} \ket{\psi_n} = \sum_{j\neq n} c_{n,j}^{(1)} \hat{H}' \ket{\psi_j}
$$

Rearranging the terms gives

$$
\begin{align*}
  c_{n,k}^2 =& \sum_{j\neq n} \frac{\braket{\psi_k |\hat{H}'|\psi_j}\braket{\psi_j |\hat{H}'|\psi_n}}{(E_n^{(0)} - E_k^{(0)})(E_n^{(0)} - E_j^{(0)})} \\
  &- \frac{\braket{\psi_k |\hat{H}'|\psi_j}\braket{\psi_j |\hat{H}'|\psi_n}}{(E_n^{(0)} - E_k^{(0)})^2}
\end{align*}
$$

Summarizing these results, we may write the energy eigenvalues and eigenstates of the perturbed Hamiltonian to second-order in $\xi$ as

$$
\begin{align*}
  E_n =& E_n^{(0)} + \xi\mathbf{H}'_{nn} + \xi^2 \sum_{j\neq n} \frac{|\mathbf{H}'_{nj}|^2}{E_n^{(0)} - E_j^{(0)}} + O(\xi^3) \\
  \ket{\varphi_n} =& \ket{\psi_n} + \xi \sum_{j\neq n} \left[\frac{\mathbf{H}'_{jn}}{E_n^{(0)} - E_j^{(0)}} \left(1 - \xi\frac{\mathbf{H}'_{nn}}{E_n^{(0)} - E_j^{(0)}} \right) \right. \\
  &+ \left. \xi \sum_{k\neq n} \frac{\mathbf{H}'_{jk} \mathbf{H}'_{kn}}{(E_n^{(0)} - E_k^{(0)})(E_n^{(0)} - E_j^{(0)})} \right] \ket{\psi_j}
\end{align*}
$$

Note that $\ket{\varphi_n}$ is not normalized, so an additional step is required to compute and apply the appropriate normalization factor.

### Degenerate case

Suppose now that two unperturbed eigenstates $\ket{\psi_p}$ and $\ket{\psi_q}$ with $p \leq q$, share the same unperturbed energy eigenvalue $E_p^{(0)} = E_q^{(0)} = E^{(0)}$. In this case, $\set{\ket{\psi_p}, \ket{\psi_q}}$ forms a basis for the two-dimensional subspace associated with the degenerate eigenvalue $E^{(0)}$. However, this basis is not unique; any linear combination of these vectors also spans the same degenerate subspace.

When degeneracy is present, the denominator in $\eqref{equation-154}$ vanishes. Unless we also have $\braket{\psi_p |\hat{H}'|\psi_q} = 0$, the first-order correction coefficient $c_{q,p}^{(1)}$ is not defined. To resolve this issue, we can choose a basis for the degenerate subspace such that the perturbation $\hat{H}$ becomes diagonal. Among all possible linear combinations of $\ket{\psi_p}$ and $\ket{\psi_q}$, we seek a particular superposition that lifts the degeneracy at first order:

$$
  \ket{\varphi^{(0)}} = d_p \ket{\psi_p} + d_q \ket{\psi_q}
$$

where the coefficients $d_p$ and $d_q$ are to be determined. To find the first order corrections, we rewrite $\eqref{equation-153}$ in the degenerate context:

$$
\begin{equation*}
  (E^{(0)} - \hat{H}_0)\ket{\varphi^{(1)}} = (\hat{H}' - E^{(1)}) (d_p \ket{\psi_p} + d_q \ket{\psi_q})
\tag{\label{equation-160}}
\end{equation*}
$$

where we have dropped the index $n$ to focus specifically on the degenerate subspace spanned by $\set{\ket{\psi_p}, \ket{\psi_q}}$. Taking the inner product of both sides woth $\bra{\psi_p}$ and $\bra{\psi_q}$, yields the following homogenous linear system of equations in $d_p$ and $d_q$:

$$
\begin{align*}
  \left(\braket{\psi_p |\hat{H}'|\psi_p} - E^{(1)} \right)d_p + \braket{\psi_p |\hat{H}'|\psi_q}d_q =& 0 \\
  \braket{\psi_q |\hat{H}'|\psi_p} d_p + \left( \right) d_q =& 0
\end{align*}
$$

This system has a nontrivial solution only if the determinant of the coefficient matrix vanishes:

$$
  \begin{vmatrix}
    \mathbf{H}'_{pp} - E^{(1)} & \mathbf{H}'_{pq} \\
    \mathbf{H}'_{qp} & \mathbf{H}'_{qq} - E^{(1)}
  \end{vmatrix} = 0
$$

This gives a quadratic equation for $E^{(1)}$ with solutions

$$
  E^{(1)} = \frac{1}{2}\left[\mathbf{H}'_{pp} + \mathbf{H}'_{qq} \pm \sqrt{(\mathbf{h})} \right]
$$

Since the diagonal matrix elements of $\mathbf{H}'$ are real, both values of $E^{(1)}$ are also real. They are equal if and only if

$$
  \mathbf{H}'_{pp} = \mathbf{H}'_{qq} \;\land\; \mathbf{H}'_{qp} = 0
$$

In this case, we the degeneracy is not lifted at first order. Otherwise, the degeneracy is resolved, and the corresponding eigenstate $\ket{\varphi^{0}}$ can be determined by solving the linear system for $d_p$ and $d_q$.

To find the first-order correction $\ket{\varphi^{(1)}}$ to $\ket{\varphi^{(0)}}$, we use the expansion

$$
  \ket{\varphi^{(1)}} = \sum_j c_j^{(1)} \ket{\varphi_j^{(0)}}
$$

and project $\eqref{equation-160}$ onto $\bra{\psi_k}$, where $k \neq p,q$, to get

$$
  c_k^{(1)} = \frac{\mathbf{H}'_{kp} d_p + \mathbf{H}'_{kq} d_q}{(E^{(0)} - E_k^{(0)})}
$$

which gives the desired oefficients $c_k^{(1)}$ for all $k \neq p,q$. To satisfy the orthogonality condition $\eqref{equation-159}$, we can set $c_p^{(1)} = c_q^{(1)} = 0$, ensuring that the first-order correction $\ket{\varphi^{(1)}}$ remains orthogonal to the unperturbed state $\ket{\varphi^{(0)}}$. 

Once the degenerate subspace is properly diagonalized, the standard non-degenerate perturbation theory may be applied within each new (non-degenerate) sector to compute higher-order corrections.

### Stark effect for a rigid rotator

## Time-dependent pertubation theory

## Adiabatic theory

## The variational method

# Non-relativistic quantum systems

## Free particle

A particle with no forces acting on it is called a free particle. This means that the particle moves in the absence of any potential. Classically, a free particle is moving at constant velocity. In quantum mechanics, the stationary position wavefunction $\psi(x,0)$ of the particle is governed by the time-independent Schr√∂dinger equation $\hat{H}\psi = E\psi$. Assuming that a free particle with mass $m$ moves in the $x$-direction, the Schr√∂dinger equation reads

$$
  -\frac{\hbar^2}{2m}\frac{\d^2 \psi}{\d x^2} = E\psi
$$

introducing $k = \sqrt{2mE}/\hbar$, this simplifies to

$$
  \frac{\d^2}{\d x^2} = -k^2 \psi
$$

with general solution

$$
  \psi(x) = Ae^{ikx} + Be^{-ikx}
$$

The wavefunction for the free particle takes the form

$$
\begin{align*}
  \Psi(x, t) =& \psi(x) e^{-iEt/\hbar} \\
  =& Ae^{ik\left(x - \hbar k t / 2m \right)} + Be^{-ik\left(x + \hbar k t / 2m \right)}
\end{align*}
$$

The two terms describe wave propagation in positive and negative $x$-direction with wave number $k$ and angular velocity $\omega = \hbar k^2 / 2m$. Letting $\mathbf{k} = k\hat{x}$, we can write the solution as

$$
  \Psi_k (\mathbf{x}, t) = Ae^{i (\mathbf{k}\cdot\mathbf{x} - \omega t )}
$$

which represents planar waves with de Broglie wavelength $\lambda = 2\pi/|k|$. According to the de Broglie formula, they carry momentum $p = \hbar k$ and energy $E = \hbar^2 k^2 / 2m$ such that the wavefunction can also be formulated

$$
  \Psi_k (\mathbf{x}, t) = Ae^{i\left(\hbar\mathbf{k}\cdot\mathbf{x} - \hbar^2 k^2 t/2m \right)/\hbar} = Ae^{i\left(\mathbf{p}\cdot\mathbf{x} - Et \right)/\hbar}
$$

The general wavefunction is given as a superposition of planar waves in the form of a integral over $k$:

$$
\begin{equation*}
  \Psi (x, t) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \phi(k) e^{i(kx - \omega t)} \;\d k 
\tag{\label{equation-63}}
\end{equation*}
$$

where $1/\sqrt{2\pi}$ is factored out for convenience. This describes a the motion of a wave packet whose amplitude is modulated by $\phi$. Noting that

$$
  \Psi(x, 0) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \phi(k) e^{ikx} \;\d x
$$

defines a Fourier transform, the coefficient function $\phi$ is given by the inverse Fourier transform

$$
  \phi(k) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \Psi (x, 0) e^{-ikx} \;\d x
$$

A wavefunction $\Psi_k$ travels with a phase velocity given by

$$
  v_k = \frac{\hbar|k|}{2m} = \sqrt{\frac{E}{2m}}
$$

In the classical case, the particle's energy equals the its kinetic energy $E_\text{classic} = \frac{p^2}{2m} = mv^2 / 2$. This implies that the particle's velocity is twice the phace velocity.

$$
  v_\text{classic} = \sqrt{\frac{2E}{m}} = 2v_k
$$

This can be shown in the quantum case as follows. We assume that $\phi(k)$ is narrowly peaked about $k = k_0$. Since the integrand in $\eqref{equation-63}$ is negligible except in the vicinity of $k_0$, we can approximate the dispersion relation $\omega(k)$ to its first-order Taylor expansion about $k_0$:

$$
  \omega(k) \approx \omega_0 + \underbrace{\frac{\d\omega(k_0)}{\d k}}_{\omega'_0} (k - k_0)
$$

Changing varibles $s = k - k_0$, the wavefunction is approximated by

$$
\begin{align*}
  \Psi(x, t) \approx& \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \phi(k_0 + s) e^{i[(k_0 + s)x - (\omega_0 + \omega'_0 s)t]} \;\d s \\
  =& \frac{1}{\sqrt{2\pi}} e^{i(k_0 x - \omega_0 t)} \int_{-\infty}^\infty \phi(k_0 + s) e^{is(x - \omega'_0 t)} \;\d s
\end{align*}
$$

The exponential coefficient is sinusoidal wave traveling at phase velocity

$$
  v_\text{phase} = \omega / k = \frac{\hbar k^2}{2m} 
$$

It is modulated by a wave packet traveling at group velocity 

$$
  v_\text{group} = \frac{\partial\omega}{\partial k} = \frac{\hbar k}{2m}
$$

showing that 

$$
  v_\text{classic} = v_\text{group} = 2v_\text{phase}
$$

### Invariance under Galilean transformations

If $\mathcal{R}$ and $\mathcal{R}'$ are two reference systems such that $\mathcal{R}'$ moves with respect to $\mathcal{R}$ with velocity $\mathbf{v}$. Assuming that the origins of the two frames coincide at time $t = 0$, the relation between the space-time coordinates in $\mathcal{R}$ and $\mathcal{R}'$ is given by the Galilean transformation

$$
\begin{align*}
  \mathbf{x} =& \mathbf{x}' + \mathbf{v}t \\
  t =& t'
\end{align*}
$$

where $\mathbf{x}$ and $\mathbf{x}'$ is the position of a particl in $\mathcal{R}$ and $\mathcal{R}'$, respectively. The momentum and energy of a free particle with mass $m$ get transformed as

$$
\begin{align*}
  \mathbf{p} =& \mathbf{p}' + m\mathbf{v} \\
  E =& E' + \mathbf{v} \cdot \mathbf{p}' + \frac{1}{2}m\mathbf{v}^2
\end{align*}
$$

The position wavefunction of the particle gets transformed as

$$
\begin{align*}
  \psi' (\mathbf{x}, t) =& \exp\left[\frac{i}{\hbar}(\mathbf{p}\cdot\mathbf{x} - Et)\right] \\
  =& \exp\left\{\frac{i}{\hbar} \left[(\mathbf{p} - m\mathbf{v}) \cdot (\mathbf{x} - \mathbf{v}t) + \left(E - \mathbf{v}\cdot\mathbf{p}' - \frac{1}{2}m\mathbf{v}^2 \right)t \right] \right\} \\
  =& \exp\left[\frac{i}{\hbar} \left(\mathbf{p}\cdot\mathbf{x} - Et \right) \right] \exp\left[\frac{i}{\hbar}\left(\frac{1}{2}m\mathbf{v}^2 t - m\mathbf{v}\cdot\mathbf{x} \right)\right] \\
  =& \psi(\mathbf{x}, t) \exp\left[\frac{i}{\hbar}\left(\frac{1}{2}m\mathbf{v}^2 t - m\mathbf{v}\cdot\mathbf{x} \right)\right]
\end{align*}
$$

and

$$
  \psi(\mathbf{x}, t) = \psi' (\mathbf{x} - \mathbf{v}t, t)  \exp\left[\frac{i}{\hbar}\left(m\mathbf{v}\cdot\mathbf{x} - \frac{1}{2}m\mathbf{v}^2 t \right)\right]
$$

Consequently, the wavefunction is invariant under Galilean transformations because the attained exponential is just a phase factor that does not carry the relevant quantities of the free motion of the particle.

### Gaussian wavepacket

The time dependent Schr√∂dinger equation for a free particle reads

$$
  i\hbar \frac{\partial \psi}{\partial t} = -\frac{\hbar^2}{2m}\frac{\partial^2 \psi}{\partial x^2}
$$

This is solved by the separable solution

$$
  \psi_k (x, t) = e^{iE_k t/\hbar}e^{ikx} \quad \forall k \in \R
$$

Although $\psi_k$ itself is non-normalisable, a valid solution can be formed from superpositions of $\psi_k$ with the Fourier transform

$$
  \psi(x, t) = \int_{-\infty}^\infty A(k) \psi_k (x,t) \d k
$$

An appropriate function for $A(k)$ is the Gaussian distribution

$$
  A(k) = \exp\left[-\frac{\left( k - k_0 \right)^2}{2\sigma} + \frac{k_0^2}{2\sigma} \right]
$$

The resulting wavefunction becomes

$$
\begin{align*}
  \psi(x, t) &= \int_{-\infty}^\infty \exp\left(-\frac{k^2 - 2kk_0}{2\sigma} - i\frac{\hbar t k^2}{2m} + ikx \right)\d k \\
  &= \int_{-\infty}^\infty \exp\left[ -\frac{\alpha}{2}\left(k - \frac{\beta}{\alpha} \right)^2 + \frac{\beta^2}{2\alpha} \right] \d k
\end{align*}
$$

with

$$
\begin{aligned}
  \alpha = \frac{1}{\sigma} + \frac{i\hbar t}{m}
\end{aligned}\quad
\begin{aligned}
  \beta = \frac{k_0}{\sigma} + ix
\end{aligned}\quad
$$

integrating gives

$$
  \psi(x, t) = \sqrt{\frac{2\pi}{\alpha (t)}}\exp\left[ -\frac{1}{2\alpha}\left( x - \frac{ik_0}{\sigma} \right)^2 \right]
$$

which is known as a Gaussian wavepacket. The probability density is given by

$$
  P(x, t) = |\psi(x, t)|^2 = \frac{2\pi C e^{k_0^2/\sigma}}{|\alpha|}\exp\left[ -\frac{1}{\sigma|\alpha|^2} \left(x - \frac{\hbar k_0 t}{m} \right)^2 \right]
$$

<details>
<summary>Details</summary>

$$
\begin{align*}
  P(x, t) = |\psi(x, t)|^2 &= \frac{2\pi C}{|\alpha|}\exp\left[-\frac{1}{2\alpha}\left( x - ik_0/\sigma \right)^2 -\frac{1}{2\alpha^*}\left( x + ik_0/\sigma \right)^2 \right] \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{2|\alpha|^2} \left[ \alpha^* \left( x - ik_0/\sigma \right)^2 + \alpha \left( x + ik_0/\sigma \right)^2 \right]\right\} \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{2|\alpha|^2} \left[ \left(\alpha + \alpha^* \right) \left( x^2 - \frac{k_0^2}{\sigma^2} \right) + i2\left(\alpha - \alpha^* \right)k_0 x  \right]\right\} \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{2|\alpha|^2} \left[ \frac{2}{\sigma} \left( x^2 - \frac{k_0^2}{\sigma^2} \right) - \frac{2}{\sigma}\frac{2\hbar k_0 t}{m} x \right]\right\} \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{\sigma|\alpha|^2} \left[ \left( x^2 - \frac{k_0^2}{\sigma^2} \right) - 2\frac{\hbar k_0 t}{m} x \right]\right\} \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{\sigma|\alpha|^2} \left[ \left( x - \frac{\hbar k_0 t}{m}\right)^2 - \frac{k_0^2}{\sigma^2} - \left(\frac{\hbar k_0 t}{m}\right)^2 \right]\right\} \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{\sigma|\alpha|^2} \left[ \left( x - \frac{\hbar k_0 t}{m}\right)^2 - k_0^2 \left( \frac{1}{\sigma^2} + \frac{\hbar^2 t^2}{m^2}\right) \right]\right\} \\
  &= \frac{2\pi C}{|\alpha|}\exp\left\{-\frac{1}{\sigma|\alpha|^2} \left[ \left( x - \frac{\hbar k_0 t}{m}\right)^2 - k_0^2 |\alpha|^2 \right]\right\} \\
  &= \frac{2\pi C e^{k_0^2/\sigma}}{|\alpha|}\exp\left[ -\frac{1}{\sigma|\alpha|^2} \left(x - \frac{\hbar k_0 t}{m} \right)^2 \right]
\end{align*}
$$
</details>

where $C = \frac{e^{-k_0^2/\sigma}}{\sqrt{4\sigma\pi^3}}$ is the normalisation coefficient. Because $\alpha$ increases with time, the wavepacket spreads out, and because the spatial dependence is of the form $x - vt$ with $v = \frac{\hbar k_0}{m}$, it also shifts with time. This can be shown more rigorously by finding the expected value for position

$$
\begin{align*}
  \langle x \rangle &= \frac{1}{\sqrt{\pi\sigma|\alpha|^2}} \int_{-\infty}^\infty x \exp\left[-\frac{1}{\sigma|\alpha|^2}\left( x - \frac{\hbar k_0 t}{m} \right)^2 \right] \d x \\
  &= \frac{1}{\sqrt{\pi\sigma|\alpha|^2}} \int_{-\infty}^\infty \left(\tilde{x} + \frac{\hbar k_0 t}{m} \right) \exp\left( -\frac{\tilde{x}^2}{\sigma|\alpha|^2} \right)\d\tilde{x} \\
  &= \frac{\hbar k_0}{m}t
\end{align*}
$$

This suggests that the momentum is $p = mv = \hbar k_0$. This can be show by calculating the expected value for the momentum operator $p = -i\hbar\frac{\d}{\d x}$

$$
\begin{align*}
  \langle p \rangle &= -i\hbar \int_{-\infty}^\infty \d x \, \frac{\d|\psi|^2}{\d x} = -i\hbar \int_{-\infty}^\infty \d x \, \psi^* \frac{\d\psi}{\d x} \\
  &= \frac{1}{\sqrt{\pi\sigma|\alpha|^2}} \int_{-\infty}^\infty \exp\left[ -\frac{1}{2a^*} \left(x + ik_0/2 \right) \right] \cdot -i\hbar \frac{\d}{\d x} \exp\left[ -\frac{1}{2a} \left(x - ik_0/2 \right) \right] \\
  &= \frac{1}{\sqrt{\pi\sigma|\alpha|^2}} \int_{-\infty}^\infty \frac{i\hbar}{\alpha} \left(x - \frac{ik_0}{\sigma} \right) \exp\left[-\frac{1}{\sigma|\alpha|^2}\left( x - \frac{\hbar k_0 t}{m} \right)^2 \right] \d x \\
  &= \frac{1}{\sqrt{\pi\sigma|\alpha|^2}} \int_{-\infty}^\infty \frac{i\hbar k_0}{\alpha} \left(\frac{\tilde{x}}{k_0} + \frac{\hbar t}{m} - \frac{i}{\sigma} \right) \exp\left( -\frac{\tilde{x}^2}{\sigma|\alpha|^2} \right)\d\tilde{x} \\
  &= \hbar k_0
\end{align*}
$$

## Infinite potential well 

The infinite potential well is used as an ideal model to describe a spatially trapped quantum particle. This is achieved by setting

$$
  V(x) = \begin{cases} 0 &\quad 0 < x < a \\ \infty &\quad \textrm{otherwise} \end{cases}
$$

Inside the well, the time-independent Schr√∂dinger equation is

$$
\begin{align*}
  -\frac{\hbar^2}{2m}\frac{\d^2 \psi}{\d x^2} =& E\psi \\
  \frac{\d^2 \psi}{\d x^2} =& -k^2 \psi
\end{align*}
$$

where $k = \sqrt{2mE}/\hbar$. This is the simple harmonic oscillator equation with general solution

$$
  \psi(x) = A \sin(kx) + B\cos(kx)
$$

which is the superposition of two states, with momentums $p_\pm = \pm \hbar k$. This configuration is therefore similar to that of standing waves, bouncing backwards and forwards inside the well. To ensure continuity of $\psi$, the boundary conditions are $\psi(0) = \psi(a) = 0$. The boundary condition $\psi(0) = 0$ implies $B = 0$, so that the wavefunction must be of the form

$$
  \psi(x) = A \sin(kx)
$$

The boundary conditon $\psi(a) = 0$ implies that $A = 0$, resulting in a trivial non-normalizable solution, or 

$$
  \sin(ka) = n\pi, \; n \in\Z
$$

For $k = 0$ we again get a trivial solution $\psi(x) = 0$, and for negative $k$, we can absorb the minus sign into $A$ since $\sin(-\theta) = -\sin(\theta)$. Hence,

$$
  k_n = \frac{n\pi}{a},\; n\in\N_+
$$

and the possible energy states are given by

$$
\begin{equation*}
  E_n = \frac{(\hbar k_n)^2}{2m} = \frac{(\hbar \pi n)^2}{2m a^2} 
\tag{\label{equation-108}}
\end{equation*}
$$

Normalizing $\psi$, we find

$$
  \braket{\psi|\psi} = \int_0^a |A|^2 \sin^2 (kx) \;\d x = |A|^2 \frac{a}{2} = 1 \implies |A|^2 = \frac{2}{a} 
$$

since the phase of $A$ carries no physical significance, we can set $A = \sqrt{2/a}$, giving the solutions

$$
  \psi_n (x) = \sqrt{\frac{2}{a}} \sin\left(\frac{n\pi}{a} x\right)
$$

The wavefunctions $\psi_n$ are orthonormal since

$$
\begin{align*}
  \braket{\psi_m|\psi_n} =& \int_0^a \psi_m^* (x) \psi_n (x) \;\d x = \frac{2}{a} \int_0^a \sin\left(\frac{m\pi}{a}x \right) \sin\left(\frac{n\pi}{a}x \right) \;\d x \\
  =& \frac{1}{a} \int_0^a \left[\cos\left(\frac{m - n}{a}\pi x\right) - \cos\left(\frac{m+n}{a}\pi x \right)\right] \;\d x \\
  =& \left[\frac{1}{(m - n)\pi} \sin\left(\frac{m-n}{a}\pi x\right) - \frac{1}{(m + n)\pi} \sin\left(\frac{m + n}{a} \pi x \right)\right]_0^a \\
  =& \frac{1}{\pi} \left(\frac{\sin[(m-n)\pi]}{m - n} - \frac{\sin[(m+n)\pi]}{m + n} \right) = \delta_{mn}
\end{align*}
$$

From Fourier theory, we know that $\sin(n\pi/a)$ forms a basis for the Hilbert space $L^2 ([0,a])$. This means that $\psi_n$ are complete, in the sense that any function $f(x)$ can be expressed as a linear combination

$$
  f(x) = \sum_{n=1}^\infty c_n \psi_n (x) = \sqrt{\frac{2}{a}} \sum_{n=1}^\infty c_n \sin\left(\frac{n\pi}{a}x\right)
$$

where the coefficients are given by 

$$
  c_n = \braket{\psi_n|f} = \int_0^a \psi_n^* (x) f(x) \;\d x
$$

<details>
<summary>Details</summary>

For any $\psi_m$ we have

$$
\begin{align*}
  \braket{\psi_m | f} =& \int_0^a \psi_m^* (x) f(x) \;\d x = \sum_{n=1}^\infty c_n \int_0^a \psi_m^* (x) \psi_n \;\d x \\
  =& \sum_{n=1}^\infty c_n \delta_{mn} = c_n
\end{align*}
$$
</details>

The stationary states of the infinite square well are

$$
  \Psi_n (x, t) = \psi_n (x) e^{-iEt/\hbar} = \sqrt{\frac{2}{a}} \sin\left(\frac{n\pi}{a} x \right) \exp\left(-\frac{i n^2 \pi^2 \hbar}{2ma^2}t \right)
$$

The general solution to the time-dependent Schr√∂dinger equation for the infinite potential well is a linear combination of stationary states:

$$
  \Psi(x,t) = \sum_{n=1}^\infty c_n \sqrt{\frac{2}{a}} \sin\left(\frac{n\pi}{a} x \right) \exp\left(-\frac{i n^2 \pi^2 \hbar}{2ma^2}t \right)
$$

By the completenes of $\psi_n$ it follows that $\Psi(x, 0) = \sum_{n=1}^\infty c_n \psi_n (x)$ so that

$$
  c_n = \sqrt{\frac{2}{a}} \int_0^a \sin\left(\frac{n\pi}{a} x \right) \Psi(x, 0) \;\d x
$$

The general state $\Psi(x,t)$ is normalized since

$$
\begin{align*}
  \braket{\Psi|\Psi} =& \int \Psi^* \Psi \; \d x = \int |\psi|^2 \;\d x \\
  =& \int \left(\sum_{m=1}^\infty c_m \psi_m (x) \right)^* \left(\sum_{n=1}^\infty c_n \psi_n (x) \right) \;\d x \\
  =& \sum_{m=1}^\infty \sum_{n=1}^\infty c_m^* c_n \int \psi_m^* (x) \psi_n (x) \;\d x \\
  =& \sum_{n=1}^\infty \sum_{m=1}^\infty c_m^* c_n \delta_{mn} = \sum_{n=1}^\infty |c_n|^2
\end{align*}
$$

The expected value for the total energy is

$$
\begin{align*}
  \langle H \rangle =& \braket{\Psi|\hat{H}\Psi} = \int \Psi^* \hat{H} \Psi \;\d x = \int \left(\sum_{m=1}^\infty c_m \psi_m \right)^* \hat{H} \left(\sum_{n=1}^\infty c_n \psi_n \right) \;\d x \\
  =& \sum_{m=1}^\infty \sum_{n=1}^\infty c_m^* c_n E_n \int \psi_m^* \psi_n \;\d x = \sum_{n=1}^\infty |c_n|^2 E_n
\end{align*}
$$

## Harmonic oscillator

The classical harmonic oscillator consists of a mass $m$ attached to a spring of forces constant $k$. The oscillatory motion is given by Hooke's law

$$
  F = -kx = m \frac{\d^2 x}{\d t^2}
$$

with solution

$$
  x(t) = A\sin(\omega t) + B\cos(\omega t)
$$

where $\omega = \sqrt{k/m}$ is the angular frequency of oscillation. The potential energy has the quadratic form

$$
\begin{equation*}
  V(x) = \frac{1}{2}kx^2 = \frac{1}{2}m\omega^2 x^2 
\tag{\label{equation-55}}
\end{equation*}
$$

The harmonic oscillator is an ideal model. However, any potential can be approximated by a parabolic function in the neighbourhood of a local minimum. The Taylor expansion of a potential $V(x)$ about a minimum $x_0$ is

$$
  V(x) = V(x_0) + \underbrace{V' (x_0)}_{=0} (x - x_0) + \frac{1}{2} V'' (x_0) (x - x_0)^2 +\cdots
$$

We are free to substract the constant $V(x_0)$ because that does not change to force. This means that

$$
  V(x) \approx \frac{1}{2} V''(x_0) (x - x_0)^2
$$

which describes simple harmonic oscillation about $x_0$ with an effective spring constant $k = V''(x_0)$.

With the quadratic potential $\eqref{equation-55}$, the Hamiltonian becomes

$$
  \hat{H} = -\frac{\hbar^2}{2m}\frac{\d^2}{\d x^2} + \frac{1}{2}m\omega^2 x^2
$$

giving the time-independent Shr√∂dinger equation

$$
\begin{equation*}
  -\frac{\hbar^2}{2m}\frac{\d^2\psi}{\d x^2} + \frac{1}{2}m\omega^2 x^2 \psi = E\psi 
\tag{\label{equation-56}}
\end{equation*}
$$

### Heisenberg's solution

Choosing a basis $\set{\ket{n}}$ in which $\hat{H}$ is diagonal, we have

$$
  \hat{H}\ket{n} = E_n \ket{n}
$$

where the energy eigenvalue $E_n$ corresponds to the eigenvector $\ket{n}$, i.e.

$$
  E_n = H_{nn} = \braket{n|\hat{H}|n}
$$

since $\braket{m|n} = \delta_{nm}$. Working in the Heisenberg picture, we preliminary compute the matric elements of $\dot{\mathbf{O}}_{nm}$ of the time derivative of a generic operator $\hat{O}$ given its matrix elements $\mathbf{O}_{nm}$. If $\hat{O}$ does not explicitly depend on time, then from

$$
  \frac{\d}{\d t} \hat{O}(t) = \frac{1}{i\hbar} [\hat{O}(t), \hat{H}]
$$

we have

$$
\begin{align*}
  \dot{\mathbf{O}}_{nm} =& \braket{n|\dot{\hat{O}}|m} = \Braket{n|\frac{1}{i\hbar} [\hat{O}(t), \hat{H}]|m} \\
  =& \frac{1}{i\hbar} \braket{n|\hat{O}\hat{H} - \hat{H}\hat{O}|m} \\
  =& \frac{1}{i\hbar} (E_m - E_n) \braket{n|\hat{O}|m} = i \frac{E_n - E_m}{\hbar} \mathbf{O}_{nm} \\
  =& i \boldsymbol{\omega}_{nm} \mathbf{O}_{nm} \tag{\label{equation-141}}
\end{align*}
$$

where $\boldsymbol{\omega}_{nm}$ are Bohr's quantized angular frequencies

$$
\begin{equation*}
  \boldsymbol{\omega}_{nm} = \frac{E_n - E_m}{\hbar} 
\tag{\label{equation-144}}
\end{equation*}
$$

To find the energy levels of the harmonic oscillator, we consider its quantum Hamiltonian equation:

$$
  \hat{\dot{x}} = \frac{\partial\hat{H}}{\partial p} = \frac{\hat{p}}{m}, \quad \hat{\dot{p}}_x = -\frac{\partial\hat{H}}{\partial x} = -m\omega^2 \hat{x}
$$

These equations lead to the second-order differential equation

$$
  \hat{\ddot{x}} + \omega^2 \hat{x} = 0
$$

Heisenberg proposed that this equation must hold for every matrix element. That is, for each pair of eigenstates $\ket{n}$ and $\ket{k}$, we have

$$
\begin{equation*}
  \left(\hat{\ddot{x}} + \omega^2 \hat{x}\right)_{nk} = \hat{\ddot{x}}_{nk} + \omega^2 \hat{x}_{nk} = 0
\tag{\label{equation-142}}
\end{equation*}
$$

The matrix elements $x_{nk} = \braket{n|\hat{x}|k}$ are given by

$$
\begin{align*}
  x_{nk} =& \int \braket{n|x} x \braket{x|k} \;\d x \\
  =& \int \psi_n^* (x) x \psi_k (x) \;\d x
\end{align*}
$$

where $\psi_k (x) = \braket{x|k}$ is the eigenfunction corresponding to the eigenvalu $E_k$. To find the matrix elements of $\hat{\ddot{x}}$ we differentiate $\eqref{equation-141}$ with respect to time, yielding

$$
  \ddot{x}_{nm} = -\omega_{nm}^2 x_{nm}
$$

From $\eqref{equation-142}$, we get the equation

$$
\begin{equation*}
  (\omega^2 - \omega_{nk}^2) x_{nk} = 0 
\tag{\label{equation-143}}
\end{equation*}
$$

For allowed energy transitions, we must have $x_{nk} \neq 0$, in which case $\omega_{nk} = \pm\omega$. This implies that the energy difference is given by

$$
  E_n - E_k = \pm\hbar\omega
$$

which shows that the energy levels of the harmonic oscillator are equally spaced, i.e. $E_{j+1} - E_j = \hbar\omega$ for any $j \geq 0$.

Since $\hat{H}$ is Hermitian, we can choose real eigenfunctions $\psi_n (x) = \braket{x|n} = \psi_n^* (x)$. Moreover, $\hat{H}$ is positive definite, i.e.

$$
\begin{align*}
  H_{nn} =& \braket{n|\hat{H}|n} = \int \psi_n^* (x) \hat{H} \psi_n (x) \;\d x \\
  =& \int \psi_n (x) \hat{H} \psi_n (x) > 0
\end{align*}
$$

To show this explicitly, note first that since the potential energy $V(x) > 0$, we only have to ascertain that $(1/2pm) \braket{n|\hat{p}^2|n} > 0$. Since $\hat{p}$ is Hermitian, it follows that

$$
\begin{align*}
  \braket{n|\hat{p}^2|n} =& [\bra{\hat{p}}][\hat{p}\ket{n}] \\
  =& [\bra{n}\hat{p}^\dagger] [\hat{p}\ket{n}] \geq 0
\end{align*}
$$

The positive definiteness of $\hat{H}$ implies a minimum energy value $E$ at $n = 0$. 

To find the matrix elements of $\hat{x}$, we note from $\eqref{equation-143}$ that $x_{nk} \neq 0$ only if $k = n \pm 1$, meaning that energy transitions occur only between neighbouring levels. Since $\hat{x}$ is Hermitian, it must be symmetric, i.e. $x_{nk} = x_{kn}$. Invoking the commutation relation $[\hat{x},\hat{p}] = i\hbar\hat{I}$ we get

$$
  \hat{x}\hat{\dot{x}} - \hat{\dot{x}}\hat{x} = i\frac{\hbar}{m}\hat{I}
$$

or

$$
  \sum_{lk} (x_{nl}\dot{x}_{lk} - \dot{x}_{nl} x_{lk}) = i\frac{\hbar}{m}\delta_{nk}
$$

which implies

$$
  \sum_{lk} (x_{nl} \dot{x}_{lk} - \dot{x}_{nl} x_{lk}) = i\frac{\hbar}{m}
$$

Using $\eqref{equation-141}$, we can rewrite this as

$$
  \sum_{lk} (x_{nl} \omega_{ln} x_{ln} - \omega_{nl} x_{nl} x_{lk}) = \frac{\hbar}{m}\delta_{nk}
$$

where $\omega$ is an antisymmetric matrix, since from $\eqref{equation-144}$ we have $\omega_{nm} = -\omega_{mn}$. Hence

$$
  2\sum_l x_{nl}^2 \omega_{ln} = \frac{\hbar}{m}
$$

Since $l$ can only take values $l = n \pm 1$, we finally obtain

$$
  x_{n, n-1}^2 \omega_{n - 1,n} + x_{n,n+1}^2 \omega_{n+1,n} = \frac{\hbar}{2m}
$$

Furthermore, $\omega_{n+1, n} = \omega$ and $\omega_{n-1, n} = -\omega$, so that we may start with $n = 0$ and construct the matrix element

$$
  x_{01} = \sqrt{\frac{(n+1)\hbar}{2m\omega}}
$$

Proceeding recursively for increasing values of $n$, we find

$$
  x_{n, n+1} = \sqrt{\frac{\hbar}{2m\omega}}
$$

The knowledge of the matrix elements of $\hat{x}$ allows us to fine the matrix elements of all the other operators. In particular

$$
\begin{align*}
  E_n =& H_{nn} = \frac{1}{2} (\dot{x}^2)_{nn} + \frac{1}{2} m\omega^2 (x^2)_{nn} \\
  =& \frac{1}{2} m \sum_l \dot{x}_{nl} \dot{x}_{ln} + \frac{1}{2} m\omega^2 \sum_l x_{nl} x_{ln} \\
  =& -\frac{1}{2} m \sum_l \omega_{nl} \omega_{ln} x_{nl} x_{ln} + \frac{1}{2} m\omega^2 \sum_l x_{nl} x_{ln}
\end{align*}
$$

Since $x_{nl}$ is symmetric and $\omega_{nl}$ anti-symmetric, we have

$$
\begin{align*}
  E_n =& \frac{1}{2} m \sum_l \omega_{nl}^2 x_{nl}^2 + \omega^2 x_{nl}^2 \\
  =& \frac{1}{2}m (\omega^2 x_{n,n+1} + \omega^2 x_{n,n-1} + \omega^2 x_{n,n+1} + \omega^2 x_{n,n-1}) \\
  =& m\omega^2 (x_{n,n+1}^2 + x_{n,n-1}^2) \\
  =& m\omega^2 \left(\frac{(n+1)\hbar}{2m\omega} + \frac{n\hbar}{2m\omega} \right) \\
  =& \left(n + \frac{1}{2} \right)\hbar\omega
\end{align*}
$$

### Algebraic method

The harmonic oscillator problem $\eqref{equation-56}$ can be solved algebraically using ladder operators. To see this, we write the Hamiltonian as

$$
  \hat{H} = \frac{1}{2m} \left[(m\omega x)^2 + \hat{p}^2 \right]
$$

We want to find operators that factor the Hamiltonian. This motivates us to define the ladder operators

$$
  \hat{a}_\pm := \frac{1}{\sqrt{2\hbar m}} (m\omega x \mp i\hat{p}) = \sqrt{\frac{m}{2\hbar\omega}}\left(\omega\hat{x} \mp i\hat{\dot{x}}\right)
$$

where $\hat{a}_- = \hat{a}$ is is called the lowering (annihilation) operator and $\hat{a}_+ = \hat{a}^\dagger$ is called the raising (creation) operator. The reason for their names lies in the way they act on the energy eigenstates. In particular, we have

$$
\begin{align*}
  a_{nk}^\dagger = \braket{n|\hat{a}_-|k} =& \sqrt{\frac{m}{2\hbar\omega}}\braket{n|\omega\hat{x} - i\hat{\dot{x}}|k} \\
  =& \sqrt{\frac{m}{2\hbar\omega}} [\omega x_{nk} - i(i\omega_{nk} x_{nk})] \\
  =& \sqrt{\frac{m}{2\bar\omega}} (\omega + \omega_{nk}) x_{nk}
\end{align*}
$$

For $k = n + 1$, we have $x_{nk} \neq 0$ and $\omega_{n,n+1} = -\omega$, hence $a_{n,n+1}^\dagger = 0$. The only non-zero matrix element of $\hat{a}^\dagger$ is then $a_{n,n - 1}^\dagger$, for which we have

$$
  \omega_{n, n-1} = \omega,\quad x_{n,n-1} = \sqrt{\frac{n\hbar}{2m\omega}}
$$

It follows that

$$
  a_{nk}^\dagger = \delta_{k, n-1} \sqrt{n}
$$

Similarly, we have

$$
  a_{nk} = \delta_{k, n+1} \sqrt{n + 1}
$$

Calculating the product operator $\hat{a}_+ \hat{a}_-$, we find

$$
\begin{align*}
  \hat{a}_+ \hat{a}_- =& \frac{1}{2\hbar m\omega} (m\omega\hat{x} - i\hat{p}) (m\omega\hat{x} + i\hat{p}) \\
  =& \frac{1}{2\hbar m \omega} \left[(m\omega x)^2 + \hat{p}^2 + i m \omega (x\hat{p} - \hat{p}x)\right] \\
  =& \frac{1}{2\hbar m \omega} \left[(m\omega x)^2 + \hat{p}^2 \right] + \frac{i}{2\hbar} \underbrace{[\hat{x},\hat{p}]}_{=i\hbar} \\
  =& \frac{1}{\hbar\omega} \hat{H} - \frac{1}{2}
\end{align*}
$$

showing that that
$$
  \hat{H} = \hbar\omega\left(\hat{a}_- \hat{a}_+ - \frac{1}{2} \right)
$$

In matrix form, we have

$$
  H_{nn} = \hbar\omega \left[(\hat{a}^\dagger \hat{a})_{nn} + \frac{1}{2}\right]
$$

where

$$
  (\hat{a}_- \hat{a}_+)_{nn} = \sum_k a_{nk}^\dagger a_{kn} = a_{n,n-1}^\dagger a_{n-1, n} = n
$$

Therefore, in the energy representation the operator $\hat{N} = \hat{a}^\dagger \hat{a}$ is diagonal and its $n$-th diagonal term is just equal to $n$, i.e.

$$
  \hat{N}\ket{n} = n\ket{n}
$$

Consequently, the eigenstates of $\hat{N}$ are also the eigenstates of $\hat{H}$ since

$$
\begin{align*}
  \hat{H}\ket{n} =& \hbar\omega\left(\hat{N} + \frac{1}{2}\hat{I} \right)\ket{n} \\
  =& \hbar\omega \left(n + \frac{1}{2}\right)\ket{n}
\end{align*}
$$

Similarly, we find

$$
  \hat{a}_- \hat{a}_+ = \frac{1}{\hbar\omega}\hat{H} + \frac{1}{2}
$$

or

$$
  \hat{H} = \hbar\omega\left(\hat{a}_- \hat{a}_+ - \frac{1}{2} \right)
$$

We now see that the ladder operators satisfy the commutation relation

$$
  [\hat{a}_- \hat{a}_+] = \hat{a}_- \hat{a}_+ - \hat{a}_+ \hat{a}_- = \hat{I}
$$

On the other hand, we have

$$
\begin{equation*}
\begin{split}
  \hat{a}\ket{n} =& \sum_k \ket{k} \braket{k|\hat{a}|n} = \sum_k a_{kn} \ket{k} \\
  =& \sum_k \delta_{n-1, k} \sqrt{k+1} \ket{k} = \sqrt{n} \ket{n - 1}
\end{split}
\tag{\label{equation-57}}
\end{equation*}
$$

and similarly

$$
\begin{align*}
  \hat{a}^\dagger \ket{n} =& \sum_k \ket{k} \braket{k|\hat{a}^\dagger |n} = \sum_k a_{kn}^\dagger \ket{k} \\
  =& \sum_k \delta_{n+1, k} \sqrt{k} \ket{k} = \sqrt{n+1} \ket{n + 1}
\end{align*}
$$

This shows that $\hat{a}$ and $\hat{a}^\dagger$ lowers and raises the energy by a unit $\hbar\omega$, respectively.

Applying $\hat{a}$ to the ground state $\ket{0}$ we expect that $\hat{a}\ket{0} = 0$, or
$$
  (m\omega\hat{x} + i\hat{p}) \ket{0} = 0
$$

In terms of the wavefunction $\psi_n (x) = \braket{x|n}$, this translates into the ordinary differential equation

$$
\begin{gather*}
  \left(m\omega\hat{x} + \hbar\frac{\d}{\d x} \right) \psi_0 (x) = 0
  \frac{\d}{\d x} \psi_0 (x) = -\frac{m\omega}{\hbar} x\psi_0 (x)
\end{gather*}
$$

Integrating the equation gives

$$
\begin{gather*}
  \int \frac{\d\psi_0}{\psi_0} = -\frac{m\omega}{\hbar} \int x \;\d x \\
  \implies \ln\psi_0 = -\frac{m\omega}{2\hbar} x^2 + \tilde{A}
\end{gather*}
$$

so that the solution is

$$
  \psi_0 (x) = A \exp\left(-\frac{m\omega}{2\hbar} x^2 \right)
$$

Normalizing $\psi_0$ yields

$$
  1 = |A|^2 \int_{-\infty}^\infty e^{-m\omega x^2 / \hbar} \;\d x = |A|^2 \sqrt{\frac{\pi\hbar}{m \omega}} \implies A = \left(\frac{m\omega}{\pi\hbar}\right)^{1/4}
$$

resulting in the wavefunction

$$
  \psi_0 (x) = \left(\frac{m\omega}{\pi\hbar}\right)^{1/4} \exp\left(-\frac{m\omega}{2\hbar} x^2 \right)
$$

Using the fact that $\hat{a} \psi_0 = 0$ we get from $\eqref{equation-57}$ that

$$
\begin{align*}
  \hbar\omega\left(\hat{a}_+ \hat{a}_-  +\frac{1}{2}\right)\psi_0 =& E_0 \psi_0 \\
  \frac{1}{2}\hbar\omega \psi_0 = E\psi_0
\end{align*}
$$

implying that the energy for the ground state is

$$
  E_0 = \frac{1}{2}\hbar\omega
$$

Having determined the ground state, we can find the excited states by repeatedly applying the raising operator $\hat{a}_+$, i.e.

$$
  \psi_n (x) = A_n (\hat{a}_+)^n \psi_0 (x)
$$

The corresponding energies are given by

$$
\begin{equation*}
  E_n = \left(n + \frac{1}{2}\right)\hbar\omega 
\tag{\label{equation-58}}
\end{equation*}
$$

To find the normalization constants we note that $\hat{a}_\pm \psi_n$ is proportional to $\psi_{n\pm 1}$, i.e.

$$
  \hat{a}_+ \psi_n = c_n \psi_{n+1}, \quad \hat{a}_- \psi_n = d_n \psi_{n-1}
$$

Furthermore, we have

$$
\begin{equation*}
\begin{split}
  \braket{\hat{a}_\pm \psi_n | \hat{a}_\pm \psi_n} =& \int_{-\infty}^\infty (\hat{a}_\pm \psi_n)^* (\hat{a}_\pm \psi_n) \;\d x \\
  =& \int_{-\infty}^\infty (\hat{a}_\mp \hat{a}_\pm \psi_n)^* \psi_n \;\d x \\
  =& \braket{\hat{a}_\mp \hat{a}_\pm \psi_n|\psi_n}
\end{split}
\tag{\label{equation-59}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

Let $f, g \in L^2 (\R)$ be square integrable functions. Noting that $\hat{a}_\pm^* = \hat{a}_\mp$ we find using integration by parts that

$$
\begin{align*}
  \braket{f|\hat{a}_\pm g} =& \int_{-\infty}^\infty f^* (\hat{a}_\pm g) \;\d x \\
  =& \frac{1}{\sqrt{2\hbar m \omega}} \int_{-\infty}^\infty f^* \left(\mp \hbar \frac{\d}{\d x} + m\omega x \right) g \;\d x
\end{align*}
$$

Using integration by parts, we get

$$
  \int_{-\infty}^\infty f^* \frac{\d g}{\d x} \; \d x = \underbrace{\left[ f^* g \right]_{-\infty}^\infty}_{=0} - \int_{-\infty}^\infty \frac{\d f^*}{\d x}
$$

so

$$
\begin{align*}
  \int_{-\infty}^\infty f^* (\hat{a}_\pm g) \;\d x =& \frac{1}{\sqrt{2\hbar m \omega}} \int_{-\infty}^\infty \left[\left(\pm\hbar\frac{\d}{\d x} + m\omega x \right) f \right]^* g \;\d x \\
  =& \int_{-\infty}^\infty (\hat{a}_\pm f)^* g \;\d x = \braket{\hat{a}_\mp f| g}
\end{align*}
$$

This shows that

$$
  \braket{f|\hat{a}_\pm g} = \braket{\hat{a}_\mp f| g}
$$
</details>

Using $\eqref{equation-57}$ and $\eqref{equation-58}$, we obtain

$$
\begin{equation*}
  \hat{a}_+ \hat{a}_- \psi_n = n\psi_n, \quad \hat{a}_- \hat{a}_+ \psi_n = (n + 1)\psi_n 
\tag{\label{equation-60}}
\end{equation*}
$$

so

$$
\begin{align*}
  \braket{\hat{a}_+ \psi_n | \hat{a}_+ \psi_n} =& \braket{c_n \psi_{n+1} | c_n \psi_{n+1}} \\
  =& |c_n|^2 \braket{\psi_{n+1}|\psi_{n+1}} = (n + 1) \braket{\psi_n|\psi_n}
\end{align*}
$$

and

$$
\begin{align*}
  \braket{\hat{a}_- \psi_n | \hat{a}_- \psi_n} =& \braket{d_n \psi_{n-1} | d_n \psi_{n-1}} \\
  =& |d_n|^2 \braket{\psi_{n-1}|\psi_{n-1}} = n \braket{\psi_n|\psi_n}
\end{align*}
$$

Since $\psi_n$ and $\psi_{n+1}$ are normalized, it follows that $|c_n|^2 = n + 1$ and $|d_n|^2 = n$, resulting in

$$
  \hat{a}_+ \psi_n = \sqrt{n + 1} \psi_{n+1}, \quad \hat{a}_- \psi_n = \sqrt{n} \psi_{n-1}
$$

This shows that the normalization factor is $A_n = 1/\sqrt{n!}$ so that

$$
  \psi_n = \frac{1}{\sqrt{n!}} (\hat{a}_+)^n \psi_0
$$

Furthermore, using $\eqref{equation-59}$ and $\eqref{equation-60}$ we have

$$
\begin{align*}
  \braket{\psi_m | \hat{a}_+ \hat{a}_- \psi_n} =& n\braket{\psi_m|\psi_n} = \braket{\hat{a}_- \psi_m| \hat{a}_- \psi_n} \\
  =& \braket{\hat{a}_+ \hat{a}_- \psi_m | \psi_n} = m \braket{\psi_m | \psi_n}
\end{align*}
$$

This only holds if $\braket{\psi_m | \psi_n} = 0$ for $m \neq n$, showing that the wavefunctions $\psi_n$ are orthonormal.

### Analytic method

To solve $\eqref{equation-58}$ analytically, we introduce the dimensionless variables

$$
  u = \sqrt{\frac{m\omega}{\hbar}}x, \quad K = \frac{2E}{\hbar\omega}
$$

reducing the time-independent Schr√∂dinger equation to

$$
\begin{equation*}
  \frac{\d^2\psi}{\d u^2} = (u^2 -K)\psi 
\tag{\label{equation-60}}
\end{equation*}
$$

In the limit $u\to\infty$, the equation approximates to

$$
  \frac{\d^2\psi}{\d u^2} \approx u^2 \psi
$$

with general solution in the form of the Gaussian wavefunction

$$
  \psi(u) \approx Ae^{-u^2 / 2} + B e^{u^2 / 2}
$$

The $B$ term blows up as $|u| \to \infty$, suggesting that physically solutions have the asymptotic form

$$
  \psi(u) \approx Ae^{-u^2 / 2}
$$

This motivates us to seek solutions of the form

$$
\begin{equation*}
  \psi(u) = h(u) e^{-u^2 / 2} 
\tag{\label{equation-60}}
\end{equation*}
$$

where $h(u)$ is a polynomial. The derivatives of $\psi(u)$ are

$$
\begin{align*}
  \frac{\d\psi}{\d u} =& \left(\frac{\d h}{\d u} - uh \right) e^{-u^2 / 2} \\
  \frac{\d^2 \psi}{\d u^2} =& \left(\frac{\d^2 h}{\d u^2} - 2u \frac{\d h}{\d u} + (u^2 - 1)h \right) e^{-u^2 / 2}
\end{align*}
$$

Substituting $\psi(u) = h(u) e^{-u^2 / 2}$ into $\eqref{equation-60}$ yields a second order ordinary diffential equation with respect to $h$:

$$
\begin{equation*}
  \frac{\d^2 h}{\d u^2} - 2u \frac{\d h}{\d u} + (K - 1)h = 0 
\tag{\label{equation-61}}
\end{equation*}
$$

This equation can be solved using the power series method assuming a solution of the form

$$
  h(u) = \sum_{j=0}^\infty a_j u^j
$$

with derivatives

$$
\begin{align*}
  \frac{\d h}{\d u} =& \sum_{j=0}^\infty j a_j u^{j-1}
  \frac{\d^2 h}{\d u^2} =& \sum_{j=0}^\infty (j + 1)(j + 2) a_{j+2} u^j 
\end{align*}
$$

Inserting the power series into $\eqref{equation-61}$ gives

$$
\begin{align*}
  \sum_{j=0}^\infty j(j-1) a_j u^{j-2} - 2\sum_{j=0}^\infty j a_j u^j (K - 1) \sum_{j=0}^\infty a_j u^j = 0 \\
  \sum_{j=0}^\infty \left[(j + 2)(j + 1)a_{j+2} - 2ja_j - (K - 1)a_j \right] u = 0
\end{align*}
$$

From the uniqueness of power series expansions, it follows that the coefficient of each power of $u$ must vanish, i.e.

$$
  (j + 1)(j + 2) a_{j + 2} - 2j a_j + (K - 1)a_j = 0
$$

This results in the recursive relation

$$
\begin{equation*}
  a_{j+2} = \frac{2j + 1 - K}{(j + 1)(j + 2)}a_j 
\tag{\label{equation-62}}
\end{equation*}
$$

If the series does not terminate, then the recursion relation approximates to $a_{j+2} \approx 2a_j / j$ as $j \to \infty$ with approximate solution

$$
  a_j \approx \frac{C}{(j/2)!}
$$

for some constant $C$. This means that $h(u)$ gets the asymptotic form

$$
  h(u) \approx C \sum_{j=0}^\infty \frac{1}{(j/2)!} u^j \approx C \sum_{j=0}^\infty \frac{1}{j!} u^{2j} \approx C^2
$$

which blows up as $|u| \to \infty$. The power series must therefore terminate for some $j$ to be normalisable. From the recursive relation $\eqref{equation-62}$, we require $K = 2n + 1$ for $n\in\N$. This mean that the total energy is given by

$$
  E_n = \left(n + \frac{1}{2} \right)\hbar\omega, \; n\in\N
$$

in general, the recursive relation $\eqref{equation-62}$ defines the Hermite polynomials $H_n$ given by the Rodrigues formula

$$
  H_n (u) = (-1)^n e^{u^2} \left(\frac{\d}{\d u}\right)^n e^{-u^2}
$$

The stationary states for the harmonic oscialltor are

$$
  \psi_n (x) = \left(\frac{m\omega}{\pi\hbar}\right)^{1/4} \frac{1}{\sqrt{2^n n!}} H_n (u) e^{-u^2 / 2}
$$

## Delta-function well

The delta-function well is a potential of the form

$$
  V(x) = -\alpha \delta(x), \; \alpha\in\R_+
$$

where $\delta$ is the Dirac delta function defined as

$$
  \delta(x) := \begin{cases}
    0, \quad& x \neq 0 \\
    \infty, \quad x = 0
  \end{cases},\quad \int_{-\infty}^\infty \delta(x) \;\d x = 1
$$

The time-independent Schr√∂dinger equation for particle of mass $m$ subject to this potential reads

$$
  -\frac{\hbar^2}{2m} \frac{\d^2 \psi}{\d x^2} - \alpha \delta (x) \psi = E \psi
$$

and allows both bound states for $E < 0$ and scattering states for $E > 0$. We will first consider bound states. In the region $x < 0$, we have $V(x) = 0$, giving

$$
  \frac{\d^2 \psi}{\d x^2} = -\frac{2mE}{\hbar^2} \psi = \kappa^2 \psi
$$

where

$$
  \kappa := \frac{\sqrt{-2mE}}{\hbar}
$$

is real a positive. The equation has general solution

$$
  \psi(x) = Ae^{-\kappa x} + Be^{\kappa x}
$$

The first term blows up as $x\to -\infty$, so we must choose $A = 0$ for a normalizable solution. In the region $x > 0$, we also have $V(x) = 0$, and the general solution is of the form

$$
  \psi(x) = Fe^{-\kappa x} + Ge^{\kappa x}
$$

In this case, the second term blows up as $x \to\infty$, so we must have $G = 0$. At $x = 0$, we require that $\psi$ is continuous, implying that $F = B$, i.e.

$$
  \psi(x) = Be^{\kappa|x|}
$$

Taking the derivative

$$
\begin{equation*}
  \frac{\d\psi}{\d x} = \begin{cases}
    -B\kappa e^{-\kappa x}, \quad& x > 0 \\
    B\kappa e^{\kappa x},\quad& x < 0
  \end{cases}
\tag{\label{equation-64}}
\end{equation*}
$$

shows that $\psi$ is not continuously differentiable at $x = 0$. The discontinuity of $\d\psi/\d x$ of can be determined by integrating the Schr√∂dinger equation in a neighbourhood $[-\epsilon,\epsilon]$ about $x = 0$, and then take the limit as $\epsilon\to 0$

$$
  -\frac{\hbar^2}{2m} \int_{-\epsilon}^\epsilon \frac{\d^2 \psi}{\d x^2} \;\d x + \int_{-\epsilon}^\epsilon V(x) \psi(x) \;\d x = E \int_{-\epsilon}^\epsilon \psi(x) \;\d x
$$

In the limit $\epsilon\to 0$, the right hand side vanishes so that

$$
\begin{align*}
  \Delta\left(\frac{\d\psi}{\d x}\right) :=& \lim_{\epsilon\to 0} \left( \left.\frac{\d\psi}{\d x}\right|_{\epsilon} - \left.\frac{\d\psi}{\d x}\right|_{-\epsilon} \right) \\
  =& \frac{2m}{\hbar^2} \lim_{\epsilon\to 0} \int_{-\epsilon}^\epsilon V(x) \psi(x) \;\d x \\
  =& -\frac{2m\alpha}{\hbar^2} \lim_{\epsilon\to 0} \underbrace{\int_{-\epsilon}^\epsilon \delta(x) \psi(x) \;\d x}_{=\psi(0)} \\
  =& -\frac{2m\alpha}{\hbar^2} \psi(0) \tag{\label{equation-65}}
\end{align*}
$$

From $\eqref{equation-64}$ we get that

$$
  \Delta\left(\frac{\d\psi}{\d x}\right) = -2B\kappa
$$

Since $B = \psi(0)$, we obtain 

$$
  \kappa = \frac{m\alpha}{\hbar}
$$

and the allowed energy is

$$
  E = -\frac{\hbar^2 \kappa^2}{2m} = -\frac{m\alpha^2}{2\hbar^2}
$$

To determine $B$, we normalize $\psi$:

$$
  1 = \int_{-\infty}^\infty |\psi(x)|^2 \;\d x = 2|B|^2 \int_0^\infty e^{-2\kappa x} \;\d x = \frac{|B|^2}{\kappa}
$$

Choosing the positive real root we find

$$
  B = \sqrt{\kappa} = \frac{\sqrt{m\alpha}}{\hbar}
$$

This shows that the delta-function well has a single bound state

$$
  \psi(x) = \frac{\sqrt{m\alpha}}{\hbar} e^{-m\alpha|x|/\hbar^2}
$$

Next, we consider scattering states with $E > 0$. In the region $x < 0$, the Schr√∂dinger equation reads

$$
  \frac{\d^2 \psi}{\d x^2} = -\frac{2mE}{\hbar^2} \psi = -k^2 \psi
$$

where

$$
  k := \frac{\sqrt{2mE}}{\hbar}
$$

is real and positive. The equation has general solution

$$
  \psi(x) = Ae^{ikx} + Be^{-ikx}
$$

describing waves with amplitude $A$ and $B$ propagating in positive and negative $x$-direction, respectively. Likewise, for $x > 0$ the general solution is

$$
  \psi(x) = Fe^{ikx} + Ge^{-ikx}
$$

describing waves with amplitude $F$ and $G$ propagating in positive and negative $x$-direction, respectively. The continuity of $\psi$ at $x$ requires that

$$
\begin{equation*}
  F + G = A + B 
\tag{\label{equation-66}}
\end{equation*}
$$

and the derivatives are

$$
\frac{\d\psi}{\d x} = \begin{cases}
  ik(Fe^{ikx} - Ge^{-ikx}) \\
  ik(Ae^{ikx} - Be^{-ikx})
\end{cases}
$$

so that

$$
  \Delta\left(\frac{\d\psi}{\d x}\right) = ik(F - G - A + B)
$$

Since $\psi(0) = A + B$, the second boundary condition $\eqref{equation-65}$ implies that

$$
  ik(F - G - A + B) = -\frac{2m\alpha}{\hbar^2} (A + B)
$$

or, more compactly

$$
\begin{equation*}
  F - G = A(1 + 2i\beta) - B(1 - 2i\beta) 
\tag{\label{equation-67}}
\end{equation*}
$$

where

$$
  \beta := \frac{m\alpha}{\hbar^2 k}
$$

If we consider scattering of a particle travelling from left (positive $x$ direction), the amplitude of the wave originating from right is zero, i.e. $G = 0$. This describes a scattering process where
- $A$ is the amplitude of an incident wave propagating in positive $x$ direction
- $B$ is the amplitude of a reflect wave in negative $x$ direction
- $F$ is the amplitude of a transmitted wave in positive $x$ direction 

Solving $\eqref{equation-66}$ and $\eqref{equation-67}$ for $B$ and $F$, we find

$$
  B = \frac{i\beta}{1 - i\beta}A, \quad F = \frac{1}{1 - i\beta} A
$$

The probability of finding the particle at a specific location is given by $|\Psi|^2$, so the relative probability that incident particle will be reflected back is

$$
  R := \frac{|B|^2}{|A|^2} = \frac{\beta^2}{1 + \beta^2} = \frac{1}{1 + (2\hbar^2 E/m\alpha^2)}
$$

called the *reflection coefficient*. Meanwhile, the probability that a particle will continue right is

$$
  T := \frac{|F|^2}{|A|^2} = \frac{1}{1 + \beta^2} = \frac{1}{1 + (m\alpha^2 / 2\hbar^2 E)}
$$

called the *transmission coefficient*. Since probability is preserved, we find

$$
  R + T = 1
$$

Note that since $\psi$ is not normalizable in this case, it does not represent physically possible particle states. Thus, $R$ and $T$ are approximate reflection and transmission probabilities for particles with energy $E$.

## Finite square well

A finite square well is described by a potential

$$
  V(x) = \begin{cases}
    -V_0, \quad& |x| \leq a \\
    0, \quad& |x| > a
  \end{cases},\; V_0 \in\R
$$

This potential admits both bound and scattering states. We first consider bound states. In the region $|x| > a$, the potential is zero, so the time-independent Schr√∂dinger equation is

$$
  \frac{\d^2 \psi}{\d x^2} = \kappa^2 \psi
$$

where

$$
\begin{equation*}
  \kappa := \frac{\sqrt{-2mE}}{\hbar} 
\tag{\label{equation-70}}
\end{equation*}
$$

is real and positive. In the region $x < -a$, the general solution is

$$
  \psi(x) = Ae^{-\kappa x} + Be^{\kappa x}
$$

The first term blows up as $x\to -\infty$, so we must have $A = 0$ for a normalizable solution. Likewise, in the region $x > a$, the general solution is

$$
  \psi(x) = Fe^{-\kappa x} + Ge^{\kappa x}
$$

However, this time the second term blows up as $x \to\infty$, so we require $G = 0$. In the region $|x| \leq a$, the potential is $V(x) = -V_0$, and the Schr√∂dinger equation is

$$
  \frac{\d^2 \psi}{\d x^2} = -l^2 \psi
$$

where

$$
\begin{equation*}
  l := \frac{\sqrt{2m(E + V_0)}}{\hbar} 
\tag{\label{equation-71}}
\end{equation*}
$$

For bound states, $E > V_0$, meaning that $l > 0$. The general solution is

$$
  \psi(x) = C \sin(lx) + D\cos(lx)
$$

Since $V(x)$ is an even function, the wavefunctions are either even or odd. This means that we only need to impose the boundary conditions on one side because $\psi(-x) = \pm\psi(x)$. If we assume that $\psi$ is even, we must have $C = 0$ and the wavefunctions have the form

$$
  \psi(x) = \begin{cases}
    Fe^{-\kappa x}, \quad& x > a \\
    D\cos(lx), \quad& 0 < x a \\
    \psi(-x), \quad& x < 0
  \end{cases}
$$

The continuity of $\psi$ at $x = a$ says

$$
\begin{equation*}
  Fe^{-\kappa a} = D\cos(la) 
\tag{\label{equation-68}}
\end{equation*}
$$

and the continuity of $\d\psi/\d x$ says

$$
\begin{equation*}
  -\kappa Fe^{-\kappa a} = -lD\sin(la) 
\tag{\label{equation-69}}
\end{equation*}
$$

Dividing $\eqref{equation-69}$ by $\eqref{equation-68}$, we find

$$
\begin{equation*}
  \kappa = l\tan(la) 
\tag{\label{equation-72}}
\end{equation*}
$$

This equation determines the allowed energies, since $\kappa$ and $l$ are both functions of $E$. For convenience, we introduce the notation

$$
\begin{equation*}
  z := la, \quad z_0 := \frac{a}{\hbar}\sqrt{2mV_0} 
\tag{\label{equation-73}}
\end{equation*}
$$

From $\eqref{equation-70}$ and $\eqref{equation-71}$, we have $(\kappa^2 + l^2) = 2mV_0 / \hbar^2$, so $\kappa a = \sqrt{z_0^2 - x^2}$, and $\eqref{equation-72}$ becomes

$$
\begin{equation*}
  \tan(z) = \sqrt{(z_0/z)^2 - 1} 
\tag{\label{equation-74}}
\end{equation*}
$$

This is a transcendental equation for $z$ as a function of $z_0$ and must be solved numerically. Two limiting cases are of special interest:
1. **Wide, deep well:** If $z_0$ is very large, the solutions to $\eqref{equation-74}$ occur slightly below $z_n = n\pi/2$ with $n$ odd. It follows from $\eqref{equation-73}$ that 
$$
  E_n + V_0 \approx \frac{n^2 \pi^2 \hbar^2}{2m(2a)^2}, \; n\in (\N/2)^C
$$
The right-hand size coincides with the infinite square well energies $\eqref{equation-108}$. In the limit $V_0 \to\infty$, the finite square well goes over to the infinite square well.
2. **Shallow, narrow well:** As $z_0$ decreases, there are fewer and fewer bound states, until only one remains for $z_0 < \pi/2$.

Next, we consider scattering states, $E > 0$. Outside the well for $x z -a$, the wavefunctions take the form

$$
  \psi(x) = Ae^{ikx} + Be^{-ikx}
$$

with

$$
  \kappa := \frac{\sqrt{2mE}}{\hbar}
$$

Inside the well for $|x| \leq a$ with $V(x) = -V_0$, the wavefunctions have the form

$$
  \psi(x) = C\sin(lx) + D\cos(lx)
$$

with

$$
  l := \frac{\sqrt{2m(E + V_0)}}{\hbar}
$$

Assuming there are no incident waves coming from the other side of the well for $x > a$, the wavefunctions take the 

$$
  \psi(x) = Fe^{ikx}
$$

This describes a scattering process where
- $A$ is the incident amplitude
- $B$ is the reflected amplitude
- $F$ is the transmitted amplitude

There are four boundary conditions:
1. Continuity of $\psi$ at $x = -a$ requires
$$
  Ae^{-ika} + Be^{ika} = -C\sin(la) + D\cos(la)
$$
2. Continuity of $\d\psi/\d x$ at $x = -a$ gives
$$
  ik[Ae^{-ika} - Be^{ika}] = l[C\cos(la) + D\sin(la)]
$$
3. Continuity of $\psi$ at $x = a$ yields
$$
  C\sin(la) + D\cos(la) = Fe^{ika}
$$
4. Continuity of $\d\psi/\d x$ at $x = a$ says
$$
  l[C\cos(la) - D\sin(la)] = ikFe^{ika}
$$

We can use two of the boundary conditions to eliminate $C$ and $D$, and solve the remaining two for $B$ and $F$, resulting in

$$
\begin{align*}
  B =& i\frac{i\sin(2la)}{2kl} (l^2 - k^2) F \\
  F =& \frac{e^{-2ika A}}{\cos(2la) - i\frac{(k^2 + l^2)}{2kl}\sin(2la)}
\end{align*}
$$

The transmission coefficient $T = |F|^2 / |A|^2$ is given by

$$
  T^{-1} = 1 + \frac{V_0^2}{4E(E + V_0)} \sin^2 \left(\frac{2a}{\hbar} \sqrt{2m(E + V_0)} \right)
$$

Note that $T = 1$, when the sine is zero, or

$$
  \frac{2a}{\hbar}\sqrt{2m (E_n + V_0)} = n\pi\; n \in\Z
$$

The energies for perfect transmission are given by

$$
  E_n + V_0 = \frac{n^2 \pi^2 \hbar^2}{2m (2a)^2}
$$

which happens to be precisely the allowed energies for infinite square well.

## Particle on a ring

A rigid body rotating in a plane can be modeled as a mass point moving along a circle of radius $r$ about the centre of mass, , corresponding to the radius of gyration. The moment of inertia of the point mass is $I = mr^2$. A quantum particle of mass $m$ constrained to move on a circle of $r$ in the $xy$-plane, subject to a constant potential, is described by the Hamiltonian

$$
  \hat{H} = -\frac{\hbar^2}{2m} \nabla^2
$$

In polar coordinates $(r,\phi)$ with

$$
\begin{align*}
  r =& \sqrt{x^2 + y^2} \\
  \phi =& \arctan\left(\frac{y}{x}\right)
\end{align*}
$$

the Laplacian is

$$
  \nabla^2 = \frac{\partial^2}{\partial r^2} + \frac{1}{r} \frac{\partial}{\partial r} + \frac{1}{r^2} \frac{\partial^2}{\partial\phi^2}
$$

Since $r$ is constant, the radial derivatives vanish, and the Hamiltonian reduces to

$$
  \hat{H} = -\frac{\hbar^2}{2mr^2} \frac{\d^2}{\d\phi^2} = -\frac{\hbar^2}{2I} \frac{\d^2}{\d\phi^2}
$$

A wavefunction $\psi(\phi)$ satisfies the stationary Schr√∂dinger equation $\hat{H}\psi = E\psi$ taking the form
$$
  \psi'' = -\frac{2IE}{\hbar^2} \psi
$$

This is a linear second-order differential equation with constant coefficients. Its general solution is

$$
\begin{equation*}
  \psi(\phi) = Ae^{im_\ell \phi} + Be^{im_\ell \phi},\; m_\ell = \sqrt{\frac{2IE}{\hbar}}
\tag{\label{equation-163}}
\end{equation*}
$$

Because wavefunctions must be single valued, it follows that $\psi(\phi + 2\pi) = \psi(\phi)$. This imposes the cyclic boundary condition

$$
  A e^{im_\ell \phi} e^{2\pi im_\ell} + Be^{-im_\ell \phi} e^{-2\pi im_\ell} = A e^{im_\ell \phi} + Be^{-im_\ell \phi}
$$

which is satifisfied only if $m_\ell \in\Z$ is an integer, since then, by Euler's relation, $e^{2\pi m_\ell} = 1$. From $\eqref{equation-163}$, it follows that the allows energies are

$$
\begin{equation*}
  E_{m_\ell} = \frac{m_\ell^2 \hbar^2}{2I}
\tag{\label{equation-164}}
\end{equation*}
$$

In polar coordinates the angular momentum operator along $z$ is 

$$
  \hat{L}_z = (\unitvec{r} \times \unitvec{p})_z = -i\hbar \frac{\d}{\d\phi}
$$

Applying $\hat{L}_z$ to the eigenfunction $\psi_{m_\ell} (\phi) = A e^{im_\ell \phi}$ gives the eigenvalue equation

$$
\begin{align*}
  \hat{L}_z \psi_{m_\ell} =& -i\hbar \frac{\d}{\d\phi} Ae^{im_\ell \phi} = m_\ell \hbar Ae^{im_\ell \phi} \\
  =& m_\ell \hbar \psi_{m_\ell}
\end{align*}
$$

The angular momentum is given by the eigenvalues $m_\ell \hbar$. The sign of $m_\ell$ determines the direction of rotation. 

The wavefunction is normalized according to

$$
  \braket{\psi_{m_\ell}, \psi_{m_\ell}} = \int_0^{2\pi} \psi^* \psi \;\d\phi = 1
$$

If $B = 0$, we obtain

$$
  \int_0^{2\pi} |\psi(\phi)|^2 \;\d\phi = |A|^2 \int_0^{2\pi} \;\d\phi = 2\pi |A|^2
$$

It follows that $|A| = 1/\sqrt{2\pi}$, and $A$ is conventionally chosen to be real, giving the wavefunctions

$$
\begin{equation*}
  \psi_{m_\ell} = \frac{1}{\sqrt{2\pi}} e^{im_\ell \phi}
\tag{\label{equation-165}}
\end{equation*}
$$

From $\eqref{equation-164}$, it follows that all energy levels except the ground state, $m_\ell = 0$, are doubly generate. This degeneracy stems from the fact that the particle can travel in either direction with the same magnitude of angular momentum, and hence with the same kinetic energy.

The probability density is uniform since

$$
  |\psi_{m_\ell}|^2 = \frac{1}{\sqrt{2\pi}} e^{-im_\ell \phi} \frac{1}{\sqrt{2\pi}} e^{im_\ell \phi} = \frac{1}{2\pi}
$$

The wave functions have the following symmetry

$$
\begin{align*}
  \phi_{m_\ell} (\phi + \pi) =& \frac{1}{\sqrt{2\pi}} e^{im_\ell (\phi + \pi)} \\
  =& \frac{1}{\sqrt{2\pi}} e^{im_\ell \phi} (e^{i\pi})^{m_\ell} \\
  =& (-1)^{m_\ell} \psi_{ml}
\end{align*}
$$

This shows that points separated by $\pi$ radians across the diameter of the ring have the same amplitude, but differ in sign if $m_\ell$ is odd.

## Particle on a sphere

A solid uniform sphere of mass $m$ and radius $R$ can be representated by the motion of a single point of mass $m$ at a distance $r = \sqrt{2/5}$ from the centre of the sphere, corresponding to the radius of gyration.

In spherical coordinates, the Laplacian is

$$
  \nabla^2 = \frac{1}{r^2} \frac{\partial}{\partial r} \left(r^2 \frac{\partial }{\partial r} \right) + \frac{1}{r^2} \Lambda^2 
$$

where the angular part $\Lambda^2$ is

$$
  \Lambda^2 = \frac{1}{\sin(\theta)} \frac{\partial}{\partial\theta} \left(\sin(\theta) \frac{\partial}{\partial\theta} \right) + \frac{1}{\sin^2 (\theta)} \frac{\partial^2}{\partial\phi^2}
$$

Using $\eqref{equation-82}$, we can express $\Lambda^2$ in terms of $\unitvec{L}^2$ as

$$
  \Lambda^2 = -\frac{\unitvec{L}^2}{\hbar^2}
$$

Since $r$ is constant, the Hamiltonian reduces to

$$
\begin{align*}
  \hat{H} =& -\frac{\hbar^2}{2m} \nabla^2 = -\frac{\hbar^2}{2m} \left(-\frac{\unitvec{L}^2}{\hbar^2 r^2}\right) \\
  =& \frac{\unitvec{L}^2}{2mr^2}
\end{align*}
$$

Since $[\hat{H}, \unitvec{L}^2] = [\hat{H}, \hat{L}_i] = 0$ for one of $i \in (x,y,z)$, it follows that the simultaneous eigenfunctions of $\unitvec{L}^2$ and $\hat{L}_z$, given by the spherical harmonics $Y_\ell^{m_\ell} (\theta, \phi)$ are also eigenfunctions of $\hat{H}$.

The spherical harmonics satisfy the eigenvalue equation

$$
  \unitvec{L}^2 Y_\ell^{m_\ell} = \hbar^2 \ell (\ell + 1) Y_\ell^{m_\ell}
$$

and from the time-independent Schr√∂rdinger equation $\hat{H}Y_\ell^{m_\ell} = E Y_\ell^{m_\ell}$ we obtain

$$
  E Y_\ell^{m_\ell} = \frac{1}{2mr^2} \unitvec{L}^2 Y_\ell^{m_\ell} = \hbar^2 \ell (\ell + 1) Y_\ell^{m_\ell} 
$$

Solving for $E$ gives the energy levels

$$
\begin{equation*}
  E_\ell = \frac{\hbar^2}{2I} l(l + 1)
\tag{\label{equation-87}}
\end{equation*}
$$

where $I = mr^2$ is the moment of inertia. The energy is independent of $m_\ell$ and for a given value of $\ell$, there are $2\ell + 1$ values of $m_\ell$. Thus, each energy level is $(2\ell + 1)$-fold degenerate.

### Rigid rotator

Consider two point masses $m_1, m_2$ joined be a massless rigid rod of fixed length $r_0$. If the origin is aligned with the centre of mass, the position of the masses $m_1$ and $m_2$, are

$$
\begin{align*}
  r_1 =& \frac{m_2}{m_1 + m_2} r_0 \\
  r_2 =& \frac{m_1}{m_1 + m_2} r_0
\end{align*}
$$

Introduce the reduced mass

$$
  m := \frac{m_1 m_2}{m_1 + m_2}
$$

The moment of inertia about any axis through the centre of mass that is perpendicular to the bond is

$$
  I = m_1 r_1^2 + m_2 r_2^2 = mr_0^2
$$

A general rigid bode has 6 degrees of freedom, 3 translational and 3 rotational. A diatomic rigid rotor is a special linear rigid body: rotation about the bond axis does not change the mass distribution and therefore carries no rotational kinetic energy. Consequently the physically relevant rotational motion has only angular dependende. The three translational degrees of freedom of the centre of mass are those of a free particle.

If the rigid body rotates with angular velocity $\boldsymbol{\omega}$ perpendicular to the bond, the classical rotational energy about the centre of mass is

$$
  T = \frac{1}{2}I\omega^2
$$

The classical angular momentum is $\mathbf{L} = I \boldsymbol{\omega}$, so equivalently

$$
  T = \frac{L^2}{2I}
$$

The rotational degrees of freedom can be quantized by the angular momentum operator $\unitvec{L}$. The Hamiltonian for the rotational motion is

$$
  \hat{H} = \frac{\unitvec{L}^2}{2I}
$$

which is equivalent to a particle on sphere. The eigenfunctions are given by the spherical harmonics $Y_\ell^{m_\ell} (\theta, \phi)$, and the eigenvalues are

$$
  E_\ell = \frac{\hbar^2}{2I}
$$

The energy difference between adjacent rotational levels is

$$
\begin{align*}
  \Delta E_{\ell \to \ell + 1} =& E_{\ell + 1} - E_\ell = \frac{\hbar^2}{2I}[(\ell + 1)(\ell + 1) - \ell(\ell + 1)] \\
  =& \frac{\hbar^2}{2I} 2(\ell + 1) = \frac{\hbar^2}{I}(\ell + 1)
\end{align*}
$$

The emitted (or absorbed) photon frequency is

$$
\begin{align*}
  \nu_{\ell \to \ell+1} =& \frac{\Delta E_{\ell, \ell + 1}}{h} \\
  =& \frac{\hbar^2 (\ell + 1)}{I h} = \frac{h(\ell + 1)}{4\pi^2 I}
\end{align*}
$$

It is common to introduce the rotational constant

$$
  B = \frac{h}{8\pi^2 I}
$$

such that $\nu_{\ell \to \ell+1} = 2B(\ell + 1)$.

## Particle in a central potential

A central potential depends only on the radial distance from the origin, $r = |\mathbf{r}|$. The rotational symmetry of such potensials implies that orbital angular momentum, $\unitvec{L} = \unitvec{r} \times \unitvec{p}$ is conserved. This latter fact follows from the classical equation of motion $\dot{\mathbf{p}} = -\nabla V$, where $\nabla V$ is parallel to $\mathbf{r}$ if $V$ is central. We then have

$$
  \frac{\d\mathbf{L}}{\d t} = \dot{\mathbf{r}} \times \mathbf{p} + \mathbf{r} \times \dot{\mathbf{p}} = 0
$$

The Hamiltonian operator of a particle with mass $m$ subject to a central potential $V$ is given by

$$
  \hat{H} = \frac{\unitvec{p}^2}{2m} + V(r) = -\frac{\hbar^2}{2m}\nabla^2 + V(r)
$$

Using spherical coordinates, the Laplacian is

$$
\begin{align*}
  \nabla^2 = \frac{1}{r^2} \frac{\partial}{\partial r} \left(r^2 \frac{\partial}{\partial r} \right) - \frac{\unitvec{L}^2}{\hbar^2 r^2}
\end{align*}
$$

Introducing the operator corresponding to the radial component of the momentum

$$
  \hat{p}_r = -i\hbar\frac{1}{r}\frac{\partial}{\partial r} r = -i\hbar\left(\frac{\partial}{\partial r} + \frac{1}{r}\right)
$$

the Hamiltonian can be written

$$
\begin{align*}
  \hat{H} =& -\frac{\hbar^2}{2m} \left[\frac{1}{r^2} \left(r^2 \frac{\partial}{\partial r} \right) - \frac{\unitvec{L}^2}{\hbar^2 r^2}\right] + V(r) \\
  =& \frac{1}{2m}\left(\hat{p}_r^2 + \frac{\hbar^2 \unitvec{L}^2}{r^2} \right) + V(r)
\end{align*}
$$

which corresponds to the classical Hamiltonian in spherical coordinates. The time-independent Schr√∂dinger equation can be expressed as

$$
\begin{equation*}
  \left\{-\frac{\hbar^2}{2m}\left[\frac{1}{r^2} \frac{\partial}{\partial r}\left(r^2 \frac{\partial}{\partial r} \right) - \frac{\unitvec{L}^2}{\hbar^2 r^2} \right] + V(r) \right\} \psi(r,\theta,\phi) = E\psi(r,\theta,\phi) 
\tag{\label{equation-42}}
\end{equation*}
$$

Since $\hat{L}_i$ and $\unitvec{L}^2$ are independent on $r$ and $[\hat{L}_i, \unitvec{x}^2] = 0 = [\hat{L}_i, \unitvec{p}^2]$, it follows that $[\hat{H}, \hat{L}_i] = 0$ and $[\hat{H}, \unitvec{L}^2] = 0$. In other words, the simultanous eigenfunctions of $\unitvec{L}^2$ and $\hat{L}_z$, given by the spherical harmonics $Y_\ell^{m_\ell} (\theta, \phi)$ are also eigenfunctions of $\hat{H}$. Thus, the wavefunctions of $\hat{H}$, solving $\eqref{equation-42}$, take the form

$$
  \psi(r,\theta,\phi) = R(r) Y_\ell^{m_\ell} (\theta, \phi)
$$

Using the fact that $\unitvec{L}^2 Y_\ell^{m_\ell} = \hbar^2\ell(\ell + 1) Y_\ell^{m_\ell}$, we can refactor $\eqref{equation-42}$ as

$$
\begin{equation*}
  \left[-\frac{\hbar^2}{2mr^2} \frac{\partial}{\partial r} \left(r^2 \frac{\partial}{\partial r} \right) + \frac{\hbar^2 \ell(\ell + 1)}{2mr^2} + V(r) - E \right] R(r) = 0 
\tag{\label{equation-43}}
\end{equation*}
$$

Substituting $u(r) = rR(r)$ with

$$
\begin{equation*}
  R(r) = u(r)/r 
\tag{\label{equation-51}}
\end{equation*}
$$ 

and

$$
\begin{gather*}
  \frac{\d R}{\d r} = \frac{1}{r^2}\left(r \frac{\d u}{\d r} - u \right) \\
  \frac{1}{r^2} \frac{\partial}{\partial r} \left(r^2 \frac{\partial}{\partial r} \right) \frac{u}{r} = \frac{1}{r} \frac{\partial^2}{\partial r^2}
\end{gather*}
$$

we can simplify $\eqref{equation-43}$ to the radial equation

$$
\begin{equation*}
  -\frac{\hbar^2}{2m} \frac{\d^2}{\d r^2}u(r) + \left[V(r) + \frac{\hbar^2 \ell(\ell + 1)}{2m r^2}\right]u(r) = Eu(r) 
\tag{\label{equation-44}}
\end{equation*}
$$

which is analogous to the one-dimensional Schr√∂dinger equation apart from the additive term

$$
  V_\text{c} (r) = \frac{\hbar^2 \ell(\ell + 1)}{2mr^2}
$$

representing a repulsive centrifugal barrier. The wavefunctions of $\hat{H}$ must satisfy the normalization condition

$$
\begin{align*}
  1 =& \int_{\R^3} |\psi(r,\theta,\phi)|^2 r^2 \;\d r \;\d \Omega \\ 
  =& \int_0^\infty \underbrace{r^2 |R(r)|^2}_{|u(r)|^2} \;\d r \underbrace{\int_\Omega |Y_\ell^{m_\ell} (\theta,\phi)|^2 \;\d\Omega}_{=1} \\
  =& \int_0^\infty |u(r)|^2 \;\d r
\end{align*}
$$

Additionally, the wavefunctions require that $R(r)$ remains finite at the origin $r = 0$. Since $R(r) = u(r)/r$ this implies we must have $u(0) = 0$.

If $l = 0$, the centrifugal-barrier term vanishes. In this case, the system is an $s$-wave. Thus, for $s$-waves, the central-potential Schr√∂dinger equation reduces to a one-dimensional problem with a constant potential, with the additional condition that $u = 0$ at the origin (otherwise $R(r)$ would diverge). It is possible to reformulate the problem in terms of a new variable $x \in\R$ by means of a potential transformation

$$
  V(x) = \begin{cases}
    V(r) + \frac{\hbar^2 \ell(\ell + 1)}{2mr^2},\quad& x = r > 0 \\
    \infty,\quad& x < 0
  \end{cases}
$$

that is, for $x < 0$, we have an infinite potential barrier, so that the wavefunction vanishes in this region. Neglecting the zero at the origin, the ground-state wavefunction has no zeros, while the excited states get incremental zeroes. The number $n$ of non-trivial zeroes of the wave function is called the *radial quantum number*. Thus, a complete 3-dimensional wavefunction can be labeled by the tree quantum numbers $(n, \ell, m_\ell)$.

Let us consider the case in which

$$
  \lim_{r\to\infty} r^2 V(r) = 0
$$

For small $r$, the centrifugal term dominates, and the behaviour of the wave function is ruled by

$$
  u(r\to 0) \simeq r^a
$$

Taking the limit of $\eqref{equation-92}$ for $r\to 0$, we obtain

$$
  \ell (\ell + 1) - a(a - 1) = 0
$$

which is satisfied for $a = \ell + 1$ and for $a = -\ell$. The latter, however, is not a good solution because the wave function would not vanish at the origin. Thus, we have

$$
  u(r\to 0) \simeq r^{\ell + 1},\quad R(r\to 0) \simeq r^\ell
$$

### Quantum Kepler problem

Consider two particles of masses $m_a$ and $m_b$ moving in a plane and interacting through a central potential $V$ that only depends on their separation. Their total Hamiltonian is

$$
\begin{align*}
  \hat{H} =& \frac{\unitvec{p}_a^2}{2m_a} + \frac{\unitvec{p}_b^2}{2m_b} + V(|\mathbf{r}_a - \mathbf{r}_b|)
  =& -\frac{\hbar^2}{2m_a} \nabla_a^2 - \frac{\hbar^2}{2m_b} \nabla_b^2 + V(\hat{r})
\end{align*}
$$

The centre of mass $\mathbf{R}$ and relative position $\mathbf{r}$ are given by

$$
\begin{equation*}
\begin{split}
  \unitvec{R} = \frac{m_a \unitvec{r}_a + m_b \unitvec{r}_b}{M} \\
  \mathbf{r} = \mathbf{r}_a - \mathbf{r}_b
\end{split}
\tag{\label{equation-85}}
\end{equation*}
$$

where $M = m_a + m_b$ is the total mass. In terms of $\mathbf{R}$ and $\mathbf{r}$ we can express the particle positions as

$$
\begin{align*}
  \mathbf{r}_a =& \mathbf{R} + \frac{m_b}{M} \mathbf{r} \\
  \mathbf{r}_b =& \mathbf{R} - \frac{m_a}{M} \mathbf{r}
\end{align*}
$$

Applying the gradient chain rule to any scalar function $f(\mathbf{r}_a, \mathbf{r}_b) = \tilde{f}(\mathbf{R}, \mathbf{r})$, we get

$$
\begin{align*}
  \nabla_a f =& \frac{\partial\mathbf{R}}{\partial\mathbf{r}_a}^\top \nabla_R f + \frac{\partial\mathbf{r}}{\partial\mathbf{r}_a}^\top \nabla_r f \\
  \nabla_b f =& \frac{\partial\mathbf{R}}{\partial\mathbf{r}_b}^\top \nabla_R f + \frac{\partial\mathbf{r}}{\partial\mathbf{r}_b}^\top \nabla_r f
\end{align*}
$$

because the coordinate transforms $\eqref{equation-85}$ are linear, the Jacobians are

$$
\begin{aligned}
  \frac{\partial\mathbf{R}}{\partial\mathbf{r}_a} =& \frac{m_a}{M} \mathbf{I} \\
  \frac{\partial\mathbf{r}}{\partial\mathbf{r}_a} =& \mathbf{I}
\end{aligned}
\quad
\begin{aligned}
  \frac{\partial\mathbf{R}}{\partial\mathbf{r}_b} =& \frac{m_b}{M} \mathbf{I} \\
  \frac{\partial\mathbf{r}}{\partial\mathbf{r}_b} =& -\mathbf{I}
\end{aligned}
$$

where $\mathbf{I}$ is the identity matrix. Thus,

$$
\begin{align*}
  \nabla_a =& \frac{m_a}{M} \nabla_R + \nabla_r \\
  \nabla_b =& \frac{m_b}{M} \nabla_R - \nabla_r
\end{align*}
$$

Taking the Laplacians we obtain

$$
\begin{align*}
  \nabla_a^2 =& \left(\frac{m_a}{M}\right)^2 \nabla_R^2 + \nabla_r^2 + 2\frac{m_a}{M} \nabla_R \cdot \nabla_r \\
  \nabla_b^2 =& \left(\frac{m_b}{M}\right)^2 \nabla_R^2 + \nabla_r^2 - 2\frac{m_b}{M} \nabla_R \cdot \nabla_r
\end{align*}
$$

Inserting this into the kinetic energy operator

$$
\begin{align*}
  \hat{T} =& -\frac{\hbar^2}{2m_a} \nabla_a^2 - \frac{\hbar^2}{2m_b} \nabla_b^2 \\
  =& -\frac{\hbar^2}{2} \left(\frac{1}{m_a}\left[\left(\frac{m_a}{M}\right)^2 \nabla_R^2 + \nabla_r^2 + 2\frac{m_a}{M} \nabla_R \cdot \nabla_r \right] \right. \\
  &+ \left. \frac{1}{m_b}\left[\left(\frac{m_b}{M}\right)^2 \nabla_R^2 + \nabla_r^2 - 2\frac{m_b}{M} \nabla_R \cdot \nabla_r \right] \right) \\
  =& -\frac{\hbar^2}{2M} \nabla_R^2 - \frac{\hbar^2}{2m} \nabla_r^2 \\
  =& \frac{\unitvec{P}^2}{2M} + \frac{\unitvec{p}^2}{2m}
\end{align*}
$$

where $\unitvec{P} = \unitvec{p}_a + \unitvec{p}_b$ and

$$
  \unitvec{p} = \frac{m_b \unitvec{p}_a - m_a \unitvec{p}_b}{M}
$$

The Hamiltonian can thus be written

$$
\begin{equation*}
  \hat{H} = \frac{\unitvec{P}^2}{2M} + \frac{\unitvec{p}^2}{2m} + V(r)
\tag{\label{equation-86}}
\end{equation*}
$$

The operator pairs $\unitvec{P}, \unitvec{R}$ and $\unitvec{p}, \unitvec{r}$ are conjugate. The commutation relation of the first pair is

$$
\begin{align*}
  [\hat{R}_j, \hat{P}_k] =& \left[\frac{m_a}{M} \hat{r}_j^a + \frac{m_b}{M} \hat{r}_j^b, \hat{p}_k^a + \hat{p}_k^b \right] \\
  =& \frac{m_a}{M} (\underbrace{[\hat{r}_j^a, \hat{p}_k^a]}_{i\hbar\delta_{jk}} + \underbrace{[\hat{r}_j^a, \hat{p}_k^b]}_{=0}) + \frac{m_b}{M} (\underbrace{[\hat{r}_j^b, \hat{p}_k^b]}_{i\hbar\delta_{jk}} + \underbrace{[\hat{r}_j^b, \hat{p}_k^a]}_{=0}) \\
  =& \left(\frac{m_a}{M} + \frac{m_b}{M} \right) i\hbar\delta_{jk} = i\hbar\delta_{jk}
\end{align*}
$$

For the second pair we have

$$
\begin{align*}
  [\hat{r}_j, \hat{p}_k] =& \left[\hat{r}_j^a - \hat{r}_j^b, \frac{m}{m_a} \hat{p}_k^a - \frac{m}{m_b} \hat{p}_k^b \right] \\
  =& \frac{m}{m_a} (\underbrace{[\hat{r}_j^a, \hat{p}_k^a]}_{=i\hbar\delta_{jk}} - \underbrace{[\hat{r}_j^a, \hat{p}_k^b]}_{=0}) + \frac{m}{m_b} (\underbrace{[\hat{r}_j^b, \hat{p}_k^b]}_{=i\hbar\delta_{jk}} - \underbrace{[\hat{r}_j^b, \hat{p}_k^a]}_{=0}) \\
  =& \left(\frac{m}{m_a} + \frac{m}{m_b}\right) i\hbar\delta_{jk} = i\hbar\delta_{jk}
\end{align*}
$$

Similarly we can show that the observables of the first pair commute with the observables of the second pair

$$
  [\hat{R}_j, \hat{p}_k] = [\hat{r}_j, \hat{P}_k] = [\hat{r}_j, \hat{R}_k] = [\hat{p}_j, \hat{P}_k] = 0
$$

Thus, the wavefunction can be separated as $\psi(\mathbf{r}_a, \mathbf{r}_b) = \Phi(\mathbf{R}) \phi(\mathbf{r})$. Decomposing the Hamiltonian $\eqref{equation-86}$ into a non-interacting term $\hat{H}_0$ and an interacting term $\hat{H}_\text{I}$ with

$$
\begin{align*}
  \hat{H}_0 =& \frac{\unitvec{P}}{2M} \\
  \hat{H}_\text{I} =& -\frac{\unitvec{p}}{2m} + V(r) \tag{\label{equation-166}}
\end{align*}
$$

the time-independent Schr√∂dinger equation becomes

$$
\begin{align*}
  \hat{H}\psi(\mathbf{r}_a, \mathbf{r}_b) =& (\hat{H}_0 + \hat{H}_\text{I}) \Phi(\mathbf{R}) \phi(\mathbf{r}) \\
  =& (E_R + E_r) \Phi(\mathbf{R}) \phi(\mathbf{r}) \\
  =& E \psi(\mathbf{r}_a, \mathbf{r}_b)
\end{align*}
$$

with

$$
\begin{align*}
  \hat{H}_0 \Phi(\mathbf{R}) =& E_R \Phi(\mathbf{R}) \tag{\label{equation-87}} \\
  \hat{H}_\text{I} \phi(\mathbf{r}) =& E_r \phi(\mathbf{r}) \tag{\label{equation-88}}
\end{align*}
$$

Equation $\eqref{equation-87}$ is the eigenvalue equation for a free particle. In spherical coordinates, the interaction equation $\eqref{equation-88}$ allows a separable solution $\phi(\mathbf{r}) = R(r) Y_\ell^{m_\ell} (\theta, \phi)$, where $Y_\ell^{m_\ell}$ are the spherical harmonics. The radial equation takes the form 

$$
  \left[-\frac{\hbar^2}{2mr^2} \frac{\partial}{\partial r} \left(r^2 \frac{\partial}{\partial r} \right) + \frac{\hbar^2 \unitvec{L}^2}{2mr^2} + V(r) - E_r \right] R(r) = 0
$$

## Hydrogenic atoms

An atomic nucleus contains $Z$ protons and $N$ of neutrons. The number of nucleons $A = Z + N$ is called the *mass number*.

A hydrogenic atom is a two-body system formed by a nucleus of charge $+Ze$ and mass $m_A = Zm_p + Nm_n$, orbited by a single electron with charge $-e$ and mass $m_e$, bound by the mutual attraction of opposite charges. Placing the nucleus at the origin, the electrostatic potential seen by electron at a distance $r$ from the origin is given by Columb's law as

$$
\begin{equation*}
  V(r) = -\frac{Ze^2}{4\pi \epsilon_0} \frac{1}{r}
\tag{\label{equation-167}}
\end{equation*}
$$

As a two-body system in a central potential, the Hamiltonian separates into the kinetic energy of centre of mass and the relative motion of the electron-nucleus pair, as in $\eqref{equation-86}$. Introducing the centre-of-mass coordinate $\mathbf{R}$ and the relative coordinate $\mathbf{r} = \mathbf{r}_e - \mathbf{r}_A$, the translation motion behaves as a free particle of total mass $M = m_e + m_A$, while the relative motion is governed by a reduced mass

$$
  m = \frac{m_e m_A}{m_e + m_A}
$$

Since the nucleus is much heavier than the electron ($m_p \approx 1836 m_e$), the centre of mass lies very close to the nucleus. Thus, the Hamiltonian for the electron-nucleus interaction takes the form $\eqref{equation-166}$ and the stationary Schr√∂dinger equation reads

$$
  \left[-\frac{\hbar^2}{2m} \nabla_\mathbf{r} - \frac{Ze^2}{r} \right] \psi(\mathbf{r}) = E \psi(\mathbf{r})
$$

Since $V$ is a central potential, the spherical symmetry ensures that the wavefunctions $\psi$ are simultaneous eigenfunctions of $\unitvec{L}^2$ and $\hat{L}_z$. Using spherical coordinates, $\psi$ takes the separable form

$$
  \psi(r, \theta, \phi) = R(r) Y_\ell^{m_\ell} (\theta, \phi)
$$

where $Y_\ell^{m_\ell}$ are the spherical harmonics. Introducing $u(r) = rR(r)$, the radial equation $\eqref{equation-44}$ with $\eqref{equation-167}$ becomes

$$
\begin{equation*}
  -\frac{\hbar^2}{2m} \frac{\d^2 u}{dr^2} + \underbrace{\left[-\frac{Ze^2}{4\pi\epsilon_0} \frac{1}{r} + \frac{\hbar^2}{2m_e} \frac{\ell(\ell + 1)}{r^2} \right]}_{=V_\text{eff} (r)} u = Eu
\tag{\label{equation-168}}
\end{equation*}
$$

Note that the potential terms vanishes in the limit $r\to\infty$, i.e. $V_\text{eff} (r) \xrightarrow{r\to\infty} 0$, implying that there is an acceptable eigenfunction $u(r)$ for any positive energy. Thus, there is a continuous spectrum for $E > 0$, describing scattering between the electron and the nucleas. The eigenfunctions for $E < 0$ are called bound states giving a discrete energy spectrum. We now focus on the bound states.

Equation $\eqref{equation-168}$ can be made dimensionless by writing $\rho = \alpha r$, with $\alpha$ having dimension $\text{L}^{-1}$ and defining $\beta$ as

$$
\begin{equation*}
  \beta = \frac{mZe^2}{2\pi\epsilon_0 \hbar^2 \alpha}
\tag{\label{equation-172}}
\end{equation*}
$$

Inserting this into $\eqref{equation-168}$, and noting that $\d\rho = \alpha \d r$, we get

$$
  \left[\frac{\d^2}{\d\rho^2} + \frac{\beta}{\rho} - \frac{\ell(\ell + 1)}{\rho^2} \right] u(\rho) = -\frac{2mE}{\hbar^2 \alpha^2} u(\rho)
$$

To put $\eqref{equation-168}$ in a convenient form, we choose $\alpha$ such that

$$
  -\frac{2mE}{\hbar^2 \alpha^2} = \frac{1}{4} \implies \alpha = \sqrt{-\frac{-8mE}{\hbar^2}}
$$

Note that $\alpha$ is real and positive for bound states $E < 0$. Substituting this into $\eqref{equation-172}$, we obtain

$$
\begin{equation*}
  \beta = \frac{Ze^2}{4\pi\epsilon_0} \sqrt{-\frac{m}{2\hbar^2 E}}
\tag{\label{equation-171}}
\end{equation*}
$$

With these definitions, $\eqref{equation-168}$ becomes

$$
\begin{equation*}
  \left[\frac{\d^2}{\d\rho^2} + \frac{\beta}{\rho} - \frac{\ell(\ell + 1)}{\rho^2} - \frac{1}{4} \right]u(\rho) = 0
\tag{\label{equation-169}}
\end{equation*}
$$

We first examine the asymptotic behaviour of solutions. In the limit $\rho\to\infty$, the dominant form of $\eqref{equation-169}$ is

$$
  \frac{\d^2 u}{\d\rho^2} - = \frac{1}{4} u
$$

with general solution $u(\rho) = Ae^{-\rho/2} + Be^{\rho/2}$. Since $e^{\rho/2}$ blows up as $r\to\infty$, we must have $B = 0$. Thus, $u(\rho) \approx Ae^{-\rho/2}$ for large $\rho$. On the other hand, in the limit $\rho\to 0$ the centrifugal term dominates for $\ell\neq 0$

$$
  \frac{\d^2 u}{\d\rho^2} = \frac{\ell(\ell + 1)}{\rho^2} u
$$

with general solution $u(\rho) = C\rho^{\ell + 1} + D\rho^{-\ell}$. Since $\rho^{-\ell}$ diverges as $\rho\to 0$, we must have $D = 0$. Thus, $u(\rho) \approx C\rho^{\ell + 1}$ for small $\rho$. For $\ell = 0$, we cannot disregard the $\beta/\rho$ term. However, we note that $u(\rho) \propto \rho$ is an approximate solution of $\eqref{equation-169}$ with $\ell = 0$, for small $\rho$, when $\beta$ is not to large. Moreover, it satisfies the boundary condition $u(\rho) = 0$. Thus, we can take $u(\rho) \propto \rho^{\ell + 1}$ in both cases.

The solutions of $\eqref{equation-169}$ can be separated in terms of their asymptotic behaviuor as

$$
\begin{equation*}
  u(\rho) = \rho^{\ell + 1} e^{-\rho/2} v(\rho) 
\tag{\label{equation-50}}
\end{equation*}
$$

with derivatives

$$
  \frac{\d u}{\d\rho} = \rho^\ell e^{-\rho/2} \left[\left(\ell + 1 - \frac{\rho}{2}\right)v + \rho v' \right]
$$

and

$$
  \frac{\d^2 u}{\d\rho^2} = \rho^\ell e^{-\rho/2} \left(\left[\frac{\ell(\ell + 1)}{\rho} -(\ell + 1) + \frac{\rho}{4} \right]v + (2\ell + 2 - \rho) v' + \rho v'' \right)
$$

In terms $v(\rho)$, the radial equation becomes

$$
\begin{equation*}
  \rho v'' + (2\ell + 2 - \rho) v' + (\beta - \ell - 1)v = 0 
\tag{\label{equation-46}}
\end{equation*}
$$

which is the associated Laguerre differential equation. This can be solved using a power series method. We assume $v(\rho)$ can be expressed as a power series

$$
  v(\rho) = \sum_{j=0}^\infty c_j \rho^{j + k},\; c_0 \neq 0
$$

with derivatives

$$
\begin{align*}
  \frac{\d v}{\d\rho} =& \sum_{j=0}^\infty (j + k) c_j \rho^{j + k - 1} \\
  \frac{\d^2 v}{\d\rho^2} =& \sum_{j=0}^\infty (j + k)(j + k - 1) c_j \rho^{j + k 2 1}
\end{align*}
$$

Inserting these into $\eqref{equation-46}$ yields

$$
\begin{equation*}
\begin{split}
  0 =& \sum_{j=0}^\infty (j + k)(j + k - 1) c_j \rho^{j + k - 1} + 2(\ell + 1) \sum_{j=0}^\infty (j + k) c_j \rho^{j + k - 1} \\
  &- \sum_{j=0}^\infty (j + k) c_j \rho^{j + k} + (\beta - \ell - 1) \sum_{j=0}^\infty c_j \rho^{j + k}
\end{split}
\tag{\label{equation-170}}
\end{equation*}
$$

The indicial equation is obtained by setting the lowest power of $\rho$, i.e. $\rho^{k-1}$ to zero

$$
\begin{align*}
  k(k - 1) c_0 + (2\ell + 2)k c_0 =& 0 \\
  k(k - 1) + (2\ell + 2)k =& 0 
\end{align*}
$$

Since $k$ cannot be negative (for which the wave function diverges at $\rho = 0$) we must have $k = 0$. Consequently, $\eqref{equation-170}$ becomes

$$
\begin{align*}
  0 =& \sum_{j=0}^\infty j(j + 1) c_j \rho^j + 2(\ell + 1) \sum_{j=0}^\infty (j + 1) c_{j+1} \rho^j \\
  &- \sum_{j=0}^\infty j c_j \rho^j + (\beta - \ell - 1) \sum_{j=0}^\infty c_j \rho^j
\end{align*}
$$

Equating the coefficients of like powers give

$$
  j(j + 1)c_{j+1} + 2(\ell + 1) (j + 1) c_{j + 1} - 2j c_j + (\beta - \ell - 1) c_j = 0
$$

resulting in the recursive relation

$$
\begin{equation*}
  c_{j+1} = \frac{j + \ell + 1 - \beta}{(j + 1)(j + 2\ell + 2)} c_j 
\tag{\label{equation-52}}
\end{equation*}
$$

If the power series $v(\rho)$ is infinite, then for large $j$ the ratio of successive terms becomes

$$
  \lim_{j\to\infty} \frac{c_{i+1}}{c_i} \rho = \frac{\rho}{j}
$$

which behaves like $e^\rho$. The contribution to the complete radial wave function from the tail part of the infinite series for $v(\rho)$ behaves as

$$
  u(\rho) \sim \rho^{\ell + 1} e^{-\rho/2} e^\rho = e^{\ell + 1} e^{\rho/2}
$$

which diverges for $\rho\to\infty$. To find normalizable solutions, we require that the power series must terminate for some integer $j = N \geq 0$, i.e. $c_N = 0$. From $\eqref{equation-52}$ this can be achieved by choosing $\beta$ such that

$$
\begin{equation*}
  \beta = N + \ell + 1 =: n \in \N_+
\tag{\label{equation-53}}
\end{equation*}
$$

defining $n$ as the *principal quantum number*. Substituting this into $\eqref{equation-171}$ and solving for $E$ gives the energy eigenvalues via the Bohr formula

$$
\begin{equation*}
  E_n = \underbrace{\frac{m}{2\hbar^2} \left(\frac{Ze^2}{4\pi\epsilon_0}\right)^2}_{E_1} \frac{1}{n^2} = \frac{E_1}{n^2}
\tag{label{equation-175}}
\end{equation*}
$$

The ground state $E_1$ defines the binding energy of the atom, which is the amount of energy needed to ionize a hydrogenic atom in its ground state. 

With $\beta = n$, we find from $\eqref{equation-172}$ that

$$
  \alpha = \left(\frac{Zme^2}{2\pi\epsilon_0 \hbar^2} \right) \frac{1}{n}
$$

By introducing the Bohr radius

$$
  a_0 = \frac{4\pi\epsilon_0 \hbar^2}{\mu e^2}
$$

we can express $\alpha$ as

$$
\begin{equation*}
  \alpha = \frac{2Z}{na_0}
\tag{\label{equation-48}}
\end{equation*}
$$

For an electron in a hydrogen atom with $Z = 1$ and $m = m_e$, the Bohr radius is

$$
  a := \frac{4\pi\epsilon_0 \hbar^2}{m_e e^2} = 5.29 \times 10^{-11} \text{m}
$$

For an arbitrary principal quantum number $n$, the possible values $\ell$ consistent with $\eqref{equation-53}$ are $\ell = 0, 1,\dots,n-1$, and for each $\ell$, there are $2\ell + 1$ possible values of $m_\ell$. The total degeneracy of the energy level $E_n$ is

$$
  d(n) = \sum_{\ell = 0}^{n-1} (2\ell + 1) = n^2
$$

This degeneracy arises because the energy depends only on $n$, and is independent of $\ell$ and $m_\ell$. The high degeneracy of hydrogenic atoms can be understood from hidden symmetries of the Coulomb potential in spaces of dimension higher than $3$, which allows orbitals of a given $n$ to rotate between between different $\ell$-subshells without changing the energy.

The $\ell$-degeneracy is unique to hydrogenic atoms; in multi-electron atoms, electron-electron interactions break this degeneracy, making the energy depend on both $n$ and $\ell$. Relativistic effecs, such as spin-orbit coupling, also lift the $\ell$-degeneracy even for hydrogenic atoms.

### Wavefunctions

Using $\eqref{equation-51}$ and $\eqref{equation-50}$ we get the radial solutions

$$
\begin{equation*}
  R_{n\ell} (r) = \frac{1}{\rho} \rho^{\ell + 1} e^{-\rho/2} v(\rho) 
\tag{\label{equation-54}}
\end{equation*}
$$

Equation $\eqref{equation-46}$ can be recognized as the standard associated Laguerre differential equation

$$
  \rho \frac{\d^2 L_q^p (\rho)}{\d\rho^2} + (p + 1 - \rho) \frac{\d L_q^p (\rho)} + (q - p) L_q^p (\rho) = 0
$$

with parameters
- $p = 2\ell + 1$
- $q - p = n - \ell - 1 \iff q = n + 1$

Thus, $v(\rho)$ are the associated Laguerre polynomials 

$$
  v(\rho) = L_{n + \ell}^{2\ell + 1} (\rho)
$$

where

$$
\begin{align*}
  L_q^p (x) :=& (-1)^p \left(\frac{\d}{\d x} \right)^p L_{p+q} (x) \\
  L_q (x) :=& \frac{e^x}{q!} \left(\frac{\d}{\d x}\right)^q (e^{-x} x^q)
\end{align*}
$$

is the $q$th Laguerre polynomial. Using $\eqref{equation-48}$ to express

$$
  \rho = \frac{2Zr}{a_0 n}
$$

the normalized radial eigenfunctions become

$$
\begin{equation*}
  R_{n\ell} (r) = \sqrt{\left(\frac{2Z}{n a_0}\right)^3 \frac{(n - \ell - 1)!}{2n[(n + \ell)!]^3}} e^{-r/n a_0} \left(\frac{2r}{na_0}\right)^\ell L_{n + \ell}^{2\ell + 1} \left(\frac{2r}{na_0}\right)
\tag{\label{equation-174}}
$$

The complete wavefunctions $\psi_{n \ell m_\ell}(r,\theta,\phi) = R_{n\ell} (r) Y_\ell^{m_\ell} (\theta, \phi)$, called orbitals, are mutually orthonormal, i.e.

$$
  \int_{\R^3} \psi_{n\ell m_\ell}^* \psi_{n' \ell' m'_\ell} r^2 \;\d r \; \d\Omega = \delta_{nn'} \delta_{\ell\ell'} \delta_{m_\ell m_\ell'}
$$

The probability of finding an electron in the state $\psi_{n\ell m_\ell}$ within in a volume element $\d\tau = r^2 \sin(\theta) \d r \d\theta \d\phi$ at positions $(r,\theta,\phi)$ is $|\psi_{n\ell m_\ell} (r,\theta,\phi)|^2 \;\d\tau$. To obtain the probability of finding an electron at a distance between $r$ and $\d r$ from the nuclues, we integrate over the spherical shell bounded by these radii:

$$
\begin{align*}
  \Pr(r)\;\d r =& \int_{\Omega} |\psi_{n\ell m_\ell}|^2 \;\d\Omega \d r \\
  =& \int_0^\pi \int_0^{2\pi} R_{n\ell}^2 |Y_\ell^{m_\ell}|^2 r^2 \sin(\theta) \;\d r \d\theta \d\phi
\end{align*}
$$

Since the spherical harmonics are normalized in the sense that

$$
  \int_0^\pi \int_0^{2\pi} R_{n\ell}^2 |Y_\ell^{m_\ell}^2 \sin(\theta) \;\d\theta \d\phi = 1
$$

this simplifies to

$$
  \Pr(r) \;\d r = R_{n\ell}^2 r^2 \;\d r
$$

The quantity $\Pr(r) = R_{n\ell}^2 (r) r^2$ is the radial probability distribution, which gives the likelihood of finding the electron at a distance $r$ which is the radial distribution function.

| $n$ | $\ell$ | $R_{n\ell} (r)$ |
| --- | --- | --- |
| $1$ | $0$ | $R_{10} = 2a^{-3/2} \exp(-r/a)$ |
| $2$ | $0$ | $R_{20} = \frac{1}{\sqrt{2}}a^{-3/2} \left(1 - \frac{1}{2}\frac{r}{a} \right) \exp(-r/2a)$ |
| $2$ | $1$ | $R_{21} = \frac{1}{2\sqrt{6}}a^{-3/2} \left(\frac{r}{a} \right) \exp(-r/2a)$ |
| $3$ | $0$ | $R_{30} = \frac{2}{3\sqrt{3}}a^{-3/2} \left[1 - \frac{2}{3}\frac{r}{a} + \frac{2}{27}\left(\frac{r}{a}\right)^2 \right] \exp(-r/3a)$ |
| $3$ | $1$ | $R_{31} = \frac{8}{27\sqrt{6}}a^{-3/2} \left(1 - \frac{1}{6}\frac{r}{a} \right) \left(\frac{r}{a}\right) \exp(-r/3a)$ |
| $3$ | $2$ | $R_{32} = \frac{4}{81\sqrt{30}}a^{-3/2} \left(\frac{r}{a}\right)^2 \exp(-r/3a)$ |
| $4$ | $0$ | $R_{40} = \frac{1}{4}a^{-3/2} \left[1 - \frac{4}{3}\frac{r}{a} + \frac{1}{8}\left(\frac{r}{a}\right)^2 - \frac{1}{192}\left(\frac{r}{a}\right)^3\right] \exp(-r/4a)$ |
| $4$ | $1$ | $R_{41} = \frac{5}{16\sqrt{15}}a^{-3/2} \left[1 - \frac{1}{4}\frac{r}{a} + \frac{1}{80}\left(\frac{r}{a}\right)^2\right]\left(\frac{r}{a}\right) \exp(-r/4a)$ |
| $4$ | $2$ | $R_{41} = \frac{1}{64\sqrt{5}}a^{-3/2} \left(1 - \frac{1}{12}\frac{r}{a}\right)\left(\frac{r}{a}\right)^2 \exp(-r/4a)$ |
| $4$ | $3$ | $R_{41} = \frac{1}{768\sqrt{35}}a^{-3/2} \left(\frac{r}{a}\right)^3 \exp(-r/4a)$ |

### Atomic orbitals

Atomic orbitals are one-electron wavefunction that describe the spatial distribution and energy of an electron in an atom. An orbital is characterized by the quantum numbers $n$, $\ell$ and $m_\ell$
- the principal quantum number $n$ specifies the electron shell and the main energy level of the electron
- the orbital angular quantum number $\ell$ specifies the subshell within a given shell with $\ell \in \set{0,\dots,n-1}$
- the magnetic quantum number $m_\ell$ spesifies the orientation of the orbital in space with $m_\ell \in \set{-\ell,\dots,\ell}$

Historically, orbitals are classified according to their value of $\ell$:
- $\ell = 0$: $s$-orbital (sharp)
- $\ell = 1$: $p$-orbital (principal)
- $\ell = 2$: $d$-orbital (diffuse)
- $\ell = 3$: $f$-orbital (fundamental)
- For $\ell \geq 4$, the orbitals are labeled alphabetically: $g, h, \dots$

| $n$ | Shell label | Subshells | Typical orbitals included |
| --- | --- | --- | --- |
| $1$ | K | $\ell = 0$ | $1s$ |
| $2$ | L | $\ell = 0, 1$ | $2s, 2p$ |
| $3$ | M | $\ell = 0, 1, 2$ | $3s, 3p, 3d$ |
| $4$ | N | $\ell = 0, 1, 2, 3$ | $4s, 4p, 4d, 4f$ |
| $5$ | O | $\ell = 0, 1, 2, 3, 4$ | $5s, 5p, 5d, 5f, 5g$ |
| $6$ | P | $\ell = 0, 1, 2, 3, 4, 5$ | $6s, 6p, 6d, 6f, 6g, 6h$ |
| $7$ | Q | $\ell = 0, 1, 2, 3, 4, 5, 6$ | $7s, 7p, 7d, 7f, 7g, 7h, 7i$ |

#### $s$-orbitals

The angular dependence of an orbital is determined by the spherical harmonic $Y_\ell^{m_\ell}$. In particular, $Y_0^0$ is a constant independent of angle, implying that all $s$-orbitals are spherically symmetric. Unlike orbitals with $\ell > 0$, $s$-orbitals have a finite probability density at the nucleus for $r = 0$. This follows from the absence of orbital momentum: when $\ell = 0$, the centrifugal barrier term in the radial Schr√∂dinger equation $\eqref{equation-}$ vanishes, allowing the wavefunction to have non-zero amplitude at the origin.

Classically, an electron with zero angular momentum would spiral into the nucleus under Coulomb attraction. In quantum mechanics, however, the electron cannot localize arbitrarily clse to the nucleus due to the Heisenberg uncertainty principle. To minimize its total energy $E = \braket{T} + \braket{T}$, the $s$-electron wavefunction must strike a balance between two competing effects:
- A wavefunction highly localized near the nucleus lowers the potential energy $\braket{V}$ because $\eqref{equation-167}$ is most negative near $r = 0$, but the sharp curvature of such a wavefunction implies a large kinetic energy $\braket{T}\propto \int |\nabla\psi_{n\ell m_\ell}|^2 \d^3 r$
- Conversely, a delocalized wavefunction with gentle curvature has a small kinetic energy, but spends more time far from the nucleus, resulting in a less negative potential energy.

The actual $s$-orbital represents the quantum-mechanical compromise between these opposing tendencies: it minimizes the total energy subject to the constraints of normalization and the uncertainty principle.

#### $p$-orbitals

For a given principal quantum number $n$, the three $p$-orbitals correspond to the orbital quantum number $\ell = 1$ and the three possible magnetic quantum numbers $m_\ell \in \set{-1, 0, 1}$. The corresponding one-electron wavefunctions are

$$
\begin{align*}
  p_z :=& \psi_{n10}(r, \theta, \phi) = \sqrt{\frac{3}{4\pi}} R_{n1} (r) \cos(\theta) \\
  p_+ :=& \psi_{n11} = -\sqrt{\frac{3}{8\pi}} R_{n1} (r) \sin(\theta) e^{i\phi} \\
  p_- :=& \psi_{n1-1} = -\sqrt{\frac{3}{8\pi}} R_{n1} (r) \sin(\theta) e^{-i\phi}
\end{align*}
$$

which span the complete space of all one-electron states with $\ell = 1$. The $p_z$-orbital with $m_\ell = 0$ is real and has the zero component of angular momentum around the $z$-axis. The $p_+$- and $p_-$-orbitals are complex conjugate pairs, corresponding to eigenstates of $\hat{L}$ with eigenvalues $\pm\hbar$, respectively. Their angular probability densities are concentrated primarily in the $xy$-plane, where $|\sin(\theta)|$ is maximal.

It is convenient to work with the real linear combinations of $p_+$ and $p_-$, which are oriented along the $x$- and $y$-axis

$$
\begin{align*}
  p_x = \frac{1}{\sqrt{2}} (p_- - p_+) = \sqrt{\frac{3}{4\pi}} R_{n1} \sin(\theta) \cos(\phi) \\
  p_y = \frac{i}{\sqrt{2}} (p_- + p_+) = \sqrt{\frac{3}{4\pi}} R_{n1} \sin(\theta) \sin(\phi)
\end{align*}
$$

The set $\set{p_x, p_y, p_z}$ forms a real orthonormal basis for the $\ell = 1$ subspace of one-electron states, and are related to the complex basis $\set{p_+, p_-, p_z}$ by a unitary transformation.

The complex orbitals are most natural in atomic and diatomic systems, where the $z$-axis provides a unique quantization direction, but the $x$- and $y$-axes are not distinguished. They are eigenstates of $\hat{L}_z$ and thus diagonalize $\mathbf{L}$. The real form are more appropriate when Cartesian symmetry is physically meaningful, such as in polyatomic (non-linear) molecules, crystals, or when describing directional bonding (e.g. in hybridization).

Geometrically, all three real orbitals, $p_x$, $p_y$ and $p_z$, share the same double-lobed shape, with opposite phases on either side of a nodal plane:
- $p_x$: lobes along $x$-axis, nodal plane $yz$
- $p_y$: lobes along $y$-axis, nodal plane $xz$
- $p_z$: lobes along $z$-axis, nodal plane $xy$

Each of these shapes reflects the single angular node ($\ell = 1$) characteristic of all $p$-orbitals.

#### $d$-orbitals

For principal quantum numbers $n\geq 3$, there exist five $d$-orbitals corresponding to the angular momentum quantum number $\ell = 2$ and the five magnetic quantum numbers $m_\ell \in\set{-2, -1, 0, 1, 2}$. Except for $m_\ell = 0$, these orbitals are complex, and represent states of definite angular momentum projection about the $z$-axis. These complex orbitals, $d_{\pm 1}$ and $d_{\pm 2}$, have cylindrical symmetry around the $z$-axis, but are not oriented along fixed Cartesian directions. It is common to form real linear combinations of these complex orbitals, adapted to Cartesian symmetry

$$
\begin{align*}
  d_{z^2} =& d_0 := \psi_{n2 0} = \sqrt{\frac{5}{16\pi}} R_{n2} (r) [3\cos^2 (\theta) - 1] \\
  &\hphantom{d_0 := \psi_{n2 0}} = \sqrt{\frac{5}{16\pi}} R_{n2} (r) \frac{3z^2 -r^2}{r^2} \\
  d_{x^2 - y^2} =& \frac{1}{\sqrt{2}} (d_{+2} + d_{-2}) = \sqrt{\frac{15}{16\pi}} R_{n2} (r) \frac{x^2 -y^2}{r^2} \\
  d_{xy} =& \frac{1}{i\sqrt{2}} (d_{+2} - d_{-2}) = \sqrt{\frac{15}{16\pi}} R_{n2} (r) \frac{xy}{r^2} \\
  d_{yz} =& \frac{1}{i\sqrt{2}} (d_{+1} + d_{-1}) = -\sqrt{\frac{15}{16\pi}} R_{n2} (r) \frac{yz}{r^2} \\
  d_{zx} =& \frac{1}{\sqrt{2}} (d_{+1} - d_{-1}) = -\sqrt{\frac{15}{16\pi}} R_{n2} (r) \frac{zx}{r^2}
\end{align*}
$$

The real set $\set{d_{z^2}, d_{x^2 - y^2}, d_{xy}, d_{yx}, d_{zx}}$ diagonalizes $\unitvec{L}^2$ but not $\hat{L}_z$ and form an orthonormal basis for the $\ell = 2$ subspace of one-electron states.

| Orbital | Angular dependence | Nodal surfaces | Orientation |
| --- | --- | --- | --- |
| $d_{z^2}$ | $3\cos^2(\theta)$ | conical nodes | aligned along $z$-axis |
| $d_{x^2 - y^2}$ | $x^2 - y^2$ | planes $x = \pm y$ | lobes along $x$ and $y$ axes |
| $d_{xy}$ | $xy$ | planes $x = 0$, $y = 0$ | between $x$- and $y$-axes |
| $d_{yz}$ | $yz$ | planes $y = 0$, $z = 0$ | between $y$- and $z$-axes |
| $d_{zx}$ | $zx$ | planes $z = 0$, $x = 0$ | between $z$- and $x$-axes |

#### Orbital radius

The mean orbital radius provides a measure of the spatial extent of an electron's probability distribution. For an electron in state $\psi_{n\ell m_\ell}$, the orbital radius is defined as the expectation value of the radial coordinate

$$
\begin{align*}
  \braket{r}_{n\ell m_\ell} =& \int_0^\infty r|R_{n\ell} (r)|^2 r^2 \;\d r \\ 
  =& \frac{n^2 a_0}{Z} \left[1 + \frac{1}{2}\left(1 - \frac{\ell(\ell + 1)}{n^2} \right) \right]
\end{align*}
$$

This shows that, for a given principal quantum number $n$, the mean radius decreases with increasing orbital angular momentum $\ell$. Surprisingly, the mean radius of an $ns$-orbital is larger than that of an $np$-orbital of the same $n$. At first glance this seems to contradict the classical expectation that the centrifugal barrier associated with higher $\ell$ values should pus the electron farther from the nucleus. This is due to the existence of additional radial nodes in the $ns$-orbital. Each node corresponds to a region of zero probability density, which redistributes the radial probability outward and thereby increases the expectation value $\braket{r}$. In contrast, orbitals with larger $\ell$ values have fewer radial nodes for the same $n$, resulting in more compact radial distributions.

The expectation value of the inverse radius is

$$
\begin{align*}
  \Braket{\frac{1}{r}}_{n\ell m_\ell} =& \int_0^\infty \frac{1}{r} |R_{n\ell} (r)|^2 r^2 \;\d r \\
  =& \frac{Z}{a_0 n^2}
\end{align*}
$$

which characterizes the mean Coulombic potential energy, since $V(r) \propto -1/r$. The fact that that the expectation value of $1/r$ is independent of $\ell$ reflects the degeneracy of hydrogenic atoms, since all orbitals for a given principal quantum number $n$ share the same potential energy expectation value, regardless of their angular momentum.

### Hydrogen spectrum

For the hydrogen atom with $Z$, the energy levels $\eqref{equation-175}$ become

$$
  E_n = -\left(\frac{\mu e^4}{32\pi^2 \epsilon_0^2 \hbar^2} \right) \frac{1}{n^2}
$$

In terms of the Rydberg constant

$$
  R_\text{H} = \frac{\mu e^4}{8\epsilon_0^2 h^3 c}
$$

the energy levels can be expressed as

$$
  E_n = -\frac{hcR_\text{H}}{n^2}
$$

The spectrum of the hydrogen atom arises from transitions between its permitted states, and the difference in energy, $\Delta E$, between the states is discarded as a photon of energy $h\nu$ and wavenumber $k = \nu/c$. For the transition $n_2 \to n_1$, the wavenumber of the emitted radiation is

$$
\begin{equation*}
  k = \left(\frac{1}{n_1^2} - \frac{1}{n_2^2}\right) R_\text{H}
\tag{\label{equation-176}}
\end{equation*}
$$

For a given value of $n_1$, the set of transitions from $n_2 = n_1 + 1, n_1 + 2, \dots$ constitutes a series of spectral lines, which bear the names of their discoverers or principal investigators
- $n_1 = 1$: Lymann series (ultraviolet)
- $n_1 = 2$: Balmer series (visible)
- $n_1 = 3$: Paschen series (infrared)
- $n_1 = 4$: Brackett series (far infrared)
- $n_1 = 5$: Pfund series (far infrared)
- $n_1 = 6$: Humphreys series (far infrared)

Because each series corresponds to a specific value of $n_1$ but all possible integer values of $n_2 > n_1$, the limit of each series is the wavenumber obtained by setting $n_2 = \infty$ in $\eqref{equation-176}$, and is given by

$$
  k_\infty = \frac{R_\text{H}}{n_1^2}
$$

The energy when $n = \infty$ is zero and corresponds to the complete removal of the electron from the atom, or the ionized state of the atom. The ionization energy $I$ of the atom, the minimum energy required to ionize it from its $n = 1$ ground state, is the energy difference $E_\infty - E_1$. Hence

$$
  I = hc R_\text{H} = 2.180 \text{ aJ} = 1312 \text{ kJ mol^{-1}} = 13.60 \text{ eV}
$$

#### Selection rules

Not all transitions between electron states are allowed. The selection rules for electric dipole transitions are derived from symmetry considerations applied to the transition dipole moment. A transition is allowed if and only if the transition dipole moment is non-zero. Conversely, a transition is forbidden when this quantity vanishes. The transition dipole moment for a transition between initial state $\ket{i}$ and final state $\ket{f}$ is defined as the matrix element

$$
\begin{equation*}
  \boldsymbol{\mu}_\text{if} = \braket{i|\unitsym{\mu}|f}
\tag{\label{equation-177}}
\end{equation*}
$$

where $\unitsym{\mu} = -e\unitvec{r}$ is the electric dipole operator. Physically, $\unitsym{\mu}_\text{if}$ quantifies the coupling between the atomic system and the electromagnetic field during the transition. Transitions involving large charge displacements $\Delta\mathbf{r}$ with significant dipolar character yield large values of $|\boldsymbol{\mu}_\text{if}|$, resulting in strong radiative coupling and intense spectral lines.

Group theory provides a framework for determining when $\boldsymbol{\mu}_\text{if} \neq \mathbf{0}$. The fundamental principle is that the integrand in $\eqref{equation-177}$ given by $\psi_\text{i} (\mathbf{r}) \mathbf{r} \psi_\text{f} (\mathbf{r})$, is non-zero if and only if it transforms as the totally symmetric irreducible representation of the symmetry group of the Hamiltonian. For atomic systems, this symmetry group is the full rotation group $\mathrm{SO}(3)$, or equivalently its double cover $\mathrm{SU}(2)$ when including spin.

First we consider spatial inversion, under which the position operator transforms as $\unitvec{r} \mapsto -\unitvec{r}$. Under inversion, an atomic orbital with quantum number $\ell$ has parity $(-1)^\ell$, which follows from the transformation property of spherical harmonics

$$
  Y_\ell^{m_\ell} (\pi - \theta, \phi + \pi) = (-1)^\ell Y_\ell^{m_\ell} (\theta, \phi)
$$

Because the position operator $\mathbf{r}$ is odd under spatial inversion, it transforms with parity $(-1)$. Consequently, the combined parity of the integrand in $\eqref{equaton-177}$ is 

$$
  (-1)^{\ell_i} (-1) (-1)^{\ell_f} = (-1)^{\ell_i + \ell_f + 1}
$$

For the integral to be non-zero, the integrand must have even parity, requiring

$$
 (-1)^{\ell_i + \ell_f + 1} = 1 \iff \ell_\text{i} + \ell_\text{f} = \text{odd}
$$

This is equivalent to the condition that $\ell_i$ and $\ell_f$ have opposite parity. This parity condition leads to the Laporte selection rule: The only allowed electric-dipole transitions are those involving a change in parity.

Next, consider the rotational characteristics of the components of the integrand. The atomic orbitals $\psi_i (\mathbf{r})$ and $\psi_f (\mathbf{r})$ are eigenfunctions of the orbital angular momentum operator $\unitvec{L}^2$ and therefore transform according to the irreducible representations $\Gamma^{(\ell_i)}$ and $\Gamma^{(\ell_f)}$ of the full rotation group $\mathrm{SO}(3)$. The electric dipole moment operator $\unitsym{\mu}$ behaves like a translation and transform according to the irreducible representation $\Gamma^{(1)}$ of $\mathrm{SO}(3)$. The direct product of $\Gamma^{(\ell_i)}$ and $\Gamma^{(1)}$ therefore decomposes under the Clebsch-Gordan series as

$$
\begin{equation*}
  \Gamma^{(\ell_i)} \otimes\Gamma^{(1)} = \Gamma^{(\ell_i + 1)} \oplus \Gamma^{(\ell_i)} \oplus \Gamma^{(\ell_i - 1)}
\tag{\label{equation-178}}
\end{equation*}
$$

By Wigner-Eckart theorem and group theoretical orthogonality relations of irreducible representations, $\eqref{equation-177}$ is non-zero if and only if 

$$
  \Gamma^{(0)} \in \Gamma^{(\ell_i)} \otimes \Gamma^{(1)} \otimes \Gamma^{(\ell_f)}
$$

where $\Gamma^{(0)}$ is the totally symmetric irreducible representation correspondonding to a rotational scalar. This requirement ensures that the overall integrand of $\eqref{equation-177}$ transforms as a scalar under rotations, so that the spatial integral remains invariant. This condition is satisfied only if the representation $\Gamma^{(\ell_f)}$ appears in the decomposition $\eqref{equation-178}$, that is

$$
  \Gamma^{(\ell_f)} \in \set{\Gamma^{(\ell_i - 1)}, \Gamma^{(\ell_i)}, \Gamma^{(\ell_i + 1)}}
$$

Equivalently, the allowed transitions must satisfy $\ell_\text{f} \in \set{\ell_\text{i} - 1, \ell_\text{i}, \ell_\text{i} - 1}$. However, we have already ruled out transitions that do not change parity, so the only allowed transitions are those to the states with $\ell_\text{f} = \ell_\text{i} \pm 1$, or $\Delta\ell = \pm 1$.

The physical origin of this selection rule can be understood in terms of angular momentum. The intrinsic spin angular momentum of a photon is $s = 1$. To conserve total angular momentum, the orbital angular must therefore change by $\Delta\ell = \pm 1$, when a photon is absorbed or emitted. The sign of $\Delta\ell$ depends on whether the transition involves absorption or emission, which is determined by the orientation of the angular momentum of the photon relative to the angular momentum of the electron.

The argument can be extended naturally to derive the selection rules for the magnetic quantum number $m_\ell$. A photon has an intrinsic helicity $\sigma = \pm 1$, defined as the projection of its spin angular momentum onto its direction of propagation. These correspond respectively to left- and right-circularly polarized photons. Suppose the quantization axis ($z$-axis) is along the photon's line of propagation. Then $m_\ell$ represents the projection of the electron's orbital angular momentum onto this same axis. Conservation of angular momentum along the propagation direction requires that the total projection $m_\ell + \sigma$ remain constant during the transition. Thus, the absorption of a photon with helicity $\sigma = 1$ (left-circular polarization) decreases the magnetic quantum number by one unit, $\Delta m_\ell = -1$, while aborption of a photon with helicity $\sigma = -1$ (right-circular polarization) increaes it by one unit, $\Delta m_\ell = 1$. Emission processes obey the same relations with opposite signs. If the photon propagates along an arbitrary direction not aligned with the quantization axis, angular momentum can be transferred to the atom through a superposition of polarization components. In this caes, transitions with no change in $m_\ell$ are also allowed. Thus, the general magnetic quantum number selection rule is

$$
  \Delta m_\ell = 0, \pm 1
$$

The selection rule on $m_\ell$ can also be deduced algebraically. Suppose the radiation is plane-polarized with its electric field in the $z$-direction, then only the $z$-component of the dipole moment is relevant, and we can write $\mu_z = -er\cos(\theta)$. The $\phi$ integral in the transition moment is then proportional to

$$
  \int_0^{2\pi} e^{-im_{\ell_f} \phi} [-er\cos(\theta)] e^{im_{\ell_i} \phi} \;\d\phi \propto \int_0^{2\pi} e^{((m_{\ell_i} - m_{\ell_f}))} \;\d\phi
$$

The intergal over $\phi$ is zero unless $m_{\ell_i} = m_{\ell_f}$. Thus, for $z$-polarized radiation $\Delta m_\ell = 0$. The selection rules $\Delta m_\ell = \pm 1$ arise similarly for radiation polarized in the $xy$-plane.

Electric dipole transitions are not the only types of transitions that may occur. The perturbation arising form the effecto of the magnetic component of the electromagnetic field can induce magnetic dipole transitions. Such transitions have intensities that are proportional to the square matrix elements like $\braket{i|\hat{L}_z |f}$ and are typically about $10^5$ times weaker than allowed electric dipole transitions. However, because the obey different selection rules, they may give rise to spectral lines where the electric dipole transition is forbidden.

Another type of transition is an electric quadrupole transition in which the spatial variation of the elecrtic field interacts with the electric quadrupole moment operator. Such transitions have intensities that are proportional to the squares of matrix elements like $\braket{i|\hat{x}\hat{y}|f}$. These transitions are about $10^8$ times weaker than electric dipole transitions. Their selection rule is $\Delta = 0, \pm 2$. The large change in angular momentum that accompanies the transitions arises from the fact that the quadrupole transition imparts an orbital angular momentum to the photon in addition to its intrinsic spin. The weakness of magnetic dipole and electric quadrupole transitions stems from the fact that both depend on the variation of the electromagnetic wave over the extent of the atom. As atomic diameters are much smaller than the typical wavelength of radiation, this variation is typically very small and the intensity is correspondingly weak.

In some systems, a transition can result in the generation of two photons by an electric dipole mechanism more efficiently than a single photon is generated by a magnetic dipole transition. An example of this multiple-quantum dipole transition is provided by the excited $1s^1 2s^1$ singlet state of helium: the two-photon process governs the lifetime of the state because the magnetic dipole transition probability is so low.

### Spin-orbit interaction

## Coulumb scattering

# Relativistic particles

## The Klein-Gordon equation

The Klein-Gordon equation is derived by quantizing the relativistic energy-momentum relation for a particle with energy $E$, momentum $\mathbf{p}$ and rest mass $m$

$$
  E^2 = \mathbf{p}^2 c^2 + m^2 c^4
$$

