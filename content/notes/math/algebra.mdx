---
title: 'Algebra'
subject: 'Mathematics'
showToc: true
---

# Category theory

<LatexFig width={50} src='/fig/category.svg' alt=''
  caption='Category diagram'
>
```latex
\documentclass[tikz]{standalone}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{cd}

\begin{document}

\begin{tikzcd}[row sep=large, column sep=large, every label/.append style = {font = \scriptsize}]
  A \arrow[r, "f"] \arrow[dr, "f\circ g" swap] \arrow[in=120, out=150, loop, "\operatorname{id}_A"] &
  B \arrow[d, "g"] \arrow[in=30, out=60, loop, "\operatorname{id}_B"] \\
  & C \arrow[in=300, out=330, loop, "\operatorname{id}_C"]
\end{tikzcd}

\end{document}
```
</LatexFig>

<MathBox title='Category' boxType='definition'>
A category $\mathcal{C}$ consists of
- a class $\mathrm{ob}(\mathcal{C})$ of *objects*
- a class $\hom(\mathcal{C})$ of *morphism*
- for each morphism $f\in\hom(\mathbb{C})$, two objects $A,B\in\mathrm{ob}(\mathbb{C})$ called the *source* and *target* of $f$, respectively
- for each $A,B,C\in\mathrm{ob}(\mathcal{C})$ a function $\circ: \hom_\mathcal{C}(B,C)\times\hom_\mathcal{C}(A,B)\to\hom_\mathcal{C}(A,C)$ defined by $(f,g)\mapsto g\circ f$ called *composition*
- for each $A\in\mathrm{ob}(\mathcal{C})$ an element $\operatorname{id}_A\in \hom_\mathcal{C}(A,A)$ called the *identity* on $A$

satisfying
- $(h\circ g)\circ f = h \circ (g \circ f)$ for each $f\in\mathcal{C}(A,B)$, $g\in\mathcal{C}(B,C)$ and $h\in\mathcal{C}(C,D)$ **(associativity)**
- $f\circ \operatorname{id}_A = f = \operatorname{id}_B \circ f$ for each $f\in\mathcal{A}$ **(identity law)**
</MathBox>

The following notation is commonly used
- $A\in\mathcal{C}$ instead of $A\in\mathrm{ob}(\mathcal{C})$
- $\mathcal{C}(A,B)$ instead of $\hom_\mathcal{C}(A,B)$
- $f:A\to B$ or $A \xrightarrow{f} B$ instead of $f\in\hom_\mathcal{C}(A,B)$
- $gf$ instead of $g\circ f$
- $1_A$ instead of $\operatorname{id}_A$

A category $\mathcal{C}$ in which both $\mathrm{ob}(\mathbf{C})$ and $\hom(\mathcal{C})$ are sets is called a *small category*. A category in which each class of morphisms $\hom_\mathcal{C}(A,B)$ is a set is called *locally small*. 

Common categories
- $\mathbf{Set}$: sets and maps
- $\mathbf{Top}$: topological spaces and continuous maps
- $\mathbf{Man}$: topological manifolds and continuous maps
- $\mathbf{Diff}$: smooth manifolds and smooth maps
- $\mathbf{Vec}$: vector spaces and linear maps
- $\mathbf{Bilin}$: bilinear maps and tensor products
- $\mathbf{Grp}$: groups and group homomorphisms
- $\mathbf{Ab}$: abelian groups and group homomorphisms
- $\mathbf{Rng}$: rings and ring homomorphisms
- $\mathbf{CRng}$: commutative rings and ring homomorphisms


<MathBox title='Isomorphism' boxType='definition'>
A map $f:A\to B$ in a category $\mathcal{C}$ is an isomorphism if there exists a map $g: B\to A$ in $\mathcal{C}$ such that $gf = 1_A$ and $fg = 1_B$. In this case, we say that $f$ is *invertible* and that $g$ is the *inverse* of $f$, denoted $g = f^{-1}$. If there is an isomorphism from $A$ to $B$, we say that $A$ and $B$ are isomorphic, denoted $A\cong B$.
</MathBox>

<LatexFig width={50} src='/fig/isomorphism.svg' alt=''
  caption='Isomorphism diagram'
>
```latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{cd}

\begin{document}

\begin{tikzcd}[row sep=normal, column sep=normal, every label/.append style = {font = \scriptsize}]
  A \arrow[loop left, "1_A"] \arrow[r, "f", yshift=0.5ex] & 
  B \arrow[loop right, "1_B"] \arrow[l, "f^{-1}", yshift=-0.5ex]
\end{tikzcd}

\end{document}
```
</LatexFig>

## Functor
<MathBox title='Functor' boxType='definition'>
Let $\mathcal{A}$ and $\mathcal{B}$ be categories. A *covariant functor* $F:\mathcal{A}\to\mathcal{B}$ consists of
1. a map $\mathrm{ob}(\mathcal{A})\to\mathrm{ob}(\mathcal{B})$ defined by $A\mapsto F(A)$
2. for each $A, A'\in\mathcal{A}$ a map $\hom_\mathcal{A}(A,A')\to\hom_\mathcal{B}(F(A), F(A'))$ defined by $f\mapsto F(f)$

satisfying
- $F(f' \circ f) = F(f')\circ F(f)$ whenever $A\xrightarrow{f} A' \xrightarrow{f'} A''$ in $\mathcal{A}$
- $F(1_A) = 1_{F(A)}$ whenever $A\in\mathcal{A}$

A functor is called *contravariant* if for each $A, A'\in\mathcal{A}$ a there is a map $\hom_\mathcal{A}(A,A')\to\hom_\mathcal{B}(F(A'), F(A))$ by $f\mapsto F(f)$ such that
- $F(f' \circ f) = F(f)\circ F(f')$ whenever $A\xrightarrow{f} A' \xrightarrow{f'} A''$ in $\mathcal{A}$
</MathBox>

If $\mathcal{C}$ is a cateogory whose objects are sets with some additional structure and whose morphisms are maps preserving that structure, the *forgetful functor* $F:C\to\mathbf{Set}$ assigns to each object its underlying set, and to each morphism the same map thought of as a map between sets. 

<MathBox title='' boxType='definition'>
Let $\mathcal{A}$ be a locally small category and $A\in\mathcal{A}$. The functor

$$
  H^A = \mathcal{A}(A,\cdot): \mathcal{A}\to\mathbf{Set}
$$

is defined as follows
- $H^A(B) = \mathcal{A}(A,B)$ for $B\in\mathcal{B}$
- for $g\in\mathcal{A}(B, B')$ define
$$
  H^A(g) = \mathcal{A}(A,g): \mathcal{A}(A,B)\to\mathcal{A,B'}
$$

by

$$
  p\mapsto g\circ p
$$

for all $p:A\to B$.
</MathBox>

<MathBox title='Representable' boxType='definition'>
Let $\mathcal{A}$ be a locally small category. A functor $X:\mathcal{A}\to\mathbf{Set}$ is *representable* if $X\cong H^A$ for some $A\in\mathcal{A}$. A *representation* of $X$ is a choice of an object $A\in\mathcal{A}$ and an isomorphism between $H^A$ and $X$.
</MathBox>

<MathBox title='Natural transformation' boxType='definition'>
Let $F, G:\mathcal{A}\to\mathcal{B}$ be two functors. A *natural transformation* $\alpha:F\to G$ is a collection $\left((F(A) \xrightarrow{\alpha_A} G(A))\right)_{A\in\mathcal{A}}$ of maps in $\mathcal{B}$ such that for every map $f:A\to A'$ in $\mathcal{A}$, the following diagram commutes.

$$
\begin{CD}
  F(A) @>F(f)>> F(A') \\
  @V{\alpha_A}VV @VV{\alpha_{A'}}V \\
  G(A) @>>G(f)> G(A')
\end{CD}
$$

The maps $\alpha_A$ are called the components of $\alpha$.

<LatexFig width={25} src='/fig/natural_transformation.svg' alt=''
  caption='Natural transform diagram'
>
```latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{cd}

\begin{document}

\begin{tikzcd}[cramped, sep=normal, every label/.append style = {font = \scriptsize}]
  \mathcal{A} 
    \arrow[r, bend left=50, "F", ""{name=U, below}] 
    \arrow[r, bend right=50, "G" swap, ""{name=D}] &
  \mathcal{B} \arrow[Rightarrow, "\alpha", from=U, to=D]
\end{tikzcd}

\end{document}
```
</LatexFig>

If every component $\alpha_A$ is invertible in $\mathcal{B}$, then $\alpha$ is called a *natural isomorphism*, denoted $\alpha: F\cong G$. In this case, the inverses $\alpha_A^{-1}$ in $\mathcal{B}$ are the components of a natural isomorphism $\alpha^{-1}:B\to A$.
</MathBox>

## Universality
<MathBox title='Universal morphism' boxType='definition'>
Let $F:\mathcal{A}\to\mathcal{B}$ be a functor between categories $\mathcal{A}$ and $\mathcal{B}$ and suppose $B\in\mathcal{B}$ is an object in $\mathcal{B}$. A *universal morphism* from $B$ to $F$ is a pair $(A, u: B\to F(A))$ of an object $A\in\mathcal{A}$ and a morphism $u\in\mathcal{D}(B,F(B))$ satisfying the *universal property*:
- for any pair $(A', f)$ with $A'\in\mathcal{A}$ and $f\in\mathcal{B}(B,F(A'))$, there is a unique morphism $h:A\to A'$ in $\mathcal{A}$ such that $f = F(h) \circ u$ according to following diagram.

<LatexFig width={50} src='/fig/universal_property.svg' alt=''
  caption='Universal property diagram'
>
```latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{cd}

\begin{document}

\begin{tikzcd}[row sep=large, column sep=large, every label/.append style = {font = \scriptsize}]
  B \arrow[r, "u"] \arrow[dr, "f" swap] & 
  F(A) \arrow[d, "F(h)", dashed] & 
  A \arrow[d, "h", dashed] \\
  & F(A') & A'
\end{tikzcd}

\end{document}
```
</LatexFig>

Equivalently, a universal morphism from $F$ to $B$ is a unique pair $(A, u: F(A)\to B)$ of an object $A\in\mathcal{A}$ and a morphism $u\in\mathcal{B}(F(A),B)$ satisfying the universal property:
- for any pair $(A', f)$ with $A'\in\mathcal{A}$ and $f\in\mathcal{B}(F(A'), B)$ there is a unique morphism $h:A' \to A$ in $\mathbb{A}$ such that $f = u\circ F(h)$.
</MathBox>

# Algebraic structures

|   | Addition $+$ | Multiplication $\cdot$ | Special features |
|---|---|---|---|---|
| **Semigroup** |   | Associative  |   |
| **Monoid** |   | Associative | Unique identity: $1a = a1 = a$  |
| **Group** |   | Associative | Inverses: aa^{-1} = a^{-1}a = \boldsymbol{1} |
| **Ring** | Abelian group | Semigroup | Zero: $0 + a = a \implies a0 = 0$  |
| **Integral domain** | Abelian group |   | No zero divisors |
| **Field** | Abelian group | Abelian monoid | Inverses under $\cdot$ except for $0$ |

<MathBox title='Field' boxType='definition'>
A field $\mathbb{F}$ is a set containing $1 \neq 0$ equipped with the binary operations $+$ (addition) and $\cdot$ (multiplication) such that
- $(\mathbb{F}, +)$ is an abelian group
- $(\mathbb{F}\setminus\Set{0}, \cdot)$ is an abelian group
- Addition and multiplication are related by distributivity, i.e. for all $a,b,c\in\mathbb{F}$
    - $a(b + c) = ab + ac$
    - $(a + b)c = ac + bc$
</MathBox>

<MathBox title='Algebra' boxType='definition'>
An algebra $A$ over a field $\mathbb{F}$ is a nonempty set $A$, together with three operations
- $+:A\times A\to A$ **(addition)**
- $\cdot: A\times A\to A$ **(multiplication)**
- $\cdot: \mathbb{F}\times A\to A$ **(scalar multiplication)**

for which the following properties hold:
- $A$ is a vector space over $\mathbb{F}$ under addition and scalar multiplication
- $A$ is a ring under addition and multiplication
- if $r\in\mathbb{F}$ and $a,b\in A$ then $r(ab) = (ra)b = a(rb)$ (scalar compatibility)
</MathBox>

# Group theory

<LatexFig width={75} src='/fig/algebraic_structures.svg' alt=''
  caption='Relation between group-like algebraic structures'
>
```latex
\documentclass[tikz]{standalone}
\usepackage{tikz}
\usetikzlibrary{cd}

\begin{document}

\begin{tikzcd}[
  row sep=5em, 
  column sep=normal, 
  math mode=false, 
  font=\sffamily, 
  every label/.append style = {font = \scriptsize}
]
  & Magma 
    \arrow[dl, red, "divisibility" {gray, description}] 
    \arrow[d, blue, "identity" {gray, description}] 
    \arrow[dr, green, "associativity" {gray, description}] & \\
  Quasigroup 
    \arrow[d, blue, "identity" {gray, description}] 
    \arrow[dr, green, "associativity" {gray, near end, description}] &
  Unital magma 
    \arrow[dl, red, "invertibility" {gray, near start, description}] 
    \arrow[dr, green, "associativity" {gray, near start, description}] & 
  Semigroup 
    \arrow[dl, red, "divisibility" {gray, near end, description}] 
    \arrow[d, blue, "identity" {gray, description}] \\
  Loop 
    \arrow[dr, green, "associativity" {gray, description}] & 
  Associative group 
    \arrow[d, blue, "identity" {gray, description}] & 
  Monoid 
    \arrow[dl, red, "invertibility" {gray, description}] \\
  & Group &
\end{tikzcd}

\end{document}
```
</LatexFig>

<MathBox title='Monoid' boxType='definition'>
A monoid is a non-empty set $M$ with a binary operation, $*: M \times M \to M$ with the properties
- $a,b\in M \implies a * b \in M$ **(closure)**
- $(a * b) * c = a * (b * c) \in M$ **(associativity)**
- $\exists e\in M : a * e = e * a = a \; \forall a\in M$ **(identity element)**
</MathBox>

<MathBox title='Group' boxType='definition'>
A group is a non-empty set $G$ and a binary operation $*: G \times G \to G$, written $(G, *)$, with the properties
- $a, b\in G \implies a * b \in G$ **(closure)**
- $(a * b) * c = a * (b * c) \in G, \; \forall a,b,c\in\mathbb{G}$ **(associativity)**
- $\exists e\in G : a * e = e * a = a \; \forall a\in G$ **(identity element)**
- $\forall a\in G,\; \exists b\in G : a * b = e$ **(inverse element)**

Note that the closure property follows implicitly from the definition $*: G \times G \to G$.

A group $(G, *)$ is abelian if $a * b = b * a$ for all $a,b \in G$ (commutativity). 
</MathBox>

# Ring theory

<MathBox title='Ring' boxType='definition'>
A ring is a non-empty set $R$ equipped with two binary (closed) operations, 
- $+: R \times R \ni (a,b)\mapsto a + b \in R$ **(addition)**
- $\cdot: R\times R \ni (a,b)\mapsto ab \in R$ **(multiplication)***

with the properties
- $(R, +)$ is an abelian group
- $(R, \cdot)$ is a monoid
- Addition and multiplication are related by distributity, i.e. for all $a,b,c\in R$
    - $(a + b)c = ac + bc$
    - $c(a + b) = ca + cb$

A ring is commutative if $ab = ba$ for all $a,b\in R$. If a ring $R$ contains an element $e$ such that $ae = ea = a$ for all $a\in R$, we say that $R$ is a ring with identity.
</MathBox>

<MathBox title='Zero divisors and units' boxType='definition'>
Let $a,b$ be in a ring $R$. If $a \neq 0$ and $b \neq 0$ but $ab = 0$, then $a$ and $b$ are *zero divisiors*. If $ab = ba = 1$, we say the $a$ is a *unit*, or that $a$ is invertible.
</MathBox>

<MathBox title='Integral domain, division ring (skew field) and field' boxType='definition'>
An *integral domain* is a commutative ring with no zero divisor. A *division ring* or *skew field* is a ring in which every non-zero element $a$ has an inverse $a^{-1}$. A *field* is a commutative ring in which every non-zero element is invertible.
</MathBox>

<MathBox title='Ring characteristic' boxType='definition'>
The *characteristic* of a ring $R$, denoted $\operatorname{char}(R)$, is the smallest positive integer such that

$$
  n\cdot 1 = \underbrace{1 + \cdots + 1}_{n \text{ times}} = 0
$$

If there is no such positive integer, then $\operatorname{char}(R) = 0$.
</MathBox>

<MathBox title='Subring' boxType='definition'>
A subring of a ring $R$ is a subset $S$ of $R$ forming a ring under the operations of addition and multiplication defined in $R$.
</MathBox>

<MathBox title='Ring homomorphism' boxType='definition'>
Let $R, S$ be two rings. A map $f:R\to S$ is a ring homomorphism if it satisfies for $a,b\in R$
1. $f(a + b) = f(a) + f(b)$ (group homomorphism)
2. $f(ab) = f(a)f(b)$
3. $f(1_R) = 1_S$
</MathBox>

<MathBox title='Ideals' boxType='definition'>
Let $\mathcal{I}$ be a subset of ring $R$. An additive subgroup of $R$ is called
- a *left ideal* of $R$ if $ra\in\mathcal{I}$ for $a\in\mathcal{I}$ and $r\in R$
- a *right ideal* of $R$ if $ar\in\mathcal{I}$ for $a\in\mathcal{I}$ and $r\in R$

A left ideal that is also a right ideal, is called a *(two-sided) ideal* of $R$. An ideal is *proper* if $\mathcal{I} \neq R$, and it is *non-trivial* if in addition $\mathcal{I}\neq 0$.
</MathBox>

<MathBox title='Kernels of ring homomorphisms' boxType='definition'>
If $f:R\to S$ is a ring homomorphism, its kernel is defined as

$$
  \ker(f) = \Set{r\in R | f(r) = 0}
$$
</MathBox>

<MathBox title='Kernels of ring homomorphisms are proper ideals' boxType='proposition'>
The kernel of a ring homomorphism $f:R\to S$ is a proper two-sided ideal.

<details>
<summary>Proof</summary>

Since a ring homomorphism is a group homomorphism, we already know that $f$ is injective if and only if $\ker(f) = \Set{0}$. Note that $\ker(f)$ is an additive subgroup of $R$. Take $a\in\ker(f)$ and $r\in R$, then 

$$
\begin{align*}
  f(ra) =& f(r)f(a) = 0 \\
  f(ar) =& f(a)f(r) = 0
\end{align*}
$$

showing that $\ker(f)$ is a two-sided ideal since $ra, ar\in\ker(f)$. Moreover, $\ker(f)$ has to be proper, i.e. $\ker(f) \neq R$, since $f(1) = 1$ by definition.
</details>
</MathBox>

<MathBox title='' boxType='lemma'>
Suppose $f:R\to S$ is a ring homomorphism and the only two-sided ideals of $R$ are $\Set{0}$ and $R$. Then $f$ is injective.

<details>
<summary>Proof</summary>

Since $\ker(f)$ is a two-sided ideal of $R$, then either $\ker(f) = \Set{0}$ or $\ker(f) = R$. However, $\ker(f) \neq R$ since $f(1) = 1$ by defininition.
</details>
</MathBox>

It is worth noting the analogy between rings and their two-sided ideals on one hand, and groups and their normal subgroups on the other hand:
- Two-sided ideals are stable when the ring acts on them by multiplication, either on the right or on the left, and thus
$$
  rar^{-1} \in\mathcal{I}, a\in\mathcal{I}, r\in R
$$
while normal subgroups are stable when the groups on them by conjugation
$$
  ghg^{-1} \in H, h\in H, g\in G (H \leq G)
$$
- Groups with only trivial normal subgroups are called simple. Similarly, rings with only two sided ideals are called simple rings.
- The kernel of a group homomorphism is a normal subgroup, while the kernel of a ring homomorphism is an ideal.

## Quotient rings

Let $\mathcal{I}$ be a proper two-sided ideal of $R$. Since $\mathcal{I}$ is an additive subgroup of $R$ by definition, it makes sense to speak of cosets $r + \mathcal{I}$ of $I$ for $r\in R$. Furthermore, a ring has a structure of abelian group for addition, so $\mathcal{I}$ satisfies the definition of a normal subgroup. From group theory, we that it makes sense to speak of the quotient group

$$
  R\setminus\mathcal{I} = \Set{r + \mathcal{I} | r\in R}
$$

which is abelian since $(R, +)$ is an abelian group. We now endow $R\setminus\mathcal{I}$ with a multiplication operation defined as

$$
  (r + \mathcal{I})(r + \mathcal{I}) = rs + \mathcal{I}
$$

To see that it is well-defined, we check that it does not depend on the choice of the representative in each coset. Suppose

$$
\begin{align*}
  r + \mathcal{I} =& r' + \mathcal{I} \\
  s + \mathcal{I} =& s' + \mathcal{I}
\end{align*}
$$

so that $a = r' - r\in\mathcal{I}$ and $b = s' - s\in\mathcal{I}$. Then

$$
  r's' = (a + r)(b + s) = ab + as + rb + rs
$$

Since $a, b\in\mathcal{I}$ and $\mathcal{I}$ is an ideal, it follows that $ab, as, rb\in\mathcal{I}$. Consequently, $r's' \in rs + \mathcal{I}$ and therefore multiplication does not depend on the choise of representatives.

Note that this is only true if $\mathcal{I}$ is a two-sided ideal, otherwise we could not have concluded that both $as$ and $rb$ are in $\mathcal{I}$.

<MathBox title='Quotient ring' boxType='definition'>
The set of cosets of the two-sided ideal $\mathcal{I}$ given by

$$
  R\setminus\mathcal{I} = \Set{r + \mathcal{I} | r\in R}
$$

is a ring with identity $1_R + \mathcal{I}$ and zero element $0_R + \mathcal{I}$ called a *quotient ring*.
</MathBox>

<MathBox title='' boxType='proposition'>
Every proper two-sided ideal $\mathcal{I}$ is the kernel of a ring homomorphism.

<details>
<summary>Proof</summary>

Consider the canonical projection $\pi:R\to R\setminus\mathcal{I}$ defined by $r\mapsto\pi(r) = r + \mathcal{I}$. We already know that $\pi$ is a group homomorphism, and that its kernel is $\mathcal{I}$. We are only left to that $\pi$ is a ring homomorphism. Since $\mathcal{I}$ is a two-sided ideal, $R\setminus\mathcal{I}$ is a ring. Moreover, for $r, s\in R$

$$
  \pi(rs) = rs + \mathcal{I} = (r + \mathcal{I})(s + \mathcal{I}) = \pi(r)\pi(s)
$$

Finally, $\pi(1_R) = 1_R + \mathcal{I}$ which is indeed the identity element of $R\setminus\mathcal{I}$.
</details>
</MathBox>

<MathBox title='Factor theorem for rings' boxType='theorem'>
Any ring homomorphism $f$ whose kernel $\ker(f)$ contains $\mathcal{I}$ can be factored through $R\setminus\mathcal{I}$. In other words, there is a unique ring homomorphism $\bar{f}:R\setminus\mathcal{I}\to S$ such that $\bar{f}\circ\pi = f$, where $\pi:R\to R\setminus\mathcal{I}$ is the canonical projection. Furthermore,
1. $\bar{f}$ is an epimorphism if and only if $f$ is
2. $\bar{f}$ is a monomorphism if and only if $\ker(f) = \mathcal{I}$
3. $\bar{f}$ is an isomorphism if and only if $f$ is an epimorphism and $\ker(f) = \mathcal{I}$

<details>
<summary>Proof</summary>

Let $a + \mathcal{I}\in R\setminus\mathcal{I}$ such that $\pi(a) = a + \mathcal{I}$ for $a\in R$, and define

$$
  \bar{f}(a + \mathcal{I}) = f(a)
$$

We need check that $\bar{f}$ is well defined in the sense that it should not depend on the choice of the representative taken in the coset. Take another representative, say $b \in a + \mathcal{I}$. Since $a$ and $b$ are in the same coset, they satisfy $a - b \in \mathcal{I} \subset\ker(f)$. Because $a - b \in\ker(f)$, we have $f(a - b) = 0$ and thus $f(a) = f(b)$.

Now that $\bar{f}$ is well defined, it remains to verify that $\bar{f}$ inherits the property of the ring homomorphism from $f$. The rest of the proof works exactly the same as for groups.

</details>
</MathBox>

<MathBox title='First isomorphism theorem for rings' boxType='theorem'>
If $f:R\to S$ is a ring homomorphism with kernel $\ker(f)$, then the range of $f$ is isomorphic to $R\setminus K$:

$$
  \operatorname{ran}(f) \cong R\setminus\ker(f) 
$$

<details>
<summary>Proof</summary>

By the factor theorem $\bar{f}: R\setminus\ker(f)\to S$ is an isomorphism if and only if $f$ is an epimorphism, and clearly $f$ is an epimorphism on its image, which concludes the proof.
</details>
</MathBox>

## The Chinese remainer theorem

<MathBox title='Operations on ideals' boxType='definition'>
Let $\mathcal{I}$ and $\mathcal{J}$ be two ideals of a ring $R$. 

- The sum of $\mathcal{I}$ and $\mathcal{J}$ is the ideal
$$
  \mathcal{I} + \mathcal{J} = \Set{x + y | x\in\mathcal{I}, y\in\mathcal{J}}
$$
If $\mathcal{I}$ and $\mathcal{J}$ are right (respectively left) ideals, so is their sum.
- The intersection $\mathcal{I}\cap\mathcal{J}$ to two (respectively right, left, two-sided) ideals of $R$ is again a (respectively right, left, two-sided) ideal of $R$.
- The product of two left (respectively right) ideals $\mathcal{I}$ and $\mathcal{J}$ is the left (respectively right) ideal
$$
  \mathcal{I}\mathcal{J} = \Set{\sum_{i=1} x_i y_i | x_i \in\mathcal{I}, y_i \in\mathcal{J}}
$$
</MathBox>

<MathBox title='Relatively prime ideals' boxType='definition'>
The two-sided ideals $\mathcal{I}$ and $\mathcal{J}$ of a ring $R$ are *relatively prime* if $\mathcal{I} + \mathcal{J} = R$.
</MathBox>

<MathBox title='' boxType='proposition'>
If $\mathcal{I}$ and $\mathcal{J}$ are relatively prime two-sided ideals of a commutative ring $R$, then $\mathcal{IJ} = \mathcal{I}\cap\mathcal{J}$. If $R$ is a noncommutative ring and $\mathbb{I}$ and $\mathcal{J}$ are co-prime ideals, then $\mathcal{I}\cap\mathcal{J} = \mathcal{IJ} + \mathcal{JI}$.

<details>
<summary>Proof</summary>

Assume $R$ is a commutative ring. We clearly have that $\mathcal{I}\mathcal{J}\subset\mathcal{I}\cap\mathcal{J}$ since $\mathcal{I}\mathcal{J}$ contains by definition sums of elements of $xy$ with $x\in\mathcal{I}$ and $y\in\mathcal{J}$. By definition of two-sided ideals, it follows that $xy\in\mathcal{I}$ and $xy\in\mathcal{J}$.

Conversely, $\mathcal{I}\cap\mathcal{J}\subset\mathcal{IJ}$ since there exists $x\in\mathcal{I}$, $y\in\mathcal{J}$ such that $x + y = 1$ by definition of relatively prime, and for every element $a\in\mathcal{I}\cap\mathcal{J}$, we have that

$$
  a = a(x + y) = ax + ay = xa + ay \in\mathcal{IJ}
$$

If $R$ is noncommutative, then for every $a\in\mathcal{I}\cap\mathcal{J}$ we have that

$$
  a(x + y) = ax + ay \in\mathcal{JI} + \mathcal{IJ}
$$

since $ax \neq xa$.
</details>
</MathBox>

<MathBox title='Modulo for ideals' boxType='definition'>
Let $R$ be a ring. If $a,b\in R$ and $\mathcal{I}$ is an ideal of $R$, then $a$ is *congruent* to $b$ *modulo* $\mathcal{I}$ if $a - b\in\mathcal{I}$.
</MathBox>

<MathBox title='Direct product of rings' boxType='definition'>
If $R_1,\dots,R_n$ are rings, the *direct product* of $R_1,\dots,R_n$ denoted by $\prod_{i=1}^n R_i$ is defined as the ring of $n$-tuples $(a_1,\dots,a_n)$ for $a_i \in R_i$, with componentwise addition and multiplication. The zero element is $(0_{R_1},\dots,0_{R_n})$ and the identity is $(1_{R_1},\dots,1_{R_n})$.
</MathBox>

<MathBox title='Chinese remainder theorem' boxType='theorem'>
Let $R$ be a commutative ring, and let $\mathcal{I}_1,\dots,\mathcal{I}_n$ be ideals in $R$, such that $\mathbb{I}_i + \mathcal{I}_j = R$ for $i \neq j$. Then for $i = 1,\dots, n$
1. If $a_1,\dots,a_n$ are elements of $R$, there exists an element $a\in R$ such that $a\equiv a_i \mod\mathcal{I}_i$
2. If $b\in R$ with $b \equiv a_i \mod\mathcal{I}_i$, then $b \equiv a \mod \bigcap_{i=1}^n \mathbb{I}_i$. Conversely, if $b$ satisfies the above congruence, then $b \equiv a_i \mod\mathcal{I}_i$.
3. We have that
$$
  R\setminus \bigcap_{i=1}^n \mathcal{I}_i \cong \prod_{i=1}^n R\setminus\mathcal{I}_i
$$

<details>
<summary>Proof</summary>

**(1):** For $j > 1$, we have by assumption that $\mathcal{I}_1 + \mathcal{I}_j = R$, and thus there exists $b_j \in\mathcal{I}_1$ and $d_j \in\mathcal{I}_j$ such that $b_j + d_j = 1$ for $j = 2,\dots,n$. This gives

$$
  \prod_{j=2}^n (b_j + d_j) = 1
$$

Expanding the left hand side we note that

$$
\begin{align*}
  & (b_2 + d_2)(b_3 + d_3)\cdots(b_n + d_n) \\
  =& (\underbrace{b_2 b_3 + b_2 d_3 + d_2 b_3}_{\in\mathcal{I}_i} + d_2 d_3)\cdots(b_n + d_n)
\end{align*}
$$

showing that all the terms belong to $\mathcal{I}_1$. However, $c_1 := \prod_{j=2}^n d_j \in \prod_{j=2}^n \mathcal{I}_j$ so that $c_1 \equiv\mod\mathcal{I}_1$. On the other hand, we also have $c_1 \mod\mathcal{I}_j$ for $j > 1$ since $c_1 \in\prod_{j=2}^n \mathcal{I}_j$.

More generally, for all $i$, we can find $c_i$ with $c_1 \mod\mathcal{I}_i$ and $c_i \equi = \mod\mathcal{I}_j$ for $j\neq i$. Now take arbitrary elements $a_1,\dots,a_n \in R$ and set $a = \sum_{i=1}^n a_i c_i$. Since $c_j \equiv 0 \mod\mathcal{I}_j$ for $j \neq i$, we have for a given $i$ that $a \equiv a_i c_i \equiv a_i \mod\mathcal{I}_i$ using that $c_i \equiv 1 \mod\mathcal{I}_i$.

**(2):** We have just shown the existence of a solution $a \mod\mathcal{I}_i$ for $i=1,\dots,n$. We now discuss the question of unicity, and show that the solution is actually not unique, but any other solution than $a$ is actually congruent to $a\mod \bigcap_{i=1}^n \mathcal{I}_i$.

We have for all $i=1,\dots,n$ that

$$
  b \equiv a_i \mod\mathbb{I}_i \iff b \equiv a \mod\mathcal{I}_i \iff b - a \equiv 0 \mod\mathcal{I}_i
$$

which is equivalent to $b - a \in\bigcap_{i=1}^n \mathcal{I}_i$.

**(3):** Define the ring homomorphism $f: R\to\prod_{i=1}^n R\setminus\mathcal{I}_i$, sending $a\mapsto f(a) = (a + \mathcal{I}_1,\dots,a+\mathcal{I}_n)$. This map is surjective: for any $(a + \mathcal{I}_1,\dots,a+\mathcal{I}_n) \in \prod_{i=1}^n R\setminus\mathcal{I}_i$, we must fin an $a\in R$ such that $f(a) = (a_1+\mathcal{I}_1,\dots,a_n+\mathbb{I}_n)$, i.e. $a + \mathcal{I}_i = a_i + \mathcal{I}_i$, or equivalently $a_i \equiv \mod\mathcal{I}_i$, which is true by **(1)**.

The kernel of $f$ is given by

$$
\begin{align*}
  \ker(f) =& \Set{a \in R | f(a) = (\mathcal{I}_1,\dots,\mathcal{I}_n)} \\
  \Set{a\in R | a\in\mathcal{I}_i, i = 1,\dots,n} \\
  =& \prod_{i=1}^n \mathcal{I}_i
\end{align*}
$$

We conclude using the first isomorphism therem for rings.
</details>
</MathBox>

## Maximal and prime ideals

<MathBox title='Generated ideal' boxType='definition'>
The ideal *generated* by the non-empty set $X$ of $R$, denoted $\langle X \rangle$, is the smallest ideal of $R$ containing $X$. It is the collection of all finite sums of the form $\sum_i r_i x_i s_i$.
</MathBox>

<MathBox title='Principal ideal' boxType='definition'>
An ideal generated by a single element $a$ is a *principal ideal* denoted $\langle a \rangle$.
</MathBox>

<MathBox title='Maximal ideal' boxType='definition'>
A *maximal ideal* in the ring $R$ is a proper ideal that is not contained in any strictly larger proper ideal.
</MathBox>

<MathBox title='Correspondence theorem for rings' boxType='theorem'>
If $\mathcal{I}$ is a two-sided ideal of a ring $R$, then the canonical map $\pi:R\to R\setminus\mathcal{I}$ set up an injective correspondence between
- the set of all subrings of $R$ containing $\mathcal{I}$ and the set of all subrings of $R\setminus\mathcal{I}$
- the set of all ideals of $R$ containing $\mathcal{I}$ and the set of all ideals of $R\setminus\mathcal{I}$
</MathBox>

<MathBox title='Characterization of maximal ideals in commutative rings' boxType='theorem'>
Let $M$ be an ideal in the commutative ring $R$, then $M$ is maximal if and only if $R\setminus M$ is a field.

<details>
<summary>Proof</summary>

First assume $M$ is maximal. Sicne $R\setminus M$ is a ring, we need to find the multiplicative inverse of $a+M\in R\setminus m$ assuming that $a + M \neq 0$ in $R\setminus M$, i.e. $a\notin M$. Since $M$ is maximal, the ideal $Ra + M$ has to be $R$ itself, since $M \subset Ra + M$. Thus $1\in Ra + M = R$, i.e. $1 = ra + rm$ for $r\in R$ and $m\in M$. Then

$$
\begin{align*}
  (r + M)(a + M) =& ra + M \\
  =& (1 - m) + M \\
  =& 1 + M
\end{align*}
$$

proving that $r + M $ is $(a + M)^{-1}$. 

Conversely, assume that $R\setminus M$ is a field. Note first that $M$ must be a proper ideal of $R$, since $M = R$, then $R\setminus M$ contains only one element and $1 = 0$.

Let $N$ be an ideal ideal of $R$ such taht $M\subset C \subset R$ and $N\neq R$. We have to prove that $M = N$ to conclude that $M$ is maximal.

By the correspondence theorem for rings, we have an injective correspondence between the set of ideal of $R$ containing $M$, and the set of ideals of $R\setminus M$. Since $N$ is such an ideal, its image $\pi(N) \in R\setminus M$ must be an ideal of $R\setminus M$, and thus must be either $\Set{0}$ or $R\setminus M$ (since $R\setminus M$ is a field). The latter yields that $N = R$, which is a contradiction, leaving the only possibility that $\pi(N) = \Set{0}$, hence $N = M$.
 
</details>
</MathBox>

<MathBox title='Prime ideal' boxType='definition'>
A *prime ideal* in a commutative ring $R$ is a proper ideal $\mathcal{P}$ of $R$ such that for any $a,b\in R$

$$
  ab \in\mathcal{P} \implies a\in\mathcal{P} \lor b\in\mathcal{P}
$$
</MathBox>

<MathBox title='Characterization of prime ideals' boxType='theorem'>
If $\mathcal{P}$ is an ideal in the commutative ring $R$, then $\mathcal{P}$ is prime ideal if and only if $R\setminus P$ is an integral domain.

<details>
<summary>Proof</summary>

First assume that $\mathcal{P}$ is prime. It is thus proper by definition, and $R\setminus \mathcal{P}$ is a ring. We must show that the definition of integral domain holds, i.e.

$$
\begin{align*}
  & (a + \mathcal{P})(b + \mathcal{P}) = 0 + \mathcal{P} \\
  \implies& a + \mathcal{P} = \mathcal{P} \lor b + \mathcal{P} = \mathcal{P}
\end{align*}
$$

Since $(a + \mathcal{P})(b + \mathcal{P}) = ab + \mathcal{P} = 0 + \mathcal{P}$, we must have $ab \in\mathcal{P}$. Since $\mathcal{P}$ is a prime, then either $a\in\mathcal{P}$ or $b\in\mathcal{P}$, implying respectively that either $a + \mathcal{P} = \mathcal{P}$ or $b + \mathcal{P} = \mathcal{P}$.

Conversely, if $R\setminus\mathcal{P}$ is an integral domain, then $\mathcal{P}$ must be proper (otherwise $1 = 0$). We need to check the definition of a prime ideal. Consider $ab\in\mathcal{P}$, implying that

$$
  (a + \mathcal{P})(b + \mathcal{P}) = ab + \mathcal{P} = 0 + \mathcal{P}
$$

Since $R\setminus\mathcal{P}$ is an integral domain, either $a + \mathcal{P} = \mathcal{P}$ or $b + \mathcal{P} = \mathcal{P}$, i.e. $a\in\mathcal{P}$ or $b\in\mathcal{P}$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
In a commutative ring, a maximal ideal is prime.

<details>
<summary>Proof</summary>

If $M$ is maximal, then $R\setminus\mathcal{M}$ is a field, and thus an integral domain. Hence $M$ is also prime.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $f:R\to S$ be an epimorphism of commutative rings.
1. If $S$ is a field, then $\ker(f)$ is a maximal ideal of $R$.
2. If $S$ is an integral domain, then $\ker(f)$ is a prime ideal of $R$.

<details>
<summary>Proof</summary>

By the first isomorphism theorem for rings, we have that $S\cong R\setminus\ker(f)$.
</details>
</MathBox>

## Polynomial ring

Assume $R$ is a commutative ring. For a space $X$, let $R[X]$ be the set of polynimals in $X$ with coefficients in $R$. It is easy to see that $R[X]$ inhertis the properties of a ring from $R$. We define the *evaluation map* $E_x$ which evaluates a polynomial $f(X) \in R[X]$ in $x\in R$, as

$$
  E_x : R[X] \to R,\; f(X) \mapsto f(X)|_{X=x} = f(x)
$$

We can check that $E_x$ is a ring homomorphism. The highest order term determines the degree of polynomial, i.e. if $p(X) = \sum_{i=0}^n a_i X^i$ with $a_n \neq 0$, then $\deg(p(X)) = \deg(p) = n$. By convention, we set $\deg(0) = -\infty$.

There is a polyniam division algorithm over $R[X]$. if $f,g \in R[X]$ with $g$ monic, then there exists unique polynomials $q,r \in R[X]$ such that $f = qg + r$, where $\deg(r) < \deg(g)$.

The requirement that $g$ is monic comes from $R$ being a ring and not necessarily a field. If $R$ is a field, $g$ does not have to be monic, since one can always multiply $g$ by the inverse of the leading coefficient, which is not possible if $R$ is not a field.

<MathBox title='Remainder theorem' boxType='theorem'>
If $f\in R[X]$ and $a\in R$, then there exists a unique polynomial $q(X)\in R[X]$ such that

$$
  f(X) = q(X)(X - a) + f(a)
$$

Hence $f(a) = 0 \implies X - a | f(X)$.

<details>
<summary>Proof</summary>

Since $(X - a)$ is monic, we can do the division

$$
  f(X) = q(X)(X - a) + r(X)
$$

Since $\deg(r) < \deg(X - a)$, then $r(X)$ must be a constant polynomial, which implies that $f(a) = r(X)$ and thus $f(X) = q(X)(X - a) + f(a)$. Furthermore, we clearly have that $f(a) = 0 \iff X - a | f(X)$
</details>
</MathBox>

<MathBox title='Remainder theorem' boxType='theorem'>
If $R$ is an integral domain, then a non-zero groupo polynomial $f$ in $R[X]$ of degree $n$ has at most $n$ roots in $R$, counting multiplicity.

<details>
<summary>Proof</summary>

If $f$ has no roots in $R[X]$ then we are done. Let us assume that $f$ has a root $a_1$ in $R$, that is $f(a_1) = 0$. Then $X - a_1 | f(X)$ by the remainder theorem, meaning that $f(X) = q_1 (X)(X - a_1)^{n_1}$ where $q_1 (a_1) \neq 0$ and $\deg(q_1) = n - n_1$ since $R$ is an integral domain. If $a_1$ is the only root of $f$ in $R$, then $n_1 \leq n$ and we done. If not, consider similarly $a_2 \neq a_1$ another root of $f$, so that $0 = f(a_2) = q_1 (a_2)(a_2 - a_1)^{n_1}$. Since $R$ is an integral domain, we must have that $q_1 (a_2) = 0$, and thus $a_2$ is a root of $q_1 (X)$. We can repeat the process with $q_1 (X)$ instead of $f(X)$: since $a_2$ is a root of $q_1 (X)$ we have $q_1 (X) = q_2 (X)(X - a_2)^{n_2}$ with $q_2(a_2) \neq 0$ and $\deg(q_2) = n - n_1 - n_2$. By going on iterating the process, we obtain

$$
\begin{align*}
  f(X) =& q_1 (X)(X - a_1)^{n_1} \\
  =& q_2 (X)(X - a_2)^{n_2} (X - a_1)^{n_1} \\
  \vdots& \\
  =& (X-a_1)^{n_1} \cdots (X - a_k)^{n_k} \cdot c(X)
\end{align*}
$$

where $c(X)$ is a polynomial with no root in $R$, possibly constant, and $n \geq \sum_{i=1}^k n_i$. Since $R$ is an integral domain, the only possible roots of $f$ are $a_1,\dots,a_k$ for $k\leq n$, and the number of roots counting multiplicity is less than $n$.
</details>
</MathBox>

## Unique factorization and Euclidean division

In this section, all rings are assumed to be integral domains.

<MathBox title='Associate elements' boxType='definition'>
The elements $a$ and $b$ are *associate* if $a = ub$ for some unit $u$.
</MathBox>

<MathBox title='Irreducible elements' boxType='definition'>
Let $a$ be a nonzero element which is not a unit. Then $a$ is *irreducible* if $a = bc$ implies that either $b$ or $c$ must be a unit.
</MathBox>

<MathBox title='Prime elements' boxType='definition'>
Let $a$ be a nonzero element which is not a unit. Then $a$ is *prime* if whenever $a | bc$, then $a | b$ or $a | c$.
</MathBox>

<MathBox title='Prime elements are irreducible' boxType='proposition'>
If $a$ is prime, then $a$ is irreducible.

<details>
<summary>Proof</summary>

Suppose that $a$ is prime, and that $a = bc$. We want to prove that either $b$ or $c$ is a unit. By definition of prime, we must have that $a$ divides either $b$ or $c$. Assume that $a | b$, then

$$
  b = ad \implies b = bcd \implies b(1 - cd) = 0 \implies cd = 1
$$

using that $R$ is an integral domain, and thus $c$ is a unit. The same argument works if we assume that $a | c$, and we conclude that $a$ is irreducible.
</details>
</MathBox>

<MathBox title='Unique factorization domain (UFD)' boxType='definition'>
A *unique factorization domain* (UFD) is an integral domain $R$ satisfying that
1. Every element $0\neq a \in R$ can be written as a product of irreducible factors $p_1,\dots,p_n$ up to a unit, i.e. $a = u \prod_{i=1}^n p_i$.
2. The above factorization is unique, i.e. if $a = u\prod_{i=1}^n p_i = v\prod_{i=1}^n q_i$ are two factorizations into irreducible factors $p_i$ and $q_j$ with units $u,v$, then $n = m$ and $p_i$ and $q_i$ are associate for all $i$.
</MathBox>

<MathBox title='' boxType='proposition'>
In a unique factorization domain $R$, we have that $a$ is irreducible if and only if $a$ is prime.

<details>
<summary>Proof</summary>

We already know that prime implies irreducible. Conversely, take $a$ to be irreducible and assume that $a | bc$. This means that $bc = ad$ for some $d\in R$. Using the property of unique factorization, we decompose $d, b$ and $c$ into products of irreducible terms (respectively $d_i, b_i, c_i$ up to units $u, v, w$)

$$
  a\cdot ud_1 \cdots d_r = vb_1 \cdots b_s \cdot wc_1 \cdots c_t
$$

Since the factorization is unique, $a$ must be associate to some either $b_i$ or $c_i$, implying that $a$ divides $b$ or $c$.
</details>
</MathBox>

<MathBox title='Noetherian ring' boxType='definition'>
Let $a_1,a_2,\dots$ be elements of an integral domain $R$. If the sequence of principal ideals $(a_1) \subseteq (a_2) \subseteq \cdots$ stabilizes, i.e. $(a_n) = (a_{n+1}) = \cdots$ for some $n$, then we say that $R$ satisfies the *ascending chain condition on principal ideals*. If the same condition holds but for general ideals, not necessarily principal, we call $R$ a *Noetherian ring.*
</MathBox>

<MathBox title='Characterization of unique factorization domain' boxType='theorem'>
Let $R$ be an integral domain.
1. If $R$ is a unique factorization domain (UFD), then $R$ satisfies the ascending chain condition on principal ideals.
2. If $R$ satisfies the ascending chain condition on principal ideals, then every nonzero element of $R$ can be factored into irreducible (this says nothing about the unicity of the factorization)
3. If $R$ is such that every nonzero element of $R$ can be factored into irreducible, and in addition every irreducible element is prime, then $R$ is a UFD.

Thus, $R$ is UFD if and only if it satisfies the ascending chain condition on principal ideals and every irreducible element of $R$ is prime.

<details>
<summary>Proof</summary>

**(1):** Recall that in a UFD, prime and irreducible are equivalent. Consider an ascending chain of principal ideals

$$
  (a_1) \subseteq (a_2) \subseteq \cdots
$$

We have that $a_{i+1} | a_i$ for all $i$. Thus, the prime factors of $a_{i+1}$ consist of some (possibly all) prime factors of $a_i$. Since $a_1$ has a unique factorization into finitely many prime factors, the prime factors will end up being the same, and the chain will stabilize.

**(2):** Take $0 \neq a_1 \in R$. If $a_1$ is irreducible, we are done. Assume thus that $a_1$ is not irreducible, i.e. $a_1 = a_2 b_2$, where $a_2$ and $b_2$ are not unit. Since $a_2 | a_1$, we have $(a_1) \subseteq (a_2)$, and actually $(a_1) \subsetneq (a_2)$. Indeed, if $(a_1) = (a_2)$, then $a_2$ would be a multiple of $a_1$, i.e. $a_2 = ca_1$ and thus

$$
  a_1 = a_2 b_2 \implies a_1 = ca_1 b_2 \implies a_1 (1 - cb_2) = 0
$$

implying that $cb_2 = 1$ and thus $b_2$ is a unit. This contradicts the assumption that $a_1$ is not irreducible. This computation has shown is that whenever we get at factor which is not irreducible, we can add a new principal ideal to the chain of ideals. Thus, if $a_2 b_2$ is a product of irreducible, we are done. Otherwise, we have that say $a_2$ is not irreducible, and $a_2 = a_3 b_3$, giving $(a_1) \subsetneq (a_2) \subsetneq (a_3)$. Since $R$ satisfies the ascending chaing condition on principal ideal, this process cannot go on and must stop, showing that we have a factorization into irreducible.

**(3):** We now know that $R$ allows a factorization into irreducible. We want to prove that this factorization is unique, under the assumption that every irreducible is prime. Suppose that $a = u\prod_{i=1}^n p_i = v \prod_{j=1}^m q_j$, where $u, v$ are unit and $p_i, q_j$ are irreducible. Then $p_1$ is irreducible, but also prime by assumption. Thus, it must divide on the $q_j$, say $q_1$, giving $q_1 = p_1 d$. Since $q_1$ is irreducible, $d$ must be a unit, and $q_1$ and $p_1$ are associate. We can iterate the process to find that $q_i$ and $p_i$ are associate for all $i$.
</details>
</MathBox>

<MathBox title='Principal ideal domain (PID)' boxType='definition'>
A *principal ideal domain* (PID) is an integral domain in which every ideal is principal.
</MathBox>

<MathBox title='' boxType='theorem'>
A principal ideal domain $R$ is a unique factorization domain.

<details>
<summary>Proof</summary>

We will prove that if $R$ as a principal ideal domain, then
- $R$ satisfies the ascending chain condition on principal ideals
- every irreducible in $R$ is also prime

Having proved these two claims, we can conclude applying the characterization of unique factorization domains.

Let us first prove that $R$ satisfies the ascending chain condition on principle ideals. Consider a sequence of principal ideals $(a_1) \subseteq (a_2) \subsetq \cdots$ and let $\mathcal{I} = \bigcup_{i=1}^\infty (a_i)$. Note that $\mathcal{I}$ is an ideal of $R$ (however, a union of ideals is not necessarily an ideal in general). Indeed, we have that $\mathcal{I}$ is closed under addition: take $a, b\in\mathcal{I}$, then there are ideals $(a_j)$ and $(a_k)$ in the chain with $a\in (a_j)$ and $b \in (a_k)$. If $m \geq \max(j,k)$, then both $a,b\in (a_m)$ and so do $a + b$. To check that $\mathcal{I}$ is closed under multiplication by an element of $R$, take again $a\in\mathcal{I}$. Then $a\in(a_j)$ for some $j$. If $r\in R$, then $ra \in (a_j)$ implying that $ra \in\mathcal{I}$.

By assumption, $\mathcal{I}$ is a principal ideal generated by, say $\mathcal{I} = (b)$. Since $b$ belongs to $\bigcup_{i=1}^\infty (a_i)$, it must belong to some $(a_n)$. Thus $\mathcal{I} = (b) \subseteq (a_n)$. For $j \geq n$, we have

$$
  (a_j) \subseteq \mathcal{I} \subseteq (a_n) \subseteq (a_j)
$$

which proves that the chain ideal stabilizes.

It remains to prove that every irreducible element is also prime. Let $a$ be an irreducible element. Consider the principal ideal $(a)$ generated by $a$. Note that $(a)$ is a proper ideal: if $(a) = R$, then $1\in (a)$ and thus $a$ is a unit, which is a contradiction.

By the ascending chain condition, $(a)$ is included in a maximal ideal $\mathcal{I}$. Since $R$ is a principal ideal domain, it follows that $\mathcal{I} = b$. Thus

$$
  (a) \subseteq (b) \implies b | a \implies a = bd
$$

where $a$ is irreducible, $b$ cannot be a unit (since $\mathcal{I}$, by definition of maximal ideal, is a proper ideal), and thus $d$ has to be unit of $R$. In other words, $a$ and $b$ are associate. Thus $(a) = \mathcal{I} = (b)$. Since $\mathcal{I}$ is a maximal ideal, it is prime implying that $a$ is prime, which concludes the proof.
</details>
</MathBox>

<MathBox title='Euclidean domain' boxType='definition'>
An integral domain $R$ is a *Euclidean domain* if there is a function $\Psi$ from $R\setminus\Set{0}$ to the non-negative integers such that

$$
  a = bq + r,\; a,b\in R,\; b\neq 0,\; q,r \in R
$$

where either $r = 0$ or $\Psi(r) < \Psi(b)$. When the division is performed with natural numbers, it is clear what it means that $r < b$. For polyonomials, we say that $\deg(r) < \deg(b)$. The function $\Psi$ generalizes these notions.
</MathBox>

<MathBox title='' boxType='theorem'>
If $R$ is a *Euclidean domain*, then $R$ is a principal ideal domain.

<details>
<summary>Proof</summary>

Let $\mathcal{I}$ be an ideal of $R$. If $\mathcal{I} = \Set{0}$, it is ideal and we aer done. Assume thus $\mathcal{I} \neq \Set{0}$ and consider the the set $\Set{\Psi(b),\; b\in\mathcal{I},\; b\neq 0}$. It is included in the non-negative integers by definition of $\Psi$, this it contains a smallest element, say $n$. let $0\neq b\in\mathcal{I}$ such that $\Psi(b) = n$.

We will now prive that $\mathcal{I} = (b)$. Take $a\in\mathcal{I}$ and compute $a = bq + r$, where $r = 0$ or $\Psi(r) < \Psi(b)$. This yields $r = a - bq \in\mathcal{I}$ and $\Psi(r) < \Psi(b)$ cannot possibly happen by minimality of $n$, forcing $r$ to be zero.
</details>
</MathBox>

## Irreducible polynomials

<MathBox title='Irreducible polynomial' boxType='definition'>
If $R$ is an integral domain, then an irreducible element of $R[X]$ is called an irreducible polynomial.
</MathBox>

Let $R$ be an integral domain. We will construct the field of fractions, also called quotient field, of $R$. Suppose $S$ is a subset of $R$ closed under multiplication, contains $1$ and does not contain $0$. This definition includes the set of all nonzero elements of an integral domain, or the set all nonzero elements of a commutative ring that are not zero divisors. We define the followin equivalence realtion on $R\times S$

$$
  (a, b) \sim (c,d) \iff s(ad - bc) = 0,\; s\in S
$$

It is clearly reflexive and symmetric. It remains to check transitivity. Suppose $(a,b)\sim(c,d)$ and $(c,d)\sim(e,f)$. Then $s(ad - bc) = 0$ and $t(cf - de) = 0$ for some $t,s\in S$. We can now multiply the first equation by $tf$, the second by $sb$ and add them

$$
  stf(ad - bc) + tsb(cf - de) = 0
$$

to get $sdt(fa - be) = 0$, proving transitivity.

If we take nonzero $a,b,c,d \in\Z$ we can write down $a/b = c/d$, or equivalently $ad = bc$, which is also what $(a,b)\sim(c,d)$ satisfies by definition if we take $R$ to be an integral domain. In a sense, $(a,b)$ is some approximation of $a/b$.

Formally, if $a\in R$ and $b\in S$, we define the fraction $a/b$ to be the equivalence class of the pair $(a,b)$. Set set of all equivalence classes is denoted $S^{-1}R$. To make it into a ring, we define the following laws in a natural way
- **Addition:**
$$
  \frac{a}{b} + \frac{c}{d} = \frac{ad + bc}{bd}
$$
- **Multiplication:**
$$
  \frac{a}{b}\frac{c}{d} = \frac{ac}{bd}
$$
- **Additive identity:**
$$
  \frac{0}{1} = \frac{0}{s},\; s\in S
$$
- **Additive inverse:**
$$
  -\frac{a}{b} = \frac{-a}{b}
$$
- **Multiplicative identity:**
$$
  \frac{1}{1} = \frac{s}{s},\; s\in S
$$

<MathBox title='' boxType='theorem'>
With the above definitions, the set of equivalence classes $S^{-1}R$ is a commutative ring.
1. If $R$ is an integral domain, so is $S^{-1}R$.
2. If $R$ is an integral domain, and $S = R\setminus\Set{0}$, then $S^{-1}R$ is a field.

<details>
<summary>Proof</summary>

**Addition is well-defined:** If $a_1/b_1 = c_1 / d_1$ and $a_2 / b_2 = c_2 / d_2$, then for some $s,t \in S$, we have

$$
\begin{align*}
  s(a_1 d_1 - b_1 c_1) =& 0 \\
  t(a_2 d_2 - b_2 c_2) =& 0
\end{align*}
$$

Multiplying the first equation by $tb_2 d_2$ and the second by $sb_1 d_1$, we get

$$
\begin{align*}
  tb_2 d_2 s(a_1 d_1 - b_1 c_1) =& 0 \\
  sb_1 d_1 t(a_2 d_2 - b_2 c_2) =& 0
\end{align*}
$$

Adding them gives

$$
\begin{align*}
  &st[d_2 d_1 (b_2 a_1 + b_1 a_2) - b_2 b_1 (d_2 c_1 + d_1 c_2)] = 0 \\
  \iff& \frac{b_2 a_1 + b_1 a_2}{b_2 b_1} = \frac{d_2 c_1 + d_1 c_2}{d_2 d_1}
\end{align*}
$$

which can be rewritten as

$$
  \frac{a_1}{b_1} + \frac{a_2}{b_2} = \frac{c_1}{d_1} + \frac{c_2}{d_2}
$$

This shows that addition does not depend on the choice of representative in an equivalence class.

**Multiplication is well-defined:** If $a_1 / b_1 = c_1 / d_1$ and $a_2 / b_2 = c_2 / d_2$, then for some $s, t\in S$, we have

$$
\begin{align*}
  s(a_1 d_1 - b_1 c_1) =& 0 \\
  t(a_2 d_2 - b_2 c_2) =& 0
\end{align*}
$$

Multiplying the first equation by $ta_2 d_2$, the second by $sc_1 d_1$, and adding them gives

$$
\begin{align*}
  &st[a_2 d_2 a_1 d_1 - c_1 b_1 b_2 c_2] = 0 \\
  \iff& \frac{a_1 a_2}{b_1 b_2} = \frac{c_1 c_2}{d_1 d_2}
\end{align*}
$$

The ring properties follows from the fact that addition and multiplication are carried out the usual way.

**(1):** We want to prove that $S^{-1}R$ is an integral domain. We assume that $R$ is an integral domain, and we check the definition of an integral domain for $S^{-1}R$. Suppose that $(a/b)(c/d) = 0$ in $S^{-1}R$, i.e.

$$
  \frac{a}{b}\frac{c}{d} = \frac{0}{1}
$$

This means that $(ac, bd) \sim (0, 1)$ and $acs = 0$ for some $s\in S$. Now $acs = 0$ is an equation in $R$, which is an integral domain, and $s \neq 0$, this $ac = 0$, so either $a$ or $c$ is $0$, and consequently either $a/b$ or $c/d$ is zero.

**(2):** We wan to prove that $S^{-1}R$ is a field, assuming that $R$ is an integral domain, and $S = R\setminus\Set{0}$. We consider $a/b$ a nonzero element of $S^{-1}R$, for which we need to find an inverse. Note that $a$ and $b$ are nonzero, thus they are both in $S$ meaning that both $a/b$ and $b/a$ are in $S^{-1}R$ and $b/a$ is the multiplicative inverse of $a/b$.

</details>
</MathBox>

<MathBox title='Ring of fractions' boxType='definition'>
Let $R$ be a commutative ring. The set of equivalence classes $S^{-1}R$ is a commutative ring, called the *ring of fractions* of $R$ by $S$, where $S$ is the set of all it non-divisors of zero. If $R$ is an integral domain, and $S = R\setminus\Set{0}$, then $S^{-1}R$ is called the *field of fractions* or *quotient field* of $R$. 
</MathBox>

<MathBox title='' boxType='proposition'>
A commutative ring $R$ can be embedded in its ring of fractions $S^{-1}$, where $S$ is the set of all it non-divisors of zero. In particular, an integral domain can be embedded its quotient field, which is the smallest field containing $R$.

<details>
<summary>Proof</summary>

Consider the map $f: R\to S^{-1}R$ by $a \mapsto f(a) = a/1$. It is not hard to check that $f$ is a ring homomorphism. If $S$ has no zero divisor, then $\ker(f)$ is given by the set of $a$ such that $f(a) = a/1 = 0/1$, i.e. the set of $a$ such that $sa = 0$ for some $s$. Since $s$ is not a zero divisor, we have $a = 0$ and $f$ is monomorphism.
</details>
</MathBox>

<MathBox title='Primitive polynomial' boxType='definition'>
Let $D$ be a unique factorization domain and let $f\in D[X]$. The greatest common divisor of all the coefficients of $f$ is called the *content* of $f$, denoted $c(f)$. A polynomial whose content is a unit is called a *primitive polynomial*.
</MathBox>

<MathBox title='' boxType='lemma'>
Let $D$ be a unique factorization domain, and consider $f \neq 0$ and $g,h\in D[x]$ such that $pf(X) = g(X)h(X)$ with $p$ a prime. Then either $p$ divides all the coefficients of $g$ or $p$ divides all the coefficients of $h$.

<details>
<summary>Proof</summary>

Denote $g(X) = g_0 + \sum_{i=1}^s g_i X^i$ and $h(X) = h_0 + \sum_{j=1}^t h_j X^j$. Suppose by contradiction that $p$ does not divide all coefficients of $g$ and neither of $h$. Let $g_u$ and $h_v$ be the coefficients of minimum index not divisible by $p$. Then the coefficients of $X^{u+v}$ in $g(X)h(X)$ is

$$
  g_0 h_{u+v} + g_1 h_{u + v - 1} + \cdots + g_u h_v + \dots + g_{u + v - 1}h_1 + g_{u+v}h_0
$$

By definition of $u$ and $v$, $p$ divides every term except $g_u h_v$, thus $p$ cannt possibly divide the entire expression, and thus there exists a coefficient of $g(X)h(X)$ not divisible by $p$. This contradicts the fact that $p|g(X)h(X)$.
</details>
</MathBox>

<MathBox title='Gauss lemma' boxType='lemma'>
Let $f,g$ be non-constant polynomials in $D[X]$ where $D$ is a unique factorization domain. The content of a product of polynomials is the product of the contents

$$
  c(fg) = c(f)c(g)
$$

up to associates. In particular, the product of two primitives polynomials is primitive.

<details>
<summary>Proof</summary>

Note that by definition of content, we can rewrite

$$
\begin{align*}
  f(X) =& c(f)f^*(X) \\
  g(X) =& c(g)g^* (X)
\end{align*}
$$

where $f^*, g^* \in D[X]$ are primitive. Clearly, $fg = c(f)c(g)f^* g^*$. Since $c(f)c(g)$ divides $fg$, it divides every coefficient of $fg$ and thus their greatest common divisor $c(f)c(g) | c(gf)$.

We now prove the converse, i.e. $c(gf) | c(f)c(g)$. Consider each prime $p$ appearing in the factorization of $c(gf)$ such that $p| c(f)c(g)$. Let $p$ be a prime factor of $c(gf)$. Since $fg = c(fg)(fg)^*$, we have that $c(fg)$ divides $fg$, i.e. $p|fg$.

By the above lemma, either $p|f$ or $p|g$, say $p|f = c(f)f^*$, meaning that either $p|c(f)$ or $p|f^*$. Since $f^*$ is primitive, $p$ cannot possibly divide $f^*$, and thus

$$
  p|c(f) \implies p| c(f)c(g)
$$

If $p$ appears with multiplicity, we iterate the reasoning with the same $p$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $D$ be a unique factorization domain with quotient field $F$. If $f$ is a non-constant polynomial in $D[X]$, then $f$ is irreducible over $D$ if and only if $f$ is primitive and $f$ is irreducible over $F$.

<details>
<summary>Proof</summary>

Assume that $f$ is irreducible over $D$. First, we show that $f$ is primitive. If $f$ were not primitive, then we could write

$$
  f = c(f)f^*
$$

where $c(f)$ is the content of $f$ and $f^*$ is primitive. Since we assume $f$ is not primitive, its content cannot be a unit, which contradict the irreducibility of $f$ over $D$. Hence, $f$ is primitive.

Next, we show that $f$ is irreducible over $F$. Assume by contradiction that $f$ is not irreducible over $F$. Since $F$ is a field, reducible means $f$ can be factored into a product of two non-constant polynomials in $F[X]$ of smaller degree, i.e. $f(X) = g(X)h(X)$ with $\deg(g) < \deg(f)$ and $\deg(h) < \deg(f)$. Since $g,h \in F[X]$ and $F$ is the field of fractions of $D$, we can write

$$
\begin{gather*}
  g(X) = \frac{a}{b}g^*(X), \quad h(X) = \frac{a}{b}h^*(X), \\
  a, b, c, d \in D
\end{gather*}
$$

where $g^*$ and $h^*$ are primitive. Thus, $f(X) = \frac{ac}{bd}g^*(X) h^*(X)$, where $g^* h^*$ is a primitive polynomial by Gauss lemma. Since we already know that $f$ is primitive, it must be that $\frac{ac}{bd} = u$ is a unit. However, this would mean that $f(X) = ug^*(X)h^*(X)$, which contradicts the fact that $f(X)$ is irreducible over $D[X]$. Hence, $f$ is irreducible over $F[X]$.

Conversely, assume that $f$ is primitive, and irreducible over $F[X]$. Assume by contradiction that the primitive polynomial $f$ is not irreducible over $D$, i.e. $f(X) = g(X)h(X)$. Since $f$ is primitive, $\deg(g) \geq 1$ and $\deg(h) \geq 1$. However, then neither $g$ not $h$ can be a unit in $F[X]$ and thus $f = gh$ contradicts the irreducibility of $f$ over $F$.
</details>
</MathBox>

<MathBox title="Eisenstein's criterion" boxType='criterion'>
Let $D$ be a unique factorization domain, with quotient field $F$ and let

$$
  f(X) = \sum_{i=1}^n a_i X^i
$$

be a polynomial in $D[X]$ with $n \geq 1$ and $a_0 \neq 0$. If $p$ is a prime in $D$ and $p$ divides $a_i$ for $0\leq i < n$, but $p$ does not divide $a_n$ nor does $p^2$ divide $a_0$, then $f$ is irreducible over $F$.

<details>
<summary>Proof</summary>

We first divide $f$ by its content to get a primitive polynomial. By the previous proposition, it is enough to prove that this primitive polynomial is irreducible over $D$.

Let $f$ be a primitive polynomial and assume by contradiction it is reducible, i.e. $f(X) = g(X)h(X)$ with $g(X) = \sum_{i=0}^r g_i X^i$ and $h(X) = \sum_{j=0} x_j X^j$. Note that $r$ cannot be zero, for if $r = 0$, then $g_0 = g$ would divide $f$ and thus all $a_i$ implying that $g_0$ divides the content of $f$ and is thus a unit. However, this would contradict the fact that $f$ is reducible. 

Assume that $r \geq 1$ and $s \geq 1$. By hypothesis $p|a_0 = g_0 h_0$ but $p^2$ does not divide $a_0$, meaning that $p$ cannot divide both $g_0$ and $h_0$. If say $p|g_0$, then $p$ does not divide $h_0$ and vice-versa.

By looking at the dominant coefficient $a_n = g_r h_s$, it follows from the assumption that $p$ does not divide $a_n$ that $p$ cannot possibly divide $g_r$. Let $i$ be the smallest integer such that $p$ does not divide $g_i$. Then

$$
  1 \leq i \leq r < n = r + s
$$

Let us look at the $i$th coefficient 

$$
  a_i = g_0 h_i + g_1 h_{i-1} + \dots + g_i h_0
$$

and by choice of $i$, $p$ must divide $g_0,\dots, g_{i-1}$. Since $p$ divides $a_i$ by assumption, it thus must divide the last term $g_i h_0$, and either $p|g_i$ or $p|h_0$ by definition of prime. Both are impossible as we have chosen $p$ dividing neither $h_0$ nor $g_i$.
</details>
</MathBox>