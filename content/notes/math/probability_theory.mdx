---
title: 'Probability Theory'
subject: 'Mathematics'
showToc: true
---

The subjects of probability and statistics are somewhat inverse of each other. In probability, random experiments are completely specified by mathematical models. By contrast, statistics deals with incompletely specified mathematical models, and experiments are designed to draw inferences about the unknown factors in the mathematical model.

# Probability space

<MathBox title='Probability space' boxType='definition'>
A probability space $(\Omega, \mathcal{F}, \mathbb{P})$ is a measure space such that the measure of the whole space is equal to one. It consists of

1. An outcome space, $\Omega$
2. An event space, a $\sigma$-algebra $\mathcal{F} \subseteq 2^\Omega = \mathcal{P}(\Omega)$, which is a collection of events (subsets) of $\Omega$ satisfying
  - $\Omega, \emptyset \in \mathcal{F}$
  - $A \in \mathcal{F} \implies A^c = \Omega \backslash A \in \mathcal{F}$
  - $\bigcup_{i \in \mathbb{N}} A_i \in \mathcal{F},\; A_i \in \mathcal{F}$
3. A probability measure, $\mathbb{P}:\mathcal{F}\to[0, 1]$ that assigns a probability to each event in the sample space $(\Omega, \mathcal{F})$, satisfying the Kolmogorov axioms
  - $\mathbb{P}(A)\geq 0$ for every event $A\in\mathcal{F}$
  - $\mathbb{P}(\Omega) = 1$
  - $\mathbb{P}\left(\bigcup_{i\in\mathbb{N}} A_i \right) = \sum_{i\in\mathbb{N}} \mathbb{P}(A_i)$ for any sequence $\{A_i\}_{i\in\mathbb{N}}$ of disjoint sets in $\mathcal{F}$, i.e. $A_i \cap A_j = \emptyset$ if $i\neq j$

Most of the sample spaces that occur in elementary probability fall into two general categories:
1. Discrete: $\Omega$ is countable and $\mathcal{F} = \mathcal{P}(\Omega)$ is the power set of $\Omega$.
2. Euclidean: $\Omega$ is a measurable subset of $\mathbb{R}^n$ for some $n\in\mathbb{N}$ and $\mathcal{F}$ is the collection of measurable subsets of $\Omega$.
</MathBox>

<MathBox title='Example: Coin toss' boxType='example'>
Flipping a fair coin has the following outcomes 
- $H$ if the coin lands on its head
- $T$ if the coin lands on its tail

Flipping the coin once can be described with the following probability space
- Sample space: $\Omega_1 = \{H, T\}$
- Event space: $\mathcal{F} = \left\{\emptyset, \Omega_1, \{H\}, \{T\} \right\} = 2^{\Omega_1}$
- Probability measure $P(\{H\}) = P(\{T\}) = \frac{1}{2}$

Flipping the coin $n$ times gives the following probability space
- $\Omega_n = \left\{ \left(\omega_i \right)_{i=1}^n \;|\; \omega_i \in\{H, T\} \right\}$
- $\mathcal{F}_n = 2^{\Omega_n}$
</MathBox>

<MathBox title='Properties of the probability measure' boxType='definition'>
Given a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, the probability measure $\mathbb{P}:\mathcal{F}\to[0, 1]$ has the following properties
- Monotonicity: If $A \subseteq B$ then $\mathbb{P}(A)\leq\mathbb{P}(B)$
</MathBox>

## Filtration

In the following discussion let $(\Omega,\mathcal{F})$ be a sample space and $(T,\mathcal{T})$ an index space.

<MathBox title='Filtration' boxType='definition'>
A collection of $\sigma$-algebras $\mathscr{F}:=\{\mathcal{F}_t\}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ if $s,t\in T$ and $s\leq t$ imply $\mathcal{F}_s\subseteq\mathcal{F}_t\subseteq\mathcal{F}$. The triple $(\Omega,\mathcal{F},\mathscr{F})$ is a filtered sample space. If $\mathbb{P}$ is a probability measure on $(\Omega,\mathcal{F})$, then $(\Omega,\mathcal{F},\mathscr{F},\mathbb{P})$ is a filtered probability space.
</MathBox>

A filtration is simply an increasing collection of $\sigma$-algebras, indexed by $T$. Each $\mathcal{F}_t$ is a $\sigma$-algebra of events up to time $t\in T$, and contains the information that is available at that given time.

<MathBox title='Partial order on filtrations' boxType='definition'>
Suppose that $\mathscr{F} = \{F_t\}_{t\in T}$ and $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ are filtrations on $(\Omega,\mathcal{F})$. We say that $\mathscr{F}$ is coarser than $\mathscr{G}$ and $\mathscr{G}$ is finer than $\mathscr{F}$, denoted $\mathscr{F}\leq\mathscr{G}$, if $\mathcal{F}_t\subseteq\mathcal{G}_t$ for all $t\in T$. The relation $\leq$ is a partial order on the collection of filtrations on $(\Omega,\mathcal{F})$. That is, if $\mathscr{F}=\{\mathcal{F}_t\}_{t\in T}$, $\mathscr{G}=\{\mathcal{G}_t\}_{t\in T}$ and $\mathscr{H}=\{\mathcal{H}_t\}_{t\in T}$ are filtrations, then
- reflexivity: $\mathscr{F}\leq\mathscr{F}$
- anti-symmetry: $\mathscr{F}\leq\mathscr{G}\land\mathscr{G}\leq\mathscr{F}\implies\mathscr{F}=\mathscr{G}$
- transitivity: $\mathscr{F}\leq\mathscr{G}\land\mathscr{G}\leq\mathscr{H}\implies\mathscr{F}\leq\mathscr{H}$
</MathBox>

<MathBox title='$\sigma$-algebra generated by the union of a filtration' boxType='proposition'>
For a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ on $(\Omega,\mathscr{F})$, defined $\mathscr{F}_\infty:=\sigma\left(\bigcup\{\mathcal{F}_t\}_{t\in T}\right)$. Then by the increasing monotonicity of $\mathscr{F}$
1. $\mathcal{F}_\infty = \sigma\left(\bigcup \{\mathcal{F}_t \;|\; t\in T,t\geq s\}\right)$ for $s\in T$
2. $\mathcal{F}_t\subseteq\mathcal{F}_\infty$ for $t\in T$
</MathBox>

<MathBox title='Intersection and union of filtrations' boxType='proposition'>
Suppose that $\mathscr{F}_i = \{F_t\}_{t\in T}$ is a filtration on $(\Omega,\mathscr{F})$ for each $i$ in an index set $I$. Then 
- $\mathscr{F}=\{\mathcal{F}_t\}_{t\in T}$ where $\mathcal{F}_t = \bigcap{i\in I}\mathcal{F}_t^i$ for $t\in T$ is also a filtration on $(\Omega,\mathcal{F})$. This filtration is sometimes denoted $\mathscr{F}=\bigwedge_{i\in I}\mathscr{F}_i$ and is the finest filtration that is coarser than $\mathscr{F}_i$ for every $i\in I$.
- $\mathscr{F}=\{\mathcal{F}_t\}_{t\in T}$ where $\mathcal{F}_t = \sigma\left(\bigcup_{i\in I} \mathcal{F}_t^i \right)$ for $t\in T$ is also a filtration on $(\Omega,\mathcal{F})$. This filtration is sometimes denoted $\mathscr{F}=\bigvee_{i\in I}\mathscr{F}_i$, and is the coarsest filtration that is finer than $\mathscr{F}_i$ for every $i\in I$. 
<details>
<summary>Proof sketch</summary>

Suppose $s,t\in T$ with $s\leq t$. Then $\mathcal{F}_s^i\subseteq\mathcal{F}_t^i\subseteq\mathcal{F}$ for each $i\in I$. Then
1. $\bigcap_{i\in I}\mathcal{F}_s^i\subseteq\bigcap_{i\in I}\mathcal{F}_t^i\subseteq\mathcal{F}$.
2. $\bigcup_{i\in I}\mathcal{F}_s^i\subseteq\bigcup_{i\in I}\mathcal{F}_t^i\subseteq\mathcal{F}$, and hence $\sigma\left(\bigcup_{i\in I}\mathcal{F}_s^i\subseteq\mathcal{F}\right) = \sigma\left(\bigcup_{i\in I}\mathcal{F}_t^i\subseteq\mathcal{F}\right)\subseteq\mathcal{F}$
</details>
</MathBox>

### Completion

<MathBox title='Complete filtration' boxType='definition'>
The filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is complete with respect to a probability measure $\mathbb{P}$ on $(\Omega,\mathcal{F})$ if
1. $\mathcal{F}$ is complete with respect to $\mathbb{P}$
2. If $A\in\mathcal{F}$ and $\mathbb{P}(A) = 0$ then $A\in\mathcal{F}_0$

Since the $\sigma$-algebras in $\mathscr{F}$ are increasing in $t\in T$, it follows that if $A\in\mathcal{F}$ is a null event, i.e. $\mathbb{P}(A) = 0$, or an almost certain event, i.e. $\mathbb{P}(A) = 1$, then $A\in\mathcal{F}_t$ for every $t\in T$.
</MathBox>

<MathBox title='Completion of a filtration' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration on the probability space $(\Omega,\mathcal{F},\mathbb{P})$. Let $\mathcal{F}_t^\mathbb{P} = \sigma(\mathcal{F}_t\cup\mathcal{N})$ for $t\in T$ where $\mathcal{N}$ is the null set of $\Omega$. Then $\mathscr{F}^\mathbb{P} = \{\mathcal{F}_t^\mathbb{P}\}_{t\in T}$ is a filtration on $\left(\Omega, \mathcal{F}^\mathbb{P} \right)$ that is finer than $\mathscr{F}$ and is complete relative to $\mathbb{P}$.
<details>
<summary>Proof sketch</summary>

If $s,t\in T$ with $s\leq t$ then $\mathcal{F}_s\subseteq\mathcal{F}_t\subseteq\mathcal{F}$ and consequently

$$
  \sigma(\mathcal{F}_s\cup\mathcal{N})\subseteq\sigma(\mathcal{F}_t\cup\mathcal{N})\subseteq\sigma(\mathcal{F}\cup\mathcal{N})
$$

showing that $\mathcal{F}_s^\mathbb{P}\subseteq\mathcal{F}_t^\mathbb{P}\subseteq\mathcal{F}^\mathbb{P}$. The probability measure $\mathbb{P}$ can be extended to $\mathcal{F}^\mathbb{P}$, and hence is defined on $\mathcal{F}_t^\mathbb{P}$ for each $t\in T$. By construction, if $A\in\mathcal{F}^\mathbb{P}$ and $\mathbb{P}(A) = 0$ then $A\in\mathcal{F}_0^\mathbb{P}$ so $\mathscr{F}_0^\mathbb{P}$ is complete with respect to $\mathbb{P}$.
</details>
</MathBox>

<MathBox title='Universal completion' boxType='proposition'>
Let $\mathcal{P}$ denote the collection of probability measures on $(\Omega,\mathcal{F})$ and suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$. Let $\mathcal{F}* = \bigcap\{\mathcal{F}^\mathbb{P} \}_{\mathbb{P}\in\mathcal{P}}$, and let $\mathscr{F}* = \bigwedge\{\mathscr{F}^\mathbb{P}\}_{\mathbb{P}\in\mathcal{P}}$. Then $\mathscr{F}*$ is a filtration on $(\Omega,\mathcal{F})$, called the universal completion of $\mathscr{F}$.
</MathBox>

### Right continuity

<MathBox title='Proposition' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \;|\; t\in[0,\infty)\}$ is a filtration on $(\Omega,\mathcal{F})$. For $t\in[0,\infty)$ define $\mathcal{F}_{t+} = \bigcap\{\mathcal{F}_s \;|\; s\in(t,\infty)\}$. Then $\mathscr{F}_+ = \{\mathcal{F}_{t+}\}_{t\in T}$ is also a filtration on $(\Omega,\mathcal{F})$ that is finer than $\mathscr{F}$.
<details>
<summary>Proof sketch</summary>

For $t\in[0,\infty)$ note that $\mathcal{F}_{t+}$ is a $\sigma$-algebra because it is the intersection of $\sigma$-algebras, and clearly $\mathcal{F}_{t+}\subseteq\mathcal{F}$. Next, if $s,t\in[0,\infty)$ with $s\leq t$, then

$$
  \mathcal{F}_{s+} = \bigcap\{\mathcal{F}_r \;|\; r\in(s,\infty)\}\subseteq\bigcap\{\mathcal{F}_r \;|\; r\in(t,\infty)\} = \mathcal{F}_{t+}
$$

Finally, for $t\in[0,\infty)$, $\mathcal{F}_t\subseteq\mathcal{F}_s$ for every $s\in(t,\infty)$ so $\mathcal{F}_t\subseteq \bigcap\{\mathcal{F}_s \;|\; s\in(t,\infty)\} = \mathcal{F}_{t+}$.
</details>
</MathBox>

<MathBox title='Right continuous filtration' boxType='definition'>
A filtration $\mathscr{F} = \{\mathcal{F}_t \;|\; t\in[0,\infty)\}$ is *right continuous* if $\mathscr{F}_+ = \mathscr{F}$ so that $\mathcal{F}_{t+} = \mathcal{F}_t$ for every $t\in[0, \infty)$. 
</MathBox>

<MathBox title='Proposition' boxType='proposition'>
If $\mathscr{F} = \{\mathcal{F}_t \;|\; t\in[0,\infty)\}$ is a filtration, then $\mathscr{F}_+$ is a right continuous filtration.
<details>
<summary>Proof sketch</summary>

For $t\in T$

$$
  \mathcal{F}_{t++} = \bigcap\{\mathcal{F}_{s+} \;|\; s\in(t,\infty)\} = \bigcap\left\{\bigcap\{ \mathcal{F}_r \;|\; r\in(s,\infty) \}\;|\; s\in(t,\infty)\right\} = \bigcap\{\mathcal{F}_u \;|\; u\in(t,\infty) \} = \mathcal{F}_{t+}
$$
</details>
</MathBox>

### Stopping time

A topological space $T$ can be extended to include $\infty$ in by definining $T_\infty = T\cup\{\infty\}$. The obvious rule that $t<\infty$ for every $t\in T$ preserves order on $T_\infty$. The topology on $T$ can be extended to $T_\infty$ by the rule that for each $s\in T$, the set $\{t\in T_\infty \;|\; t>s\}$ is an open neighbourhood of $\infty$. This makes $T_\infty$ a one-point compactification of $T$. The extended space $T_\infty$ can be made measurable by giving it the Borel $\sigma$-algebra generated by the extended topology of $T_\infty$.

<MathBox title='Random time' boxType='definition'>
Let $(\Omega,\mathcal{F})$ be a sample space and $(T_\infty, \mathcal{T}_\infty)$ a time space where $T_\infty = T\cup\{\infty\}$. A random variable $\tau:\Omega\to T_\infty$ taking values in $T_\infty$ is called a random time. 
</MathBox>

<MathBox title='Stopping time' boxType='definition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$. A random time $\tau$ is a stopping time relative to $\mathscr{F}$ if $\{\tau\leq t\}\in\mathcal{F}_t$ for each $t\in T$. Equivalently, $\tau$ is a stopping time relative to $\mathscr{F}$ if $\{\tau > t\}\in\mathcal{F}_t$ for each $t\in T$ since $\{\tau\leq t\}^c = \{\tau > t\}$.
</MathBox>

<MathBox title='Inheritance property of stopping time' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ and $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ are filtrations on $(\Omega,\mathcal{F})$ and that $\mathscr{G}$ is finer than $\mathscr{F}$. If a random time $\tau$ is a stopping time relative to $\mathscr{F}$ then $\tau$ is a stopping time relative to $\mathscr{G}$.
<details>
<summary>Proof</summary>

For $t\in T$, then $\{\tau\leq t\}\in\mathcal{F}_t$ and hence $\{\tau\leq t\}\in\mathcal{G}_t$ since $\mathcal{F}_t\subseteq\mathcal{G}_t$.
</details>
</MathBox>

<MathBox title='Properties of stopping time' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$, and that $\tau$ is a stopping time relative to $\mathscr{F}$. Then for every $t\in T$
1. $\{\tau < t\}\in\mathcal{F}_t$
2. $\{\tau \geq t\}\in\mathcal{F}_t$
3. $\{\tau = t\}\in\mathcal{F}_t$
<details>
<summary>Proof</summary>

1. Suppose that $T=\mathbb{N}$. Then $\{\tau< t\} = \{\tau\leq t-1\}\in\mathcal{F}_{t-1}\subseteq\mathcal{F}_t$ for $t\in\mathbb{N}$. Next suppose that $T=[0,\infty)$. Fix $t\in(0,\infty)$ and let $(s_i)_{i\in\mathbb{N}}$ be a strictly increasing sequence in $[0,\infty)$ with $\s_n\xrightarrow{n\to\infty} t$. Then $\{\tau< t\} = \bigcup_{n\in\mathbb{N}} \{\tau\leq s_n\}$. However, $\{\tau\leq s_n\}\in\mathcal{F}_{s_n}\subseteq\mathcal{F}_t$ for each $n$, so $\{\tau < t\}\in\mathcal{F}_t$.
2. Note that $\{\tau\geq t\} = \{\tau< t\}^c$ for $t\in T$. It follows that $\{\tau\geq t\}\in\mathcal{F}_t$
3. For $t\in T$ note that $\{tau = t\} = \{\tau\leq t\}\setminus\{\tau < t\}$. Both events in the set difference are in $\mathcal{F}_t$.
</details>
</MathBox>

<MathBox title='Condition for stopping time on right continuous filtrations' boxType='proposition'>
Suppose that $T=[0,\infty)$ and that $\mathscr{F} = \{\mathcal{F}_t \;|\; t\in[0,\infty)\}$ is a filtration on $(\Omega,\mathcal{F})$. A random time $\tau$ is a stopping time relative to $\mathscr{F}_+$ if and only if $\{\tau< t\}\in\mathcal{F}_t$ for every $t\in[0,\infty)$.

If $\mathscr{F}$ is right-continuous, then $\tau$ is a stopping time relative to $\mathscr{F}$ if and only if $\{\tau<t\}\in\mathcal{F}_t$ for every $t\in[0,\infty)$.
<details>
<summary>Proof</summary>

We need to show that $\{\tau\leq t\}\in\mathcal{F}_{t+}$ for every $t\in[0,\infty)$ if and only if $\{\tau< t\}\in\mathcal{F}_t$ for every $t\in[0,\infty)$. Suppose first that $\tau$ is a stopping time relative to $\mathscr{F}$. Fix $t\in[0,\infty)$ and let $(t_n)_{n\in\mathbb{N}}$ be a strictly decreasing sequence in $[0,\infty)$ with $t_n \xrightarrow{n\to\infty} t$. Then for each $k\in\mathbb{N}$, we have $\{\tau\leq t\} = \bigcap_{n=k}^\infty \{\tau < t_n\}$. If $s> t$ then there exists $k\in\mathbb{N}$ such that $t_n < s$ for each $n\geq k$. Therefore $\{\tau\leq t_n\}\in\mathcal{F}_{t_n}\subseteq\mathcal{F}_s$ for $n\geq k$, and it follows that $\{\tau\leq t\}\in\mathcal{F}_s$. Since this is true for every $s> t$ it follows that $\{\tau, t\}\in\mathcal{F}_{t+}$.

Conversely, suppose that $\{\tau\leq t\}\in\mathcal{F}_{t+}$ for every $t\in[0,\infty)$. Fix $t\in(0,\infty)$ and let $(t_n)_{n\in\mathbb{N}}$ be a strictly increasing sequence in $(0,\infty)$ with $t_n\xrightarrow{n\to\infty}t$. Then $\bigcup_{n\in\mathbb{N}}\{\tau\leq t_n\} = {\tau<t\}$. However for every $n\in\mathbb{N}$

$$
  \{\tau\leq t_n\}\in\mathcal{F}_{t_n +} = \bigcap\{\mathcal{F}_s \;|\; s\in(t_n, t)\}\subseteq\mathcal{F}_t
$$

Hence $\{\tau<t\}\in\mathcal{F}_t$.
</details>
</MathBox>

<MathBox title='Condition for stopping time on discrete filtrations' boxType='proposition'>
Suppose that $T=\mathbb{N}$ and that $\mathscr{F} = \{\mathcal{F}_n \}_{n\in\mathbb{N}}$ is a filtration on $(\Omega,\mathcal{F})$. A random time $\tau$ is a stopping time relative to $\mathscr{F}$ if and only if $\{\tau = t\}\in\mathcal{F}_n$ for every $n\in\mathbb{N}$.
<details>
<summary>Proof</summary>

If $\tau$ is a stopping time then by previous results, $\{\tau = t\}\in\mathcal{F}_n$ for every $n\in\mathbb{N}$. Conversely, suppose that this condition holds. For $n\in\mathbb{N}$, then $\{\tau\leq n\} = \bigcup_{k=0}^n \{\tau = k\}$. However, $\{\tau = k\}\in\mathcal{F}_k\subseteq\mathcal{F}_n$ for $k\in\{0,1,\dots,n\}$ so $\{\tau\leq n\}\in\mathcal{F}_n$.
</details>
</MathBox>

#### $\sigma$-algebra

<MathBox title='$\sigma$-algebra of a stopping time' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\tau$ is a stopping time relative to $\mathscr{F}$. Define $\mathcal{F}_\tau = \{A\in\mathcal{F} \;|\; A\cap\{\tau\leq t\}\in\mathcal{F}_t\;\forall t\in T\}$. Then $\mathcal{F}_\tau$ is a $\sigma$-algebra.
<details>
<summary>Proof</summary>

First $\Omega\in\mathcal{F}_\tau$ since $\Omega\cap\{\tau\leq t\}\in\mathcal{F}_t$ for $t\in T$. If $A\in\mathcal{F}_\tau$, then $A^c\cap\{\tau\leq t\} = \{\tau\leq t\}\setminus(A\cap\{\tau\leq t\})\in\mathcal{F}_t$ for $t\in T$. Finally, suppose that $A_i\in\mathcal{F}_\tau$ for $i$ in a countable index set $I$, then $\left(\bigcup_{i\in I} A_i \right)\cap\{\tau\leq t\} = \bigcup_{i\in I} (A_i \cap \{\tau\leq t\})\in\mathcal{F}_t$ for $t\in T$.
</details>
</MathBox>

<MathBox title='Proposition' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$. Fix $s\in T$ and define $\tau(\omega) = s$ for all $\omega\in\Omega$. Then $\mathcal{F}_\tau = \mathcal{F}_s$
<details>
<summary>Proof</summary>

Suppose that $A\in\mathcal{F}_s$. Then $A\in\mathcal{F}$ and for $t\in T$ we have $A\cap\{\tau\leq t\}=A$ if $s\leq t$ and $A\cap\{\tau\leq t\}=\emptyset$ if $s>t$. In either case, $A\cap\{\tau\leq t\}\in\mathcal{F}_t$ and hence $A\in\mathcal{F}_\tau$. Conversely, suppose that $A\in\mathcal{F}_\tau$. Then $A = A\cap\{\tau\leq s\}\in\mathcal{F}_s$.
</details>
</MathBox>

<MathBox title='Measurability of stopping time' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\tau$ is a stopping time relative to $\mathscr{F}$. Define $\mathcal{F}_\tau = \{A\in\mathcal{F} \;|\; A\cap\{\tau\leq t\}\in\mathcal{F}_t\;\forall t\in T\}$. Then $\tau$ is measurable with respect to $\mathcal{F}_\tau$.
<details>
<summary>Proof</summary>

If suffices to show that $\{\tau\leq s\}\in\mathcal{F}_\tau$ for each $s\in T$. For $s,t\in T$

$$
  \{\tau\leq t\}\cap\{\tau\leq s\} = \{\tau\leq s\wedge t\}\in\mathcal{F}_{s\wedge t}\subseteq\mathcal{F}_t
$$
</details>
</MathBox>

<MathBox title='Proposition' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\tau$ is a stopping time relative to $\mathscr{F}$. Define $\mathcal{F}_\tau = \{A\in\mathcal{F} \;|\; A\cap\{\tau\leq t\}\in\mathcal{F}_t\;\forall t\in T\}$. If $A\in\mathcal{F}_\tau$ then for $t\in T$
1. $A\cap\{\tau\leq T\}\in\mathcal{F}_t$
2. $A\cap\{\tau = T\}\in\mathcal{F}_t$
<details>
<summary>Proof</summary>

1. By definition $A\cap\{\tau\leq t\}\in\mathcal{F}_t$. However $\{\tau< t\}\subseteq\{\tau\leq t\}$ and $\{\tau<t\}\in\mathcal{F}_t$. Hence $A\cap\{\tau<t\}=A\cap\{\tau\leq t\}\cap\{\tau<t\}\in\mathcal{F}_t$
2. Similarly, $\{\tau = t\}\subseteq\{\tau\in t\}$ and $\{\tau = t \}\in\mathcal{F}_t$. Hence $A\cap\{\tau= t\} = A\cap\{\tau\leq t\}\cap\{\tau= t\}\in\mathcal{F}_t$.
</details>
</MathBox>

<MathBox title='Inheritance property' boxType='proposition'>
Suppose that $\mathscr{F}=\{\mathcal{F}_t \}_{t\in T}$ and $\mathscr{G}=\{\mathcal{G}_t \}_{t\in T}$ are filtrations on $(\Omega,\mathcal{F})$ and that $\mathscr{G}$ is finer than $\mathscr{F}$. If $\tau$ is a stopping time relative to $\mathscr{F}$, then $\mathcal{F}_\tau\subseteq\mathcal{G}_\tau$. 
<details>
<summary>Proof</summary>

From previous results, $\tau$ is also a stopping time relative to $\mathscr{G}$. If $A\in\mathcal{F}_\tau$ then for $t\in T$ we have $A\cap\{\tau\leq t\}\in\mathcal{F}_t\subseteq\mathcal{G}_t$, so $A\in\mathcal{G}_\tau$.
</details>
</MathBox>

<MathBox title='Ordering property' boxType='proposition'>
Suppose that $\mathscr{F}=\{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\rho$ and $\tau$ are stopping times relative to $\mathscr{F}$ with $\rho\leq\tau$. Then $\mathcal{F}_\rho\subseteq\mathcal{F}_\tau$. 
<details>
<summary>Proof</summary>

Suppose that $A\in\mathcal{F}_\rho$ and $t\in T$. Note that $\{\rho\leq t\}\subseteq\{\tau\leq t\}$. By definition $A\cap\{\rho\leq t\}\in\mathcal{F}_t$ and $\{\tau\leq t\}\in\mathcal{F}_t$. Hence $A\cap\{\tau\leq t\} = A\cap\{\rho\cap t\}\cap\{\tau\leq t\}\in\mathcal{F}_t$ so $A\in\mathcal{F}_\tau$.
</details>
</MathBox>

<MathBox title='Proposition' boxType='proposition'>
Suppose that $\mathscr{F}=\{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\rho$ and $\tau$ are stopping times relative to $\mathscr{F}$ with $\rho\leq\tau$. Then each of the following events is in $\mathcal{F}_\tau$ and $\mathcal{F}_\rho$
1. $\{\rho<\tau\}$
2. $\{\rho=\tau\}$
3. $\{\rho>\tau\}$
4. $\{\rho\leq\tau\}$
5. $\{\rho<\geq\tau\}$
<details>
<summary>Proof</summary>

For simplicity let $T=\mathbb{N}$
1. Let $t\in T$, then

$$
  \{\rho\leq\tau\}\cap\{\tau\leq t\} = \bigcup_{n=0}^t \bigcup_{k=0}^{n-1} \{\tau = n,\rho = k\}
$$

Each event in the union is in $\mathcal{F}_t$
2. Let $t\in T$, then

$$
  \{\rho=\tau\}\cap\{\tau\leq t\} = \bigcup_{n=0}^t \{\rho = n,\tau = k\}
$$

Each event in the union is in $\mathcal{F}_t$
3. This follows from symmetry by reversing $\{\rho<\tau\}$
4. Note that $\{\rho\leq\tau\} = \{\rho<\tau\}\cup\{\rho=\tau\}\in\mathcal{F}_\tau$
5. Note that $\{\rho\geq\tau\} = \{\rho>\tau\}\cup\{\rho=\tau\}\in\mathcal{F}_\tau$
</details>
</MathBox>

<MathBox title='Stopped filtration' boxType='proposition'>
Suppose that $\mathscr{F}=\{\mathcal{F}_t \}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\tau$ is a stopping time for $\mathscr{F}$. For $t\in T$ define $\mathcal{F}_t^\tau = \mathcal{F}_{t\wedge\tau}$. Then $\mathscr{F}^\tau = \{\mathcal{F}_t^\tau\}_{t\in T}$ is a filtration coarser than $\mathscr{F}$.
<details>
<summary>Proof</summary>

The random time $t\wedge\tau$ is a stopping time for each $t\in T$ by previous results, so $\mathcal{F}_t^\tau$ is a sub $\sigma$-algebra of $\mathcal{F}$. If $t\in T$, then by definition $A\in\mathcal{F}_t^\tau$ if and only if $A\cap\{t\wedge\tau\leq r\}\in\mathcal{F}_r$ for every $r\in T$. However, for $r\in T$, then $\{t\wedge\tau\leq r\} = \Omega$ if $r\geq t$ and $\{t\wedge\tau\leq r\}=\{\tau\leq r\}$ if $r<t$. Hence $A\in\mathcal{F}_t^\tau$ if and only if $A\cap\{\tau< r\}\in\mathcal{F}_r$ for $r<t$ and $A\in\mathcal{F}_t$. So in particular, $\mathscr{F}^\tau$ is coarser than $\mathscr{F}$. Further, suppose that $s,t\in T$ with $s\leq t$ and that $A\in\mathcal{F}_s^\tau$. Let $r\in T$. If $r<s$ then $A\cap\{\tau\leq r\}\in\mathcal{F}_r$. If $s\leq r< t$, then $A\in\mathcal{F}_s\subseteq\mathcal{F}_r$ and $\{\tau\leq r\}\in\mathcal{F}_r$ so again $A\cap\{\tau\leq r\}\in\mathcal{F}_r$. Finally if $r\geq t$ then $A\in\mathcal{F}_s\subseteq\mathcal{F}_t$. Hence $A\in\mathcal{F}_t^\tau$.
</details>
</MathBox>

#### Construction

<MathBox title='Trivial stopping time' boxType='proposition'>
Suppose $s\in T_\infty$ and that $\tau(\omega) = s$ for all $\omega\in\Omega$. Then $\tau$ is a stopping time relative to any filtration on $(\Omega,\mathcal{F})$. 
<details>
<summary>Proof</summary>

For $t\in T$ note that $\{\tau\leq t\} = \Omega$ if $s\leq t$ and $\{\tau<t\} = \emptyset$ if $s>t$. 
</details>
</MathBox>

<MathBox title='Combinations of stopping time' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $\tau_1$ and $\tau_2$ are stopping times relative to $\mathscr{F}$. Then each of the following is also a stopping time relative to $\mathscr{F}$
1. $\tau_1\vee\tau_2 = \max\{\tau_1,\tau_2\}$
2. $\tau_1\wedge\tau_2 = \min\{\tau_1,\tau_2\}$
3. $\tau_1+\tau_2$

It follows that if $(\tau_i)_{i=1}^{n\in\mathbb{N}}$ is a finite sequence of stopping times relative to $\mathscr{F}$, then each of the following is also a stopping time relative to $\mathscr{F}$:
1. $\bigvee_{i=1}^n \tau_i$
2. $\bigwedge_{i=1}^n \tau_i$
3. $\sum_{i=1}^n \tau_i$
<details>
<summary>Proof</summary>

1. Note that $\{\tau_1 \vee \tau_2 \leq t \} = \{\tau_1\leq t\}\cap\{\tau_2\leq t\}\in\mathcal{F}_t$ for $t\in T$.
2. Note that $\{\tau_1 \wedge \tau_2 \leq t \} = \{\tau_1 > t\}\cap\{\tau_2 > t\}\in\mathcal{F}_t$ for $t\in T$.
3. Suppose first that $T=\mathbb{N}$. Then $\{\tau_1 + \tau_2 \leq t\} = \bigcup_{n=0}^t \{\tau_1 = n\}\cap\{\tau_2 \leq t-n\}$. However, for $n\leq t$, then $\{\tau_1 = n\}\in\mathcal{F}_n\subseteq\mathcal{F}_t$ and $\{\tau_2\leq t-n\}\in\mathcal{F}_{t-n}\subseteq\mathcal{F}_t$. Hence $\{\tau_1 + \tau_2\leq t\}\in\mathcal{F}_t$. Suppose instead that $T=[0,\infty)$ and $t\in T$. Then $\tau_1 + \tau_2 > t$ if and only if either $\tau_1\leq t$ and $\tau_2 > t - \tau_2$ or $\tau_1 > t$. Clearly $\{\tau_1>t\}\in\mathcal{F}_t$, so it remains show that the first event is also in $\mathcal{F}_t$. Note that $\tau_1\leq t$ and $\tau_2 > t-\tau_1$ if and only if there exists a rational $q\in[0, t]$ such that $q\leq\tau_1\leq t$ and $\tau_2\geq t-q$. Each of these events is in $\mathcal{F}_t$ and hence so is the union of events over the countable collection of rationals $q\in[0, t]$.
</details>
</MathBox>

<MathBox title='Countable combinations of stopping time' boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration on $(\Omega,\mathcal{F})$ and that $(\tau_n)_{n\in\mathbb{N}}$ is a sequence of stopping times relative to $\mathscr{F}$. Then $\sup\{\tau_n\}_{n\in\mathbb{N}}$ is also a stopping time relative to $\mathscr{F}$.

If $(\tau_n)_{n\in\mathbb{N}}$ is an increasing sequence of stopping times relative to $\mathscr{F}$, then $\lim_{n\to\infty}\tau_n = \sup\{\tau_n\}_{n\in\mathbb{N}}$ is a stopping time relative to $\mathscr{F}$.
<details>
<summary>Proof</summary>

Let $\tau = \sup\{\tau_n\}_{n\in\mathbb{N}}$. Note that $\tau\in T_\infty$ is a random time. For $t\in T$ then $\{\tau\leq t\} = \bigcap_{n\in\mathbb{N}}\{\tau_n\leq t\}$. However, $\{\tau_n\leq t\}\in\mathcal{F}_t$ for each $n\in\mathbb{N}$ and hence the intersection is also in $\mathcal{F}_t$. 
</details>
</MathBox>

<MathBox title='Stopping times of right-continuous filtrations' boxType='proposition'>
Let $T=[0,\infty)$ and suppose that $\mathscr{F} = \{\mathcal{F}_t \;|\; t\in[0,\infty)\}$ is a filtration on $(\Omega,\mathcal{F})$. If $(\tau_n)_{n\in\mathbb{N}}$ is a sequence of stopping times relative to $\mathscr{F}$, then each of the following is a stopping time relative to $\mathscr{F}_+$
1. $\inf\{\tau_n\}_{n\in\mathbb{N}}$
2. $\liminf_{n\to\infty}\tau_n$
3. $\limsup_{n\to\infty}\tau_n$
<details>
<summary>Proof</summary>

1. Let $\tau = \inf\{\tau_n\}_{n\in\mathbb{N}}$. Then $\{\tau\geq t\} = \bigcap_{n\in\mathbb{N}} \{\tau_n\geq t\}\in\mathcal{F}_t$ for $t\in T$. Hence by previous results, $\tau$ is a stopping time relative to $\mathscr{F}_+$.
2. Note that $\liminf_{n\to\infty}\tau_n = \sup\{\inf\{\tau_k \;|\; k\geq n\}\;|\; n\in\mathbb{N}\}$ and so this is a stopping time relative to $\mathscr{F}_+$ by part ($1$) and the result above on supremums.
3. Note that $\limsup_{n\to\infty}\tau_n = \inf\{\sup\{\tau_k \;\; k\geq n\}\;\; n\in\mathbb{N}\}$, and so this is a stopping time relative to $\mathscr{F}_+$.
</details>
</MathBox>

## Events

<MathBox title='Event' boxType='definition'>
Let $(\Omega, \mathcal{A}, \mathbb{P})$ be a probability space. An event is a subset $A\subseteq\Omega$. If $\omega\in\Omega$ is the outcome of a random experiment, then $A$ is said to occur if $\omega\in A$. Otherwise, if $\omega\notin A$, then $A$ is said to not occur. In terms of the indicator function $\mathbf{1}_A:\Omega\to\{0, 1\}$, this is written

$$
  \mathbf{1}_A(\omega) = \begin{cases} 1,\quad \omega\in A \\ 0,\quad \omega\notin A \end{cases}
$$
</MathBox>

<MathBox title='Algebra of events' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and consider the events $A, B\in\mathcal{F}$. Then
1. $A\subseteq B$ if and only if the occurence of $A$ implies the occurence of $B$, i.e. $A\subseteq B\iff \mathbf{1}_A\leq \mathbf{1}_B$.
2. $A\cup B$ is the event that occurs if and only if $A$ occurs or $B$ occurs, i.e. $\mathbf{1}_{A\cup B} = 1 - (1 - \mathbf{1}_A)(1 - \mathbf{1}_B) = \max\{\mathbf{1}_A, \mathbf{1}_B\}$.
3. $A\cap B$ is the event that occurs if and only if $A$ occurs and $B$ occurs, i.e. $\mathbf{1}_{A\cap B} = \mathbf{1}_A\mathbf{1}_B = \min\{\mathbf{1}_A, \mathbf{1}_B\}$
4. $A$ and $B$ are disjoint if and only if they are mutually exclusive; they cannot both occur on the same run of experiment.
5. $A^c$ is the event that occurs if and only if $A$ does not occur, i.e $\mathbf{1}_{A^c} = 1 - \mathbf{1}_A$.
6. $A\setminus B$ is the event that occurs if and only if $A$ occurs and $B$ does not occur, i.e. $\mathbf{1}_{A\setminus B} = \mathbf{1}_A(1 - \mathbf{1}_B)$
7. $(A\cap B^c)\cup(B\cap A^c)$ is the event that occurs if and only if one but not both of the given events occur.
8. $(A\cap B)\cup(A^c\cap B^c)$ is the event that occurs if and only if both or neither of the given events occur.
</MathBox>

### Equivalence

<MathBox title='Null and almost sure events' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$  be a probability space. Define the following collections of events
- $\mathcal{N} := \{A\in\mathcal{F}\;|\; \mathbb{P}(A) = 0\}$, the collection of null events
- $\mathcal{M} := \{A\in\mathcal{F}\;|\; \mathbb{P}(A) = 1\}$, the collection of almost sure events
- $\mathcal{D} := \mathcal{N}\cup\mathcal{M} = \{A\in\mathcal{F}\;|\; \mathbb{P}(A) = 0 \lor \mathbb{P}(A) = 1\}$, the collection of essentially deterministic events

The collection of essentially deterministic events is a sub $\sigma$-algebra of $\mathcal{F}$.
</MathBox>

<MathBox title='Equivalence of events' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. Two events $A, B\in\mathcal{F}$ are equivalent if 

$$
\begin{gather*}
  A\Delta B = (A\setminus B)\cup(B\setminus A)\in\mathcal{N} \\
  \iff \mathbb{P}(A\Delta B) = 0 \iff \mathbb{P}(A\setminus B) = \mathbb{P}(A\setminus B) = 0
\end{gather*}
$$

The relation $\equiv$ is a an equivalence relation on $\mathcal{F}$ satisfying for $A,B,C\in\mathcal{F}$
- reflexivity: $A\equiv A$
- symmetry: $A\equiv B\implies B\equiv A$
- transitivity: $A\equiv B\land B\equiv C\implies A\equiv C$
</MathBox>

<MathBox title='Properties of equivalent events' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. The following properties hold for equivalent events
1. If $A, B\in\mathcal{F}$ and $A\equiv B$ then $\mathbb{P}(A) = \mathbb{P}(B)$
2. If $A\equiv B$ then $A^c \equiv B^c$
3. Suppose that $A_i, B_i\in\mathcal{F}$ for $i$ in a countable set $I$. If $A_i\equiv B_i$ for $i\in I$ then
  a. $\bigcup_{i\in I} A_i\equiv \bigcup_{i\in I} B_i$
  b. $\bigcap_{i\in I} A_i\equiv \bigcap_{i\in I} B_i$
4. If $A\in\mathcal{N}$ then $A\equiv B$ if and only if $B\in\mathcal{N}$
5. If $A\in\mathcal{M}$ then $A\equiv B$ if and only if $B\in\mathcal{M}$
</MathBox>

## Completion
<MathBox title='Complete probability space' boxType='definition'>
A probability space $(\Omega,\mathcal{F},\mathbb{P})$ is complete if $A\in\mathcal{N}$ and $B\subseteq A$ implies $B\in\mathcal{F}$ (and hence $B\in\mathcal{N}$).
</MathBox>

<MathBox title='Extended equivalence' boxType='definition'>
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. For $A, B\subseteq\Omega$, define $A\equiv B$ if and only if there exists $N\in\mathcal{N}$ such that $A\Delta B\subseteq N$. The relation $\equiv$ is an equivalence relation on $\mathcal{P}(\Omega)$. 
</MathBox>

<MathBox title='Completion of a probability space' boxType='proposition'>
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. Consider the collection $\mathcal{F}_0 = \{A\subseteq\Omega\;|; A\equiv B\textrm{ for some }B\in\mathcal{F}\}$. For $A\in\mathcal{F}_0$, define $\mathbb{P}_0(A) = \mathbb{P}(B)$ where $B\in\mathcal{F}$ and $A\equiv B$. Then
- $\mathcal{F}_0$ is a $\sigma$-algebra of subsets of $\Omega$ and $\mathcal{F}\subseteq\mathcal{F}_0$
- $\mathbb{P}_0$ is a probability measure on $(\Omega, \mathcal{F}_0)$
- the probability space $(\Omega,\mathcal{F}_0,\mathbb{P}_0)$ is the completion of $(\Omega,\mathcal{F},\mathbb{P})$
</MathBox>

## Random variables

<MathBox title='Random variable' boxType='definition'>
Let $(\Omega, \mathcal{F})$ and $(S, \mathcal{S})$ be event spaces. A measurable function $X: \Omega\to S$ is called a random variable if $\{X\in A \} := X^{-1}[A] = \{ \omega\in\Omega \;|\; X(\omega)\in A \}\in\mathcal{F}$ for all $A\in\mathcal{S}$. For a probability measure $\mathbb{P}:\mathcal{F}\to [0, 1]$ we can define

$$
  \mathbb{P}( X\in A) := \mathbb{P}\left( X^{-1}[A]\right) = \mathbb{P}(\{\omega \in\Omega | X(\omega)\in A\})
$$

The collection of events $\{\{X\in A\}\;|\; A\in\mathcal{S}\}$ is a sub $\sigma$-algebra of $\mathcal{F}$, and is the $\sigma$-algebra generated by $X$, denoted $\sigma(X)$.

Usually we set $\left(S, \mathcal{S}\right) = (\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
</MathBox>

<MathBox title='Properties of random variables' boxType='proposition'>
Consider the random variable $X: \Omega \to \tilde{\Omega}$, then for events $A, B\subseteq \tilde{\Omega}$
1. $\{X\in A\cup B\} = \{X\in A\}\cup\{X\in B\}$
2. $\{X\in A\cap B\} = \{X\in A\}\cap\{X\in B\}$
3. $\{X\in A\setminus B\} = \{X\in A\}\setminus\{X\in B\}$
4. $A\subseteq B\implies \{X\in A\}\subseteq\{X\in B\}$
5. $A\cap B = \emptyset \implies \{X\in A\}\cap\{X\in B\}=\emptyset$ (disjoint)
</MathBox>

### Convergence

In the following discussion, Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space induced from a metric space $(\Omega, d)$. In this setting, $\mathcal{F}$ is the Borel $\sigma$-algebra generated by the topology of $\Omega$.

<MathBox title='Convergence of random variables (almost surely)' boxType='definition'>
Suppose that $(X_n)_{n\in\mathbb{N}}$ is a sequence of random variables with domain in $\Omega$. We say that $X_n \xrightarrow{n\to\infty} X$ with *probability* $1$ if the event that corresponding to this convergence has probability $1$ (almost surely), i.e.

$$
  \mathbb{P}\{\omega\in\Omega\;|\; X_n(\omega)\xrightarrow{n\to\infty} X(\omega)\} = 1
$$

Convergence with probability $1$ (almost surely) is called strong convergence. A weaker convergence criteria is that $X_n\xrightarrow[\textrm{i.p.}]{n\to\infty} X$ *in probability* if

$$
  \forall\epsilon>0: \mathbb{P}\left[d(X_n,X)>\epsilon\right]\xrightarrow{n\to\infty} 0
$$
<details>
<summary>Details</summary>

We need to verify that the convergence $X_n\xrightarrow{n\to\infty} X$ defines a valid event. The easiest way is to check if the complement is a valid event. Note that $X_n$ does not converge to $X$ as $n\to\infty$ if and only if the metric $\lim_{n\to\infty} d(X_n, X)>\epsilon$ for some $\epsilon>0$. Moreover, to construct a countable set we may choose rational $\epsilon\in\mathbb{Q}_+$ giving

$$
  \{X_n\xrightarrow{n\to\infty} X}^c = \bigcup_{\epsilon\in\mathbb{Q}_+}\limsup_{n\to\infty}\{d(X_n, X)>\epsilon \}
$$

Since $X_n$ and $X$ are random variables, the set $\{d(X_n, X)>\epsilon\}$ is an event for each $\epsilon\in\mathbb{Q}_+$ and $n\in\mathbb{N}$. Next, the limit superior of a sequence of events is an event. Finally, a countable union of events is an event.

Equivalently, the convergence statement can be rewritten as $\mathbb{P}(X_n\xrightarrow{n\to\infty} X) = 1$ iff

$$
  \mathbb\left(\bigcup_{\epsilon\in\mathbb{Q}_+} \{d(X_n, X)>\epsilon\;\forall n\in\mathbb{N}\} \right) = 0
$$
</details>
</MathBox>

<MathBox title='Criterion for almost surely convergence' boxType='proposition'>
Suppose that $(X_n)_{n\in\mathbb{N}}$ is a sequence of random variables with domain in $\Omega$. If for every $\epsilon > 0$

$$
  \sum_{n\in\mathbb{N}}\mathbb{P}\left[d(X_n, X)>\epsilon \right]
$$

then $X_n\xrightarrow{n\to\infty}X$ almost surely.
<details>
<summary>Details</summary>

By the first Borel-Cantelli lemma, if

$$
  \sum_{n\in\mathbb{N}}\mathbb{P}\left[d(X_n, X)>\epsilon \right]
$$

then

$$
  \mathbb{P}\left[d(X_n, X)>\epsilon\;\forall n\in\mathbb{N}\right] = 0
$$

this is equivalent with that

$$
  \mathbb\left(\bigcup_{\epsilon\in\mathbb{Q}_+} \{d(X_n, X)>\epsilon\;\forall n\in\mathbb{N}\} \right) = 0
$$

By Boole's inequality, a countable union of events has probability $0$ if and only if every event in the union has probability $0$.
</details>
</MathBox>

<MathBox title='Proposition' boxType='proposition'>
Suppose that $(X_n)_{n\in\mathbb{N}}$ is a sequence of random variables with domain in $\Omega$. If $X_n\xrightarrow{n\to\infty}X$ in probability, then there exists a subsequence $(n_k)_{k\in\mathbb{N}}$ of $\mathbb{N}$ such that $X_{n_k}\xrightarrow{k\to\infty}X$ almost surely.

<details>
<summary>Details</summary>

Suppose that $X_n\xrightarrow{n\to\infty}X$ in probability. Then for each $k\in\mathbb{N}$ there exists $n_k\in\mathbb{N}$ such that 

$$
  \mathbb{P}\left[ d(X_{n_k}, X)>\frac{1}{k} \right]<\frac{1}{k^2}
$$

We can make the choices so that $n_k < n_{k+1}$ for each $k$. It follows that $\sum_{k=1}^\infty\mathbb{P}\left[d(X_n, X)>0 \right]<\infty$ for every $\epsilon>0$ and by the criterion for almost surely convergence we conclude that $X_{n_k}\xrightarrow{n\to\infty}X$ with probability $1$.
</details>
</MathBox>

### Equivalence

<MathBox title='Equivalence of random variables' boxType='definition'>
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $(S,\mathcal{S})$ be a sample space. Two random variables $X, Y:S\to\tilde T$ are equivalent if $\mathbb{P}(X=Y)=1$, denoted $X\equiv Y$. The relation $\equiv$ is a an equivalence relation on $\mathcal{F}$ satisfying for $X,Y,Z:S\to T$
- reflexivity: $X\equiv X$
- symmetry: $X\equiv Y\implies Y\equiv X$
- transitivity: $X\equiv Y\land Y\equiv Z\implies X\equiv Z$
</MathBox>

<MathBox title='Properties of equivalent random variables' boxType='proposition'>
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $(S,\mathcal{S})$ be a sample space. Suppose that $X, Y:\Omega\to S$ are equivalent, i.e. $X\equiv Y$. Then
- $\{X\in A\}\equiv\{Y\in A\}$ for every $A\in \mathcal{S}$
- $X$ and $Y$ have the same probability distribution on $(S, \mathcal{S}$

Consider a third sample space $(U,\mathcal{U})$ and suppose that $g:T\to U$ is measurable. If $X\equiv Y$ then $g(X)\equiv g(Y)$.
</MathBox>

# Stochastic processes

In the following discussion, let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability, $(S,\mathcal{S})$ a state space and $(T,\mathcal{T})$ an index space.

<MathBox title='Stochastic process' boxType='definition'>
A stochastic (random) process on $(\Omega,\mathcal{F},\mathbb{P})$ with state space $(S,\mathcal{S})$ and index space $(T,\mathcal{T})$ is a collection of random variables $\mathbf{X}:=\{X_t: \Omega\to S\}_{t\in T}$, forming a function $\mathbf{X}:\Omega\times T\to S$. A stochastic process $\mathbf{X}$ is measurable if the function $\mathbf{X}:\Omega\times T$ given by $(\omega, t)\mapsto X_t(\omega)$ is measurable with respect to $\mathcal{F}\otimes\mathcal{T}$ and $\mathcal{S}$. If $T$ is countable, then $\mathcal{T} = \mathcal{P}(T)$, and it follows that $\mathbf{X}$ is measurable. Often $X_t$ is written $X(t)$ for convenience.

For the state space, $S$ is usually a topological space and $\mathcal{S}$ the Borel $\sigma$-algebra generated by the topology of $S$. A standard set of assumptions is that the topology is locally compact, Hausdorff, and has a countable base. The index set $T$ usually represents time. For a discrete-time process, $T\subseteq\mathbb{N}$ and $\mathcal{T} = \mathcal{P}(T)$. For a continuous-time process, $T\subseteq[0,\infty)$ and $\mathcal{T}\subseteq\mathcal{B}(\mathbb{R})$, the Borel $\sigma$-algebra generated by the standard Euclidean topology.

The filtration $\mathscr{F}^0:=\left\{\mathcal{F}_t^0 = \sigma\{X_s \;|\; s\in T,s\leq t\} \right\}_{t\in T}$ is the natural filtration associated with $\mathbf{X}$.
</MathBox>

<MathBox title='Adapted process' boxType='definition'>
A stochastic process $\mathbf{X} = \{X_t\}_{t\in T}$ on $(\Omega,\mathcal{F})$ is adapted to a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ on $(\Omega,\mathcal{F})$ if $X_t$ is measurable with respect to $\mathcal{F}_t$ for each $t\in T$. Equivalently, $\mathbf{X}$ is adapted to $\mathscr{F}$ if $\mathscr{F}$ is finer than $\mathscr{F}^0 $, the natural filtration associated with $\mathbf{X}$. That is, $\sigma\{X_s\;|\; s\in T, s\leq t\} \subseteq \mathcal{F}_t$ for each $t\in T$. The natural filtration $\mathscr{F}^0$ is the therefore the coarsest filtration to which $\mathbf{X}$ is adapted.
</MathBox>

<MathBox title='Predictable process' boxType='definition'>
Let $T=\mathbb{N}$. A discrete stochastic process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ on $(\Omega,\mathcal{F})$ is predictable by the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ if $X_{n+1}$ is measurable with respect to $\mathcal{F}_n$ for all $n\in\mathbb{N}$. If $\mathbf{X}$ is predictable by $\mathscr{F}$ then $\mathbf{X}$ is also adapted to $\mathscr{F}$.
</MathBox>

<MathBox title='Progressively measurable process' boxType='definition'>
Let $T_t = \{s\in T\;|\; s\leq t\}$ for $t\in T$ and let $\mathcal{T}_t = \{A\cap T_t \;|\; A\in\mathcal{T}\}$ be the corresponding induced $\sigma$-algebra. Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a stochastic process on $(\Omega,\mathcal{F})$, and that $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is a filtration. Then $\mathbf{X}$ is progressively measurable relative to $\mathscr{F}$ if $\mathbf{X}:\Omega\times T_t \to S$ is measurable with respect to $\mathcal{F}_t\otimes\mathcal{T}_t$ and $\mathcal{S}$ for each $t\in T$.
</MathBox>

<MathBox title='Properties of pregressively measurable processes' boxType='proposition'>
Let $\mathbf{X} = \{X_t\}_{t\in T}$ be a stochastic process with sample space $(\Omega,\mathcal{F})$ and state space $(S,\mathcal{S})$, and let $\mathscr{F}=\{\mathcal{F}_t\}_{t\in T}$ be a filtration. If $\mathbf{X}$ is progressively measurable relative to $\mathscr{F}$ then
1. $\mathbf{X}$ is measurable
2. $\mathbf{X}$ is adapted to $\mathscr{F}$
<details>
<summary>Details</summary>

1. If $A\in\mathcal{S}$ then

$$
  \mathbf{X}^{-1}(A) = \{(\omega, t)\in\Omega\times T \;|\; X_t(\omega)\in A \} = \bigcup_{n\in\mathbb{N}}\{(\omega,t)\in\Omega\times T_n \;|\; X_t(\omega)\in A \}
$$

By assumption, the $n$-th term in the union is in $\mathcal{F}\otimes\mathcal{T}_n\subseteq\mathcal{F}\otimes\mathcal{T}$, so the union is in $\mathcal{F}\otimes\mathcal{T}$.
2. Suppose that $t\in T$. Then $\mathbf{X}:\Omega\times T_t\to S$ is measurable with respect to $\mathcal{F}_t\otimes\mathcal{T}_t$ and $\mathcal{S}$. However, $X_t:\Omega\to S$ is just the cross section of this function at $t$ and thus is measurable with respect to $\mathcal{F}_t$ and $\mathcal{S}$.
</details>
</MathBox>

<MathBox title='Right continuous processes are progressively measurable to the natural filtration' boxType='proposition'>
Suppose that the sample space $(S,\mathcal{S})$ is a Hausdorff topological space that is locally compact and has a countable base. Consider a right continuous stochastic process $\mathbf{X} = \{X_t \;|\; t\in[0,\infty)\}$. Then $\mathbf{X}$ is progressively measurable to the natural filtration $\mathscr{F}^0$.
</MathBox>

## Equivalence

<MathBox title='Equivalence in distribution' boxType='definition'>
Two stochastic processes $\mathbf{X} = \{X_t\}_{t\in T}$ and $\mathbf{Y} = \{Y_t\}_{t\in T}$ with state space $(S,\mathcal{S})$ and index set $T$ are equivalent *in distribution* if they have the same finite dimensional distributions. This defines an equivalence relation on the collection of stochastic processes with this state space and index set. That is, if $\mathbf{X}$, $\mathbf{Y}$ and $\mathbf{Z}$ are such processes then
- reflexivity: $\mathbf{X}$ is equivalent in distribution with $\mathbf{X}$
- symmetry: if $\mathbf{X}$ is equivalent in distribution with $\mathbf{Y}$, then $\mathbf{Y}$ is equivalent in distribution with $\mathbf{X}$
- transitivity: if $\mathbf{X}$ is equivalent in distribution with $\mathbf{Y}$, and $\mathbf{Y}$ is equivalent in distribution with $\mathbf{Z}$, then $\mathbf{X}$ is equivalent in distribution with $\mathbf{Z}$

Stochastic processes equivalent in distribution share the same sample space and index set, and need not be defined on the same probability space.
</MathBox>

<MathBox title='Version of equivalence' boxType='definition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ and $\mathbf{Y} = \{Y_t\}_{t\in T}$ are stochastic processes defined on the same probability space $(\Omega,\mathcal{F},\mathbb{P})$ and both with state space $(S,\mathcal{S})$ and index set $T$. Then $\mathbf{Y}$ is a *version of* $\mathbf{X}$ if $Y_t$ is equivalent to $X_t$, i.e. $\mathbb{P}(X_t = Y_t = 1)$ for every $t\in T$. This defines an equivalence relation on the collection of stochastic processes on the same probability space and with this state space and index set. That is, if $\mathbf{X}$, $\mathbf{Y}$ and $\mathbf{Z}$ are such processes then
- reflexivity: $\mathbf{X}$ is a version of $\mathbf{X}$
- symmetry: if $\mathbf{X}$ is a version of $\mathbf{Y}$, then $\mathbf{Y}$ is a version of $\mathbf{X}$
- transitivity: if $\mathbf{X}$ is a version of $\mathbf{Y}$, and $\mathbf{Y}$ is a version of $\mathbf{Z}$, then $\mathbf{X}$ is a version of $\mathbf{Z}$
</MathBox>

<MathBox title='Indistinguishable from equivalence' boxType='definition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ and $\mathbf{Y} = \{Y_t\}_{t\in T}$ are stochastic processes defined on the same probability space $(\Omega,\mathcal{F},\mathbb{P})$ and both with state space $(S,\mathcal{S})$ and index space $(T, \mathcal{T})$. Then $\mathbf{X}$ is *Indistinguishable from* $\mathbf{X}$ if $\mathbb{P}(X_t = Y_t = 1\;\forall t\in T)$. This defines an equivalence relation on the collection of stochastic processes on the same probability space and with this state space and index set. That is, if $\mathbf{X}$, $\mathbf{Y}$ and $\mathbf{Z}$ are such processes then
- reflexivity: $\mathbf{X}$ is indistinguishable from $\mathbf{X}$
- symmetry: if $\mathbf{X}$ is indistinguishable from $\mathbf{Y}$, then $\mathbf{Y}$ is indistinguishable from $\mathbf{X}$
- transitivity: if $\mathbf{X}$ is indistinguishable from $\mathbf{Y}$, and $\mathbf{Y}$ is indistinguishable from $\mathbf{Z}$, then $\mathbf{X}$ is indistinguishable from $\mathbf{Z}$

Trivially, if $\mathbf{X}$ is indistinguishable from $\mathbf{Y}$, then $\mathbf{X}$ is a version of $\mathbf{Y}$. The converse is also true if $T$ is countable.
</MathBox>

## Kolmogorov existence theorem
 
<MathBox title='Consistency conditions for probability measures' boxType='definition'>
Suppose that $(S,\mathcal{S})$ is a measurable space and $T$ is an index set. For $n\in\mathbb{N}$, let $T^{(n)}\subseteq T^n$ denote the set of $n$-tuples of distinct elements of an index set $T$, and let $\mathbf{T}=\bigcup_{n\in\mathbb{N}}T^{(n)}$ denote the set of all finite sequences of distinct elements of $T$. If $n\in\mathbb{N}$, $\mathbf{t} = (t_i)_{i=1}^n \in T^{(n)}$ and $\pi$ is a permutation of $\{i\}_{i=1}^n$, let $\mathbf{t}\pi$ denote the elements of $T^{(n)}$ with coordinates $(\mathbf{t}\pi)_i = t_{\pi(i)}$. That is, we permute the coordinates of $\mathbf{t}$ according to $\pi$. If $C\in\mathcal{S}^n$ let

$$
  \pi C = \left\{(x_i)_{i=1}^n \in S^n \;|\; \left(x_{\pi(i)} \right)_{i=1}^n \in C \right\}\in\mathcal{S}^n
$$

If $n>1$, let $\mathbf{t}_-$ denote the vector $(t_i)_{i=1}^{n-1}\in T^{(n-1)}$. 

Suppose that $P_\mathbf{t}$ is a probability measure on $(S^n, \mathcal{S}^n)$ for each $n\in\mathbb{N}$ and $\mathbf{t}\in T^{(n)}$. The collection $\mathcal{P} = \{P_\mathbf{t}\}_{\mathbf{t}\in\mathbf{T}}$ is consistent if
1. $P_{\mathbf{t}\pi}(C) = P_{\mathbf{t}}(\pi C)$ for every $n\in\mathbb{N}$, $\mathbf{t}\in T^{(n)}$, permutation $\pi$ of $\{i\}_{i=1}^n$ and measurable $C\in\mathcal{S}^n$ 
2. $P_{\mathbf{t}_-}(C) = P_\mathbf{t}(C\times S)$ for every $n>1$, $\mathbf{t}\in T^{(n)}$ and measurable $C\in\mathcal{S}^{n-1}$
</MathBox>

<MathBox title='Kolmogorov existence theorem' boxType='theorem'>
If $\mathcal{P}$ is a consistent collection of probability distributions relative to an index set $T$ and a state space $(S,\mathcal{S})$, then there exists a probability space $(\Omega,\mathcal{F},\mathbb{P})$ and a stochastic process $\mathbf{X} = \{X_t\}_{t\in T}$ on this probability space such that $\mathcal{P}$ is the collection of finite dimensional distribution of $\mathbf{X}$.
<details>
<summary>Proof sketch</summary>

Let $\Omega = S^T$ be the set of functions from $T$ to $S$, i.e. the outcomes of $\mathbf{X}$. Let $\mathcal{F} = \mathcal{S}^T$, the product $\sigma$-algebra, generated by sets of the form

$$
  B = \{\omega\in\Omega\;|\; \omega(t)\in A_t \; \forall t\in T}
$$

where $A_t\in\mathcal{S}$ for all $t\in T$ and $A_t = S$ for all but finitely many $t\in T$. Suppose that $A_t = S$ except for $\mathbf{t} = (t_i)_{i=1}^n\in T^{(n)}$. Then we require

$$
  \mathbb{P}(B) = P_\mathbf{t}\left(\prod_{i=1}^n A_{t_i} \right)
$$

Applying Caratheodory's existence theorem and the consistency $\mathcal{P}$ guarantees that $\mathbb{P}$ can be extended to probability measure on all of $\mathcal{F}$. Finally, for $t\in T$ define $X_t:\Omega\to S$ by $X_t(\omega) = \omega(t)$ for $\omega\in\Omega$, so that $X_t$ is simply the coordinate function of index $t$. Hence, we have a stochastic process $\mathbf{X} = \{X_t\}_{t\in T}$ with state space $(S,\mathcal{S})$ defined on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ with $\mathcal{P}$ as the collection of finite dimensional distributions.
</details>
</MathBox>

## Stopping processes

Note that a random time state $X_\tau$ is a random state at random time, and therefore depends on an outcome $\omega\in\Omega$ in two ways, i.e. $X_\{\tau(\omega)\}(\omega)$.

<MathBox title='Random time states are measurable' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a measurable stochastic process on the sample space $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$. If $\tau$ is a finite random time, then $X_\tau$ is measurable. 
<details>
<summary>Proof</summary>

Note that $X_\tau:\Omega\to S$ is the composition of the function $\omega\mapsto(\omega,\tau(\omega))$ from $\Omega$ to $\Omega\times T$ with the function $(\omega, t)\mapsto X_t(\omega)$ from $\Omega\times S$ to $S$. The firs function is measurable because the two coordinate functions are measurable. The second function is measurable by assumption.
</details>
</MathBox>

<MathBox title='Stopped process' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a measurable stochastic process on the sample space $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$. If $\tau$ is a random time, then the process $\mathbf{X}^\tau = \{X_t^\tau\}_{t\in T}$ defined by $X_t^\tau = X_{t\wedge\tau}$ for $t\in T$ is the process $\mathbf{X}$ stopped at $\tau$. 
<details>
<summary>Proof</summary>

For each $t\in T$, note that $t\wedge \tau$ is a finite random time, and hence $X_{t\wedge\tau}$ is measurable by the previous result. Thus $\mathbf{X}^\tau$ is a well-defined stochastic process on $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$.
</details>
</MathBox>

<MathBox title='Stopped processes inherit progressive measurability' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a stochastic process on the sample space $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$, and that $\mathbf{X}$ is progressively measurable with respect to a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ on $(\Omega,\mathcal{F})$. If $\tau$ is a finite stopping time relative to $\mathscr{F}$, then the stopped process $\mathbf{X}^\tau =\{X_t^\tau\}_{t\in T}$ is progressively measurable with respect to the stopped filtration $\mathscr{F}^\tau$. Consequently, $X_\tau$ is measurable with respect to $\mathcal{F}_\tau$.
</MathBox>

<MathBox title='Entry and hitting time' boxType='definition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a stochastic process on the sample space $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$, and let $T_+ = \{t\in T\;|\; t>0\}$ For $A\in\mathcal{S}$, define
1. $\rho_A = \inf\{t\in T\;|\; X_t\in A\}$, the first entry time to $A$
2. $\tau_A = \inf\{t\in T_+ \;|\; X_t\in A\}$, the first hitting time to $A$
</MathBox>

<MathBox title='Stopping times for discrete processes' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a discrete stochastic process on the sample space $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$. If $A\in\mathcal{S}$, then $\tau_A$ and $\rho_A$ are stopping times relative to the natural filtration $\mathscr{F}^0$.
<details>
<summary>Proof</summary>

Let $n\in\mathbb{N}$. Note that $\{\rho_A > n\} = \{X_i \notin A\}_{i=0}^n\in\sigma\{X_i\}_{i=1}^n$. Similarly, $\{\tau_A>n\} = \{X_i \notin A\}_{i=0}^n\subseteq\sigma\{X_i\}_{i=1}^n$
</details>
</MathBox>

<MathBox title='Stopping times for continuous processes' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \;|\; t\in[0,\infty)\}$ is a right-continuous stochastic process on the sample space $(\Omega,\mathcal{F})$ with state space $(S,\mathcal{S})$. Suppose that $S$ is a Hausdorff topological space that is locally compact and has countable bases, and that $\mathcal{S}$ is the $\sigma$-algebra of Borel sets. Then $\tau_A$ and $\rho_A$ are stopping times relative to the natural filtration $\mathscr{F}_+^0$ for every open $A\in\mathcal{S}$.

Similarly, if $\mathbf{X}$ is progressively measurable relative to a complete, right-continuous filtration $\mathscr{F} = \{\mathcal{F}_t\;|\; t\in[0,\infty)\}$. If $A\in\mathcal{S}$ then $\rho_A$ and $\tau_A$ are stopping times relative to $\mathscr{F}$.
</MathBox>

# Probability distribution

<MathBox title='Probability distribution' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ and $\left(\mathbb{R}, \mathcal{B}(\mathbb{R}), \mathbb{P}_X \right)$ be probability spaces and $X: \Omega \to \mathbb{R}$ a random variable. Then the probability measure $\mathbb{P}_X: \mathcal{B}(\mathbb{R}) \to [0, 1]$ defined by

$$
  \mathbb{P}_X (B) := \mathbb{P}\left( X^{-1}(B) \right) = \mathbb{P}(X \in B)
$$

is called a probability distribution of $X$.
<details>
<summary>Proof</summary>

To prove that $\mathbb{P}_X$ is a probability measure we first verify

$$
\begin{gather*}
  X^{-1}(\mathbb{R}) = \Omega \implies \mathbb{P}_X (\mathbb{R}) = \mathbb{P}\left( X^{-1}(\mathbb{R}) \right) = \mathbb{P}(\Omega) = 1 \\
  X^{-1}(\emptyset) = \emptyset \implies \mathbb{P}_X (\emptyset) = \mathbb{P}\left( X^{-1}(\emptyset) \right) = \mathbb{P}(\emptyset) = 0
\end{gather*}
$$

To verify $\sigma$-additivity choose $(B_n)_{n\in\mathbb{N}} \in\mathcal{B}(\mathbb{R})$ pairwise disjoint, then

$$
  i \neq j \implies X^{-1}\left( B_i \right) \cap X^{-1}\left( B_j \right) = X^{-1}\left( B_i \cap B_j \right) = X^{-1}(\emptyset) = \emptyset
$$

so $X^{-1}\left( B_i \right) \in \mathcal{F}$ is pairwise joint, and moreover

$$
\begin{align*}
  \mathbb{P}_X \left( \bigcup_{j=1}^\infty B_j \right) &= \mathbb{P}\left( X^{-1}\left( \bigcup_{j=1}^\infty B_j \right) \right) = \mathbb{P}\left( \bigcup_{j=1}^\infty X^{-1}\left(  B_j \right) \right) \\
  &= \sum_{j=1}^\infty \mathbb{P}\left( X^{-1}\left(B_j \right) \right) = \sum_{j=1}^\infty \mathbb{P}_X \left( B_j \right)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Rules of probability measures' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. The probability measure $\mathbb{P}$ satisfy the following rules for the events $A, B\in\mathcal{F}$:
1. Complement rule: $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$
  - $\mathbb{P}(\emptyset) = 1 - \mathbb{P}(\Omega) = 0$
2. Difference rule: $\mathbb{P}(B\setminus A) = \mathbb{P}(B) - \mathbb{P}(A\cap B)$
  - If $A\subseteq B$, i.e. $A\cap B = A$, then 
      i. $\mathbb{P}(B\setminus A) = \mathbb{P}(B) - \mathbb{P}(A)$ and $\mathbb{P}(A)\leq\mathbb{P}(B)$
      ii. If $\mathbb{P}(B) = 0$ then $\mathbb{P}(A) = 0$. 
      iii. If $\mathbb{P}(A) = 1$ then $\mathbb{P}(B) = 1$
3. Boole's inequality: if $\{A_i\}_{i\in I}$ is countable collection of events then $\mathbb{P}\left(\bigcup_{i\in I} A_i\right)\leq\sum_{i\in I}\mathbb{P}(A_i)$
  - If $\mathbb{P}(A_i) = 0$ for each $i\in I$ then $\mathbb{P}\left(\bigcup_{i\in I} A_i\right) = 0$
4. Bonferroni's inequality: if $\{A_i\}_{i\in I}$ is countable collection of events then $\mathbb{P}\left(\bigcap_{i\in I} A_i\right)\geq 1 - \sum_{i\in I}\left[1 - \mathbb{P}(A_i)\right]$
  - If  $\mathbb{P}(A_i) = 1$ for each $i\in I$ then $\mathbb{P}\left(\bigcap_{i\in I} A_i\right) = 1$
5. Partition rule: if $\{A_i\}_{i\in I}$ is countable collection of events that partition $\Omega$, then $\mathbb{P}(B) = \sum_{i\in I}\mathbb{P}(A_i\cap B)$
6. Inclusion-exclusion rule: $\mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cap B) \iff \mathbb{P}(A\cap B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cup B)$
  - If $\{A_i \}_{i\in I}\subseteq\mathcal{F}$ for an index set $I$ with $|I| = n\in\mathbb{N}$ then

$$
\begin{align*}
  \mathbb{P}\left(\bigcup_{i\in I} A_i \right) &= \sum_{k=1}^n (-1)^{k-1} \sum_{J\subseteq I,\; |J|=k} \mathbb{P}\left( \bigcap_{j\in J} A_j \right) \\
  \mathbb{P}\left(\bigcap_{i\in I} A_i \right) &= \sum_{k=1}^n (-1)^{k-1} \sum_{J\subseteq I,\; |J|=k} \mathbb{P}\left( \bigcup_{j\in J} A_j \right)
\end{align*}
$$
</MathBox>

## Construction of probability measures
<MathBox title='Rescaling of probability measures' boxType='proposition'>
Let $(\Omega, \mathcal{F})$ be a sample space. If $\mu: \Omega\to [0, \infty)$ is a positive measure on $\Omega$ with $0<\mu(\Omega)<\infty$, then a probability measure on $(\Omega, \mathcal{F})$ can be defined as

$$
  \mathbb{P}(A) := \frac{\mu(A)}{\mu(\Omega)},\quad A\in\mathcal{F}
$$

<details>
<summary>Proof</summary>

To prove that $\mathbb{P}$ is a probability measure, we varify the Kolmogorov axioms for $A\subseteq\Omega$
1. $\mathbb{P}(A) \geq 0$ since $\mu(A)\geq 0$ and $0<\mu(\Omega)<\infty$.
2. $\mathbb{P}(\Omega) = \frac{\mu(\Omega)}{\mu(\Omega)} = 1$
3. If $\{A_i\}_{i\in I}\subseteq\mathcal{F}$ is a countable collection of disjoint events then

$$
  \mathbb{P}\left(\bigcup_{i\in I} A_i \right) = \frac{1}{\mu(\Omega)}\mu\left( \bigcup_{i\in I} A_i \right) = \frac{1}{\mu(\Omega)}\sum_{i\in I}\mu(A_i) = \sum_{i\in I}\frac{\mu(A_i)}{\mu(\Omega)} = \sum_{i\in I}\mathbb{P}(A_i)
$$
</details>
</MathBox>

<MathBox title='Construction of discrete probability measures' boxType='proposition'>
Let $(\Omega, \mathcal{F})$ be a sample space. Consider a function $g: \Omega\to [0, \infty)$, then $\mu$ defined by $\mu(A) = \sum_{x\in A} g(x)$ for $A\in\Omega$ is a positive measure on $\Omega$. If $0<\mu(\Omega)<\infty$ then a probability measure on $(\Omega, \mathcal{F})$ can be defined as

$$
  \mathbb{P}(A) := \frac{\mu(A)}{\mu(\Omega)} = \frac{\sum_{x\in A} g(x)}{\sum_{x\in \Omega} g(x)},\quad A\subseteq\Omega
$$
</MathBox>
<details>
<summary>Proof</summary>

To prove that $\mathbb{P}$ is a probability measure, we varify the Kolmogorov axioms for $A\subseteq\Omega$
1. $\mathbb{P}(A) \geq 0$ since $g$ is nonnegative, $\mu(A)\geq 0$ and $0<\mu(\Omega)<\infty$.
2. $\mathbb{P}(\Omega) = \frac{\sum_{x\in \Omega} g(x)}{\sum_{x\in \Omega} g(x)} = 1$
3. If $\{A_i\}_{i\in I}\subseteq\mathcal{F}$ is a countable collection of disjoint events then

$$
  \mathbb{P}\left(\bigcup_{i\in I} A_i \right) = \frac{1}{\mu(\Omega)}\mu\left( \bigcup_{i\in I} A_i \right) = \frac{1}{\mu(\Omega)}\sum_{i\in I}\sum_{x\in A_i} g(x) = \sum_{i\in I}\frac{\mu(A_i)}{\mu(\Omega)} = \sum_{i\in I}\mathbb{P}(A_i)
$$
</details>

<MathBox title='Construction of continuous probability measure' boxType='proposition'>
Let $(\Omega, \mathcal{F})$ be a sample space with $\Omega\subseteq\mathbb{R}^n$. Consider a function $g: \Omega\to [0, \infty)$, then $\mu$ defined by $\mu(A) = \int_A g(x)\mathrm{d}x$ for $A\in\Omega$ is a positive measure on $\Omega$. If $0<\mu(\Omega)<\infty$ then a probability measure on $(\Omega, \mathcal{F})$ can be defined as

$$
  \mathbb{P}(A) := \frac{\mu(A)}{\mu(\Omega)} = \frac{\int_{A} g(x)\mathrm{d}x}{\sum_{\Omega}g(x)\mathrm{d}x},\quad A\subseteq\Omega
$$
<details>
<summary>Proof</summary>

To prove that $\mathbb{P}$ is a probability measure, we varify the Kolmogorov axioms for $A\subseteq\Omega$
1. $\mathbb{P}(A) \geq 0$ since $g$ is nonnegative, $\mu(A)\geq 0$ and $0<\mu(\Omega)<\infty$.
2. $\mathbb{P}(\Omega) = \frac{\int_{\Omega} g(x)\mathrm{d}x}{\int_{\Omega} g(x)\mathrm{d}x} = 1$
3. If $\{A_i\}_{i\in I}\subseteq\mathcal{F}$ is a countable collection of disjoint events then

$$
  \mathbb{P}\left(\bigcup_{i\in I} A_i \right) = \frac{1}{\mu(\Omega)}\mu\left( \bigcup_{i\in I} A_i \right) = \frac{1}{\mu(\Omega)}\sum_{i\in I}\int_{A_i} g(x)\mathrm{d}x = \sum_{i\in I}\frac{\mu(A_i)}{\mu(\Omega)} = \sum_{i\in I}\mathbb{P}(A_i)
$$
</details>
</MathBox>

## Cumulative distribution function (CDF)

<MathBox title='Cumulative distribution function' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and $X: \Omega \to \mathbb{R}$ a random variable. The cumulative distribution function for $X$ is defined as

$$
\begin{gather*}
  F_X : \mathbb{R} \to [0, 1]\\
  F_X(x) := \mathbb{P}_X \left((-\infty, x]\right) = P(X \leq x)
\end{gather*}
$$
</MathBox>

<MathBox title='Properties of cumulative distribution functions' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and $X: \Omega \to \mathbb{R}$ a random variable. The cumulative distribution function $F_X$ has the following properties:
- Limits
$$
\begin{gather*}
  \lim_{x\to -\infty} F_X(x) = 0 \\
  \lim_{x\to \infty} F_X(x) = 1
\end{gather*}
$$
- Monotonically increasing $x_1 < x_2 \implies F_X(x_1) \leq F_X(x_2)$
- Right continuity: $\lim_{x \to x_0} F_X (x) = F_X{x_0}$.
</MathBox>

## Conditional probability

<MathBox title='Conditional probability' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and consider an event $B\in\mathcal{F}$ with $\mathbb{P}(B)\neq 0$. The conditional probability of an event $A\in\mathcal{F}$ given $B$ is defined as

$$
  \mathbb{P}(A|B) := \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}
$$

where $\mathcal{P}(\cdot|B):\mathcal{A}\to[0, 1]$ is the conditional probability measure given $B$, which satisfies
- $\mathcal{P}(B|B) = 1$
<details>
<summary>Proof</summary>

To prove that $A\mapsto\mathbb{P}(A|B)$ is probability measure, we verify the Kolmogorov axioms
1. Trivially $\mathbb{P}(A|B)\geq 0$ for every $A\in\mathcal{A}$
2. Trivially $\mathbb{P}(\Omega|B) = \frac{\mathbb{P}(\Omega\cap B)}{\mathbb{P}(B)} = \frac{\mathbb{P}(B)}{\mathbb{P}(B)} = 1$
3. If $\{A_i\}_{i\in I}\subseteq\mathcal{F}$ is a countable collection of pairwise disjoint events then

$$
\begin{align*}
  P\left( \bigcup_{i\in I} A_i | B \right) &= \frac{1}{\mathbb{P}(B)}\mathbb{P}\left[\left(\bigcup_{i\in I} A_i \right)\cap B\right] = \frac{1}{\mathbb{P}(B)}\mathbb{P}\left[\bigcup_{i\in I}(A_i \cap B) \right] \\
  &= \frac{1}{\mathbb{P}(B)}\sum_{i\in I}\mathbb{P}(A_i\cap B) = \sum_{i\in I}\frac{\mathbb{P}(A_i\cap B)}{\mathbb{P}(B)} = \sum_{i\in I}\mathbb{P}(A_i|B)
\end{align*}
$$

Where we have used the fact that the collection of events $\{A_i\cap B\}_{i\in I}$ is also pairwise disjoint.
</details>
</MathBox>

<MathBox title='Correlation of events' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. Two events $A, B\in\mathcal{F}$ with positive probability can be related in the following ways
1. Positively correlated: $\mathbb{P}(A|B)>\mathbb{P}(A)\iff\mathbb{P}(B|A)>\mathbb{P}(B)\iff\mathbb{P}(A\cap B)>\mathbb{P}(A)\mathbb{P}B$
2. Negatively correlated: $\mathbb{P}(A|B)<\mathbb{P}(A)\iff\mathbb{P}(B|A)<\mathbb{P}(B)\iff\mathbb{P}(A\cap B)<\mathbb{P}(A)\mathbb{P}B$
3. Uncorrelated or independent: $\mathbb{P}(A|B)=\mathbb{P}(A)\iff\mathbb{P}(B|A)=\mathbb{P}(B)\iff\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)$
</MathBox>

<MathBox title='Properties of correlation' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space adn consider two events $A, B\in\mathcal{F}$. Then
1. $A$ and $B$ have the same correlation as $A^c$ and $B^c$.
2. $A$ and $B$ have the opposite correlation as $A$ and $B^c$
<details>
<summary>Proof</summary>

1. Applying DeMorgan's theorem, the complement rule and the inclusion-exclusion rule gives

$$
\begin{align*}
  \mathbb{P}(A^c \cap B^c) - \mathbb{P}(A^c)\mathbb{P}(B^c) &= \mathbb{P}\left[ (A\cap B)^c \right] - \mathbb{P}(A^c)\mathbb{P}(B^c) \\
  &= \left[1 - \mathbb{P}(A\cap B) \right] - \left[1 - \mathbb{P}(A)\right]\left[\mathbb{P}(B)] \\
  &= 1 - \left[\mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cap B) \right] - \left[1 - \mathbb{P}(A) - \mathbb{P}(B) - \mathbb{P}(A)\mathbb{P}(B) \right] \\
  &= \mathbb{P}(A\cap B) - \mathbb{P}(A)\mathbb{P}(B)
\end{align*}
$$

2. Applying the difference rule and the complement rule

$$
\begin{align*}
  \mathbb{P}(A \cap B^c) - \mathbb{P}(A)\mathbb{P}(B^c) &= \mathbb{P}(A) - \mathbb{P}(A\cap B) - \mathbb{P}(A)[1 - \mathbb{P}(B)] \\
  &= \left[1 - \mathbb{P}(A\cap B) \right] - \left[1 - \mathbb{P}(A)\right]\left[\mathbb{P}(B)] \\
  &= -\left[\mathbb{P}(A\cap B) - \mathbb{P}(A)\mathbb{P}(B) \right]
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Multiplication rule' boxType='theorem'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and consider two events $A, B\in\mathcal{F}$ with positive probability, then

$$
  \mathbb{P}(A\cap B) = \mathbb{P}(A)\mathbb{P}(B|A) = \mathbb{P}(B)\mathbb{P}(B|A)
$$

In the general case, suppose that $(A_i \in\mathcal{F})_{i=1}^{n\in\mathbb{N}}$ is a sequence of events. then

$$
  \mathbb{P}\left(\bigcap_{i=1}^n A_i \right) = \mathbb{P}(A_1)\mathbb{P}(A_2|A_1)\mathbb{P}(A_3|A_1\cap A_2)\cdots\mathbb{P}\left(A_n | \bigcup_{i=1}^{n-1} A_i\right)
$$
</MathBox>

<MathBox title='Law of total probability' boxType='theorem'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and consider two events $A, B\in\mathcal{F}$ with $\mathbb{P}(B) > 0$. Then

$$
  \mathbb{P}(A) = \mathbb{P}(B)\mathbb{P}(A|B) + \mathbb{P}(B^c)\mathbb{P}(A|B^c)
$$

In the general case, suppose that $\{B_i \}_{i\in I}\subseteq\mathcal{F}$ is a countable collection of events that partition $\Omega$ with $\mathbb{P}(B_i) > 0$ for each $i\in I$. For an event $A\in\mathcal{F}$ then

$$
  \mathbb{P}(A) = \sum_{i\in I}\mathbb{P}(B_i)\mathbb{P}(A|B_i)
$$
<details>
<summary>Proof</summary>

Note that $A = (A\cap B)\cup (A\cap B^c)$ is a disjoint union, so

$$
\begin{align*}
  \mathbb{P}(A) &= \mathbb{P}\left[(A\cap B)\cup (A\cap B^c) \right] = \mathbb{P}(A\cap B) + \mathbb{P}(A\cap B^c) \\
  &= \mathbb{P}(B)\mathbb{P}(A|B) + \mathbb{P}(B^c)\mathbb{P}(A|B^c)
\end{align*}
$$
</details>
</MathBox>

<MathBox title="Bayes' theorem" boxType='theorem'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and consider two events $A, B\in\mathcal{F}$ with $\mathbb{P}(B) > 0$. Then Bayes' theorem states that

$$
  \mathbb{P}(A|B) = \frac{\mathbb{P}(A)\mathbb{P}(B|A)}{\mathbb{P}(B)} = \frac{\mathbb{P}(A)\mathbb{P}(B|A)}{\mathbb{P}(A)\mathbb{P}(B|A) + \mathbb{P}(A^c)\mathbb{P}(B|A^c)}
$$

where
- $\mathbb{P}(A)$ is the prior probability of $A$
- $\mathbb{P}(A|B)$ is the posterior probability of $A$

In the general case, suppose that $\{A_i \}_{i\in I}\subseteq\mathcal{F}$ is a countable collection of events that partition $\Omega$ with $\mathbb{P}(A_i) > 0$ for each $i\in I$. Then Bayes' theorem takes the general form for $j\in I$

$$
  \mathbb{P}(A_j |B) = \frac{\mathbb{P}(A_j)\mathbb{P}(B|A_j)}{\sum_{i\in I}\mathbb{P}(A_i)\mathbb{P}(B|A_i)}
$$
</MathBox>

<MathBox title='Conditional probability kernel' boxType='definition'>
Suppose that $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space, and that $(S,\mathcal{S})$ and $(T,\mathcal{T})$ are measurable spaces. Consider the random variables $X:\Omega\to S$ and $Y:\Omega\to T$. The function $P$ defined as follows is a probability kernel from $(S,\mathcal{S})$ to $(T,\mathcal{T})$, known as the conditional probability kernel of $Y$ given $X$.

$$
  P(x, A) = \mathbb{P}(Y\in A | X = x),\quad x\in S, A\in\mathcal{T}
$$

The right and left operators associated with this kernel correspond to the conditional expectation and probability destribution, respectively.
1. If $f:T\to\mathbb{R}$ is measurable, then $Pf(x) = \mathbb{E}[f(Y)|X = x]$ for $x\in S$
2. If $\mu$ is the probability distribution of $X$ then $\mu P$ is the probability distribution of $Y$ 

<details>
<summary>Proof</summary>

Recall that for $A\in\mathcal{T}$ the conditional probability $\mathbb{P}(Y\in A| X)$ is itself a random variable, and is measurable with respect to $\sigma(X)$. That is, $\mathbb{P}(Y\in A|X) = P(X, A)$ for some measurable function $S\ni x \mapsto P(x, A)\in [0,1]$. Then by definition $\mathbb{P}(Y\in A|X=x)=P(x,A)$. Trivially, $A\mapsto P(x, A)$ is a probability measure on $(T,\mathcal{T})$ for $x\in S$.

1. Since $A\mapsto P(x, A)$ is the conditional distribution of $Y$ given $X = x$
$$
  \mathbb{E}[f(Y)| X=x] = \int_S P(x,\mathrm{d}y)f(y) = Pf(x)
$$
2. Let $A\in\mathcal{T}$. Conditioning on $X$ gives
$$
\begin{align*}
  \mathbb{P}(Y\in A) &= \mathbb{E}[\mathbb{P}(Y\in A| X)] \\
  &= \int_S P(Y\in A| X=x)\,\mathrm{d}\mu(x) \\
  &= \int_S P(x, A)\,\mathrm{d}\mu(x) = \mu P(A)
\end{align*}
$$
</details>
</MathBox>

## Independence

<MathBox title='Independence of events' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. Two events $A, B\in\mathcal{F}$ are independent (uncorrelated) if $\mathbb{P}(A\cap B) = \mathbb{P}(A)\mathbb{P}(B)$. In the general case, a countable collection $\mathcal{A} = \{A_i \}_{i\in I}\subseteq\mathcal{F}$ of events is independent if for every finite $J\subseteq I$

$$
  \mathbb{P}\left(\bigcap_{j\in J} A_j \right) = \prod_{j\in J}\mathbb{P}(A_j)
$$

From the definition it follows that $\mathcal{A}$ has the following inheritance properties
1. If $\mathcal{A}$ is independent, then $\mathcal{B}$ is independent for every $\mathcal{B}\subseteq\mathcal{A}$.
2. If $\mathcal{B}$ is independent for every finite $\mathcal{B}\subseteq\mathcal{A}$ then $\mathcal{A}$ is independent.

The notion of independence can be extended to collections of collections of events. Consider an index set $I$ and suppose that $\mathcal{A}_i$ is a collection of events for each $i\in I$. Then $\mathscr{A} = \{\mathcal{A}\}_{i\in I}$ is independent if and only if for every choice of $A_i\in\mathcal{A}_i$ for $i\in I$, the collection of events $\{A_i\}_{i\in I}$ is independent as defined above. The independence of $\{A_i\}_{i\in I}$ is equivalent to the independence of $\{\mathcal{A}_i\}_{i\in I}$ where $\mathcal{A}_i = \sigma\{A_i\} = \{\Omega,\emptyset, A_i, A_i^c\}$ for each $i\in I$. From the definition it follows that $\mathscr{A}$ has the following inheritance properties
1. If $\mathscr{A}$ is independent, then $\mathscr{B}$ is independent for every $\mathscr{B}\subseteq\mathscr{A}$.
2. If $\mathscr{B}$ is independent for every finite $\mathscr{B}\subseteq\mathscr{A}$ then $\mathscr{A}$ is independent.
</MathBox>

Note that independence and disjointness of events are different concepts. Two disjoint events can never be independent.
<MathBox title='Disjoint events are negatively correlated' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and consider two disjoint events $A, B\in\mathcal{F}$ with positive probability. Then $A$ and $B$ are dependent, and are in fact negatively correlated.
<details>
<summary>Proof</summary>

Note that $\mathbb{P}(A\cap B) = \mathbb{P}(\emptyset) = 0$ but $\mathbb{P}(A)\mathbb{P}(B) > 0$.
</details>
</MathBox>

<MathBox title='Properties of independence' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. If $A, B\in\mathcal{F}$ are independent events, then the following pairs of events are also independent:
1. $A^c$ and $B$
2. $B$ and $A^c$
3. $A^c$ and $B^c$

In the general case, suppose that $\mathcal{A} = \{A_i\}_{i\in I}\mathcal{F}$ and $\mathcal{B} = \{B_i\}_{i\in I}\subseteq\mathcal{F}$ are two countable collections of events with the property that for each $i\in I$, either $B_i = A_i$ or $B_i = A_i^c$. Then $\mathcal{A}$ is independent if and only if $\mathcal{B}$ is independent.
<details>
<summary>Proof</summary>

1. Note that $\mathbb{P}(A^c \cap B) = \mathbb{P}(B\setminus A)$. Applying the difference rule and the complement rule

$$
\begin{align*}
  \mathbb{P}(A^c \cap B) &= \mathbb{P}(B) - \mathbb{P}(A\cap B) \\
  &= \mathbb{P}(B) - \mathbb{P}(A)\mathbb{P}(B) = \mathbb{P}(B)[1 - \mathbb{P}(A)] \\
  &= \mathbb{P}(B)\mathbb{P}(A^c)
\end{align*}
$$

2. Note that $\mathbb{P}(A \cap B^c) = \mathbb{P}(A\setminus B)$. Applying the difference rule and the complement rule

$$
\begin{align*}
  \mathbb{P}(A \cap B^c) &= \mathbb{P}(A) - \mathbb{P}(A\cap B) \\
  &= \mathbb{P}(A) - \mathbb{P}(A)\mathbb{P}(B) = \mathbb{P}(A)[1 - \mathbb{P}(B)] \\
  &= \mathbb{P}(A)\mathbb{P}(B^c)
\end{align*}
$$

3. Applying DeMorgan's theorem, the complement rule and the inclusion-exclusion rule

$$
\begin{align*}
  \mathbb{P}(A^c \cap B^c) &= \mathbb{P}[(A\cup B)^c] = 1 - \mathbb{P}(A\cup B) \\
  &= 1 - [\mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cap B)] \\
  &= 1 - [1 - \mathbb{P}(A^c)] - [1 - \mathbb{P}(B^c)] + [1 - \mathbb{P(A^c)}][1 - \mathbb{P}(B^c)] \\
  &= \mathbb{P}(A^c)\mathbb{P}(B^c)
\end{align*}
$$

For the general case, it suffices to show $\mathcal{A}$ independent implies $\mathcal{B}$ independent due to the symmetry of the relation between $\mathcal{A}$ and $\mathcal{B}$. By the inheritance property, it also suffices to consider where the index set $I$ is finite. Fix $k\in I$ and define $B_k = A_k^c$ and $B_i = A_i$ for $i\in I\setminus\{k\}$. Suppose that $J\subseteq I$. If $k\notin J$, then trivially $\mathbb{P}\left(\bigcup_{j\in J} B_j \right) = \prod_{j\in J}\mathbb{P}(B_j)$. If $k\in J$, then by the difference rule

$$
\begin{align*}
  \mathbb{P}\left(\bigcup_{j\in J}B_j\right) &= \mathbb{P}\left(\bigcap_{j\in J\setminus\{k\}} A_j \right) - \mathbb{P}\left(\bigcup_{j\in J} A_j \right) \\
  &= \prod_{j\in J\setminus\{k\}}\mathbb{P}(A_j) - \prod_{j\in J}\mathbb{P}(A_j) \\
  &= \left[\prod_{j\in J\setminus\{k\}}\mathbb{P}(A_j) \right][1 - \mathbb{P}(A_k)] \\
  &= \prod_{j\in J}\mathbb{P}(B_j)
\end{align*}
$$

Suppose that $\mathcal{B} = \{B_i \}_{i\in I\}\subseteq\mathcal{F}$ is a general finite collection of events where $B_i = A_i$ or $B_i = A_i^c$ for each $i\in I$. Then same procedure can be applied by a finite sequence of complement changes. Hence $\mathcal{B}$ is a collection of independent events.
</details>
</MathBox>

<MathBox title='Independence of collection of random variables' boxType='definition'>
Let $(S,\mathcal{S},\mathbb{P})$ be a probability space and $(T_i,\mathcal{T}_i)$ be event spaces for $i$ in an index set $I$. A collection of random variables $\mathcal{X} = \{X_i:S\to T_i\}_{i\in I}$ is independent if the collection of events $\{\{X_i\in B_i\}\;|\; i\in I\}$ is independent for every choice of $B_i\in\mathcal{T}_i$ for $i\in I$. Equivalently, $\mathcal{X}$ is independent if for every finite $J\subseteq I$ and for every choice of $B_j\in \mathcal{T}_j$ for $j\in J$

$$
  \mathbb{P}\left(\bigcap_{j\in J}\{X_j \in B_j \}\right) = \prod_{j\in J}\mathbb{P}(X_j\in B_j)
$$

From the definition it follows that $\mathcal{X}$ has the following inheritance properties
1. If $\mathcal{X}$ is independent, then $\mathcal{Y}$ is independent for every $\mathcal{Y}\subseteq\mathcal{X}$.
2. If $\mathcal{Y}$ is independent for every finite $\mathcal{Y}\subseteq\mathcal{X}$ then $\mathcal{X}$ is independent.
</MathBox>

<MathBox title='Independence is preserved under compositions' boxType='proposition'>
Let $(S,\mathcal{S},\mathbb{P})$ be a probability space and $(T_i,\mathcal{T}_i)$ and $(U_i,\mathcal{U}_i)$ be event spaces for $i$ in an index set $I$. Suppose that $g_i:T_i\to U_i$ are measurable functions. If the collection $\mathcal{X} = \{X_i:S\to T_i\}_{i\in I}$ is independent then $\{g_i(X_i)\}_{i\in I}$ is also independent.
<details>
<summary>Proof</summary>

Suppose that $C_i\in\mathcal{U}_i$ for each $i\in I$ such that $g_i^{-1}[C_i]\in\mathcal{T}_i$. Then $\{g_i(X_i)\in C_i\} = \{X_i\in g_i^{-1}[C_i]\}\in\mathcal{S}$ for $i\in I$. By the independence of $\{X_i\}_{i\in I}$, the collection of events $\{\{X_i\in g_i^{-1}[C_i]\}\;|\; i\in I\}$ is independent.
</details>
</MathBox>

<MathBox title='Condition for independence of collections of $\sigma$-algebras' boxType='proposition'>
Let $(X,\mathcal{F},\mathbb{P})$ be a probability space. Suppose that $\mathcal{A}_i$ is a collection of events, and a $\pi$-system for each $i$ in an index set $I$. If $\{\mathcal{A}_i\}_{i\in I}$ is independent, then the collection of $\sigma$-algebras $\{\sigma(\mathcal{A}_i)\}_{i\in I}$ is independent.
<details>
<summary>Proof</summary>

Due to inheritance of independence it suffices to consider a finite set of collections. Suppose that $\{\mathcal{A}_i\}_{i=1}^{n\in\mathbb{N}}$ is independent. Fix $A_i\in\mathcal{A}_i$ for $i\in\{1,2,\dots,n\}$ and let $E=\bigcap_{i=2}^n A_i$, and $\mathcal{L}=\{B\in\mathcal{F} \;|\; \mathbb{P}(B\cap E) = \mathbb{P}(B)\mathbb{P}(E)\}$. We will show that $\mathcal{L}$ is a $\lambda$-system and apply the $\pi$-$\lambda$ theorem to find that $\sigma(\mathcal{A}_1)\subseteq\mathcal{L}$. Trivially $X\in\mathcal{L}$ since $\mathbb{P}(X\cap E) = \mathbb{P}(E) = \mathbb{P}(X)\mathbb{P}(E)$. Next, suppose that $A\in\mathcal{L}$, then

$$
\begin{align*}
  \mathbb{P}(A^c\cap E) &= \mathbb{P}(E) - \mathbb{P}(A\cap E) = \mathbb{P}(E) - \mathbb{P}(A)\mathbb{P}(E) \\
  &= [1 - \mathbb{P}(A)]\mathbb{P}(E) = \mathbb{P}(A^c)\mathbb{P}(E)
\end{align*}
$$

showing that $A^c\in\mathcal{L}$. Finally, suppose that $\{A_j\}_{j\in J}$ is a countable collection of disjoint sets in $\mathcal{L}$, then

$$
\begin{align*}
  \mathcal{P}\left[\left(\bigcup_{j\in J}A_j \right)\cap E \right] &= \mathbb{P}\left[\bigcup_{j\in J}(A_j\cap E)\right] = \sum_{j\in J}\mathbb{P}(A_j\cap E) \\
  &= \sum_{j\in J}\mathbb{P}(A_j)\mathbb{P}(E) = \mathbb{P}(E)\sum_{j\in J}\mathbb{P}(A_j) \\
  &= \mathbb{P}(E)\mathbb{P}\left(\bigcup_{j\in J}A_j \right)
\end{align*}
$$

showing that $\bigcup_{j\in J}A_j\in\mathcal{L}$, and thus $\mathcal{L}$ is a $\lambda$-system. Trivially $\mathcal{A}_1\subseteq \mathcal{L}$ by the independence assumption, so by the $\pi$-$\lambda$ theorem, $\sigma(\mathcal{A}_1)\subseteq\mathcal{L}$. Thus, we have that for every $A_1\in\sigma(\mathcal{A}_1)$ and $A_i\in\mathcal{A}_i$ for $i\in\{2,3,\dots,n\}$

$$
  \mathbb{P}\left(\bigcap_{i=1}^n A_i\right) = \prod_{i=1}^n\mathbb{P}(A_i)
$$

Hence we have shown that $\{\sigma(\mathcal{A}_1), \mathcal{A}_2,\dots,\mathcal{A}_n\}$ is independent. Repeating the argument $n-1$ times, we get that $\{\sigma(\mathcal{A}_i)\}_{i=1}^n$ is independent.
</details>
</MathBox>

<MathBox title='Proposition' boxType='proposition'>
Suppose that $\mathcal{A}$ is an independent collection of events, and that $\{\mathcal{B}_j\}_{j\in J}$ is a partition of $\mathcal{A}$. Then $\{\sigma(\mathcal{B}_j)\}_{j\in J}$ is independent. 

<details>
<summary>Proof</summary>

Let $\mathcal{B}*_j$ denote the set of all finite intersections of sets in $\mathcal{B}_j$, for each $j\in J$. Then clearly $\mathcal{B}*_j$ is a $\pi$-system for each $j$, and $\{\mathcal{B}*_j\}_{j\in J}$ is independent. By the previous result $\{\sigma(\mathcal{B}*_j)\}_{j\in J}$ is independent. However, clearly $\sigma(\mathcal{B}*_j) = \sigma(\mathcal{B})$ for $j\in J$. 
</details>
</MathBox>

## Exchangeability

<MathBox title='Exchangeable collection of events' boxType='definition'>
Let $I$ be an index set. A collection of events $\mathcal{A} = \{A\}_{i\in I}$ is exchangeable if the probability of a finite intersection of events depends only on the number of events. That is, for finite $J, K\subseteq I$ with $|J|=|K|$ then

$$
  \mathbb{P}\left(\bigcap_{j\in J} A_j \right) = \mathbb{P}\left(\bigcap_{k\in K} A_k \right)
$$

From the definition it follows that $\mathcal{A}$ has the following inheritance properties
1. If $\mathcal{A}$ is exchangeable, then $\mathcal{B}$ is exchangeable for every $\mathcal{B}\subseteq\mathcal{A}$.
2. If $\mathcal{B}$ is exchangeable for every finite $\mathcal{B}\subseteq\mathcal{A}$ then $\mathcal{A}$ is exchangeable.
</MathBox>

<MathBox title='Inclusion-exclusion formula for exhangeable events' boxType='corollary'>
Let $\mathcal{A} = \{A_i\}_{i=1}^{n\in\mathbb{N}}$ be an exchangeable collection of events. For $J\subseteq \{1,2,\dots,n\}$ with $|J| = k$, let $p_k = \mathbb{P}\left(\bigcap_{j\in J}A_j\right)$. Then the inclusion-exclusion formula reduces to

$$
  \mathbb{P}\left(\bigcup_{i=1}^n A_i \right) = \sum_{k=1}^n (-1)^{k-1}\binom{n}{k}p_k
$$
</MathBox>

## Continuity

<MathBox title='Continuity theorem for probability' boxType='theorem'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and consider a sequence of events $(A_n\in\mathcal{F})_{n\in\mathbb{N}}$.
1. If the sequence is increasing then $\lim_{n\to\infty}\mathbb{P}(A_n)=\mathbb{P}\left(\lim_{n\to\infty} A_n \right)=\lim_{n\to\infty}\mathbb{P}\left(\bigcup_{i=1}^n A_i \right)=\mathbb{P}\left(\bigcup_{n\in\mathbb{N}} A_n \right)$
2. If the sequence is decreasing then $\lim_{n\to\infty}\mathbb{P}(A_n)=\mathbb{P}\left(\lim_{n\to\infty} A_n \right)=\lim_{n\to\infty}\mathbb{P}\left(\bigcap_{i=1}^n A_i \right)=\mathbb{P}\left(\bigcap_{n\in\mathbb{N}} A_n \right)$ 
<details>
<summary>Proof</summary>

1. Define the collection of events $\mathcal{B} = \{B_n\}_{n\in\mathbb{N}}\subseteq\mathcal{F}$ where $B_1 = A_1$ and $B_n = A_n\setminus A_{n-1}$ for $n\in\mathbb{N}\setminus\{1\}$. Note that $\mathcal{B}$ is pairwise disjoint and has the same union as $\{A_n\}_{n\in\mathbb{N}}$. From countable additivity

$$
  \mathbb{P}\left(\bigcup_{n\in\mathbb{N}} A_n \right) = \mathbb{P}\left(\bigcup_{n\in\mathbb{N}} B_n \right) = \sum_{n\in\mathbb{N}}\mathbb{P}(B_n) = \lim_{n\to\infty} \sum_{i=1}^n \mathbb{P}(B_i)
$$

However, $\mathbb{P}(B_1) = \mathbb{P}(A_1)$ and $\mathbb{P}(B_i) = \mathbb{P}(A_i) - \mathbb{P}(A_{i-1})$ for $i\in\mathbb{N}\setminus\{1\}$. Thus $\sum_{i\in n}\mathbb{P}(B_i) = \mathbb{P}(A_n)$ resulting in $\mathbb{P}\left(\bigcup_{n\in\mathbb{N}}A_n\right) = \lim_{n\to\infty}\mathbb{P}(A_n)$.

2. Note that the sequence of complements $\left(A_n^c\right)_{n\in\mathbb{N}}$ is increasing. Applying DeMorgan's rule and the complement rule on the result above gives

$$
  \mathbb{P}\left(\bigcap_{n\in\mathbb{N}} A_n \right) = 1 - \mathbb{P}\left(\bigcup_{n\in\mathbb{N}} A_n^c \right) = 1 - \lim_{n\to\infty}\mathbb{P}\left(A_n^c\right) = \lim_{n\to\infty}\left[1 - \mathbb{P}\left(A_n^c\right) \right] = \lim_{n\to\infty}\mathbb{P}(A_n)
$$
</details>
</MathBox>

<MathBox title='Bounded limits of probability' boxType='proposition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. A sequence of events $(A_n\in\mathcal{F})_{n\in\mathbb{N}}$ has the following the following bounded limits.
1. $\mathbb{P}\left(\limsup_{n\to\infty} A_n \right) = \lim_{n\to\infty}\mathbb{P}\left(\bigcup_{i=n}^\infty A_i \right)$
2. $\mathbb{P}\left(\liminf_{n\to\infty} A_n \right) = \lim_{n\to\infty}\mathbb{P}\left(\bigcap_{i=n}^\infty A_i \right)$
</MathBox>

<MathBox title='Borel-Cantelli lemmas' boxType='lemma'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. 
1. **First Borel-Cantelli lemma:** Suppose that $(A_n \in\mathcal{F})_{n\in\mathbb{N}}$ is a sequence of events. If $\sum_{n\in\mathbb{N}}\mathbb{P}(A_n)<\infty$ then $\mathbb{P}\left(\limsup_{n\to\infty}A_n\right) = 0$.
2. **Second Borel-Cantelli lemma:** Suppose that $(A_n \in\mathcal{F})_{n\in\mathbb{N}}$ is a sequence of independent events. If $\sum_{n\in\mathbb{N}}\mathbb{P}(A_n) = \infty$ then $\mathbb{P}\left(\limsup_{n\to\infty}A_n\right) = 1$.
<details>
<summary>Proof</summary>

1. Recall that $\mathbb{P}\left(\limsup_{n\to\infty} A_n\right) = \lim_{n\to\infty}\mathbb{P}\left(\bigcup_{i=n}^\infty A_i\right)$. Boole's inequality gives 

$$
  \mathbb{P}\left(\bigcup_{i=n}^\infty A_i)\leq\sum_{i=n}^\infty \mathbb{P}(A_i)
$$

Since $\sum_{i=n}^\infty \mathbb{P}(A_i)$, it follows that $\sum_{i=n}^\infty \mathbb{P}(A_i) \xrightarrow{n\to\infty} 0$.

2. Note that $\mathbb{P}\left(\limsup_{n\to\infty} A_n\right) = 1 - \mathbb{P}\left[\left(\limsup_{n\to\infty} A_n\right)^c\right]$ and recall that $\left(\limsup_{n\to\infty}A_n\right)^c = \liminf_{n\to\infty} A_n^c$.

$$
  \mathbb{P}\left[\left(\limsup_{n\to\infty} A_n\right)^c\right] = \mathbb{P}\left(\liminf_{n\to\infty} A_n^c) = \lim_{n\to\infty}\mathbb{P}\left(\bigcap_{i=n}^\infty A_i^c)
$$

Recall that $1 - x \leq e^{-x}$ for every $x\in\mathbb{R}$, so that $1 - \mathbb{P}(A_i)\leq\exp\left[-\mathbb{P}(A_i)\right]$ for each $i\in\mathbb{N}$.

$$
  \mathbb{P}\left(\bigcap_{i=n}^\infty A_i^c) = \prod_{i=n}^\infty \mathbb{P}(A_i^c) = \prod_{i=1}^\infty\left[1 - \mathbb{P}(A_i) \right] \leq \prod_{i=n}^\infty\exp\left[-\mathbb{P}(A_i)\right] = \exp\left( -\sum_{i=n}^\infty\mathbb{P}(A_i)\right) = 0 \right) 
$$
</details>
</MathBox>

<MathBox title='Tail $\sigma$-algebra' boxType='definition'>
Let $(X_n)_{n\in\mathbb{N}}$ be a sequence of random variables. The tail $\sigma$-algebra of the sequence is 

$$
  \mathcal{T} = \bigcap_{n\in\mathbb{N}}\sigma\{X_n,X_{n+1},\dots\}
$$

An event $B\in\mathcal{T}$ is a tail event for the sequence. A random variable $Y$ that is measurable with respect to $\mathcal{T}$ is a tail random variable for the sequence.
</MathBox>

<MathBox title='Kolmogorov zero-one theorem' boxType='theorem'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}}$ is an independent sequence of random variables.
1. If $B$ is a tail event for $\mathbf{X}$ then $\mathbb{P}(B) = 0$ or $\mathbb{P}(B) = 1$.
2. If $Y$ is a real-valued tail random variable for $\mathbf{X}$ then $Y$ is constant with probability $1$.
<details>
<summary>Proof</summary>

1. By definition $B\in\sigma\{X_{n+i}\}_{i\in\mathbb{N}}$ for each $n\in\mathbb{N}}$, so $\{X_i\}_{i=1}^n \cup \{\mathbf{1}_B\}$ is an independent set of random variables. Thus $\{X_n\}_{n\in\mathbb{N}}\cup\{\mathbf{1}_B\}$. However, $B\in\sigma\{X_n\}_{n\in\mathbb{N}}$ so it follows that $B$ is independent itself. Therefore $\mathbb{P}(0)$ or $\mathbb{P}(1)$.
2. The function $y\mapsto \mathbb{P}(Y\leq y)$ on $\mathbb{R}$ is the cumulative distribution function of $Y$. This function is clearly increasing, and it can be shown that it is right continuous and that $\mathbb{P}(Y\leq y)\xrightarrow{y\to-\infty}0$ and $\mathbb{P}(Y\leq y)\xrightarrow{y\to\infty}1$. However, since $Y$ is a tail random variable, $\{Y\leq y\}$ is a tail event and hence $\mathbb{P}(Y\leq y)\in\{0,1\}$ for each $y\in\mathbb{R}$. It follows that there exists $c\in\mathbb{R}$ such that 

$$
  \mathbb{P}(Y\leq y) = \begin{cases} 0, &\quad y<c \\ 1, &\quad y\geq c \end{cases}
$$

Hence $\mathbb{P}(Y=c) = 1$.
</details>
</MathBox>

# Moments of random variables

<MathBox title='Moment' boxType='definition'>
If $a\in\mathbb{R}$ and $n\in\mathbb{N}$, the moment of $X$ about $a$ of order $n$ is defined as

$$
  \mathbb{E}\left[(X - a)^n \right]
$$
</MathBox>

## Expected value

The expected value (mean) of a real-valued random variable gives a measures of the center of the variables' distribution. In the following discussion, let $(\Omega, \mathcal{F}, \mathbb{P})$ and $(S,\mathcal{S},\mathbb{P})$ be probability spaces, and $X: \Omega\to S$ a random variable.

<MathBox title='Expected value' boxType='definition'>
The expected of $X$ is defined as the Lebesgue integral

$$
  \mathrm{E}[X] \equiv \mathbb{E}(X) := \int_{\Omega} X \;\mathrm{d}\mathbb{P}
$$

Depending on $S$ the expected value can take the following forms:
1. If $S$ is finite, then the expectation reduces to the simple function $\mathbb{E}(X) = \sum_{x\in S} x\mathbb{P}(X = x)$
2. If $S\subseteq[0,\infty)$, then $\mathbb{E}(X) = \sup\{\mathbb{E}(Y) : Y\textrm{ has finite range and }0\leq Y \leq X \}$
3. For general $S\subseteq\mathbb{R}$, then $\mathbb{E}(X) = \mathbb{E}(X^+) - \mathbb{E}(X^-)$ as long as the right side is not of the form $\infty - \infty$. Here $X_+ := \max(X, 0)$ and $X_- := \max(-X, 0)$ denote the positive and negative part of $X$, respectively.
4. If $A\in\subseteq\mathcal{F}$ then $\mathbb{E}(X;A) = \mathbb{E}(X\mathbf{1}_A)$ assuming that the expected value on the right exists. 
</MathBox>

<MathBox title='Properties of expectation' boxType='proposition'>
Let $X, Y : \Omega\to\mathbb{R}$ be random variables with $\mathbb{E}(|X|), \mathbb{E}(|Y|)\leq\infty$.
- Linearity: $\mathbb{E}(aX + bY) = a\mathbb{E}(X) + b\mathbb{E}(Y)$ for all $a, b \in \mathbb{R}$.
- Positivity: If $\mathbb{P}(X\geq 0) 1$ then $\mathbb{E}(X) \geq 0$ and $\mathbb{E}(X) = 0$ if and only if $\mathbb{P}(X=0) = 1$.
- Monotonicity: If $X \overset{a.s}{\leq} Y$, i.e. $\mathbb{P}\left( X\leq Y \right) = 1$, then $\mathbb{E}(X) \leq \mathbb{E}(Y)$.
- If $\mathbb{P}(X = Y)$, then $\mathbb{E}(X) = \mathbb{E}(Y)$.
- If $X, Y$ are independent, then $\mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y)$.
- If $X$ is symmetric about $a\in\mathbb{R}$, then $\mathbb{E}(X) = a$.
- Absolute value inequality: $|\mathbb{E}(X)| \leq \mathbb{E}(|X|)$.
  - If $\mathbb{E}(X)$ is finite, the equality holds if and only if $\mathbb{P}(X\geq 0) = 1$ or $\mathbb{P}(X\leq 0) = 1$.
- Hölder's inequality: If $p, q\in[1, \infty]$ with $\frac{1}{p} + \frac{1}{q}$, then $\mathbb{E}(|XY|) \leq \lVert X\rVert_p \cdot \lVert Y\rVert_q = \left[\mathbb{E}(|X|^p)\right]^{1/p} \left[\mathbb{E}(|X|^q)\right]^{1/q}$.

<details>
<summary>Proof</summary>

**Symmetry property:** By assumption, the distribution of $X - a$ is the same as the distribution of $a - X$ giving 

$$
\begin{align*}
  \mathbb{E}(a - X) &= \mathbb{E}(X - a) \\
  a - \mathbb{E}(X) &= \mathbb{E}(X) - a \\
  2\mathbb{E}(X) &= 2a \\
  \mathbb{E}(X) &= a
\end{align*}
$$
</details>
</MathBox> 

<MathBox title='Change of variables theorem' boxType='theorem'>
Suppose that $P$ is the probability distribution of $X$. If $g:S\to\mathbb{R}$ is measurable then, assuming that the expected value exists

$$
  \mathbb{E}[g(X)] = \int_\Omega g[X(\omega)]\,\mathrm{d}\mathbb{P}(\omega) = \int_S g(x)\,\mathrm{d}P(x)
$$
</MathBox> 

<MathBox title='Law of the unconscious statistician' boxType='theorem'>

Suppose that $\mu$ is a positive measure on $(S,\mathcal{S})$, and that the distribution of $X:\Omega\to S$ is absolutely continuous with respect to $\mu$, i.e. $\mu(A) = 0 \implies P(A) = \mathbb{P}(X\in A) = 0$ for $A\in\mathcal{S}$. By the Radon-Nikodym theorem, $X$ has a probability density function $f:X(A)\to\mathbb{R}$ such that

$$
  P(A) = \mathbb{P}(X\in A) = \int_A f\,\mathrm{d}\mu,\quad A\in\mathcal{S}
$$

If $g:S\to\mathbb{R}$ is measurable, then by changing variables

$$
  \mathbb{E}[g(X)] = \int_\Omega g[X(\omega)]\,\mathrm{d}\mathbb{P}(\omega) = \int_S g(x)\,\mathrm{d}P(x) = \int_S g(x)f(x)\,\mathrm{d}\mu(x)
$$

**Discrete distributions:** 
If $(S,\mathcal{P}(S), \#)$ is a discrete measure space, $X$ has a discrete distribution on $S$. Since $\#(A) = 0 \iff A=\emptyset$ and $\mathbb{P}(X\in\emptyset) = 0$, then $X$ is always absolutely continuous with respect to $\#$. The probability density function $f$ of $X$ with respect to $\#$ is simply $f(x) = \mathbb{P}(X = x)$ for $x\in S$. In this case

$$
  \mathbb{E}[g(X)] = \sum_{x\in S} g(x)f(x)
$$

If $X$ is real-valued and $g = 1$, this reduces to the original definition of expected value in the discrete case

$$
  \mathbb{E}(X) = \sum_{x\in S}xf(x) 
$$

**Continuous distributions:**
Suppose that $(\mathbb{R}^n,\mathcal(\mathbb{R}^n), \lambda_n)$ is a Euclidean measure space. The distribution of $X$ is absolutely continuous with respect to the Lebesgue measure $\lambda_n$ if $\lambda_n(A) = 0 \implies \mathbb{P}(X\in A) = A$. In this case,

$$
  \mathbb{E}[g(X)] = \int_S g(x)f(x)\,\mathrm{d}\lambda_n(x)
$$
</MathBox>

<MathBox title="Markov's inequality" boxType='theorem'>
If $X$ is a nonnegative random variable then

$$
  \mathbb{P}(X\geq x) \leq\frac{\mathbb{E}(X)}{x},\quad x>0
$$

As a direct corollary, if $X$ is a real-valued random variable and $k\in(0,\infty)$, then

$$
  \mathbb{P}(|X|\geq x) \leq\frac{\mathbb{E}\left(|X|^k \right)}{x^k},\quad x>0
$$

<details>
<summary>Proof</summary>

For $x > 0$, note that $x\cdot\mathbf{1}(X\geq x)\leq X$. Taking the expected value gives $x\mathbb{P}(X\geq x)\leq\mathbb{E}(X)$.

For $k\geq 0$, the function $x\mapsto x^k$ is strictly increasing on $[0,\infty)$. Applying Markov's inequality gives

$$
  \mathbb{P}(|X|\geq x) = \mathbb{P}\left(|X|^k \geq x^k) \leq\frac{\mathbb{E}\left(|X|^k \right)}{x^k}
$$

</details>
</MathBox>

<MathBox title="Jensen's inequality" boxType='proposition'>
Let $X$ be an integrable random variable with $\mathbb{E}(|X|) < \infty. $If $\phi: \mathbb{R}\to\mathbb{R}$ is a convex function and $\mathbb{E}\left[|\phi(X)|\right] < \infty$, then 

$$
  \mathbb{E}\left[\phi(X)\right]\overset{\textrm{a.s.}}{\geq}\phi\left[\mathbb{E}(X)\right]
$$

Two useful special cases are $\left|\mathbb{E}(X)\right| < \mathbb{E}(|X|)$ and $\left[\mathbb{E}(X)\right]^2 \leq \mathbb{E}\left(X^2\right)$

<details>
<summary>Proof</summary>

Recall that a convex function is the supremum of countably many affine functions, i.e. for $x\in\mathbb{R}$

$$
  \phi(x) = \sup_{n\in\mathbb{N}} (a_n x + b_n),\quad a_n, b_n\in\mathbb{R}
$$

Thus, for all $n\in\mathbb{N}$ we have $\mathbb{E}[\phi(X)] \overset{\textrm{a.s.}{\geq} a_n \mathbb{E}(X) + b_n$. Using the fact that the supremum is over a countable set we get

$$
  \mathbb{E}[\phi(X)] \geq\sup_{n\in\mathbb{N}}\left[a_n\mathbb{E}(X) + b_n\right] = \phi[\mathbb{E}(X)]
$$
</details>
</MathBox>

### Convergence theorems

<MathBox title='Monotone convergence theorem' boxType='theorem'>
Let $(X_n)_{n\in\mathbb{N}}$ be an increasing sequence of random variables with $0\leq X_n \xrightarrow{n\to\infty} X$. Then

$$
  \lim_{n\to\infty} \mathbb{E}(X_n)\overset{\textrm{a.s.}}{=}\mathbb{E}(X)
$$
</MathBox>

<MathBox title="Fatous's lemma" boxType='lemma'>
Let $(X_n)_{n\in\mathbb{N}}$ be an increasing sequence of random variables with $X_n \geq 0$ for all $n$. Then

$$
  \mathbb{E}(\liminf_{n\to\infty} X_n)\overset{\textrm{a.s.}}{\leq}\liminf_{n\to\infty} \mathbb{E}(X)
$$
</MathBox>

<MathBox title='Dominated convergence theorem' boxType='theorem'>
Let $Y$ be a nonnegative random variable with $\mathbb{E}(Y)<\infty$ and suppose that $(X_n)_{n\in\mathbb{N}}$ is a sequence of random variables with $X_n \underset{n\to\infty}{\uparrow} X$. If $|X_n| \leq Y \leq\infty$ Then

$$
\begin{gather*}
  \mathbb{E}(|X|)\leq\mathbb{E}(Y) \leq\infty \\
  \lim_{n\to\infty} \mathbb{E}(X) \overset{\textrm{a.s.}}{=} \mathbb{E}(X)
\end{gather*}
$$
</MathBox>

## Variance

<MathBox title='Variance and standard deviation' boxType='definition'>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X: \Omega\to\mathbb{R}$ a random variable with expected value $\mathrm{E}(X)$. The variance of $X$ is defined as 

$$
\begin{align*}
  \mathrm{var}(X) :=& \mathbb{E}\left(\left[ X - \mathbb{E}(X) \right]^2 \right) \\
  =& \mathbb{E}(X^2) - \mathbb{E}(X)^2
\end{align*}
$$

The standard deviation of $X$ is defined as

$$
  \sigma_X = \mathrm{sd}(X) := \sqrt{\mathrm{var}(X)}
$$

<details>
<summary>Details</summary>

$$
\begin{align*}
  \mathrm{var}(X) &:= \mathbb{E}\left[\left( X - \mathbb{E}(X) \right)^2 \right] \\
  &= \mathbb{E}\left[ X^2 - 2\mathbb{E}(X)\cdot X + \mathbb{E}(X)^2  \right] \\
  &= \mathbb{E}\left(X^2 \right) - \mathbb{E}\left[ 2 \mathbb{E}(X)\cdot X \right] + \mathbb{E}\left[\mathbb{E}(X)^2 \right] \\
  &= \mathbb{E}\left(X^2 \right) - 2 \mathbb{E}(X) \mathbb{E}(X) + \mathbb{E}\left[\mathbb{E}(X)^2 \right] \\
  &= \mathbb{E}\left(X^2 \right) - 2 \mathbb{E}(X)^2 + \mathbb{E}(X)^2 \underbrace{\int_\Omega 1 \;\mathrm{d}P}_{=P(\Omega) = 1} \\
  &= \mathbb{E}\left(X^2 \right) - \mathbb{E}(X)^2 
\end{align*}
$$
</details>
</MathBox> 

Recall that the second moment of $X$ about $a\in\mathbb{R}$ is $\mathbb{E}\left[ (X-a)^2 \right]$. Thus, the variance is the second moment of $X$ about the mean $\mu_X = \mathbb{E}(X)$, or equivalently, the second central moment of $X$. In general, the second moment of $X$ about $a\in\mathbb{R}$ represents the mean square error if $a$ is an estimate of $X$. 

<MathBox title='Properties of variance' boxType='proposition'>
1. Positive definiteness: $\mathrm{var}(X) \geq 0$ and $\mathrm{var}(X) = 0$ if and only if $\mathbb{P}(X = c) = 1$ for some constant $c = \mathbb{E}(X)$.
2. Variance of linear combinations: If $a,b\in\mathbb{R}$
  a. $\mathrm{var}(a + bX) = b^2\mathrm{var}(X)$
  b: $\mathrm{sd}(a + bX) = |b|\mathrm{var}(X)$

<details>
<summary>Proof</summary>

Let $\mu = \mathbb{E}(X)$

1. These results follows from the positive property of expected value. Evidently, $(X - \mu)^2 \geq 0$ with probability $1$ so $\mathbb{E}\left[(X -\mu)^2\right]\geq 0$. Additionally, $\mathbb{E}\left[(X -\mu)^2\right] = 0$ if and only if $\mathbb{P}(X = \mu) = 1$.
2. By linearity, $\mathbb{E}(a + bX) = a + b\mu$, giving
$$
\begin{align*}
  \mathrm{var}(a + bX) &= \mathbb{E}\left([(a + bX) - (a + b\mu)]^2 \right) \\
  &= \mathbb{E}\left[b^2(X - \mu)^2\right] = b^2\mathrm{var}(X)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Standard score' boxType='definition'>
Suppose that $X$ is a random variable with mean $\mu$ and variance $\sigma^2$. The *standard score* of $X$ is defined as the random variable

$$
  Z := \frac{X - \mu}{\sigma}
$$

with $\mathbb{E}(Z) = \frac{1}{\sigma}[\mathbb{E}(X) - \mu] = 0$ and $\mathrm{var}(Z) = \frac{1}{\sigma^2}\mathrm{var}(X) = 1$.
</MathBox> 

The standard score of $X$ measures the distance from $\mathbb{E}(X)$ to $X$ in terms of standard deviations.

<MathBox title='' boxType='proposition'>
Let $Z$ denote the standard score of $X$, and suppose that $Y = a + bX$ where $a,b\in\mathbb{R}$ and $b\neq 0$. Then
1. If $b > 0$, the standard score of $Y$ is $Z$
2. If $b < 0$, the standard score of $Y$ is $-Z$

<details>
<summary>Proof</summary>

Since $\mathbb{E} = a + b\mathbb{E}(X)$ and $\mathrm{sd}(Y) = |b|\mathrm{sd}(X)$, then

$$
  \frac{Y - \mathbb{E}}{\mathrm{sd}(Y)} = \frac{b}{|b|}\frac{X - \mathbb{E}(X)}{\mathrm{sd}(X)} 
$$
</details>
</MathBox> 

<MathBox title='Coefficient of variation' boxType='definition'>
Suppose that $X$ is a random variable with $\mathrm{E}(X) \neq 0$. The coefficient of variation is the ratio of the standard deviation to the mean

$$
  \mathrm{cv}(X) := \frac{\mathrm{sd}}{\mathbb{E}(X)}
$$
</MathBox> 

<MathBox title="Chebyshev's inequalities" boxType='proposition'>
Suppose that $X$ is a real-valued random variable with mean $\mu_X = \mathbb{E}(X)\in\mathbb{R}$ and standard deviation $\sigma_X = \mathrm{sd}(X)\in(0,\infty)$

**Chebyshev's first inequality**

$$
  \mathbb{P}(|X - \mu_X|\geq t) \leq \frac{\sigma_X^2}{t^2},\quad t>0
$$

**Chebyshev's second inequality**

$$
  \mathbb{P}(|X - \mu_X|\geq k\sigma) \leq \frac{1}{k^2},\quad k>0
$$

<details>
<summary>Proof</summary>

Chebyshev's first inequality can be proved by applying Markov's inequality to the random variable $Y = (X - \mu_X)^2$ with $\mathbb{E}(Y) = \left[(X - \mu_X)^2 \right] = \sigma_X^2$

$$
  \mathbb{P}(|X - \mu|\geq t) = \frac{\mathbb{E}\left[ (X - \mu_X)^2 \right]}{t^2} = \frac{\sigma_X^2}{t^2}
$$

Chebyshev's second inequality follows by substituting $t = k\sigma$.
</details>
</MathBox>

## Skewness

<MathBox title='Skewness' boxType='definition'>
Let $X$ be a random variable with mean $\mu$ and variance $\sigma^2$. The skewness of $X$ is the third moment of the standard score of $X$

$$
\begin{align*}
  \mathrm{skew}(X) :=& \mathbb{E}\left[\left( \frac{X - \mu}{\sigma} \right)^3 \right] \\
  =& \frac{\mathbb{E}(X^3) - 3\mu\sigma^2 - \mu^3}{\sigma^3}
\end{align*}
$$

Depending on the sign of its skewness, a distribution $X$ is called
1. Positively skewed if $\matrm{skew}(X)> 0$.
2. Negatively skewed if $\matrm{skew}(X)< 0$.
3. Unskewed if $\matrm{skew}(X) = 0$.

<details>
<summary>Details</summary>

Note that $(X - \mu)^3 = X^3 - 3X^2\mu + 3X\mu^2 - \mu^3$ and $\mathbb{E}(X^2) = \sigma^2 + \mu^2$. From the linearity of expected value we have

$$
\begin{align*}
  \mathbb{E}\left[(X - \mu)^3 \right] &= \mathbb{E}(X^3) - 3\mu\mathbb{E}(X^2) + 3\mu^2\mathbb{E}(X) - \mu^3 \\
  &= \mathbb{E}(X^3) - 3\mu\mathbb{E}(X^2) + 2\mu^3 \\
  &= \mathbb{E}(X^3) - 3\mu\sigma^2 - \mu^3
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Properties of skewness' boxType='proposition'>
Let $X$ be a real-valued random variable with $\mathbb{E}(X) = \mu$ and $\mathrm{var}(X) = \sigma^2$.
1. If the distribution of $X$ is symmetric $\mathrm{skew}(X)$.
2. If $a\in\mathbb{R}$ and $b\in\mathbb{R}\setminus\{0\}$
  a. $\mathrm{skew}(a + bX) = \mathrm{skew}(X) if $b > 0$
  b. $\mathrm{skew}(a + bX) = -\mathrm{skew}(X) if $b < 0$

<details>
<summary>Proof</summary>

1. Recall that if $X$ is symmetric about $a\in\mathbb{R}$ then $\mathbb{E}(X) = a$, such that $\skew(X) = \frac{\mathbb{E}\left[(X - a)^3 \right]}{\sigma^3}$. By symmetry and linearity

$$
  \mathbb{E}[(X - a)^3] = \mathbb{E}[(a - X)^3] = -\mathbb{E}[(X - a)^3]
$$

It follows that $\mathbb{E}[(X - a)^3] = 0$.

2. Let $Z = \frac{X - \mu}{\sigma}$, the standard score of $X$. Recall that the standard score of $a + bX$ is
  a. $Z$ if $b > 0$
  b. $-Z$ if $b < 0$

The result follows since skewness is defined in terms of an odd power of $Z$.
</details>
</MathBox>

## Kurtosis

Kurtosis is a measure of the fatness in the tails of a distribution.

<MathBox title='Kurtosis' boxType='definition'>
Let $X$ be a random variable with mean $\mu$ and variance $\sigma^2$. The kurtosis of $X$ is the fourth moment of the standard score of $X$

$$
\begin{align*}
  \mathrm{kurt}(X) :=& \mathbb{E}\left[\left( \frac{X - \mu}{\sigma} \right)^4 \right] \\
  =& \frac{\mathbb{E}(X^4) - 4\mu\mathbb{E}(X^3) + 6\mu^2\sigma^2 + 3\mu^4}{\sigma^4}
\end{align*}
$$

<details>
<summary>Details</summary>

Note that $(X - \mu)^4 = X^4 - 4X^3\mu + 6X^2\mu^2 - 4X\mu^3 + \mu^4$ and $\mathbb{E}(X^2) = \sigma^2 + \mu^2$. From the linearity of expected value we have

$$
\begin{align*}
  \mathbb{E}\left[(X - \mu)^3 \right] &= \mathbb{E}(X^4) - 4\mu\mathbb{E}(X^3) + 6\mu^2\mathbb{E}(X^2) - 4\mu^3\mathbb{E}(X) + \mu^4 \\
  &= \mathbb{E}(X^4) - 4\mu\mathbb{E}(X^3) + 6\mu\mathbb{E}(X^2) - 3\mu^4 \\
  &= \mathbb{E}(X^4) - 4\mu\mathbb{E}(X^3) + 6\mu^2\sigma^2 + 3\mu^4
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Invariance under linear transformations' boxType='proposition'>
If $a\in\mathbb{R}$ and $b\in\mathbb{R}\setminus\{0\}$, then $\mathrm{kurt}(a + bX) = \mathrm{kurt}(X)$
  a. $\mathrm{skew}(a + bX) = \mathrm{skew}(X) if $b > 0$
  b. $\mathrm{skew}(a + bX) = -\mathrm{skew}(X) if $b < 0$

<details>
<summary>Proof</summary>

Let $Z = \frac{X - \mu}{\sigma}$, the standard score of $X$. Recall that the standard score of $a + bX$ is
1. $Z$ if $b > 0$
2. $-Z$ if $b < 0$

The result follows since kurtosis is defined in terms of an even power of $Z$.
</details>
</MathBox>

## Covariance

Suppose that $X$ and $Y$ are real-valued random variables with means $\mathbb{E}(X), \mathbb{E}(Y)$ and variances $\mathrm{var}(X),\mathrm{var}(Y)$, respectively.

<MathBox title='Covariance and correlation' boxType='definition'>
The covariance of $(X, Y)$ is defined by

$$
\begin{align*}
  \mathrm{cov}(X,Y) &:= \mathbb{E}([X-\mathbb{E}(X)][Y-\mathbb{E}(Y)]) \\
  &= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{Y}
\end{align*}
$$

and, assuming the variances are positive, the correlation of $(X, Y)$ is defined by

$$
\begin{align*}
  \rho_{X,Y} &= \mathrm{corr}(X,Y) := \frac{\mathrm{cov}(X,Y)}{\sigma_X \sigma_Y} \\
  &= \frac{\mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)}{\sqrt{\mathbb{E}(X^2) - \mathbb{E}(X)^2}\cdot\sqrt{\mathbb{E}(X^2) - \mathbb{E}(X)^2}}
\end{align*}
$$

Depending on the sign of their coveriance, $X$ and $Y$ are called:
1. Positively correlated if $\mathrm{cov}(X, Y) > 0$.
2. Negatively correlated if $\mathrm{cov}(X, Y) < 0$.
3. Uncorrelated if $\mathrm{cov}(X, Y) = 0$.

<details>
<summary>Details</summary>

$$
\begin{align*}
  \mathrm{cov}(X,Y) &= \mathbb{E}([X-\mathbb{E}(X)][Y-\mathbb{E}(Y)]) \\
  &= \mathbb{E}(XY - X\mathbb{E}[Y] - \mathbb{E}[X]Y + \mathbb{E}[X]\mathbb{E}[Y]) \\
  &= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) - \mathbb{E}(X)\mathbb{E}(Y) \\
  &= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{Y}
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Properties of covariance' boxType='proposition'>
1. Symmetry: $\mathrm{cov}(X,Y) = \mathrm{cov}(Y,X)$
2. Covariance generalizes variance: $\mathrm{cov}(X,X) = \mathbb{E}([X-\mathbb{E}(X)][X-\mathbb{E}(X)]) = \mathbb{E}([X - \mathbb{E}]^2) = \mathrm{var}X$
3. If $X$ and $Y$ are independent, then they are uncorrelated, i.e. $\mathrm{cov}(X,Y) = 0$.
4. Bilinearity: If $X, Y, Z$ are random variables and $a,b$ are real constants then
  a. $\mathrm{cov}(aX + bY, Z) = a\mathrm{cov}(X, Z) + b\mathrm{cov}(Y, Z)$
  b. $\mathrm{cov}(X, aY + bZ) = a\mathrm{cov}(X, Y) + b\mathrm{cov}(X, Z)$
  c. In the general case, suppose that $(X_i)_{i=1}^{n\in\mathbb{N}}$ and $(Y_i)_{i=1}^{m\in\mathbb{N}}$ are sequences of random variables, and that $(a_i)_{i=1}^{n\in\mathbb{N}}$ and $(b_i)_{i=1}^{m\in\mathbb{N}}$ are constants. Then
$$
  \mathrm{cov}\left( \sum_{i=1}^n a_i X_i, \sum_{j=1}^m b_j Y_j \right) = \sum_{i=1}^n\sum_{j=1}^m a_i b_j \mathrm{cov}(X_i, X_j)
$$

<details>
<summary>Proof</summary>

1. This follows trivially from the definition.
2. Let $\mu = \mathbb{E}(X)$. Then $\mathrm{cov}(X, X) = \mathbb{E}\left[(X - \mu)^2 \right] = \mathrm{var}(X)$.
3. If $X$ and $Y$ are independent then $\mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y)$
4a. 
$$
\begin{align*}
  \mathrm{cov}(aX + bY, Z) &= \mathbb{E}[(aX + bY)Z] - \mathbb{E}(aX + bY)\mathbb{E}(Z) \\
  &= \mathbb{E}(aXZ + bYZ) - [a\mathbb{E}(X) + b\mathbb{E}(Y)]\mathbb{E}(Z) \\
  &= a[\mathbb{E}(XZ) - \mathbb{E}(X)\mathbb{E}(Z)] + b[\mathbb{E}(YZ) - \mathbb{E}(Y)\mathbb{E}(Z)] \\
  &= a\mathrm{cov}(X, Z) + b\mathrm{cov}(Y, Z)
\end{align*}
$$
4b.
$$
\begin{align*}
  \mathrm{cov}(X, aY + bZ) &= \mathbb{E}[X(aY + bZ)] - \mathbb{E}(X)\mathbb{E}(aY + bZ) \\
  &= \mathbb{E}(aXY + bXZ) - \mathbb{E}(X)[a\mathbb{E}(Y) + b\mathbb{E}(Z)] \\
  &= a[\mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)] + b[\mathbb{E}(XZ) - \mathbb{E}(X)\mathbb{E}(Z)] \\
  &= a\mathrm{cov}(X, Y) + b\mathrm{cov}(X, Z)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Properties of correlation' boxType='proposition'>
1. Symmetry: $\mathrm{cor}(X,Y) = \mathrm{cor}(Y,X)$
2. The correlation between $X$ and $Y$ is the covariance of corresponding standard scores
$$
\begin{align*}
  \mathrm{cor}(X, Y) &= \mathrm{cov}\left(\frac{X - \mathbb{E}(X)}{\mathrm{sd}(X)}, \frac{Y - \mathbb{E}(Y)}{\mathrm{sd}(Y)} \right) \\
  &= \mathbb{E}\left( \frac{X - \mathbb{E}(X)}{\mathrm{sd}(X)}\frac{Y - \mathbb{E}(Y)}{\mathrm{sd}(Y)} \right)
$$
3. If $a, b\in\mathbb{R}$ and $b\neq 0$ then:
  a. $\mathrm{cor}(a + bX, Y) = \mathrm{cor}(X, Y)$ if $b > 0$
  b. $\mathrm{cor}(a + bX, Y) = -\mathrm{cor}(X, Y)$ if $b < 0$

<details>
<summary>Proof</summary>

1. This follows trivially from the definition.
2. From the definitions and linearity of expected value

$$
\begin{align*}
  \mathrm{cor}(X, Y) &= \frac{\mathrm{cov}(X, Y)}{\mathrm{sd}(X)\mathrm{sd}(Y)} \\
  &= \frac{\mathbb{E}([X - \mathbb{E}(X)][Y - \mathbb{E}(Y)])}{\mathrm{sd}(X)\mathrm{sd}(Y)} \\
  &= \mathbb{E}\left( \frac{X - \mathbb{E}(X)}{\mathrm{sd}(X)}\frac{Y - \mathbb{E}(Y)}{\mathrm{sd}(Y)} \right)
\end{align*}
$$

3. Let $Z$ denote the standard score of $E$. If $b > 0$, the standard score of $a + bX$ is also $Z$. If $b < 0$, the standard score of $a + bX$ is $-Z$. The result follows from $(2)$. 
</details>
</MathBox>

<MathBox title='Variance of a sum' boxType='proposition'>
If $(X_i)_{i=1}^{n\in\mathbb{N}}$ is a sequence of real-valued random variables then

$$
\begin{align*}
  \mathrm{var}\left(\sum_{i=1}^n X_i \right) &= \sum_{i=1}^n \sum_{j=1}^n \mathrm{cov}(X_i, X_j) \\
  &= \sum_{i=1}^n \mathrm{var}(X_i) + \sum_{\{(i, j): i<j\}} \mathrm{cov}(X_i, X_j)
\end{align*}
$$

If all $X_i$ are pairwise uncorrelated for each $i$, then this reduces to

$$
  \mathrm{var}\left(\sum_{i=1}^n X_i) = \sum_{i=1}^n \mathrm{var}(X_i)
$$

<details>
<summary>Proof</summary>

$$
\begin{align*}
  \mathrm{var}\left( \sum_{i=1}^n X_i) &= \mathrm{cov}\left(\sum_{i=1}^n X_i, \sum_{j=1}^n X_j \right) \\
  &= \sum_{i=1}^j \sum_{j=1}^n \mathrm{cov}(X_i, X_j)
\end{align*}
$$

The result follows since $\mathrm{cov}(X_i, X_i) = \mathrm{var}(X_i)$ for each $i$ and $\mathrm{cov}(X_i, X_j) = \mathrm{cov}(X_j, X_i)$ for $i\neq j$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $X$ and $Y$ are real-valued random variables then 

1. $\mathrm{var}(X + Y) + \mathrm{var}(X - Y) = 2[\mathrm{var}(X) + \mathrm{var}(Y)]$
2. If $\mathrm{var}(X) = \mathrm{var}(Y)$ then $X + Y$ and $X - Y$ are uncorrelated.

<details>
<summary>Proof</summary>

1. From the variance of a sum with $n=2$ we get

$$
\begin{align*}
  \mathrm{var}(X + Y) &= \mathrm{var}(X) + \mathrm{var}(Y) + 2\mathrm{cov}(X, Y) \\
  \mathrm{var}(X - Y) &= \mathrm{var}(X) + \mathrm{var}(-Y) + 2\mathrm{cov}(X, -Y) \\
  &= \mathrm{var}(X) + \mathrm{var}(Y) - 2\mathrm{cov}(X, Y)
\end{align*}
$$

Adding the variances gives the result.

2. From linearity and symmetry of covariance we get

$$
\begin{align*}
  \mathrm{cov}(X + Y, X - Y) &= \mathrm{var}(X, X) - \mathrm{cov}(X, Y) + \mathrm{cov}(Y, X) - \mathrm{cov}(Y, Y) \\
  &= \mathrm{var}(X) - \mathrm{var}(Y)
\end{align*}
$$

If $X + Y$ and $X - Y$ are uncorrelated then $\mathrm{var}(X) = \mathrm{var}(Y)$. 
</details>
</MathBox>

### The best linear predictor

Consider two random variables $X$ and $Y$, where $X$ is observable while $Y$ is not. One way to estimate $Y$ is to find the linear function from observed values of $X$ that is closest to $Y$ in mean square sense. The best linear predictor for $Y$ is a linear function of $X$ that shares the same expected value as $Y$, and whose covariance with $X$ is same as that of $Y$.

<MathBox title='Criteria of the linear predictor' boxType='proposition'>
Let $X$ and $Y$ be real-valued random variables. The random variable

$$
  L(Y|X) := \mathbb{E}(Y) + \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}[X - \mathbb{E}(X)]
$$

is the only linear function of $X$ that satisfies

1. $\mathbb{E}[L(X|Y)] = \mathbb{E}(Y)$
2. $\mathrm{cov}[X, L(Y|X)] = \mathrm{cov}(X, Y)$
  a. Equivalently, $\mathrm{cov}[Y - L(Y|X), U] = 0$ for every linear function $U$ of $X$

<details>
<summary>Proof</summary>

1. By linearity of the expected value
$$
\begin{align*}
  \mathbb{E}[L(Y|X)] &= \mathbb{E}(Y) + \frac{\mathrm{var}(X, Y)}{\mathrm{var}(X)}[\mathbb{E}(X) - \mathbb{E}(X)]
  &= \mathbb{E}(Y)
\end{align*}
$$

2. By linearity of covariance
$$
\begin{align*}
  \mathrm{cov}[X, L(Y|X)] &= \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}\mathrm{cov}(X, X) \\
  &= \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}\mathrm{var}(X) = \mathrm{cov}(X, Y)
\end{align*}
$$
2a. Suppose that $U = a + bX$, where $a, b\in\mathbb{R}$, then
$$
\begin{align*}
  \mathrm{cov}[Y - L(Y|X), U] &= b\mathrm{cov}[Y - L(Y|X), X] \\
  &= b\left(\mathrm{cov}(Y, X) - \mathrm{cov}[L(Y|X), X]\right) = 0
\end{align*}
$$

Conversely, to show the uniquenes of $L(Y|X)$, suppose that $U = a + bX$ satisfies 
1. $\mathbb{E}(U) = \mathbb{E}(Y)$
2. $\mathrm{cov}(X, U) = \mathrm{cov}(X, Y)$
  a. Equivalently, $\mathrm{cov}(Y - U, V) = 0$ for every linear function $V$ of $X$ 

The second equality gives 

$$
\begin{align*}
  \mathrm{cov}(X, Y) &= \mathrm{cov}(X, a + bX)= b\mathrm{cov}(X, X) = b\mathrm{var}(X) \\
  b &= \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}
\end{align*}
$$

The first equation gives

$$
\begin{align*}
  \mathbb{E}(Y) &= \mathbb{E}(a + bX) = a + b\mathbb{E}(X) =  \\
  a &= \mathbb{E}(Y) - b\mathbb{E}(X) = \mathbb{E}(Y) - \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}\mathbb{E}(X)
\end{align*}
$$

Hence $U = \mathbb{E}(Y) + \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}[X - \mathbb{E}(X)] = L(Y|X)$. Equivalently, by letting $V =  X$, then from equation $(2a)$ we get

$$
\begin{align*}
  \mathrm{cov}(Y - U, X) &= 0 \\
  \mathrm{cov}(U, X) = \mathrm{cov}(Y, X)
\end{align*}
$$

Hence $U = L(Y|X)$.
</details>
</MathBox>

<MathBox title='Properties of the linear predictor' boxType='proposition'>
The linear predictor $L(Y|X)$ has the following properties for random variables $X, Y, Z$ and constants $a, b$

1. $\mathrm{var}[L(Y|X)] = \frac{\mathrm{cov}^2(X, Y)}{\mathrm{var}(X)}$
2. $\mathrm{cov}[L(Y|X), Y] = \frac{\mathrm{cov}^2(X, Y)}{\mathrm{var}(X)}$
3. Linearity: $L(aY + bZ|X) = aL(Y|X) + bL(Z|X)$

<details>
<summary>Proof</summary>

1. 
$$
\begin{align*}
  \mathrm{var}[L(Y|X)] &= \left[\frac{\mathrm{cov}(X, Y)^2}{\mathrm{var}(X)}\right]^2 \mathrm{var}(X) \\
  &= \frac{\mathrm{cov}^2(X, Y)}{\mathrm{var}(X)}
\end{align*}
$$

2. 
$$
\begin{align*}
  \mathrm{cov}[L(Y|X), Y] &= \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}\mathrm{cov}(X, Y) \\
  &= \frac{\mathrm{cov}^2(X, Y)}{\mathrm{var}(X)}
\end{align*}
$$

3. This follows from linearity of expected value and covariance
$$
\begin{align*}
  L(aY + bZ|X) &= \mathbb{E}(aY + bZ) + \frac{\mathrm{cov}(X, aY + bZ)}{\mathrm{var}(X)}[X - \mathbb{E}(X)] \\
  &= a\left(\mathbb{Y} + \frac{\mathrm{cov}(X, Y)}{\mathrm{var}(X)}[X - \mathbb{E}(X)] \right) + b\left(\mathbb{Z} + \frac{\mathrm{cov}(X, Z)}{\mathrm{var}(X)}[X - \mathbb{E}(X)] \right) \\
  &= aL(Y|X) + bL(Z|X)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Best linear predictor' boxType='proposition'>
The linear predictor $L(Y|X)$ is the linear function of $X$ that is closest to $Y$ in the mean square sense, i.e. for any linear function $U$ of $X$

$$
  \mathbb{E}\left( [Y - L(Y|X)]^2 \right) \leq \mathbb{E}[(Y - U)^2]
$$

Equality holds if and only if $U = L(Y|X)$ with probability $1$. The mean square error when $L(Y|X)$ is used as a predictor of $Y$ is

$$
  \mathbb{E}\left([Y - L(Y|X)]^2 \right) = \mathbb{var}(Y)\left[1 - \cor^2(X, Y) \right]
$$

Since the mean square error $\mathbb{E}\left([Y - L(Y|X)]^2 \right) \geq 0$, it follows that $\mathrm{cor}^2 (X, Y) \leq 1$. The sign of $\mathrm{cor}(X, Y)$ corresponds with sign of the slope in $L(Y|X)$.

<details>
<summary>Proof</summary>

For clearer notation, we abbreviate $L(Y|X)$ by $L$. Suppose that $U$ is a linear function of $X$. Then

$$
\begin{align*}
  \mathbb{E}\left[(Y - U)^2 \right] &= \mathbb{E}\left([(Y - L)(L - U)]^2\right) \\
  &= \mathbb{E}\left[(Y - L)^2 \right] + 2\mathbb{E}[(Y - L)(L - U)] + \mathbb{E}\left[(L - U)^2\right]
\end{align*}
$$

Noting that $Y - L$ has mean $0$, we recognize the middle term as $\mathrm{cov}(Y - L, L - U)$. Since $L$ and $U$ are linear functions of $X$, then so is $L- U$, and $\mathrm{cov}(Y - L, L - U) = 0$. Hence

$$
\begin{align*}
  \mathbb{E}\left[(Y - U)^2 \right] &= \mathbb{E}\left[(Y - L)^2 \right] + \mathbb{E}\left[(L - U)^2\right] \\
  &\geq \mathbb{E}\left[(Y - L)^2\right]
\end{align*}
$$

Equality holds if and only if $\mathbb{E}\left[(L - U)^2\right] = 0$, if and only if $\mathbb{P}(L = U) = 1$.

Again, since $Y - L$ has mean $0$

$$
\begin{align*}
  \mathbb{E}\left[(Y - L)^2 \right] &= \mathrm{var}(Y - L) \\
  &= \mathrm{var}(Y) - 2\mathrm{cov}(L, Y) + \mathrm{var}(L) \\
  &= \mathrm{var}(Y) - \frac{\mathrm{cov}^2(X, Y)}{\mathrm{var}(X)} \\
  &= \mathrm{var}(Y)\left[1 - \frac{\mathrm{cov}^2 (X, Y)}{\mathrm{var}(X)\mathrm{var}(Y)} \right] \\
  &= \mathrm{var}(Y)\left[1 - \mathrm{cor}^2(X, Y) \right]
\end{align*}
$$
</details>
</MathBox>

## Conditional moments

<MathBox title='Conditional expectation' boxType='definition'>
Suppose that $X\in\mathcal{L}_1(\Omega,\mathcal{F},\mathbb{P})$ is an integrable random variable, i.e. $\mathbb{E}(|X|) < \infty$, and let $\mathcal{G}\subseteq\mathcal{F}$ be a sub $\sigma$-algebra of $\mathcal{F}$. The conditional expectation of $X$ given $\mathcal{G}$ is the random variable $\mathbb{E}(X|\mathcal{G})$ defined by the following properties

1. $\mathbb{E}(X|\mathcal{G})$ is measurable with respect to $\mathcal{G}$
2. If $A\in\mathcal{G}$ then $\mathbb{E}[\mathbb{E}(X|\mathcal{G})\mathbf{1}_A] = \mathbb{E}(X\mathbf{1}_A)$
  a. Equivalently, if $Z\in\mathcal{L}_1(\Omega, \mathcal{G}, \mathbb{P})$ is $\mathcal{G}$-measurable and $\mathbb{E}(|ZX|) < \infty$ then $\mathbb{E}\left[Z \mathbb{E}(X|\mathcal{G})\right] = \mathbb{E}(ZX)$

If $X\in \mathcal{L}^2(\Omega,\mathcal{F},\mathbb{P})$ is square integrable, then the conditional expectation $\mathbb{E}(X|\mathcal{G})$ is defined as the orthogonal projection of $X$ onto the closed subspace $\mathcal{L}^2(\Omega,\mathcal{F},\mathbb{P})$. The orthogonal projection $\mathbb{E}(X|\mathcal{G})$ minimizes the squared difference $\mathbb{E}(X - Y)^2$ among all random variables $Y\in \mathcal{L}^2(\Omega,\mathcal{G},\mathbb{P})$.

<details>
<summary>Proof</summary>

The existence of $\mathbb{E}(X|\mathcal{G})$ can be established with the Radon-Nikodym theorem. Assuming $X\geq 0$, we define the finite $\sigma$-measure for $G\in\mathcal{G}$

$$
  \mu(G) = \int_G X\;\mathrm{d}\mathbb{P} := \mathbb{E}(X\cdot\mathbf{1}_G)
$$

By construction $P(G) = \mathbb{P}(X\in G) = 0 \implies \mu(X) = 0$, so that $\mu$ is absolutely continuous with respect to $P$, i.e. $\mu\ll P$. By the Radon-Nikodym theorem, there is a random variable $Y\in\mathcal{G} = \frac{\mathrm{d}\mu}{\mathrm{d}\mathbb{P}} := \mathbb{E}(X|\mathcal{G})$, giving

$$
  \int_G X\;\mathrm{d}\mathbb{P} = \int_G \mathbb{E}(X|\mathcal{G})\;\mathrm{d}\mathbb{P} \quad \forall G\in\mathcal{G}
$$

To show equivalence of the defining properties, first note that $(2a)$ implies $(2)$ since $Z = \mathbf{1}_A$ is $\mathcal{G}$-measurable if $A\in\mathcal{G}$. The converse, i.e $(2)$ implies $(2a)$ can be shown by bootstrapping. If $Z = \mathbf{1}_A$ for some $A\in\mathcal{G}$, then trivially $\mathbb{E}[Z\mathbb{E}(X|\mathcal{G})] = \mathbb{E}(ZX)$. Next, suppose that $Z$ is a $\mathcal{G}$-measurable simple random variable of the form $Z = \sum_{i\in I} a_i \mathbf{1}_{A_i}$ where $I$ is a finite index set, $a_i \geq 0$ and $A_i \in\mathcal{G}$ for $i \in I$. Then

$$
\begin{align*}
  \mathbb{E}[Z\mathbb{E}(X|\mathcal{G})] &= \mathbb{E}\left[\sum_{i\in I} a_i \mathbf{1}_{A_i} \mathbb{E}(X|\mathcal{G}) \right] \\
  &= \sum_{i\in I} a_i \mathbb{E}[\mathbf{1}_{A_i}\mathbb{E}(X|\mathcal{G})] \\
  &= \sum_{i\in I} a_i \mathbb{E}\left(\mathbf{1}_{A_i} \right) \\
  &= \mathbb{E}\left(\sum_{i\in I} a_i \mathbf{1}_{A_i} X \right) = \mathbb{E}(ZX)
\end{align*}
$$

Next suppose that $Z$ is nonnegative and $\mathcal{G}$-measurable. Then there exists a sequence of simple $\mathcal{G}$-measurable random variables $(Z_n)_{n\in\mathbb{N}}$ with $Z_n \underset{n\to\infty}{\uparrow} X$. By the previous step, $\mathbb{E}[Z_n \mathbb{E}(X|\mathcal{G})] = \mathbb{E}(Z_n X)$ for each $n$. Using the monotone convergence theorem in the limit $n\to\infty$ gives $\mathbb{E}[Z \mathbb{E}(X|\mathcal{G})] = \mathbb{E}(Z X)$. Finally, suppose that $Z$ is a general $\mathcal{G}$-measurable random variable. Then $Z = Z^+ - Z^-$ where $Z^+$ and $Z^-$ are the positive and negative parts of $Z$. Since these parts are nonnegative and $\mathcal{G}$-measurable, then $\mathbb{E}[Z^{\pm}(X|\mathcal{G})] = \mathbb{E}(Z^{\pm}X)$. Hence

$$
\begin{align*}
  \mathbb{E}[Z\mathbb{E}(X|\mathcal{G})] &= \mathbb{E}\left[(Z^+ - Z^-)\mathbb{E}(X|\mathcal{G}) \right] \\
  &= \mathbb{E}[Z^+\mathbb{E}(X|\mathcal{G})] - \mathbb{E}[Z^-\mathbb{E}(X|\mathcal{G})] \\
  &= \mathbb{E}(Z^+) - \mathbb{E}(Z^-) = \mathbb{E}(ZX)
\end{align*}
$$
</details>
</MathBox>

For a countably generated $\mathcal{G} = \sigma(Y)$ when $Y$ is a discrete variable, such that the space $\Omega$ is partitioned into disjoint sets $\Omega = \bigcup_n G_n$, the conditional expectation of a random variable $X$ given $ \sigma(Y)$ is

$$
  \mathbb{E}[X|\sigma(Y)] \overset{a.s.}{=} \sum_n \frac{\mathbb{E}(Y\mathbf{1}_{X=x_n})}{\mathbb{P}(X=x_n)}\mathbf{1}_{X=x_n} =\sum_n \frac{\mathbb{E}(X\mathbf{1}_{G_n})}{P(G_n)}\mathbf{1}_{G_n}
$$

Suppose that $X:\Omega\to S\subseteq\mathbb{R}$ and $Y:\Omega\to T\subseteq\mathbb{R}^n$ are Lebesgue-measurable random variables and that $(X,Y)$ has a joint continuous distribution with probability density function $f$. Then $Y$ has probability density function $h$ given by

$$
  h(y) = \int_S f(x,y)\mathrm{d}x,\quad y\in T
$$

Assuming $h(y) > 0$ for $y\in T$, a conditional probability density function of $X$ given $Y=y$ is defined by

$$
  g(x|y) = \frac{f(x,y)}{h(y)}
$$

If $\mathbb{E}(|X|)< \infty$, the conditional expectation of $X$ given $\sigma(Y)$ is

$$
  \mathbb{E}(X|Y) := \mathbb{E}[X|\sigma(Y)] = \int_S xg(x|\sigma(Y)),\mathrm{d}x
$$

<details>
<summary>Proof</summary>

We first show that the integral is measurable with respect to $\sigma(Y)$. Since $y\mapsto \int_S xg(x|y)\,\mathrm{d}x$ is measurable as a function from $T$ into $\mathbb{R}$, the random variable $\int_x g(x|Y)\,\mathrm{d}x$ is a measurable function of $Y$ and so is measurable with respect to $\sigma(Y)$. Next suppose that $B\in\sigma(Y)$. Then $B = \{Y\in A\}$ for some $A\in\mathcal{F}$. Then

$$
  \mathbb{E}\left[\mathbf{1}_B \int_S xg(x|Y)\,\mathrm{d}x \right] &= \mathbb{E}\left[\mathbf{1}_{Y\in A} \int_S xg(x|Y)\,\mathrm{d}x \right] \\
  &= \mathbb{E}\left[\mathbf{1}_{Y\in A} \int_S x\frac{f(x,y)}{h(y)}\,\mathrm{d}x \right] \\
  &= \int_A \int_S x\frac{f(x, y)}{h(y)}h(y)\,\mathrm{d}x\,\mathrm{d}y \\
  &= \int_{S\times A} xf(x,y)\mathrm{d}(x,y) \\
  &= \mathbb{E}(\mathbf{1}_{Y\in A}X) = \mathbb{E}(\mathbf{1}_B X)
$$
</details>

<MathBox title='Properties of conditional expectation' boxType='proposition'>
Suppose that $X, Y:\Omega\to\mathbb{R}$ are integrable random variables

- Expectation rule: $\mathbb{E}[\mathbb{E}(X|\mathcal{G})] = \mathbb{E}(X)$
- Positivity: $X \geq 0 \implies \mathbb{E}(X|\mathcal{G}) \geq 0$
- Linearity: $\mathbb{E}(aX + bY|\mathcal{G}) = a\mathbb{E}(X|\mathcal{G}) + b\mathbb{E}(Y|\mathcal{G})$ for $a,b\in\mathbb{R}$
- Monotonicity: $X \leq Y \implies \mathbb{E}(X|\mathcal{G})\leq\mathbb{E}(Y|\mathcal{Y})$
- Independence property: If $X$ is independent of $\mathcal{G}$ then $\mathbb{E}(X|\mathcal{G}) = \mathbb{E}(X)$
- $\mathcal{L}^p$-contractivity: If $X\in \mathcal{L}^p$ then $\mathbb{E}(X|\mathcal{G}) \in\mathcal{L}^p$ and $\lVert \mathbb{E}(X|\mathcal{G}\rVert_p \leq \lVert X \rVert_p$
- Stability: if $Y$ is a $\mathcal{G}$-measurable with $\mathbb{E}(|XY|)<\infty$, then $\mathbb{E}(XY|\mathcal{G}) = Y\mathbb{E}(X|\mathcal{G})$
- Tower property: $\mathcal{H}\subseteq\mathcal{G} \implies \mathbb{E}\left[\mathbb{E}(X|\mathcal{H})|\mathcal{G}\right] = \mathbb{E}(X|\mathcal{H}) = \mathbb{E}\left[\mathbb{E}(X|\mathcal{G})|\mathcal{H}\right]$

<details>
<summary>Proof</summary>

**Law of total expectation:** This follows immediately by letting $A = \Omega$ in the definition.

**Positivity:** Let $A = \{\mathbb{E}(X|\mathcal{G}) < 0 \}$. Note that $A\in\mathcal{G}$ and thus $\mathbb{E}(X\mathbf{1}_A) = \mathbb{E}[\mathbb{E}(X|\mathcal{G})\mathbf{1}_A]$. Since $X\overset{\textrm{a.s}}{\geq} 0$ we have $\mathbb{E}(X\mathbf{1}_A)\geq 0$. Conversely, if $\mathbb{P}(A) > 0$ then $\mathbb{E}[\mathbb{E}(X|\mathcal{G})\mathbf{1}_A]<0$ which is a contradiction. Hence, we must have $\mathbb{P}(A) = 0$.

**Monotonicity:** Note that if $X\leq Y$ then $Y - X\geq 0$. Thus, by the positivity and linearity properties 

$$
\begin{gather*}
  \mathbb{E}(Y - X|\mathcal{G}) = \mathbb{E}(Y|\mathcal{G}) - \mathbb{E}(X|\mathcal{G}) \geq 0 \\
  \mathbb{E}(Y|\mathcal{G})\geq\mathbb{E}(X|\mathcal{G})
\end{gather*}
$$

**Linearity:** Note that $\mathbb{E}(|aX + bY|) \leq |a|\mathbb{E}(|X|) + |b|\mathbb{E}(|Y|)$ so $\mathbb{E}(aX + bY|\mathcal{G})$ is defined. It remains to show that $a\mathbb{E}(X|\mathcal{G}) + b\mathbb{E}(Y|\mathcal{G})$ satisfy the conditons for conditional expectation. Clearly, the sum is $\mathcal{G}$-measurable since both terms are. If $A\in\mathcal{G}$ then

$$
\begin{align*}
  \mathbb{E}\left(\left[a\mathbb{E}(X|\mathcal{G}) + b\mathbb{E}(Y|\mathcal{G})\right]\mathbf{1}_A\right) &= a\mathbb{E}\left[\mathbb{E}(X|\mathcal{G})\mathbf{1}_A \right] + b\mathbb{E}\left[\mathbb{E}(Y|\mathcal{G})\mathbf{1}_A \right] \\
  &= a\mathbb{E}(X\mathbf{1}_A) + b\mathbb{E}(Y\mathbf{1}_A) \\
  &= \mathbb{E}(aX\mathbf{1}_A) + \mathbb{E}(bY\mathbf{1}_A) \\
  &= \mathbb{E}([aX + bY]\mathbf{1}_A)
\end{align*}
$$

**Independence property:** We show that $\mathbb{E}(X)$ satisfy the conditions for conditional expectation. Clearly, $\mathbb{E}(X)$ is $\mathcal{G}$-measurable as a constant random variable. If $A\in\mathcal{G}$ then $X$ and $\mathbf{1}_A$ are independent and hence

$$
  \mathbb{E}(X\mathbf{1}_A) = \mathbb{E}(X)\mathbb{P}(A) = \mathbb{E}[\mathbb{E}(X)\mathbf{1}_A]
$$

**$\mathcal{L}^p$-contractivity:** Note that $|\mathbb{E}(X|\mathcal{G})|\leq \mathbb{E}(|X|\,|\mathcal{G})$. Since $t\mapsto t^p$ is increasing and convex on $[0, \infty)$ we have 

$$
  |\mathbb{E}(X|\mathcal{G})|^k \leq [\mathbb{E}(|X|\,|\mathcal{G})]^2 \leq \mathbb{mathbb{E}\left(|X|^k \,\mathcal{G} \right)}
$$

where the last step follows from Jensen's inequality. Taking expected values gives

$$
  \mathbb{E}\left[|\mathbb{E}(X|\mathcal{G})|^k \right] \leq \mathbb{E}\left(|X|^k \right)< \infty
$$

In the case $p = \infty$, it follows that $0\leq |X|\leq \lVert X\rVert_\infty\mathbf{1}_\Omega$ if $X\in\mathcal{L}_\infty$, and thus $0\leq\mathbb{E}(|X|\;|\mathcal{G})\leq\lVert X\rVert_\infty \mathbf{1}_\Omega$. Hence $\mathbb{E}(|X|\;|\mathcal{G})\in \mathcal{L}_\infty$ and $\lVert\mathbb{E}(|X|\;\mathcal{G})\rVert_\infty \leq\lVert X\rVert_\infty$.

**Stability:** We need to show that, for all $A\in\mathcal{G}$

$$
  \mathbb{E}(XY\mathbf{1}_A) = \mathbb{E}\left[Y\mathbb{E}(X|\mathcal{G})\mathbf{1}_A \right]
$$

This can be shown by proving 

$$
  \mathbb{E}(ZX) = \mathbb{E}[Z\mathbb{E}(X|\mathcal{G})]
$$

where $Z$ is $\mathcal{G}$-measurable with $\mathbb{E}(|ZX|)<\infty$. This holds for $Z = \sum_{k=1}^{n\in\mathbb{N}}\alpha_k \mathbf{1}_{A_k}$ by the linearity property. Assuming that both $Z$ and $X$ are nonnegative, we can find an increasing sequence $(Z_n)_{n\in\mathbb{N}}$ such that $0\leq Z_n\xrightarrow{n\to\infty} Z$. Then $\mathbb{E}(|Z_n X|) < \infty$ for all $n\in\mathbb{N}$ and the monotone convergence theorem implies that

$$
\begin{align*}
  \mathbb{E}(ZX) &= \lim_{n\to\infty} \mathbb{E}(Z_n X) \\
  &= \lim_{n\to\infty}\mathbb{E}[Z_n \mathbb{E}(X|\mathcal{G})] \\
  &= \mathbb{E}[Z\mathbb{E}(X|\mathcal{G})]
\end{align*}
$$

Assuming $X\in \mathcal{L}_+^1$, the $\mathcal{L}^p$-contractivity for $p=1$ implies that

$$
  |\mathbb{E}(X|\mathcal{G})| \leq\mathbb{E}(|X|\; |\mathcal{G})
$$

and thus

$$
  \left| Z_n\mathbb{E}(X|\mathcal{G})\right| \leq Z_n \mathbb{E}(|X|\; |\mathcal{G}) \leq Z\mathbb{E}(|X|\; |\mathcal{G})
$$

It follows that $\mathbb{E}[Z\mathbb{E}(|X|\;|\mathcal{G})] = \mathbb{E}(Z|X|) < \infty$. Applying the dominated convergence theorem we get

$$
\begin{align*}
  \mathbb{E}[Z\mathbb{E}(|X|\;|\mathcal{G})] &= \lim_{n\to\infty} \mathbb{E}\left[Z_n \mathbb{E}(X|\mathcal{G}) \right] \\
  &= \lim_{n\to\infty}\mathbb{E}(Z_n X) = \mathbb{E}(ZX)
\end{align*}
$$

The case of a general $Z$ follows by linearity. The stability property follows by taking $Z = Y\mathbf{1}_A$

**Tower propery:** Note that $\mathbb{E}(X|\mathcal{H})$ is $\mathcal{H}$-measurable and thus also $\mathcal{G}$-measurable. Hence by the expectation rule $\mathbb{E}\left[\mathbb{E}(X|\mathcal{H})|\mathcal{G}\right] = \mathbb{E}(X|\mathcal{H})$. 

Conversely, we show that $\mathbb{E}(X|\mathcal{H})$ satisfy the conditions for $\mathbb{E}\left[\mathbb{E}(X|\mathcal{G})|\mathcal{H}\right]$. Clearly, $\mathbb{E}(X|\mathbb{H})$ is $\mathcal{H}$-measurable. If $A\in\mathcal{H}$ then $A\in\mathcal{G}$ and hence

$$
  \mathbb{E}\left[\mathbb{E}(X|\mathcal{G})\mathbf{1}_A \right] = \mathbb{E}(X\mathbf{1}_A) = \mathbb{E}\left[\mathbb{E}(X|\mathcal{H})\mathbf{1}_A\right]
$$
</details>
</MathBox>

<MathBox title="Conditional Jensen's inequality" boxType='theorem'>
If $\phi: \mathbb{R}\to\mathbb{R}$ is a convex function and $\mathbb{E}\left[|\phi(X)|\right] < \infty$, then 

$$
  \mathbb{E}\left[\phi(X)|\mathcal{G}\right] \overset{\textrm{a.s.}}{\geq} \phi\left[\mathbb{E}(X|\mathcal{G})\right]
$$
<details>
<summary>Proof</summary>

Recall that a convex function is the supremum of countably many affine functions, i.e. for $x\in\mathbb{R}$

$$
  \phi(x) = \sup_{n\in\mathbb{N}} (a_n x + b_n),\quad a_n, b_n\in\mathbb{R}
$$

Thus, for all $n\in\mathbb{N}$ we have $\mathbb{E}[\phi(X)|\mathcal{G}] \overset{\textrm{a.s.}{\geq} a_n \mathbb{E}(X|\mathcal{G}) + b_n$. Using the fact that the supremum is over a countable set we get

$$
  \mathbb{E}[\phi(X)|\mathcal{G}] \geq\sup_{n\in\mathbb{N}}\left[a_n\mathbb{E}(X|\mathcal{G}) + b_n\right] = \phi[\mathbb{E}(X|\mathcal{G})]
$$
</details>
</MathBox>

### Conditional convergence theorems

<MathBox title='Conditional monotone convergence theorem' boxType='theorem'>
Let $(X_n)_{n\in\mathbb{N}}$ be an increasing sequence of random variables with $0\leq X_n \xrightarrow{n\to\infty} X$. Then

$$
  \lim_{n\to\infty} \mathbb{E|\mathcal{G}}(X_n) \overset{\textrm{a.s.}}{=} \mathbb{E}(X|\mathcal{G})
$$

<details>
<summary>Proof</summary>

Since $X_n$ is increasing it follows that $\mathbb{E}(X_n|\mathcal{G})$ is increasing for $n\in\mathbb{N}$. Letting $Y = \lim_{n\to\infty}\mathbb{E}(X_n|\mathcal{G})$, we want to show that $Y \overset{\textrm{a.s.}}{=} \mathbb{E}(X|\mathcal{G})$. Clearly, $Y$ is $\mathcal{G}$-measurable as a limit of $\mathcal{G}$-measurable random variables. Applying the monotone convergence theorem gives

$$
\begin{align*}
  \mathbb{E}(X\mathbf{1}_A) &= \lim_{n\to\infty}(X\mathbf{1}_A) \\
  &= \lim_{n\to\infty}(X\mathbf{1}_A) \\
  &= \lim_{n\to\infty}\left[\mathbb{E}(X_n|\mathcal{G})\mathbf{1}_A\right] \\
  &= \left[\mathbb{E}(X|\mathcal{G})\mathbf{1}_A\right]
\end{align*}
$$
</details>
</MathBox>

<MathBox title="Conditional Fatous's lemma" boxType='lemma'>
Let $(X_n)_{n\in\mathbb{N}}$ be an increasing sequence of random variables with $X_n \geq 0$ for all $n$. Then

$$
  \mathbb{E}(\liminf_{n\to\infty} X_n|\mathcal{G}) \overset{\textrm{a.s.}}{\leq} \liminf_{n\to\infty} \mathbb{E}(X|\mathcal{G})
$$

<details>
<summary>Proof</summary>

The sequence $\inf_{k\geq n} X_k$ is increasing in $n\in\mathbb{N}$ and $\lim_{n\to\infty}\inf_{k\geq n} X_k = \liminf_{n\to\infty} X_n$. By the conditional monotone convergence theorem we get

$$
  \lim_{n\to\infty}\mathbb{E}\left(\inf_{k\geq n} X_k | \mathca{G} \right) = \mathbb{E}\left(\liminf_{n\to\infty} X_n|\mathcal{G}\right)
$$

Clearly, $\mathbb{E}\left(\inf_{k\geq n} X_k | \mathcal{G} \right)\leq\inf_{k\geq n} \mathbb{E}(X_k|\mathcal{G})$. Passing to the limit gives the desired inequality.
</details>
</MathBox>

<MathBox title='Conditional dominated convergence theorem' boxType='theorem'>
Let $Y$ be a nonnegative random variable with $\mathbb{E}(Y)<\infty$ and suppose that $(X_n)_{n\in\mathbb{N}}$ is a sequence of random variables with $X_n \underset{n\to\infty}{\uparrow} X$. If $|X_n| \leq Y \leq\infty$ Then

$$
  \lim_{n\to\infty} \mathbb{E}(X|\mathcal{G}) \overset{\textrm{a.s.}}{=} \mathbb{E}(X|\mathcal{G})
$$

<details>
<summary>Proof</summary>

Noting that $X_n + Y$ and $Y - X_n$ are positive random variables we may apply Fatou's lemma

$$
\begin{align*}
  \mathbb{E}(X + Y|\mathcal{G}) &= \mathbb{E}\left[ \liminf_{n\to\infty}(X_n + Y)|\mathcal{G} \right] \leq \liminf_{n\to\infty}\mathbb{E}(X_n + Y|\mathcal{G}) \\
  \mathbb{E}(X - Y|\mathcal{G}) &= \mathbb{E}\left[ \liminf_{n\to\infty}(X_n - Y)|\mathcal{G} \right] \leq \liminf_{n\to\infty}\mathbb{E}(X_n - Y|\mathcal{G})
\end{align*}
$$

Hence, we obtain $\liminf_{n\to\infty}\mathbb{E}\left(X_n|\mathcal{G}\right)\geq\mathbb{E}(X|\mathcal{G})$ and $\limsup_{n\to\infty}\mathbb{E}\left(X_n|\mathcal{G}\right)\leq\mathbb{E}(X|\mathcal{G})$
</details>
</MathBox>

### Relation to conditional probability

<MathBox title='Conditional probability' boxType='definition'>
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and suppose that $\mathcal{G}$ is a sub $\sigma$-algebra of $\mathcal{F}$. The conditional probability of an event $A\in\mathcal{F}$ given $\mathcal{G}$ can be defined as a special case of conditional expectation

$$
  \mathbb{P}(A|\mathcal{G}) = \mathbb{E}(\mathbb{1}_A|\mathcal{G})
$$

The conditional probability $\mathbb{P}(A|\mathcal{G})$ is characterized by the following properties
1. $\mathbb{P}(A|\mathcal{G})$ is measurable with respect to $\mathcal{G}$
2. If $B\in\mathcal{G}$ then $\mathbb{E}[\mathbb{P}(A|\mathcal{G})\mathbf{1}_B] = \mathbb{P}(A\cap B)$
  a. Equivalently, if $U$ is measurable with respect to $\mathcal{G}$ and $\mathbb{E}(|U|)< \infty$ then $\mathbb{E}[U\mathbb{P}(A|\mathcal{G})] = \mathbb{E}(U\mathbf{1}_A)$

<details>
<summary>Proof</summary>

For the second property, note that 

$$
\begin{align*}
  \mathbb{E}[\mathbf{1}_B\mathbb{P}(A|\mathcal{G})] &= \mathbb{E}[\mathbf{1}_B\mathbb{E}(\mathbf{1}_A|\mathcal{G})] \\
  &= \mathbb{E}(\mathbf{1}_A\mathbf{1}_B) = \mathbb{E}(\mathbf{1}_{A\cap B}) \\
  &= \mathbb{P}(A\cap B)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Probability of an event by conditioning' boxType='proposition'>
If $A\in\mathcal{F}$ then $\mathbb{P}(A) = \mathbb{E}[\mathbb{P}(A|\mathcal{G})]$.

<details>
<summary>Proof</summary>

This follows from the mean property of condtional expectation since 

$$
\begin{align*}
  \mathbb{E}[\mathbb{P}(A|\mathcal{G})] &= \mathbb{E}[\mathbb{E}(\mathbf{1}_A | \mathcal{G})] \\
  &= \mathbb{E}(\mathbf{1_A}) = \mathbb{P}(A)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Conditional axioms of probability' boxType='axiom'>
The following axioms hold for conditional probability

1. $\mathbb{P}(A|\mathcal{G})\geq 0$ for every $A\in\mathcal{F}$
2. $\mathbb{P}(\Omega|\mathcal{G}) = 1$
3. If $\{A_i \}_{i\in I}$ is a countable disjoint subset of $\mathcal{F}$, then

$$
  \mathbb{P}\left(\bigcup_{i\in I} A_i |\mathcal{G}) = \sum_{i\in I}\mathbb{P}(A_i |\mathcal{G})
$$
 
<details>
<summary>Proof</summary>

1. This follows from the positive definiteness of conditional expectation.
2. This is trivial since $\mathbf{1}_{\Omega} = 1$.
3. Note that $\sum_{i\in I} \mathbb{P}(A_i |\mathcal{G})$ is $\mathcal{G}$-measurable since each term in the sum has this property. Let $B\in\mathcal{G}$, then

$$
\begin{align*}
  \mathbb{E}\left[\sum_{i\in I} \mathbb{P}(A_i |\mathcal{G})\mathbf{1}_B \right] &= \sum_{i\in I}\mathbb{E}[\mathbb{P}(A_i |\mathcal{G})\mathbf{1}_B] \\
  &= \sum_{i\in I}\mathbb{P}(A_i \cap B) = \mathbb{P}\left(B \cap\bigcup_{i\in I} A_i \right)
\end{align*}
$$
</details>
</MathBox>

<MathBox title="Conditional Bayes' theorem" boxType='theorem'>
Suppose that $A\in\mathcal{G}$ and $B\in\mathcal{F}$, then

$$
  \mathbb{P}(A|B) = \frac{\mathbb{E}[\mathbb{P}(B|\mathcal{G})\mathbf{1}_A]}{\mathbb{E}[\mathbb{E}(B|\mathcal{G})]}
$$

<details>
<summary>Proof</summary>

$$
\begin{align*}
  \frac{\mathbb{E}[\mathbb{P}(B|\mathcal{G})\mathbf{1}_A]}{\mathbb{E}[\mathbb{E}(B|\mathcal{G})]} &= \frac{\mathbb{E}[\mathbb{E}(\mathbf{1}_B|\mathcal{G})\mathbf{1}_A]}{\mathbb{E}[\mathbb{E}(\mathbf{1}_B)|\mathcal{G}]} \\
  &= \frac{\mathbb{E}(\mathbb{1}_A\mathbb{1}_B)}{\mathbb{P}(B)} = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}
\end{align*}
$$

</details>
</MathBox>

### Best predictor

<MathBox title='' boxType='proposition'>
Suppose that $X, U\in\mathcal{L}_1(\Omega,\mathcal{F},\mathbb{P})$ are random variables with $\mathbb{E}(|X|)< \infty$ and $\mathbb{E}(|XU|)< \infty$, and that $U$ is measurable with respect to $\mathcal{G}$. Then $X - \mathbb{E}(X|\mathcal{G})$ and $U$ are uncorrelated.

<details>
<summary>Proof</summary>

Note that $X - \mathbb{E}(X|\mathcal{G})$ has mean $0$ by the mean property of conditional expectation. Computing the covariance of $X - \mathbb{E}(X|\mathcal{G})$ and $U$

$$
\begin{align*}
  \mathrm{cov}[X - \mathbb{E}(X|\mathcal{G}), U] &= \mathbb{E}(U[X - \mathbb{E}(X|\mathcal{G})]) \\
  &= \mathbb{E}(UX) - \mathbb{E}[U\mathbb{E}(X|\mathcal{G})] \\
  &= \mathbb{E}(UX) - \mathbb{E}(UX) = 0
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Conditional expecation as best predictor' boxType='theorem'>
Suppose that $X\in\mathcal{L}_2(\Omega,\mathcal{F},\mathbb{P})$ is a square integrable random variable with $\mathbb{E}(X^2)< \infty$. The conditional expectation $\mathbb{E}(X|\mathcal{G})$ is the closest random variable to $X$ in mean square sense (best predictor). That is, for any $U\in\mathcal{L}_2(\Omega,\mathcal{F},\mathbb{P})$ that is $\mathcal{G}$-measurable:

$$
  \mathbb{E}\left[X - \mathbb{E}(X|\mathcal{G})\right]^2 \leq\mathbb{E}\left[(X - U)^2 \right]
$$

Equality holds if and only if $\mathbb{P}[U = \mathbb{E}(X|\mathcal{G})] = 1$, i.e. $U \equiv\mathbb{E}(X|\mathcal{G})$

<details>
<summary>Proof</summary>

Note that 

$$
\begin{align*}
  \mathbb{E}\left[(X - U)^2\right] &= \mathbb{E}\left([X -\mathbb{E}(X|\mathcal{G}) + \mathbb{E}(X|\mathcal{G}) - U]^2 \right) \\
  &= \mathbb{E}\left([X - \mathbb{E}(X|\mathcal{G})^2] \right) + 2\mathbb{E}([X - \mathbb{E}(X|\mathcal{G})][\mathbb{E}(X|\mathcal{G}) - U]) + \mathbb{E}\left([\mathbb{E}(X|\mathcal{G}) - U]^2 \right)
\end{align*}
$$

Since $X - \mathbb{E}(X|\mathcal{G})$ has mean $0$, the middle term is 

$$
  2\mathrm{cov}[X - \mathbb{E}(X|\mathcal{G}), \mathbb{E}(X|\mathcal{G}) - U]
$$

Since $\mathbb{E}(X|\mathcal{G}) - U$ is $\mathcal{G}$-measurable, this covariance is $0$ by the proposition above. Hence

$$
\begin{align*}
  \mathbb{E}\left[(X - U)^2 \right] = \mathbb{E}\left([X - \mathbb{E}(X|\mathcal{G})]^2 \right) + \mathbb{E}\left([\mathbb{E}(X|\mathcal{G}) - U]^2 \right) \\
  &\geq \mathbb{E}\left([X - \mathbb{E}(X|\mathcal{G})]^2\right)
\end{align*}
$$

Equality holds if and only if $\mathbb{E}\left([\mathbb{E}(X|\mathcal{G}) - U]^2 \right) = 0$ if and only if $\mathbb{P}[U = \mathbb{E}(X|\mathcal{G})] = 1$.
</details>
</MathBox>

### Conditional variance

<MathBox title='Conditional covariance' boxType='definition'>
Suppose that $X\in\mathcal{L}_2(\Omega,\mathcal{F},\mathbb{P})$ is a square integrable random variable with $\mathbb{E}(X^2) < \infty$, and let $\mathcal{G}\subseteq\mathcal{F}$ be a sub-$\sigma$-algebra of $\mathcal{F}$. The conditional variance of $X$ given $\mathcal{G}$ is

$$
\begin{align*}
  \mathrm{var}(X|\mathcal{G}) &= \mathbb{E}\left( [X - \mathbb{E}(X|\mathcal{G})]^2 | \mathcal{G} \right) \\
  &= \mathbb{E}\left(X^2 |\mathcal{G} \right) - \mathbb{E}(X|\mathcal{G})^2
\end{align*}
$$

<details>
<summary>Proof</summary>

Expanding the square in the definition and using basic properties of conditional expectation gives

$$
\begin{align*}
  \mathrm{var}(X|\mathcal{G}) &= \mathbb{E}\left(X^2 - 2X\mathbb{E}(X|\mathcal{G}) + [\mathbb{E}(X|\mathcal{G})]^2 |\mathcal{G} \right) \\
  &= \mathbb{E}\left(X^2 |\mathcal{G}\right) - 2\mathbb{E}[X\mathbb{E}(X|\mathcal{G})|\mathcal{G}] + \mathbb{E}\left([\mathbb{E}(X|\mathcal{G})]^2 |\mathcal{G} \right) \\
  &= \mathbb{E}\left(X^2 |\mathcal{G} \right) - 2\mathbb{E}(X|\mathcal{G})\mathbb{E}(X|\mathcal{G}) + [\mathbb{E}(X|\mathcal{G})]^2 \\
  &= \mathbb{E}\left(X|\mathcal{G} \right) - [\mathbb{E}(X|\mathcal{G})]^2
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Conditional variance identities' boxType='proposition'>
Suppose that $X\in\mathcal{L}_2(\Omega,\mathcal{F},\mathbb{P})$ is a square integrable random variable with $\mathbb{E}(X^2) < \infty$. Then

1. $\mathrm{var}(X) = \mathbb{E}[\mathrm{var}(X|\mathcal{G})] + \mathrm{var}[\mathbb{E}(X|\mathcal{G})]$
2. $\mathbb{E}\left([X - \mathbb{E}(X|\mathcal{G})]^2 \right) = \mathrm{var}(X) - \mathrm{var}[\mathbb{E}(X|\mathcal{G})]$

<details>
<summary>Proof</summary>

1. Taking the expected value of the conditional variance formula gives
$$
  \mathbb{E}[\mathrm{var}(X|\mathcal{G})] = \mathbb{E}(X^2) - \mathbb{E}\left[\mathbb{E}(X|\mathcal{G})^2 \right]
$$

Writing out the terms

$$
\begin{align*}
  \mathbb{E}(X) &= \mathrm{var}(X) + \mathbb{E}(X)^2 \\
  \mathbb{E}\left[\mathbb{E}(X|\mathcal{G})^2\right] &= \mathrm{var}[\mathbb{E}(X|\mathcal{G})] + \mathbb{E}[\mathbb{E}(X|\mathcal{G})]^2 \\
  &= \mathrm{var}[\mathbb{E}(X|\mathcal{G})] + \mathbb{E}(X)^2
\end{align*}
$$

Substituting back gives

$$
  \mathbb{E}[\mathrm{var}(X|\mathcal{G})] = \mathrm{var}(X) \mathrm{var}[\mathbb{E}(X|\mathcal{G})]
$$

2. 
$$
\begin{align*}
  \mathbb{E}\left([X - \mathbb{E}(X|\mathcal{G})]^2 \right) &= \mathbb{E}[\mathrm{var}(X|\mathcal{G})] \\
  &= \mathrm{var}(X) - \mathrm{var}[\mathbb{E}(X|\mathcal{G})]
\end{align*}
$$
</details>
</MathBox>

### Conditional covariance

<MathBox title='Conditional covariance' boxType='definition'>
Suppose that $X, Y\in\mathcal{L}_2(\Omega,\mathcal{F},\mathbb{P})$ are square integrable random variables with $\mathbb{E}(X^2),\mathbb{E}(Y^2) < \infty$. Let $\mathcal{G}\subseteq\mathcal{F}$ be a sub $\sigma$-algebra of $\mathcal{F}$. The conditional variance of $X$ and $Y$ given $\mathcal{G}$ is

$$
\begin{align*}
  \mathrm{var}(X, Y|\mathcal{G}) &= \mathbb{E}\left([X - \mathbb{E}(X|\mathcal{G})][Y - \mathbb{E}(Y|\mathcal{G})]|\mathcal{G} \right) \\
  &= \mathbb{E}(XY|\mathcal{G}) - \mathcal{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G})
\end{align*}
$$

The conditional covariance generalizes conditional variance as

$$
  \mathrm{cov}(X,X|\mathcal{G}) = \mathrm{var}(X|\mathcal{G})
$$

<details>
<summary>Proof</summary>

$$
\begin{align*}
  \mathrm{cov}(X,Y|\mathcal{G}) &= \mathbb{E}\left(XY - X\mathbb{E}(Y|\mathcal{G}) - Y\mathbb{E}(X|\mathcal{G}) + \mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G}) |\mathcal{G} \right) \\
  &= \mathbb{E}(XY|\mathcal{G}) - \mathbb{E}[X\mathbb{E}(Y|\mathcal{G})|\mathcal{G}] - \mathbb{E}[Y\mathbb{E}(X|\mathcal{G})|\mathcal{G}] + \mathbb{E}[\mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G})|\mathcal{G}] \\
  &= \mathbb{E}(XY|\mathcal{G}) - \mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G}) - \mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G}) + \mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G}) \\
  &= \mathbb{E}(XY|\mathcal{G}) - \mathcal{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G})
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Covariance by conditioning' boxType='proposition'>
Suppose that $X,Y\in\mathcal{L}_2(\Omega,\mathcal{F},\mathbb{P})$ are square integrable random variables, then

$$
  \mathrm{cov}(X, Y) = \mathbb{E}[\mathrm{cov}(X,Y|\mathcal{G})] + \mathrm{cov}[\mathbb{E}(X|\mathcal{G}),\mathbb{E}(Y|\mathcal{G})]
$$

<details>
<summary>Proof</summary>

Taking the expected value of the conditional covariance gives
$$
  \mathbb{E}[\mathrm{cov}(X,Y|\mathcal{G})] = \mathbb{E}(XY) - \mathbb{E}[\mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G})]
$$

Note that $\mathbb{E}(XY) = \mathrm{cov}(X,Y) + \mathbb{E}(X)\mathbb{E}(Y)$ and similarly

$$
\begin{align*}
  \mathbb{E}[\mathbb{E}(X|\mathcal{G})\mathbb{E}(Y|\mathcal{G})] &= \mathrm{cov}[\mathbb{E}(X|\mathcal{G}),\mathbb{E}(Y|\mathcal{G})] + \mathbb{E}[\mathbb{E}(X|\mathcal{G})]\mathbb{E}[\mathbb{E}(Y|\mathcal{G})] \\
  &= \mathrm{cov}[\mathbb{E}(X|\mathcal{G}),\mathbb{E}(Y|\mathcal{G})] + \mathbb{E}(X)\mathbb{E}(Y)
\end{align*}
$$

Substituting gives

$$
  \mathbb{E}[\mathrm{cov}(X,Y|\mathcal{G})] = \mathrm{cov}(X,Y) - \mathrm{cov}[\mathbb{E}(X|\mathcal{G}),\mathbb{E}(Y|\mathcal{G})]
$$

</details>
</MathBox>

## Generating functions

### Probability generating functions

In the following discussion $N:\Omega\to\mathbb{N}$ is random variable taking values in $\mathbb{N}$. 

<MathBox title='Probability generating function (PGF)' boxType='definition'>
The probability generating function $P$ of $N$ is defined by

$$
  P(t) := \mathbb{E}(t^N)
$$

for all $t\in\mathbb{R}$ for which the expectation exists in $\mathbb{R}$.
</MathBox>

<MathBox title='PGF in terms of PDF' boxType='proposition'>
Suppose that $N$ has probability density function $f$ and probability generating function $P$. Then $P$ takes the form of a power series in $t\in(-r,r)$

$$
  P(t) = \sum_{n=0}^\infty f(n)t^n
$$

where $r\in[1,\infty]$ is the radius of convergence of the series.
</MathBox>

<MathBox title='PDF in terms of PGF' boxType='proposition'>
Suppose that $N$ has probability density function $f$ and probability generating function $P$. Then $f$ is given by

$$
  f(k) = \frac{P^{(k)}(0)}{k!},\quad k\in\mathbb{N}
$$

<details>
<summary>Proof</summary>

Differentiating $k$ times gives 

$$
\begin{gather*}
  P^{(k)}(t) = \sum_{n=k}^\infty n^{(n)}f(n)t^{n-k} \\
  \implies P^{(k)}(0) = k^{(k)}f(k) = k!f(k)
\end{gather*}
$$
</details>
</MathBox>

<MathBox title='Factorial moments of PGF' boxType='proposition'>
Suppose that the radius of convergence is $r > 1$. Then $P^{(k)} = \mathbb{E}\left( N^{(k)}\right)$ for $k\in\mathbb{N}$. In particular, $N$ has finite moments of all orders. The expectation and variance of $N$ are given by:

1. $\mathbb{E}(N) = P'(1)$
2. $\mathrm{var}(N) = P''(1) + P'(1)[1 - P'(1)]$

<details>
<summary>Proof</summary>

Recall that

$$
  P^{(k)}(t) = \sum_{n=k}^\infty n^{(n)}f(n)t^{n-k},\quad t\in(-r, r)
$$

If $r > 1$ then $P^{(k)}(1) = \sum_{n=k}^{\infty} n^{(k)}f(n) = \mathbb{E}\left(N^{(k)}\right)$. Using this rule, the expectation and variance of $N$ are calculated as

1. $\mathbb{E}(N) = \mathbb{E}\left( N^{(1)} \right) = P'(1)$
2. $\mathbb{E}(N^2) = \mathbb{E}[N(N-1)] + \mathbb{E}(N) = \mathbb{E}\left(N^{(n)}\right) + \mathbb{E}(N) = P''(1) + P'(1)$. From $(1)$ the variance becomes $\mathrm{var}(N) = P''(1) + P'(1) - [P'(1)]^2$
</details>
</MathBox>

<MathBox title='PGF of independent variables' boxType='proposition'>
Suppose that $(N_i)_{i=1}^{n\in\mathbb{N}} :\Omega\to\mathbb{N}$ are independent random variables valued in $\mathbb{N}$ with probability generating functions $P_i$ having radii of convergence $r_i$. Then the probability generating function $P$ of $N = \sum_{i=1}^n N_i$ is given by

$$
  P(t) = \prod_{i=1}^n P_i(t)
$$

for $|t| < \bigwedge_{i=1}^n r_i$

<details>
<summary>Proof</summary>

Recall that the expected product of independent variable is the product of the expected values

$$
  P(t) = \mathbb{E}\left( t^{\sum_{i=1}^n N_i} \right) = \mathbb{E}\left( \prod_{i=1}^n t^{N_i}\right) = \prod_{i=1}^n \mathbb{E}\left(t^{N_i}\right) = \prod_{i=1}^n P_i(t),\quad |t| < \bigwedge_{i=1}^n r_i
$$
</details>
</MathBox>

### Moment generating functions

In the following discussion suppose that $X:\Omega\to\mathbb{R}$, i.e. $X$ is real-valued random variable, with probability density function $f$.

<MathBox title='Moment generating function (MGF)' boxType='definition'>
The moment generating function of a random variable $X:\Omega\to\mathbb{R}$ is defined by

$$
  M(t) := \mathbb{E}\left(e^{tX}\right),\quad t\in\mathbb{R}
$$
</MathBox>

<MathBox title='MGF in terms of PDF' boxType='proposition'>
Suppose that $X$ has moment generating function $M$ that is finite in an open interval $I$ about $0$. Then $X$ ha moments of all orders and

$$
  M(t) = \int_{-\infty}^\infty e^{tx} f(x)\,\mathrm{d}x
$$
</MathBox>

Recall that the two-sided Laplace transform of $f$ is given by

$$
  \mathcal{L}\{f\}(t) = \int_{-\infty}^\infty e^{-xt}f(x)\,\mathrm{d}x
$$

The moment generating function of $X$ is thus a Laplace transform of the probability density function $f$ at $-t$, i.e. $M(t) = \mathcal{L}\{f\}(-t)$.

<MathBox title='' boxType='proposition'>
Suppose that $X$ has moment generating function $M$ that is finite in an open interval $I$ about $0$. Then $X$ ha moments of all orders and

$$
  M(t) = \sum_{n=0}^\infty \frac{\mathbb{E}(X^n)}{n!}t^n,\quad t\in I
$$

In particular $M^{(n)}(0) = \mathbb{E}(X^n)$.

<details>
<summary>Proof</summary>

By Fubini's theorem, the expected value operator can be interchanged with the infinite series for the exponential function

$$
  M(t) = \mathbb{E}\left(e^{tX}\right) = \mathbb{E}\left( \sum_{n=0}^\infty \frac{X^n}{n!}t^n \right) = \sum_{n=0}^\infty \frac{\mathbb{E}(X^n)}{n!}t^n,\quad t\in I
$$
</details>
</MathBox>

In combinatorial terms, the moment generating function is the exponential generating function of the sequence of moments. Thus, a random variable that does not have finite moments of all orders cannot have a finite moment generating function. Even when a random variables does have moments of all orders, the moment generating function may not exist.

<MathBox title='MGF of linear transformation' boxType='proposition'>
Suppose that $X$ has moment generating function $M$ and that $a,b\in\mathbb{R}$. The moment generating function $N$ of $Y = a + bX$ is given by

$$
  N(t) = e^{at}M(bt),\quad t\in\mathbb{R}
$$

<details>
<summary>Proof</summary>

$$
  \mathbb{E}\left( e^{t(a + bX)} \right) = \mathbb{E}\left( e^{ta}e^{tbX} \right) = e^{ta}\mathbb{E}\left( e^{(tb)X} \right) = e^{at}M(bt)
$$

for $t\in\mathbb{R}$.
</details>
</MathBox>

<MathBox title='MGF of independent random variables' boxType='proposition'>
Suppose that $(X_i)_{i=1}^{n\in\mathbb{N}} :\Omega\to\mathbb{R}$ are independent real-valued random variables with moment generating functions $M_i$. The moment generating function $M$ of $X = \sum_{i=1}^n X_i$ is given by

$$
  M(t) = \prod_{i=1}^n M_i(t),\quad t\in\mathbb{R}
$$

<details>
<summary>Proof</summary>

Recall that the expected product of independent variables is the product of the expected values. 

$$
  M(t) = \mathbb{E}\left( e^{t\sum_{i=1}^n X_i)} \right) = \mathbb{E}\left( \prod_{i=1}^n e^{tX_i} \right) = \prod_{i=1}^n \mathbb{E}\left( e^{tX_i}\right) = \prod_{i=1}^n M_i(t),\quad t\in\mathbb{R}
$$

for $t\in\mathbb{R}$.
</details>
</MathBox>

<MathBox title='MGF in terms of PGF' boxType='proposition'>
Suppose that $X:\Omega\to\mathbb{N}$ with probability generating function $P$ having radius of convergence $r$. The moment generating function $M$ of $X$ is given by

$$
  M(t) = P(e^t),\quad t<\ln{r}
$$

<details>
<summary>Proof</summary>

$$
  M(t) = \mathbb{E}(e^{tX}) = \mathbb{E}\left[(e^t)^X\right] = P(e^t),\quad e^t < r
$$
</details>
</MathBox>

<MathBox title='Chernoff bounds' boxType='proposition'>
If $X$ has moment generating function $M$ then

1. $\mathbb{P}(X\geq x)\leq e^{-tx}M(t)$ for $t > 0$
2. $\mathbb{P}(X\leq x)\leq e^{-tx}M(t)$ for $t < 0$

<details>
<summary>Proof</summary>

1. From Markov's inequality $\mathbb{P}(X\geq x) = \mathbb{P}\left(e^tX \leq e^tx\right) \leq e^{-tx}\mathbb{E}\left(e^{tX}\right) = e^{-tx} M(t)$ if $t>0$.
2. Similarly, $\mathbb{P}(X\leq x) = \mathbb{P}\left(e^tX \geq e^tx\right) \leq e^{-tx} M(t)$ if $t>0$.
</details>
</MathBox>

### Characteristic functions

<MathBox title='Characteristic function' boxType='definition'>
Suppose that $X$ has moment generating function $M$ that is finite in an open interval $I$ about $0$. Then $X$ ha moments of all orders and

$$
  \chi(t) := \mathbb{E}\left(e^{itX}\right) = \mathbb{E}\left[\cos(tX)\right] +i\mathbb{E}\left[\sin(tX)]\right],\quad t\in\mathbb{R}
$$
</MathBox>

<MathBox title='' boxType='proposition'>
If $X$ has a continuous distribution on $\mathbb{R}$ with probability density function $f$ and characteristic function $\chi$ then

$$
  \chi(t) = \int_{-\infty}^\infty e^{itx}f(x)\,\mathrm{d}x,\quad t\in\mathbb{R}
$$
</MathBox>

Recall that the Fourier transform of $f$ is given by

$$
  \mathcal{F}\{f\}(t) = \int_{-\infty}^\infty e^{-itx}f(x)\,\mathrm{d}x
$$

The characteristic function of $X$ is thus a Fourier transform of the probability density function $f$ at $-t$, i.e. $\chi(t) = \mathcal{F}\{f\}(-t)$.

<MathBox title='Inversion formula' boxType='proposition'>
Suppose that $X$ has characteristic function $\chi$. If $a,b\in\mathbb{R}$ and $a<b$ then

$$
  \int_{-n}^n \frac{e^{-iat} - e^{-ibt}}{2\pi it}\chi(x)\,\mathrm{d}t \xrightarrow{n\to\infty} \mathbb{P}(a < X < b) + \frac{1}{2}\left[\mathbb{P}(X = b) -  \mathbb{P}(X = a)\right]
$$

If $X$ has a continuous distribution on $\mathbb{R}$ with probability density function $f$ and characteristic function $\chi$ then

$$
  f(x) = \frac{1}{2\pi} \int_{-\infty}^\infty e^{-itx}\chi(t)\,\mathrm{d}t
$$
</MathBox>

<MathBox title='Inversion formula' boxType='proposition'>
Suppose that $X$ has characteristic function $\chi$. If $n\in\mathbb{N}$ and $\mathbb{E}(|X^n|)<\infty$ then

$$
  \chi(t) = \sum_{k=0}^n \frac{\mathbb{E}(X^k)}{k!}(it)^k + o(t^n)
$$

where $\frac{o(t^n)}{t^n} \xrightarrow{t\to\infty} 0$. In particular 

$$
  \chi^{(n)}(0) = i^n\mathbb{E}(X^n)
$$
</MathBox>

<MathBox title='Characteristic function under linear transform' boxType='proposition'>
Suppose that $X$ has characteristic function $\chi$ and that $a,b\in\mathbb{R}$. The characteristic function $\psi$ of $Y = a + bX$ is given by $\psi(t) = e^{iat}\chi(bt)$ for $t\in\mathbb{R}$.

<details>
<summary>Proof</summary>

$$
  \psi(t) = \mathbb{E}\left( e^{it(a + bX)} \right) = \mathbb{E}\left(e^{ita}e^{itbX}\right) = e^{ita}\mathbb{E}\left( e^{i(tb)X} \right) = e^{iat}\chi(bt)
$$
</details>
</MathBox>

<MathBox title='Characteristic function of independent random variables' boxType='proposition'>
Suppose that $(X_j)_{j=1}^{n\in\mathbb{N}} :\Omega\to\mathbb{R}$ are independent real-valued random variables with characteristic functions $\chi_j$. The moment generating function $\chi$ of $X = \sum_{j=1}^n X_j$ is given by

$$
  \chi(t) = \prod_{j=1}^n \chi_i(t),\quad t\in\mathbb{R}
$$

<details>
<summary>Proof</summary>

Recall that the expected product of independent variables is the product of the expected values. 

$$
  \chi(t) = \mathbb{E}\left( e^{it\sum_{j=1}^n X_j)} \right) = \mathbb{E}\left( \prod_{j=1}^n e^{itX_j} \right) = \prod_{j=1}^n \mathbb{E}\left( e^{itX_j}\right) = \prod_{j=1}^n \chi_j(t),\quad t\in\mathbb{R}
$$

for $t\in\mathbb{R}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $X$ has moment generating function $M$ that satisfies $M(t) < \infty$ for $t$ in an open interval $I$ about $0$. Then the characteristic function $\chi$ of $X$ satisfies 

$$
  \chi(t) = M(it),\quad t\in I
$$

</MathBox>

<MathBox title='Continuity theorem' boxType='theorem'>
Suppose that $(X_n :\Omega\to\mathbb{R})_{n\in\mathbb{N}}$ is a sequence of real-valued random variables with characteristic function $\chi_i$.

1. If the distribution of $X_n$ converges to the distribution of a random variable $X\xrightarrow{n\to\infty} X$ and $X$ has characteristic function $\chi$, then $\chi_{n}(t)\xrightarrow{n\to\infty} \chi(t)$ for all $t\in\mathbb{R}$
2. If $\chi_n(t)\xrightarrow{n\to\infty}\chi(t)$ for $t$ in an open interval about $0$, and if $\chi$ is continuous at $0$, then $\chi$ is the characteristic function of a random variable $X$, and the distribution of $X_n\xrightarrow{n\to\infty} X$. 
</MathBox>

## Uniformly integrable random variables

<MathBox title='' boxType='proposition'>
If $X$ is a random variable, then $\mathbb{E}(|X|) < \infty$ if and only if $\mathbb{E}\left(|X|\mathbf{1}_{|X|\geq x} \right)\xrightarrow{\to\infty} 0$.

<details>
<summary>Proof</summary>

Note $|X|\mathbf{1}_{|X|\leq x}$ is nonnegative, increasing in $x\in[0,\infty)$ and $|X|\mathbf{1}_{|X|\leq x}\xrightarrow{x\to\infty} |X|$. From the monotone convergence theorem, $\mathbb{E}\left(|X|\mathbf{1}_{|X|\leq x} \right)\xrightarrow{x\to\infty}\mathbb{E}(|X|)$. Furthermore

$$
  \mathbb{E}(|X|) = \mathbb{E}(|X|\mathbf{1}_{|X|\leq x}) + \mathbb{E}(|X|\mathbf{1}_{|X| > x})
$$

If $\mathbb{E}(|X|) < \infty$ then taking limits shows that $\mathbb{E}(|X|\mathbf{1}_{|X|> x})\xrightarrow{x\to\infty} 0$. Since $\mathbb{E}\left(|X|\mathbf{1}_{|X|\leq x}\right)\leq x$, then $\mathbb{E}\left(|X|\mathbf{1}_{|X| > x} \right) = \infty$ if $\mathbf{E}(|X|) = \infty$.
</details>
</MathBox>

<MathBox title='Uniformly integrable random variable' boxType='definition'>
Suppose that $I$ is an index set, which is not necessarily countable, and that $\mathbf{X} = \{X_i \}_{i\in I}$ is a collection of random variables. The collection $\mathbf{X}$ is *uniformly integrable* if for each $\varepsilon > 0$ there exists $x > 0$ such that for all $i\in I$

$$
  \mathbb{E}\left(|X_i|\mathbf{1}_{|X_i| > x}\right) < \varepsilon
$$

Equivalently $\mathbb{E}\left(|X_i|\mathbf{1}_{|X_i| > x}\right)\xrightarrow{x\to\infty} 0$ uniformly in $i\in I$.
</MathBox>

<MathBox title='Conditions for uniform integrability' boxType='proposition'>
Suppose that $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space. The collection $\mathbf{X}$ is uniformly integrable if and only if

1. $\{\mathbb{E}(|X_i|)\}_{i\in I}$ is bounded.
2. For each $\varepsilon > 0$ there exists $\delta > 0$ such that if $A\in\mathcal{F}$ and $\mathbb{P}(A) < \delta$, then $\mathbb{E}(|X_i|\mathbf{1}_A) < \varepsilon$ for all $i\in I$.

<details>
<summary>Proof</summary>

Suppose that $\mathbb{X}$ is uniformly integrable. With $\varepsilon = 1$ there exists $x > 0$ such that $\mathbb{E}\left(|X_i|\mathbf{1}_{|X_i| > x}\right) < 1$ for all $i\in I$. Thus

$$
\begin{align*}
  \mathbb{E}(|X_i|) &= \mathbb{E}(|X_i|\mathbf{1}_{|X_i|\leq x}) + \mathbb{E}(|X_i|\mathbf{1}_{|X_i| > x}) \\
  &= x + 1
\end{align*}
$$

showing that $\mathbb{E}(|X|)$ is bounded. Next, for $\varepsilon > 0$ there exist $x > 0$ such that $\mathbb{E}(|X_i|\mathbf{1}_{|X_i| > x}) < \frac{\varepsilon}{2}$ for all $i\in I$. Let $\delta = \frac{\varepsilon}{2x}$. If $A\in\mathcal{F}$ and $\mathbb{P}(A) < \delta$, then

$$
\begin{align*}
  \mathbb{E}\left(|X_i| \right) &= \mathbb{E}\left(|X_i|\mathbf{1}_{A \cap \{|X|\leq x\}} \right) + \mathbb{E}\left(|X_i|\mathbf{1}_{A \cap \{|X| > x\}} \right) \\
  &\leq x\mathbb{P}(A) + \mathbb{E}\left(|X_i|\mathbf{1}_{|X| > x} \right) < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon 
\end{align*}
$$

Conversely, suppose that condition $(1)$ and $(2)$ hold. By $(1)$, there exists $c > 0$ such that $\mathbb{E}(|X_i|)\leq c$ for all $i\in I$. Let $\varepsilon > 0$, then by $(2)$ there exists $\delta > 0$ such that if $A\in\mathcal{F}$ with $\mathbb{P}(A) < \delta$, then $\mathbb{E}(|X_i|\mathbf{1}_A) < \varepsilon$ for all $i\in I$. Next, by Markov's inequality

$$
  \mathbb{P}(|X_i| > x) \leq\frac{\mathbb{E}(|X_i|)}{x}\leq \frac{c}{x}
$$

Pick $x> 0$ such that $\frac{c}{x} < \infty$, then $\mathbb{P}(|X_i| > x) < \delta$ for each $i\in I$. Then for each $j\in I$, we have $\mathbb{E}(|X_i|\mathbf{1}_{|X_j| > x) < \varepsilon$ for all $i\in I$ and so in particular $\mathbb{E}(|X_i|\mathbf{1}_1 > x) < \infty$ for all $i \in I$. Hence $\mathbf{X}$ is uniformly integrable.
</details>
</MathBox>

# Vector spaces of random variables

Many probability concepts have elegant intepretations if we think of the collection of real-valued random variables as a vector space. In particular, variance and higher moments are related to the concept of norm and distance, while covariance is related to the inner product. 

A vector space $\mathcal{V}$ on a probability space $(\Omega, \mathcal{F},\mathbb{P})$ can be formed from all real-valued random variables $X:\Omega\to\mathbb{R}$. Recall, that two random variables $X, Y$ on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ are equivalent if $\mathbb{P}(X=Y)=1$, in which case we write $X\equiv Y$. The vector space then consists of all equivalence classes $[X]$ under $\equiv$.

## Norm
<MathBox title='Norm' boxType='definition'>
For $k\in [1,\infty)$, the $k$-norm of $X\in\mathcal{V}$ is defined by

$$
  \lVert X \rVert_k := \left[\mathbb{E}\left( |X|^k \right) \right]^{1/k}
$$

The set of random variables with finite $k$-norm forms a subspace $\mathcal{L}_k$ of the vector space $\mathcal{V}$.
</MathBox>

<MathBox title='Properties of the norm' boxType='proposition'>
Suppose that $k\in [1,\infty)$. The $k$-norm of $X\in\mathcal{V}$ has the following properties for $X, Y\in\mathcal{V}$

1. Positive definiteness: $\lVert X \rVert_k \geq 0$ and $\lVert X \rVert_k = 0$ if and only if $\mathbb{P}(X = 0) = 1$, i.e. $X\equiv 0$.
2. Scaling property: $\lVert cX \rVert_k = |c|\cdot\lVert X\rVert_k$ for $c\in\mathbb{R}$.
3. Minkowski's inequality: $\lVert X + Y \rVert_k \leq \lVert X \rVert_k + \lVert Y \rVert_k$
4. Lyapunov's inequality: suppose that $j,k\in[1, \infty)$ with $j\leq k$, then $\lVert X \rVert_j \leq \lVert X \rVert_k$

<details>
<summary>Proof</summary>

1. First $|X|^k \geq 0$ with probability $1$, so $\mathbb{E}\left( |X|^k \right)\geq 0$. In addition $\mathbb{E}\left( |X|^k \right) = 0$ if and only if $\mathbb{P}(X = 0) = 1$.
2. 

$$
\begin{align*}
  \lVert cX\rVert_k &=  \left[\mathbb{E}\left( |cX|^k \right) \right]^{1/k} =  \left[\mathbb{E}\left( |c|^k|X|^k \right) \right]^{1/k} \\
  &=  \left[|c|^k \mathbb{E}\left( |X|^k \right) \right]^{1/k} = |c| \left[\mathbb{E}\left( |X|^k \right) \right]^{1/k} \\
  &= |c|\cdot\lVert X\rVert_k
\end{align*}
$$
3. The first quadrant $S = \{ (x,y)\in\mathbb{R}^2 \;|\; x\geq 0, y\geq 0 \}$ is a convex set and $g(x, y) = \left( x^{1/k} + y^{1/k} \right)^k$ is concave on $S$. From Jensen's inequality, if $U$ and $V$ are nonnegative random variables then

$$
  \mathbb{E}\left[ \left( U^{1/k} + V^{1/k} \right)^k \right] \leq \left( \left[\mathbb{E}(U) \right]^{1/k} + \mathbb{E}(V) \right]^{1/k} \right)^k
$$

Letting $U = |X|^k$ nad $V = |Y|^k$ and simplifying gives the result. To verify that $g$ is concave on $S$, we compute the Jacobian determinant of the second derivatives. Let $h(x, y) = x^{1/k} + y^{1/k}$ so that $g = h^k$.

$$
\begin{align*}
  g_{xx} &= \frac{k - 1}{k} h^{k-2} x^{1/k - 2} \left(x^{1/k} - h \right) \\
  g_{yy} &= \frac{k - 1}{k} h^{k-2} y^{1/k - 2} \left(y^{1/k} - h \right) \\
  g_{xy} &= \frac{k - 1}{k} h^{k-2} x^{1/k - 1} x^{1/k - 1} = g_{yx}
\end{align*}
$$

The Jacobian determinant is $g_{xx} g_{yy} - g_{xy}^2 = 0$ on $S$. Clearly $h(x,y) \geq x^{1/k}$ and $h(x,y) \geq y^{1/k}$ on $S$, such that $g_xx, g_yy \leq 0$ on $S$. Thus, the second derivative matrix of $g$ is negative semi-definite.
4. Note that $S = \{ x\in\mathbb{R}\;|\; x\geq 0\}$ is convex and $g(x) = x^{k/j}$ is convex on $S$. From Jensens' inequality, if $U$ is a nonnegative random variable then 

$$
  \left[\mathbb{E}(U) \right]^{k/j} \leq \mathbb{E}\left(U^{k/j}\right)
$$

Letting $U = |X|^j$ and simplifying gives the result.
</details>
</MathBox>

## Metric

<MathBox title='Metric' boxType='definition'>
For $k\in [1,\infty)$, The $k$ metric between $X, Y\in\mathcal{V}$ is defined by

$$
  d_k (X,Y) := \lVert X - Y \rVert_k = \left[\mathbb{E}\left( |X - Y|^k \right) \right]^{1/k}
$$

In particular, the standard deviation is simply the 2-metric from a random variable $X$ to its mean $\mu = \mathbb{E}(X)$

$$
  \mathrm{sd}(X) = d_2 (X, \mu) = \lVert X - \mu \rVert_2 = \sqrt{\mathbb{E}\left[(X - \mu)^2 \right]} 
$$
</MathBox>

<MathBox title='Properties of the metric' boxType='proposition'>
Suppose that $k\in [1,\infty)$, the $k$ metric has the following properties for $X, Y, Z\in\mathcal{V}$

1. Symmetry: $d_k (X, Y) = d_k (Y, X)$
2. Positive definiteness: $d_k (X, Y) \geq 0$ and $d_k (X, Y) = 0$ if and only if $\mathbb{P}(X = Y) = 1$, i.e. $X \equiv Y$
3. Triangle inequality: $d_k (X, Z) \leq d_k (X, Y) + d_k (Y, Z)$

<details>
<summary>Proof</summary>

1. This follows trivially from the definition.
2. This follows directly from the positive definiteness of the $k$ norm.
3. From Minkowski's inequality

$$
\begin{align*}
  d_k (X, Z) &= \lVert X - Z \rVert_k = \lVert (X - Y) + (Y - Z)\rVert_k \\
  &\leq \lVert X - Y \rVert_k + \lVert Y - Z \rVert_k \\
  &= d_k (X, Y) + d_k (Y, Z)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Convergence' boxType='definition'>
Suppose that $X_n \in\mathcal{L}_k$ for $n\in\mathbb{N}_+$ and that $X\in\mathcal{L}_k$ for $k\in[1, \infty)$. Then $X_n \xrightarrow{n\to\infty} X$ in $k-$th mean if $X_n \xrightarrow{n\to\infty} X$ in the vector space $\mathcal{L}$_k. That is,

$$
  d_k (X_n, X) = \lVert X_n - X \rVert_k \xrightarrow{n\to\infty} 0
$$

or equivalently $\mathbb{E}\left(|X_n - x|^k\right) \xrightarrow{n\to\infty} 0$.

When $k = 1$, we say that $X_n \xrightarrow{n\to\infty} X$ in *mean*, and when $k=2$ we say that $X_n \xrightarrow{n\to\infty} X$ in *mean square*.
</MathBox>

<MathBox title='Properties of convergence' boxType='proposition'>
Suppose that $X_n\in\mathcal{L}_k$ for $n\in\mathbb{N}_+$ and that $X\in\mathcal{L}_k$, where $k\in[1,\infty)$.

1. Suppose that $1\leq j\leq k$. If $X_n \xrightarrow{n\to\infty} X$ in $k$-th mean, then $X_n \xrightarrow{n\to\infty} X$ in $j$-th mean.
2. If $X_n \xrightarrow{n\to\infty} X$ in $k$-th mean then $\lVert X_n \rVert_k \xrightarrow{n\to\infty} \lVert X \rVert_k$. Equivalently, if $\mathbb{E}\left(|X - X_n|^k \right)\xrightarrow{n\to\infty} 0$, then $\mathbb{E}\left(|X_n|^k \right) \xrightarrow{n\to\infty} \mathbb{E}\left(|X|^k \right)$.

<details>
<summary>Proof</summary>

1. This follows from Lyapunov's inequality. Note that $0\leq 0 d_j (X_n, X) \xrightarrow{n\to\infty} 0$.
2. This follows from the reverse triangle inequality for normed vector space, which in this case reads

$$
  \left| \lVert X_n \rVert_k - \lVert X \rVert_k \right| \leq \lVert X_n - X\rVert_k
$$

If the right side converges to $0$ as $n\to\infty$, then so does the left side.
</details>
</MathBox>

<MathBox title='Convergence in mean implies convergence in probability' boxType='proposition'>
Suppose that $X_n\in\mathcal{L}_1$ for $n\in\mathbb{N}_+$ and that $X\in\mathcal{L}_1$. If $X_n \xrightarrow{n\to\infty} X$ in mean, then $X_n \xrightarrow{n\to\infty} X$ in probability.

<details>
<summary>Proof</summary>

This follows from Markov's inequality. For $\varepsilon > 0$ 

$$
  0 \leq\mathbb{P}\left(|X_n - X| > \varepsilon \right) \leq \frac{\mathbb{E}(|X_n - X|)}{\varepsilon}\xrightarrow{n\to\infty} 0
$$
</details>
</MathBox>

In summary, the following implications in the various modes of convergence hold
- Convergence with probability $1$ implies convergence in probability.
- Convergence in $k$-th mean implies convergence in $j$-th mean if $j\leq k$.
- Convergence in $k$-th mean implies converge in probability.
- Convergence in probability implies convergence in distribution.

### Center and spread

<MathBox title='Root mean square error (RMSE)' boxType='definition'>
For $X\in\mathcal{L}_2$, define the root mean square error function by

$$
  d_2 (X, t) := \lVert X - t \rVert_2 = \sqrt{\mathbb{E}\left[(X - t)\right]^2},\quad t\in\mathbb{R}
$$

The 2-metric $d_2 (X, t)$ is minimized when $t = \mathbb{E}(X)$ and the minimum value is $\mathrm{sd}(X)$.

<details>
<summary>Proof</summary>

Note that $d_2 (X, t)$ share the same critical points as $d^2^2 (X, t) = \mathbb{E}\left[(X - t)^2\right]$, the mean square error function. Expanding $d_2^2(X, t)$ gives a quadratic function of $t$

$$
  \mathbb{E}\left[(X - t)^2\right] = \mathbb{E}(X^2) - 2t\mathbb{E}(X) + t^2
$$

which is a parabola opening upward. The minimum occurs at $t = \mathbb{E}(X)$, and the minimum value is $\mathrm{var}(X)$. The minimum value for $d_2(X, t)$ is thus $\mathrm{sd}(X)$.
</details>
</MathBox>

<MathBox title='Mean absolute error (MAE)' boxType='definition'>
For $X\in\mathcal{L}_1$, define the mean absolute error function by

$$
  d_1 (X, t) := \lVert X - t \rVert_1 = \mathbb{E}\left(|X - t|\right),\quad t\in\mathbb{R}
$$

The 1-metric $d_1 (X, t)$ is minimized when $t$ is any median of $X$.

<details>
<summary>Proof</summary>

Suppose first that $X\in\mathcal{L}_1$ has a discrete distribution with values in a finite set $S\subseteq\mathbb{R}$. Note that

$$
  \mathbb{E}\left(|X - t|\right) = \mathbb{E}(t - X, X\leq t) + \mathbb{E}(X - t, X>t)
$$

Thus $\mathbb{E}\left(|X - t|\right) = a_t t + b_t$ where $a_t = 2\mathbb{P}(X\leq t) - 1$ and $b_t = \mathbb{E}(X) - 2\mathbb{E}(X, X\leq t)$. Note that $\mathbb{E}\left(|X - t|\right)$ is a continuous, piecewise linear function of $t$, with corners at the values in $S$, which makes it a linear spline. Let $m$ be the smallest median of $X$. If $t< m$ and $t\notin S$, then the slope of the linear piece at $t$ is negative. Let $M$ be the largest median of $X$. If $t> M$ and $t\notin S$, then the slope of the linear piece at $t$ is positive. If $t\in(m, M)$, then the slope of the linear piece at $t$ is $0$. Thus, $\mathbb{E}(|X - t|)$ is minimized for every $t$ in the median interval $[m, M]$.

Suppose next that $X\in\mathcal{L}_1$ has a general distribution on $\mathbb{R}$. Let $s, t\in\mathbb{R}$ and suppose that first that $s< t$. Computing the expected value over the events $X\leq s$, $s< X\leq t$ and $X\geq t$, and simplifying gives

$$
\begin{align*}
  \mathbb{E}(|X - t|) &= \mathbb{E}(|X - s|) \\
  &\quad + (t-s)\left[ 2\mathbb{P}(X \leq s) - 1 \right] \\
  &\quad + 2\mathbb{E}(t - X, s< X\leq t)
\end{align*}
$$

Suppose next that $t< s$. Using similar methods gives

$$
\begin{align*}
  \mathbb{E}(|X - t|) &= \mathbb{E}(|X - s|) \\
  &\quad + (t-s)\left[ 2\mathbb{P}(X < s) - 1 \right] \\
  &\quad + 2\mathbb{E}(X - t, t\leq X< s)
\end{align*}
$$

Note that the last terms on the right in these equations are nonnegative. If $s$ is a median of $X$, then the middle terms on the right in the equations are also nonnegative. Hence, if $s$ is a median of $X$ and $t$ is any other number, then $\mathbb{E}(|X - t|)\leq \mathbb{E}(|X - s|)$
</details>
</MathBox>

## Inner product

<MathBox title='Inner product' boxType='definition'>
The inner product of $X, Y\in\mathcal{L}_2$ is defined by

$$
  \langle X, Y \rangle := \mathbb{E}(XY)
$$

The covariance of $X$ and $Y$ is the inner product of the corresponding centered variables, while the correlation is the inner product of the corresponding standard scores:

1. $\mathrm{cov}(X, Y) = \langle X - \mathbb{E}(X), Y -\mathbb{E}(Y)\rangle$
2. $\mathrm{cor} = \left\langle \frac{X -\mathbb{E}(X)}{\mathrm{sd}(X)}, \frac{Y -\mathbb{E}(Y)}{\mathrm{sd}(Y)} \right\rangle$

Thus, $X$ and $Y$ are uncorrelated if and only if the centered variables $X - \mathbb{E}(X)$ and $Y - \mathbb{E}(Y)$ are orthogonal elements of $\mathcal{L}_2$.
</MathBox>

<MathBox title='Properties of the inner product' boxType='proposition'>
The inner product has the following properties for $X, Y, Z\in\mathcal{L}_2$ and $a, b\in\mathbb{R}$

1. Symmetry: $\langle X, Y \rangle = \langle Y, X\rangle$
2. Positive definiteness: $\langle X, X \rangle \geq 0$ and $\langle X , X \rangle = 0$ if and only if $\mathbb{P}(X = 0) = 1$
3. Bilinearity: 
  a. $\langle aX + bY, Z\rangle = a\langle X, Z \rangle + b\langle Y, Z \rangle$
  b. $\langle X, aY + bZ\rangle = a\langle X, Y \rangle + b\langle X, Z \rangle$ 

<details>
<summary>Proof</summary>

1. This follows trivially from the definition.
2. Note that $\mathbb{E}(X^2) \geq 0$ and $\mathbb{E}(X^2) = 0$ if and only if $\mathbb{P}(X = 0) = 1$
3. This follows from linearity of the excpected value.
</details>
</MathBox>

<MathBox title="Hölder's inequality" boxType='proposition'>
Suppose that $j, k\in[1, \infty)$ and $\frac{1}{j} + \frac{1}{k} = 1$. For $X\in\mathcal{L}_j$ and $Y\in\mathcal{L}_k$

$$
  \langle |X|, |Y|\rangle \leq \lVert X\rVert_j \lVert Y \rVert_k
$$

When $j = k = 1$, we get the Cauchy-Schwartz inequality

$$
  \mathbb{E}(|X|\cdot|Y|) \leq \sqrt{\mathbb{E}\left(X^2\right)}\sqrt{\mathbb{E}\left(Y^2\right)}
$$

<details>
<summary>Proof</summary>

Note that $S = \{ (x,y)\in\mathbb{R}^2 \;|\; x\geq 0, y\geq 0 \}$ is a convex set and $g(x, y) = x^{1/j}y^{1/k}$ is concave on $S$. From Jensen's inequality, if $U$ and $V$ are nonnegative random variable then 

$$
  \mathbb{E}\left( U^{1/j} V^{1/k} \right) \leq \left[\mathbb{E}(U)\right]^{1/j}\left[\mathbb{E}(K)\right]^{1/k}
$$

Substituting $U = |X|^j$ and $V = |Y|^k$ gives the result. To verify that $g$ is concave on $S$, we compute the Jacobian determinant of the second derivatives

$$
\begin{align*}
  g_{xx} &= \frac{1}{j}\left(\frac{1}{j} - 1\right)x^{1/j - 2}y^{1/k} \\
  g_{yy} &= \frac{1}{k}\left(\frac{1}{k} - 1\right)x^{1/j - 2}y^{1/k} \\
  g_{xy} &= \frac{1}{j}\frac{1}{k}x^{1/j - 1}y^{1/k - 1} \\
\end{align*}
$$

The Jacobian determinant is $g_{xx} g_{yy} - g_{xy}^2 = 0$ on $S$. Since $\frac{1}{j}, \frac{1}{k}< 1$, then $g_{xx}, g_{yy} < 0$ on $S$. Thus, the second derivative matrix is negative semi-definite on $S$.
</details>
</MathBox>

<MathBox title='Parallellogram rule' boxType='proposition'>
If $X, Y\in\mathcal{L}_2$ then the parallellogram rule holds

$$
  \lVert X + Y \rVert_2^2 + \lVert X - Y \rVert_2^2 = 2\lVert X \rVert_2^2 + 2\lVert X \rVert_2^2
$$

This is equivalent to the variance identity

$$
  \mathrm{var}(X + Y) + \mathrm{var}(X - Y) = 2\left[\mathrm{var}(X) + \mathrm{var}(Y)]
$$

<details>
<summary>Proof</summary>

This follows from bilinearity of the inner product

$$
\begin{align*}
  \lVert X + Y \rVert_2^2 + \lVert X - Y \rVert_2^2 &= \langle X + Y, X + Y \rangle + \langle X - Y, X - Y \rangle \\
  &= \left(\langle X, X \rangle + 2\langle X, Y \rangle 0 \langle Y, Y \rangle \right) + \left(\langle X, X \rangle - 2\langle X, Y \rangle 0 \langle Y, Y \rangle \right) \\
  &= 2\lVert X \rVert_2^2 + 2\lVert Y \rVert_2^2
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Pythagorean theorem' boxType='theorem'>
If $(X_i)_{i=1}^{n\in\mathbb{N}}$ is a sequence of orthogonal random variables in $\mathcal{L}_2$ with $\langle X_i, X_j \rangle = 0$ for $i\neq j$, then

$$
  \left\lVert \sum_{i=1}^n X_i \right\rVert_2^2 = \sum_{i=1}^n \lVert X_i \rVert_2^2
$$

<details>
<summary>Proof</summary>

This follows from bilinearity of the inner product

$$
  \left\lVert \sum_{i=1}^n X_i \right\rVert_2^2 = \left\langle \sum_{i=1}^n X_i , \sum_{j=1}^n X_j \right\rangle = \sum_{i=1}^n \sum_{j=1}^n \langle X_i, X_j \rangle
$$

By the orthogonality assumption this reduces to

$$
  \left\lVert \sum_{i=1}^n X_i \right\rVert_2^2 = \sum_{i=1}^n \langle X_i , X_i \rangle = \sum_{i=1}^n \lVert X_i \rVert_2^2
$$
</details>
</MathBox>

### Projections

<MathBox title='Projection' boxType='definition'>
Let $\mathcal{U}$ be a subspace of $\mathcal{L}_2$ and suppose that $X\in\mathcal{L}_2$. The projection of $X$ onto $\mathcal{U}$ is the vector $V\in\mathcal{U}$ with the property that $X - V$ is perpendicular to $\mathcal{U}$

$$
  \langle X - V, U \rangle = 0,\quad U\in\mathcal{U}
$$
</MathBox>

<MathBox title='Properties of the projection' boxType='proposition'>
Let $\mathcal{U}$ be a subspace of $\mathcal{L}_2$ and suppose that $X\in\mathcal{L}_2$. The projection of $X$ onto $\mathcal{U}$ has the following properties
1. The projection is unique.
2. If $V$ is the projection of $X$ onto $\mathcal{U}$. Then $\lVert X - V \rVert_2^2 \leq \lVert X - U \rVert_2^2$ for all $U\mathcal{U}$. Equality holds if and only if $U\equiv V$.

<details>
<summary>Proof</summary>

1. Suppose that $V_1$ and $V_2$ are projections of $X$ on $mathcal{U}$, then by noting that $V_1 - V_2\in\mathcal{U}$

$$
\begin{align*}
  lVert V_1 - V_2 \rVert_2^2 &= \langle V_1 - V_2, V_1 - V_2 \rangle \\
  &= \langle V_1 - X + X - V_2, V_1 - V_2 \rangle \\
  &= \langle V_1 - X, V_1 - V_2\rangle + \langle X - V_2, V_1 - V_2\rangle \\
  &= 0
\end{align*}
$$

Hence $V_1 \equiv V_2$.
2. If $U\in\mathcal{U}$, then 

$$
  \lVert X - U \rVert_2^2 &= \lVert X - V + V - U \rVert_2^2 \\
  &= \lVert X - V \rVert_2^2 + 2\langle X - V, V - U \rangle + \lVert V - U \rVert_2^2 \\
  &= \lVert X - V \rVert_2^2 + \lVert X - V \rVert_2^2 \\
  &\geq \lVert X - V \rVert_2^2
$$

Equality holds if and only if $\lVert V - U \rVert_2^2 = 0 \iff V \equiv U$.
</details>
</MathBox>

<MathBox title='Best linear predictor' boxType='proposition'>
If $X\in\mathcal{L}_2$ then the set $\mathcal{W}_X = \{ a + bX \;|\; a,b\in\mathbb{R} \}$ is the subspace of $\mathcal{L}_2$ generated by $X$ and $1$.

Recall that for $X, Y\in\mathcal{L}_2$, the best linear predictor of $Y$ based on $X$ is 

$$
  L(Y|X) = \mathbb{E}(Y) + \frac{\mathrm{var}(X, Y)}{\mathrm{var}(X)}[X - \mathbb{E}(X)]
$$

The best linear linear predictor $L(Y|X)$ is the projection of $Y$ onto $\mathcal{W}_X$

<details>
<summary>Proof</summary>

Note that $\mathcal{W}_X$ is the set of all linear combinations of the vectors $1$ and $X$. To show that $\mathcal{W}_X$ is a subspace of $\mathcal{L}_2$, we check the closure properties
1. If $U, V\in\mathcal{W}_X$, then $U+V\in\mathcal{W}_X$.
2. If $c \in\mathbb{R}$, then $cU\in\mathcal{W}_X$.

Note that $L(Y|X)\in\mathcal{W}_X$. To prove that $L(Y|X)$ is the projection of $Y$ onto $\mathcal{W}_X$ we just need to show that $Y - L(Y|X)$ is ortogonal to $\mathcal{W}_X$. Since $\mathcal{W}_X$ is spanned by $X$ and $1$, it suffices to show that

1. $\langle Y - L(Y|X), X \rangle = 0$
2. $\langle Y - L(Y|X), 1 \rangle = 0$

For the first inner product, note that $\mathbb{E}(X[X - \mathbb{E}(X)]) = \mathrm{var}(X)$. Thus, 

$$
\begin{align*}
  \mathbb{E}[XL(Y|X)] &= \mathbb{E}(X)\mathbb{E}(Y) + \mathrm{cov}(X, Y) \\
  &= \mathbb{E}(XY)
$$

which shows $(1)$. By linearity, $\mathbb{E}[L(Y|X)] = \mathbb{E}(Y)$ so that $(2)$ holds as well.
</details>
</MathBox>

# Hurst exponential

Let $X$ be a stochastic process. Then $X$ is self-similar (self-affine) if

$$
  X(t) = \simeq \lambda^{-H} X(\lambda x)\quad\forall \lambda < 0
$$

where the Hurst exponent $H\in[0, 1]$ expresses the tendency for $\mathrm{d}X = \frac{\mathrm{d}X(t)}{\mathrm{d}t}\mathrm{d}t$ to change sign
- when $H = \frac{1}{2}$, the sign changes randomly. In this case $X$ is a Brownian motion.
- when $\frac{1}{2}<H\leq 1$, the sign tends not to change. In this case $X$ is called persistent.
- when $0\leq H < \frac{1}{2}$, the sign tends to change (anti-correlation). In this case $X$ is called anti-persistent.

The unconditional moments of $X(t)$, if they exist, behave as power laws of time

$$
  \mathrm{E}\left[ |X(t) | \right]^q = \mathrm{E}\left[ |X(1)|^q \right]|t|^{qH}
$$

The Hurst exponent $H$ of a time series is defined in terms of the asymptotic behaviour of the rescaled range as a function of the time span $n$

$$
  \lim_{n\to\infty} \mathrm{E}\left[ \frac{R(n)}{S(n)} \right] = Cn^H
$$

where
- $R(n)$ is the range of the first $n$ cumulative deviations from the mean
- $S(n)$ is the sum of the first $n$ standard deviations
- $C$ is a constant

## Estimation techniques

### Rescaled range analysis
The rescaled range is calculated as follows
1. Calculate the mean $m = \frac{1}{n}\sum_{i=1}^n X_i$
2. Create a mean-adjusted series $Y_t = X_t - m$ for $t \in [1, n]$
3. Calculate the cumulative deviate series $Z_t = \sum_{i=1}^t Y_i$
4. Compute the range $R(n) = \max[(Z_i)_{i\in[1, n]}] - \min[(Z_i)_{i\in[1, n]}]$
5. Compute the standard deviation $S(n) = \sqrt{\frac{1}{n}\sum_{i=1}^n \left(X_i - m \right)^2}$

The Hurst exponent is estimated by

$$
  H = \frac{\ln\left[ R(n)/S(n) \right]}{\ln(Cn)}
$$

Generalized Hurts exponent for a time series $x(t)$

$$
  \langle \left| g(t + \tau) - g(t) \right|^q \rangle_t \sim \tau^{qH(q)}
$$

### Moment-based estimators

Another method for estimating the global Hurst exponent utilizes absolute moments of a Gaussian random variable. Assuming that we have $N$ observations of an MBM with equal spacing in time, the $k$-th moment in window of size $\epsilon_N \leq N$ is given by

$$
  M_k (t) = \frac{1}{\epsilon_N} \sum_{i=0}^{\epsilon_N - 1} \left| X\left(t - \frac{i}{N} \right) - X\left(t - \frac{i + 1}{N} \right) \right|^k
$$

which is an estimate for $E\left[ \left| X(t) - X\left(t - \frac{1}{N} \right) \right|^k \right]$ given by

$$
  E\left[ \left| X(t) - X\left(t - \frac{1}{N} \right) \right|^k \right] = \frac{2^{k/2}\Gamma\left( \frac{k + 1}{2} \right)}{\Gamma\left( \frac{1}{2} \right)}\sigma^k N^{-kH(t)}
$$

This leads to the following estimate of $H(t)$

$$
  \hat{H}(t) = -\frac{\ln\left[ \sqrt{\pi}M_k (t) \right] - \ln\left[ 2^{k/2} \Gamma\left( \frac{k + 1}{2} \right)\sigma^k \right]}{k \ln(N)}
$$

which converges towards $H(t)$ at the rate $\mathcal{O}\left[ \left( \sqrt{\epsilon_N} \ln(N) \right)^{-1}\right]$. For $k = 1$, the estimator becomes

$$
  \hat{H}(t) = -\frac{\ln\left( \sqrt{\frac{\pi}{2}} \frac{M_1 (t)}{\sigma} \right)}{\ln(N)}
$$

To get rid of the parameter $\sigma$, the ratio of two moments can be calculated for observations in a common window at different resolutions. For $k = 2$, the average quadratic variation $M_2 (t)$ can be compared with a statistic $M'_2 (t)$ with halved resolution

$$
  M'_2 (t) = \frac{2}{\epsilon_N} \sum_{i=0}^{\epsilon_N / 2 - 1} \left| X\left( t - \frac{2i}{N} \right) - X\left( t - \frac{2(i + 1)}{N} \right) \right|^2
$$

The ratio $M'_2(t)/M_2(t)$ converges towards $2^{2H(t)}$, resulting in the estimator

$$
  \hat{H}(t) = \frac{1}{2}\log_2 \left( \frac{M'_2 (t)}{M_2 (t)} \right)
$$

Estimators can be derived from more general filters

$$
  V^a_{t, i} (X) = \frac{j+1}{d} a_j X\left( t - \frac{i + j - 1}{N} \right)
$$

The moment-based approach is retrieved for $a = (1, -1)$.

### Averaged wavelet coefficient method

Applying the wavelet transform to a self-similar stochastic process $X(t)$ gives

$$
\begin{align*}
  \mathcal{W}\left[ X(t) \right](a, b) &\simeq \mathcal{W}\left[ \lambda^{-H} X(\lambda t) \right](a, b) \\
  &= \frac{1}{\sqrt{a}}\int_{-\infty}^\infty \lambda^{-H} X(\lambda t) \overline{\psi\left( \frac{t - b}{a} \right)}\mathrm{d}t \\
  &= \lambda^{-\frac{1}{2}-H} \frac{1}{\sqrt{\lambda a}} \int_{-\infty}^\infty X(\lambda t') \overline{\psi\left( \frac{t' - \lambda b}{\lambda a} \right)}\mathrm{d}t' \\
  &= \lambda^{-\frac{1}{2}-H} \mathcal{W}\left[ X(t) \right] (\lambda a, \lambda b)
\end{align*}
$$

This shows that if we rescale the wavelet domain with the factor $\lambda$, the wavelet coefficient of the original domain rescales by a factor $\lambda^{\frac{1}{2}+H}$. The average wavelet coefficient at a given scale $a$ can be found by averaging out the translation parameter $b$

$$
  W[X(t)](a) := \langle | \mathcal{W}[X(t)](a, b) | \rangle_b
$$

where $\langle\cdot\rangle_b$ is the arithmic mean operator with respect to the translation parameter $b$. The rescaling relation becomes

$$
  W[X(t)](\lambda a) \simeq \lambda^{\frac{1}{2}+H}W[h](a)
$$

### Variational smoothing

The variational smoothing $\mathcal{H}$ of a noisy parameter $\hat{H}$ aims at minimizing the quadratic distance between $\mathcal{H}$ and $\hat{H}$ 

$$
  \mathcal{H} = \underset{h \in C^2([0, 1], \mathbb{R})}{\mathrm{argmin}} \int_0^1 \left[ \left( h(t) - \hat{H}(t) \right)^2 + \lambda h'(t)^2 \right]\mathrm{d}t = \underset{h \in C^2([0, 1], \mathbb{R})}{\mathrm{argmin}} \int_0^1 \mathcal{L} \left[ t, h(t), h'(t)\right]\mathrm{d}t
$$

where $\lambda \geq 0$ is a smoothness factor. The Euler-Lagrange equation becomes

$$
  \frac{\partial}{\partial h}  \mathcal{L} \left[ t, h(t), h'(t)\right] = \frac{\mathrm{d}}{\mathrm{d}}\frac{\partial}{\partial h'} \mathcal{L} \left[ t, h(t), h'(t)\right]
$$

For $\lambda > 0$, we get the second order linear differential equation

$$
  \mathcal{H}''(t) - \frac{\mathcal{H}(t)}{\lambda} = -\frac{\hat{H}(t)}{\lambda}
$$

with the general solution

$$
  \mathcal{H}(t) = e^{t/\sqrt{\lambda}} \left( A - \frac{1}{2\sqrt{\lambda}} \int_0^t e^{-s/\sqrt{\lambda}} \hat{H}(s) \mathrm{d}s \right) + e^{-t/\sqrt{\lambda}} \left( B + \frac{1}{2\sqrt{\lambda}} \int_0^t e^{s/\sqrt{\lambda}} \hat{H}(s) \mathrm{d}s \right)
$$

The unique solution that minimizes $\int_0^1 \left[ \mathcal{H}(t) - \hat{H}(t) \right]^2 \mathrm{d}t$ is 

$$
  \mathcal{H}(t) = \Phi \hat{H}(t) + Ae^{\frac{t}{\sqrt{\lambda}}} +  Be^{-\frac{t}{\sqrt{\lambda}}}
$$

where the operator $\Phi$ is given by

$$
  \Phi h(t) = \frac{e^{t/\sqrt{\lambda}}}{2\sqrt{\lambda}} \int_0^t e^{-s/\sqrt{\lambda}} h(s) \mathrm{d}s + \frac{e^{-t/\sqrt{\lambda}}}{2\sqrt{\lambda}} \int_0^t e^{s/\sqrt{\lambda}}h(s) \mathrm{d}s
$$

and where 

$$
\begin{align*}
  \mathcal{G}(t) &= \hat{H} - \Phi\hat{H}(t) \\
  C &= \sqrt{\frac{2}{\sqrt{\lambda}\left( e^{2/\sqrt{\lambda} - 1} \right)}} \\
  D &= C\left( e^{-2/\sqrt{\lambda}} - C^4 \right)^{-1/2} \\
  A &= C^2 \left( 1 + C^2 D^2 \right) \int_0^1 \mathcal{G}(s) e^{s/\sqrt{\lambda}}\mathrm{d}s - C^2 D^2 \int_0^1 \mathcal{G}(s) e^{-s/\sqrt{\lambda}}\mathrm{d}s \\
  B &= -C^2 D^2 \int_0^1 \mathcal{G}(s) e^{s/\sqrt{\lambda}}\mathrm{d}s + D^2 \int_0^1 \mathcal{G}(s) e^{-s/\sqrt{\lambda}}\mathrm{d}s
\end{align*}
$$

When $\lambda$ is close to zero, the exponentials in the closed form of $\mathcal{H}$ blow up, giving inaccuracies in the discrete approximation of the integrals for the coefficients $A$ and $B$. In a discrete framework the coefficients can be calculted using least-squares regression

$$
\begin{align*}
  A &= \frac{1}{\left( \sum_{i=1}^n e^{2t_i /\sqrt{\lambda}} \right)\left( \sum_{i=1}^n e^{-2t_i /\sqrt{\lambda}} \right) - n^2} \left[ \left( \sum_{i=1}^n e^{-2t_i /\sqrt{\lambda}} \right) \left( \sum_{i=1}^n e^{t_i /\sqrt{\lambda}} \left| 1 - \Phi^d \right| \hat{H}(t_i) \right) - n \left( \sum_{i=1}^n e^{-t_i /\sqrt{\lambda}} \left| 1 - \Phi^d \right| \hat{H}(t) \right) \right] \\
  B &= \frac{1}{\left( \sum_{i=1}^n e^{2t_i /\sqrt{\lambda}} \right)\left( \sum_{i=1}^n e^{-2t_i /\sqrt{\lambda}} \right) - n^2} \left[ \left( \sum_{i=1}^n e^{2t_i /\sqrt{\lambda}} \right) \left( \sum_{i=1}^n e^{-t_i /\sqrt{\lambda}} \left| 1 - \Phi^d \right| \hat{H}(t_i) \right) - n \left( \sum_{i=1}^n e^{t_i /\sqrt{\lambda}} \left| 1 - \Phi^d \right| \hat{H}(t) \right) \right]
\end{align*}
$$

In the limit $\lambda \to 0$, there exists $\xi \in [0, 1]$ such that

$$
  \min_{(A, B) \in \mathbb{R}^2} \int_0^1 \left[ \Phi H(t) + Ae^{t/\sqrt{\lambda}} + Be^{-t/\sqrt{\lambda}} - H(t) \right]^2 \mathrm{d}t \leq 4\lambda^2 H''(\xi)^2 + \mathcal{O}(\lambda^2)
$$
