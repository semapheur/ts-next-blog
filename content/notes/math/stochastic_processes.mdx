---
title: 'Stochastic Processes'
subject: 'Mathematics'
showToc: true
---

To review, a stochastic process on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ is a collection of random variables $\mathbf{X}:=\{X_t: \Omega\to S\}_{t\in T}$, with state space $(S,\mathcal{S})$ and index space $(T,\mathcal{T})$, usually representing time. The random variable $X_t \in S$ describes the state of a system at time $t\in T$.

When representing time, the index set $T$ is usually either discrete time, $T = \mathbb{N}$, with a discrete topology or continuous time, $T = [0,\infty)$, with the usual Euclidean topology. In both cases, $T$ is given the Borel $\sigma$-algebra $\mathcal{T}$, generated by the open sets of the underlying topology. In the discrete case, this is simply the power set, $\mathcal{T} = \mathcal{P}(\mathbb{N})$, so that every subset of $T$ is measurable. The time space $(T,\mathcal{T})$ has a natural measure, which is the counting measure in the discrete case and the Lebesgue measure in the continuous case.

The state set $S$ usually has a topology and $\mathcal{S}$ is the Borel $\sigma$-algebra. A typical set of assumption is that the topology on $S$ is locally compact, Hausdorff, and with countable base (LCCB). Under these assumptions, any natural positive measure $\lambda$ on the state space $(S, \mathcal{S})$ will usually be a Borel measure satisfying $\lambda(C) < \infty$ if $C\subset S$ is compact. If $(S,\mathcal{S})$ is a discrete state space then $S$ is countable with $\mathcal{S} = \mathcal{P}(S)$. The compact sets are simply the finite sets, and the reference measure is the counting measure. If $S = \mathbb{R}^n$ for some $n\in\mathbb{N}$, then $S$ is usually gieven the Euclidean topology (which is LCCB) so that $\mathcal{S}$ is the usual Borel $\sigma$-algebra. In this case, the compact sets are the closed, bounded sets and the reference measure is the $n$-dimensional Lebesgue measure.

A filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is an increasing collection of sub $\sigma$-algebras of $\mathcal{F}$, encoding the information available at time $t$. A stochastic process $\mathbf{X}$ is adapted to a filtration $\mathscr{F}$ if $X_t$ is measurable with respect to $\mathcal{F}_t$ for each $t\in T$. The coarsest filtration is the natural filtration $\mathscr{F}^0 = \left\{ \mathcal{F}_t^0 \mid t\in T \right\}$, where $\mathcal{F}_t^0 = \sigma\{ X_s \mid s\in T, s\leq t \}$, the $\sigma$-algebra generated by the process up to time $t\in T$. In continuous time, it is often necessary to finer $\sigma$-algebras in order to have a nice mathematical theory. In particular, we often assume that the filtration $\mathscr{F}$ is right continuous in the sense that $\mathcal{F}_{t+} = \mathcal{F}_t$ for $t\in T$ where $\mathcal{F}_{t+} = \bigcup\{ \mathcal{F}_s \mid s\in T, s > t \}$. This can be accomplished by taking $\mathscr{F} = \mathscr{F}_+^0$ so that $\mathcal{F} = \mathcal{F}_{t+}^0$ for $t\in T$. In this case, $\mathscr{F}$ is called the right continuous refinement of the natural filtration. We also sometimes need to assume that $\mathscr{F}$ is complete with respect to $\mathbb{P}$, such that if $A\in\mathcal{S}$ with $\mathbb{P}(A) = 0$ and $B\subseteq A$ then $B\in\mathcal{F}_0$. That is, $\mathcal{F}_0$ contains all the null events (and hence also all of the almost cerain events), and therefore so does $\mathcal{F}_t$ for all $t\in T$.

In the following discussion, $\mathcal{B}$ denotes the collection of bounded, measurable functions $f: S\to\mathbb{R}$, $\mathcal{C}$ the collection of bounded, continuous functions $f:S\to\mathbb{R}$, and $\mathcal{C}_0$ the set of continuous functions $f:S\to\mathbb{R}$ vanishing at $\infty$. The latter property means that for every $\varepsilon > 0$, there exists a compact set $K\subseteq S$ such that $|f(x)| < \varepsilon$ for $x\in K^c$. These are all vector spaces under the usual (pointwise) addition and scalar multiplication, and $\mathcal{C}_0 \subseteq\mathcal{C}\subseteq\mathcal{B}$. The norm on these spaces is the supremum norm, defined by $\lVert f \rVert = \sup\{|f(x)|:x\in S\}$ for $f\in\mathcal{B}$.

# Renewal process

A renewal process is a stochastic model for events occuring randomly in time. These temporal events are commonly called renewals or arrivals. A renewal process gives rise to several interrelated random processes:
- the sequence of interarrival times
- the sequence of arrival times
- the counting process

<MathBox title='Renewal process' boxType='definition'>
Let $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ be a sequence of independent, identically distributed random variables representing holding times between each arrival, also called *interarrival times*. Each holding time $X_n$ takes values in $[0,\infty)$ with $\mathbb{P}(X > 0) > 0$. If the holding time $X_n$ takes values in the set $\{nd \}_{n\in\mathbb{N}}$ for some $d\in (0,\infty)$, then its distribution is called arithmetic. The time at $n$th arrival is defined as

$$
  T_n := \sum_{i=1}^n X_i
$$

The sequence $\mathbf{T} = (T_n)_{n\in\mathbb{N}}$ is the partial sum process associated with the sequence of interarrival times $\mathbf{X}$.

For $t\geq 0$, let $N_t$ denote the number of arrivals in the interval $[0, t]$, i.e.

$$
  N_t = \sum_{i=1}^\infty \mathbf{1}(T_n \leq t) = \max{n\in\mathbb{N} \mid T_n \leq t}
$$

The random process $\mathbf{N} = \{ N_t \}_{t\geq 0}$ is called a renewal (counting) process.
</MathBox>

The counting process can be extended into a counting measure corresponding to a sequence of arrival times $\mathbf{T} = (T_n)_{n\in\mathbb{N}}$ in $[0,\infty)$. If $A$ is a (measurable) subset of $[0,\infty)$, then $N(A)$ denotes the number of the random mpoints in $A$, i.e.

$$
  N(A) = \sum_{n=1}^\infty \mathbf{1}(T_n \in A)
$$

In terms of the counting measure, $N_t = N[0,t]$ for $t\geq 0$ and $N(s - t] = N_t - N_s$ for $s\leq t$. The counting process is this a "cumulative measure function" for the counting measure, analogous to the cumulative distribution function of a probability measure.

<MathBox title='Properties of arrival times' boxType='proposition'>
Let $\mu = \mathbb{E}(X)$ denote the common mean of the interarrival times. If $m, n\in\mathbb{N}$ then

1. $\mu > 0$
2. $\mathbb{E}(T_n) = n\mu$
3. $\mathrm{var}(T_n) = n\sigma^2$
4. $\mathrm{cov}(T_m, T_n) = \min\{m, n\}\sigma^2$
5. $T_n \xrightarrow{n\to\infty} \infty$ with probability $1$
6. $\lim_{n\to\infty} \frac{T_n}{n} = \mu$ with probability $1$ (strong law of large numbers)

<details>
<summary>Proof</summary>

1. Note that if $\mu = 0$ then $\mathbb{P}(X > x) = 0$ for every $x > 0$ by Markov's inequality. This means that $\mathbb{P}(X = 0) = 1$, which contradicts the assumption that $\mathbb{P}(X > 0) > 0$.
2. This follows from the additive property of expected value.
3. This follows from the additive property of variance of indepedent variables.
4. For $m\leq n$, note that $T_n = T_m + (T_n - T_m)$. Since $T_m$ and $T_n - T_m$ are independent then

$$
\begin{align*}
  \mathrm{cov}(T_m, T_n) &= \mathrm{cov}[T_m, T_m + (T_n - T_m)] \\
  &= \mathrm{cov}(T_m, T_m) + \mathrm{cov}(T_m, T_n - T_m) \\
  &= \mathrm{var}(T_m) = m\sigma^2
\end{align*}
$$

5. Since $\mathbb{P}(X > 0) > 0$, there exists $t > 0$ such that $\mathbb{P}(X > t) > 0$. By the second Borel-Cantelli lemma it follows that $X_i > t$ with probability $1$ for infinitely many $n\in\mathbb{N}_+$. Therefore $\lim_{n\to \infty} T_n = \sum_{i=1}^\infty X_i = \infty$ with probability $1$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ be an sequence of interarrival times with common distribution function $F$, i.e. 

$$
  F(x) = \mathbb{P}(X \leq x),\; x\in[0,\infty)
$$

For $n\in\mathbb{N}$, the arrival time $T_n$ has the distribution function $F_n$, i.e.

$$
  F_n (t) = \mathbb{P}(T_n \leq t),\; t\in[0,\infty)
$$

The distributions of the arrival time are the convolution powers of $F$, i.e. $F_n = F^{*n}$.

<details>
<summary>Proof</summary>

This follows from the definitions: $F_n$ is the distribution function of $T_n = \sum_{i=1}^n X_i$. Since $\mathbf{X}$ is an independent, identically distributed sequence, it follows that $F_n = F^{*n}$.
</details>
</MathBox>

<MathBox title='Properties of counting processes' boxType='proposition'>
For $t\geq 0$ and $n\in\mathbb{N}$

1. $T_n \leq t$ if and only if $N_t \geq n$. Equivalently, $T_n > t$ if and only if $N_t < n$.
2. $N_t = n$ if and only if $T_n \leq t < T_{n+1}$
3. $N_t + 1$ is a stopping time for the sequence of interarrival times $\mathbf{X}$

The following events have probability $1$:
4. $N_t < \infty$ for all $t\in[0,\infty)$
5. $N_t \xrightarrow{t\to\infty} \infty $

<details>
<summary>Proof</summary>

1. The event $\{N_t \geq n\}$ means that there are at least $n$ arrivals in $[0,t]$.
2. The event $\{N_t \geq n\}$ means that there are exactly $n$ arrivals in $[0,t]$.
3. Note that $N_t + 1$ takes values in $\mathbb{N}_+$, so we need to show that the event $\{N + 1 = n\}$ is measurable with respect to $\mathcal{F}_N = \sigma\{X_n\}_{n\in\mathbb{N}_+}$. From the 2nd property, $N_t + 1 = n$ if and only if $N_t = n - 1$ if and only if $T_{n-1} \leq t < T_n$. The last event is clearly measurable with respect to $\mathcal{F}_n$.
4. The event $\{N_t \leq\infty\}$ occurs if and only if $T_n < \infty$ for all $n\in\mathbb{N}$ which also occurs with probability $1$. 
5. The event $N_t \xrightarrow{t\to\infty} \infty$ occurs if and only if $T_n \xrightarrow{n\to\infty} \infty$, which occurs with probability $1$.

$$
\begin{align*}
  \mathrm{cov}(T_m, T_n) &= \mathrm{cov}[T_m, T_m + (T_n - T_m)] \\
  &= \mathrm{cov}(T_m, T_m) + \mathrm{cov}(T_m, T_n - T_m) \\
  &= \mathrm{var}(T_m) = m\sigma^2
\end{align*}
$$

5. Since $\mathbb{P}(X > 0) > 0$, there exists $t > 0$ such that $\mathbb{P}(X > t) > 0$. By the second Borel-Cantelli lemma it follows that $X_i > t$ with probability $1$ for infinitely many $n\in\mathbb{N}_+$. Therefore $\lim_{n\to \infty} T_n = \sum_{i=1}^\infty X_i = \infty$ with probability $1$.
</details>
</MathBox>

## Comparison

<MathBox title='Renewal comparison rules' boxType='proposition'>
Suppose that $\mathbf{X} = (X_i)_{n\in\mathbb{N}_+}$ and $\mathbf{Y} = (Y_i)_{n\in\mathbb{N}_+}$ are two interarrival sequences defined on the same probability space, with $Y_i \leq X_i$ with probability $1$ for each $n$. Then for $n\in\mathbb{N}$ and $t\in[0,\infty)$

1. $T_{Y,n} \leq T_{X,n}$
2. $N_{Y,t} \geq N_{X,t}$
3. $m_Y (t) \geq m_X (t)$
</MathBox>

## Renewal function

<MathBox title='Renewal function' boxType='definition'>
The function $M$ thath gives the expected number of arrivals up to time $t$ is known as the renewal function

$$
  M(t) = \mathbb{E}(N_t),\; t\in[0,\infty)
$$
</MathBox>

If the renewal function $M$ is differentiable, the derivative $m = M'$ describes the renewal density where $m(t)$ gives the expected rate of arrivals per unit time at $t\in[0,\infty)$.

<MathBox title='' boxType='proposition'>
Let $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ be an sequence of interarrival times with common distribution function $F$, i.e. 

$$
  F(x) = \mathbb{P}(X \leq x),\; x\in[0,\infty)
$$

For $n\in\mathbb{N}$, the arrival time $T_n$ has the distribution function $F_n$, i.e.

$$
  F_n (t) = \mathbb{P}(T_n \leq t),\; t\in[0,\infty)
$$

The renewal function is given in terms of the interarrival distribution function by

$$
  M(t) = \sum_{n=1}^\infty F_n (t),\; t\in[0,\infty]
$$

<details>
<summary>Proof</summary>

The result follows by taking the expected value of $N_t = \sum_{n=1}^\infty \mathbf{1}(T_n \leq t)$.
</details>
</MathBox>

<MathBox title='Renewal measure' boxType='proposition'>
The renewal function $M$ is a positive measure on $[0,\infty)$, known as the renewal measure, given by

$$
  M(A) = \sum_{n=1}^\infty \mathbb{P}(T_n \in A),\; A\subset [0, \infty)
$$

<details>
<summary>Proof</summary>

Note that $N$ is a (random) counting measure on $[0,\infty)$. If $(A_i)_{i\in\mathbb{N}_+}$ is a sequence of disjoint, measurable subsets of $[0,\infty)$ then

$$
  N\left(\bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty N(A_i)
$$

Taking expected values gives

$$
  m\left(\bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty m(A_i)
$$

The interchange of sum and expected value is justified since the terms are nonnegative.
</details>
</MathBox>

## Renewal equations

<MathBox title='Renewal equation' boxType='definition'>
Let $F$ be the distribution function of an interarrival sequence $\mathbf{X}. $Suppose that $a:[0,\infty)\to\mathbb{R}$ is locally bounded. An integral equation of the form

$$
  u = a + u * F
$$

for an unknown function $u:[0,\infty)\to\mathbb{R}$ is called a *renewal equation* for $u$.
</MathBox>

<MathBox title='Renewal equations' boxType='proposition'>
The renewal equations for the renewal function $M$ and interarrival distribution $F$ are

1. $M = F + M*F$
2. $F = M - F*M$

<details>
<summary>Proof</summary>

1. Conditioning on the time of the first arrival $X_1$ and breaking the integration domain

$$
\begin{align*}
  M(t) &= \mathbb{E}(N_t) = \int_0^\infty \mathbb{E}(N_t\mid X_1 = s)\,\mathrm{d}F(s) \\
  &= \int_0^t \mathbb{E}(N_t \mid X_1 = s)\,\mathrm{d}F(s) + \int_t^\infty \mathbb{E}(N_t \mid X_1 = s)\,\mathrm{d}F(s)
\end{align*}
$$

If $s > t$ then $\mathbb{E}(N_t\mid X_1 = s) = 0$. If $0\leq s\leq t$, then by the renewal property $\mathbb{E}(N_t \mid X_1 = s) = 1 + M(t - s)$. Hence we have

$$
  M(t) = \int_0^t [1 + M(t - s)]\,\mathrm{d}F(s) = F(t) + (M * F)(t)
$$

2. This follows from the commutative property of convolution 

$$
  F = M - M * F = M - F * M 
$$
</details>
</MathBox>

<MathBox title='Laplace transform of renewal equations' boxType='proposition'>
The distributions $F$ and $M$ have Laplace transforms $\Phi$ and $\Gamma$, respectively, related by

$$
  \Gamma = \frac{\Phi}{1 - \Phi} \quad \Phi = \frac{\Gamma}{\Gamma + 1}
$$

<details>
<summary>Proof</summary>

Taking the Laplace transform of the renewal equation $M = F + M * F$ gives 

$$
\begin{gather*}
  \Gamma = \Phi + \Gamma\Phi \\
  \iff \Gamma = \frac{\Phi}{1 - \Phi} \\
  \iff \Phi = \frac{\Gamma}{\Gamma + 1}
\end{gather*}
$$

Since $F$ is a probability distribution on $[0,\infty)$ with $F(0) < 1$, it follows that $0 < \Phi(s) < 1$ for $s\in(0,\infty)$.

Alternatively, recall that $M = \sum_{n=1}^\infty F^{*n}$. Taking the Laplace transform and using the formula for geometric series gives

$$
  \Gamma = \sum_{n=1}^\infty \Phi^n = \frac{\Phi}{1 - \Phi}
$$
</details>
</MathBox>

<MathBox title='Solution of the renewal equations' boxType='proposition'>
Suppose that $a:[0,\infty)\to\mathbb{R}$ is locally bounded. Then the unique locally bounded solution to the renewal equation $u = a + u * F$ is $u = a + a * M$

<details>
<summary>Proof</summary>

**Direct proof**
Suppose that $u = a + a*M$. Then $u*F = a*F + a*M$. From the renewal equations we have $M*F = M - F$, such that 

$$
\begin{align*}
  u*F &= a*F + a*(M - F) \\
  &= a*[F + (M - F)] = a*M 
\end{align*}
$$

Since $a*M = u - a$ by definition of $u$, then $u = a + u*F$ such that $u$ is a solution to the renewal euation. Next, since $a$ is locally bounded, it follows that $u = a + a*M$. Suppose that $v$ is another locally bounded solution of the integral equation, and let $w = u - v$. Then $w$ is locally bounded and 

$$
  w*F = (u*F) - (v*F) = [(u - a) - (v - a)]= u - v = w
$$

Thus, $w = w*F_n$ for $n\in\mathbb{N}_+$. Suppose that $|w(s)| \leq D_t$ for $0\leq s \leq t$. Then $|w(t)|\leq D_t F_n(t)$ for $n\in\mathbb{N}_+$. Since $M(t) = \sum_{n=1}^\infty F_n (t) < \infty$ it follows that $\lim_{n\to\infty} F_n(t) = 0$. Hence $w(t) = 0$ for $t\in[0,\infty)$ and $u = v$.

**Proof using Laplace transforms**
Let $\alpha$ and $\theta$ denote the Laplace transforms of $a$ and $u$ respectively, and $\Phi$ the Laplace transform of the distribution $F$. Taking the Laplace transform of the renewal equations gives $\theta = \alpha + \theta\Phi$. Solving for $\theta$ gives

$$
  \theta = \frac{\alpha}{1 - \Phi} = \alpha\left(1 + \frac{\Phi}{1 - \Phi} \right) = \alpha + \alpha\Gamma
$$

where $\Gamma = \frac{\Phi}{1 - \Phi}$ is the Laplace transform of the distribution $M$. Hence $\theta$ is the Laplace transform of $a + a * M$.
</details>
</MathBox>

## Limit theorems

<MathBox title='Law of large numbers for renewal processes' boxType='theorem'>
If $\mu < infty$, then $\lim_{t\to\infty} \frac{N_t}{t} = \frac{1}{\mu}$ with probability $1$.

<details>
<summary>Proof</summary>

Recall that $T_{N_t} \leq t < T_{N_t + 1}$ for $t > 0$. Hence, if $N_t > 0$

$$
  \frac{T_{N_t}}{N_t} \leq \frac{t}{N_t} < \frac{T_{N_t + 1}}{N_t}
$$

Note that $N_t \xrightarrow{t\to\infty} \infty$ with probability $1$. By the strong law of large numbers $\lim_{n\to\infty} \frac{T_n}{n} = \mu$ with probability $1$. It follows that $\lim_{t\to\infty} \frac{T_{N_t}}{N_t} = \mu$ with probability $1$. Also, $\lim_{t\to\infty} \frac{N_t + 1}{N_t} = 1$ with probability $1$. Thus with probability $1$

$$
  \frac{T_{N_t + 1}}{N_t} = \frac{T_{N_t + 1}}{N_t + 1}\frac{N_t + 1}{N_t} \xrightarrow{t\to\infty} \mu
$$

By the squeeze theorem for limits it follows that $\lim_{t\to\infty}\frac{t}{N_t} = \mu$ with probability $1$.
</details>
</MathBox>

<MathBox title='Central limit theorem for renewal processes' boxType='theorem'>
Suppose that $\mu < 0$ and $\sigma < 0$, and let

$$
  Z_t = \frac{N_t - t/\mu}{\sigma\sqrt{t/\mu^3}},\; t > 0
$$

The distribution of $Z_t$ converges to the standard normal distribution as $t\to\infty$.

<details>
<summary>Proof</summary>

For $n\in\mathbb{N}_+$ let

$$
  W_n = \frac{T_n - n\mu}{\sigma\sqrt{n}}
$$

The distribution of $W_n$ converges to the standard normal distribution as $n\to\infty$ by the ordinary central limit theorem. For $z\in\mathbb{R}$, we have $\mathbb{P}(Z_t \leq z) = \mathbb{P}\left(T_{n(z,t)} > t \right)$ where $n(z,t) = \lfloor t/\mu + z\sigma\sqrt{t/\mu^3} \rfloor$. Also, $\mathbb{P}(Z_t \leq z) = \mathbb{P}[W_{n(z,t)} > w(z,t)]$ where

$$
  w(z,t) = -\frac{z}{\sqrt{1 + z\sigma/\sqrt{t/\mu}}}
$$

Note that $n(z,t) \xrightarrow{t\to\infty} \infty$ and $w(z,t) \xrightarrow{t\to\infty} -z$. Recall that $1 - \Phi(-z)$ = \Phi(z), where $\Phi$ is the standard normal distribution function. Hence $\mathbb{P}(Z_t \leq z) \xrightarrow{t\to\infty} \Phi(z)$.
</details>
</MathBox>

<MathBox title='Elementary renewal theorem' boxType='theorem'>
$$
  \lim_{t\to\infty} \frac{M(t)}{t} = \frac{1}{\mu}
$$

<details>
<summary>Proof</summary>

We first show that $\liminf_{t\to\infty} \frac{M(t)}{t} \geq \frac{1}{\mu}$. This result is trivial if $\mu = \infty$, so assume that $\mu < \infty$. Recall that $N_t + 1$ is a stopping time for the sequence of interarrival times $\mathbf{X}$, and that $T_{N_t + 1} > t$ for $t > 0$. From Wald's equation it follows that

$$
  \mathbb{E}(T_{N_t + 1}) = \mathbb{E}(N_t + 1)\mu = [M(t) + 1]\mu > t
$$

Thus $\frac{M(t)}{t} > \frac{1}{\mu} - \frac{1}{t}$ for $t > 0$ implying that $\liminf_{t\to\infty} \frac{M(t)}{t} \geq \frac{1}{\mu}$.

Next we show that $\limsup_{t\to\infty} \frac{M(t)}{t} \leq \frac{1}{\mu}$. For this part of the proof, we need to truncate the arrival times, and use the basic comparison method. For $a > 0$, let

$$
  X_{a,i} = \begin{cases} 
    X_i,\quad& $X_i \leq a$ \\
    a,\quad& X_i > a
  \end{cases}
$$

and consider the renewal process with the sequence of interarrival times $\mathbf{X}_a = (X_{a,n})_{n\in\mathbb{N}_+}$. Note that $T_{a, N_{a,t} + 1} \leq t + a$ for $t > 0$ and $a > 0$. From Wald's equation, it follows that $[M_a (t) + 1]\mu_a \leq t + a$. Thus

$$
  \frac{M_a (t)}{t} \leq \left( \frac{1}{\mu_a} + \frac{a}{t\mu_a} \right) - \frac{1}{t},\; a,t > 0
$$

Since $M(t) \leq M_a (t)$ it follows that 

$$
  \frac{M(t)}{t} \leq \left( \frac{1}{\mu_a} + \frac{a}{t\mu_a} \right) - \frac{1}{t},\; a,t > 0
$$

Hence $\limsup_{t\to\infty} \frac{M(t)}{t} \leq \frac{1}{\mu_a}$ for $a > 0$. By the monotone convergence theorem $\lim_{a\to\infty} \mu_a = \mu$ implying that $\limsup_{t\to\infty} \frac{M(t)}{t} \leq \frac{1}{\mu}$
</details>
</MathBox>

<MathBox title='Renewal theorem' boxType='theorem'>
For $h > 0$

$$
  \lim_{t\to\infty} M(t, t+h] = \frac{h}{\mu}
$$

in each of the follow cases:
1. The renewal process is non-arithmetic
2. The renewal process is arithmetic with span $d$, and $h$ is a multiple of $d$
</MathBox>

<MathBox title='Direct Riemann integration' boxType='theorem'>
Suppose that $g:[0,\infty)\to[0\infty)$. For $h\in[0,\infty)$ and $k\in\mathbb{N}$, let $m_k (g, h) = \inf\{ g(t) \mid t\in[kh, (k+1)h) \}$ and $M_k (g, h) = \sup\{ g(t) \mid t\in[kh, (k+1)h) \}$. The lower and upper Riemann sums of $g$ on $[0,\infty)$ corresponding to $h$ are

$$
  L_g (h) = h\sum_{k=0}^\infty m_k (g,h)\quad U_g (h) = h\sum_{k=0}^\infty M_k (g,h)
$$

The sums exist in $[0,\inty]$ and have the following properties
1. $L_g (h) \leq U_g (h)$ for $h > 0$
2. $L_g (h)$ increases as $h$ decreases
3. $U_g (h)$ decreases as $h$ decreases

The function $g$ is direct Riemann integrable if $U_g (h) < \infty$ for every $h > 0$ and

$$
  \lim_{h\downarrow 0} L_g (h) = \lim_{h\downarrow 0} U_g (h)
$$

The common value is the integral $int_0^\infty g(t)\,\mathrm{d}t$. If $g$ is Riemann integrable on $[0,t]$ for every $t\in[0,\infty)$ and if $U_g (h) < \infty$ for some $h\in(0,\infty)$ then $g$ is directly Riemann integrable.
</MathBox>

<MathBox title='Key renewal theorem' boxType='theorem'>
Suppose that the renewal process is non-arithmetic and that $g:[0,\infty)\to[0,\infty)$ is directly Riemann integrable. Then

$$
  (g*M)(t) = \int_0^t g(t - s)\,\mathrm{d}M(s) \xrightarrow{t\to\infty} \frac{1}{\mu}\int_0^\infty g(x)\,\mathrm{d}x
$$
</MathBox>

<MathBox title='Relations between renewal theorems' boxType='proposition'>
1. The renewal theorem implies the elementary renewal theorem.
2. The elementary renewal theorem almost implies the renewal theorem
3. The key renewal theorem implies the renewal theorem

<details>
<summary>Proof</summary>

1. Let $a_n = M(n, n+1]$ for $n\in\mathbb{N}$. From the renewal theorem $\lim_{n\to\infty} a_n = \frac{1}{\mu}$ such that $\lim_{n\to\infty} \frac{1}{n}\sum_{k=0}^{n-1} a_k = \frac{1}{\mu}$. It follows that $\lim_{n\to\infty} \frac{M(n)}{n} = \frac{1}{\mu}$. Since the renewal function is increasing for $t > 0$

$$
  \frac{\lfloor t \rfloor}{t}\frac{M(\lfloor t \rfloor)}{\lfloor t \rfloor} \leq \frac{M(t)}{t} \leq \frac{\lceil t \rceil}{t}\frac{M(\lceil t \rceil)}{\lceil t \rceil}
$$

From the squeeze theorem for limits it follows that $lim_{t\to\infty} \frac{M(t)}{t} = \frac{1}{\mu}$

2. Assume that $g(x) = \lim_{t\to\infty} [M(t + x) - M(t)]$ exists for each $x > 0$. Note that

$$
  M(t + x + y) - M(t) = [M(t + x + y) - M(t + x)] + [M(t + x) - M(t)]
$$

In the limit $t\to\infty$, then $g(x+y) = g(x) + g(y)$ for all $x,y\geq 0$. It follows that $g$ is increasing and $g(x) = cx$ for $x \geq 0$ where $c$ is a constant. Likewise as in the 1st proof, $\lim_{n\to\infty} \frac{M(n)}{n} = c$. From the elementary renewal theorem, we conclude that $c = \frac{1}{\mu}$.

3. This results follows by applying the key renewal theorem to the function $g_h (x) = \mathbf{1}(0\leq x\leq h)$ for $h > 0$.
</details>
</MathBox>

## Delayed renewal process

In a delayed renewal process, the first arrival time is allowed to have a different distribution than the other interarrival times.

<MathBox title='Delayed renewal process' boxType='definition'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of independent variables taking values in $[0,\infty)$ with $(X_i)_{i\in\mathbb{N}_+ \setminus \{1\}}$ identically distributed. Suppose also that $\mathbb{P}(X_n > 0) > 0$ for $n\in\mathbb{N}_+$. The stochastic process with $\mathbf{X}$ as the sequence of interarrival times is a delayed renewal process.
</MathBox>

Let $G$ denote the distribution function of $X_1$, and $G_n$ the distribution function of the arrival time $T_n = \sum_{i=1}^n T_n$ for $n\in\mathbb{N}_+$. Ignoring $X_1$, the interarrival sequence $(X_i)_{i\in\mathbb{N}_+ \setminus\{1\}}$ with common distribution function $F$ and common mean $\mu$, produces an ordinary renewal process. Thus

$$
  G_n = G*F_{n-1} = F_{n-1}*G
$$

<MathBox title='Delayed renewal function' boxType='proposition'>
The delayed renewal function $U(t) = \mathbb{E}(N_t)$ satisfies

$$
  U(t) = \sum_{n=1}^\infty G_n (t),\; t\in[0,\infty)
$$

<details>
<summary>Proof</summary>

$$
  U(t) = \mathbb{E}(N_t) = \mathbb{E}\left(\sum_{n=1}^\infty \mathbf{1}(T_n \leq t) \right) = \sum_{n=1}^\infty \mathbb{P}(T_n \leq t) = \sum_{n=1}^\infty G_n (t)
$$
</details>
</MathBox>

<MathBox title='Delayed renewal equations' boxType='proposition'>
The delayed renewal function $U$ satisfies the equations

1. $U = G + M*G$
2. $U = G + U*F$

<details>
<summary>Proof</summary>

1. Conditioning on the time of the first arrival $T_1 = X_1$, and noting that $\mathbb{E}(N_t \mid  X_1 = s) = 0$ if $s > t$ and $\mathbb{E}(N_t \mid  X_1 = s) = 1 + M(t-s)$ if $0\leq s\leq t$

$$
\begin{align*}
  U(t) &= \int_0^\infty \mathbb{E}(N_t\mid X_1 = s)\,\mathrm{d}G(s) = \int_0^t [1 + M(t - s)]\mathrm{d}G(s) \\
  &= G(t) + \int_0^t M(t-s)\,\mathrm{d}G(s)
\end{align*}
$$

2. Note that

$$
\begin{align*}
  U &= \sum_{n=1}^\infty G_n = G + \sum_{n=2}^\infty G_n \\
  &= G + \sum_{n=2}^\infty (G_{n-1} * F) = G + \left( \sum_{n=1}^\infty G_n \right)*F \\
  &= G + U*F
\end{align*}
$$
</details>
</MathBox>

### Asymptotic behaviour

<MathBox title='Strong law of large numbers for delayed renewal processes' boxType='proposition'>
With probability $1$
$$
  \lim_{t\to\infty} \frac{N_t}{t} = \frac{1}{\mu}
$$

<details>
<summary>Proof</summary>

We will show that $\lim_{n\to\infty} \frac{T_n}{n} = \mu$ with probability $1$ and the rest is exactly the same as for regular renewal processes. For $n\in\mathbb{N}_+ \setminus \{1\}$

$$
\frac{T_n}{n} = \frac{X_1}{n} + \frac{n-1}{n}\frac{1}{n-1}\sum_{i=2}^n X_i
$$

Note that with probability $1$ we have $\lim_{n\to\infty}\frac{X_1}{n} = 0$, $\lim_{n\to\infty}\frac{n}{n-1} = 1$ and $\lim_{n\to\infty} \frac{1}{n-1}\sum_{n=2}^n X_i = \mu$. The latter follows from the ordinary strong law of large numbers.
</details>
</MathBox>

<MathBox title='Delayed elementary renewal theorem' boxType='theorem'>
With probability $1$
$$
  \lim_{t\to\infty} \frac{U(t)}{t} = \frac{1}{\mu}
$$
</MathBox>

<MathBox title='Delayed renewal theorem' boxType='theorem'>
For $h > 0$

$$
  U(t,t+h] = U(t+h) - U(t) \xrightarrow{t\to\infty} \frac{h}{\mu}
$$

in each of the following cases:
1. $F$ is non-arithmetic
2. $F$ is arithmetic with span $d\in(0,\infty)$, and $h$ is a multiple of $d$
</MathBox>

<MathBox title='Delayed key renewal theorem' boxType='theorem'>
Suppose that the delaye renewal process is non-arithmetic and that $g:[0,\infty)\to[0,\infty)$ is directly Riemann integrable. Then

$$
  (g*U)(t) = \int_0^t g(t-s)\,\mathrm{d}U(s) \xrightarrow{t\to\infty} \frac{1}{\mu}\int_0^\infty g(x)\,\mathrm{d}x
$$
</MathBox>

### Stationary point processes

A point process if a stochastic process that models a discrete set of random points in a measure space $(S\mathcal{S},\lambda)$. The special cases $S=\mathbb{N}$ with counting measure and $S = [0,\infty)$ with length measure are of particular interest as (delayed) renewal processes give rise to point processes in these spaces.

For a general point process on $S$, let $N(A)$ denoted the number of random points $A\in\mathcal{S}$. TThe process is said to by stationary if $\lambda(A) = \lambda(B)$ implies that $N(A)$ and $N(B)$ have the same distribution for $A,B\in\mathcal{S}$. For $S = [0,\infty)$ the term stationary increments is often used, because the stationarity property means that for $s,t\in[0,\infty)$, the distribution of $N(s,s+t] = N_{s+t} - N_s$ depends only on $t$.

<MathBox title='' boxType='proposition'>
For the delayed renewal process, the point process $\mathbf{N}$ is stationary if and only if the initial arrival time has the distribution function

$$
  G(t) = \frac{1}{\mu}\int_0^t F^c (s)\,\mathrm{d}s,\; t\in[0,\infty)
$$

in which case the renewal function is $U(t) = \frac{t}{\mu}$.

<details>
<summary>Proof</summary>

Suppose first that $\mathbf{N}$ has stationary increments. In particular, this means that the arrival times have continuous distributions. For $s,t\in[0,\infty)$

$$
\begin{align*}
  U(s+t) = \mathbb{E}(N_{s+t}) = \mathbb{E}[(N_{s+t} - N_t) + N_t] \\
  &= \mathbb{E}(N_{s+t} - N_t) + \mathbb{E}(N_t) \\
  &= U(s) + U(t)
\end{align*}
$$

The only increasing solutions to this functional equation are linear function, such that $U(t) = ct$ for some positive constant $c$. Substituting $m_d$ into the renewal equation $U = G + U*F$ gives

$$
\begin{align*}
  ct &= G(t) + \int_0^t c(t-s)\,\mathrm{d}F(s) \\
  &= G(t) + ctF(t) - \int_0^t cs\,\mathrm{d}F(s)
\end{align*}
$$

Integrating the by parts and simplifying gives

$$
  G(t) = c\int_0^t F^c (s)\,\mathrm{d}s
$$

If we let $t\to\infty$ the left side converges to $1$ and the right side to $c\mu$, thus $c = \frac{1}{\mu}$ and $U(t) = \frac{t}{\mu}$ for $t\in[0,\infty)$.

Conversely, suppose that $G$ has the assumed form. Note that this is a continuous distribution with density function $t\mapsto \frac{F^c(t)}{\mu}$. Substituting into the renewal equation, it follows that the renewal denisty $U'$ satisfies

$$
  U' = \frac{1}{\mu}F^c + \frac{1}{\mu}F_c * \sum_{n=1}^\infty F_n = \frac{1}{\mu}
$$

Thus $U(t) = \frac{t}{\mu}$. The process $\mathbf{N}$ has stationary increments if and only if the remaining life $R_t$ at time $t$ has distribution function $G$ for each $t$.

$$
  \mathbb{P}(R_t > y) = G^c (t + y) + \int_0^t F^c (t + y - s)\,\mathrm{d}m_d (s),\; y\geq 0
$$

Note that $G^c (t+y) = \frac{1}{\mu}\int_{t+y}^\infty F^c (u)\,\mathrm{d}u$ and $\mathrm{d}U(s) = \frac{1}{\mu}\mathrm{d}s$. Substituting gives

$$
  \mathbb{P}(R_t > y) = \frac{1}{\mu}\int_{t+y}^\infty F^c (u)\,\mathrm{d}u + \frac{1}{\mu}\int_y^{t+y} F^c (u)\,\mathrm{d}u = \frac{1}{\mu}\int_y^\infty F^c (u)\,\mathrm{d}u
$$
</details>
</MathBox>

### Patterns in multinomial trials

Suppose that $\mathbf{L} = \{L_n\}_{n\in\mathbb{N}_+}$ is a sequence of indepedent, identically distributed random variables taking values in a finite set $S$, making $\mathbf{L}$ a sequence of multinomial trials. Let $f$ denote the common probability density function, such that $f(a) = \mathbb{P}(L = a)$ for $a\in S$ and a generic trial variable $L$. Assuming that all outcomes in $S$ are possible, requires $f(a) > 0$ for all $a\in S$.

The finite set $S$ can be interpreted as an alphabet. In this context, the sequence $\mathbf{L}$ is an infinite string of letters from $S$. We are interested in the repeated occurence of a particular finite substring of letters in the infinite sequence.

Let $\mathbf{a}$ denote a finite pattern from the alphabet $S$ and consider the successive random trials $\mathbf{T} = (T_n)_{n\in\mathbb{N}}$ where $\mathbf{a}$ is completed in $\mathbf{L}$. Let $T_0 = 0$ and let $X_n = T_n - T_{n-1}$ for $n\in\mathbb{N}_+$ such that $\mathbf{X} = (X_n)_{n\in\mathbb{N}}$ defines a sequence of interarrival times. For $k\in\mathbb{N}$, let $N_k = \sum_{i=1}^\infty \mathbf{1}(T_n \leq k)$ and let $U$ denote the renewal function.

Note that certain patterns may have a suffix (a proper substring at the end) which is also a prefix (a proper substring at the beginning) of the pattern. If no proper suffix of $\mathbf{a}$ is also a prefix, then $\mathbf{a}$ is simple. Otherwise, $\mathbf{a}$ is compound. If $\mathbf{a}$ is simple, then $\mathbf{L}$ forms an ordinary renewal process. However, if $\mathbf{a}$ is compound, then $\mathbf{L}$ forms a delayed process. 

Suppose that $mathbf{a} = (a_i)_{i=1}^k$ is a pattern of length $k\in\mathbb{N}_+$ where $a_i \in S$. Note that $X_1$ takes values in $\{k, k+1, \dots\}$. If $\mathbf{a}$ is compound $(X_i)_{i\in\mathbb{N}_+ \setminus\{1\}$ will have some minimum value $j < k$. Regardless of whether $\mathbf{a}$ is simple or compound, the renewal proces is arithmetic with span $1$. In this setting, the probability density function takes the form 

$$
  f(\mathbf{a}) = \prod_{i=1}^k f(a_i)
$$

Let $\mu(\mathbf{a})$ denote the common mean of $X_n$ for $n\in\mathbb{N}_+\setminus\{1\}$, giving the mean number of trials between occurences of $\mathbf{a}$. Let $\nu(\mathbf{a}) = \mathbb{E}(X_1)$, i.e. the mean time number of trials until $\mathbf{a}$ occurs foor the first time.

<MathBox title='' boxType='proposition'>
1. If $\mathbf{a}$ is a word in $S$, then

$$
  \mu(\mathbf{a}) = \frac{1}{f(\mathbf{a})}
$$

2. Suppose that $\mathbf{a}$ is a compound word, and that $\mathbf{b}$ is the largest word that is a proper suffix and prefix of $\mathbf{a}$. Then

$$
  \nu(\mathbf{a}) = \nu(\mathbf{b}) + \mu(\mathbf{a}) = \nu(\mathbf{b}) + \frac{1}{f(\mathbf{a})}
$$

<details>
<summary>Proof</summary>

1. Suppose that $\mathbf{a}$ has length $k\in\mathbb{N}_+$, and consider the discrete interval $(n, n+k] = \{n+1, n+2, \dots, n+k\}$. By the renewal theorem, $\lim_{n\to\infty} U(n, n+k] = \frac{1}{\mu(\mathbf{a})}$. Since $N(n, n+k]$ (the number of times $\mathbf{a}$ occurs in the interval) is $1$ or $0$, it follows that $U(n, n+k] = f(\mathbf{a})$ for any $n$. 

2. Since $\mathbf{b}$ is the largest prefix-suffix, the expected number of trials to from $\mathbf{b}$ to $\mathbf{a}$ is the same as the expected number of trials to go from $\mathbf{a}$ to $\mathbf{a}$, given by $\mu(\mathbf{a})$. To form the word $\mathbf{a}$ initially, the word $\mathbf{b}$ must be formed first, so this result follows from the additivity of expected value and the 1st propery.
</details>
</MathBox>

## Alternating renewal process

An alternating renewal process models a system that, over time, alternates between two states.

<MathBox title='Age processes' boxType='definition'>
Let $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ and $\mathbf{V} = (V_n)_{n\in\mathbb{N}_+}$ denote the successive lengths of time that the system is in state $1$ and $0$, respectively. Suppose that the $\mathbf{W} = ((U_n, V_n))_{n\in\mathbb{N}_+}$ is an independent, identically distributed sequence. It follows that $\mathbf{U}$ and $\mathbf{V}$ each are independent, identically distributed sequences, but $\mathbf{U}$ and $\mathbf{V}$ might well be dependent. Let $\mu = \mathbb{E}(U)$ denote the mean og a generic time period $U$ in state $1$ and $\nu = \mathbb{E}(V)$ the mean of a generic time period $V$ in state $0$. Let $G$ denote the distribution function of a time period $U$ in state $1$, and as usual, let $G^c = 1 - G$ denote the right distribution function of $U$.

It is natural to consider returns to state $1$ as the arrivals in an alternating renewal process. Let $X_n = U_n + V_n$ for $n\in\mathbb{N}_+$ and consider the renewal process with interarrival times $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$. This makes sense, because $\mathbf{X}$ is an independent, identically distributed sequence of nonnegative variables. As for an ordinary renewal process, $F$ denotes the common distribution function of $X_n$, while $M$ is the renewal function. Note that $\mathbb{E}(X) = \mu + \nu$.

In this setting the renewal process associated with $\mathbf{W}$ is known as an alternating renewal process.
</MathBox>

### State process
If $I_t \in \{0, 1 \}$ is the state of the system at time $t\in[0,\infty)$, then $\mathbf{I} = \{I_t\}_{t\geq 0}$ is a stochastic process with state space $\{0,1\}$. The stochastic processes $\mathbf{W}$ and $\mathbf{I}$ are equivalent in the sense that we can recover one from another. Let $p(t) = \mathbb{P}(I_t = 1)$, the probability that the device is in state $1$ at time $t$.

<MathBox title='' boxType='proposition'>
The function $p$ satisfies the renewal equation $p = G^c + p*F$ and hence $p = G^c + G^c * M$.

<details>
<summary>Proof</summary>

Conditioning on the first arrival $X_1$

$$
\begin{align*}
  \mathbb{P}(I_t = 1) &= \mathbb{P}(I_t = 1, X_1 > t) + \mathbb{P}(I_t = 1, X_1 \leq t) \\
  &= \mathbb{P}(I_t = 1, X_1 > t) + \int_0^t \mathbb{P}(I_t = 1 | X_1 = s)\,\mathrm{d}F(s)
\end{align*}
$$

Since $\{I_t = 1, X_1 > t\} = \{U_1 > t\}$, it follows that $\mathbb{P}(I_t = 1, X_1 > t) = \mathbb{P}(U_1 > t) = G^c (t)$. By the elementary renewal theorem $\mathbb{P}(I_t = 1 | X_s) = p(t - s)$ for $s\leq t$. Thus

$$
  p(t) = G^c (t) + \int_0^t p(t-s)\,\mathrm{d}F(s),\; t\in[0,\infty)
$$

or equivalent $p = G^c + p*F$. By the fundamental theorem on renewal equations, the solution is $p = G^c + G^c *M$, so

$$
  p(t) = G^c(t) + \int_0^t G^c (t-s)\,\mathrm{d}M(s),\; t\in[0,\infty)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If the alternating renewal process is non-arithmetic, then

$$
  \lim_{t\to\infty} p(t) = \frac{\mu}{\mu + \nu}
$$

Equivalently, for $\mathbb{P}(I_t = 0) = 1 - p(t)$

$$
  \lim_{t\to\infty} 1 - p(t) = \frac{\nu}{\mu + \nu}
$$

<details>
<summary>Proof</summary>

From the alternating renewal equation $p = G^c + G^c * M$. As a basic property of the right distribution function $\lim_{t\to\infty} G^c (t) = 0$. By the key renewal theorem

$$
  \lim_{t\to\infty} (G^c * M)(t) = \frac{1}{\mu + \nu}\int_0^\infty G^c (s)\,\mathrm{d}s
$$

By another property of the right distribution function $\int_0^\infty G^c (s)\,\mathrm{d}s = \mu$.
</details>
</MathBox>

## Renewal reward process

In a renewal reward process, each interarrival time is associated with a random variable that is generically thought of as the reward associated with that interarrival time. 

<MathBox title='Renewal reward process' boxType='proposition'>
Suppose that $\mathbf{Y} = (Y_n)_{n\in\mathbb{N}_+}$ is a sequence of real-valued variables, where $Y_n$ is thought of as the reward (or cost) associated with the interarrival time $X_n$. Let $\mathbf{Z} = ((X_n, Y_n))_{n\in\mathbb{N}_+}$ be an indepedent, identically distributed sequence. Let $\nu = \mathbb{E}(Y)\in\mathbb{R}$ denote the mean of a generic reward $Y$.

The stochastic process $\mathbf{R} = \{R_t\}_{t\geq 0}$ defined by

$$
  R_t = \sum_{i=1}^{N_t} Y_t,\; t\in[0,\infty)
$$

is the reward renewal process associated with $\mathbf{Z}$. The function $r$ given by $r(t) = \mathbb{E}(R_t)$ is the reward function.
</MathBox>

In the special case that $\mathbf{Y}$ and $\mathbf{X}$ are independent, the distribution of $R_t$ is known as a compound distribution, based on the distribution of $N_t$ and the distribution of a generic reward $Y$.

Note that a renewal reward process generalizes an ordinary renewal process. If $Y_n = 1$ for each $n\in\mathbb{N}_+$, then $R_t = N_t$ for $t\in[0,\infty)$ and the reward process simply reduces to the counting process.

<MathBox title='Renewal reward theorem' boxType='theorem'>
1. $\lim_{t\to\infty} \frac{R_t}{t} = \frac{\nu}{\mu}$ with probability $1$
2. $\lim_{t\to\infty} \frac{r(t)}{t} = \frac{\nu}{\mu}$

<details>
<summary>Proof</summary>

1. Note that

$$
  \frac{R}{t} = \frac{R_t}{N_t}\frac{N_t}{t}
$$

By the strong law of large numbers for the indepedent, identically distributed sequence $\mathbf{Y}$

$$
  \lim_{n\to\infty} \frac{1}{n} \sum_{i=1}^n Y_i = \nu
$$

with probability $1$. Since $N_t \xrightarrow{t\to\infty} \infty$ with probability $1$ it follows that with probability $1$

$$
  \frac{R_t}{N_t} = \frac{1}{N_t}\sum_{i=1}^{N_t} Y_i \xrightarrow{t\to\infty} \nu
$$

From the law of large number for the renewal process, $\lim_{t\to\infty} \frac{N_t}{t} = \frac{1}{\mu}$.

2. Note that

$$
  R_t = \sum_{i=1}^{N_t} Y_i = \sum_{i=1}^{N_t + 1} Y_i - Y_{N_t + 1}
$$

Recall that $N_t + 1$ is a stopping time for the sequence of interarrival times $\mathbf{X}$, and hence is also a stopping time for the sequence of interarrival time, reward pairs $\mathbf{Z}$. By Wald's equation

$$
\begin{align*}
  \mathbb{E}\left( \sum_{i=1}^{N_t + 1} Y_i \right) &= \nu\mathbb{E}(N_t + 1) \\
  &= \nu[M(t) + 1] = \nu M(t) + \nu
\end{align*}
$$

By the elementary renewal theorem

$$
  \frac{\nu M(t) + \nu}{t} = \nu\frac{M(t)}{t} + \frac{\nu}{t} \xrightarrow{t\to\infty} \frac{\nu}{\mu}
$$

It remains to show that

$$
  \lim_{t\to\infty} \frac{\mathbb{E}(Y_{N_t + 1})}{t} = 0
$$

Let $u(t) = \mathbb{E}(Y_{N_t + 1})$ for $t\in[0,\infty)$. Taking cases for the first arrival time $X_1$ gives

$$
  u(t) = \mathbb{E}[Y_{N_t + 1}\mathbf{1}(X_1 > t)] + \mathbb{E}[Y_{N_t + 1}\mathbf{1}(X_1 \leq t)]
$$

Since $X_1 > t$ if and only if $N_t = 0$, the first term is $\mathbb{E}[Y_1\mathbf{1}(X_1 > t)] = a(t)$. Assuming that the expected reward $\nu$ exists in $\mathbb{R}$, it follows that $|a(t)| \leq\mathbb{E}(|Y_1|) < \infty$. This shows that $a$ is bounded with $\lim_{t\to\infty} a(t) = 0$. For the second term, if the first arrival occurs at time $s\in[0,t]$, then the renewal process restarts, independently of the past, so

$$
  \mathbb{E}[Y_{N_t + 1}\mathbf{1}(X_1 \leq t)] = \int_0^t u(t-s)\,\mathrm{d}F(s),\; t\in[0,\infty)
$$

It follows that $u$ satisfies the renewal equation $u = a + u*F$. By the fundamental theorem on renewal equations, the solution is $u = a + a*M$. For some $\varepsilon > 0$, there exists $T\in(0,\infty)$ such that $|a(t)| < \varepsilon$ for $t > T$. For $t > T$

$$
\begin{align*}
  \left|\frac{u(t)}{t}\right| &\leq \frac{1}{t}\left[|a(t) + \int_0^{t-T} |a(t-s)|\,\mathrm{d}M(s) + \int_{t-M}^t |a(t-s)|\,\mathrm{d}M(s)\right] \\
  &\leq \frac{1}{t}[\varepsilon + \varepsilon M(t-T) + \mathbb{E}|Y_1|[M(t) - M(t - T)]]
\end{align*}
$$

Using the elementary renewal theorem, the last expression converges to $\frac{\varepsilon}{\mu}$ as $t\to\infty$. Since $\varepsilon > 0$ is arbitrary, it follows that $\lim_{t\to\infty} \frac{u(t)}{t} = 0$.
</details>
</MathBox>

### General reward process

The renewal process $\mathbb{R} = \{R_t\}_{t\geq 0}$ is a step function, taking the value $\sum_{i=1}^n Y_i$ on the renewal interval $[T_n, T_{n+1})$. The reward process can be modified so that the reward accrue continuously in time or in a mixed discrete/continuous manner.

<MathBox title='Conditions for general reward processes' boxType='definition'>
Suppose that $\mathbf{Z} = ((X_n, Y_n))_{n\in\mathbb{N}_+}$ is the sequence of interarrival times and rewards. A stochastic process $\mathbf{V} = \{V_t\}_{t\geq 0}$ is a reward process associated with $\mathbf{Z}$ if the following conditions hold for $n\in\mathbb{N}$:

1. $V_{T_n} = \sum_{i=1}^n Y_i$
2. $V_t$ is between $V_{T_n}$ and $V_{T_n + 1}$
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that the rewards are nonnegative and that $\mathbf{U} = \{U_t\}_{t\geq 0}$ is a nonnegative stochastic process satisfying

1. $t\mapsto U_t$ piecewise continuous
2. $\int_{T_n}^{T_{n+1}} U_t\,\mathrm{d}t = Y_{n+1}$ for $n\in\mathbb{N}$

Let $V_t = \int_0^t U_s\,\mathrm{d}s$ for $t\in[0,\infty)$. Then $\mathbb{V} = \{ V_t \}_{t\geq 0}$ is a reward process associated with $\mathbf{Z}$.

<details>
<summary>Proof</summary>

By additivity of the integral it follows that $V_{T_n} = \sum_{i=1}^n Y_i$ for $n\in\mathbb{N}$. Since $\mathbf{U}$ is nonnegative, $\mathbf{V}$ is increasing and $V_{T_n} \leq V_t \leq V_{T_{n+1}}$ for $t\in(T_n, T_{n+1})$. 
</details>
</MathBox>

The stochastic process $\mathbf{U}$ can be interpreted as a reward density process, where $U_t$ is the rate at which the reward is being accrued at time $t$.

<MathBox title='General reward renewal theorem' boxType='theorem'>
Suppose that the $\mathbf{V} = \{V_t\}_{t\geq 0}$ is a reward process associated with $\mathbf{Z} = ((X_n, Y_n))_{n\in\mathbb{N}_+}$ and let $v(t) = \mathbb{E}(V_t)$ for $t\in[0,\infty)$ be the corresponding reward function.

1. $\lim_{t\to\infty} \frac{V_t}{t} = \frac{\nu}{\mu}$ with probability $1$
2. $\lim_{t\to\infty} \frac{v(t)}{t} = \frac{\nu}{\mu}$

<details>
<summary>Proof</summary>

The proof is shown for nonnegative reward variables $Y$. If the rewards variables take positive and negative values, the variables can be split into positive and negative parts.

1.  Note that

$$
  \frac{R_t}{t} \leq\frac{V_t}{t}\leq\frac{R_t}{t} + \frac{Y_{N_t + 1}}{t}
$$

From the renewal reward theorem, $\lim_{t\to\infty} \frac{R_t}{t} = \frac{\nu}{\mu}$, and $\lim_{t\to\infty} \frac{Y_{N_t+1}}{t} = 0$, both with probability $1$. Hence the strong law of large numbers holds for $\mathbf{V}$.

2. Taking expected values of the displayed inequalities

$$
  \frac{r(t)}{t} \leq\frac{v(t)}{t}\leq\frac{r(t)}{t} + \frac{\mathbb{E}(Y_{N_t + 1})}{t}
$$

From the renewal reward theorem $\lim_{t\to\infty}\frac{r(t)}{t} = \frac{\nu}{\mu}$ and $\lim_{t\to\infty}\frac{\mathbb{E}(Y_{N_t + 1})}{t} = 0$. Hence the 2nd property holds.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that the rewards are positive, and consider the continuous reward process with density process $\mathbf{U} = \{U_t\}_{t\geq 0}$. Let $u(t) = \mathbb{E}(U_t)$ for $t\in[0,\infty)$. Then

1. $\lim_{t\to\infty} \frac{1}{t} \int_0^t U_s\,\mathrm{d}s = \frac{\nu}{\mu}$ with probability $1$
2. $\lim_{t\to\infty} \frac{1}{t} \int_0^t u(s)\,\mathrm{d}s = \frac{\nu}{\mu}$
</MathBox>

### Asymptotic behaviour

<MathBox title='Limits of alternating renewal processes' boxType='proposition'>
The limits of the alternating renewal process are

1. $\lim_{t\to\infty} \frac{1}{t}\int_0^t I_s\,\mathrm{d}s = \frac{\mu}{\mu + \nu}$
2. $\lim_{t\to\infty} \frac{1}{t}\int_0^t p(s)\,\mathrm{d}s = \frac{\mu}{\mu + \nu}$

<details>
<summary>Proof</summary>

Consider the renewal reward process where the reward associated with the interarrival time $X_n$ is $U_n$ (on period). The rewards $U_n$ are nonnegative and clearly 

$$
  \int_{T_n}^{T_{n+1}} I_s\,\mathrm{d}s = U_{n+1}
$$

Thus $t\mapsto \int_0^t I_s\,\mathrm{d}s$ for $t\in[0,\infty)$ defines a continuous reward process. The results follow directly from the reward renewal theorem.
</details>
</MathBox>

### Thinning
Consider a basic renewal process with the usual notation. For $n\in\mathbb{N}_+$ suppose that arrival $n$ is either accepted or rejected. The process of accepting or rejecting points in a point process is known as thinning the point process.

Define the random variable $Y_n$ to be $1$ in the first case, and $0$ in the second. Let $Z_n = (X_n, Y_n)$ denote the intearrival time and rejection variable pair and assume that $\mathbf{Z} = (Z_n)_{n\in\mathbb{N}_+}$ is an independent, identically distributed sequence.  Note that this structure defines a renewal reward process, such that $\mathbf{Y} = (Y_n)_{n\in\mathbb{N}_+}$ is a sequence of Bernoulli trials. Let $p$ denotes probability of accepting an arrival. The thinned counting process $\mathbf{R} = \{R_t\}_{t\geq 0}$ is given by

$$
  R_t = \sum_{i=1}^{N_t} Y_i
$$

and denotes the number of accepted point in $[0,t]$ for $t\in[0,\infty)$. Let $r(t) = \mathbb{E}(R_t)$ denote the expected number of accepted points in $[0,\infty)$.

<MathBox title='Limits of thinned renewal processes' boxType='proposition'>
The limits of the thinned renewal process are

1. $\lim_{t\to\infty} \frac{R(t)}{t} = \frac{p}{\mu}$
2. $\lim_{t\to\infty} \frac{r(t)}{t} = \frac{p}{\mu}$

<details>
<summary>Proof</summary>

This follows immediately from the renewal theorem since $\nu = p$.
</details>
</MathBox>

## Age processes

Renewal processes can be applied to model the reliability of devices.

<MathBox title='Age processes' boxType='definition'>

**Current life**
The random variable

$$
  C_t = t - T_{N_t}
$$

is called the *current life* at time $t \geq 0$. This variable takes values in the interval $[0,t]$ and is the age of the device that is in service at time $t$. The random process $\mathbf{C} = (C_t)_{t\geq 0}$ is the current life process.

**Remaining life**
The random variable

$$
  R_t = T_{N_t + 1} - 1
$$

is called the *remaining life* at time $t\geq 0$. This variable takes values in the interval $(0,\infty)$ and is the time remaining until the device that is in service at time $t$ fails. The random process $\mathbf{R} = (R_t)_{t\geq 0}$ is the remaining life process.

The random variable

$$
  L_t = C_t + R_t = T_{N_t + 1} - T_{N_t} = X_{N_t + 1}
$$

is called the *total life* at time $t\geq 0$. This variable takes values in $[0,\infty)$ and gives the total life of the device that is in service at time $t$. The random proces $\mathbf{L} = (L_t)_{t\geq 0}$ is the total life process.
</MathBox>

<MathBox title='Properties of age processes' boxType='proposition'>
Suppose that $t\in[0,\infty)$, $x\in[0,t]$ and $y\in[0,\infty)$, then

1. $\{R_t > y\} = \{N_{t+y} - N_t = 0\}$
2. $\{C_t\geq x\} = \{R_{t-x} > x\} = \{N_t - N_{t-x} = 0\}$
3. $\{C_t \geq x, R_t > y\} = \{R_{t-x} > x + y\} = \{N_{t+y} - N_{t-x} = 0\}$
4. $\mathbb{P}(L_t > x) \geq\mathbb{P}(X > x)$ for $x\geq 0$

<details>
<summary>Proof</summary>

1. The events $\{N_{t+y} - N_t = 0\}$ means that there are no arrivals in the interval $(t, t+y]$.
2. The events $\{N_t - N_{t-x} = 0\}$ means that there are no arrivals in the interval $(t-x, t]$.
3. The events $\{N_{t+y} - N_{t-x} = 0\}$ means that there are no arrivals in the interval $(t-x, t+x]$.
4. Recall that if $A$ and $B$ are nested events in a probability space, i.e. $A\subseteq B$, then the events are positively correlated, i.e. $\mathbb{P}(A\mid B) \geq\mathbb{P}(A)$. Conditioning $\{L_t > x\}$ on $N_t$

$$
\begin{align*}
  \mathbb{P}(L_t > x | N_t = 0) &= \mathbb{P}(X_{N_t + 1} > x | N_t = 0) \\
  &= \mathbb{P}(X_1 > x | X_1 > t) \geq\mathbb{P}(X_1 > x) \\
  &= 1 - F(x)
\end{align*}
$$

where $F$ is the cumulative density function of the interarrival times. For $n\in\mathbb{N}_+$

$$
\begin{align*}
  \mathbb{P}(X_{N_t + 1} > x | N_t = n) &= \mathbb{P}(X_{n + 1} > x | T_n \leq t < T_{n+1}) \\
  &= \mathbb{P}(X_{n+1} > x | T_n \leq t < T_n + X_{n+1})
\end{align*}
$$

Conditioning additionally on $T_n$ for $s \leq t$

$$
\begin{align*}
  \mathbb{P}(X_{n+1} > x | T_n = s, X_{n+1} > t-s) &= \mathbb{P}(X_{n+1} > x | X_{n+1} > t-s) \\
  &\geq \mathbb{P}(X_{n+1} > x) = 1 - F(x)
\end{align*}
$$

It follows that $\mathbb{P}(X_{N_t + 1} > x | N_t = n) \geq 1 - F(x)$ for every $n\in\mathbb{N}$ and hence

$$
\begin{align*}
  \mathbb{P}(X_{N_t + 1} > x) &= \sum_{n=0}^\infty \mathbb{P}(X_{N_t + 1} > x | N_t = n)\mathbb{P}(N_t = n) \\
  &\geq \sum_{n=0}^\infty [1 - F(x)]\mathbb{P}(N_n = n) = 1 - F(x)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Inspection paradox' boxType='proposition'>
Suppose that $t\in[0,\infty)$, $x\in[0,t]$ and $y\in[0,\infty)$, then

1. $\{R_t > y\} = \{N_{t+y} - N_t = 0\}$
2. $\{C_t\geq x\} = \{R_{t-x} > x\} = \{N_t - N_{t-x} = 0\}$
3. $\{C_t \geq x, R_t > y\} = \{R_{t-x} > x + y\} = \{N_{t+y} - N_{t-x} = 0\}$

<details>
<summary>Proof</summary>

1. The events $\{N_{t+y} - N_t = 0\}$ means that there are no arrivals in the interval $(t, t+y]$.
2. The events $\{N_t - N_{t-x} = 0\}$ means that there are no arrivals in the interval $(t-x, t]$.
3. The events $\{N_{t+y} - N_{t-x} = 0\}$ means that there are no arrivals in the interval $(t-x, t+x]$.
</details>
</MathBox>

### Distributions of age variables

For $t, y\in[0,\infty)$, let

$$
  r_y (t) = \mathbb{P}(R_t > y) = \mathbb{P}(N(t,t+y] = 0)
$$

and let $F_y^c (t) = F^c (t + y)$. Note that $y\mapsto r_y (t)$ is the right distribution function of $R_t$. 

<MathBox title='Age process distributions' boxType='proposition'>
For $y\in[0,\infty)$ the right distribution $r_y$ satisfies the renewal equation $r_y = F_y^c + r_y * F$ and hence for $t\in[0,\infty)$ the distribution of the remaining life variable is given by

$$
  \mathbb{P}(R_t > y) = F^c (t + y) + \int_0^t F^c (t + y - s)\,\mathrm{d}M(s),\; y\geq 0
$$

The distribution of the current life variable is given by

$$
  \mathbb{P}(C_t \geq x) = F^c (t) + \int_0^{t-x} F^c (t - s)\,\mathrm{d}M(s)
$$

The joint distribution of the current and remaining life variables is given by

$$
  \mathbb{P}(C_t \geq x, R_t > y) = F^c (t + y) + \int_0^{t-x} F^c (t + y - s)\,\mathrm{d}M(s)
$$

<details>
<summary>Proof</summary>

**Remaining life distribution**
Conditioning on the time of the first renewal

$$
  \mathbb{P}(R_t > y) = \int_0^\infty \mathbb{P}(R_t > y | X_1 = s)\,\mathrm{d}F(s)
$$

Breaking the integration interval into three parts $[0,t]$, $(t, t+y]$ and $(t+y,\infty)$ and noting that
- $\mathbb{P}(R_t > y | X_1 = s) = \mathbb{P}(R_{t-s} > 0)$ for $s\in[0,t]$
- $\mathbb{P}(R_t > y | X_1 = s) = 0$ for $s\in(t, t+y)$
- $\mathbb{P}(R_t > y | X_1 = s) = 1$ for $s\in(t + y, \infty)$

Combining the result gives

$$
\begin{align*}
  \mathbb{P}(R_t > y) &= \int_0^t \mathbb{P}(R_{t-s} > y)\,\mathrm{d}F(s) + \int_t^{t+y} 0\,\mathrm{d}F(s) + \int_{t+y}^\infty 1\,\mathrm{d}F(s) \\
  &= (r_y * F)(t) + 1 - F(t + y) = F_y^c(t) + (r_y * F)(t)
\end{align*}
$$

**Current life distribution**
The result follows from the fact that $\mathbb{P}(C_t \geq x) = \mathbb{P}(R_{t-x} > x)$ for $x\in[0,t]$.

**Joint distribution of current and remaining life**
The result follows from the fact that $\mathbb{P}(C_t \geq x, R_t > y) = \mathbb{P}(R_{t-x} > x + y)$.
</details>
</MathBox>

### Limits

<MathBox title='Age process limiting distributions' boxType='proposition'>
1. If the renewal process is non-arithmetic then

$$
  \lim_{t\to\infty} \mathbb{P}(R_t > x) = \frac{1}{\mu}\int_x^\infty F^c (y)\,\mathrm{d}y,\; x\in[0,\infty)
$$

2. If the renewal process is aperiodic, then

$$
  \lim_{t\to\infty} \mathbb{P}(C_t > x) = \frac{1}{\mu}\int_x^\infty F^c (y)\,\mathrm{d}y,\; x\in[0,\infty)
$$

3. The current and remainig life have the same limiting distribution:

$$
  \lim_{t\to\infty}\mathbb{P}(C_t \leq x) = \lim_{t\to\infty}\mathbb{P}(R_t \leq x) = \frac{1}{x}\int_0^x F^c (y)\,\mathrm{d}y
$$

4. If the renewal process is non-arithmetic then

$$
  \lim_{t\to\infty}\mathbb{P}(L_t \leq x) = \frac{1}{\mu}\int_0^x y\,\mathrm{d}F(y),\; x\in[0,\infty)
$$

<details>
<summary>Proof</summary>

1. Recall that 

$$
  \mathbb{P}(R_t > x) = F^c (t + x) + \int_0^t F^c (t + x - s)\,\mathrm{d}M(s)\,\; x\in[0,\infty)
$$

Since $\lim_{t\to\infty} F^c (t+x) = 0$, it follows that the integral converges to $\frac{1}{\mu}\int_0^\infty F^c(x + y)\,\mathrm{d}y$ by the key renewal theorem. Changing variables in the limiting integral gives the result.

2. Recall that, since the renewal process is aperiodic

$$
  \mathbb{P}(C_t > x) = F^c (t) + \int_0^{t-x} F^c (t - s)\,\mathrm{d}M(s)\,\; x\in[0,t]
$$

Note that $\lim_{t\to\infty} F^c (t) = 0$. The change of variables $u = t - x$ changes the integral into $\int_0^u F^c (u + x - s)\,\mathrm{d}M(s)$. By the key renewal theorem, this integral converges to

$$
  \frac{1}{\mu}\int_0^\infty F^c (y+x)\,\mathrm{d}y = \int_x^\infty F^c (y + x)\,\mathrm{d}y
$$

3. By the previous two results, the limiting right distribution functions of $R_t$ and $C_t$ are the same. The ordinary (left) limiting distribution function is

$$
  1 - \frac{1}{\mu}\int_x^\infty F^c(y)\,\mathrm{d}y = \frac{1}{\mu}\left(\mu - \int_x^\infty F^c(y)\,\mathrm{d}y \right)
$$

Note that $\mu = \int_0^\infty F^c (y)\,\mathrm{d}y$, so the result follows since

$$
  \int_0^\infty F^c (y)\,\mathrm{d}y - \int_x^\infty F^c(y)\,\mathrm{d}y = \int_0^x F^c(y)\,\mathrm{d}y
$$

4. Fix $x\in[0,\infty)$. For $n\in\mathbb{N}_+$ define state $1$ (on) period associated with the interarrival time $X_n$ by $U_n = X_n \mathbf{1}(X_n > x)$. The state $0$ (off) period corresponding to $X_n$ is $V_n = X_n - U_n$. Thus, each renewal period is either totally on or off, depending on whether or not the interarrival time is greater that $x$. Note that the system is on at time $t\in[0,\infty)$ if and only if $L_t > x$, such that for a generic interarrival time $X$

$$
  \lim_{t\to\infty}\mathbb{P}(L_t > x) = \frac{1}{\mu}\mathbb{E}[X\mathbf{1}(X > x)]
$$

Finally, note that $\mathbb{E}[X\mathbf{1}(X > x)] = \int_x^\infty y\,\mathrm{d}F(y)$.
</details>
</MathBox>

<MathBox title='Age process limits' boxType='proposition'>
Let $\mu = \mathbb{E}(X)$ and $\nu = \mathbb{E}(X^2)$.

Limits for the current life process
1. $\frac{1}{t}\int_0^t C_s\,\mathrm{d}s = \frac{\nu}{2\mu}$ with probability $1$
2. $\frac{1}{t}\int_0^t c(s)\,\mathrm{d}s = \frac{\nu}{2\mu}$

Limits for the remaining life process
3. $\frac{1}{t}\int_0^t R_s\,\mathrm{d}s = \frac{\nu}{2\mu}$ with probability $1$
4. $\frac{1}{t}\int_0^t r(s)\,\mathrm{d}s = \frac{\nu}{2\mu}$

Limits for the total life process
5. $\frac{1}{t}\int_0^t L_s\,\mathrm{d}s = \frac{\nu}{mu}$ with probability $1$
6. $\frac{1}{t}\int_0^t l(s)\,\mathrm{d}s = \frac{\nu}{2\mu}$ 

<details>
<summary>Proof</summary>

Consider the renewal reward process where the reward associated with the interarrival time $X_n$ is $\frac{1}{2}X_n^2$ for $n\in\mathbb{N}$.

**Current life**
The process $t\mapsto\int_0^t C_s\,\mathrm{d}s$ for $t\in[0,\infty)$ is a continuous reward process for this sequence of rewards. To see this, note that for $t\in[T_n, T_{n+1})$, we have $C_t = t - T_n$. Changing variables and noting that $T_{n+1} = T_n + X_{n+1}$ we have

$$
  \int_{T_n}^{T_{n+1}} C_t\,mathrm{d}t = \int_0^{X_{n+1}} s\,\mathrm{d}s = \frac{1}{2}X_{n+1}^2
$$

The results follow directly from the reward renewal theorem.

**Remaining life**
The process $t\mapsto\int_0^t R_s\,\mathrm{d}s$ for $t\in[0,\infty)$ is a continuous reward process for this sequence of rewards. To see this, note that for $t\in[T_n, T_{n+1})$, we have $C_t = t - T_n$. Changing variables and noting that $T_{n+1} = T_n + X_{n+1}$ we have

$$
  \int_{T_n}^{T_{n+1}} R_t\,mathrm{d}t = \int_0^{X_{n+1}} s\,\mathrm{d}s = \frac{1}{2}X_{n+1}^2
$$

The results follow directly from the reward renewal theorem.

**Total life**
The limits for the total life process follow trivially from the results for the current and remaining life processes.
</details>
</MathBox>

## Replacement models
Replacement models are variations on a basic renewal process in which the devices is replaced at times other than failure. Often the cost $a$ of a planned replacement is less than the cost $b$ of an emergency replacement (at failure).

In the age replacement model, the device is replace either when it fails or when it reaches a specified age $s\in(0,\infty)$. This model gives rise to a new renewal process with interarrival sequence $\mathbf{U} = (U_n)_{n\in\mathbb{N}}$ where $U_n = \min\{X_n, s\}$ for $n\in\mathbb{N}_+$. If $a,b\in(0,\infty)$ are the costs of planned and unplanned replacements, respectively, then the associated cost associated with the renewal period $U_n$ is

$$
  Y_n = a\mathbf{1}(U_n = s) + b\mathbf{1}(U_n < s) = a\mathbf{1}(X_n \geq s) + b\mathbf{1}(X_n < s)
$$

The sequence $((U_n, Y_n))_{n\in\mathbb{N}_+}$ satisfies the assumptions of a renewal process. If $a\geq b$, i.e. the planned cost of replacement is at least as large as the unplanned cost of replacement, then $Y_n \geq b$ for $n\in\mathbb{N}_+$. In this case, the model makes no financial sense.

<MathBox title='Properties of age replacement processes' boxType='proposition'>
Let $F$ be the common distribution function associated with the underlying intearrival sequence $\mathbf{X}$ for. Then

1. The expected cost of a renewal period is $\mathbb{E}(Y) = aF^c(s) + bF(s)$
2. The expected length of a renewal period is $\mathbb{E}(U) = \int_0^s F^c (x)\,\mathrm{d}x$ 
3. The limiting expected cost per unit time is 

$$
  K(s) = \frac{\mathbb{E}(Y)}{\mathbb{E}(U)} = \frac{aF^c (s) + bF(s)}{\int_0^s F^c}
$$

<details>
<summary>Proof</summary>

The 1st and 2nd properties follow from the definition of the reward $Y$ and the renewal period $U$. The 3rd property follows from the reward renewal theorem.
</details>
</MathBox>

<MathBox title='Age replacement cost density limits' boxType='proposition'>
1. $C(s) \xrightarrow{s\downarrow 0} \infty$
2. $C(s) \xrightarrow{s\uparrow 0} \infty$

<details>
<summary>Proof</summary>

1. Recall that $F^c (0) > 0$ an $\lim_{s\downarrow 0} \int_0^s F^c(x)\,\mathrm{d}x = 0$
2. Note that $\lim_{s\to\infty} F^c(s) = 0$ and $\lim_{s\to\infty} F(s) = 1$ and

$$
  \lim_{s\to\infty} \int_0^s F^c(x)\,\mathrm{d}x = \int_0^\infty F^c(x)\,\mathrm{d}x = \mu
$$
</details>
</MathBox>

# Markov process

A Markov process is a stochastic process with the property that the probability of a future event dependens only on the present state, i.e. the future is independent of the past.

| | Countable (discrete) state space | Continuous or general state space |
|---|---|---|
| **Discrete-time** $T=\mathbb{N}$ | discrete-time Markov chain | Markov process on a measurable space |
| **Continuous-time** $T=[0,\infty)$ | continuous-time Markov chain | Continuous stochastic process with the Markov property |

<MathBox title='Markov process' boxType='definition'>
A stochastic process $\mathbf{X}$ is a *Markov process* if it satisfies the Markov property

$$
  \mathbb{P}(X_{s+t}\in A|\mathcal{F}_s) = \mathbb{P}(X_{s+t}\in A|X_s)
$$

for all $s,t\in T$ and $A\in\mathcal{S}$. In particular, a Markov process $\mathbf{X}$ is *time homogeneous* (stationary) if

$$
  \mathbb{P}(X_{s+t}\in A | X_s = x) = \mathbb{P}(X_t\in A | X_0 = x)
$$
</MathBox>

The Markov property states that the conditional distribution of a future state $X_{s+t}$ given $\mathcal{F}_s$ is the same as the conditional distribution of $X_{s+t}$ just given the current state $X_s$. This means that any additional knowledge of events in the past is irrevelant in terms of predicting the future state $X_{s+t}$.

<MathBox title='Markov property in terms of conditional expectation' boxType='proposition'>
A stochastic process $\mathbf{X}$ is a *Markov process* if and only if

$$
  \mathbb{E}\left[f(X_{s+t})|\mathcal{F}_s\right] = \mathbb{E}\left[f(X_{s+t})|X_s\right]
$$

for all $s,t\in T$ and $f\in\mathcal{B}$. If a Markov process $\mathbf{X}$ is *time homogeneous* (stationary) then

$$
  \mathbb{E}\left[f(X_{s+t})|X_s = x\right] = \mathbb{E}\left[f(X_{s+t})|X_0 = x\right]
$$

<details>
<summary>Proof</summary>

By letting $f = \mathbf{1}_A$ for $A\in\mathcal{S}$ then $\mathbb{E}[\mathbf{1}_A(X_{x+t})] = \mathbb{P}(X_{x+s}\in A)$. Thus the conditional expectation formulation is equivalent with the Markov property.

</details>
</MathBox>

<MathBox title='Markov property is preserved under coarser filtrations' boxType='proposition'>
Suppose that the stochastic process $\mathbf{X}$ is adapted to the filtration $\mathscr{F}$, and $\mathscr{F}\subseteq\mathscr{G}$, i.e. $\mathscr{G}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a Markov process relative to $\mathscr{G}$, then $\mathbf{X}$ is a Markov process relative to $\mathscr{F}$.

In particular, if $\mathbf{X}$ is a Markov process, then $\mathbf{X}$ satisfies the Markov property relative to the natural filtration $\mathcal{F}^0$

<details>
<summary>Proof</summary>

Note $\mathbf{X}$ is adapted to $\mathscr{G}$, since $\mathbf{X}$ is adapted to $\mathscr{F}$ and $\mathscr{F}\subseteq\mathbf{G}$. If $s,t\in T$ and $f\in\mathcal{B}$ then

$$
\begin{align*}
  \mathbb{E}[f(X_{t+s})|\mathcal{F}_s] &= \mathbb{E}\left(\mathbb{E}[f(X_{s+t})|\mathcal{G}_s] | \mathcal{F}_s \right) \\
  &= \mathbb{E}\left( \mathbb{E}[f(X_{s+t})|X_s]|\mathcal{F}_s \right) \\
  &= \mathbb{E}[f(X_{s+t})|X_s]
\end{align*}
$$

The first equality is a basic property of conditional expected value. The second uses the fact that $\mathbf{X}$ is Markov relative to $\mathscr{G}$, and the third follows since $X_s$ is measurable with respect to $\mathcal{F}_s$
</details>
</MathBox>

<MathBox title='Feller process' boxType='definition'>
A Markov process $\mathbf{X}$ is a *Feller process* if it satisfies
1. Continuity in space: For $t\in T$ and $y\in S$, the distribution of $X_t$ given $X_0 = x$ converges to the distribution of $X_t$ given $X_0 = y$ as $x\to y$. This means taht $\mathbb{E}[f(X_t)| X_0 = x] \xrightarrow{x\to y}$ for every $f\in\mathcal{C}$.
2. Continuity in time: Given $X_0 = x$ for $x\in S$, then $X_t \xrightarrow{t\downarrow 0} x$ in probability. This means that $\mathbb{P}[X_t \in U | X_0 = x] \xrightarrow{t\downarrow 0}$ for every neighbourhood $U$ of $x$.
</MathBox>

Note that if $S$ is discrete, the first Feller property is always satisfied, and if $T$ is discrete, the second Feller property is always satisfied. In partical, every discrete-time Markov chain is a Feller process.

## Strong Markov process (stopping time)

Strong Markov processes arise with stopping times. Recall that random time is a random variable $\tau:\Omega\to T_\infty$ on $(\Omega,\mathcal{F},\mathbb{P})$ where $T_\infty = T \cup \{\infty\}$ is an enlarged time space. For a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ filtration on $(\Omega,\mathcal{F})$, a random time $\tau$ is called a stopping time relative to $\mathscr{F}$ if $\{\tau\leq t\}\in\mathcal{F}_t$ for each $t\in T$. For any stopping time $\tau$ on $\Omega$ we can define

$$
  \mathcal{F}_\tau = \{ A\in\mathcal{F} \mid A\cap \{\tau \leq t \}\in\mathcal{F}_t \; \forall t\in T \}
$$

Note that if $\mathbf{X} = \{X_t \}_{t\in T}$ is a stochastic process adapted to a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$, then for a stopping time $\tau$ the random variable $X_\tau$ is not necessarily measurable with respect to $\mathcal{F}_\tau$. For this we require that $\mathbf{X}$ is progressively measurable relative to $\mathscr{F}$ in the sense that $\mathbf{X}:\Omega\times T_t\to S$ is measurable with respect to $\mathcal{F}_t \otimes\mathcal{T}_t$ and $\mathcal{S}$. This is always true in the discrete case and more generally if $S$ has an LCCB topology with $\mathcal{S}$ as the Borel $\sigma$-algebra, and $\mathbf{X}$ is right continuous.

<MathBox title='Strong Markov process' boxType='definition'>
The process $\mathbf{X}$ is a strong Markov process if

$$
  \mathbb{E}\left[ f(X_{\tau + t})|\mathcal{F}_\tau \right] = \mathbb{E}[f(X_{\tau + t})|X_\tau]
$$

for every $t\in T$, stopping time $\tau$ and $f\in\mathcal{B}$. If a strong Markov process $\mathbf{X}$ is *time homogeneous* (stationary) then

$$
  \mathbb{E}\left[f(X_{\tau + t})|X_\tau = x\right] = \mathbb{E}\left[f(X_{\tau+t})|X_0 = x\right]
$$
</MathBox>

For a stationary process, the strong Markov property implies the ordinary Markov process, since a fixed time $t\in T$ is trivially also a stopping time. The converse is also true in discrete time. In continuous time it depends on the continuity of $\mathbf{X}$ and the filtration $\mathscr{F}$

<MathBox title='Stationarity and the strong Markov property' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a time homogeneous Markov process in discrete time. Then $\mathbf{X}$ is a strong Markov process.

If $\mathbf{X} = \{X_t \}_{t\geq 0}$ is a Feller Markov process, then $\mathbf{X}$ is a strong Markov process relative to the filtration $\mathscr{F}_+^0$, the right-continuous refinement of the natural filtration.
</MathBox>

<MathBox title='The strong Markov property is preserved under coarser filtrations' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is progressively measurable relative to the filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ and that the filtration $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a strong Markov process relative to $\mathscr{G}$ then $\mathbf{X}$ is a strong Markov process relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Since $\mathbf{X}$ is adapted to $\mathscr{F}$, it is also adapted to $\mathscr{G}$. Suppose that $\tau$ is a stopping time for $\mathscr{F}$ and that $t\in T$ and $f\in\mathcal{B}$. Then $\tau$ is also a stopping time for $\mathscr{G}$ and $\mathcal{F}_\tau \subseteq\mathcal{G}_\tau$. Hence

$$
\begin{align*}
  \mathbb{E}\left[f(X_{\tau + t})|\mathcal{F}_\tau\right] &= \mathbb{E}\left(\mathbb{E}\left[f(X_{\tau + t})|\mathcal{G}_\tau\right]|\mathcal{F}_\tau \right) \\
  &= \mathbb{E}\left(\mathbb{E}\left[f(X_{\tau + t})|X_\tau\right]|\mathcal{F}_\tau \right) \\
  &= \mathbb{E}\left[f(X_{\tau + t})|X_\tau\right]
\end{align*}
$$

The last equation follows since $\mathbf{X}_\tau$ is measurable with respect to $\mathcal{F}_\tau$ given that $\mathbf{X}$ is progressively measurable to $\mathscr{F}$.
</details>
</MathBox>

## Transition kernels of Markov processes

The transition kernels of a time-homogeneous Markov process is the conditional distribution given the initial distribution of the process. This means that the initial distribution and the transition kernels determine the finite dimensional distributions of a Markov process.

<MathBox title='Transition kernel' boxType='definition'>
Suppose that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a time-homogeneous Markov process. For $t\in T$ let

$$
  P_t(x,A) = \mathbb{P}(X_t\in A \mid X_0 = x),\; x\in S, A\in\mathcal{S}
$$

Then $P_t$ is a probability kernel on $(S,\mathcal{S})$ known as the transition kernel of $\mathbf{X}$ for time $t$. 

<details>
<summary>Proof</summary>

For a fixed $t\in T$, the measurability of $x\mapsto\mathbb{P}(X_t \in A \mid X_0 = x)$ for $A\in\mathcal{S}$ is built into the definition of conditional probability. Additionally, $A\mapsto\mathbb{P}(X_t\in A \mid X_0 = x)$ is a probability measure on $\mathcal{S}$ for $x\in S$. In general, the conditional distribution of one random variable, conditioned on a value of another random variable defines a probability kernel.
</details>
</MathBox>

The transition kernel $P_t(x,\cdot)$ of a time-homogeneous Markov process $\mathbf{X}$ at time $t$ is the conditional distribution of $X_t$ given $X_0 = x \in S$. By the time-homogeneous property, $P_t(x, \cdot)$ is also the conditional distribution of $X_{s+t}$ given $X_s = x$ for $s\in T$

$$
  P_t(x, A) = \mathbb{P}(X_{s+t}\in A | X_s = x),\; s,t\in T, x\in S, A\in\mathcal{S}
$$

Usually there is a natural reference measure $\lambda$ on $(S,\mathcal{S})$, in which case the transition kernel $P_t$ will often have a transition density with respect to $\lambda$

$$
  P_t(x, A) = \mathbb{P}(X_t \in A \mid X_0 = x) = \int_A p_t(x, y)\lambda(\mathrm{d}y),\; x\in S, A\in\mathcal{S}
$$

<MathBox title='Chapman-Kolmogorov equation' boxType='theorem'>
Suppose that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a time-homogeneous Markov process with transition kernels $\mathbf{P} = \{ P_t \}_{t\in T}$. For $s,t\in T$ then $P_s P_t = P_{s+t}$ given by

$$
  P_{s+t}(x,A) = \int_S P_s(x, \mathrm{d}y) P_t(y, A),\; x\in S, A\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

Note that $P_x(x,\cdot)$ is the conditional distribution of $X_s$ given $X_0 = x \in S$. Conditioning on $X_s$ for $A\in\mathcal{S}$ gives

$$
\begin{align*}
  P_{s+t}(x,A) &= \mathbb{P}(X_{s+t}\in A \mid X_0 = x) \\
  &= \int_S P_s(x, \mathrm{d}y)\mathbb{P}(X_{s+t}\in A \mid X_s = y, X_0 = x)
\end{align*}
$$

By the Markov and time-homogeneous properties, we have

$$
  \mathbb{P}(X_{s+t}\in A \mid X_s = y, X_0 = x) = \mathbb{P}(X_t\in A \mid X_0 = y) = P_t(y,A)
$$

Substituting we get

$$
  P_{s+t}(x,A) &= \int_S P_s (x,\mathrm{d}y)P_t(y, A) = (P_s P_t)(x, A)
$$
</details>
</MathBox>

The set of transition kernels $\mathbf{P}$ is a semi-group. Generally, the commutative property does not hold for the product operation on kernels. However, transition kernels a of time-homogeneous Markov process are commutative, i.e. $P_s P_t = P_t P_s = P_{s+t}$ for $s,t\in T$.

In discrete time, $T = \mathbb{N}$, the transition kernels of $\mathbf{X}$ are simply the powers of the one-step transition kernel. That is if $P = P_1$ then $P_n = P^n$ for $n\in\mathbb{N}$.

<MathBox title='' boxType='corollary'>
Suppose that $\lambda$ is the reference measure on $S$ and that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a Markov process with transition densities $\{ p_t \}_{t\in T}$. If $s,t \in T$, then $p_s p_t = p_{s+t}$

$$
  p_t (x, z) = \int_S p_s(x, x) p_t(y, z)\lambda(\mathrm{d}y),\; x, z\in S
$$

<details>
<summary>Proof</summary>

By the Chapman-Kolmogorov equation, the transition kernels of $\mathbf{X}$ satisfy $P_s P_t = P_{s+t}$. Since $P_s$ has density $p_s$, $P_t$ has density $p_t$ and $P_s P_t$ has density $p_{s + t}$ it follows from the Chapman-Kolmogorov equation that $P_{s+t}$ has density $p_s p_t$.
</details>
</MathBox>

A kernel defines two operations:
- operating on the left with positive measure on $(S,\mathcal{S})$
- operating on the right with measurable, real-valued functions

<MathBox title='Left transition kernel operation' boxType='proposition'>
If $\mu_s$ is the distribution of $X_s$, then $X_{s+t}$ has distribution $\mu_{s+t} = \mu_s P_t$ for $s,t\in T$

$$
  \mu_{s+t}(A) = \int_S \mu_s(\mathrm{d}x)P_t(x, A),\; A\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

Conditioning on $X_s$ gives

$$
\begin{align*}
  \mathbb{P}(X_{s+t}\in A) &= \mathbb{E}\left[\mathbb{P}(X_{s+t}\in A \mid X_s) \right] \\
  &= \int_S \mu_s(\mathrm{d}x)\mathbb{P}(X_{s+t}\in A \mid X_s = x) \\
  &= \int_S \mu_s(\mathrm{d}x)\mathbb{P}_t(x, A) \\
  &= \mu_s P_t (A)
\end{align*}
$$
</details>
</MathBox>

If $\mathcal{P}$ denotes the collection of probability measures on $(S,\mathcal{S})$, the left operator $P_t$ maps $\mathcal{P}$ back into $\mathcal{P}$. In particular, if $X_0$ has distribution $\mu_0$ then $X_t$ has distribution $\mu_t = \mu_0 P_t$ for every $t\in T$.

<MathBox title='Invariant positive measures' boxType='definition'>
A positive measure $\mu$ on $(S, \mathcal{S})$ is invariant for $\mathbf{X}$ if $\mu P_t = \mu$ for every $t\in T$.
</MathBox>

If $\mu$ is a probability measure that is invariant for $\mathbf{X}$, and $X_0$ has distribution $\mu$, then $X_t$ also has distribution $\mu$ for every $t\in T$ making the process $\mathbf{X}$ identically distributed. In discrete time, note that if $\mu P = \mu$ then $\mu P^n = \mu$ for every $n\in \mathbb{N}$ so $\mu$ is invariant for $\mathbf{X}$

<MathBox title='Right transition kernel operation' boxType='proposition'>
Suppose that $f:S\to\mathbb{R}$. If $t\in T$ then

$$
  P_t f(x) = \int_S P_t(x, \mathrm{d}y)f(y) = \mathbb{E}[f(X_t)\mid X_0 = x],\; x\in S
$$

<details>
<summary>Proof</summary>

This follows directly from the definition of conditional expectation.
</details>
</MathBox>

In particular, the right operator $P_t$ is defined on $\mathcal{B}$, the vector space of bounded, linear functions $f:S\to\mathbb{R}$, and is in fact a linear operator on $\mathcal{B}$. That is, if $f,g\in\mathcal{B}$ and $c\in\mathbb{R}$ then $P_t (f+g) = P_t f + P_t g$ and $P_t (cf) = cP_t f$. Moreover, $P_t$ is a contraction operator on $\mathcal{B}$, since $\lVert P_t f \rVert\leq \lVert f \rVert$ for $f\in\mathcal{B}$. It follows that $P_t$ is a continuous operator on $\mathcal{B}$.

<MathBox title='Harmonic measurable function' boxType='definition'>
A measurable function $f:S\to\mathbb{R}$ is harmonic for $\mathbf{X}$ is $P_t f = f$ for all $t\in T$.
</MathBox>

In discrete time, if $Pf = f$ then $P^n f = f$ for all $n\in\mathbb{N}$, making $f$ harmonic for $\mathbf{X}$.

<MathBox title='Differential form of Markov distributions' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a Markov process with transition operators $\mathbf{P} = \{P_t \}_{t\in T}$ and that $(t_i)_{i=1}^{n\in\mathbb{N}} \in T^n$ is strictly increasing. If $X_0$ has distribution $\mu_0$, then in differential form the distribution of $(X_i)_{i=0}^{t_n}$ is

$$
  \mu_0(\mathrm{d}x_0)P_{t_1}(x_0, \mathrm{d}x_1)\prod_{i=2}^{n} P_{t_n - t_{n-1}}(x_{n-1}, \mathrm{d}x_n)
$$

<details>
<summary>Proof</summary>

This follows from induction and repeated use of the Markov property. If $t\in T$ with $t> 0$, then conditioning on $X_0$ gives for $A, B\in\mathcal{S}$

$$
\begin{align*}
  \mathbb{P}(X_0 \in A, X_t\in B) = \int_A \mathbb{P}(X_t\in B \mid X_0 = x)\mu_0 (\mathrm{d}x) \\
  &= \int_A P_t (x, B\mu(\mathrm{d}x) \\
  &= \int_A \int_B P_t(x,\mathrm{d}y)\mu_0 (\mathrm{d}x)
\end{align*}
$$

Hence in differential form, the distribution of $(X_0, X_t)$ is $\mu(\mathrm{d}x)P_t(x,\mathrm{d}y)$. If $s,t\in T$ with $0 < s < t$, then conditioning on $(X_0, X_s=$ and using the previous result gives for $A, B, C \in\mathcal{S}$

$$
  \mathbb{P}(X_0\in A, X_s\in B, X_t\in C) = \int_{A\times B} \mathbb{P}(X_t\in C \mid X_0 = x, X_s = y)\mu_0 (\mathrm{d}x) P_s(x, \mathrm{d}y)
$$

By the Markov property

$$
\begin{align*}
  \mathbb{P}(X_t\in C \mid X_0 = x, X_s = y) &= \mathbb{P}(X_t \in C | X_s = y) \\
  &= P_{t-s}(y, C) = \int_C P_{t-s}(y,\mathrm{d}z)
\end{align*}
$$

Hence in differential form, the distribution of $(X_0, X_s, X_t)$ is $\mu_0(\mathrm{d}x)P_s(x,\mathrm{d}y)P_{t-s}(y,\mathrm{d}z})$. Continuing in this manner gives the general result.
</details>
</MathBox>

Knowing the transition kernels and the initial distribution determines a finite set of distributions for a Markov process. From the Kolmogorov construction theorem, we know that there exists a stochastic process that has these finite dimensional distributions. This is straightforward in discrete time, however in continuous time two problems arise. First, it is not clear how to construct the transition kernels so that the Chapman-Kolmogorov equations are satisfied. Second, we want the Markov process to exhibit certain properties that go beyond the finite dimensional distributions.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a Markov process on an LCCB state space $(S,\mathcal{S})$ with transition operators $\mathbf{P} = \{P_t \}_{t\in [0,\infty)}$. Then $\mathbf{X}$ is a Feller process if and only if

1. Continuity in space: If $f\in\mathcal{C}_0$ and $t\in[0,\infty)$, then $P_t f\in\mathcal{C}_0$
2. Continuity in time: If $f\in\mathcal{C}_0$ and $x\in S$ then $P_t f(x) \xrightarrow{t\downarrow 0} f(x)$

A semi-group of probability kernels $\mathbf{P}$ satisfying these properties is called a Feller semi-group.
</MathBox>

This means that a Markov process $\mathbf{X}$ is Feller if and only if $\mathbf{P}$ is Feller. The first property means that $P_t$ is an operator on the vector space $\mathcal{C}_0$, in addition to being an operator on the larger space $\mathcal{B}$. The second condition implies a stronger form of continuity in time.

Note that if $S$ is discrete, then the first property is automatically satisfied. If $T$ is discrete, then the second property is automatically satisfied.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{P} = \{P_t \}_{t\in [0,\infty)}$ is a Feller semi-group of transition operators. Then $t\mapsto P_t f$ is continuous (with respect to the supremum norm) for $f\in\mathcal{C}_0$, i.e.

$$
  \lVert P_{t+s} f - P_t f \rVert = \sup\{|P_{t+s}f(x) - P_t f(x)| : x\in S \} \xrightarrow{s\to 0} 0
$$
</MathBox>

### Sampling in time

<MathBox title='Time sampled Markov process gives a time-discrete Markov process' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a Markov process with state space $(S,\mathcal{S})$ and that $(t_i)_{i=0}^{n\in\mathbb{N}}$ is an increasing sequence in $T$. Let $Y_n = X_{t_n}$, then $\mathbb{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a Markov process in discrete time.

<details>
<summary>Proof</summary>

For $n\in\mathbb{N}$, let $\mathcal{G}_n = \sigma\{ Y_k \mid k\in\mathbb{N}, k\leq n \}$ so that $\{\mathcal{G}_n\}_{n\in\mathbb{N}}$ is the natural filtration associated with $\mathbf{Y}$. Note that $\mathcal{G}_n \subseteq \mathcal{F}_{t_n}$ and $Y_n = X_{t_n}$ is measurable with respect to $\mathcal{G}_n$ for $n\in\mathcal{N}$. Let $k, n\in\mathbb{N}$ and let $A\in\mathcal{S}$, then

$$
\begin{align*}
  \mathbb{P}(Y_{k+n}\in A \mid \mathcal{G}_k) = \mathbb{P}(X_{t_{n+k}}\in A \mid \mathcal{G}_l) \\
  &=  \mathbb{P}(X_{t_{n+k}}\in A \mid X_{t_k}) \\
  &= \mathbb{P}(Y_{n+k}\in A \mid Y_k) 
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a time-homogenous Markov process with state space $(S,\mathcal{S})$ and transition kernels $\mathbf{P} = \{P_t\}_{t\in T}$. Fix $r\in T$ with $r>0$ and define $Y_n = X_{nr}$ for $n\in\mathbb{N}$. Then $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a time-homogenous Markov process in discrete time, with one-step transition kernel

$$
  Q(x, A) = P_r (x, A),\; x\in S, A\in\mathcal{A}
$$
</MathBox>

### Enlarging the sample space

A non-homogeneous Markov process can be turned into a time-homogenous Markov process at the expense of enlarging the state space.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a non-homogenous Markov process with state space $(S,\mathcal{S})$. Suppose that $\tau$ is a random variable taking values in $T$, independent of $\mathbf{X}$. Let $\tau_t = \tau + t$ and let $Y_t = (X_{\tau_t}, \tau_t)$ for $t\in T$. Then $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a homogenous Markov process with state space $(S\times T, \mathcal{S} \otimes \mathcal{T})$. For $t\in T$, the transition kernel $P_t$ is given by

$$
  P_t [(x, r), A\times B] = \mathbb{P}(X_{r+t}\in A\mid X_r = x)\mathbf{1}(r + t\in B), (x,r)\in S\times T, A\times B\in\mathcal{S}\otimes\mathcal{T}
$$

<details>
<summary>Proof</summary>

By definition and the substitution rule

$$
\begin{align*}
  \mathbb{P}[Y_{s+t}\in A\times B \mid Y_s = (x,r)] &= \mathbb{P}(X_{\tau_{s+t}}\in A, \tau_{s+t}\in B \mid X_{\tau_{s}} = x, \tau_s = r) \\
  &= \mathbb{P}(X_{tau+s+t}\in A, \tau+s+t\in B \mid X_{\tau+s} = x, \tau+s = r) \\
  &= \mathbb{P}(X_{r+t}\in A, r+t\in B \mid X_r = x, \tau+s = r)
\end{align*}
$$

Since $\tau$ is independent of $\mathbf{X}$ the last term is

$$
  \mathbb{P}(X_{r+t}\in A, r+t\in B \mid X_r = x, \tau+s = r) = \mathbb{P}(X_{r+t}\in A \mid X_r = x)
$$

which does not depend on $s$, making $\mathbf{Y}$ time-homogenous.
</details>
</MathBox>

Sometimes a stochastic process with weak memory can be made into a Markov process by enlarging the state space appropriately

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{n\in\mathbb{N}}$ is a random process with state space $(S,\mathcal{S})$ in which the future depends on the last $k$ states, i.e.

$$
  \mathbb{P}(X_{n+k} \in A | \mathcal{F}_{n+k-1}) = \mathbb{P}(X_{n+2}\in A \mid X_n,\dots,X_{n+k}),\; A\in\mathcal{S}
$$

where $\{\mathcal{F}_n\}_{n\in\mathbb{N}}$ is the natural filtration associated with the process $\mathbf{X}$. Suppose also that the process is time-homogenous in the sense that

$$
  \mathbb{P}(X_{n+k}\in A \mid X_n = x_0, \dots, X_{n+k} = x_k) = Q(x_0,\dots,x_k, A)
$$
 
independently of $n\in\mathbb{N}$. Let $Y_n = (X_n+i)_{i=0}^k-1$, then $\mathbf{N} = \{Y_n\}_{n\in\mathbb{N}}$ is a time homogenous Markov process with state space $S^k, \bigotimes_{i=1}^k \mathcal{S}$. The one-step transition kernel is

$$
  P[(x_i)_{i=1}^k, \prod_{i=1}^k A_i] = I(x_1, A_1)Q_1(x_1, x_2, A_2)\dots Q_{k-1}(x_1,\dots,x_k, Q_k)\; x_i\in S, A_i\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

For $k=2$ note that $\sigma\{Y_k \mid k\leq n\} = \sigma\{(X_k, X_{k+1}) \mid k\leq n \} = \mathcal{F}_{n+1}$ for $n\in\mathbb{N}$. Thus, the natural filtration associated with $\mathbf{Y}$ is $\{\mathcal{F}_n\}_{n\in\mathbb{N}}$. If $C\in\mathcal{S}\mathcal{S}$ then

$$
\begin{align*}
  \mathbb{P}(Y_{n+1}\in C \mid \mathcal{F}_{n+1}) &= \mathbb{P}[(X_{n+1}, X_{n+2})\in C \mid \mathcal{F}_{n+1}] \\
  &= \mathbb{P}[(X_{n+1}, X_{n+2})\in C \mid X_n, X_{n+1}] = \mathbf{P}(Y_{n+1}\in C \mid Y_n)
\end{align*}
$$

by the given assumption on $\mathbf{X}$. Hence $\mathbf{Y}$ is a Markov process. Next,

$$
\begin{align*}
  \mathbb{P}[Y_{n+1}\in A\times B \mid Y_n = (x,y)] &= \mathbb{P}[(X_{n+1}, X_{n+2})\in A\times B \mid (X_n, X_{n+1}) = (x,y)] \\
  &= \mathbb{P}(X_{n+1}\in A, X_{n+2}\in B \mid X_n = x, X_{n+1} = y) \\
  &= \mathbb{P}(y\in A, X_{n+2}\in B \mid X_n = x, X_{n+1} = y) \\
  &= I(y, A)Q(x,y,B)
\end{align*}
$$
</details>
</MathBox>

## Potential operators

### Discrete-time

<MathBox title='Discrete-time potential kernel' boxType='proposition'>

For $\alpha\in (0,1]$, the $\alpha$-potential kernel $R_\alpha$ of a discrete time Markov process $\mathbf{X}$ is defined as

$$
  R_\alpha (x, A) = \sum_{n=0}^\infty \alpha^n P^n (x, A),\; x\in S, A\in\mathcal{S}
$$

The special case $R = R_1$ is simply the potential kernel of $\mathbf{X}$ where $R(x, A)$ is the expected number of visits of $\mathbf{X}$ to $A$, starting at $x$.

<details>
<summary>Proof</summary>

The function $x\mapsto R_\alpha (x, A)$ from $S$ to $[0,\infty)$ is measurable for $A\in\mathcal{S}$ since $x\mapsto P^n(x, A)$ is measurable for each $n\in\mathbb{N}$. The mapping $A\mapsto R_\alpha (x, A)$ is a positive measure on $\mathcal{S}$ for $x\in S$ since $A\mapsto P^n(x, A)$ is a probability measure for each $n\in\mathbb{N}$. The interpretation of $R(x, A)$ comes from interchanging sum and expected value, which is allowed since the terms are nonnegative.

$$
\begin{align*}
  R(x, A) &= \sum_{n=0}^\infty P^n (x, A) \\
  &= \sum_{n=0}^\infty \mathbb{E}[\mathbf{1}(X_n \in A) | X_0 = x] \\
  &= \mathbb{E}\left( \sum_{n=0}^\infty \mathbf{1}(X_n \in A) \middle| X_0 = x \right) \\
  &= \mathbb{E}[#\{n\in\mathbb{N} : X_n \in A\}|X_0 = x]
\end{align*}
$$
</details>
</MathBox>

For a discrete-time Markov process $\mathbf{X}$, the potential kernel $R_\alpha (x, A)$ for $\alpha\in(0,1)$ can be interpreted as the expected number of times $\mathbf{X}$ visits $A\in\mathcal{S}$ starting at $x\in S$. The parameter $\alpha$ represents a discount rate of this expected value in the sense that a future vists at time $n$ has a present value of $\alpha^n$.

The potential kernel $R_\alpha$ defines two operators, operating on the right on measurable functions, and on the left on positive measures. For measurable functions $f:S\to\mathbb{R}$, the right potential operator is defined as

$$
\begin{align*}
  R_\alpha f(x) &= \sum_{n=0}^\infty \alpha^n P^n f(x) \\
  &= \sum_{n=0}^\infty \alpha^n \int_S P^n (x,\mathrm{d}y) f(y) \\
  &= \sum_{n=0}^\infty \alpha^n \mathbb{E}[f(X_n)|X_0 = x]
\end{align*}
$$

The functions $f\in\mathcal{B}$ represents the reward/cost when $\mathbf{X}$ visits $x\in S$.

<MathBox title='' boxType='proposition'>

If $\alpha\in (0,1)$, then $R_\alpha (x, S) = \frac{1}{1-\alpha}$. It follows that the right operator $R_\alpha$ is a bounded, linear operator on $\mathcal{B}$ with $\lVert R_\alpha \rVert = \frac{1}{1-\alpha}$. It also follows that $(1-\alpha)R_\alpha$ is a probability kernel.

<details>
<summary>Proof</summary>

Using geometric series

$$
  R_\alpha (x, S) \sum_{n=0}^\infty \alpha^n P^n (x, S) = \sum_{n=0}^\infty \alpha^n = \frac{1}{1-\alpha}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $\alpha\in (0,1)$, then $(1-\alpha)R_\alpha (x, \cdot)$ is the conditional distribution of $X_N$ given $X_0 = x\in S$, where $N$ is independent of $\mathbf{X}$ and has the geometric distribution on $\mathbb{N}$ with parameter $1-\alpha$.

<details>
<summary>Proof</summary>

Conditioning on $N$ gives

$$
  \mathbb{P}(X_N \in A | X_0 = x) = \sum_{n=0}^\infty \mathbb{P}(N=n)\mathbb{P}(X_N \in A | N = n, X_0 =x)
$$

By the substitution rule and the assumption of independence

$$
\begin{align*}
  \mathbb{P}(X_N \in A | N = n, X_0 = x) &= \mathbb{P}(X_n \in A | N=n, X_0 = x) \\
  &= \mathbb{P}(X_n \in A | X_0 = x) = P^n(x,A)
\end{align*}
$$

Since $N$ has the geometric distribution on $\mathbb{N}$ with parameter $1-\alpha$ it follows that $P(N = n) = (1-\alpha)\alpha^n$ for $n\in\mathbb{N}$. Substituting gives

$$
  \mathbb{P}(X_N \in A | X_0 = x) = \sum_{n=0}^\infty (1-\alpha)\alpha^n P^n (x, A) = (1-\alpha) R_\alpha (x, A)
$$
</details>
</MathBox>

The kernel $(1-\alpha)R_\alpha$ is a transition probability kernel corresponding to the random time $N$ rather than the deterministic time $n\in\mathbb{N}$.

For positive measures $\mu$ on $\mathcal{S}$, the left potential operator is defined as

$$
  \mu R_\alpha (A) = \sum_{n=0}^\infty \alpha^n \mu P^n (A) = \sum_{n=0}^\infty \alpha^n \int_S \mu(\mathrm{d}x)P^n (x, A),\; A\in\mathcal{S} 
$$

If $X_0$ has distribution $\mu$, then $\mu P^n$ is the distribution of $X_n$ for $n\in\mathbb{N}$. In this case, $(1-\alpha)\mu R_\alpha$ is the distribution of $X_N$, where $N$ is independent of $\mathbf{X}$ and is geometrically distributed on $\mathbb{N}$ with parameter $1 - \alpha$.

<MathBox title='' boxType='proposition'>
The potential kernels $\mathbb{R} = \{ R_\alpha \}_{\alpha\in (0, 1)}$ completely determine the transition kernels $\mathbf{P} = \{P_n\}_{n\in\mathbb{N}}$.

<details>
<summary>Proof</summary>

For $x\in S$ and $A\in\mathcal{A}$, the function $\alpha\mapsto R_\alpha(x, A)$ is a power series in $\alpha$ with coefficients $n\mapsto P^n(x,A)$. In combinatorial terms, $\alpha\mapsto R_\alpha(x, A)$ is the ordinary generating function of the sequence $n\mapsto P^n (x, A)$. This power series has radius of convergence at least $1$, extending the domain to $\alpha\in (-1, 1)$. Thus, we can recover the transition kernels by derivating $R_\alpha$ and evaluating at $\alpha = 0$

$$
  P^n (x, A) = \frac{1}{N!}\left. \frac{\mathrm{d}^n}{\mathrm{d}\alpha^n} R_\alpha (x, A) \right|_{\alpha = 0}
$$
</details>
</MathBox>

The kernels $\mathbf{R} = \{ R_\alpha \}_{\alpha\in (0,1)}$, along with the initial distribution, completely determine the finite dimensional distributions of the discrete-time Markov process $\mathbf{X}$.

<MathBox title='' boxType='proposition'>
If $\alpha,\beta\in (0, 1]$ and $k\in\mathbb{N}$, then (as kernels)

1. $P^k R_\alpha = R_\alpha P^k = \sum_{n=0}^\infty \alpha^n P^{n+k}$
2. $R_\alpha R_\beta = R_\beta R_\alpha = \sum_{m=0}^\infty\sum_{n=0}^\infty \alpha^m \beta^n P^{m+n}$
3. $I + \alpha R_\alpha P = I + \alpha P R_\alpha = R_\alpha$

If $\alpha\leq\beta$ then (as kernels)

4. $\beta R_\beta = \alpha R_\alpha + (\beta - \alpha) R_\alpha R_\beta$

If $\alpha\in (0,1)$, then as operator as on $\mathcal{B}$

5. $R_\alpha = (I - \alpha P)^{-1}$
6. $P = \frac{1}{\alpha}(1 - R_\alpha^{-1})$
 
<details>
<summary>Proof</summary>

Suppose that $f\in\mathcal{B}$ is nonnegative. Since the kernels are nonnegative we can interchange sums with kernel operations.

1. Evaluating $R_\alpha P^k$ directly
$$
  R_\alpha P^k f = \sum_{n=0}^\infty \alpha^n P^n P^k f = \sum_{n=0}^\infty \alpha^n P^{n+k} f
$$

The other direction requires an interchange

$$
  P^k R_\alpha f = P^k \sum_{n=0}^\infty \alpha^n P^n f = \sum_{n=0}^\infty \alpha^n P^k P^n f = \sum_{n=0}^\infty \alpha^n P^{n+k}f
$$

2. Only the first direction is shown as the other is similar.
$$
\begin{align*}
  R_\alpha R_\beta &= \sum_{m=0}^\infty \alpha^m P^m R_\beta f \\
  &= \sum_{m=0}^\infty \alpha^m P^m \left( \sum_{n=0}^\infty \beta^n P^n f \right) \\
  &= \sum_{m=0}^\infty \sum_{n=0}^\infty \alpha^m \beta^n P^m P^n f \\
  &= \sum_{m=0}^\infty \sum_{n=0}^\infty \alpha^m \beta^n P^{m+n} f
\end{align*}
$$

3. From the 1st identity
$$
\begin{align*}
  (I + \alpha R_\alpha P)f &= (I + \alpha RP_\alpha)f \\
  &= f + \sum_{n=0}^\infty \alpha^{n + 1} P^{n+1} f \\
  &= \sum_{n=0}^\infty \alpha^n P^n f = R_\alpha f
\end{align*}
$$

4. Assume $\alpha < \beta$ as the case $\alpha = \beta$ is trivial. From the 2nd identity

$$
  R_\alpha R_\beta f = \sum_{j=0}^\infty \sum_{k=0} \alpha^j \beta^k P^{j+k} f
$$

Changing the sum variables to $n = j + k$ and $j$

$$
\begin{align*}
  R_\alpha R_\beta f = \sum_{n=0}^\infty \sum_{j=0}^n \alpha^j \beta^{n-j} P^n f \\
  &= \sum_{n=0}^\infty \sum_{j=0}^n \left( \frac{\alpha}{\beta} \right)^j \beta^n P^n f \\
  &= \sum_{n=0}^\infty \frac{1 - \left( \frac{\alpha}{\beta} \right)^{n+1}}{1 - \frac{\alpha}{\beta}} \beta^n P^n f \\
  &= \frac{1}{\beta - \alpha}  \beta \left( \sum_{n=0}^\infty \beta^n P^n f \right) - \alpha \left( \sum_{n=0}^\infty \alpha^n P^n f \right) \\
  &= \frac{1}{\beta - \alpha} (\beta R_\beta f -\alpha R_\alpha f)
\end{align*}
$$

Note that $R_\alpha f$ is finite since $\alpha < 1$.

5. Since the operators are bounded, we can subtract. From the 3rd property

$$
\begin{gather*}
  I + \alpha R_\alpha  P = R_\alpha \iff R_\alpha (I - \alpha P) = I \\
  I + \alpha P R_\alpha = R_\alpha \iff (I - \alpha) R_\alpha = I
\end{gather*}
$$

6. This follows from the 5th property.
</details>
</MathBox>

### Continuous-time

<MathBox title='Continuous-time potential kernel' boxType='proposition'>
For $\alpha\in [0, \infty)$ the $\alpha$-potential kernel $U_\alpha$ of $\mathbf{X}$ is defined as

$$
  U_\alpha (x, A) := \int_0^\infty e^{-\alpha t} P_t (x, A)\,\mathrm{d}t,\; x\in S, A\in\mathcal{S}
$$

1. The special case $U = U_0$ is simply the potential kernel of $\mathbf{X}$.
2. $U(x, A)$ is the expected amount of time that $\mathbf{X}$ spends in $A$, starting at $x$
3. The family of kernels $\mathbf{U} = \{ U_\alpha \}_{\alpha\in (0,\infty)}$ is known as the reolvent of $\mathbf{X}$

<details>
<summary>Proof</summary>

Since $\mathbf{P} = \{ P_t \}_{t\in T}$ is a Feller semigroup of transition operators, the mapping $(t,x)\mapsto P_t (x, A)$ from $[0,\infty)\times S$ to $[0,1]$ is jointly measurable for $A\in\mathcal{S}$. Thus, $U_\alpha (x, A)$ makes sense for $x\in S$ and $A\in\mathcal{S}$, and $x\mapsto U_\alpha (x, A)$ from $S$ to $[0,\infty)$ is measurable for $A\in\mathcal{S}$. That $A\mapsto U_\alpha (x, A)$ is a measure on $\mathcal{S}$ follows from the usual interchange of sum and integral, via Fubini's theorem. Suppose that $\{ A_j \}_{j\in J}$ is a countable collection of disjoint sets in $\mathcal{S}$, and let $S = \bigcup_{j\in J} A_j$, then

$$
\begin{align*}
  U_\alpha (x, A) &= \int_0^\infty e^{-\alpha t} P_t (x, A)\mathrm{d}t = \int_0^\infty \left[ \sum_{j\in J} e^{-\alpha t}P_t (x, A_j) \right]\mathrm{d}t \\
  &= \sum_{j\in J} \int_0^\infty e^{-\alpha t} P_t (x, A_j)\mathrm{d}t = \sum_{j\in J} U_\alpha (x, A_j)
\end{align*}
$$

The interpretation of $U(x, A)$ is another interchange of integrals

$$
\begin{align*}
  U(x, A) &= \int_0^\infty P_t (x, A)\mathrm{d}t = \int_0^\infty \mathbb{E}[\mathbf{1}(X_t \in A) \mid X_0 = x]\mathrm{d}t \\
  &= \mathbb{E}\left( \int_0^\infty \mathbf{1}(X_t \in A) \middle| X_0 = x \right)
\end{align*}
$$

The integral inside the expectation is the Lebesgue measure of $\{ t\in [0,\infty) : X_t\in A \}$
</details>
</MathBox>

The potential kernel $U_\alpha$ defines two operators, operating on the right on functions, and left on positive measures. For measurable functions $f:S\to\mathbb{R}$, the right potential operator is defined as

$$
\begin{align*}
  U_\alpha f(x) = \int_S U_\alpha (x, \mathrm{d}y)f(y) = \int_0^\infty e^{-\alpha t} P_t f(x)\mathrm{d}t \\
  &= \int_0^\infty e^{-\alpha t} \int_S P_t (x,\mathrm{d}y) f(y) = \int_0^\infty e^{-\alpha t}\mathbb{E}[f(X_t)\mid X_0]\mathrm{d}t,\; x\in S
\end{align*}
$$

<MathBox title='' boxType='proposition'>
If $\alpha > 0$, then $U_\alpha (x, S) = \frac{1}{\alpha}$ for all $x\in S$. It follows that the right potential operator $U_\alpha$ is a bounded, linear operator on $\mathcal{B}$ with $\lVert U_\alpha \rVert = \frac{1}{\alpha}$. It also follows that $\alpha R_\alpha$ is a probability kernel.

<details>
<summary>Proof</summary>

$$
  U_\alpha (x, S) \int_{n=0}^\infty \alpha^n P_t (x, S)\,\mathrm{d}t = \int_{n=0}^\infty e^{-\alpha t} \mathrm{d}t = \frac{1}{\alpha}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $\alpha > 0$, then $\alpha U_\alpha (x, \cdot)$ is the conditional distribution of $X_\tau$ where $\tau$ is independent of $\mathbf{X}$ and has the exponential distribution on $[0,\infty)$ with parameter $\alpha$.

<details>
<summary>Proof</summary>

Since $\tau$ is exponentially distributed it has the probability density function $f(t) = \alpha e^{-\alpha t}$ for $t\in[0,\infty)$. Conditioning on $\tau$ gives

$$
  \mathbb{P}(X_\tau \in A \mid X_0 = x) = \int_0^\infty \alpha e^{-\alpha t}\mathbb{P}(X_\tau \in A \mid \tau = t, X_0 = x) = P_t (x, A)
$$

By the substitution rule and the assumption of independence

$$
\begin{align*}
  \mathbb{P}(X_\tau \in A \mid \tau = t, X_0 = x) &= \mathbb{P}(X_t \in A \mid \tau = t, X_0 = x) \\
  &= \mathbb{P}(X_t \in A \mid X_0 = x) = P_t (x, A)
\end{align*}
$$

Substituting gives

$$
  \mathbb{P}(X_\tau \in A \mid X_0 = x) = \int_0^\infty \alpha e^{-\alpha t} P_t (x, A)\mathrm{d}t = \alpha U_\alpha (x, A)
$$
</details>
</MathBox>

The kernel $\alpha R_\alpha$ is a transition probability kernel corresponding to the random time $N$ rather than the deterministic time $n\in\mathbb{N}$.

For positive measures $\mu$ on $\mathcal{S}$, the left potential operator is defined as

$$
\begin{align*}
  \mu U_\alpha &= \int_S \mu(\mathrm{d}x) U_\alpha (x, A) = \int_0^\infty e^{-\alpha t} \mu P_t f(x)\mathrm{d}t \\
  &= \int_0^\infty e^{-\alpha t} \left[ \int_S \mu(\mathrm{d}x) P_t (x, A)\right] \mathrm{d}t = \int_0^\infty e^{-\alpha t}\left[ \int_S \mu(\mathrm{d}x)\mathbb{P}(X_t \in A) \right]\mathrm{d}t,\; A\in\mathcal{S}
\end{align*}
$$

In particular, suppose that $\alpha > 0$ and that $X_0$ has distribution $\mu$. Then $\mu P_t$ is the distribution of $X_t$ for $t\in[0,\infty)$ so that $\alpha \mu U_\alpha$ is the distribution of $X_\tau$, where $\tau$ is independent of $\mathbf{X}$ and is exponentially distributed on $[0,\infty)$ with parameter $\alpha$.

<MathBox title='' boxType='proposition'>
The resolvent $\mathbf{U} = \{U_\alpha\}_{\alpha\in (0,\infty)}$ completely determines the family of transition kernels $\mathbf{P} = \{P_t\}_{t\in (0,\infty)}$

<details>
<summary>Proof</summary>

Note that the function $\alpha\mapsto U_\alpha (x, A)$ on $(0,\infty)$ is the Laplace transform of the function $t\mapsto P_t (x, A)$ on $[0,\infty)$. The Laplace transform of a function determines the function completely.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\alpha, \beta, t \in [0,\infty)$. Then as kernels

1. $P_t U_\alpha = U_\alpha P_t = \int_0^\infty e^{-\alpha s} P_{s+t}\mathrm{d}s$
2. $U_\alpha U_\beta = U_\beta U_\alpha = \int_0^\infty \int_0^\infty e^{-\alpha s} e^{-\beta t} P_{s+t}\mathrm{d}s\,\mathrm{d}t$

If $\alpha\leq\beta$ then as kernels

3. $U_\alpha = U_\beta + (\beta -\alpha) U_\alpha U_\beta$

4. If $\alpha\in (0,\infty)$ and $f\in\mathcal{C}_0$ then $U_\alpha f \in\mathcal{U}_0$.
5. If $f\in\mathcal{C}_0$ then $\alpha U_\alpha f \xrightarrow{\alpha\to\infty} f$

<details>
<summary>Proof</summary>

Suppose that $f\in\mathcal{B}$ is nonnegative. Since the integrands are nonnegative we can interchange integrals.

1. Evaluating $U_\alpha P_t$ directly
$$
  U_\alpha P_t f = \int_0^\infty e^{-\alpha s}P_s P_t f \,\mathrm{d}s = \int_0^\infty e^{-\alpha s} P_{s+t}f\,\mathrm{d}s
$$

The 1st identity involves an interchange

$$
  P_t U_\alpha f = P_t \int_0^\infty e^{-\alpha s} P_s f\,\mathrm{d}s = \int_0^\infty e^{-\alpha s}P_t P_s f\,\mathrm{d}s = \int_0^\infty e^{-\alpha s} P_{s+t} f\,\mathrm{d}s
$$

2. Only the first direction is shown as the other is similar

$$
\begin{align*}
  U_\alpha U_\beta f &= \int_0^\infty e^{-\alpha s} P_s U_\beta f\,\mathrm{d}s = \int_0^\infty e^{-\alpha s} P_s \int_0^\infty e^{-\beta t} P_t f\,\mathrm{d}t \\
  &= \int_0^\infty e^{-\alpha s} \int_0^\infty e^{-\beta t}P_s P_t f\,\mathrm{d}s\,\mathrm{d}t = \int_0^\infty \int_0^\infty e^{-\alpha s} e^{-\beta t} P_{s+t} f\,\mathrm{d}s\,\mathrm{d}t
\end{align*}
$$

3. Assume $\alpha < \beta$ as the case $\alpha = \beta$ is trivial. From the 2nd identity

$$
  U_\alpha U_\beta f = \int_0^\infty \int_0^\infty e^{-\alpha s} e^{-\beta t} P_{s+t} f\,\mathrm{d}s\,\mathrm{d}t
$$

The transformation $u = s + t, v = s$ maps $[0,\infty)^2$ one-to-one onto $\{(u,v)\in[0,\infty)^2 : u\geq v\}$. The inverse transformation is $s = v, t = u - v$ with Jacobian $-1$. This gives

$$
\begin{align*}
  U_\alpha U_\beta f &= int_0^\infty \int_0^u e^{-\alpha v} e^{-\beta(u - v)} P_u f\,\mathrm{d}v\,\mathrm{d}u \\
  &= \int_0^\infty \left(\int_0^u e^{(\beta - \alpha)v}\,\mathrm{d}v \right) e^{-\beta u} P_u f\,\mathrm{d}u \\
  &= \frac{1}{\beta - \alpha}\int_0^\infty [e^{(\beta - \alpha)u}] e^{-\beta u} P_u f,\mathrm{d}u \\
  &= \frac{1}{\beta - \alpha}\left(\int_0^\infty e^{-\alpha u} P_u f\,\mathrm{d}u -\int_0^\infty e^{-\beta u} P_u f\,\mathrm{d}u \right) \\
  &= \frac{1}{\beta - \alpha}(U_\alpha f - U_\beta f)
\end{align*}
$$

Note that $U_\beta f$ is finite since $\beta > 0$.

4. Suppose that $f\in\mathcal{C}_0$ and that $(x_i)_{i\in\mathbb{N}}$ is a sequence in $S$. Then $P_t f\in \mathcal{C}_0$ for $t\in[0,\infty)$. Hence if $x_n \xrightarrow{n\to\infty} x \in S$ then $e^{-\alpha t}P_t f(x_n) \xrightarrow{n\to\infty} e^{-\alpha t}P_t f(x)$ for each $t\in[0,\infty)$. By the dominated convergence theorem

$$
  U_\alpha f (x_n) = \int_0^\infty e^{-\alpha t}P_t f(x_n)\,\mathrm{d}t \xrightarrow{n\to\infty} \int_0^\infty e^{-\alpha t} P_t f(x)\,\mathrm{d}t = U_\alpha f(x)
$$

Hence $U_\alpha$ is continuous. Next suppose that $x_n \xrightarrow{n\to\infty} \infty$. This means that for every compact $C\subseteq S$, there exists $m\in\mathbb{N}_+$ such that $x_n \not\in C$ for $n > m$. Then $e^{-\alpha t} P_t f(x_n) \xrightarrow{n\to\infty} 0$ for each $t\in[0,\infty)$. Again by the dominated convergence theorem

$$
  U_\alpha f(x_n) = \int_0^\infty e^{-\alpha t} P_t f(x_n)\,\mathrm{d}t \xrightarrow{n\to\infty} 0
$$

Hence $U_\alpha f \in \mathcal{C}_0$.

5. Convergence is with respect to the supremum norm on $\mathcal{C}_0$. Suppose that $f\in\mathcal{C}_0$. Note first that with change of variables $s = \alpha t$

$$
  \alpha U_\alpha f = \int_0^\infty \alpha e^{-\alpha t} P_t f\,\mathrm{d}t = \int_0^\infty e^{-s} P_{s/\alpha}f\,\mathrm{d}s
$$

and hence

$$
\begin{align*}
  |\alpha U_\alpha f - f| &= \left| \int_0^\infty e^{-s}(P_{s/\alpha} f - f)\,\mathrm{d}s \right| \\
  \leq \int_0^\infty e^{-s} |P_{s/\alpha f - f}\,\mathrm{d}s \\
  \leq \int_0^\infty e^{-s} \lVert P_{s/\alpha} f - f \rVert\,\mathrm{d}s
\end{align*}
$$

It follows that

$$
  \lVert \alpha U_\alpha f - f \rVert \leq \int_0^\infty e^{-s} \lVert P_{s/\alpha} f - f \rVert\mathrm{d}s
$$

However, $\lVert P_{s\alpha} f - f \rVert \xrightarrow{\alpha\to\infty} 0$ and hence by the dominated convergence theorem

$$
  \int_0^\infty e^{-s}\lVert P_{s/\alpha} f - f \rVert\,\mathrm{d}s \xrightarrow{\alpha\to\infty} 0
$$
</details>
</MathBox>

### Infinitesimal generator

<MathBox title='Infinitesimal generator' boxType='definition'>
The infinitesimal generator of the Markov process $\mathbf{X}$ is the operator $G:\mathcal{D}\to\mathcal{C}_0$ defined by

$$
  Gf := \lim_{t\downarrow 0}\frac{P_t f - f}{t}
$$

on the domain $\mathcal{D}\subseteq\mathcal{C}_0$ for which the limit exists. The limit is with respect to the supremum norm such that $f\in\mathcal{D}$ and $Gf = g$ implies $f,g\in\mathcal{C}_0$ and

$$
\left\lVert \frac{P_t f - f}{t} g \right\rVert = \sup\left\{ \left| \frac{P_t f(x) - f(x)}{t} - g(x) \right|: x\in S \right\} \xrightarrow{t\downarrow 0} 0
$$

In particular

$$
  Gf(x) = \lim_{t\downarrow 0} \frac{P_t f(x) - f(x)}{t} = \lim_{t\downarrow 0}\frac{\mathbb{E}[f(X_t)\midX_0 = x] - f(x)}{t},\; s\in S
$$
</MathBox>

<MathBox title='' boxType='proposition'>
The domain $\mathcal{D}$ is a subspace of $\mathcal{C}_0$ and the generator $G$ is a linear operator on $\mathcal{D}$ satisfying

1. If $f\in\mathcal{D}$ and $c\in\mathcal{R}$ then $cf\in\mathcal{D}$ and $G(cf) = cGf$.
2. If $f,g\in\mathcal{D}$ then $f+g\in\mathcal{D}$ and $G(f+g) = Gf + Gg$

<details>
<summary>Proof</summary>

These properties follows from the linearity of $P_t$ for $t\in[0,\infty)$ and basic results on convergence

1. 
$$
  \frac{P_t(cf) - (cf)}{t} = c\frac{P_t f - f}{t} \xrightarrow{t\downarrow 0} cGf
$$

2.
$$
  \frac{P_t (f+g) - (f+g){t} = \frac{P_t f - f}{t} + \frac{P_t g - g}{t} \xrightarrow{t\downarrow 0} Gf + Gg
$$
</details>
</MathBox>

Note that $G$ is the (right) derivative at $0$ of the function $t\mapsto P_t f$. Because of the semigroup property, this differentiability property at $0$ implies differentiability at arbitrary $t\in[0,\infty)$.

<MathBox title='' boxType='proposition'>
If $f\in\mathcal{D}$ and $t\in[0,\infty)$, then $P_t f\in\mathcal{D}$ and the following derivative rules hold with respect to the supremum norm

1. Kolmogorov forward equation: $P'_t f = P_t Gf$
2. Kolmogorov backward equation: $P'_t f = GP_t f$

<details>
<summary>Proof</summary>

1. By assumption

$$
  \lim_{h\downarrow 0} \frac{P_h f - f}{h} = Gf
$$

Since $P_t$ is a bounded, linear operator on $\mathcal{C}_0$, it preserves limits, giving

$$
  \lim_{h\downarrow 0}\frac{P_t P_h f - P_t}{h} = \lim_{h\downarrow 0} \frac{P_{t+h} f - P_t f}{h} = P_t G f
$$

This proves the Kolmogorov forward equation for the derivative from the right. Since $t\mapsto P_t f$ is continuous, the result is also true for the two-sided derivative.

2. From the Kolmogorov forward equation

$$
  \lim_{h\to 0}\frac{P_t P_h f - P_t}{h} = \lim_{h\to 0} \frac{P_{t+h} f - P_t f}{h} = P_t G f
$$

By definition, this means that $P_t f \in\mathcal{D}$ and $GP_t f = P_t G f = P'_t f$.
</details>
</MathBox>

Infinitesimal generators allows us to construct a Markov process with desired properties, by which the transition operators $\mathbf{P} = \{P_t\}_{t\geq 0}$ are obtained from the initial value problem

$$
  P'_t = GP_t,\quad P_0 = I
$$

<MathBox title='' boxType='proposition'>
Suppose that $\alpha\in (0,\infty)$

1. If $f\in\mathcal{D}$ then $Gf\in\mathcal{C}_0$ and $f + U_\alpha G f = \alpha U_\alpha f$
2. If $f\in\mathcal{C}_0$ then $U_\alpha f \in\mathcal{D}$ and $f + GU_\alpha f = \alpha U_\alpha f$
3. $U_\alpha = (\alpha I - G)^{-1}:\mathcal{C}_0\to\mathcal{D}$
4. $G = \alpha I - U_\alpha^{-1}:\mathcal{D}\to\mathcal{C}_0$

<details>
<summary>Proof</summary>

1. By definition, if $f\in\mathcal{D}$ then $Gf\in\mathcal{C}_0$. Hence using the Kolmogorov equations and integrating by parts

$$
\begin{align*}
  f + U_\alpha G f &= f + \int_0^\infty e^{-\alpha t} GP_t f\,\mathrm{d}t = f + \int_0^\infty e^{-\alpha t} P'_t f\,\mathrm{d}t \\
  &= \left. f - e^{-\alpha t} P_t \right_0^\infty + \alpha\int_0^\infty + \alpha\int_0^\infty e^{-\alpha t}P_t f \,\mathrm{d}t
\end{align*}
$$

Note that $e^{-\alpha t} P_t f \xrightarrow{t\to\infty} 0$ while $P_0 f = f$. The last term is $\alpha U_\alpha f$.

2. From the 1st identity and the substitution $u = s + t$

$$
\begin{align*}
  P_t U_\alpha f &= \int_0^\infty e^{-\alpha s} P_{s+t}f\,\mathrm{d}s \\
  &= \int_t^\infty e^{-\alpha (u - t)} P_u f\,\mathrm{d}u \\
  &= e^{-\alpha t}\int_t^\infty e^{-\alpha u} P_u f\,\mathrm{d}u
\end{align*}
$$

Hence

$$
  \frac{P_t U_\alpha f - U_\alpha f}{t} = \frac{1}{t}\left[ e^{-\alpha t} \int_t^\infty e^{-\alpha u} P_u f\,\mathrm{d}u - U_\alpha f \right]
$$

Adding and substracting $e^{\alpha u} U_\alpha f$ and combining integrals gives

$$
  \frac{P_t U_\alpha f - U_\alpha f}{t} = \frac{1}{t}\left[ e^{\alpha t} \int_t^\infty e^{-\alpha u} P_u f\,\mathrm{d}u - e^{\alpha t} \int_0^\infty e^{-\alpha u} P_u f\,\mathrm{d}u \right] + \frac{e^{\alpha t} - 1}{t} U_\alpha f \\
  &= -e^{\alpha t}\frac{1}{t} \int_0^t e^{-\alpha s} P_s f\,\mathrm{d}s + \frac{e^{\alpha t} - 1}{t} U_\alpha f
$$

Since $s\mapsto P_s f$ is continuous, the first term converges to $-f$, and the second term converges to $\alpha U_\alpha f$ as $t\downarrow 0$.

3. From the 1st identity we have $\alpha U_\alpha - U_\alpha G = I \iff U_\alpha (\alpha I - G) = I$, and from the 2nd identity we have $\alpha U_\alpha - GU_\alpha = I \iff (\alpha I - G)U_\alpha = I$. 
4. This follows from the 3rd identity.
</details>
</MathBox>

## Examples and applications

### Recurrence relations and differential equations

Markov processes can be viewed as stochastic counterparts of deterministic recurrence relations (discrete time) and differential equations (continuous time)

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{n\in\mathbb{N}}$ is a stochastic process with state space $(S,\mathcal{S})$ satisfying the recurrence relation

$$
  X_{n+1} = g(X_n),\; n\in\mathbb{N}
$$

where $g:S\to S$ is measurable. Then $\mathbf{X}$ is a homogenous Markov process with one-step transition operator $P$ given by $Pf = g\circ g$ for a measurable function $f:S\to\mathbb{R}$

<details>
<summary>Proof</summary>

Clearly $\mathbf{X}$ is determined by the initial state, and in fact $X_n = g^n (X_0)$ for $n\in\mathbb{N}$ where $g^n$ is the $n$-fold composition power of $g$. Therefore, the only possible source of randomness is in the initial state. The Markov and time homogenous properties simply follow from the trivial fact that $g^{m+n}(X_0) = g^n[g^m(X_0)]$ so that $X_{m+n} = g^n(X_m)$. That is, the state at time $m+n$ is completely determined by the state at time $m$ (regardless of the previous states) and the time increment $n$. In particular, $Pf(x) = \mathbb{E}[g(X_1)\mid X_0 = x] = f[g(x)]$ for measurable $f:S\to\mathbb{R}$ and $x\in S$. Note that for $n\in\mathbb{N}$, the $n$-step transition operator is given by $P^n f = f\circ g^n$.
</details>
</MathBox>

<MathBox title='Recurrence relation' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{t\geq 0}$ is a stochastic process with state space $(\mathbb{R},\mathcal{R})$ satisfying the first-order differential equation

$$
  \frac{\mathrm{d}}{\mathrm{d}t}X_t = g(X_t)
$$

where $g:\mathbb{R}\to\mathbb{R}$ is Lipschitz continuous. Then $\mathbf{X}$ is a Feller Markov process.

<details>
<summary>Proof</summary>

Lipschitz continuity means that there exists a constant $k\in(0,\infty)$ such that $|g(y) - g(x)|\leq k|x-y|$ for $x,y\in\mathbb{R}$. This is a standard condition on $g$ that guarantees the existence of a solution to the differential equation on $[0,\infty)$. Therefore, the only source of randomness in the process comes from the initial value $X_0$. Let t\mapsto X_t(x) denote the unique solution with $X_0(x) = x$ for $x\in\mathbb{R}$. The Markov and time homogeneous properties follow from the fact that $X_{t+s}(x) = X_t(X_s(x))$ for $x,t\in[0,\infty)$ and $x\in S$. That is, the state at time $t+s$ depends only on the state at time $s$ and the time increment $t$. The Feller properties follow from the continuity of $t\mapsto X_t(x)$ and the continuity of $x\mapsto X_t(x)$. The latter is the continuous dependence on the initial value, guaranteed by the assumption on $g$. Note that the transition operator is given by $P_t f(x) = f[X_t (x)]$ for a measurable function $f:S\to\mathbb{R}$ and $x\in S$.
</details>
</MathBox>

The deterministic process $\mathrm{d}X_t = g(X_t)\mathrm{d}t$ can be turned into a diffusion processs, with Markov property, by adding a stochastic term related to a Wiener process (Brownian motion).


# Processes with independent, stationary increments

<MathBox title='Independent and stationary increments' boxType='definition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process adapted to $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$. Then for all $s,t\in T$ with $s\leq t$, the process $\mathbf{X}$ is said to have
1. *Independent increments* if $X_t - X_s$ is independent of $\mathcal{F}_s$
2. *Stationary increments* if $X_t - X_s$ has the same distribution as $X_{t-s} - X_0$

Processes with independent and stationary increments are random walk processes. In continuous time, such processes are known as Lévy processes, which also have a third property

3. *Continuity in probability*: for any $\epsilon > 0$ and $t\geq 0$ then $\lim_{h\to 0} \mathbb{P}(|X_{t+h} - X_t|>\epsilon) = 0$
</MathBox>

Stationary increments means that the probability distribution of any increment $X_t - X_s$ depends only the length $t - s$ of the time interval. Several stochastic processes are characterized by specific distributions of their stationary increments
- Wiener process: $X_t - X_s$ has a normal distribution with $\mathbb{E}(X_t - X_s) = 0$ and $\mathrm{Var}(X_t - X_s) = t - s$
- Poisson process:  $X_t - X_s$ has a poisson distribution with $\mathbb{E}(X_t - X_s) = \gamma(t - s)$ where $\gamma > 0$ is the intensity of the process.
- Cauchy process: $X_t - X_s$ has a Cauchy distribution with density $f(x, t) = \frac{1}{\pi}\frac{t}{x^2 + t^2}$

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process with independent, stationary increments, and let $Q$ denote the distribution of $X_t - X_0$. Then

$$
  Q_s * Q_t = Q_{s+t},\; s,t\in T
$$

<details>
<summary>Proof</summary>

Note that $Q_s$ is the distribution of $X_s - X_0$, and by the stationary property, $Q_t$ is the distribution of $X_{s+t} - X_s$. By the independence property, $X_s - X_0$ and $X_{s+t} - X_s$ are independent. Hence $Q_s * Q_t$ is the distribution of $[X_s - X_0] + [X_{s+t} - X_{s}] = X_{s+t} - X_0$. By definition, this variable has distribution $Q_{s+t}$.
</details>
</MathBox>

The collection of increment distributions $\mathbf{Q} = \{Q_t\}_{t\in T}$ forms a semi-group with convolution as the operator.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a Lévy process, and let

$$
  m(t) = \mathbb{E}(X_t) \quad v(t) = \mathrm{var}(X_t)
$$

1. If $\mu_0 = \mathbb{E}(X_0) \in\mathbb{R}$ and $\mu_1 = \mathbb{E}(X_1)\in\mathbb{R}$ then $m(t) = \mu_0 + (\mu_1 + \mu_0)t$
2. If in addition $\sigma_0^2 = \mathrm{var}(X_0)\in (0,\infty)$ and $\sigma_1^2 = \mathrm{var}(X_1)\in (0, \infty)$ then $v(t) = \sigma_0^2 + (\sigma_1^2 + \sigma_0^2)t$

<details>
<summary>Proof</summary>

Let $m_0 (t) = \mathbb{E}(X_t - X_0) = m(t) - \mu_0$ and $v_0 (t) = \mathrm{var}(X_t - X_0) = v(t) - \sigma_0^2$ denote the mean and variance functions for the centered process $\{ X_t - X_0 \}_{t\in T}$. Let $s,t\in T$

1. From the additive property of expected value and the stationary property
$$
\begin{align*}
  m_0 (t + s) &= \mathbb{E}(X_{t+s} - X_0) \\
  &= \mathbb{E}[(X_{t+s} - X_s) + (X_s - X_0)] \\
  &= \mathbb{E}(X_{t+s} - X_s) + \mathbb{E}(X_s - X_0) \\
  &= m_0 (t) + m_0 (s)
\end{align*}
$$

1. From the additive property of variance for independent variables and the stationary property
$$
\begin{align*}
  v_0 (t + s) &= \mathrm{var}(X_{t+s} - X_0) \\
  &= \mathrm{var}[(X_{t+s} - X_s) + (X_s - X_0)] \\
  &= \mathrm{var}(X_{t+s} - X_s) + \mathrm{var}(X_s - X_0) \\
  &= v_0 (t) + v_0 (s)
\end{align*}
$$

This shows that $m_0$ and $v_0$ satisfy the Cauchy equation. By the Lévy properties there exists $a\in\mathbb{R}$ and $b^2\in(0,\infty)$ such that $m_0(t) = at$ and $v_0(t) = b^2 t$. Substituting $t=1$ gives $a = \mu_1 - \mu_0$ and $b^2 = \sigma_1^2 - \sigma_0^2$ producing the desired result.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
A discrete time process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ has independent increments if and only if there exists a sequence of independent, real-valued random variables $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ such that

$$
  X_n = \sum_{i=0}^n U_i
$$

In addition, $\mathbf{X}$ has stationary increments if and only if $(U_n)_{n\in\mathbb{N}}$ are identically distributed.

<details>
<summary>Proof</summary>

Suppose first that $\mathbf{U}$ is a sequence of independent, real-valued random variables, and define $X_n = \sum_{i=0}^n U_i$ for $n\in\mathbb{N}$. Note that $\mathcal{F}_n = \sigma\{X_i\}_{i=0}^n = \sigma\{U_i\}_{i=0}^n$. If $k, n\in\mathbb{N}$ with $k\leq n$, then $X_n - X_k = \sum_{i=k+1}^n U_i$ which is independent of $\mathcal{F}_k$ by the independence assumption on $\mathbf{U}$. Hence $\mathbf{X}$ has independent increments. Suppose in addition that  $(U_n)_{n\in\mathbb{N}}$ are identically distributed. Then the increment $X_n - X_k$ above has the same distribution as $\sum_{i=1}^{n-k} U_i = X_{n-k} - X_0$. Hence $\mathbf{X}$ has stationary increments.

Conversely, suppose that $\mathbf{X}$ has independent increments. Let $U_0 = X_0$ and $U_n = X_n - X_{n-1}$ for $n\in\mathbb{N}$ such that $X_n = \sum_{i=0}^n U_i$ and $\mathcal{F}_n = \sigma\{X_i\}_{i=0}^n = \sigma\{U_i\}_{i=0}^n$. Since $\mathbf{X}$ has independent increments, $U_n$ is indepedent of $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$ making $(U_n)_{n\in\mathbb{N}_+}$ mutually independent. If in addition, $\mathbf{X}$ has stationary increments, $U_n = X_n - X_{n-1}$ has the same distribution as $X_1 - X_0 = U_1$ for $n\in\mathbb{N}_+$. Hence $(U_n)_{n\in\mathbb{N}}$ are identically distributed. 
</details>
</MathBox>

## Relation to Markov processes

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process with independent, stationary increments, and let $Q$ denote the distribution of $X_t - X_0$. Then $\mathbf{X}$ is a time-homogeneous Markov process with transition operator

$$
  P_t f(x) = \int_S f(x+y)Q_t (\mathrm{d}y),\; f\in\mathcal{B}
$$

<details>
<summary>Proof</summary>

Since $X_{s+t} - X_{s}$ is independent of $\mathcal{F}_s$ it follows that

$$
  \mathbb{E}[f(X_{s+t})|\mathcal{F}_s] = \mathbb{E}[f(X_{s+t} - X_s + X_s)|\mathcal{F}_s] = \mathbb{E}[f(X_{s+t})|X_s]
$$

By the stationary property

$$
  \mathbb{E}[f(X_{s+t}\mid X_s = x)] = \int_S f(x+y)Q_t(\mathrm{d}y)\; x\in S
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that for positive $t\in T$ is a process with independent, the distribution $Q_t$ has probability density function $g_t$ with respect to the reference measure $\lambda$. Then the transition density is

$$
  p_t (x,y) = g_t (y - x),\; f\in\mathcal{B}
$$

By the property of $Q_t$, it follows that $g_s * g_t = g_{s+t}$.
</MathBox>

<MathBox title='Lévy processes are Feller Markov' boxType='proposition'>
If $Q_t \xrightarrow{t\downarrow 0} Q_0$ (Lévy property) then $\mathbf{X}$ is a Feller Markov process.
</MathBox>

### Random walk

<MathBox title='Markov random walk' boxType='definition'>
Suppose that $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ is a sequence of indepedent, real-valued random variables, with $(U_n)_{n\in\mathbb{N}}$ identically distributed with common distribution $Q$. Then the partial sum process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ associated with $\mathbf{U}$ is a time homogeneous Markov process with one-step transition kernel

$$
  P(x, A) = Q(A - x),\; x\in S, A\in\mathcal{S}
$$

More generally, the $n$-step transition kernel is 

$$
  P^n (x, A) = Q^{*n}(A - x)
$$

This Markov process is known as a random walk where $U_n$ represents the distance on the real in which the process moves at time $n$. If $Q$ has probability density function $g$ with respect to the reference measure $\lambda$, the one-step transition density is

$$
  p(x, y) = g(y - x),\; x,y\in S
$$
</MathBox>

<MathBox title='' boxType='proposition'>
For $t\in[0,\infty)$, let $g_t$ denoted the probability density function of the Poisson distribution with parameter $t$, i.e.

$$
  g_t (n) = e^{-1} \frac{t^n}{n!},\; n\in\mathbb{N}
$$

Let $p_t(x,y) = g_t (y - x)$ for $x,y\in\mathbb{N}$. Then $\{p_t\}_{t\geq 0}$ is the collection of transition densities for a Feller semigroup on $\mathbb{N}$.

<details>
<summary>Proof</summary>

We need to show that $\{g_t\}_{t\geq 0}$ satisfies the semi-group property, and that the continuity result holds. By the properties of the Poisson distribution, if $U, V$ are independent Poisson variables with parameters $s,t\in[0,\infty)$, respectively, then $U+V$ has a Poisson distribution with parameter $s + t$. Hence $g_s * g_t = g_{s+t}$. Moreover $g_t \xrightarrow{t\downarrow 0} g_0$. 
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
For $t\in[0,\infty)$, let $g_t$ denoted the probability density function of the normal distribution with mean $0$ and variance $t$, i.e.

$$
  g_t(z) = \frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2t}},\; z\in\mathbb{R}
$$

and let $p_t(x,y) = g_t (y - x)$ for $x,y\in\mathbb{R}$. Then $\{p_t\}_{t\geq 0}$ is the collection of transition densities for a Feller semigroup on $\mathbb{N}$.

<details>
<summary>Proof</summary>

We need to show that $\{g_t\}_{t\geq 0}$ satisfies the semi-group property, and that the continuity result holds. By the properties of the normal distribution, if $U, V$ are independent normal variables with mean $0$ and variances $s,t\in(0,\infty)$ respectively, then $U+V$ is normally distributed with mean $0$ and parameter $s + t$. Hence $g_s * g_t = g_{s+t}$. Moreover, the normal distribution with variance $t$ converges to a point mass at $0$ as $t\downarrow 0$. 
</details>
</MathBox>

# Martingale

A martingale is a stochastic process for which the conditional expectation of the next value is equal to the present value.

<MathBox title='Martingale' boxType='definition'>
A stochastic process $\mathbf{X}$ is a *martingale* with respect to a filtration $\mathscr{F}$ if $\mathbb{E}(X_t\mid \mathcal{F}_s) = X_s$ for all $s, t\in T$ with $s\leq t$.

If the equality in the martingale conditions does not hold, then for  for all $s, t\in T$ with $s\leq t$, the process $\mathbf{X}$ is (with respect to $\mathscr{F}$)
1. *sub-martingale* $\mathbb{E}(X_t\mid \mathcal{F}_s) \geq X_s$ for all $s, t\in T$ with $s\leq t$.
2. *super-martingale* $\mathbb{E}(X_t\mid \mathcal{F}_s) \leq X_s$ for all $s, t\in T$ with $s\leq t$.

If $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is discrete, then for all $n\in\mathbb{N}$ the process $\mathbf{X}$ is (with respect to $\mathscr{F}$)
1. martingale if and only if $\mathbb{E}(X_{n+1}\mid \mathcal{F}_n) = X_n$
2. sub-martingale if and only if $\mathbb{E}(X_{n+1}\mid \mathcal{F}_n) \geq X_n$
3. super-martingale if and only if $\mathbb{E}(X_{n+1}\mid \mathcal{F}_n) \leq X_n$

<details>
<summary>Details</summary>

To show the bicondationality in the discrete case, suppose that $k,n\in\mathbb{N}$ with $k< n$. Then $k\leq n - 1$ so $\mathcal{F}_k\subseteq\mathcal{F}_{n-1}$ and hence

$$
\begin{align*}
  \mathbb{E}(X_n \mid  \mathcal{F}_k) &= \mathbb{E}[\mathbb{E}(X_n \mid \mathcal{F}_{n-1})] \\
  &= \mathbb{E}(X_{n-1}\mid \mathcal{F}_k)
\end{align*}
$$
</details>
</MathBox>

In gambling terms, martingale, sub-martingale and super-martingale processes are abstractions of fair, favourable or unfair games (from the gambler's perspective).

<MathBox title='Martingales are preserved under coarser filtrations' boxType='proposition'>
Suppose that the stochastic process $\mathbf{X}$ is adapted to the filtration $\mathscr{F}$, and $\mathscr{F}\subseteq\mathscr{G}$, i.e. $\mathscr{G}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a (sub/super-)martingale relative to $\mathscr{G}$, then $\mathbf{X}$ is a (sub/super-)martingale process relative to $\mathscr{F}$.

In particular, if $\mathbf{X}$ is a (sub/super-)martingale relative to some filtration, then $\mathbf{X}$ is also a (sub/super-)martingale relative to the natural filtration $\mathcal{F}^0$

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s\leq t$. Note that $\mathbf{X}$ is adapted to $\mathscr{G}$, since $\mathbf{X}$ is adapted to $\mathscr{F}$ and $\mathscr{F}\subseteq\mathscr{G}$. Appyling the tower and monotonicity of conditional expected value we have that

1. If $\mathbf{X}$ is a martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t \mid  \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t \mid \mathcal{G}_s)|\mathcal{F}_s] \\
  &= \mathbb{E}(X_s\mid \mathcal{F_s}) = X_s
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t \mid  \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t \mid \mathcal{G}_s)|\mathcal{F}_s] \\
  &\geq \mathbb{E}(X_s\mid \mathcal{F_s}) = X_s
\end{align*}
$$

3. If $\mathbf{X}$ is a super-martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t \mid  \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t \mid \mathcal{G}_s)|\mathcal{F}_s] \\
  &\leq \mathbb{E}(X_s\mid \mathcal{F_s}) = X_s
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Linear properties of martingales' boxType='proposition'>
For the processes $\mathbf{X} = \{X_t \}_{t\in T}$ and $\mathbf{Y} = \{Y\}_{t\in T}$, let $\mathbf{X} + \mathbf{Y} = \{ X_t + Y_t \}_{t\in T}$.

1. If $\mathbf{X}$ and $\mathbf{Y}$ are (sub/super-)martingales with respect to $\mathscr{F}$ then $\mathbf{X}+\mathbf{Y}$ is a (sub/super-)martingale with respect to $\mathscr{F}$.

For the constant $c\in\mathbb{R}$, let $c\mathbf{X} = \{ cX_t \}_{t\in T}$.

2. If $\mathbf{X}$ is a martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is also a martingale with respect to $\mathscr{F}$.
3. If $\mathbf{X}$ is a sub-martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is a sub-martingale if $c > 0$, a super-martingale if $c < 0$, and a martingale if $c = 0$.
4. If $\mathbf{X}$ is a super-martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is a super-martingale if $c > 0$, a sub-martingale if $c < 0$, and a martingale if $c = 0$.

The linearity properties implies that the collection of martingales with respect to a fixed filtration $\mathscr{F}$ forms a vector space.

<details>
<summary>Proof</summary>

The additive property (1) follows from the additive property of conditional expectation. Note that $\mathbb{E}(|X_t + Y_t|)\leq\mathbb{E}(|X_t|) + \mathbb{E}(|Y_t|) < \infty$ for $t\in T$. For $s, t\in T$ with $s\leq t$ we have

$$
  \mathbb{E}(X_t + Y_t | \mathcal{F}_s) = \mathbb{E}(X_t\mid \mathcal{F}_s) + \mathbb{E}(X_t\mid \mathcal{F}_s)
$$

The scalar properties (2, 3, 4) follows from the scalar property of conditional expectation. Note that $\mathbb{E}(|cX_t|) = |c|\mathbb{E}(|X_t|)\leq\infty$. For $s, t\in T$ with $s\leq t$ we have

$$
  \mathbb{E}(cX_t | \mathcal{F}_s) = c\mathbb{E}(X_t \mid  \mathcal{F}_s)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that the process $\mathbf{X}$ takes values in an interval $S\subseteq\mathbb{R}$ and that $g:S\to\mathbb{R}$ is convex with $\mathbb{E}[|g(X_t)|]< \infty$ for $t\in T$. Then $g(\mathbf{X}) = \{g(X_t)\}_{t\in T}$ is a sub-martingale with respect to $\mathscr{F}$ if either

1. $\mathbf{X}$ is a martingale.
2. $\mathbf{X}$ is a sub-martingale and $g$ is also increasing.

Since $x \mapsto |x|^k$ is convex on $\mathbb{R}$ for $k\in[1,\infty)$, it follows that $|\mathbf{X}|^k = \{|X_t|^k \}_{t\in T}$ is a sub-martingale if $\mathbf{X}$ is a martingale and $\mathbb{E}\left(|X_t|^k \right)< \infty$ for $t\in T$. 

In particular, if $\mathbf{X}$ is a sub-martingale, then $\mathbf{X}^+ = \{X_t^+\}_{t\in T}$ is also a sub-martingale since $x\mapsto x^+ = \max\{x, 0\}$ is increasing and convex on $\mathbb{R}$.

<details>
<summary>Proof</summary>

Let $s,t\in T$ with $s\leq t$. Since $g$ is convex, it follows from Jensen's inequality that

$$
  \mathbb{E}[g(X_t)|\mathcal{F}_s] \geq g[\mathbb{E}(X_t\mid \mathcal{F}_s)]
$$

1. Since $\mathbf{X}$ is a martingale, then $\mathbb{E}(X_t \mid  \mathscr{F}_s) = X_s$ and substituting into the inequality above sbows that $g(\mathbf{X})$ is sub-martingale

$$
  \mathbb{E}[g(X_t)|\mathcal{F_s}] \geq g(X_s) 
$$

2. Since $\mathbf{X}$ is a sub-martingale, then $\mathbb{E}(X_t \mid \mathcal{F}_t) \geq X_s$. Since $g$ is also increasing, then $g[\mathbb{E}(X_t \mid \mathcal{F}_s)]\geq g(X_s)$. Substituting into the inequality above shows that $g(\mathbf{X})$ is a sub-martingale

$$
  \mathbb{E}[g(X_t)|\mathcal{F}_s] \geq g(X_s)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\geq 0}$ is a continuous-time process adapted to $\mathscr{F} = \{ \mathcal{F}_t\}_{t\geq 0}$. Let $\{ t_n\}_{n\in\mathbb{N}}\subset [0,\infty)$ be a strictly increasing sequence of time points with $t_0$ and define $Y_n = X_{t_n}$ nad $\mathcal{G}_n = \mathcal{F}_{t_n}$ for $n\in\mathbb{N}$. If $\mathbf{X}$ is a (sub/super)-martingale with respect to $\mathscr{F}$, then $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a (sub/super-martingale) with respect to $\mathscr{G}$.

<details>
<summary>Proof</summary>

Since $\{t_n\}_{n\in\mathbb{N}}$ is increasing, $\mathscr{G}$ is a discrete-time filtration. Next, $\mathbb{E}(|Y_n|) = \mathbb{E}(|X_{t_n}|) < \infty$. Finally, suppose that $\mathbf{X}$ is a martingale and $n, k\in \mathbb{N}$ with $k< n$. Then $t_k < t_n$ so

$$
  \mathbb{E}(Y_n \mid  \mathcal{G}_k) = \mathbb{E}(Y_n \mid  \mathcal{F}_{t_k}) = X_{t_k} = Y_k
$$

Hence $\mathbf{Y}$ is also a martingale. The proof is analogous for sub- and super-martingales, but with inequalities replacing the second equality above.
</details>
</MathBox>

## Martingale transform

<MathBox title='Martingale transform' boxType='proposition'>
Suppose that the discrete process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is adapted to the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ and that $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ is predictable relative to $\mathscr{F}$, i.e. $Y_n$ is measurable to $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$. The transform of $\mathbf{X}$ by $\mathbf{Y}$ is the process $\mathbf{Y}\cdot\mathbf{X}$ defined by

$$
  (\mathbf{Y}\cdot\mathbf{X})_n = X_0 + \sum_{k=1}^n Y_k (X_k - X_{k-1})
$$

1. If $\mathbf{X}$ is a martingale relative to $\mathscr{F}$ then $\mathbf{Y}\cdot\mathbf{X}$ is also a martingale relative to $\mathscr{F}$.
2. If $\mathbf{X}$ is sub-martingale relative to $\mathscr{F}$ and $\mathbf{Y}$ is non-negative, then $\mathbf{Y}\cdot\mathbf{X}$ is also a sub-martingale relative to $\mathscr{F}$.
3. If $\mathbf{X}$ is a super-martingale relative to $\mathscr{F}$ and $\mathbf{Y}$ is non-negative, then $\mathbf{Y}\cdot\mathbf{X}$ is also a super-martingale relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Suppose that $|Y_n|\leq c\in(0,\infty)$ for $n\in\mathbb{N}$, then

$$
\begin{align*}
  \mathbb{E}\left[|(\mathbf{Y}\cdot\mathbf{X})_n| \right] \leq \mathbb{E}(|X_0|) + c\sum_{k=1}^n \left[\mathbb{E}(|X_k|) + \mathbb{E}(|X_{k+1}|) \right] \\
  &< \infty
\end{align*}
$$

Since $(\mathbf{Y}\cdot\mathbf{X})_n$, $Y_{n+1}$ and $X$ are measurable with respect to $\mathcal{F}_n$ for $n\in\mathbb{N}$, it follows that

$$
\begin{align*}
  \mathbb{E}\left[ (\mathbf{Y}\cdot\mathbf{X})_{n+1} |\mathcal{F}_{n} \right] &= \mathbb{E}\left[(\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}(X_{n+1} - X_n)|\mathcal{F}_n \right] \\
  &= (\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}\mathbb{E}(X_{n+1} - X_n |\mathcal{F}_n) \\
  &= (\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}\left[\mathbb{E}(X_{n+1}\mid \mathcal{F}_n) - X_n \right]
\end{align*}
$$
</details>
</MathBox>

## Doob decomposition

<MathBox title='Doob decomposition theorem' boxType='theorem'>
Suppose that the discrete process $\mathbf{X} = \{ X_n\}_{n\in\mathbb{N}}$ is adapted to the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$. Then there is a unique decomposition $\mathbf{X} = \mathbf{Y} + \mathbf{Z}$ where $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$ and $\mathbf{Z} = \{Z_n\}_{n\in\mathbb{N}}$ is predictable relative to $\mathscr{F}$.

1. If $\mathbf{X}$ is a sub-martingale relative to $\mathscr{F}$, then $\mathbf{Z}$ is increasing.
2. If $\mathbf{X}$ is a super-martingale relative to $\mathscr{F}$, then $\mathbf{Z}$ is decreasing.

<details>
<summary>Proof</summary>

Define $Z_0 = 0$ and for $n\in\mathbb{N}_+$

$$
  Z_n = \sum_{k=1}^n \left[\mathbb{E}(X_k \mid  \mathcal{F}_{k-1} - X_{k-1} \right]
$$

Then $Z_n$ is measurable with respect to $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$, so $\mathbf{Z}$ is predictable with respect to $\mathscr{F}$. Define for $n\in\mathbb{N}_+$

$$
\begin{align*}
  Y_n &= X_n - Z_n \\
  &= X_n - \sum_{k=1}^n \left[\mathbb{E}(X_k \mid  \mathcal{F}_{k-1} - X_{k-1}) \right]
\end{align*}
$$

Then $\mathbb{E}(|Y_n|) < \infty$ and trivially $X_n = Y_n + Z_n$ for $n\in\mathbb{N}$. Next we show that $\mathbf{Y}$ is martingale

$$
  \mathbb{E}(Y_{n+1}\mid \mathcal{F}_n) - Z_{n+1} \\
  &= \mathbb{E}(X_{n+1}\mid \mathcal{F}_n) - \sum_{k=1}^{n+1} \left[\mathbb{E}(X_{n+1}\mid  \mathcal{F}_{k-1} - X_{k-1} \right] \\
  &= X_n - \sum_{k=1}^n \left[\mathbb{E}(X_k \mid \mathcal{F}_{k-1}) - X_{k-1} \right] = Y_n
$$

It remains to prove the uniqueness of the decomposition. Suppose that $\mathbf{X}$ has the decomposition in terms of $\mathbf{Y}$ and $\mathbf{Z}$ given in the theorem. Since $\mathbf{Y}$ is a martingale and $\mathbf{Z}$ is predictable

$$
\begin{align*}
  \mathbb{E}(X_n - X_{n-1} | \mathcal{F}_{n-1}) &= \mathbb{E}(Y_n \mid  \mathcal{F}_{n-1}) - \E(Y_{n-1} \mid  \mathcal{F}_{n-1}) \\ 
  &= Y_{n-1} - Y_{n-1} + Z_n - Z_{n-1} \\
  &= Z_n - Z_{n-1}, \quad n \in \mathbb{N}_+
\end{align*}
$$

Since $Z_0 = 0$, then $\mathbf{X}$ uniquely determines $\mathbf{Z}$. Finally, since $Y_n = X_n - Z_n$ for $n\in\mathbb{N}$, then $\mathbf{X}$ also uniquely determines $\mathbf{Z}$.

1. If $\mathbf{X}$ is a sub-martingale, then $\mathbb{E}(X_n\mid \mathcal{F}_{n-1}) - X_{n-1} \geq 0$ for $n\in\mathbb{N}_+$ so $\mathbf{Z}$ is increasing.
2. If $\mathbf{X}$ is a super-martingale, then $\mathbb{E}(X_n\mid \mathcal{F}_{n-1}) - X_{n-1} \leq 0$ for $n\in\mathbb{N}_+$ so $\mathbf{Z}$ is decreasing.
</details>
</MathBox>

## Stopping time

### Optional stopping

Doob's theorem states that stopping a martingale at random time $\tau$ does not alter the martingale property, provided the decision about when to stop is solely based on information available up to $\tau$. 

<MathBox title="Doob's optional stopping theorem" boxType='theorem'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\rho, \tau \in T$ are bounded stopping times relative to $\mathscr{F}$ with $\rho\leq\tau$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau | \mathcal{F}_p) = X_\rho$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau | \mathcal{F}_p) \geq X_\rho$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau | \mathcal{F}_p) \leq X_\rho$

<details>
<summary>Proof</summary> 

**Discrete time**
1. Suppose that $\tau\leq k\in\mathbb{N}_+$ and let $A\in\mathcal{F}_\tau$. For $j\in\mathbb{N}$ with $j\leq k$, it follows that $A\cap \{\tau = j\}\in\mathcal{F}_j$. Thus, by the martingale property

$$
  \mathbb{E}(X_k;A\cap\{\tau = j}) = \mathbb{E}(X_j;A\cap\{\tau = j}) = \mathbb{E}(X_\tau; A\cap\{\tau = j \})
$$

Since $k$ is an upper bound on $\tau$, the events $A\cap\{\tau = j \}$ partition $A$ for $j = 0, 1,\dots, k$. Summing the equation over $j$ gives $\mathbb{E}(X_k; A) = \mathbb{E}(X_\tau; A)$. By definition of conditional expectation $\mathbb{E}(X_k \mid  \mathcal{F}_\tau) = X_\tau$. Since $k$ is also an upper bound for $\rho$, it follows that $\mathbb{E}(X_k \mid  \mathcal{F}_\rho) = X_\rho$. Using the tower property we get

$$
\begin{align*}
  X_\rho &= \mathbb{E}(X_k \mid  \mathcal{\rho}) = \mathbb{E}[\mathbb{E}(X_k \mid  \mathcal{F}_\rho)|\mathcal{F}_\tau] \\
  &= \mathbb{E}[\mathbb{E}(X_k\mid \mathcal{F}_\tau)|\mathcal{F}_\rho] = \mathbb{E}(X_\tau|\mathcal{F}_\rho)
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale, then by Doob's decomposition theorem, $X_n = Y_n + Z_n$ for $n\in\mathbb{N}$ where $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$ and $\mathbf{Z} = \{Z_n \}_{n\in\mathbb{N}}$ is increasing and is predictable relative to $\mathscr{F}$

$$
  \mathbb{E}(X_\tau | \mathcal{F}_\rho) = \mathbb{E}(Y_\tau | \mathcal{F}_\rho) + \mathbb{E}(Z_\tau | \mathcal{F}_\rho)
$$

Since $\mathbb{E}(Y_\tau | \mathcal{F}_\rho) = Y_\rho$ by the first condition and since $\mathbf{Z}$ is increasing, $\mathbb{E}(Z_\tau | \mathcal{F}_\rho) \geq\mathbb{E}(Z_\rho | \mathcal{F}_\rho) = Z_\rho$. Hence $\mathbb{E}(X_\tau | \mathcal{F}_\rho) \geq X_\rho$.

3. The proof when $\mathbf{X}$ is a super-martingale is same as for when $\mathbf{X}$ is a sub-martingale, except that the process $\mathbf{Z}$ is decreasing.

**Continuous time**

Note that in continuous time, the proofs when $\mathbf{X}$ is a sub or super-martingale is the same as in discrete time.

Suppose that $\mathbf{X}$ is a martingale. We need to show that $\mathbb{E}(X_\tau; A) = \mathbb{E}(X_\rho; A)$ for every $A\in\mathcal{F}_\rho$. Let $\rho_n = \lceil 2^n \rho \rceil / 2^n$ and $\tau_n = \lceil 2^n \tau \rceil / 2^n$ for $n\in\mathbb{N}$. The stopping times $\rho_n$ and $\tau_n$ take values in a countable set $T_n$ for each $n\in\mathbb{N}$ and $\rho_n \xrightarrow{n\to\infty}\rho$ and $\tau_n\xrightarrow{n\to\infty}\tau$. The process $\{ X_t \}_{t\in T_n}$ is a discrete-time martingale for each $n\in\mathbb{N}$. By the right continuity of $\mathbf{X}$, 

$$
  X_{\rho_n} \xrightarrow{n\to\infty} X_\rho \quad X_{\tau_n}\xrightarrow{n\to\infty}X_\tau
$$

Suppose next that $\tau\leq c$ where $c\in(0,\infty)$ so that $\rho\leq c$ also. Then $\rho_n \leq c+1$ and $\tau_n \leq c+1$ for $n\in\mathbb{N}$ so the discrete stopping times are uniformly bounded. From the discrete version of the theorem $X_{\rho_n} = \mathbb{E}(X_{c+1} \mid \mathcal{F}_{\tau_n})$ for $n\in\mathbb{N}$. It follows that the sequences $\{ X_{\rho_n} \}_{n\in\mathbb{N}}$ and $\{ X_{\tau_n} \}_{n\in\mathbb{N}}$ are uniformly integrable and hence $X_{\rho_n}\xrightarrow{n\to\infty} X_\rho$ and $X_{\tau_n}\xrightarrow{n\to\infty} X_\tau$ in mean as well as with probability $1$. 

Let $A\in\mathcal{F}_p$. Since $\rho\leq\rho_n$, it follows that $\mathcal{F}_\rho \subseteq \mathcal{F}_{\rho_n}$ and thus $A\in\mathcal{F}_{\rho_n}$ for each $n\in\mathbb{N}$. By the theorem in discrete time

$$
  \mathbb{E}(X_{\tau_n};A) = \mathbb{E}(X_{\rho_n}; A)
$$

Letting $n\to\infty$ gives $\mathbb{E}(X_\tau;A) = \mathbb{E}(X_\rho;A)$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\rho, \tau \in T$ are bounded stopping times relative to $\mathscr{F}$ with $\rho\leq\tau$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau) = \mathbb{E}(X_\rho)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau ) \geq \mathbb{E}(X_\rho)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau) \leq \mathbb{E}(X_\rho)$

<details>
<summary>Proof</summary> 

Recall that $\mathbb{E}(X_\tau) = \mathbb{E}[\mathbb{E}(X_\tau | \mathcal{F}_)]$, so the results follow directly from the Doob's optional stopping theorem.
</details>
</MathBox>

### Stopped martingale

<MathBox title='Stopped process' boxType='definition'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\tau \in T_\infty$ is a stopping time relative to $\mathscr{F}$. The stopped process $\mathbf{X}^\tau = \{X_t^\tau\}_{t\geq 0}$ is defined by

$$
  X_t^\tau = X_{t\wedge \tau} = \begin{cases} 
    X_t,\quad t < \tau \\
    X_\tau,\quad t\geq \tau
  \end{cases}
$$

<details>
<summary>Details</summary> 

In continuous times, the standard assumptions ensure that $\mathbf{X}^\tau$ is a valid stochastic process and is adapted to $\mathscr{F}$. That is, $X_t^\tau$ is measurable with respect to $\mathcal{F}_t$ for each $t\in[0,\infty)$. Moreover, $\mathbf{X}^\tau$ is also right continuous and has left limits.
</details>
</MathBox>

<MathBox title='Elementary stopping theorem' boxType='theorem'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\tau \in T$ is a stopping times relative to $\mathscr{F}$

1. If $\mathbf{X}$ is a martingale then so is $\mathbf{X}^\tau$
2. If $\mathbf{X}$ is a sub-martingale then so is $\mathbf{X}^\tau$
3. If $\mathbf{X}$ is a super-martingale then so is $\mathbf{X}^\tau$

<details>
<summary>Proof</summary> 

If $s,t\in T$ with $s\leq t$ then $\tau\wedge s$ and $\tau\wedge t$ are bounded stopping times with $\tau\wedge s\leq \tau\wedge t$. The results follow directly from the optional stopping theorem.

In discrete time, the theorem can be proved using the martingale transform. Suppose that $T=\mathbb{N}$ and define the process $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ by

$$
  Y_n = \mathbf{1}(\tau\geq n) = 1 - \mathbf{1}(\tau\leq n-1)
$$

which is bounded and nonnegative. By the definition of a stopping time, $\{ \tau\leq n - 1 \}\in\mathcal{F}_{n-1}$, so the process $\mathbf{Y}$ is predictable. The transform of $\mathbf{X}$ by $\mathbf{Y}$ is

$$
\begin{align*}
  (\mathbf{Y}\cdot\mathbf{X})_n &= X_0 + \sum_{k=1}^n Y_k(X_k - X_{k+1}) \\
  &= X_0 + \sum_{k=1}^n \mathbf{1}(\tau\geq k)(X_k - X_{k-1})
\end{align*}
$$

Note that 

$$
\begin{align*}
  X_k^\tau - X_{k-1}^\tau &= \begin{cases}
    X_k - X_{k-1}$, & $\tau \geq k$ \\
    X_k^\tau - X_{k-1}^\tau = X_\tau - X_\tau = 0, & \tau < k
  \end{cases} \\
  &= \mathbf{1}(\tau\geq k)(X_k - X_{k-1})
$$

Hence

$$
\begin{align*}
  (\mathbf{Y}\cdot\mathbf{X})_n &= X_0 + \sum_{k=1}^n (X_k^\tau - X_{k+1}^\tau) \\
  &= X_0 + X_n^\tau - X_0^\tau = X_n^\tau
\end{align*}
$
$$

If $\mathbf{X}$ is a (sub/super-)martingale, then so is the transform $\mathbf{X}\cdot\mathbf{Y}=\mathbf{X}^\tau$

</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\tau \in T$ is a stopping times relative to $\mathscr{F}$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_{t\wedge\tau} = \mathbf{E}(X_0)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_{t\wedge\tau} \geq\mathbf{E}(X_0)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_{t\wedge\tau} \leg\mathbf{E}(X_0)$
</MathBox>

### Discrete time

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $|X_n|$ is bounded uniformly for $n\in\mathbb{N}$ and that the stopping time $\tau$ is finites

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau) = \mathbb{E}(X_0)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau) \geq\mathbb{E}(X_0)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau) \leq\mathbb{E}(X_0)$

<details>
<summary>Proof</summary> 

Assume that $\mathbf{X}$ is a super-martingale. The proof for a sub-martingale is similar and the result follows immediately. By the mean property for a stopped super-martingale

$$
  \mathbb{E}(X_{\tau\wedge n})\leq\mathbb{E}(X_0),\; n\in\mathbb{N}
$$

Since $\tau < \infty$ with probability $1$, then $\tau\wedge n \xrightarrow{n\to\infty} \tau$ with probability $1$. Since $|X_n|$ is bounded in $n\in T$, it follows from the bounded convergence theorem that $\mathbb{E}(X_{\tau\wedge n})\xrightarrow{n\to\infty}\mathbb{E}(X_\tau)$. Letting $n\to\infty$ in the displayed equation gives $\mathbb{E}(X_\tau)\leq\mathbb{E}(X_0)$.
</details>
</MathBox>

<MathBox title='Wald identities' boxType='proposition'>
Let $S_n = \sum_{i=1}^n \xi_i$, then the following identities hold: 
1. if $\mathrm{E}\left[ |\xi_i | \right] < \infty$ and $\mathrm{E}\left[ \tau \right] < \infty$ then $ \mathrm{E}[|S_\tau|] < \infty$ and  
$$
  \mathrm{E}[S_\tau] = \mathrm{E}[\tau] \cdot \mathrm{E}[\xi_k]
$$
2. if $\mathrm{E}\left[ \xi_i \right] = 0$ and $\sigma^2 = \mathrm{E}\left[ \xi_i^2 \right] < \infty$ then 
$$
  \mathrm{E}[S_\tau^2] = \sigma^2 \mathrm{E}[\tau]
$$
3. assume that $\mathrm{E}\left[ e^{\theta \xi_1} \right] = e^{-\psi(\theta)} < \infty$, then for every bounded stopping time
$$
  \mathrm{E}\left[ \theta S_\tau - \tau \psi(\theta) \right] = 1
$$
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $|X_{n+1} - X_n|$ is bounded uniformly for $n\in\mathbb{N}$ and that $\mathbb{E}(\tau) < \infty$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau) = \mathbb{E}(X_0)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau) \geq\mathbb{E}(X_0)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau) \leq\mathbb{E}(X_0)$

<details>
<summary>Proof</summary> 

Assume that $\mathbf{X}$ is a super-martingale. The proof for a sub-martingale is similar and the result follows immediately. By the mean property for a stopped super-martingale

$$
  \mathbb{E}(X_{\tau\wedge n})\leq\mathbb{E}(X_0),\; n\in\mathbb{N}
$$

Suppose that $|X_{n+1} - X_n| \leq c$ for $c\in (0,\infty)$. Then

$$
\begin{align*}
  |X_{\tau\wedge n - X_0}| &= \left| \sum_{k=1}^{\tau\wedge n} (X_k - X_{k-1}) \right| \\
  &\leq \sum_{k=1}^{\tau\wedge n} |X_k - X_{k-1}| \leq c(\tau\wedge n) \leq c\tau
\end{align*}
$$

Hence $|X_{\tau\wedge n}| \leq c\tau + |X_0|$. Since $\mathbb{E}(\tau) < \infty$ we know that $\tau < \infty$ with probability $1$, such that $\tau\wedge n \xrightarrow{n\to\infty} \tau$. Also $\mathbb{E}(c\tau + |X_0|) < \infty$ so by the dominated convergence theorem $\mathbb{E}(X_{\tau\wedge n}) \xrightarrow{n\to\infty}\mathbb{E}(X_\tau)$. Letting $n\to\infty$ in the displayed equation gives $\mathbb{E}(X_\tau)\leq\mathbb{E}(X_0)$.
</details>
</MathBox>

### Wald's equation

<MathBox title="Wald's equation" boxType='proposition'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of indepedent, identically distributed variables with common mean $\mu\in\mathbb{R}$. If $N$ is a stopping time for $\mathbf{X}$ with $\mathbb{E}(N) < \infty$ then

$$
  \mathbb{E}\left( \sum_{k=1}^N X_k \right) = \mu\mathbb{E}(N)
$$

<details>
<summary>Proof</summary>

Let $\mathscr{F}$ denote the natural filtration associated with $\mathbf{X}$. Let $c = \mathbb{E}(|X_n|)$, which by assumption $c < \infty$. Let

$$
  Y_n = \sum_{k=1}^n (X_k - \mu),\; n\in\mathbb{N}_+
$$

Then $\mathbf{Y} = (Y_n)_{n\in\mathbb{N}_+}$ is a martingale relative to $\mathscr{F}$ with mean $0$. Note that

$$
  \mathbb{E}(|Y_{n+1} - Y_n|) = \mathbb{E}(|X_{n+1} - \mu|)\leq c + |\mu|
$$

By the optional stopping theorem we have $\mathbb{E}(Y_N) = 0$. Hence

$$
\begin{align*}
  0 &= \mathbb{E}(Y_N) = \mathbb{E}\left[ \sum_{k=1}^N (X_k - \mu) \right] \\
  &= \mathbb{E}\left( \sum_{k=1}^N X_k - N\mu \right) \\
  &= \mathbb{E}\left( \sum_{k=1}^N X_k \right) - \mu\mathbb{E}(N)
\end{align*}
$$
</details>
</MathBox>

## Markov processes

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a time-homogeneous Markov process with state space $(S,\mathcal{S})$, relative to the filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$ and transition kernels $\mathbf{P} = \{P_t\}_{t\in T}$. Suppose that $h:S\to\mathbb{R}$ and that $\mathbb{E}[|h(X_t)] < \infty$ for $t\in T$, then

1. $h$ is *harmonic* for $\mathbf{X}$ if $P_t h = h$ for $t\in T$
2. $h$ is *sub-harmonic* for $\mathbf{X}$ if $P_t h \geq h$ for $t\in T$
3. $h$ is *super-harmonic* for $\mathbf{X}$ if $P_t h \leq h$ for $t\in T$

For $h(\mathbf{X}) = \{ h(X_t) \}_{t\in T}$
1. $h$ is *harmonic* for $\mathbf{X}$ if and only if $h(X)$ is a martingale with respect to $\mathscr{F}$
2. $h$ is *sub-harmonic* for $\mathbf{X}$ if and only if $h(X)$ is a sub-martingale with respect to $\mathscr{F}$
3. $h$ is *super-harmonic* for $\mathbf{X}$ if and only if $h(X)$ is a super-martingale with respect to $\mathscr{F}$

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s\leq T$. Then by the Markov property

$$
  \mathbb{E}[h(X_t)|\mathcal{F_s}] = \mathbb{E}[h(X_t)|X_s] = P_{t-s} h(X_s)
$$

If $h$ is harmonic, $\mathbb{E}[h(X_t)|\mathcal{F}_s] = h(X_s)$ such that $h(\mathbf{X})$ is a martingale. Conversely, if $h(\mathbf{X})$ is a martingale, then $P_{t-s} h(X_s) = h(X_s)$. Letting $s = 0$ and $X_0 = x$ gives $P_t h(x) = h(x)$ so $h$ is harmonic. The proofs for sub and super-martingales are similar, with inequalities replacing the equalities.
</details>
</MathBox>

## Inequalities

### Maximal inequalities

<MathBox title="Markov's inequality (alternate)" boxType='proposition'>
If $X$ is a real-valued random variable then

$$
  \mathbb{P}(X\geq x) \leq \frac{1}{x}\mathbb{E}(X;X\geq x),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

Clearly

$$
  x\mathbf{1}(X\geq x)\leq X\mathbf{1}(X\geq x),\; x\in(0,\infty)
$$

Taking expected values gives $x\mathbb{P}(X\geq) \leq\mathbb{E}(X;X\geq x)$. Dividing by $x$ gives the result.
</details>
</MathBox>

<MathBox title="Doob's inequality" boxType='theorem'>
For the process $\mathbf{X}$, define the corresponding maximal process $\mathbf{U} = \{ U_t \}_{t\in T}$ by

$$
  U_t = \sup\{ X_s : s\in T_t \},\; t\in T
$$

where $T_t = \{s\in T : s\leq t\}$. If $\mathbf{X}$ is a sub-martingale then

$$
  \mathbf{P}(U_t \geq x) \leq \frac{1}{x}\mathbf{E}(X_t; U_t \geq x),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

**Discrete time**
For $T=\mathbb{N}$ the maximal process is $U_n = \max\{X_k : k\in\mathbb{N}_n\}$ for $n\in\mathbb{N}$. Let $x\in(0,\infty)$ and define $\tau_x = \min\{k\in\mathbb{N} : X_k \geq x\}$ where $\min(\emptyset) = \infty$. The random time $\tau_x$ is a stopping time relative to $\mathscr{F}$. The processes $\{U_n\}_{n\in\mathbb{N}}$ and $\{\tau_x\}_{x\in (0,\infty)}$ are inverses in the sense that $U_n \geq x$ if and only iff $\tau_x \leq n$.

Note that

$$
  \mathbb{E}(X_{\tau_x \wedge n}) = \mathbb{E}(X_{\tau_x \wedge n}; \tau_x \leq n) + \mathbb{E}(X_{\tau_x \wedge n}; \tau_x > n)
$$

If $\tau_x \leq n$ then $X_{\tau_x \wedge n} = X_{\tau_x}\geq x$. On the other hand, if $\tau_x > n$ then $X_{\tau_x \wedge n} = X_n$ giving

$$
  \mathbb{E}(X_{\tau_x \wedge n}) \geq x\mathbb{P}(\tau_x \leq n) + \mathbb{E}(X_n; \tau_x > n) = x\mathbb{P}(U_t \geq x) + \mathbb{E}(X_n ; \tau_x > n)
$$

Similarly

$$
  \mathbb{E}(X_n) = \mathbb{E}(X_n; \tau_x \leq n) + \mathbb{E}(X_n; \tau_x > n) = \mathbb{E}(X_n; U_\tau \geq n) + \mathbb{E}(X_n ; \tau_x > n)
$$

By the optional stopping theorem $\mathbb{E}(X_{\tau_x \wedge n})\leq\mathbb{E}(X_n)$, giving

$$
\begin{gather*}
  x\mathbb{P}(U_t \geq x) + \mathbb{E}(X_n;\tau_x > n) \leq \mathbb{E}(X_n; U_t \geq x) + \mathbb{E}(X_n; \tau_x > n) \\
  \iff \mathbb{P}(U_t \geq x) \leq \frac{1}{x}\mathbb{E}(X_n; U_t \geq x)
\end{gather*}
$$
 
**Continuous time**

For $k\in\mathbb{N}$, let $\mathbb{D}_k^+ = \{ j/2^k : j\in\mathbb{N} \}$ denote the set of nonnegative dyadic rationals of rank $k$ or less. For $t\in[0,\infty)$ let $T_t^k = \left(\mathbb{D}_k^+ \cap [0,t] \right) \cup \{t\}$ so that $T_t^k$ is the finite set of such dyadic rationals that are less than $t$, including $t$. Note that $T_t^k$ has an ordered enumeration such that $\mathbf{X}^k = \{X_s\}_{s\in T_t^k}$ is a discret-time sub-martingale for each $k\in\mathbb{N}$. Let $U_t^k = \sup\{ X_s \}_{s\in T_t^k}$ and note that $T_t^j \subset T_t^k \subset [0,t]$ for $t\in[0,\infty)$ and $j,k\in\mathbb{N}$ with $j< k$. Thus $U_t^j \leq U_t^k \leq U_t$. It follows that for $x\in(0,\infty)$

$$
  \{U_t^j\} \subseteq \{U_t^k \geq x} \subset \{U_t \geq x\}
$$

The set $\mathbb{D}^+$ of all nonnegative dyadic rationals is dense in $[0,\infty)$. Since $\mathbf{X}$ is right continuous with left limits, it follows that if $U_t \geq x$ then $U_t^k \geq x$ for some $k\in\mathbb{N}$. That is

$$
  \{U_t \geq x\} = \bigcup_{k=0}^\infty \{ U_t^k \geq x \}
$$

The maximal inequality applies to the discrete-time sub-martingale $X^k$ such that for each $k\in\mathbb{N}$

$$
  \mathbb{P}(U_t^k \geq x) \leq \frac{1}{x}\mathbb{E}(X_t ; U_t^k \geq x)
$$

By the monotone convergence theorem, $\mathbb{P}(U_t^k \geq x)\xrightarrow{k\to\infty} \mathbb{P}(U_t \geq x)$, and $\mathbb{E}(X; U_t \geq x)\xrightarrow{k\to\infty}\mathbb{E}(X; U_t \geq x)$.
</details>
</MathBox>

Recall that the positive part of $x\in\mathbb{R}$ is 

$$
  x^+ = x\vee 0 = \begin{cases} x,\quad x > 0 \\ 0,\quad x \leq 0 \end{cases}
$$ 

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X}$ is a sub-martingale. For $t\in T$, 

1. Let $V_t = \sup\{ X_s^+ \}_{s\in T_t}$, then
$$
  \mathbb{P}(V_t \geq x) \leq\frac{1}{x}\mathbb{E}(X_t^+; V_t \geq x),\; x\in(0,\infty)
$$

2. Let $W_t = \sup\{ |X_s| \}_{s\in T_t}$ then
$$
  \mathbb{P}(W_t \geq x) \leq\frac{1}{x}\mathbb{E}(|X_t|; W_t \geq x),\; x\in(0,\infty)
$$
<details>
<summary>Proof</summary>

1. Since $\mathbf{X}$ is a sub-martingale and $x\mapsto x^+$ is increasing and convex, $\mathbf{X}^+ = \{ X_t^+ \}_{t\in T}$ is also a sub-martingale. Hence the result follows from the general maximal inequality for sub-martingales.

2. Since $\mathbf{X}$ is a sub-martingale and $x\mapsto |x|$ is increasing and convex, $|\mathbf{X}| = \{ |X_t| \}_{t\in T}$ is also a sub-martingale. Hence the result follows from the general maximal inequality for sub-martingales.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X}$ is a martingale. For $t\in T$, let $W_t = \sup\{|X_s|\}_{s\in T_t}$. Then for $k > 1$ 

$$
  lVert W_t \rVert_k \leq \frac{k}{k-1}\lVert X_t \rVert_k
$$

or in terms of expected value

$$
  \mathbb{E}\left(|W_t|^k \right) \leq\left(\frac{k}{k-1}\right)^k \mathbb{E}\left(|X_t|^k \right)
$$

<details>
<summary>Proof</summary>

Fix $t\in T$. If $\mathbf{E}(|X_t|^k) = \infty$ the inequality holds trivially, so assume $\mathbb{E}(|X_t|^k) < \infty$, i.e. $X_t \in L_k$. The proof relies on Hölder's inequality, which is applicable by truncating $W_t$ and considering instead the bounded random variable $W_t \wedge c$, where $c\in(0,\infty)$. First, we need to show

$$
  \mathbb{P}(W_t \wedge c \geq x) \leq \frac{1}{x}\mathbb{E}(|X_t|; W_t \wedge c \geq x),\; x\in(0,\infty)
$$

If $c < x$, both sides are $0$. If $c\in x$, then $\{ W_t \wedge c \geq x \} = \{ W_t \geq x \}$ such that from the maximum inequality corollary

$$
\begin{align*}
  \mathbb{P}(W_t \wedge c \geq x) &= \mathbb{P}(W_t \geq x) \\
  &\leq \frac{1}{x}\mathbb{E}(|X_t|; W_t \geq x) = \mathbb{E}(|X_t|; W_t \wedge c \geq x)
\end{align*}
$$

Recall that 

$$
  \lVert W_t \wedge c \rVert_k^k = \mathbb{E}[(W_t \wedge c)^k] = \int_0^\infty kx^{k-1}\mathbb{P}(W_t \wedge c \geq x)\,\mathrm{d}x
$$

Applying the inequality

$$
  \mathbb{E}[(W_t \wedge c)^k] \leq \int_0^\infty kx^{k-2}\mathbb{E}[|X_t|; W_t \wedge c \geq x]\,\mathrm{d}x
$$

Fubini's theorem allows interchanging the expected value and the integral

$$
  \mathbb{E}[(W_t \wedge c)^k] \leq \mathbb{E}\left[\int_0^{W_t \wedge c} kx^{k-2} |X_t|\,\mathrm{d}x\right] = \frac{1}{k-1}\mathbb{E}[|X_t|(W_t \wedge c)^{k-1}]
$$

Note that $X_t \in L_k$ and $(W_t \wedge c)^{k-1} \in L_j$ where $j = \frac{k}{k-1}$ is the conjugate to $k$. By Hölder's inequality

$$
  \lVert W_t \wedge c \rVert_k^k \leq \frac{k}{k-1} \lVert X_t \rVert_k \cdot \lVert (W_t \wedge c)^{k-1} \rVert_j = \frac{k}{k-1} \lVert X_t \rVert_k \cdot \lVert W_t \wedge c \rVert_k^{k-1}
$$

where we have used that $\lVert (W_t \wedge c)^{k-1} \rVert_j = \lVert W_t \wedge c \rVert_k^{k-1}$. Dividing by this factor gives

$$
  \lVert W_t \wedge c \rVert_k \leq \frac{k}{k-1}\lVert X_t \rVert_k
$$

By the monotone convergence theorem $\lVert W_k \wedge c \rVert_k \stackrel{c\to\infty}{\uparrow} \lVert W_t \rVert_k$. Letting $c\to\infty$ gives

$$
  \lVert W_t \rVert_k \leq \frac{1}{k-1}\lVert X_t \rVert_k
$$
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X}$ is a super-martingale. For $t\in T$, let $U_\infty = \sup\{ X_t \}_{t\in T}$ 

$$
  \mathbb{P}(U_\infty \geq x) \leq \frac{1}{x}\mathbb{E}(X_0),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

Let $Y_t = -X_t$ for $t\in T$. Since $\mathbf{X}$ is a super-martingale, $\mathbf{Y}$ is a sub-martingale. And since $\mathbf{X}$ is nonnegative, $Y_t^+ = X_t$ for $t\in T$. Let $U_t = \sup\{ X_s \}_{s\in T_t} = \sup\{ Y_s^+ \}_{s\in T_t}$. By the maximal inequality for sub-martingales, and since $\mathbf{X}$ is a super-martingale we have

$$
  \mathbb{P}(U_t \geq x) \leq \frac{1}{x}\mathbb{E}(Y_t^+) = \frac{1}{x}\mathbb{E}(X_t) \leq \frac{1}{x}\mathbb{E}(X_0),\; x\in(0,\infty)
$$

Note that $U_t \stackrel{\uparrow}{t\to\infty} U_\infty$. Let $x\in(0,\infty)$ and $\varepsilon\in(0,x)$. If $U_\infty \geq x$ then $U_t \geq x - \varepsilon$ for sufficiently large $t\in T$. Hence

$$
  \{ U_\infty \geq x \} \subseteq \bigcup_{k=1}^\infty \{ U_k \geq x - \varepsilon \}
$$

Using the continuity theorem for increasing events, and the result above gives

$$
  \mathbb{P}(U_\infty \geq x) \leq \lim_{k\to\infty} \mathbb{P}(U_k \geq x - \varepsilon) \leq \frac{1}{x-\varepsilon}\mathbb{E}(X_0)
$$

Since this holds for all $\varepsilon\in (0,x)$, it follows that $\mathbb{P}(U_\infty \geq x) \leq \frac{1}{x}\mathbb{E}(X_0)$.
</details>
</MathBox>

<MathBox title="Kolmogorov's inequality" boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}_+}$ is a sequence of indepedent variables with $\mathbb{E}(X_n) = 0$ and $\mathrm{var}(X_n) = \mathbb{E}(X_n^2) < \infty$. Let $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ be the partial sum process associated with $\mathbf{X}$, i.e.

$$
  Y_n = \sum_{i=1}^n X_i,\; n\in\mathbb{N}
$$

For $n\in\mathbb{N}$, let $U_n = \max\{|Y_i|\}_{i\in\mathbb{N}_n}$. Then

$$
  \mathbb{P}(U_n \geq x) \leq \frac{1}{x^2}\mathrm{var}(Y_n) = \frac{1}{x^2}\sum_{i=1}^n \mathbb{E}(X_i^2),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

Note that $\mathbf{Y}$ is a martingale. Since the function $x\mapsto x^2$ on $\mathbb{R}$ is convex, $\mathbf{Y}^2 = \{Y_i^2 \}_{i\in\mathbb{N}_n}$ is a sub-martingale. Let $V_n = \max\{Y_i^2\}_{i\in\mathbb{N}_n}$ for $n\in\mathbb{N}$ and let $x\in(0,\infty)$. Applying the maximal inequality for sub-martingales we have

$$
  \mathbb{P}(U_n \geq x) = \mathbb{P}(V_n \geq x^2) \leq \frac{1}{x^2}\mathbb{E}(Y_n^2) = \frac{1}{x^2}\mathrm{var}(Y_n)
$$

Since $\mathbb{X}$ is an independent sequence

$$
  \mathrm{var}(Y_n) = \sum_{i=1}^n \mathrm{var}(X_i) = \sum_{i=1}^n \mathbb{E}(X_i^2)
$$
</details>
</MathBox>

### Up-crossing inequality

#### Discrete time
The up-crossing inequality gives a bound on how much a sub/super-martingale can oscillate.

<MathBox title='Up-crossing' boxType='definition'>
Suppose that $\mathbf{x} = (x_n)_{n\in\mathbb{N}}$ is a sequence of real numbers, and that $a, b\in\mathbb{R}$ with $a < b$. Define $t_0(\mathbf{x}) = 0$ and the recursively define

$$
\begin{align*}
  s_{k+1} (\mathbf{x}) &= \int\{n\in\mathbb{N} \mid n\geq t_k (\mathbf{x}), x_n \leq a\} \\
  t_{k+1} (\mathbf{x}) &= \int\{n\in\mathbb{N} \mid n\geq s_{k+1} (\mathbf{x}), x_n \geq b\}
\end{align*}
$$

1. The number of up-crossings of the interval $[a,b]$ by the sequence $\mathbf{x}$ up to time $n\in\mathbb{N}$ is
$$
  u_n(a,b,\mathbf{x}) = \sup\{k\in\mathbb{N} \mid t_k(\mathbf{x})\leq n \}
$$
2. The total number of up-crossings of the interval $[a,b]$ by the sequence $\mathbf{x}$ is
$$
  u_\infty (a,b,\mathbf{x}) = \sup\{k\in\mathbb{N} \mid t_k(\mathbf{x}) \}
$$

Note that if $t_k (\mathbf{x}) < \infty$, then $(x_n \mid n = s_k(\mathbf{x}),\dots,t_k(\mathbf{x}))$ is the $k$th up-crossing of the interval $[a, b]$ by the sequence $\mathbf{x}$.
</MathBox>

<MathBox title='Properties of up-crossings' boxType='proposition'>
Suppose that $\mathbf{x} = (x_n)_{n\in\mathbb{N}}$ is a sequence of real numbers, and that $a, b\in\mathbb{R}$ with $a < b$.

1. $u_n (a,b,\mathbf{x})$ is increasing in $n\in\mathbb{N}$
2. $u_n (a,b,\mathbf{x})\xrightarrow{n\to\infty} u(a,b,\mathbf{x})$
3. If $c,d\in\mathbb{R}$ with $a < c < d < b$ then $u_n (c,d,\mathbf{x}) \geq u_n(a,b,\mathbf{x})$ for $n\in\mathbb{N}$ and $u(c,d,\mathbf{x}) \geq u(a,b,\mathbf{x})$

<details>
<summary>Proof</summary>

1. Note that $\{k\in\mathbb{N} \mid t_k(\mathbf{x}) \leq n\}\subset\{k\in\mathbb{N} \mid t_k(\mathbf{x}) \leq n + 1 \}$
2. Note that $\bigcup_{n=0}^\infty \{ k\in\mathbb{N} \mid t_k(\mathbf{x}) \} = \{ k\in\mathbb{N} \mid t_k (\mathbf{x})\leq \infty \}$
3. Every up-crossing of $[a,b]$ is also an up-crossing of $[c,d]$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{x} = (x_n)_{n\in\mathbb{N}}$ is a sequence of real numbers. Then $\lim_{n\to\infty} x_n$ exists in $R^* = \mathbb{R}\cup\{-\infty, \infty\}$ if and only if $u_\infty (a,b,\mathbf{x})< \infty$ for every $a,b\in\mathbb{Q}$ with $a < b$.

<details>
<summary>Proof</summary>

Proving by contraposition, the following statements are equivalent
1. $\lim_{n\to\infty} x_n$ does not exist in $\mathbb{R}^*$
2. $\liminf_{n\to\infty} x_n < \limsup_{n\to\infty} x_n$
3. There exists $a,b\in\mathbb{Q}$ with $a < b$ and with $x_n \leq a$ and $x_n \geq b$ for infinitely many $n\in\mathbb{N}$
4. There exists $a,b\in\mathbb{Q}$ with $a < b$ and $u_\infty (a, b, \mathbf{x})$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a process with respect to the filtration $\mathscr{F} = \{F_n\}_{n\in\mathbb{N}}$, and let $a,b\in\mathbb{R}$ with $a < b$. Let $U_n = u_n (a,b,\mathbf{x})$ be the random number of up-crossing of $[a,b]$ by $\mathbf{X}$ up to time $n\in\mathbb{N}$.

1. If $\mathbf{X}$ is a super-martingale then
$$
\begin{align*}
  \mathbb{E}(U_n) &\leq \frac{1}{b-a}\mathbb{E}[(X_n - a)^-] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_n^-) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_n|) + |a|\right]
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale then
$$
\begin{align*}
  \mathbb{E}(U_n) &\leq \frac{1}{b-a}\mathbb{E}[(X_n - a)^+] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_n^+) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_n|) + |a|\right]
\end{align*}
$$

<details>
<summary>Proof</summary>

Let $\sigma_k = s_k(\mathbf{X})$ and $\tau_k = t_k(\mathbf{X})$ be the random times that define the up-crossings of $\mathbf{X}$ for $k\in\mathbb{N}$. Let $Y_k = X_{\tau_k \wedge n} - X_{\sigma_k \wedge n}$ and then define $Z_n = \sigma_{k=1}^n Y_k$. For the $k$th term $Y_k$

- If $\tau_k \leq n$ then $Y_k = X_{\tau_k} - X_{\sigma_k} \geq b - a$. By definition, the first $U_n$ terms are of this form.
- If $\sigma_k \leq n < \tau_k$ then $Y_k = X_n - X_{\sigma_k} \geq X_n - a$. There is at most one such term, with index $k = U + 1$.
- If $\sigma_k > n$ then $Y_k = X_n - X_n = 0$

Hence $Z_n \geq (b - a)U_n + (X_n - a)\mathbf{1}(\sigma_{U_n + 1} \leq n)$ and so $(b - a)U_n \leq Z_n - (X_n - a)\mathbf{1}(\sigma_{U_n + 1} \leq n)$. Note that $\sigma_k \wedge n$ and $\tau_k \wedge n$ are bounded stopping times and of course $\sigma_k \wedge n \leq \tau_k \wedge n$.

1. If $\mathbf{X}$ is a super-martingale, if follows from the optional stopping theorem that
$$
  \mathbb{E}(Y_k) = \mathbb{E}(X_{\tau_k \wedge n}) - \mathbb{E}(X_{\sigma_k \wedge n}) \leq 0
$$

Thus $\mathbb{E}(Z_n) \leq 0$. Finally, $-(X_n - a)\mathbf{1}(\sigma_{U_n + 1} \leq n) \leq (X_n - a)^-$. Taking expected values gives

$$
  (b - a)\mathbb{E}(U_n) \leq \mathbb{E}(Z_n) + \mathbb{E}[(X_n - a)^-] \leq \mathbb{E}[(X_n - a)^-]
$$

The remaining parts of the inequality follow since $(x - a)^- \leq x^- + |a| \leq |x| + |a|$ for $x\in\mathbb{R}$

**Additional details**
On a sidenote, the process $\mathbf{Z} = \{Z_n\}_{n\in\mathbb{N}}$ can be viewed as a transform of $\mathbf{X}$ by a predictable process. Specifically, for $n\in\mathbb{N}_+$, let $I_n = 1$ if $\sigma_k < n \leq \tau_k$ for some $k\in\mathbb{N}$, and let $I_n = 0$ otherwise. Since $\sigma_k$ and $\tau_k$ are stopping times, note that $\{I_n = 1\}\in\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$. Hence the process $\mathbf{I} = \{ I_n \}_{n\in\mathbb{N}_+}$ is predictable with respect to $\mathcal{F}$. Moreover, the transform of $\mathbf{X}$ by $\mathbf{I}$ is

$$
  (\mathbf{I}\cdot\mathbf{X})_n = \sum_{j=1}^n I_j (X_j - X_{j-1}) = \sum_{k=1}^n (X_{\tau_k \wedge n} - X_{\sigma_k \wedge n}) = Z_n
$$

Since $\mathbf{I}$ is a nonnegative process, if $\mathbf{X}$ is a (sub/super-)martingale, then $\mathbf{I}\cdot\mathbf{X}$ is also a (sub/super-)martingale.
</details>
</MathBox>

#### Continuous time

<MathBox title='Continuous up-crossings' boxType='definition'>
Suppose that $\mathbf{x}: [0,\infty)\to\mathbb{R}$, and that $a, b\in\mathbb{R}$ with $a < b$.

1. If $I\subset [0,\infty)$ is finite, define $t_0^I (\mathbf{x}) = 0$ and the recursively define

$$
\begin{align*}
  s_{k+1}^I (\mathbf{x}) &= \int\{t\in I \mid t\geq t_k^I (\mathbf{x}), x_t \leq a\} \\
  t_{k+1}^I (\mathbf{x}) &= \int\{t\in I \mid t\geq s_{k+1}^I (\mathbf{x}), x_n \geq b\}
\end{align*}
$$

The number of up-crossings of the interval $[a,b]$ by the function $\mathbf{x}$ restricted to $I$ is

$$
  u_I (a, b, \mathbf{x}) = \sup\{k\in\mathbb{N} \mid t_k^I(\mathbf{x}) < \infty \}
$$

2. If $I\subseteq [0,\infty)$ is infinite, the number of up-crossings of the interval $[a,b]$ by $\mathbf{x}$ restricted to $I$ is

$$
  u_I(a,b,\mathbf{x}) = \sup\{u_J(a,b,\mathbf{x}) \mid J \textrm{ is finite and } J\subset I\}
$$
</MathBox>

For simpler notation, let $u_t (a, b, \mathbf{x}) = u_{[0,t]}(a,b,\mathbf{x})$, the number of up-crossings of $[a,b]$ by $\mathbf{x}$ on $[0,t]$ and $u_\infty(a,b,\mathbf{x}) = u_{[0,\infty)}(a,b,\mathbf{x})$, the total number of up-crossings of $[a,b]$ by $\mathbf{x}$.

<MathBox title='Properties of up-crossings' boxType='proposition'>
Suppose that $\mathbf{x}: [0,\infty)\to\mathbb{R}$ and that $a,b\in\mathbb{R}$ with $a < b$

1. If $I, J \subseteq [0,\infty)$ with $I\subseteq J$ then $u_I (a,b,\mathbf{x}) \leq u_J (a,b,\mathbf{x})$
2. If $(I_n)_{n\in\mathbb{N}}$ is an increasing sequence of sets in $[0,\infty)$ and $J = \bigcup_{n=0}^\infty I_n$ then $u_{I_n}(a,b,\mathbf{x}) \xrightarrow{n\to\infty} u_J (a,b,\mathbf{x})$
3. If $c,d\in\mathbb{R}$ with $a < c < d < b$ and $I\subset [0,\infty)$ then $u_I (c,d,\mathbf{x}) \geq u_I(a,b,\mathbf{x})$

<details>
<summary>Proof</summary>

1. The result follows easily from the definitions if $I$ is finite (and $J$ either finite of infinite). If $I$ is infinite (and hence so is $J$), note that
$$
  \{ u_K (a,b,\mathbf{x}) \mid K \textrm{ is finite and } K\subseteq I \} \subseteq \{ u_K (a,b,\mathbf{x}) \mid K \textrm{ is finite and } K \subseteq J \}
$$
2. Since $I_n$ is increasing in $n\in\mathbb{N}$, note that if $K\subset [0,\infty)$ is finite, then $K\subseteq J$ if and only if $K\subseteq I_n$ for some $n\in\mathbb{N}$.
3. Every up-crossing of $[a,b]$ is also an up-crossing of $[c,d]$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{x}:[0,\infty)\to\mathbb{R}$. Then $\lim_{t\to\infty} x_t$ exists in $R^* = \mathbb{R}\cup\{-\infty, \infty\}$ if and only if $u_\infty (a,b,\mathbf{x})< \infty$ for every $a,b\in\mathbb{Q}$ with $a < b$.

<details>
<summary>Proof</summary>

Proving by contraposition, the following statements are equivalent
1. $\lim_{t\to\infty} x_t$ does not exist in $\mathbb{R}^*$
2. $\liminf_{t\to\infty} x_t < \limsup_{t\to\infty} x_t$
3. There exists $a,b\in\mathbb{Q}$ with $a < b$, and there exists $s_n, t_n\in[0,\infty)$ with $x_{s_n} \leq a$ and $x_{t_n} \geq b$ for $n\in\mathbb{N}$
4. There exists $a,b\in\mathbb{Q}$ with $a < b$ and $u_\infty (a, b, \mathbf{x})$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_t\}_{t\geq 0}$ is a process with respect to the filtration $\mathscr{F} = \{F_t\}_{t\geq 0}$, and let $a,b\in\mathbb{R}$ with $a < b$. Let $U_t = u_t (a,b,\mathbf{x})$ be the random number of up-crossing of $[a,b]$ by $\mathbf{X}$ up to time $t\in[0,\infty)$.

1. If $\mathbf{X}$ is a super-martingale the
$$
\begin{align*}
  \mathbb{E}(U_t) &\leq \frac{1}{b-a}\mathbb{E}[(X_t - a)^-] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_t^-) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_t|) + |a|\right]
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale then
$$
\begin{align*}
  \mathbb{E}(U_t) &\leq \frac{1}{b-a}\mathbb{E}[(X_t - a)^+] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_t^+) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_t|) + |a|\right]
\end{align*}
$$

<details>
<summary>Proof</summary>

Suppose that $\mathbf{X}$ is a sub-martingale; the proof for a super-martingale is analogous. Fix $t\in[0,\infty)$ and $a,b\in\mathbb{R}$ with $a < b$. For $I\subseteq [0,\infty)$ let $U_I = u_I (a,b,\mathbf{X}$. Suppose that $I$ is finite and that $t\in I$ is the maximumm of $I$. Since $\mathbf{X}$ restricted to $I$ is also a sub-martingale, the discrete-time up-crossing theorem applies giving

$$
  \mathbf{E}(U_I) \leq \frac{1}{b-a}\mathbb{E}[(X_t - a)^+]
$$

Since $U_t = \sup\{ U_I \mid I \textrm{ is finite and } I\subset [0,t] \}$, there exists finite $I_n$ for $n\in\mathbb{N}$ with $U_{I_n} \stackrel{n\to\infty}{n\to\infty}$. In particular, $U_t$ is measurable. By the properties of continuous-time up-crossings, there exists such a sequence with $I_n$ increasing in $n$ and $t\in I_n$ for each $n\in\mathbb{N}$. By the monotone convergence theorem $\mathbb{E}(U_{I_n}) \xrightarrow{n\to\infty} \mathbb{E}(U_t)$, giving

$$
  \mathbb{E}(U_t) \leq\frac{1}{b-a}\mathbb{E}[(X_t - a)^+]
$$
</details>
</MathBox>

## Convergence

If $\mathbf{X}$ is a sub-martingale realtive to $\mathscr{F}$, the inequality condition for $s,t\in T$

$$
  \mathbb{E}(X_t \mid  \mathcal{F}_s) \geq X_s,\; s\leq t
$$

suggests that $\mathbf{X}$ displays an increasing property. If $\mathbf{X}$ is a super-martingale, the inequality reverses suggesting that $\mathbf{X}$ displays a decreasing property. By coupling these properties with a boundedness property, then intuitively the sub/super-martingale should converge as $t\to\infty$. This is indeed the case as shown by the following theorems. 

<MathBox title='First martingale convergence theorem' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a sub/super-martingale with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, and that $\mathbf{E}(|X_t|)$ is bounded in $t\in T$. Then there exists a random variable $X_\infty$ that is measurable with respect to $\mathcal{F}_\infty$ such that $\mathbb{E}(|X_\infty|) < \infty$ and $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$.

<details>
<summary>Proof</summary>

Let $T_t = \{ s\in T \mid s\leq t\}$. For $a,b\in\mathbb{R}$ with $a < b$, let $U_t (a,b)$ denote the number of up-crossings of the interval $[a,b]$ by the process $\mathbf{X}$ on $T_t$, and let $U_\infty(a,b)$ denote the number of up-crossings of $[a,b]$ by $\mathbf{X}$ on $T$. Recall that $U_t \stackrel{\uparrow}{t\to\infty} U_\infty$. Suppose that $\mathbb{E}(|X_t|) < c$ for $c\in (0,\infty)$. By the up-crossing inequality

$$
  \mathbb{E}[U_t(a,b)] \leq \frac{1}{b-a}\left[|a| + \mathbb{E}(|X_t|)\right] \leq \frac{|a| + c}{b - a}
$$

By the monotone convergence theorem, it follows that

$$
  \mathbb{E}[U_\infty (a,b)] < \frac{|a| + c}{b - a} < \infty
$$

Showing that $\mathbb{P}[U_\infty (a,b) < \infty] = 1$. Thus $U_\infty (a,b) < \infty$ with probability $1$ for every $a,b\in\mathbb{Q}$ with $a < b$. By our characterization of convergence in terms of up-crossings, it follows that there exists a random variable $X_\infty$ with values in $\mathbb{R}^* = \mathbb{R} \cup \{-\infty, \infty\}$ such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$. Note that $X$ is measurable with $\mathcal{F}_\infty$. By Fatou's lemma

$$
  \mathbb{E}(|X_\infty|) \leq \liminf{t\to\infty}\mathbb{E}(|X_t|) < \infty
$$

Hence $\mathbb{P}(X_\infty \in\mathbb{R}) = 1$
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
If $\mathbf{X} = \{X_t\}_{t\in T}$ is a nonnegative super-martingale with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, then there exists a random variable $X_\infty$, measurable with respect to $\mathcal{F}_\infty$ such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$.

<details>
<summary>Proof</summary>

Since $\mathbb{X}$ is a nonnegative super-martingale $\mathbb{E}(|X_t|) = \mathbb{E}(X_t) \leq\mathbb{E}(X_0)$ for $t\in T$. Hence the first martingale convergence theorem applies.
</details>
</MathBox>

<MathBox title='Second martingale convergence theorem' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is uniformly integrable and a sub/super-martingale relative to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$ and in mean. If $\mathbf{X}$ is a martingale with respect to $\mathscr{F}$ then $X_t = \mathbb{E}(X_\infty | \mathcal{F}_t)$ for $t\in T$.

<details>
<summary>Proof</summary>

Since $\mathbf{X}$ is uniformly integrable, $\mathbb{E}(|X_t|)$ is bounded in $t\in T$. By the first martingale convergence theorem, there exists $X_\infty$ that is measurable with respect to $\mathcal{F}_\infty$ such that $\mathbb{E}(|X_\infty|) < \infty$ and $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$. By the uniform integrability theorem, the convergence is also in mean, i.e. $\mathbb{E}(|X_t - X_\infty|) \xrightarrow{t\to\infty} 0$. Suppose that $\mathbf{X}$ is a martingale relative to $\mathscr{F}$. For fixed $s\in T$ we know that $\mathbb{E}(X_t \mid  \mathcal{F}_s) \xrightarrow{t\to\infty} \mathbb{E}(X_\infty | \mathcal{F}_s)$. Since $\mathbb{E}(X_t \mid  \mathcal{F}_s) = X_s$ for $t\geq s$ it follows that $X_s = \mathbb{E}(X_\infty | \mathcal{F}_s)$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a sub/super-martingale with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, and that $\lVert X_t \rVert_k$ is bounded in $t\in T$ for some $k\in (1,\infty)$. Then there exists a random variable $X_\infty \in L_k$ such that $X_t \xrightarrow{t\to\infty} X_\infty$.

<details>
<summary>Proof</summary>

Suppose that $\lVert X_t \rVert_k \leq c$ for $t\in T$ where $c\in (0,\infty)$. Since $\lVert X \rVert_1 \leq \lVert X_t \rVert_k$ then $\mathbb{E}(|X_t|)$ is bounded in $t\in T$ and the first martingale convergence theorem applies. Hence there exists $X_\infty$ measurable relative to $\mathcal{F}_\infty$ such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$. Equivalently, with probability $1$

$$
  |X_t - X_\infty|^k \xrightarrow{t\to\infty} 0
$$

For $t\in T$ let $T_t = \{ s\in T \mid s\leq t \}$ and define $W_t = \sup\{|X_s| \mid s\in T_t \}$. By the norm version of the maximal inequality

$$
  \lVert W_t \rVert_k \leq \frac{k}{k-1}\lVert X_t \rVert_k \leq \frac{ck}{k-1}
$$

Letting $W_\infty = \sup\{ |X_s| \mid s\in T \}$, then by the monotone convergence theorem

$$
  \lVert W_\infty \rVert_k = \lim_{t\to\infty} \lVert W_t \rVert_k \leq \frac{ck}{k-1}
$$

Showing that $W_\infty \in L_k$. Since $|X_\infty| \leq W_\infty$ it follows that $X_\infty \in L_k$ also. Moreover, $|X_t - X_\infty|^k \leq 2^k W_\infty^k$, so applying the dominated convergence theorem on the first displayed equation gives $\mathbb{E}(|X_t - X_\infty|^k) \xrightarrow{t\to\infty} 0$.
</details>
</MathBox>

### Kolmogorov zero-one law

<MathBox title='Kolmogorov zero-one law' boxType='theorem'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of independent random variables on a state space $(S,\mathcal{S})$. Let $\mathcal{G} = \sigma\{X_k \mid k\geq n\}$ for $n\in\mathbb{N}_+$ and let $\mathcal{G}_\infty = \bigcap_{n=1}^\infty \mathcal{G}_n$. That is, $\mathcal{G}_\infty$ is the tail $\sigma$-algebra of $\mathbf{X}$, the collection of events that depend only on the term of the sequence with arbitrarily large indices. 

If $A\in\mathcal{G}_\infty$ then $\mathbb{P}(A) = 0$ or $\mathbb{P}(A) = 1$. 

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{ X_k \mid k\leq n \}$ for $n\in\mathbb{N}_+$ so that $\mathscr{F} = \{F_n\}_{n\in\mathbb{N}_+}$ is the natural filtration associated with $\mathbf{X}$. Let $\mathcal{F}_\infty = \sigma\left( \bigcup_{n\in\mathbb{N}_+} \mathcal{F}_n \right)$ and let $A\in\mathcal{G}_\infty$ be a tail event. Then $\{\mathbb{E}(\mathbf{1}_A | \mathcal{F}_n)\}_{n\in\mathbb{N}_+}$ is the Doob martingale associated with the indicator variable $\mathbf{1}_A$ and $\mathscr{F}$. By the properties of the Doob martingale, $\mathbb{E}(\mathbf{1}_A \mid \mathcal{F}_n) \xrightarrow{n\to\infty} \mathbb{E}(\mathbf{1}_A|\mathcal{F}_\infty)$ with probability $1$. Since $A\in\mathcal{F}_\infty$ then $\mathbb{E}(\mathbf{1}_A | \mathcal{F}_\infty) = \mathbf{1}_A$. On the other hand $A\in\mathcal{G}_{n+1}$ and the $\sigma$-algebras $\mathcal{G}_{n+1}$ and $\mathcal{F}_n$ are independent, so that $\mathbb{E}(\mathbf{1}_A|\mathcal{F}_n) = \mathbb{P}(A)$ for each $n\in\mathbb{N}_+$. Thus $\mathbb{P}(A) = \mathbf{1}_A$.
</details>
</MathBox>

## Backwards martingales

<MathBox title='Backwards martingale' boxType='definition'>
Let $\mathbf{Y} = \{Y_t\}_{t\in T}$ be a process on a probability space $(\Omega,\mathcal{F},\mathbb{P})$, having state space $\mathbb{R}$. Suppose that $\mathcal{G}_t$ is a sub $\sigma$-algebra of $\mathcal{F}$ for each $t\in T$ and that $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is decreasing, i.e. if $s,t\in T$ with $s\leq t$ then $\mathcal{G}_t \subseteq\mathcal{G}_s$. Let $\mathcal{G}_\infty = \bigcap_{t\in T} \mathcal{G}_t$. 

The process $\mathbf{Y}$ is a *backwards martingale* (or reversed martingale) with respect to $\mathscr{G}$ if $\mathbb{E}(Y_s \mid  \mathcal{G}_t) = Y_t$ for all $s,t \in T$ with $s\leq t$.
</MathBox>

A backwards martingale can be formulated as an ordinary martingale by using negative times as indices. Let $T^- = \{-t\}_{t\in T}$ such that in the discrete case $T^-$ is the set of non-positive integers, and in the continuous case $T^- = (-\infty, 0]$.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. Let $X_t = Y_{-t}$ and $\mathcal{F}_t = \mathcal{G}_{-t}$ for $t\in T^-$. Then $\mathbf{X} = \{X_t\}_{t\in T^-}$ is a martingale with respect to $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T^-}$.

<details>
<summary>Proof</summary>

Since $\mathscr{G}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$, the collection $\mathscr{F}$ is an increasing family of sub $\sigma$-algebras of $\mathcal{F}$, and hence is a filtration. Next, $X_t = Y_{-t}$ is measurable with respect to $\mathcal{G}_{-t}= \mathcal{F}_t$ for $t\in T^-$, so $\mathbf{X}$ is adapted to $\mathscr{F}$. If $s,t\in T^-$ with $s\leq t$ then $-t\leq -s$ so

$$
  \mathbb{E}(X_t\mid \mathcal{F}_s) = \mathbb{E}(X_t\mid \mathcal{G}_{-s}) = Y_{-s} = X_s
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. Fix $t\in T$ and define $X_s^t = Y_{t-s}$ and $\mathcal{F}_s^t = \mathcal{G}_{t-s}$ for $s\in T_t = \{s\in T \mid s\leq t\}$. Then $\mathbf{X}^t = \{X_s^t \mid s\in T_t\}$ is a martingale relative to $\mathscr{F}^t = \{\mathcal{F}_s^t\}_{s\in T_t}$.

<details>
<summary>Proof</summary>

Since $\mathscr{G}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$, the collection $\mathscr{F}^t$ is an increasing family of sub $\sigma$-algebras of $\mathcal{F}$, and hence is a filtration. Next, $X_s^t = Y_{t-s}$ is measurable with respect to $\mathcal{G}_{t-s}= \mathcal{F}_s^t$ for $s\in T_t$, so $\mathbf{X}^t$ is adapted to $\mathscr{F}^t$. If $r,s\in T_t$ with $r\leq s$ then $t - s \leq t - r$ so

$$
  \mathbb{E}(X_s^t|\mathcal{F}_r^t) = \mathbb{E}(Y_{t-s}\mid \mathcal{G}_{t-r}) = Y_{t-r} = X_r^t
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. Then $Y_t = \mathbb{E}(Y_0 \mid \mathcal{G}_t)$ for $t\in T$ and hence $\mathbf{Y}$ is uniformly integrable.

<details>
<summary>Proof</summary>

The fact that $Y_t = \mathbb{E}(Y_0 \mid \mathcal{G}_t)$ for $t\in T$ follows directly from the definition of a backwards martingale. Since we have assumed that $\mathbb{E}(|Y_0|) < \infty$, it follows that $\mathbf{Y}$ is uniformly integrable.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $Y$ is a random variable on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ with $\mathbb{E}(|Y|) < \infty$, and that $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$. Let $Y_t = \mathbb{E}(Y\mid \mathcal{G}_t)$ for $t\in T$. Then $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G}$.

<details>
<summary>Proof</summary>

By definition $Y_t = \mathbb{E}(Y\mid \mathcal{G}_t)$ is measurable relative to $\mathcal{G}_t$. Also

$$
\begin{align*}
  \mathbb{E}(|Y_t|) &= \mathbb{E}[\mathbb{E}(Y\mid \mathcal{G}_t)] \\
  &\leq \mathbb{E}[\mathbb{E}(|Y|\mid\mathcal{G}_t)] = \mathbb{E}(|Y|) < \infty
\end{align*}
$$

Suppose that $s,t\in T$ with $s\leq t$. Then $\mathcal{G}_t \subseteq\mathcal{G}_s$ and by the tower property

$$
  \mathbb{E}(Y_s\mid \mathcal{G}_t) = \mathbb{E}[\mathbb{E}(Y_s\mid \mathcal{G}_s)|\mathcal{G}_t] = \mathbb{E}(Y_s\mid \mathcal{G}_t) = Y_t
$$
</details>
</MathBox>

<MathBox title='Backwards martingale convergence theorem' boxType='theorem'>
Suppose that $\mathbf{Y} = \{ Y_t \}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$. Then there exists a random variable $Y_\infty$ such that

1. $Y_t \xrightarrow{t\to\infty} Y_\infty$ with probability $1$
2. $Y_t \xrightarrow{t\to\infty} Y_\infty$ in mean
3. $Y_\infty = \mathbb{E}(Y_0\mid \mathcal{G}_\infty)$

<details>
<summary>Proof</summary>

Fix $t\in T$ and let $T_t = \{s\in T \mid s\leq t \}$. Let $X_s^t = Y_{t-s}$ and $\mathcal{F}_s^t = \mathcal{G}_{t-s}$ for $s\in T_t$, so that $\mathbf{X}^t = \{ X_s^t\}_{s\in T_t}$ is a martingale relative to $\mathscr{F}^t = \{F_s^t\}_{s\in T_t}$. For $a,b\in\mathbb{R}$ with $a < b$ let $U_t (a, b)$ denote the number of up-crossings of $[a, b]$ by $\mathbf{X}^t$ on $T_t$. Note that $U_t (a,b)$ is also the number of down-crossings of $[a, b]$ by $\mathbf{Y}$ on $T_t$. By the up-crossing inequality applied to $\mathbf{X}$

$$
  \mathbb{E}[U_t(a,b)] \leq\frac{1}{b - a}[\mathbb{E}(|X_t|) + |a|] = \frac{1}{b-a}[\mathbb{E}(|Y_0|) + |a|]
$$

Let $U_\infty (a,b)$ denote the number of down-crossing of $[a,b]$ by $\mathbf{Y}$ on $T$. Since $U_t \stackrel{\uparrow}{t\to -\infty}$ if follows from the monotone convergence theorem that

$$
  \mathbb{E}[U_\infty (a,b)] \leq \frac{1}{b-a}[\mathbb{E}(|Y_0|) + |a|]
$$

Thus $U_\infty(a,b) < \infty$ with probability $1$ for every $a, b \in\mathbb{Q}$ with $a < b$. By the characterization of convergence in terms of down-crossing, there exists a random variable $Y_\infty$ with values in $\mathbb{R}^* = \mathbb{R} \cup \{-\infty, \infty\}$ such that $Y_t \xrightarrow{t\to\infty} Y_\infty$. By Fatou's lemma

$$
  \mathbb{E}(|Y_\infty|) \leq\liminf_{t\to\infty}\mathbb{E}(|Y_t|) \leq\mathbb{E}(|Y_0|) < \infty
$$

In particular $\mathbb{P}(Y_\infty \in\mathbb{R}) = 1$. Since $\mathbf{Y}$ is uniformly integrable and $Y_\infty \in L_1$, it follows that $Y_t \xrightarrow{t\to\infty} Y_\infty$ in $L_1$.

It remains to show that $Y_\infty = \mathbb{E}(Y_0 \mid \mathcal{G}_\infty)$. Let $A\in\mathcal{G}_\infty$. Then $A\in\mathcal{G}_t$ for every $t\in T$. Since $Y_t = \mathbb{E}(Y_0 \mid \mathcal{G}_t)$ it follows by definition that $\mathbb{E}(Y_t;A) = \mathbb{E}(Y_0;A)$ for every $t\in T$. Letting $t\to\infty$ and using the dominated convergence theorem gives $\mathbb{E}(Y_\infty;A) = \mathbb{E}(Y_0;A)$. Hence $Y_\infty = \mathbb{E}(Y_0 \mid \mathcal{G}_\infty)$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. If $Y_0 \in L_k$ for some $k\in[1,\infty)$ then $Y_t \xrightarrow{t\to\infty} Y_\infty$ in $L_k$.

<details>
<summary>Proof</summary>

By the backwards martingale convergence theorem, there exists a random variable $Y_\infty \in L_1$ such that $Y_t\xrightarrow{t\to\infty} Y_\infty$ with probability $1$ in $L_1$. The function $x\mapsto |x|^k$ is convex on $\mathbb{R}$ so by Jensen's inequality

$$
  \mathbb{E}(|Y_t|^k) = \mathbb{E}[|\mathbb{E}(Y_0\mid \mathcal{G}_t)|^k] \leq \mathbb{E}[\mathbb{E}(|Y_0|^k \mid \mathcal{G}_t)] = \mathbb{E}(|Y_0|^k) < \infty
$$

so $Y_t \in L_k$ for every $t\in T$. By Fatou's lemma

$$
  \mathbb{E}(|Y_\infty|^k) \leq\liminf_{t\to\infty} \mathbb{E}(|Y_t|^k) \leq \mathbb{E}(|Y_0|^k) < \infty
$$

showing that $Y_\infty \in L_k$. Since $Y_t = \mathbb{E}(Y_0\mid \mathcal{G}_t)$ and $Y_\infty$ is measurable relative to $\mathcal{G}_t$, then by Jensen's inequality

$$
  |Y_t - Y_\infty|^k = |\mathbb{E}(Y_0 - Y_\infty | \mathcal{G}_t)|^k \leq \mathbb{E}(|Y_0 - Y_\infty|^k \mid\mathcal{G}_t)
$$

It follows that the collection of random variables $\{|Y_t - Y_\infty|^k\}_{t\in T}$ is uniformly integrable, and hence $\lim_{t\to\infty} \mathbb{E}(|Y_t - Y_\infty|^k) = 0$.
</details>
</MathBox>

### Strong law of large numbers

<MathBox title='Strong law of large numbers' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}_+}$ is a sequence of independent, identically distributed random variables with common mean $\mu\in\mathbb{R}$. Let $Y_n = \sum_{i=1}^n X_i,\;n\in\mathbb{N}$ so that $\mathbf{Y} = \{ Y_n \}_{n\in\mathbb{N}}$ is the partial sum process associated with $\mathbf{X}$. Let $M_n = Y_n / n$ for $n\in\mathbb{N}_+$ so that $\mathbf{M} = \{M_n\}_{n\in\mathbb{N}_+}$ is the sequence of sample means.

1. $\lim_{n\to\infty} M_n = \mu$ with probability $1$
2. $\lim_{n\to\infty} M_n = \mu$ in mean

<details>
<summary>Proof</summary>

For $n\in\mathbb{N}$ let

$$
  \mathcal{G}_n = \sigma\{Y_n, Y_{n+1}, Y_{n+2}, \dots\} = \sigma\{Y_n, X_{n+1}, X_{n+2}, \dots\} = 
$$

so that $\mathscr{G} = \{\mathcal{G}_n\}_{n\in\mathbb{N}}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$. The core of the proof is to show that $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. For $n\in\mathbb{N}_+$, clearly $M_n$ is measurable with respect to $\mathcal{G}_n$. By independence $\mathbb{E}(X_i\mid \mathcal{G_n}) = \mathbb{E}(X_i\mid Y_n)$ for $i\in\{1,2,\dots,n\}$. By symmetry, $\mathbb{E}(X_i\mid Y_n) = \mathbb{E}(X_i\mid Y_n)$ for $i,j\in\{1,2,\dots,n\}$. Thus

$$
\begin{align*}
  Y_n &= \mathbb{E}(Y_n\mid \mathcal{G}_n) = \sum_{j=1}^n \mathbb{E}(Y_n\mid \mathcal{G}_n) \\
  &= \sum_{j=1}^n \mathbb{E}(X_i\mid \mathcal{G}_n) = n\mathbb{E}(X_i\mid \mathcal{G}_n)
\end{align*}
$$

so that $\mathbb{E}(X_i\mid \mathcal{G}_n) = Y_n/n = M_n$ for each $i\in\{1,2,\dots,n\}$. Next

$$
\begin{align*}
  \mathbb{E}(Y_n\mid \mathcal{G}_{n+1}) &= \mathbb{E}(Y_n\mid \mathcal{G}_{n+1}) \\
  &= Y_{n+1} - \mathbb{E}(X_{n+1}\mid \mathcal{G}_{n+1}) \\
  &= Y_{n+1} - \frac{1}{n+1}Y_{n+1} = \frac{n}{n+1}Y_{n+1}
\end{align*}
$$

Dividing by $n$ gives $\mathbb{E}(M_n\mid \mathcal{G}_{n+1}) = M_{n+1}$ and hence $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. From the backwards martingale convergence theorem, there exists $M_\infty$ such that $M_n \xrightarrow{n\to\infty} M_\infty$ with probability $1$ and in mean. For $n,k\in\mathbb{N}_+$

$$
  M_{n+k} = \frac{1}{n+k}\sum_{i=1}^k X_i + \frac{n}{n+k}\frac{1}{n}\sum_{i=k+1}^{k+n} X_i
$$

Letting $n\to\infty$ gives

$$
  M_\infty = \lim_{n\to\infty}\frac{1}{n}\sum_{i=k+1}^{k+n} X_i
$$

for every $k\in\mathbb{N}_+$. Hence $M_\infty$ is a tail random variable for $\mathbf{X}$. From the Kolmogorov 0-1 law, $M_\infty$ must be a constant. Convergence in mean implies that the means converge, and since $\mathbb{E}(M_n) = \mu$ for each $n$, it follows that $M_\infty = \mu$.
</details>
</MathBox>

### Exchangeable variables

Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of random variables each taking values in $S$. Recall that $\mathbf{X}$ is exchangeable if for every $n\in\mathbb{N}$, every permutation of $\mathbf{X}$ has the same distribution on $(S^n,\mathcal{S}^n)$. Clearly if $\mathbf{X}$ is a sequence of indepedent, identically distributed variables, then $\mathbf{X}$ is exchangeable. Conversely, if $\mathbf{X}$ is exchangeable, by definition the variables are identically distributed, but not necessarily indepedent. On the other hand conditionally indepedent and identically distributed sequences are exchangeable.

<MathBox title='' boxType='proposition'>
Suppose that $\Theta$ is a random variable on $(T,\mathcal{T})$. If $\mathbf{X}$ is conditionally indepedent and identically distributed given $\Theta$, then $\mathbf{X}$ is exchangeable.

<details>
<summary>Proof</summary>

Implicit in the statement is that the variables in the sequence have a regular conditional distribution $\mu_\Theta$ given $\Theta$. For every $n\in\mathbb{N}_+$, the conditional distribution of every permutation of $(X_i)_{i=1}^n$, given $\Theta$ is $\mu_\Theta^n$ on $(S^n,\mathcal{S}^n)$ where $\mu_\Theta^n$ is the $n$-fold product measure. Unconditionally, the distribution of any permutation is $B\mapsto \mathbb{E}[\mu_\Theta^n (B)]$ for $B\in\mathcal{S}^n$
</details>
</MathBox>

<MathBox title="de Finetti's theorem" boxType='theorem'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is an exchangeable sequence of random variables, each taking values in $\{0,1\}$. Then there exists a random variable $P$ with values in $[0,1]$ such that given $P = p\in[0,1]$, then $\mathbf{X}$ is a sequence of Bernoulli trials with success parameter $p$

<details>
<summary>Proof</summary>

Recall the falling power notation $r^{(j)} = r(r-1)\cdots(r-j+1)$ for $r\in\mathbb{R}$ and $j\in\mathbb{N}$. For $n\in\mathbb{N}_+$ and $k\in\{0,1,\dots,n\}$ let

$$
  B_k^n = \left\{ (x_1, x_2, \dots, x_n)\in \{0,1\}^n \middle| \sum_{i=0}^n x_i = k \right\}
$$

That is, $B_k^n$ is the set of bit strings of length $n$ with $1$ occurring exactly $k$ time. Note that $|B_n^k| = \binom{n}{k} = n^{(k)}/k!$.

$\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is an exchangeable sequence variables with values in $\{0,1\}$. For $n\in\mathbb{N}_+$ let $Y_n = \sum_{n=1}^n X_i$ and $M_n = Y_n / n$, such that $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ is the partial sum process associated with $\mathbf{X}$ and $\mathbf{M} = \{ M_n \}_{n\in\mathbb{N}_+}$ the sequence of sample means. Let $\mathcal{G}_n = \sigma\{Y_n, Y_{n+1},\dots \}$ and $\mathcal{G}_\infty = \bigcap_{n=0}^\infty \mathcal{G}_n$. The family of $\sigma$-algebras $\mathscr{G} = \{\mathcal{G}_n\}_{n\in\mathbb{N}_+}$ is the decreasing. The key to the proof is to find two backwards martingales and use the backwards martingale convergence theorem.

Let $m\in\mathbb{N}_+$ and $k\in\{0,1,\dots,m\}$. By exchangeability, the random vector $(X_i)_{i=1}^m$ given $Y_n = k$ is uniformly distributed on $B_k^m$. If $n\in\mathbb{N}_+$ and $n\leq m$, the random vector $(X_i)_{i=1}^m$ fits the hypergeometric model. Thus if $j\in\{0,1,\dots,n\}$ and $(x_i)_{i=1}^n \in B_j^n$ then

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n \mid Y_m = k) = \frac{k^{(j)}(m-k)^{(n-j)}}{m^{(n)}}
$$

Equivalently

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n \mid Y_m) = \frac{Y_m^{(j)}(m-Y_m)^{(n-j)}}{m^{(n)}}
$$

Given $Y_m$, the variables $(Y_{m+1}, Y_{m+1},\dots)$ give no additional information about the distribution of $(X_i)_{i=1}^n$ and hence

$$
\begin{align*}
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n|\mathcal{G}_m) &= \mathbb{E}[\mathbf{1}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n)|\mathcal{G}_m] \\
  &= \frac{Y_m^{(j)}(m-Y_m)^{(n-j)}}{m^{(n)}}
\end{align*}
$$

For fixed $n,j$ and $(x_i)_{i=1}^n \in B_j^n$, the conditional expected value, as a function of $m$, is a Doob backward martingale relative to $\mathscr{G}$ and hence converges to $\mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n|\mathcal{G}_\infty)$ as $m\to\infty$.

Next we show that $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. Trivially, $M_n$ is measurable with respect to $\mathcal{G}_n$ and $\mathbf{E}(M_n) \leq 1$ for each $n\in\mathbb{N}$. Thus we need to show that $\mathbb{E}(M_n \mid  \mathcal{G}_m) = M_m$ for $m,n\in\mathbb{N}_+$ with $n\leq m$. We already know that the conditional distribution of $Y_n$ given $Y_m = k$ is hypergeometric with parameters $m,k$ and $n$

$$
  P(Y_n = j|Y_m = k) = \binom{n}{j}\frac{k^{(j)}(m - k)^{(n-j)}}{m^{(n)}},\; j\in\{0,1,\dots,n\}
$$

Recall that the mean of the hypergeometric distribution is the sample size times the proportion of type $1$ object in the population, giving

$$
  \mathbb{E}(Y_n = j | Y_m = k) = \frac{1}{n}\mathbb{E}(Y_n \mid  Y_m = k) = \frac{1}{n}n\frac{k}{m} = \frac{k}{m}
$$

Equivalently $\mathbb{E}(M_n \mid  Y_m) = Y_m / m = M_m$. Given $Y_m$, the variables $(Y_{m+1}, Y_{m+2},\dots)$ give no additional information and so $\mathbf{E}(M_n \mid \mathcal{G}_m) = Y_m$. Hence $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. From the backwards martingale convergence theorem there exists a random variable $P$ such that $M_n \xrightarrow{n\to\infty} P$ with probability $1$.

Suppose that $n\in\mathbb{N}_+$ and $j\in\{0,1,\dots,n\}$ and that $m\in\mathbb{N}_+$ and $k_m \in \{0,1,\dots,m \}$. If $n,j$ are fixed and $\lim_{m\to\infty} k_m / m = p \in [0,1]$ then

$$
  \lim_{m\to\infty} \frac{k_m^{(j)}(m - k_m)^{(n-j)}}{m^{(n)}} = p^j (1 - p)^{n-1}
$$

Since $Y_m / m \xrightarrow{m\to\infty} P$ we get

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots,X_n = x_n|\mathcal{G}_\infty) = P^j (1 - P)^{n-j} 
$$

Since the random variable $P$ is measurable with respect to $\mathcal{G}_\infty$ then as $m\to\infty$

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots,X_n = x_n|P) = P^j (1 - P)^{n-j} 
$$

Given $P = p\in[0,1]$, it follows that $\mathbf{X}$ is a sequence of Bernoulli trials with success parameter $p$.
</details>
</MathBox>

De Finetti's theorem states that the distribution of $n$ distinct variables in the exchangeable sequence is a mixture of the product measures. If $\mu_\theta$ is the distribution of a generic $X$ on $(S,\mathcal{S})$ given $\Theta = \theta$ and $\nu$ is the distribution of $\Theta$ on $(T,\mathcal{T})$, then the distribution $n$ of the variables on $(S^n, \mathcal{S}^n)$ is

$$
  B\mapsto \int_T \mu_\theta^n (B)\,\mathrm{d}\nu(\theta)
$$

If $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is an exchangeable sequence of random variables, each taking values in a measurable space $(S,\mathcal{S})$, then there exists a random variable $\Theta$ such that $\mathbf{X}$ is independent and identically distributed given $\Theta$. The generalization of de Finetti's theorem is central in Bayesian statistical inference. For and exchangeable sequence of random variables (observations in a statistical experiment), there is a hidden, random parameter $\Theta$. Given $\Theta = \theta$, the variables are indepedent and identically distributed. We gain information about $\Theta$ by imposing a *prior distribution* on $\Theta$ and the updating thes, based on our observations and using Baye's theorem, to a posterior distribution.

## Examples

### Constant sequence

<MathBox title='Martingale condition for constant sequences' boxType='proposition'>
Suppose that $X$ is a random variable that is measurable with respect to $\mathcal{F}_0\in\mathscr{F}$, and with $\mathbb{E}(|X|) < \infty$. Let $X_t = X$ for $t\in T$. Then the constant sequence process $\mathbf{X} = \{ X_t \}_T$ is a martingale with respect to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Since $X$ is measurable with respect to $\mathcal{F}_0$, it is measurable with respect to $\mathcal{F}_t$ for all $t\in T$. Thus $\mathbf{X}$ is adapted to $\mathscr{F}$. If $s,t\in T$ with $s\leq t$, then

$$
  \mathbb{E}(X_t \mid \mathcal{F}_s) = \mathbb{E}(X_t \mid  \mathcal{F}_s) = X = X_s
$$
</details>
</MathBox>

### Lévy process

<MathBox title='Martingale conditions for processes with independent increments' boxType='proposition'>
Suppose that the continuous process $\mathbf{X} = \{X_t\}_{t\in [0,\infty)}$ has independent increments, and let $m(t) = \mathbb{E}(X_t)$ for $t\in [0,\infty)$. Then $\mathbf{X}$ is
1. Martingale if $m$ is constant.
2. Sub-martingale if $m$ is increasing.
3. Super-martingale if $m$ is decreasing.

Let $Y_t = X_t - m(t)$. The process $\mathbf{Y} = \{ Y_t \}_{t\geq 0}$ is called the compensated process associated with $\mathbf{X}$ and has mean $0$. If $\mathbf{X}$ has independent increments, so does $\mathbf{Y}$, making it a martingale.

<details>
<summary>Proof</summary>

Suppose that $s,t\in[0,\infty)$ with $s< t$. Then

$$
\begin{align*}
  \mathbb{E}(X_t \mid  \mathcal{F}_s) &= \mathbb{E}\left[X_s + (X_t - X_s) |\mathcal{F}_s \right] \\
  &= \mathbb{E}(X_s \mid \mathcal{F}_s ) + \mathbb{E}(X_t - X_s |\mathcal{F}_s)
\end{align*}
$$

Since $X_s$ is measurable to $\mathcal{F}_s$ and $X_t - X_s$ is independent of $\mathcal{F}_s$, we obtain

$$
\begin{align*}
   \mathbb{E}(X_t \mid  \mathcal{F}_s) &= \mathbb{E}(X_t \mid \mathcal{F}_s ) + \mathbb{E}(X_t - X_s |\mathcal{F}_s) \\
   &= X_s + \mathbb{E}(X_t - X_s) = X_s + m(t) - m(s)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Second moment martingale for processes with independent increments' boxType='proposition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has independent increments with constant mean function, and with $\mathrm{var}(X_t) < \infty$ for $t\in T$. Let 

$$
  Y_t = X_t^2 - \mathrm{var}(X_t)\quad t\in T
$$

Then $\mathbf{Y} = \{Y_t\}$ is a martingale.

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s< t$. Note that $\mathbb{E}(Y_t\mid \mathcal{F}_s) = \mathbb{E}(X_t^2 | \mathcal{F}_s) -\mathrm{var}(X_t)$. Rewriting $X_t^2$ as

$$
\begin{align*}
  X_t^2 &= [(X_t - X_s) + X_s]^2 \\
  &= (X_t - X_s)^2 + 2(X_t - X_s)X_s + X_s^2 
\end{align*}
$$

Since $X_t - X_s$ is independent of $\mathcal{F}_s$, $X_s$ is measurable with respect to $\mathcal{F}_s$ and $\mathbb{E}(X_t - X_s) = 0$, it follows that

$$
\begin{align*}
  \mathbb{E}(X_t^2 | \mathcal{F}_s) &= \mathbb{E}[(X_t - X_s)^2] + 2X_s \mathbb{E}(X_t - X_s) + X_s^2 \\
  &= \mathbb{E}[(X_t - X-s)^2] + X_s^2
\end{align*}
$$

Since $X_t - X_s$ also has mean $0$

$$
\begin{align*}
  \mathrm{var}(X_t) &= \mathrm{var}[(X_t - X_s) + X_s] \\
  &= \mathrm{var}(X_s) + \mathrm{var}(X_t - X_s)^2 \\
  &= \mathrm{var}(X_s) + \mathbb{E}[(X_t - X_s)^2]
\end{align*}
$$

Combining the results gives

$$
  \mathbb{E}(Y_t \mid  \mathcal{F}_s) = X_s^2 - \mathrm{var}(X_s) = Y_s
$$
</details>
</MathBox>

<MathBox title='Martingale conditions for random walks' boxType='proposition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has stationary, independent increments, and let $a = \mathbb{E}(X_1 - X_0)$. Then $\mathbf{X}$ is
1. Martingale if $a=0$.
2. Sub-martingale if $a\geq 0$.
3. Super-martingale if $a\leq 0$.

<details>
<summary>Proof</summary>

Note that for a process with stationary, independent increments, the mean function reduces to $m(t) = \mathbb{E}(X_0) + at$ for $t\in T$. Follwing the same argument as for processes with independent increments, we get

$$
  \mathbb{E}(X_t \mid  \mathcal{F}_s) = X_s + a(t - s)
$$
</details>
</MathBox>

<MathBox title='Second moment martingale for random walks' boxType='proposition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has independent increments with $\mathbb{E}(X_0) = \mathbb{E}(X_1)$ and $b^2 = \mathbb{E}\left(X_1^2\right) < \infty$. Let

$$
  Y_t = X_t^2 - \mathrm{var}(X_0) - b^2 t,\quad t\in T
$$

Then $\mathbf{Y} = \{Y_t\}$ is a martingale.

<details>
<summary>Proof</summary>

Since $\mathbb{E}(X_0) = \mathbb{E}(X_1)$, then $\mathbf{X}$ has constant mean function. Note that $\mathrm{var}(X_t) = \mathrm{var}(X_0) + b^2 t$. Following the same argument as for second order martingales for processes with independent increments, we obtain

$$
\begin{align*}
  \mathbb{E}(Y_s\mid \mathcal{F}_s) &= X_s - \mathrm{var}(X_s) \\
  &= X_s - \mathrm{var}(X_0) - b^2 t = Y_s
\end{align*}
$$
</details>
</MathBox>

### Partial sums

In discrete time, a process with independent increments reduces to a partial sum process.

<MathBox title='Martingale conditions for partial sums' boxType='definition'>
Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is a sequence of indepedent random variables with $\mathbb{E}(|V_n|) < \infty$, and let

$$
  X_n = \sum_{k=0}^n V_k
$$

Then $\mathbf{X} = \{X_n\}$ is a partial sum process associated with $\mathbf{V}$. For $n\in\mathbb{N}$, the process $\mathbf{X}$ is
1. sub-martingale if $\mathbb{E}(V_n)\geq 0$
2. super-martingale if $\mathbb{E}(V_n)\leq 0$
3. martingale if $\mathbb{E}(V_n) = 0$

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}} = \sigma\{V_i\}_{i=0}^{n\in\mathbb{N}}$. Note first that

$$
  \mathbb{E}(|X_n|) \leq \sum_{k=0}^n \mathbb{E}(|V_k|) < \infty
$$

Next

$$
\begin{align*}
  \mathbb{E}(X_{n+1}\mid \mathcal{F}_n) \\
  &= \mathbb{E}(X_n\mid \mathcal{F}_n) + \mathbb{E}(X_n\mid \mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$

The last equality holds since $X_n$ is measurable with respect to $\mathcal{F}_N$ and $V_{n+1}$ is independent of $\mathcal{F}_n$.
</details>
</MathBox>

<MathBox title='Second moment martingale for partial sums' boxType='definition'>
Let $\mathbf{X}$ be a partial sum process associated with $\mathbf{V}$. Suppose that $\mathbb{E}(V_k) = 0$ for $k\in\mathbb{N}_+$ and $\mathrm{var}(V_k) < \infty$ for $k\in\mathbb{N}$, and let 

$$
  Y_n = X_n^2 - \mathrm{var}(X_n)
$$

Then $\mathbf{Y} = \{ Y_n\}_{n\in\mathbb{N}}$ is a martingale with respect to $\mathbf{X}$.

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}}$. Since $\mathbf{V}$ is independent, note that

$$
  \mathrm{var}(X_n) = \mathrm{var}\left( \sum_{k=0}^n V_k \right) = \sum_{k=0}^n \mathrm{var}(V_k)
$$

Since $\mathbb{E}(V_k) = 0$, then $\mathrm{var}(V_k) = \mathbb{E}(V_k^2)$. In particular, $\mathbb{E}(|Y_n|) < \infty$ for $n\in\mathbb{N}$. Next

$$
\begin{align*}
  \mathbb{E}(Y_{n+1}\mid \mathcal{F}_n)] \\
  &= \mathbb{E}\left[(X_n + V_{n+1})^2 - \mathrm{var}(X_{n+1})|\mathcal{F}_n \right] \\
  &= \mathbb{E}\left[ X_n^2 + 2X_n V_{n+1} + V_{n+1}^2 - \mathrm{var}(X_{n+1})|\mathcal{F}_n \right] \\
  &= X_n^2 + 2X_n\mathbb{E}(V_{n+1}) + \mathbb{E}(V_{n+1}^2) - \mathrm{var}(X_{n+1})
\end{align*}
$$

Next

$$
\begin{align*}
  \mathbb{E}(X_{n+1}\mid \mathcal{F}_n) \\
  &= \mathbb{E}(X_n\mid \mathcal{F}_n) + \mathbb{E}(X_n\mid \mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$
</details>
</MathBox>

### Difference sequence

<MathBox title='Martingale difference sequence' boxType='definition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a discrete process adapted to $\mathscr{F}$. Let $V_0 = X_0$ and $V_n = X_n - X_{n-1}$ for $n\in\mathbb{N}$. The process $\mathbf{V} = \{ V_n\}_{n\in\mathbb{N}}$ is the martingale difference sequence associated with $\mathbf{X}$ such that for $n\in\mathbb{N}$

$$
  X_n = \sum_{k=0}^n V_k
$$
</MathBox>

<MathBox title='Properties of martingale difference sequence' boxType='proposition'>
Let $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ be a discrete process adapted to $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$. Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is the martingale difference sequence associate with $\mathbf{X}$. Then
1. $\mathbb{V}$ is adapted to $\mathscr{F}$.
2. $\mathbb{E}(V_n\mid \mathcal{F}_k) = 0$ for $k,n\in\mathbb{N}$ with $k< n$.
3. $\mathbb{E}(V_n) = 0$ for $n\in\mathbb{N}_+$
4. If $\mathrm{var}(X_n) < \infty$ for $n\in\mathbb{N}$, then $\mathbf{V}$ is an uncorrelated sequence and

$$
  \mathrm{var}(X_n) = \sum_{k=0}^n \mathrm{var}(V_k) = \mathrm{var}(X_0) + \sum_{k=1}^n \mathbb{E}\left(V_k^2\right)
$$

<details>
<summary>Proof</summary>

1. Obviously, $V_0 = X_0$ is measurable with respect to $\mathcal{F}_0$. For $n\in\mathbb{N}_+$, then $X_n$ and $X_{n-1}$ and thus $V_n$ are measurable with respect to $\mathcal{F}_n$. Hence $\mathbf{V}$ is adapted to $\mathscr{F}$.
2. Let $k\in\mathbb{N}$. By the martingale and adapted properties

$$
\begin{align*}
  \mathbb{E}\left( V_{k+1} | \mathcal{F}_k \right) &= \mathbb{E}(X_{k+1}\mid \mathcal{F}_k) - \mathbb{E}(X_{k+1}\mid  \mathcal{F}_k) \\
  &= X_k - X_k = 0
\end{align*}
$$

By the tower property of conditional expectation

$$
  \mathbb{E}\left( V_{k+1} | \mathcal{F}_k \right) = \mathbb{E}[\mathbb{E}(V_{k+2}\mid \mathcal{F}_{k+1})|\mathcal{F}_k] = 0
$$

The result follows from induction.
3. Since $\mathbf{X}$ is a martingale, it has constant mean. Hence $\mathbb{E}(V_n) = \mathbb{E}(X_n) - \mathbb{E}(X_{n-1}) = 0$ for $n\in\mathbb{N}_+$.
4. Let $k,n\in\mathbb{N}$ with $k< n$. To show that $V_k$ and $V_n$ are uncorrelated, we just have to show that $\mathbb{E}(V_k V_n) = 0$ since $\mathbb{E}(V_n) = 0$. By $(3)$

$$
\begin{align*}
  \mathbb{E}(V_k V_n) &= \mathbb{E}[\mathbb{E}(V_k V_n |\mathcal{F}_k)] \\
  &= \mathbb{E}[V_k\mathbb{E}(V_n\mid \mathcal{F}_k)] = 0
\end{align*}
$$

To prove the formula for $\mathrm{var}(X_n)$, note that the variance of a sum of uncorrelated variables is the sum of the variances. Since $V_k$ has mean $0$, then $\mathrm{var}(V_k) = \mathbb{E}(V_k^2)$ for $k\in\mathbb{N}_+$. Hence it follows that

$$
  \mathrm{var}(X_n) = \sum_{k=0}^n \mathrm{var}(V_k) = \mathrm{var}(X_0) + \sum_{k=1}^n \mathbb{E}\left(V_k^2\right)
$$
</details>
</MathBox>

### Partial products

<MathBox title='Martingale conditions for partial products' boxType='proposition'>
Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is an sequence of indepedent random variables with $\mathbb{E}(|V_n|) < \infty$, and let

$$
  X_n = \prod_{k=0}^n V_k
$$

Then $\mathbf{X} = \{X_n\}$ is a partial products process associated with $\mathbf{V}$. For $n\in\mathbb{N}$, the process $\mathbf{X}$ is
1. martingale if $\mathbb{E}(V_n) = 0$
2. sub-martingale if $\mathbb{E}(V_n) \geq 1$
3. super-martingale if $\mathbb{E}(V_n)\leq 1$

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}} = \sigma\{V_i\}_{i=0}^{n\in\mathbb{N}}$. Since the random variables are independent

$$
  \mathbb{E}(X_n) = \prod_{k=0}^n \mathbb{E}(V_k) < \infty
$$

Next, since $X_n$ is measurable with respect to $\mathcal{F}_n$ and $V_{n+1}$ is indepedent of $\mathcal{F}_n$
$$
\begin{align*}
  \mathbb{E}(X_{n+1}\mid \mathcal{F}_n) \\
  &= X_n \mathbb{E}(V_{n+1}\mid \mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$

</details>
</MathBox>

### Likelihood ratio test

Let $(S,\mathcal{S},\mu)$ be a measure space. Suppose that $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}}$ is a sequence of independent, identically distributed random variables, taking values in $S$. In statistical terms, $\mathbf{X}$ corresponds to sampling from the common distribution, and a central statistical problem is to draw inferences about the distribution from observations of $\mathcal{X}$. Suppose that the underlying distribution either has probability density functions $g_0$ or $g_1$ with respect to a measure $\mu$. The Likelihood ratio test is a hypothesis test, where the null and alternative hyptheses are

- $H_0$: the probability density function is $g_0$
- $H_1$: the probability density function is $g_1$

The test is based on the test statistical

$$
  L_n = \prod_{i=1}^n \frac{g_0(X_i)}{g_i (X_i)},\; n\in\mathbb{N}
$$

known as the likelihood ratio test statistic. Small values of the test statistic are evidence in favor of the alternative hypothesis $H_1$.

<MathBox title='Likelihood ratio martingale' boxType='proposition'>
Under the alternative hypothesis $H_1$, the process $\mathbf{L} = \{ L_n \}_{n\in\mathbb{N}}$ is a martingale with respect to $\mathbf{X}$, known as the likelihood ratio martingale.

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{ X_i \}_{i=1}^n$. Since $L_n$ is measurable with respect to $\mathcal{F}_n$ and $\frac{g_0(X_{n+1})}{g_1(X_{n+1})}$ is independent of $\mathcal{F}_n$ we have

$$
  \mathbb{E}(L_{n+1}\mid\mathcal{F}_n) = \mathbb{E}\left[ L_n \frac{g_0(X_{n+1})}{g_1(X_{n+1})}\middle| \mathcal{F}_n \right] = L_n\mathbb{E}\left[\frac{g_0(X_{n+1})}{g_1(X_{n+1})}\middle| \mathcal{F}_n \right]
$$

Using the change of variables formula for expected value under $H_1$ gives

$$
  \mathbb{E}\left[\frac{g_0(X_{n+1})}{g_1(X_{n+1})}\middle| \mathcal{F}_n \right] = \int_S \frac{g_0(x)}{g_1(x)}g_1(x)\,\mathrm{d}\mu(x) = \int_S g_0(x)\,\mathrm{d}\mu(x) = 1
$$
</details>
</MathBox>

<MathBox title='Likelihood ratio martingale' boxType='proposition'>
Under the alternative hypothesis $H_1$, then $L_n \xrightarrow{n\to\infty} 0$ with probability $1$.

<details>
<summary>Proof</summary>

Assume that $H_1$ is true. Since $\mathbf{L}$ is a nonnegative martingale, the first martingale convergence theorem applies and there exists a random variable $L_\infty$ with values in $[0,\infty)$ such that $L_n \xrightarrow{n\to\infty} L_\infty$ with probability $1$. Note that

$$
  \ln{L_n} = \sum_{i=1}^n \ln\left[\frac{g_0(X_i)}{g_1(X_i)}\right]
$$

The variables $\ln\left[\frac{g_0(X_i)}{g_1(X_i)}\right]$ for $i\in\mathbb{N}_+$ are also independent and identically distributed, so let $m$ denote the common mean. The natural logarithm is concave and the martingale $\mathbf{L}$ has mean $1$, so by Jensen's inequality

$$
  m = \mathbb{E}\left(\ln\left[\frac{g_0(X_i)}{g_1(X_i)}\right]\right) < \ln\left(\mathbb{E}\left[\frac{g_0(X_i)}{g_1(X_i)}\right]\right) = \ln(1) = 0
$$

It follows that $m\in[-\infty, 0)$. By the strong law of large numbers, $\lim_{n\to\infty}\frac{1}{n}\ln(L_n) = m$ with probability $1$. Hence we must have $\lim_{n\to\infty} \ln(L_n) = -\infty$ with probability $1$. By continuity $\lim_{n\to\infty} (L_n) = \ln(L_\infty)$ with probability $1$ so $L_\infty = 0$ with probability $1$.
</details>
</MathBox>

Small values of $L_n$ are evidence in favor of $H_1$ and the decision rule is to reject $H_0$ in favor of $H_1$ if $L_n \leq l$ for a chosen critical value $l\in (0,\infty)$. If $H_1$ is true and the sample size $n$ is sufficiently large, we will reject $H_0$. Since $\mathbf{L}$ is a mean $1$ martingale (under $H_1$), $\lim_{n\to\infty}\mathbf{E}(L_n) = 1$ even though $\lim_{n\to\infty} L_n = 0$ with probability $1$. 

### Doob's martingale

<MathBox title="Doob's martingale" boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \}_{t\in T}$ is a filtration on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ and that $X$ is a real-valued random variable with $\mathbb{E}(|X|)< \infty$. Define $X_t = \mathbb{E}(X\mid \mathcal{F}_t)$ for $t\in T$. Then $\mathbf{X} = \{ X_t \}_{t\in T}$ is a martingale with respect to $\mathscr{F}$.

Note that $\mathbf{E}(|X|) < \infty$ implies that $X$ is uniformly integrable. Thus the second martingale convergence theorem states that every uniformly integrable martingale is a Doob martingale.

<details>
<summary>Proof</summary>

For $t\in T$, recall that $|X_t| = |\mathbb{E}(X\mid \mathcal{F}_t)| \leq \mathbb{E}(|X_t|\mid\mathcal{F}_t)$. Taking expected values gives $\mathbb{E}(|X_t|)\leq\mathbb{E}(|X|)< \infty$. Suppose that $s,t\in T$ with $s< t$. Using the tower property of conditional expected value

$$
  \mathbb{E}(X_t\mid \mathcal{F}_s) = \mathbb{E}\left[\mathbb{E}(X_t\mid \mathcal{F}_t)|\mathcal{F}_s \right] = \mathbb{E}(X_t\mid \mathcal{F}_s) = X_s
$$
</details>
</MathBox>

Doob's martingale arises naturally in Bayesian estimations. Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}}$ is a sequence of indepedent random variables whose common distribution depends on an unknown real-valued parameter $\theta$, with values in the parameter space $A\subseteq\mathbb{R}$. For each $n\in\mathbb{N}_+$ let $\mathcal{F}_n = \sigma\{X_i\}_{i=1}^n$ so that $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}_+}$ is the natural filtration associated with $\mathbf{X}$. In Bayesian estimation, we model the unknown parameter $\theta$ with a random variable $\Theta$ taking values in $A$ and having a specified prior distribution. The Bayesian estimator of $\theta$ based on the sample $\mathbf{X}_n = \{ X_i \}_{i=1}^n$ is 

$$
  U_n = \mathbb{E}(\Theta | \mathcal{F}_n),\; n\in\mathbb{N}
$$

It follows that the sequence of Bayesian estimators $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ is a Doob martingale.

<MathBox title='' boxType='proposition'>
Let $\mathbf{X} = \{X_t\}_{t\in T}$ be the Doob martingale constructed from $X$ and $\mathscr{F}$. Then $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$ and in mean, where

$$
  X_\infty = \mathbb{E}(X\mid \mathcal{F}_\infty)
$$
</MathBox>

### Density functions

For the following discussion, let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ a filtration in discrete time. Note that $\mathcal{F}_\infty = \sigma\left(\bigcup_{n=0}^\infty \mathcal{F}_n \right)$ Suppose that $\mu$ is a finite measure on the sample space $(\Omega,\mathcal{F})$. For each $n\in\mathbb{N}\cup\{\infty\}$, the restriction of $\mu$ to $\mathcal{F}_n$ is a measure on the measurable space $(\Omega,\mathcal{F}_n)$, and similarly the restriction of $\mathbb{P}$ to $\mathcal{F}_n$ is a probability measure on $(\Omega, \mathcal{F}_n)$. For simplicity, these will be referred to as $\mu$ and $\mathbb{P}$ of $\mathcal{F}_n$, respectively.

Suppose now that $\mu$ is absolutely continuous relative to $\mathbb{P}$ on $\mathcal{F}_n$ for each $n\in\mathbb{N}$. This means that if $A\in\mathcal{F}_n$ and $\mathbb{P}(A) = 0$ then $\mu(B) = 0$ for every $B\in\mathcal{F}_n$ with $B\subseteq A$. By the Radon-Nikodym theorem, $\mu$ has a density function $X_n :\Omega\to\mathbb{R}$ with respect to $\mathbb{P}$ on $\mathcal{F}_n$ for each $n\in\mathbb{N}_+$, which is known as the Radon-Nikodym derivative.

<MathBox title='' boxType='proposition'>
The sequence of density functions $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

By definition $X_n$ is measurable with respect to $\mathcal{F}_n$. Also $\mathbb{E}(|X_n|) = \lVert\mu\rVert$, i.e. the total variation of $\mu$, for each $n\in\mathbb{N}$. Since $\mu$ is a finite measure $\lVert\mu\rVert < \infty$. By definition

$$
  \mu(A) = \int_A X_n\;\mathrm{d}\mathbb{P} = \mathbb{E}(X_n; A),\; A\in\mathcal{F}_n
$$

On the other hand, if $A\in\mathcal{F}_n$ then $A\in\mathcal{F}_{n+1}$ and so $\mu(A) = \mathbb{E}(X_{n+1};A)$. Since $X_n$ is measurable with respect to $\mathcal{F}_n$ and $\mathbb{E}(X_{n+1};A) = \mathbb{E}(X_n;A)$ for all $A\in\mathcal{F}_n$, if follows that $\mathbb{E}(X_{n+1}\mid \mathcal{F}_n) = X_n$. Hence $\mathbf{X}$ is a martingale relative to $\mathscr{F}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
There exists a random variable $X_\infty$ such that $X_n \xrightarrow{n\to\infty} X_\infty$ with probability $1$.

1. If $\mu$ is absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$ then $X_\infty$ is a density function of $\mu$ with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$.
2. If $\mu$ and $\mathbb{P}$ are mutually singular on $\mathcal{F}_\infty$ then $X_\infty = 0$ with probability $1$.

<details>
<summary>Proof</summary>

Since $\mu$ is a finite measure, $\lVert\mu\rVert < \infty$ and the first martingale convergence applies. Thus, there exists a random variable $X_\infty$ measurable relative to $\mathcal{F}_\infty$ such that $X_n \xrightarrow{n\to\infty}X_\infty$.

1. If $\mu$ is absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$, then $\mu$ has a density function $Y_\infty$ with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$. It remains to show that $X_\infty = Y_\infty$ with probability $1$. By definition $Y_\infty$ is measurable with respect to $\mathcal{F}_\infty$ and

$$
  \int_A Y_\infty\;\mathrm{d}\mathbb{P} = \mathbb{E}(Y_\infty; A) = \mu(A),\; A\in\mathcal{F}_\infty
$$

Suppose that $n\in\mathbb{N}$ and $A\in\mathcal{F}_n$. By definition $\mathbb{E}(X_n;A) = \mu(A)$. Since $A\in\mathcal{F}_\infty$, then $\mathbb{E}(Y_\infty;A) = \mu(A)$. Also, since $X_n$ is measurable relative to $\mathcal{F}_n$ it follows that $X_n = \mathbb{E}(Y_\infty |\mathcal{F}_n)$, showing that $\mathbf{X}$ is the Doob martingale associated with $Y_\infty$. By the convergence property of Doob martingales $X_\infty = \mathbb{E}(X_\infty|\mathcal{F}_\infty) = Y_\infty$ with probability $1$ as $n\to\infty$.

2. Suppose that $\mu$ and $\mathbb{P}$ are mutually singular on $\mathcal{F}_\infty$. Assume first that $\mu$ is a positive measure, so that $X_n$ is nonnegative for $n\in\mathbb{N}\cup{\infty}$. By the definition of mutual singularity, there exists $B\in\mathcal{F}_\infty$ such that $\mu_\infty (B) = 0$ and $\mathbb{P}_\infty(B^c) = 0$, so that $\mathbb{P}(B) = 1$. We need to show that $\mathbb{E}(X_\infty; A) \leq \mu(A)$ for every $A\in\mathcal{F}_\infty$. Let

$$
  \mathcal{M} = \{ A\in\mathcal{F}_\infty \mid \mathbb{E}(\mathcal{F}_\infty; A)\leq\mu(A) \}
$$

Suppose that $A\in\bigcup_{k=0}^\infty \mathcal{F}_k$ so that $A\in\mathcal{F}_k$ some $k\in\mathbb{N}$. Then $A\in\mathcal{F}_n$ for all $n\geq k$ and therefore $\mathbb{E}(X_n;A) = \mu(A)$ for all $n\geq k$. By Fatou's lemmas

$$
  \mathbb{E}(X_\infty; A) \leq\liminf_{n\to\infty} \mathbb{E}(X_n;A)\leq\mu(A)
$$

showing that $A\in\mathcal{M}$. Suppose that $\{A_n \}_{n\in\mathbb{N}}$ is an increasing or decreasing sequence in $\mathcal{M}$, and let $A_\infty = \lim_{n\to\infty} A_n$ (the union in the increasing case, and the intersection in the second case). Then $\mathbb{E}(X_\infty;A_n) \leq \mu(A_n)$ for each $n\in\mathbb{N}$. By the continuity theorems, $\mathbb{E}(X_\infty;A_n) \xrightarrow{n\to\infty}\mathbb{E}(X_\infty;A_\infty)$ and $\mu(A_n)\xrightarrow{n\to\infty}\mu(A_\infty)$. Therefore $\mathbb{E}(X_\infty; A_\infty) \leq \mu(A_\infty)$ and so $A_\infty \in\mathcal{M}$. It follows that $\mathcal{M}$ is a monotone class. Since $\mathcal{M}$ contains the algebra $\bigcup_{n=0}^\infty \mathcal{F}_n$, it follows from the monotone class theorem that $\mathcal{F}_\infty \subseteq\mathcal{M}$. In particular $B\in\mathcal{M}$, so $\mathbb{E}(X_\infty) = \mathbb{E}(X_\infty;B)\leq\mu(B) = 0$ and therefore $X_\infty = 0$ with probability $1$. If $\mu$ is a general finite measure, the by the Jordan decomposition theorem, $\mu$ can be written uniquely in the form $\mu = \mu^+ - \mu^-$ where $\mu^+$ and $\mu^-$ are finite positive measures. Moreover, $X_n^+$ is the density function of $\mu^+$ on $\mathcal{F}_n$ and $X_n^-$ is the density function of $\mu^-$ on $\mathcal{F}_n$. By the first part of the proof $X^+ = 0 = X^-$ so $X = 0$ all with probability $1$.
</details>
</MathBox>

In certain cases, martingales can be used to give a probabilistic proof of the Radon-Nikodym theorem. Starting from a sample set $\Omega$, suppose that $\mathcal{A}_n = \{ A_i^n \}_{i\in I_n}$ is a countable partition of $\Omega$ for each $n\in\mathbb{N}$. That is, $I_n$ is countable, $A_i^n \cap A_j^n = \emptyset$ for distinct $i, j\in I_n$ and $\bigcup_{i\in I_n} A_i^n = \Omega$. Suppose also that $\mathcal{A}_{n+1}$ refines $\mathcal{A}_n$ for each $n\in\mathbb{N}$ in the sense that $A_i^n$ is a union of sets in $\mathcal{A}_{n+1}$ for each $i\in I_n$. 

Let $\mathcal{F}_n = \sigma(\mathcal{A}_n)$. Thus $\mathcal{F}_n$ is generated by a countable partition, and the sets in $\mathcal{F}_n$ are of the form $\bigcup_{j\in J} A_j^n$ where $J\subseteq I_n$. By the refinement property $\mathcal{F}_n\subseteq\mathcal{F}_{n+1}$ so that $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ is a filtration. Let $\mathcal{F} = \mathcal{F}_\infty = \sigma\left( \bigcup_{n=0}^\infty \mathcal{F}_n \right) = \sigma\left( \bigcup_{n=0}^\infty \mathcal{A}_n \right)$, forming the sample space $(\Omega,\mathcal{F})$. Suppose that $\mathbb{P}$ is a probability measure on $(\Omega,\mathcal{F})$ with the property that $\mathbb{P}(A_i^n) > 0$ for $n\in\mathbb{N}$ and $i\in I_n$. These constructions gives the probability space $(\Omega,\mathcal{F},\mathbb{P})$.

Suppose that $\mu$ is a finite measure on $(\Omega,\mathcal{F})$. By assumption, the only null set for $\mathbb{P}$ on $\mathcal{F}_n$ is $\emptyset$, making $\mu$ automatically absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}_n$.

<MathBox title='' boxType='proposition'>
The density function of $\mu$ with respect to $\mathbb{P}$ on $\mathcal{F}_n$ is the random variable $X_n$ defined by

$$
  X_n := \sum_{i\in I_n}\frac{\mu(A_i^n)}{\mathbb{P}(A_i^n)}\mathbf{1}(A_i^n)
$$

<details>
<summary>Proof</summary>

We need to show that $\mu(A) = \mathbb{E}(X_n;A)$ for each $A\in\mathcal{F}_n$. Suppose that $A = \bigcup_{j\in J} A_j^n$ where $J\subseteq I_n$, then

$$
\begin{align*}
  \mathbb{E}(X_n;A) &= \sum_{j\in J}\mathbb{E}(X_n;A_j^n) \\
  &= \sum_{j\in J}\frac{\mu(A_j^n)}{\mathbb{P}(A_j^n)}\mathbb{P}(A_j^n) \\
  &= \sum_{j\in J}\mu(A_j^n) = \mu(A)
\end{align*}
$$
</details>
</MathBox>

For a concrete example, consider $\Omega = [0,1)$. For $n\in\mathbb{N}$ let

$$
  \mathcal{A}_n = \left\{ \left[\frac{j}{2^n}, \frac{j+1}{2^n} \right)\right\}_{j=0}^{2^n -1}
$$

This is the partition of $[0,1)$ into $2^n$ subintervals of equal length $1/2^n$ based on the dyadic rationals of rank $n$ or less. Note that every interval in $\mathcal{A}$ is the union of two adjacent intervals in $\mathcal{A}_{n+1}$, so the refinement property holds. Let $\mathbb{P}$ be the ordinary Lebesgue measure on $[0,1)$ so that $\mathbb{P}(A_i^n) = 1/2^n$ for $n\in\mathbb{N}$ and $i\in \{0,1,\dots,2^n-1\}$. Let $\mathcal{F}_n = \sigma(\mathcal{A}_n)$ and $\mathcal{F} = \sigma\left(\bigcup_{n=0}^\infty \mathcal{F}_n \right) = \sigma\left( \bigcup_{n=0}^\infty \mathcal{A}_n \right)$. Since the dyadic rationals are dense in $[0,1)$, it follows that $\mathcal{F}$ is the ordinary Borel $\sigma$-algebra on $[0,1)$. Thus, our probability space $(\Omega,\mathcal{F},\mathbb{P})$ is simply $[0,1)$ with the usual Euclidean structures. If $\mu$ is a finite measure on $([0,1),\mathcal{F})$ then the density function $\mu$ on $\mathcal{F}_n$ is the random variable $X_n$ whose value on the interval $\left[\frac{j}{2^n}, \frac{j+1}{2^n} \right]$ is

$$
  2^n \mu\left[\frac{j}{2^n}, \frac{j+1}{2^n}\right]
$$

If $\mu$ is absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}$, then a density function of $\mu$ is $X = \lim_{n\to\infty} X_n$.

# Brownian motion

## Wiener process (Standard Brownian motion)
<MathBox title='Wiener process' boxType='definition'>
A Wiener process is a random process $\mathbf{W} = \{ W_t \}_{t\geq 0}$ with state space $\mathbb{R}$ that satisfies the following properties:
1. $\mathbb{P}(W_0 = 0) = 1$
2. $\mathbf{W}$ has stationary increments, i.e. for $s,t\in[0,\infty)$ with $s < t$, the distribution of $W_t - W_s$ is the same the distribution of $W_{t-s}$.
3. $\mathbf{W}$ has independent increments, i.e for $t_1, t_2, \dots,t_n\in[0,\infty)$ with $t_1 < t_2 < \dots < t_n$ the random variables $W_{t_1}, W_{t_2} - W_{t_1}, \dots, W_{t_n} - W_{t_{n-1}}$ are independent
4. $W_t$ is normally distributed with mean $\mathbb{E}(W_t) = 0$ and variance $\mathrm{var}(W_t) = t$ for each $t\in(0,\infty)$
5. $t\mapsto W_t$ is continuous on $[0,\infty)$ with probability $1$ 
</MathBox>

<MathBox title='' boxType='proposition'>
Let $\mathbf{W} = \{W_t\}_{t\geq 0}$ be a Wiener process. By definition $W_t$ has the probability density function

$$
  f_t (x) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}
$$

Then $\mathbf{X}$ is a Gaussian process with the following properties
1. if $0 < t_1 < t_2 < \dots < t_n < \infty$ then $\left(W_{t_1}, W_{t_2},\dots,W_{t_n}\right)$ has probability density function for $(x_1, x_2,\dots, x_n)\in\mathbb{R}^n$

$$
  f_{t_1,t_2,\dots,t_n}(x_1,x_2,\dots,x_n) = f_{t_1}(x_1)f_{t_2 - t_1}(x_2 - x_1)\cdots f_{t_n - t_{n-1}}(x_n - x_{n-1})
$$

2. mean function $m(t) = 0$ for $t\in[0,\infty)$
3. covariance function $c(s,t) = \min\{s,t\}$ for $s,t\in[0,\infty)$
4. $\mathbb{E}\left(W_t^{2n}\right) = \frac{(2n)!t^n}{n!2^n}$
5. $\mathbb{E}\left(W_t^{2n-1}\right) = 0$
6. moment generating function $\mathbb{E}(e^{uX_t}) = e^{tu/2}$ for $u\in\mathbb{R}$ 

<details>
<summary>Proof</summary>

</details>
</MathBox>

### Wiener isometry
<MathBox title='Wiener isometry' boxType='theorem'>
Let $\mathbf{W} = \{ W_t\}_{t\geq 0}$ be a Wiener process on the probability space $(\Omega,\mathcal{F},\mathbb{P})$. For any nonempty interval $J\subseteq\mathbb{R}_+$, the mapping $\mathbf{1}_{(s,t]} \mapsto W_t - W_s$ extends to a linear isometry $I_W : L^2(J)\to L^2(\Omega,\mathcal{F},\mathbb{P})$. For every function $f\in L^2(J)$, the random variable $I_W (f)$ is mean-zero Gaussian.

<details>
<summary>Proof</summary>

Note that for $L^2[0,1]$ and $s, t\in(0,1]$

$$
  \langle \mathbf{1}_{[0,t]}, \mathbf{1}_{[0,s]} \rangle = \min\{s,t\} = \langle W_t \rangle
$$

Let $H_0$ be the set of all finite linear combinations of indicators functions $1$. Then $H_0$ is a dense, linear, subspace of $L^2(J)$. Since $I_W$ is a linear isometry of $H_0$, it extends uniquely to a linear isometry of $L^2 (J)$ by results from Hilbert space theory.

It remains to show that the random variable $I_W(f)$ for any $f\in L^2(J)$ must be mean-zero Gaussian. Since $H_0$ is dense in $L^2(J)$, there exists a sequence $(f_n)_{n\in\mathbb{N}}$ in $H_0$ such that $\lim_{n\to\infty} f_n = f\in L^2(J)$ for $n\in\mathbb{N}$. Since $I_W$ is a linear isometry, it follows that $\lim_{n\to\infty} I_W (f_n) = I_W (f)\in L^2(J)$. Note that convergence in $L^2$ implies convergence in measure, which in turn implies convergence in distribution. In particular, for any $\theta\in\mathbb{R}$

$$
  \lim_{n\to\infty} \mathbb{E}e^{i\theta I_X(f_n)} = \mathbb{E}e^{i\theta I_X(f)}
$$

Each of the random variables has a centered Gaussian distribution, and consequently has a characteristic function

$$
  \mathbb{E}e^{i\theta I_W(f_n)} = e^{-\theta^2 \sigma_n^2 / 2} 
$$

The weak convergence of these random variables implies that $\lim_{n\to\infty} \sigma_n^2 = \sigma^2$ and that $I_W (f)$ has characteristic function

$$
  \mathbb{E}e^{i\theta I_W(f)} = e^{-\theta^2 \sigma^2 / 2}
$$

Hence $I_W(f)$ has a Gaussian distribution with mean $0$ and variance $\sigma^2$.
</details>
</MathBox>

The Hilbert space isometry $I_W$ suggests that Wiener processes can be represented with orthonormal bases. If $\{ \psi_n \}_{n\in\mathbb{N}}$ is an orthonormal basis of $L^2[0,1]$, then $\{ I_W (\psi) \}_{n\in\mathbb{N}}$ must be an orthonormal set in $L^2 (\Omega,\mathcal{F},\mathbb{P})$. Since uncorrelated Gaussian variables are necessarily independent, it follows that the standard normal variables $\Z_{n} := I_W (\psi_n)$ must be indepedent, identically distributed. By linear isometry, $I_W$ must map the $L^2[0,1]$-series expansion of $\mathbf{1}_{[0,t]}$ for $t\in(0,1]$ in the basis $\psi_n$ to the series expansion of $X_t$ in the basis $\xi_n$ 

<MathBox title='' boxType='corollary'>
Suppose that $(Z_n)_{n\in\mathbb{N}}$ is a sequence of independent, standard normally distributed variables, and let $\{\psi_n\}_{n\in\mathbb{N}}$ be an orthonormal basis of $L^2[0,1]$. Then for every $t\in[0,1]$, the infinite series

$$
  W_t := \sum_{n=1}^\infty Z_n \langle \mathbf{1}_{[0,t]}, \psi_n \rangle
$$

converges in the $L^2$-metric, and the resulting stochastic process $\{ W_t \}_{t\geq 0}$ is a mean-zero Gaussian process with covariance function

$$
  \mathrm{cov}(W_t, W_s) = \min\{s,t\}
$$
</MathBox>

Wiener was able to show by brute forces that for the particular basis $\psi_n = (x) = \sqrt{2}\cos(\pi n x)$, the series

$$
  W_t = \sum_{n=1}^\infty Z_n \langle \mathbf{1}_{[0,t]}, \psi_n \rangle
$$

converges not only in $L^2$, but also uniformly in $t$. This basis gives the following presentation of a Wiener process with continuous paths: 

$$
  W_t = Z_0 t + \sum_{k=1}^\infty \sum_{n=2^{k-1}}^{2^k-1} n^{-1}Z_n \sqrt{X}\sin(\pi n t)
$$

### Lévy's construction

Lévy discovered that the Haar wavelet basis is a more natural orthonormal basis for the construction of the Wiener process. The Haar mother wavelet function $h:\mathbb{R}\to\{-1, 0, 1\}$ is defined as

$$
  h(t) := \begin{cases} 
    1 \quad& 0\leq t \leq \frac{1}{2} \\ 
    -1 \quad& \frac{1}{2} < t \leq 1 \\
    0 \quad& t < 0 \land t > 1
  \end{cases}
$$

For any $n\in\mathbb{N}$ and $0\leq k < 2^n$ the Haar function $h_{n,k}:\mathbb{R}\to\mathbb{R}$ is defined as

$$
  h_{n,k} (t) := 2^{n/2}h(2^n t - k)
$$

This function has support on the dyadic intervals $I_{n,k} = \left[\frac{k}{2^n}, \frac{k+1}{2^n}\right]$ with length $|I_{n,k}| = \frac{1}{2^n}$. Since $|h_{n,k}| = 2^{n/2}$ on $I_{n,k}$ it follows that 

$$
  \lVert h_{n,k} \rVert_{2}^2 = \int_\mathbb{R} |h_{n,k}(t)|^2\,\mathrm{d}t = 2^n \int_{I_{n,k}} \,\mathrm{d}t = 1
$$

Furthermore, the Haar functions are mutually orthogonal

$$
  \langle h_{n,k}, h_{m,l} \rangle = \int_{R} h_{n,k} h_{m,l}\,\mathrm{d}t = \delta_{nm}\delta_{kl}
$$

The Haar functions therefore form an orthonormal basis that is complete on $L^2[0,1]$ (not proved here). For the Haar basis the inner products of the series $X_t = \sum_{n=1}^\infty \Z_n \langle \mathbf{1}_{[0,t]}, \psi_n \rangle$, define the Shauder functions $G_{n,k}$

$$
  G_{n,k}(t) = \langle\mathbf{1}_{[0,t]}, h_{n,k}\rangle = \int_0^t h_{n,k}(s)\,\mathrm{d}s
$$

<MathBox title='' boxType='theorem'>
If the random variables $\Z_{n,k}$ are independent, standard normally distributed then

$$
  W_t := Z_{0,1}t + \sum_{n=1}^\infty \sum_{k=0}^{2^n - 1} Z_{n,k} G_{n, k}(t)
$$

converges uniformly with probability 1 for $t\in[0,1]$ and the limit function $X_t$ is a standard Wiener process.

<details>
<summary>Proof</summary>

Recall that if $Z$ is a standard normal random variable, then for every $x > 0$

$$
  \mathbb{P}(|Z| \geq x) \leq \frac{2}{\sqrt{2\pi}x}e^{-\frac{x^2}{2}}
$$

By the Wiener isometry corollary, the random variables $X_t$ defined in terms of Schauder functions are centered Gaussians with covariances that agree with the covariances of a Wiener process. To prove that this series defines a Brownian motion, it suffices to show that the series converges uniformly for $t\in[0,1]$ with probability $1$.

The Schauder function $G_{n,k}$ has maximum value $2^{-n/2}$, so to prove that the series converges uniformly, it suffices to show with probability $1$ that

$$
  \sum_{n=1}^\infty \sum_{k=1}^{2^m} \frac{|Z_{n,k}|}{2^{m/2}} < \infty
$$

To do this we will use the Borel-Cantelli lemma and the tail estimate for the normal distribution to show that with probability $1$, there is a (possibly random) $m_*$ such that for all $n \geq n_*$

$$
  \max_k (|Z_{n,k}|) \leq 2^{n/4}
$$

This will imply that almost surely, the series is eventually dominated by a multiple of the geometric series $\sum 2^{-(n+2)/4}$, and consequently converges uniformly in $t$. It suffices to show that the probabilities of the complementary events are summable. By the tail estimate for the normal distribution

$$
  \mathbb{P}(|Z_{n,k} \geq 2^{n/4}|) \leq\frac{4}{2^{n/4}\sqrt{2\pi}}e^{-2^{n/2}}
$$

Hence, by the Bonferroni inequality (crude union bound)

$$
  \mathbb{P}(\max_{k\in[1, 2^n]}(|Z_{n,k}|) \geq 2^{n/4}} \leq 2^n 2^{-n/4} \sqrt{2/\pi}e^{-2^{n-1}}
$$

Since this bound is summable in $n$, the Borell-Cantelli lemma implies that $\max_k (|Z_{n,k}|)\leq 2^{n/4}$ must hold with probability $1$. This proves the series in theorem converges uniformly with probability $1$, and thus $X_t$ is continuous.
</details>
</MathBox>

### Brownian motion as a limit of random walks

Wiener process is in a sense a limit of rescaled simple random walks. Let $\mathbf{X} = (X_n)_{n\in\mathbb{N}+}$ be the symmetric simple random walk. Thus $X_n = \sum_{i=1}^n U_i$ where $\mathbf{U} = (U_n)_{n\in\mathbb{N}}$ is a sequence of independent variables with $\mathbf{P}(U_n = 1) = \mathbf{P}(U_n = -1) = \frac{1}{2}$. Recall that $\mathbb{E}(X_n) = 0$ and $\mathrm{var}(X_n) = n$ for $n\in\mathbb{N}$. Since $\mathbf{X}$ is the partial sum process associated with an indepedent, identically distributed sequence, $\mathbf{X}$ has stationary, indepedent increments. By the central limit theorem, $\frac{X_n}{\sqrt{n}}$ converges to a standard normal distribution as $n\to\infty$.

For $h,d\in(0,\infty)$ the continuous time process

$$
  X_{h,d} = \{dX_{\lfloor t/h \rfloor}\}_{t\in(0,\infty)}
$$

is a jump process with jumps at $\{ nh \}_{n\in\mathbb{N}}$, and with jumps of sized $\pm d$. Note that $\mathbf{E}[X_{h,d}(t)] = 0$ and $\mathrm{var}[X_{h,d}(t)] = d^2\lfloor t/h \rfloor$. If $d = \sqrt{h}$, then by the central limit theorem the distribution of $X_{h,d}(t)$ will converge to the normal distribution with mean $0$ and variance $t$ as $h\downarrow 0$.

### Transformations

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\geq 0}$ is a Wiener process. The following transforms preserve the Wiener process:

1. $\mathbf{Y} = \{ Y_t \}_{t\geq 0}$ with $Y_t = -X_t$ (spatial reflection)
2. $\mathbf{Y} = \{ Y_t \}_{t\geq 0}$ with $Y_t = X_{s+t} - X_s$ for some $s\in[0,\infty)$ (shift)
3. $\mathbf{Y} = \{ Y_t \}_{t\in[0,T]}$ with $Y_t = X_{T-t} - X_T$ for $0\leq t \leq T$ (time reversal)
4. $\mathbf{Y} = \{ Y_t \}_{t\geq 0}$ with $Y_t = \frac{1}{a}X_{a^2 t}$ (temporal and spatial scaling invariance)
5. $\mathbf{Y} = \{ Y_t\}_{t\geq 0}$ with $Y_0 = 0$ and $Y_t = tX_{1/t}$ (time inversion)

<details>
<summary>Proof</summary>

1. Clearly $\mathbf{Y}$ is a Gaussian process, with mean function $\mathbb{E}(-X_t) = -\mathbf{E}(X_t) = 0$ for $t\in[0,\infty)$ and covariance function $\mathrm{cov}(-X_s, -X_t) = \mathrm{cov}(X_s, X_t) = \min\{s,t\}$ for $s,t\in[0,\infty)$. Since $\mathbf{X}$ is continuous, so is $\mathbf{Y}$.
2. Since $\mathbf{X}$ has stationary, independent increments, the process $\mathbf{Y}$ is equivalent in distribution to $\mathbf{X}$. Since $\mathbf{X}$ is continuous, so is $\mathbf{Y}$.
3. $\mathbf{Y}$ is a Gaussian process, since a finite, linear combination of variables from this process reduces to a finite, linear combination of variables from $\mathbf{X}$. Next, $\mathbb{E}(Y_t) = \mathbb{E}(X_{T-t}) - \mathbb{E}(X_T) = 0$. If $s,t\in[0,T]$ with $s\leq t$ then

$$
\begin{align*}
  \mathrm{cov}(Y_s, Y_t) &= \mathrm{cov}(X_{T-s} - X_T, X_{T-t} - X_t) \\
  &= \mathrm{cov}(X_{T-s},X_{T-t}) - \mathrm{cov}(X_{T-s},X_T) - \mathrm{cov}(X_T,X_{T-t}) + \mathrm{cov}(X_T,X_t) \\
  &= (T-t) - (T-s) - (T-t) + T = s
\end{align*}
$$

Since $t\mapsto X_t$ is continuous on $[0,T]$ with probability $1$, then so is $t\mapsto Y_t$.
4. $\mathbf{Y}$ is a Gaussian process, since finite, linear combinations of variables in $Y$ reduce to finite, linear combinations of variables in $\mathbf{X}$. Next, $\mathbb{E}(Y_t) = a\mathbb{E}(X_{a^2t) = 0$ for $t \geq 0$. If $0 < s < t$

$$
  \mathrm{cov}(Y_s, Y_t) = \mathrm{cov}\left(\frac{1}{a}X_{a^2s}, \frac{1}{a}X_{a^2t} \right) = \frac{1}{a^2}\mathrm{cov}(X_{a^2s}, \mathrm{cov}_{a^2t}) = \frac{1}{a^2}a^2 s = s
$$

Finally, $\mathbf{Y}$ is continuous since $\mathbf{X}$ is continuous.

5.  $\mathbf{Y}$ is a Gaussian process, since finite, linear combinations of variables in $Y$ reduce to finite, linear combinations of variables in $\mathbf{X}$. Next, $\mathbf{E}(Y_t) = t\mathbb{E}(X_{1/t}) = 0$ for $t > 0$ and for $s,t > 0$ with $s < t$

$$
  \mathrm{cov}(Y_s, Y_t) = \mathrm{cov}(sX_{1/s},tX_{1/t}) = st\mathrm{cov}(X_{1/s}, X_{1/t}) = st\frac{1}{t} = s
$$

Since $t\mapsto X_t$ is continuous on $[0,\infty)$ with probability $1$, it follows that $t\mapsto Y_t$ is continuous on $(0,\infty)$ with probability $1$. To prove continuity at $t = 0$, we need to show that $tX_{1/t} \xrightarrow{t\downarrow 0} 0$ with probability $1$, or equivalently $\frac{X_s}{s}\xrightarrow{s\uparrow\infty}0$. This statement holds by the law of iterated logarithm.
</details>
</MathBox>

### Irregularity

<MathBox title='' boxType='proposition'>
A Wiener process $\mathbf{W}$ is nowhere differentiable on $[0,\infty)$ with probability $1$.

<details>
<summary>Proof</summary>

It suffices to show that the path $\mathbf{W}$ is not differentiable at any $t\in(0,1)$. Suppose the contrary that the path is differentiable at $t = t_* \in (0,1)$. Then for some $\varepsilon > 0$ and $C < \infty$

$$
  |W_t - W_{t_*}| \leq C|t-t_*|,\; \forall t\in(t_* - \varepsilon, t_* + \varepsilon)
$$

that is, the graph of $\mathbf{W}$ would lie between two intersecting lines of finite slope in some neighbourhood of their intersection. By the triangle inequality, there would be some $0\leq m \leq 4^k$ for infinitely many $k\in\mathbb{N}$ such that

$$
  \left|W_{\frac{m+i+1}{4^k}} - W_{\frac{m+i}{4^k}}\right| \leq \frac{16C}{4^k}\, \forall $i\in\{0,1,2\}$
$$

We will show that the probability for this event is $0$. Let $B_{m,k} = B_{k,m}(C)$ be the event where this inequality holds, and set

$$
  B_k = \bigcup_{m\leq 4^k} B_{m,k}
$$

Then by the Borel-Cantelli lemma it is enough to show that

$$
  \sum_{k=1}^\infty \mathbb{P}(B_m) < \infty
$$

For all $s,t\geq 0$, the increment $W_{t+s} - W_t$ is Gaussian with mean $0$ and standard deviation $\sqrt{s}$. Consequently, since the tree increments in the inequality are independent, each with standard deviation $2^{-k}$, and since the standard normal density is bounded above by $\frac{1}{\sqrt{2\pi}}$, it follows that

$$
  \mathbb{P}(B_{m,k}) = \mathbb{P}\left(|Z| \leq \frac{16C}{2^k}\right)^3 \leq \left(\frac{32C}{2^k\sqrt{2\pi}}\right)^3
$$

where $Z$ is the standard normal. Since $B_k$ is the union of $4^k$ such events, it follows that

$$
  \mathbb{P}(B_k) \leq 4^k\left(\frac{32C}{2^k\sqrt{2\pi}}\right)^3 \leq \frac{1}{2^k}\left(\frac{32C}{\sqrt{2\pi}}\right)^3 < \infty
$$
</details>
</MathBox>

<MathBox title='Incremental bound of Brownian motions' boxType='proposition'>
Let $\mathbf{W} = \{W_t\}_{t\geq 0}$ be a Wiener process. 

1. There exists a constant $c > 0$ such that, almost surely, for sufficiently small $h > 0$ and all $t\in [0,1-h]$

$$
  |W_{t+h} - W_t| \leq c\sqrt{h\ln\left(\frac{1}{h} \right)}
$$

2. For all $c < \sqrt{2}$, then almost surely for $\varepsilon > 0$ there exists $0 < h < \varepsilon$ and $t\in[0,1-h]$ with

$$
  |W_{t+h} - W_t| \geq c\sqrt{h\ln\left(\frac{1}{h} \right)}
$$

<details>
<summary>Proof</summary>

**Lower incremental bound**
From Lévy's construction

$$
  W_t = \sum_{n = 1}^\infty F_n (t) = Z_{0,1}t + \sum_{n=1}^\infty \sum_{k=0}^{2^n - 1} Z_{n,k} G_{n, k}(t)
$$

By the tail estimate of the standard normal distribution, it follows that for any $c > \sqrt{2\ln(2)}$ 

$$
  \lVert F_n \rVert_\infty < c\sqrt{n}2^{-n/2}$ for any $c \geq \sqrt{2\ln(2)}
$$

and there exists a random $N \in\mathbb{N}$ such that for all $n > N$

$$
  \lVert F_n' \rVert_\infty \leq \frac{2}{2^{-n}}\lVert F_n \rVert_\infty \leq 2c\sqrt{n}2^{n/2}
$$

By the mean value theorem, for all $m > N$

$$
\begin{align*}
  |W_{t+h} - W_t| \leq \sum_{n=0}^\infty |F_n (t + h) - F_n(t)| &\leq \sum_{n=0}^m h\lVert F'_n \rVert_\infty + \sum_{n=m+1}^\infty 2\lVert F_n \rVert_\infty \\
  &\leq h\sum_{n=0}^N \lVert F'_n \rVert + 2ch\sum_{n=N}^m \sqrt{n}2^{n/2} + 2c\sum_{n=m+1}^\infty \sqrt{n}2^{-n/2}
\end{align*}
$$

Suppose that $h$ is small enough such that the first summand is smaller than $\sqrt{h\ln(\frac{1}{h})}$ and that $m$ defined by $2^{-m} < h \leq 2^{-m+1}$ exceeds $N$. For this choise of $m$ the second and third summands are bounded constant multiples of $\sqrt{h\ln\frac{1}{h}}$ as both sums are dominated by their largest elements. It follows that

$$
  |W_{t+h} - W_t| \leq C\sqrt{h\ln\left(\frac{1}{h} right)}
$$

**Upper incremental bound**

Let $c < \sqrt{2}$, and for $k, n \in\mathbb{N}$ define the events

$$
  A_{k,n} = \{ W_{(k+1)^e^{-n}} - W_{ke^{-n}} > c\sqrt{n} e^{-n/2} \}
$$

By the tail estimate for a normal distribution

$$
  \mathbb{P}(A_{k,n}) = \mathbb{P}(W_{e^n} > c\sqrt{n}e^{-n/2}) = \mathbb{P}(W_1 > c\sqrt{n}) \geq \frac{c\sqrt{n}}{c^2 n + 1}e^{-c^2 n/2}
$$

By our assumption on $c$, we have $e^n\mathbb{P}(A_{k,n}) \xrightarrow{n\to\infty}\infty$. Using the fact that $1 - x \leq e^{-x}$ for all $x\in\mathbb{R}$

$$
  \mathbb{P}\left(\bigcup_{k=0}^{\lfloor e^n - 1 \rfloor} A_{k,n}^c \right) = (1 -\mathbb{P}(A_{0,n}))^{e^n} \leq \exp(e^n\mathbb{P}(A_{0,n})) \xrightarrow{n\to\infty} 0
$$

Letting $h = e^{-n}$, then for any $\varepsilon > 0$, $h\in(0,\varepsilon)$ and $t\in[0,1-h]$ it follows that

$$
  |W_{t+h} - W_t| \leq c\sqrt{h\ln\left(\frac{1}{h} right)}
$$

with probability $0$.
</details>
</MathBox>

<MathBox title='Hölder continuity of Brownian motions' boxType='proposition'>
Let $\mathbf{W}$ be a Wiener process.

1. If $\alpha < \frac{1}{2}$, then $\mathbf{W}$ is almost surely everywhere locally $\alpha$-Hölder continuous.1
2. If $\alpha > \frac{1}{2}$, then $\mathbf{W}$ almost surely fails to be everywhere locally $\alpha$-Hölder continuous.

<details>
<summary>Proof</summary>

1. Let $c < 0$ be defined such that for sufficiently small $h > 0$

$$
  |W(t + h) - W(t)| \leq c\sqrt{h\ln\left(\frac{1}{h}\right)}
$$

Applying this to the Brownian motions $\{ W_t - W_k \}_{t\in[k,k+1]}$ for $k\in\mathbb{N}$, then almost surely for every $k$ there exists $h_k$ such that for all $t\in[k,k+1]$ and $h$ with $0 < h < (k + 1 - h) \lor h_k$

$$
  |W(t + h) - W(t)| \leq c\sqrt{h\ln\left(\frac{1}{h}\right)} \leq Ch^\alpha
$$

2. Let $\varepsilon < \frac{1}{e}$. By the upper bound of Brownian increments there exists $0 < h < \varepsilon$, $c > 0$ and $t\in[0,1-h]$ with

$$
  |W(t + h) - W(t)| \geq c\sqrt{h\ln\left(\frac{1}{h}\right)} = \sqrt{h}\sqrt{\ln\left(\frac{1}{h}\right)}
$$

Letting $\varepsilon\to\infty$, there exists an $h$ such that the above inequality holds. Since $\sqrt{\ln\left(\frac{1}{h}\right)}$ diverges, it follows that $\mathbf{W}$ fails to be $\alpha$-Hölder continuous at $t$. 
</details>
</MathBox>

<MathBox title='Dimensionality of Brownian motions' boxType='proposition'>
The graph of an $n$-dimensional Brownian motion $\mathbf{W}$, denoted $G_\mathbf{W}$ satisfies, almost surely

$$
  \mathrm{dim}(G_\mathbb{W}) \leq \begin{cases} 
    \frac{3}{2}, \quad& n=1 \\  
    2,\quad& n\geq 2  
  \end{cases}
$$

and for any fixed set $A\subset[0,\infty)$, almost surely

$$
  \mathrm{dim} \mathbf{W}_A \leq \min\{ 2\mathrm{dim}(A), n \}
$$
<details>
<summary>Proof</summary>

Recall that that the upper bound for the dimension of an $\alpha$-Hölder continuous function $f:[0,1]\to\mathbb{R}^n$ is

$$
  \mathrm{dim}(G_f) \leq 1 + (1-\alpha)\min\left\{n, \frac{1}{\alpha}\right\}
$$

and for any $A\subset [0,1]$

$$
  \mathrm{dim}f(A) \leq \frac{\mathrm{dim}(A)}{\alpha}
$$

Furthermore, if $\alpha < \frac{1}{2}$, then almost surely, Brownian motion is everywhere locally $\alpha$-Hölder continuous.

The result follows from these facts and the countable additivity of Hausdorff measures.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $\mathbf{W} = \{W_t\}_{t\geq 0}$ be an $n$-dimensional Wiener process. If $n \geq 2$ then $\dim{\mathrm{Ran}_\mathbf{W}} = \dim{G_\mathbf{W}} = 2$ almost surely.

<details>
<summary>Proof</summary>

For $n\geq 2$, the lower bound for the dimension of $\mathbf{W}$ is $\dim{G_\mathbf{W}} \leq 2$. It remains to show that $\dim{G_\mathbf{W}} \geq 2$. Let $\mu_W$ be the measure defined by $\mu_W (A) = \lambda (W^{-1}(A)) \cap [0,1]$, or equivalently for all bounded functions $f:\mathbb{R}^n \to\mathbb{R}$

$$
  \int_{\mathbb{R}^n} f(x)\,\mathrm{d}\mu_W (x) = \int_0^1 f(W_t)\,\mathrm{d}t
$$

Using the energy method, we want to show that for any $0 < \alpha < 2$

$$
\begin{align*}
  \mathbb{E}[I_\alpha (\mu_A)] &= \mathbb{E}\iint \frac{\mathrm{d}\mu_W (x)\mathrm{d}\mu_W (y)}{|x-y|^\alpha} \\
  &= \mathbb{E}\left( \int_0^1 \int_0^1 \frac{\mathrm{d}s\mathrm{d}t}{|W_t - W_s|^\alpha} \right) < \infty>
\end{align*}
$$

Note that

$$
\begin{align*}
  \mathbb{E}(|W_t - W_s|^{-\alpha}) &= \mathbb{E}[(|t-s|^{1/2} |W_1|)^{-\alpha}] \\
  &= |t-s|^{-\alpha/2} \int_{\mathbb{R}^n} \frac{c_n}{|z|^n} e^{-|z|^2 / 2}\,\mathrm{d}z
\end{align*}
$$

where $c_n$ is a constant that comes from the joint normal density that depends only on $n$. Substituting and applying Fubini's theorem gives

$$
  \mathbb{E}[I_\alpha (\mu_W)] = k\int_0^1 \int_0^1 \frac{\mathrm{d}t\mathrm{d}t}{|t-s|^{\alpha/2}} \leq 2k \int_0^1 \frac{\mathrm{d}u}{u^{\alpha/2}} < \infty
$$

Thus, $I_\alpha (\mu_W) < \infty$ since any random variable with finite expectation is finite almost surely. By the energy method, $\dim{\mathrm{Ran}_\mathbf{W}} > \alpha$ almost surely. The lower bound on the range follows from letting $\alpha\to 2$. Since the graph can be projected onto the range by a Lipschitz map, the dimension of the graph is at least the dimension of the range. Hence if $n\geq 2$, then almost surely $\dim(G_\mathbf{W}) \geq 2$.
</details>
</MathBox>

### Markov property

<MathBox title='Transition probability density' boxType='proposition'>
Wiener process is a time-homogenous Markov process with transition probability density

$$
  p_t(x,y) = f_t (y-x) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{(y-x)^2}{2t}},\; t\in(0,\infty);\, x,y\in\mathbb{R}
$$

The transition density $p$ satisfies the diffusion equations

$$
\begin{align*}
  \frac{\partial}{\partial t}p_t (x,y) &= \frac{1}{2}\frac{\partial^2}{\partial y^2} p_t (x,y) \\
  \frac{\partial}{\partial t}p_t (x,y) &= \frac{1}{2}\frac{\partial^2}{\partial x^2} p_t (x,y)
\end{align*}
$$

known as the forward and backward equations, respectively.

<details>
<summary>Proof</summary>

Recall the process $\{ X_{s+t} - X_s \}_{t\geq 0}$ is another Wiener process and is independent of $\mathcal{F}_s$.
</details>
</MathBox>

The Markov property asserts that the difference process $\{ W_{t+s} - W_s \}_{t\geq 0}$ for $s\leq t$ is a Wiener process that is also independent of the path $\{ W_r \}_{0\leq r\leq s}$ up to time $s$. Stated in terms of $\sigma$-algebras, define

$$
  \mathcal{F}_t^W := \sigma\left(\{W_s\}_{0\leq s\leq t}\right)
$$

Check
$$
  \mathcal{F}_\tau = \{ B\in\mathcal{F} \mid B\cap \{ \tau \leq t \}\in\mathcal{F} \; \forall t\geq 0 \}
$$

to be the smallest $\sigma$-algebra containing all events of the form $\{ W_s \in B \}$ where $0\leq s\leq t$ and $B\subset\mathbb{R}$ is a Borel set. The collection $\mathscr{F}^W = \{ \mathcal{F}_t^W \}_{t\geq 0}$ is called the standard filtration associated with the Brownian motion.

<MathBox title='Admissible filtration' boxType='definition'>
Let $\mathbf{W} = \{W_t\}_{t\geq 0}$ be a Wiener process, and $\mathscr{F} = \{\mathcal{F_t}\}_{t\geq 0}$ a filtration on the probability space of $\mathbf{W}$. Then $\mathscr{F}$ is an *admissible filtration* if 
- $\mathbf{W}$ is adapted to $\mathscr{F}$
- the post-$t$ process $\{W_{t+s} - W_t \}_{s\geq 0}$ is independent of the $\sigma$-algebra of $\mathcal{F}_t$ for every $t\in[0,\infty)$
</MathBox>

<MathBox title='Markov property for Wiener process' boxType='proposition'>
If $\mathbf{W} = \{W_t\}_{t\geq 0}$ is a Wiener process, then the standard filtration $\mathscr{F}^W$ is admissible.

<details>
<summary>Proof</summary>

Fix $s\geq 0$ and consider two events of the form

$$
\begin{align*}
  A &= \bigcap_{j=1}^{n\in\mathbb{N}_+} \{ W_{s_j} - W_{s_j - 1} \leq x_j \} \in \mathcal{F}_s \\
  B &= \bigcap_{j=1}^{m\in\mathbb{N}_+} \{ W_{t_j + s} - W_{(t_j + s) - 1} \leq y_j \} \in \mathcal{F}_s
\end{align*}
$$

By indepedent increments property, events $A$ and $B$ are independent. Events of type $A$ generate the $\sigma$-algebra $\mathcal{F}_s$ and events of type $B$ generate the smallest $\sigma$-algebra with respect to which the post-$s$ Brownian motion $W_{t+s} - W_s$ is measurable. Hence, the post-$s$ Brownian motion is independent of $\mathcal{F}_s$.
</details>
</MathBox>

<MathBox title='Strong Markov property for Wiener process' boxType='proposition'>
Let $\mathbf{W} = \{W_t\}_{t\geq 0}$ be a Wiener process, and $\tau < \infty$ be a stopping time relative to the standard filtration, with associated stopping $\sigma$-algebra $\mathcal{F}_\tau$. For $t\geq 0$, define the post-$\tau$ process

$$
  W_t^* = W_{t+\tau} - W_\tau
$$

and let $\{ F_t^* \}_{t\geq 0}$ be the standard filtration for this process. Then

1. $\{ W_t^* \}_{t\geq 0}$ is a Wiener process
2. for each $t > 0$, the $\sigma$-algebra $\mathcal{F}_t^*$ is indepedent of $\mathcal{F}_\tau$

Alternatively, the strong Markov property for Wiener process can be formulated in terms of spliced processes. Let $\{ W_s^* \}_{s\geq 0}$ be a second Brownian motion on the same probability space that is independent of $\mathcal{F}_\tau$. Then the spliced process

$$
  \tilde{W}_t = \begin{cases} 
    W_t &\quad t \leq\tau \\
    W_\tau + W_{t-\tau}^* &\quad t\geq\tau 
  \end{cases}
$$

is also a Brownian motion.

<details>
<summary>Proof</summary>

Suppose that the theorem is true for all stopping times taking values in $D_m = \{\frac{k}{2^m}\}_{k\in\mathbb{N}}$ for $m\in\mathbb{N}_+$. Recall that if $\tau$ is a finite stopping time, then so is $\tau_m = \min\{ \frac{k}{2^m}\geq \tau\}$. Clearly, the sequence $\tau_m$ is non-increasing in $m$ and $\lim_{m\to\infty} \tau_m = \tau$. Thus, the stopping fields $\mathcal{F}_{\tau_m}$ are reverse-ordered, and $\mathcal{F}_\tau \subset\mathcal{F}_{\tau_m}$.

By assumption, the post-$\tau_m$ process $\Delta W(\tau_m, t) = W_{t + \tau_m} - W_{\tau_m}$ is a Wiener process independent of $\mathcal{F}_{\tau_m}$. Since $\mathcal{F}_\tau \subset\mathcal{F}_{\tau_m}$, the process $\Delta W(\tau_m, t)$ is also independent of $\mathcal{F}_\tau$. Since Brownian paths are right-continuous, the convergence $\tau_m \downarrow \tau$ implies that for each $t\geq 0$

$$
  \lim_{m\to\infty} \Delta W(\tau_m, t) = \Delta W(\tau, t) = W_t^*
$$

This shows that the post-$\tau$ process $W_t^*$ is independent of $\mathcal{F}_\tau$. It remains to show that the post-$\tau$ process $W_t^*$ is a Brownian motion. Since the sample paths are obviously continuous, it suffices to show that $W_t^*$ has stationary, independent increments and is normally distributed with mean $0$ and variance $\mathrm{var}(W_t^*) = t$. For this we need to show that 

$$
  \mathbb{E}\left( \exp\left[ i\sum_{j=1}^k \theta_j (W_{t_j}^* - W_{t_j - 1}^* \right] \right) = \mathbb{E}\left( \exp\left[ i\sum_{j=1}^k \theta_j (W_{t_j} - W_{t_j - 1} \right] \right)
$$

By assumption, $\{ \Delta W(\tau_m, t) \}_{t\geq 0}$ is a Brownian motion for each $m\in\mathbb{N}_+$, so the equation holds when $W_t^*$ is replaced by $\Delta W(\tau_m, t)$ in the left expectation. Since $\lim_{m\to\infty} \Delta W(\tau_m, t) = W_t^*$, the equality follows from the dominated convergence theorem.

It remains to prove that if $\tau$ is a stopping time taking values in $D_m$ for $m\in\mathbb{N}$, then the post-$\tau$ process $\{ W_t^* \}_{t\geq 0}$ is a Brownian motion and is independent of $\mathcal{F}_\tau$. For ease of notation, we assume that $m = 0$; the general case can be proved by replacing each $n\in\mathbb{N}$ in the following argument by $\frac{n}{2^m}$. If $B$ is any event in $\mathcal{F}_\tau$, then

$$
  \mathbb{E}\left(\mathbf{1}_B \exp\left[i \sum_{j=1}^k \theta_j (W_{t_j}^* - W_{t_j - 1}^*) \right] \right) = \mathbb{P}\mathbb{E}\left(\exp\left[i \sum_{j=1}^k \theta_j (W_{t_j} - W_{t_j - 1}) \right] \right)
$$

Since $\tau$ takes only nonnegative integer values, the event $B$ can be partioned as $B = \bigcup_{n\in\mathbb{N}_+} (B \cap \{ \tau = n \})$. Since $\tau$ is a stopping time, the event $B\cap\{ \tau = n \}$ is in the $\sigma$-algebra $\mathcal{F}_n$. On $\{\tau= n\}$ the post $\tau$-process coincides with the post-$n$ process $\Delta W(n,t) = W_{t+n} - W_n$. The Markov property implies that the post-$n$ process $\Delta W(n,t)$ is a Brownian motion independent of $\mathcal{F}_n$, and hence independent of $B\cap\{\tau = n\}$. Consequently,

$$
\begin{align*}
  \mathbb{E}\left(\mathbf{1}_B \mathbf{1}_{\tau = n} \exp\left[ i\sum_{j=1}^k \theta_j (W_{t_j}^* - W_{t_j - 1}^*)\right] \right) &= \mathbb{E}\left(\mathbf{1}_B \mathbf{1}_{\tau = n} \exp\left\{ i\sum_{j=1}^k \theta_j [\Delta W(n,t_j) - \Delta W(n, t_j - 1)]\right\} \right) \\
  &= \mathbb{P}(B\cap\{\tau = n\})\mathbb{E}\left( \exp\left\{ i\sum_{j=1}^k \theta_j (W_{t_j} - W_{t_j - 1})\right\} \right)
\end{align*}
$$

Summing over $n\in\mathbb{N}$ and using the dominated convergence theorem on the left and the monotone convergence theorem on the right gives the result.
</details>
</MathBox>

### Blumenthal's 0-1 law

Let $\mathscr{F} = \{\mathcal{F}_t\}_{t\geq 0}$ be a filtration. The *right-continuous augmentation* of $\mathscr{F}$ is the collection

$$
  \mathscr{F}_{t_+} = \left\{\mathcal{F}_{t_+} \mid \bigcap_{s > t} \mathcal{F}_s \right\}
$$

The right-continuity implies that the enlarged filtration satisfies $\mathcal{F}_{t_+} = \bigcap_{s > t} \mathcal{F}_{s_+}$.

<MathBox title='Admissability of the augmented filtration' boxType='proposition'>
If $\mathbf{W} = \{W_t\}_{t\geq 0}$ is a Wiener process and $\mathscr{F}^W$ is the standard filtration, then the augmented filtration $\mathscr{F}_{t_+}$. is admissible

$$
  \mathcal{F}_\tau = \{ B\in\mathcal{F} \mid B\cap \{ \tau \leq t \}\in\mathcal{F} \; \forall t\geq 0 \}
$$

Define $W_t = W_{\tau + t} - W_\tau$ for $t\in[0,\infty)$. Then $\mathbf{Y} = \{ Y_t \}_{t\geq 0}$

<details>
<summary>Proof</summary>

We must show that for each $s\geq 0$, the post-$s$ process $\{ \Delta W(s,t) W_{t+s} - W_s \}_{t\geq 0}$ is indepedent of the $\sigma$-algebra $\mathcal{F}_{s+}^W$. By the Markov property, for any $m\geq 1$ the post-($s+2^{-m}$) process $\{ \Delta W(s+2^m, t) \}_{t\geq 0}$ is indepedent of $\mathcal{F}_{s+2^{-n}}^W$, and since $\mathcal{F}_{s_+}^W$ is contained in $\mathcal{F}_{s+2^{-n}}^W$ it follows that the process $\{ \Delta W(s+2^m, t) \}_{t\geq 0}$ is independent of $\mathcal{F}_{s_+}^W$. The path-continuity of the Wiener process guarantees that for each $t\geq 0$

$$
  \lim_{m\to\infty} \Delta W(s + 2^{-m}, t) = \Delta(s,t)
$$

The independence property for Lévy processes implies that $\{ \Delta W(s, t) \}_{t\geq 0}$ is independent of $\mathcal{F}_{s_+}^W$. 
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
For every $t\geq 0$ and every integrable random variable $Y$ that is measurable with respect to $\mathcal{F}_\infty^W$ generated by the Wiener process, it follows that

$$
  \mathbb{E}(Y\mid \mathcal{F}_{t_+}^W) = \mathbb{E}(Y\mid \mathcal{F}_{t}^W)
$$

Consequently, for any event $F\in\mathcal{F}_{t_+}^W$ there is an event $F'\in\mathcal{F}_t^W$ such that $\mathbb{P}(F\Delta F') = 0$.

<details>
<summary>Proof</summary>

It suffices to consider random variables of the form

$$
  Y = \exp\left[i \sum_{j=1}^m \theta_j (W_{t_j} - W_{t_j - 1}) \right]
$$

where $0\leq t_1 \dots < t_k = t < t_{k+1} < \dots < t_m$. For such $t_j$, the random variable $\sum_{j\leq k} \theta_j (W_{t_j} - W_{t_j - 1})$ is measurable with respect to $\mathcal{F}_t^W$, and hence also with respect to $\mathcal{F}_{t_+}^W$. By admissability of $\mathcal{F}_{t_+}^W$, the random variable $\sum_{k < j\leq m} \theta_j (W_{t_j} - W_{t_j - 1})$ is indepedent of $\mathcal{F}_{t_+}^W$. It follows that

$$
\begin{align*}
  \mathbb{E}(Y \mid \mathcal{F}_{t_+}^W) &= \exp\left[ i\sum_{j\leq k} \theta_j (W_{t_j} - W_{t_j - 1}) \right] \\
  &\cdot \mathbb{E}\exp\left[ i\sum_{k < j \leq m} \theta_j (W_{t_j} - W_{t_j - 1}) \right] \\
  &= \mathbb{E}(Y \mid \mathcal{F}_t^W)
\end{align*}
$$

Applying the equation for $Y = \mathbf{1}_F$ gives

$$
  \mathbf{1}_F = \mathbb{E}(\mathbf{1}_F \mid \mathcal{F}_{t_+}^W) = \mathbb{E}(Y \mid \mathcal{F}_t^W)
$$

Since $\mathbf{1}_F \in \{0,1\}$ it follows that its projection on $\mathcal{F}_t^W$, it follows that its projection on $\mathcal{F}_t^W$ is an indicator $\mathbf{1}_{F'}$ for some $F'\in\mathcal{F}_t^W$. 
</details>
</MathBox>

<MathBox title="Blumenthal's 0-1 law" boxType='corollary'>
Every event in $F_{0^+}^W$ has probability $0$ or $1$.

<details>
<summary>Proof</summary>

The $\sigma$-algebra $\mathcal{F}_0^W$ is the trivial $\sigma$-algebra $\{\emptyset, \Omega\}$, because it is generated by the constant random variable $W_0$. Therefore, each event $F\in\mathcal{F}_{0_+}^W$ differs from either $\emptyset$ or $\Omega$ by an event of probability $0$ and so $\mathbb{P}(F) \in \{0,1\}$. 
</details>
</MathBox>

The augmentation $\mathcal{F}_{0_+}^W$ contains events such as

$$
\begin{align*}
  A_+ &= \bigcap_{n\in\mathbb{N}_+} \bigcup_{q\in\mathbb{Q};q\leq 2^{-n}} \{ W_q > 0 \} \\
  A_- &= \bigcap_{n\in\mathbb{N}_+} \bigcup_{q\in\mathbb{Q};q\leq 2^{-n}} \{ W_q < 0 \}
\end{align*}
$$

The event $A_+$ (respectively, $A_-$) is the event that the path of $W_t$ takes positve (respectively, negative) values at arbitrarily small times. On the event $A_+ \cap A_-$, the path $W_t$ must cross and recross $0$ infinitely often in each time interval of $(0, 2^{-n})$. Blumenthal's law implies that both $A_+$ and $A_-$ have probabilities $0$ and $1$.

For each $n\in\mathbb{N}_+$, the event $\bigcup_{q\in\mathbb{Q};q\leq 2^{-n}} \{ W_q > 0 \}$ has probability at least $\frac{1}{2}$, because the chance that $W_{2^{-n}} > 0$ is $\frac{1}{2}$. Consequently, the intersection must have probabilities at least $\frac{1}{2}$, and so by the Blumenthal's law $\mathbb{P}(A_+) = 1$. A similar argument shows that $\mathbb{P}(A_-) = 1$. It follows that $\mathbb{P}(A_+ \cap A_+) = 1$.

### Embedded simple random walks

<MathBox title='' boxType='lemma'>
Let $\mathbf{W} = \{W_t\}_{t\geq 0}$ be a Wiener process. Define $\tau := \min\{t > 0 : |W_t| = 1 \}$. Then $\tau < \infty$ with probability $1$.

<details>
<summary>Proof</summary>

Define a sequence of independent Bernoulli trials $G_n$ in such a way that if any of them results in a success, then the path $W_t$ must escappe from the interval $[-1,1]$. Set $G_n = \{ W_{n+1} - W_n > 2\}$. These events are independent, and each has probability $p := 1 - \Phi(2) > 0$. Since $p >0$ infinitely many of the events $G_n$ will occur (the number $N$ of trials until the first success will have the geometric distribution with parameter $p$). Clearly, if $G_n$ occurs, then $\tau \leq n+1$. 
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Define $\tau_{n+1} := \min\{ t > \tau_n : |W_{t+\tau_n} - W_{\tau_n}| = 1 \}$ with $\tau_0 = 0$. The sequence $Y_n := W_{\tau_n}$ is a simple random walk started at $Y_0 = W_0 = 0$. The sequence of random vectors

$$
  (W_{\tau_{n+1} - W_{\tau_n}}, \tau_{n+1} - \tau_n)
$$

is indepedent and identically distributed.
</MathBox>

<MathBox title='' boxType='corollary'>
The Wiener process visits every point in $\mathbb{R}$ with probability $1$.

<details>
<summary>Proof</summary>

By continuity and the intermediate value theorem, if $\mathbf{W}$ reaches $w > 0$, then $\mathbf{W}$ visits every point in $[0,w]$. By symmetry, a similar statement holds for $y < 0$. Thus the event that $\mathbf{X}$ visits every point in $\mathbb{R}$ is 

$$
  \bigcap_{n=1}^\infty (\{\tau_n < \infty \} \cap \{ \tau_{-n} < \infty \})
$$

The probability of a countable intersection of events with probability $1$ has still probability $1$.
</details>
</MathBox>

### Reflection principle

Let $M_t = \max\{ X_s \}_{0\leq s\leq t}$ denote the maximum of a Wiener process $\mathbf{W}$ on the interval $[0,t]$, and let $\tau_a = \min\{ t\geq 0 \mid W_t = a \}$ denote the passage time to the value $a$. Since $\mathbf{W}$ visits every real number it follows that $\tau_a < \infty$. Since $\tau_a$ is a stopping time, the post-$\tau$ process $W_t^* := W_{\tau + t} - W_\tau$ is a Wiener process that is independent of $\mathcal{F}_{\tau_a}$. Consequently, the reflection $\{ -W_t^*\}_{t\geq 0}$ is also a Wiener process that is independent of $\mathcal{F}_{\tau_a}$.

<MathBox title='Reflection principle' boxType='proposition'>
Define the process $\tilde{\mathbf{W}} = \{ \tilde{W}_t\}_{t\geq 0}$ where

$$
  \tilde{W}_t := \begin{cases}
    W_t &\quad t < \tau_a \\
    2a - W_t &\quad t\geq\tau_a
  \end{cases}
$$

If $\{ W_t \}_{t\geq 0}$ is a Wiener process, then so is $\{ \tilde{W}_t\}_{t\geq 0}$.

<details>
<summary>Proof</summary>

This is just a special case of the strong Markov property of a spliced Wiener process.
</details>
</MathBox>

The reflected process $\tilde{\mathbf{W}}$ is a Brownian motion that agrees with the original Brownian motion $\mathbf{W}$ up until the first time $\tau_a$ that the path reaches the state $a = W_t$. For $t \geq \tau_a$, the graph of $\tilde{\mathbf{W}}$ is obtained from the path of $\mathbf{W}$ by reflecting in the line $w = a$ after time $\tau_a$.

<MathBox title='' boxType='proposition'>

$$
  \mathbb{P}(M_t \geq a) = \mathbb{P}(\tau_a \leq t) = 2\mathbb{P}(W_t > a) = 2 - 2\Phi(\frac{a}{\sqrt{t}})
$$

<details>
<summary>Proof</summary>

Note that since the paths of $\mathbf{W}$ and $\tilde{\mathbf{W}}$ coincide up until time $\tau_a$

$$
  \mathbb{P}(\tau < t, W_t < a) = \mathbb{P}(\tau < t, \tilde{W}_t < a)
$$

After time $\tau_a$, the path $\tilde{\mathbf{W}}$ is gotten by reflecting the path $\mathbf{W}$ in the line $w = a$. On the event $\tau < t$, it follows that $W_t < a$ if and only if $\tilde{W}_t > a$, such that

$$
  \mathbb{P}(\tau < t, \tilde{W}_t < a) = \mathbb{P}(\tau < t, W > a)
$$

Combining the two equalities and using the fact that $\mathbb{P}(W_t = a) = 0$ gives

$$
  \mathbb{P}(\tau < a) = 2\mathbb{P}(\tau < t, W_t > a) = 2\mathbb{P}(W_t > a)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
For $a > 0$, the hitting time $\tau_a$ has the same distribution as $\frac{a^2}{Z^2}$ where $Z is a standard normal variable. The probability density function $f_a$ is given by

$$
  f_a (t) = \frac{a}{\sqrt{2\pi t^3}}e^{-\frac{a^2}{2t}}
$$

<details>
<summary>Proof</summary>

Note that $W_t \geq a \implies M_t \geq a \implies \tau_a \leq t$. Thus

$$
  \mathbb{P}(W_t \geq a) = \mathbb{P}(W_t \geq a, \tau_a \leq t) = \mathbb{P}(W_t \geq a \mid \tau_a \leq t)\mathbb{P}(\tau_a \leq t)
$$

From the strong Markov property, $s\mapsto W_{\tau + s} - a$ is another Wiener process. Hence $\mathbb{P}(W_t \geq a \mid \tau_a \leq t) = \frac{1}{2}$. Therefore

$$
\begin{align*}
  \mathbb{P}(\tau_a \leq t) &= 2\mathbb{P}(W_t \geq a) = \frac{2}{\sqrt{2\pi t}}\int_a^\infty e^{-\frac{x^2}{2t}}\,\mathrm{d}x \\
  &= \frac{2}{\sqrt{2\pi}}\int_{a/\sqrt{t}}^\infty e^{-\frac{z^2}{2}}\,\mathrm{d}z
\end{align*}
$$

where we have used the substitution $z = \frac{x}{\sqrt{t}}$. We recognize the last integral as $\mathbb{P}\left(\frac{a^2}{Z^2} \leq t\right)$ where $Z$ has a standard normal distribution. Taking the derivative of the integral with respect to $t$ gives the probability density function.
</details>
</MathBox>

<MathBox title='Wiener processes are recurrent' boxType='proposition'>
Wiener processes are recurrent. That is, $\mathbb{P}(\tau_a < \infty) = 1$ for every $a\in\mathbb{R}$.

<details>
<summary>Proof</summary>

Trivially $\tau_0 = 0$. Suppose that $a > 0$. Then from the distribution of $\tau_a$

$$
  \mathbb{P}(\tau < \infty) = \lim_{t\to\infty}\mathbb{P}(\tau_a \leq t) = \frac{2}{\sqrt{2\pi}}\int_0^\infty e^{-\frac{z^2}{2}}\,\mathrm{d}z = 1
$$

If $a < 0$, then by symmetry $\tau_a$ has the same distribution as $\tau_{-a}$ with $\mathbb{P}(\tau_a < \infty) = 1$.
</details>
</MathBox>

<MathBox title='Wiener processes are null recurrent' boxType='proposition'>
Wiener processes are null recurrent. That is, $\mathbb{E}(\tau_a) = \infty$ for every $a\in\mathbb{R}\setminus \{0\}$.

<details>
<summary>Proof</summary>

By distribution, it suffices to consider $a > 0$. From the result on the distribution of $\tau_a$

$$
  \mathbb{E}(\tau_a) = \int_0^\infty \mathbb{P}(\tau_a > t)\,\mathrm{d}t = \frac{2}{\sqrt{2\pi}}\int_0^\infty \int_0^{a/\sqrt{t}} e^{-\frac{z^2}{2}}\,\mathrm{d}z\,\mathrm{d}t
$$

Changing the order of integration gives

$$
  \mathbb{E}(\tau_a) = \frac{2}{\sqrt{2\pi}}\int_0^\infty \int_0^{a^2/z^2} e^{-\frac{z^2}{2}}\,\mathrm{d}t\,\mathrm{d}z =\frac{2a^2}{\sqrt{2\pi}}\int_0^\infty \frac{1}{z^2}e^{-\frac{z^2}{2}}\,\mathrm{d}z
$$

We get a lower bound on the last integral by integrating over the interval $[0,1]$ and noting that $e^{-\frac{z^2}{2}}\geq e^{-\frac{1}{2}}$ on this integral. Thus

$$
  \mathbb{E}(\tau_a) \geq \frac{2a^2 e^{-\frac{1}{2}}}{\sqrt{2\pi}}\int_0^1 \frac{1}{z^2}\,\mathrm{d}z = \infty
$$
</details>
</MathBox>

<MathBox title='Hitting times have stationary, independent increments' boxType='proposition'>
The process $\{ \tau_x \}_{x\geq 0}$ has stationary, indepedent increments. As a direct result, the collection of probability density functions $\{g_x \}_{x > 0}$ is closed under convolution, i.e. $g_x * g_y = g_{x+y}$ for $x,y\in(0,\infty)$.

<details>
<summary>Proof</summary>

Suppose that $x, y\in[0,\infty)$ with $x < y$. By continuity, $\mathbf{W}$ must reach $x$ before reaching $y$. Thus $\tau_y = \tau_x + (\tau_y - \tau_x)$. Note that $\tau_y - \tau_x$ is the hitting time to $y - x$ for the the process $t \mapsto W_{\tau_x + t} - x$, which is a Wiener process independent of $\mathcal{F}_{\tau_x}$. Hence $\tau_y - \tau_x$ is independent of $\mathcal{F}_{\tau_x}$ and has the same distribution as $\tau_{y-x}$. 
</details>
</MathBox>

<MathBox title='Hitting times have stationary, independent increments' boxType='proposition'>
For $t > 0$, the maximum process $M_t$ has the same distributino as $|W_t|$, known as the half-normal distribution with scale parameter $t$ and probability density function

$$
  h_t (m) = \sqrt{\frac{2}{\pi t}}\exp\left( -\frac{m^2}{2t} \right),\; m\in[0,\infty)
$$

For $t\geq 0$, $M_t$ has mean $\mathbb{E}(M_t) = \sqrt{\frac{2t}{\pi}}$ and variance $\mathrm{var}(M_t) = t\left( 1 - \frac{2}{\pi} \right)$

<details>
<summary>Proof</summary>

From the inverse relation and the distribution of $\tau_m$, it follows that $\mathbb{P}(M_t \geq m) = \mathbb{P}(\tau_m \leq t) = 2\mathbb{P}(W_t \geq m) = \mathbb{P}(|W_t| \geq m)$ for $m\geq 0$. By definition, $|W_t|$ has the half-normal distribution with parameter $t$. In particular

$$
  \mathbb{P}(M_t \geq m) = \frac{2}{\sqrt{2\pi t}}\int_m^\infty e^{-\frac{w^2}{2t}}\,\mathrm{d}w
$$

Taking the negative derivate with respect to $m$ gives the half-normal distribution function.
</details>
</MathBox>

### Martingales

<MathBox title='Wiener processes are martingales' boxType='proposition'>
Let $\mathbf{W}$ be a Wiener process and let $\mathscr{F} = \{\mathcal{F}_t \}_{t\geq 0}$ be an admissible filtration. Then each of the following is a continuous martingale relative to $\mathscr{F}$ with $\theta\in\mathbb{R}$

1. $\{W_t\}_{t\geq 0}$
2. $\{W_t^2 - t\}_{t\geq 0}$
3. $\left\{\exp\left(\theta W_t - \frac{\theta^2 t}{2} \right)\right\}_{t\geq 0}$
4. $\left\{\exp\left(i\theta W_t - \frac{\theta^2 t}{2} \right) \right\}_{t\geq 0}$

Consequently, for any bounded stopping time $\tau < \infty$, the following Wald identities holds
5. $\mathbb{E}(W_t) = 0$
6. $\mathbb{E}(W_t^2) = \mathbb{E}(\tau)$
7. $\mathbb{E}\left[\exp\left(\theta W_\tau - \frac{\theta^2 \tau}{2}\right)\right] = 1$
8. $\mathbb{E}\left[i\exp\left(\theta W_\tau - \frac{\theta^2 \tau}{2}\right)\right] = 1$

<details>
<summary>Proof</summary>

Note that the Wald identities follow from Doob's optional sampling formula.

Let $s,t \in[0,\infty)$ with $s < t$.

1. Since $W_s$ is measurable with respect to $\mathcal{F}_s$ and $W_t - W_s$ is independent of $\mathcal{F}_s$ it follows that

$$
  \mathbb{E}(W_t \mid\mathcal{F}_s) = \mathbb{E}[W_s + (W_t - W_s) \mid\mathcal{F}_s] = W_s + \mathbb{E}(W_t - W_s) = W_s
$$

2. Note that

$$
\begin{align*}
  X_t = W_t^2 - t &= [W_s + (W_t - W_s)]^2 - t \\
  &= W_s^2 + 2W_s(W_t - W_s) + (W_t - W_s)^2 - t
\end{align*}
$$

Since $W_s$ is measurable relative to $\mathcal{F}_s$ and $W_t - W_s$ is indepedent of $\mathcal{F}_s$ we have

$$
  \mathbb{E}(X_t \mid\mathcal{F}_s) &= W_s^2 + 2W_s\mathbb{E}(W_t - W_s) + \mathbb{E}[(W_t - W_s)^2] - t
$$

Note that $\mathbb{E}(X_t - X_s) = 0$ and $\mathbb{E}[(W_t - W_s)^2] = \mathrm{var}(W_t - W_s) = t - s$. Hence, $\mathbb{E}(X_t \mid\mathcal{F}_s) = W_s^2 - s = X_s$.

3. 

$$
\begin{align*}
  \mathbb{E}\left(\exp\left[ \theta W_{t+s} - \frac{\theta^2(t+s)}{2} \right] \mid \mathcal{F}_s \right) &= \exp\left( \theta W_{t+s} - \frac{\theta^2 s}{2} \right) \mid \mathcal{F}_s \mathbb{E}\left(\exp\left[ \theta W_{t+s} - W_s - \frac{\theta^2(t+s)}{2} \right] \mid \mathcal{F}_s \right) \\
  &= \exp\left( \theta W_{t+s} - \frac{\theta^2 s}{2} \right) \mid \mathcal{F}_s \mathbb{E}\left(\exp\left[ \theta W_{t+s} - W_s - \frac{\theta^2(t+s)}{2} \right] \right) \\
  &= \exp\left( \theta W_{t+s} - \frac{\theta^2 s}{2} \right)
\end{align*}
$$
</details>
</MathBox>

#### First-passage problems

##### Two-point passage
Fix constants $a,b > 0$ and define $\tau = \tau_{-a, b}$ to be the first time $t$ such that $W_t = -a \lor +b$. The random variable $\tau$ is a finite, but unbounded stopping time, and so the Wald identities may not be applied directly. However, for each $n\in\mathbb{N}_+$, the random variable $t \land n$ is a bounded stopping time. Consequently,

$$
  \mathbb{E}(W_{\tau \land n}) = 0 \quad \mathbb{E}(W_{\tau\land n}^2) = \mathbb{E}(\tau \land n)
$$

Until $\tau$, the Wiener path remains between the values $-a$ and $b$, so the random variables $|W_{\tau\land n}|$ are uniformly bounded by $a+b$. By path-continuity, $\lim_{n\to\infty} W_{\tau\land n} = W_\tau$. By the dominated convergence theorem

$$
  \mathbb{E}(W_\tau) = -a\mathbb{P}(W_\tau = -a) + b\mathbb{P}(W_\tau = b) = 0
$$

Since $\mathbb{P}(W_\tau = -a) + \mathbb{P}(W_\tau = b) = 1$ it follows that

$$
  \mathbb{P}[W_\tau = b] = \frac{a}{a+b}
$$

The dominated convergence theorem also guarantees that $\lim_{n\to\infty} \mathbb{E}(W_{\tau\land n}^2) = \mathbb{E}(W_\tau^2)$, and the monotone convergence theorem that $\lim_{n\to\infty} \mathbb{E}(\tau\land n) \stackrel{\uparrow}{=} \mathbb{E}(\tau)$. It follows that 

$$
  \mathbb{E}(W_\tau^2) = \mathbb{E}(\tau) = ab
$$

##### One-point passage

Let $\tau = \tau_a$ be the first passage time to the value $a = W_t$. Recall that $\tau$ is a stopping time and $\tau < \infty$ with probability $1$, but $\tau$ is not bounded. For any $n < \infty$, the truncation $\tau \land n$ is a bounded stopping time. By the third Wald identity for any $\theta > 0$

$$
  \mathbb{E}\left(\exp\left[ \theta W_{\tau\land n} - \theta^2(\tau\land n) \right]\right) = 1
$$

Since the path $W_t$ does not assume a value larger than $a$ until after time $\tau$, the random variables $W_{\tau\land n}$ are uniformly bounded by $a$, making the random variables in the last equation dominated by the constant $e^{\theta a}$. Because, $\tau < \infty$ with probability $1$, $\lim_{n\to\infty} \tau\land n = \tau$, and by path-continuity, $\lim_{n\to\infty} W_{\tau\land n} = a$. By the dominated convergence theorem

$$
  \mathbb{E}\left(\exp\left[ \theta a - \theta^2 (\tau) \right] \right) = 1
$$

Setting $\lambda = \frac{\theta^2}{2}$ we have

$$
  \mathbb{E}\left(e^{-\lambda\tau_a}\right) = e^{-\sqrt{2\lambda}a}
$$

### Zeroes and arcsine laws

<MathBox title='Zero set of Wiener processes' boxType='definition'>
The zero set of a Wiener process $\mathbf{W}$ is $Z = \{ t\geq 0 \mid W_t = 0 \}$. 
</MathBox>

Note that for any fixed $t > 0$, the probability that $t\in Z$ is $0$, because $\mathbb{P}(W_t = 0) = 0$. Hence, because $\mathbb{Q}_+$ is countable

$$
  \mathbb{P}(\mathbb{Q}_+ \cap Z \neq\emptyset) = 0
$$

<MathBox title='Properties of Wiener zero sets' boxType='proposition'>
Let $\lambda$ denote the Lebesgue measure. With probability $1$, the zero set $Z$ satisfies
1. $Z$ is closed
2. $\lambda(Z) = 0$
3. $Z$ is nowhere dense, i.e. the closure of $Z$ has empty interior
4. $Z$ is perfect, i.e. for every $t\in Z$ there is a sequence of distinct elements $t_n\in Z$ such that $\lim_{n\to\infty} t_n = t$ (no isolated points)
5. $Z$ has Hausdorff dimension $\frac{1}{2}$

<details>
<summary>Proof</summary>

1. Note that $Z$ is the inverse image of the closed set $\{0\}$ under the function $t\mapsto W_t$. Because the path $W_t$ is continuous with probability $1$, the zero set $Z$ is closed with probability $1$. 

2. For each $t\in(0,\infty)$ note that $\mathbb{P}(t\in Z) = \mathbb{P}(W_t = 0) = 0$. since $W_t$ has a continuous distribution. By Fubini's theorem

$$
\begin{align*}
  \mathbb{E}[\lambda(Z)] &= \mathbb{E}\left[ \int_0^\infty \mathbf{1}_Z (t)\,\mathrm{d}\lambda(t) \right] \\
  &= \int_0^\infty \mathbb{E}[\mathbf{1}_Z(t)]\,\mathrm{d}\lambda(t) \\
  &= \int_0^\infty \mathbb{P}(W_t = 0)\,\mathrm{d}t \\
  &= 0
\end{align*}
$$

3. Since $Z$ is closed with Lebesgue measure $0$, its interior is empty.
4. Fix $0 < q\in\mathbb{Q}_+$ and define $z_q$ to be the first time $t\geq 0$ such that $W_{z_q} = 0$. Because $W_q \neq 0$ almost surely, the random variable $z_q$ is well-defined with $z_q > q$. By the strong Markov property, the post-$z_q$ process $W_{z_q + t} - W_{z_q}$ is a Wiener process, which has infinitely manny zeroes in every time interval $(0, \varepsilon)$ with probability $1$. Since $W_{z_q} = 0$ and since $\mathbb{Q}$ is countable, it follows that $W_t$ almost surely has infinitely many zeroes in every interval $(z_q, z_q + \varepsilon)$ for $\varepsilon > 0$.

Let $t$ be any zero of the path. Then either there is an increasing sequence $t_n$ of zeroes such that $\lim_{t\to\infty} t_n = t$, or there is a real number $\varepsilon > 0$ such that the interval $(t - \varepsilon, t)$ is free of zeroes. In the latter case, there is a rational number $q\in (t-\varepsilon, t)$, and $t = z_q$. In this case, there must be a decreasing sequence $t_n$ of zeroes such that $\lim_{n\to\infty} t_n = t$.
</details>
</MathBox>

<MathBox title='Arcsine laws' boxType='proposition'>
For $s,t\in[0,\infty)$ with $s< t$, let $E(s,t)$ be the event that $\mathbf{X}$ has a zero in the time interval $(s,t)$. That is, $E(s,t) = \{X_u = 0 \textrm{ for some } u\in(s,t)\}$

$$
  \mathbb{P}[E(s,t)] = 1 - \frac{2}{\pi}\arcsin\left(\sqrt{\frac{s}{t}}\right)
$$

<details>
<summary>Proof</summary>

Conditioning on $X_s$ and using symmetry gives

$$
\begin{align*}
  \mathbb{P}[E(s,t)] &= \int_\infty^{-\infty} \mathbb{P}[E(s,t)| X_s = x] f_s(x)\,\mathrm{d}x \\
  &= 2\int_{-\infty}^0 \mathbb{P}[E(s,t)|X_s = x]f_s(x)\,\mathrm{d}x
\end{align*}
$$

By the homogeneity of $\mathbf{X}$ in time and space, note that for $x > 0$, $\mathbb{P}[E(s,t)|X_s = -x] = \mathbb{P}(\tau_x < t - s)$. A process in state $-x$ at time $s$ that hits $0$ before time $t$ is the same as the process in state $0$ at time $0$ reaching state $x$ before time $t-s$, giving

$$
  \mathbb{P}[E(s,t)] = \int_0^\infty \int_0^{t-s} g_x (u) f_s (-x)\,\mathrm{d}u\,\mathrm{d}x
$$

where $g_x$ is the probability density function of $\tau_x$. Substituting gives

$$
\begin{align*}
  \mathbb{P}[E(s,t)] &= \frac{1}{\pi\sqrt{s}}\int_0^{t-s} u^{-3/2} \int_0^\infty x\exp\left[ -\frac{1}{2}x^2 \left( \frac{u+s}{us} \right) \right]\,\mathrm{d}x\,\mathrm{d}u \\
  &= \frac{\sqrt{s}}{\pi}\int_0^{t-s} \frac{1}{(u+s)\frac{u}}\mathrm{d}u
\end{align*}
$$

Substituting $v=\sqrt{\frac{u}{s}}$ gives

$$
\begin{align*}
  \mathbb{P}[E(s,t)] &= \frac{2}{\pi}\int_0^{\sqrt{t/s - 1}}\frac{1}{v^2 + 1}\mathrm{d}v \\
  &= \frac{2}{\pi}\arctan\left( \sqrt{\frac{t}{s} - 1} \right) \\
  &= 1 - \frac{2}{\pi}\arcsin\left(\frac{s}{t}\right)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
The Wiener process $\mathbf{W}$ has infinitely many zeroes in $(0,t)$ with probability $1$.

<details>
<summary>Proof</summary>

Let $E(s,t)$ be the event that $\mathbf{W}$ has a zero in the time interval $(s,t)$. Note that from the arcsine laws $\mathbb{P}[E(0,t)] = 1$ for every $t > 0$. The event that $\mathbf{W}$ has infinitely many zeroes in $(0,t)$ is $\bigcap_{n=1}^\infty E(0,\frac{t}{n}$. The intersection of a countable collection of events with probability $1$ still has probability $1$.
</details>
</MathBox>

<MathBox title='The zero set has the arcsine distribution' boxType='proposition'>
Let $Z_t$ denote the time of the last zero of the Wiener process $\mathbf{W}$ before time $t$, i.e. $Z_t = \max\{s\in[0,t] \mid X_s = 0 \}$. Then $Z_t$ has the arcsine distribution with parameter $t$. The distribution function $H_t$ and the probability density function $h_t$ are given By

$$
\begin{align*}
  H_t (s) &= \frac{2}{\pi}\arcsin\left( \sqrt{\frac{s}{t}} \right),\; 0\leq s\leq t \\
  h_t (s) &= \frac{1}{\pi\sqrt{s(t - s)}},\; 0 < s < t
\end{align*}
$$

The mean of $Z_t$ is $\mathbb{E}(Z_t) = \frac{t}{2}$ and the variance is $\mathrm{var}(Z_t) = \frac{t^2}{8}$.

<details>
<summary>Proof</summary>

For $0\leq s < t$, the event $Z_t \leq s$ is the same as $E(s,t)^c$, i.e. that there are no zeroes in the interval $(s,t)$. Hence the distribution function $H_t$ follows from the arcsine laws.
</details>
</MathBox>

### Growth rate

<MathBox title='Law of iterated logarithm' boxType='proposition'>

$$
  \limsup_{t\to\infty} = \frac{X_t}{\sqrt{2t \ln[\ln(t)]}} = 1
$$
</MathBox>

### Quadratic variation

For a fixed $t > 0$, an increasing sequence $0 = t_0 < t_1 < \dots < t_n = t$ for $n\in\mathbb{N}$ defines a partition $\Pi = \{t_i \}_{i=0}^{n\in\mathbb{N}}$ of the interval $[0, t]$. The *mesh* of $\Pi$ is the length of its longest interval $t_i - t_{i-1}$. If $\Pi$ is a partition of $[0,t]$ and if $0 < s < t$, then the *restriction* of $\Pi$ to $[0,s]$ (or restriction to $[s, t]$) is defined by terminating the sequence $t_i$ at the largest entry before $s$ and appending $s$. A partition $\Pi' = \{ t'_j \}_{j=0}^{n'}$ is a refinement of $\Pi$ if $\Pi \subseteq \Pi'$. A *nested sequence* of partitions is a sequence $(\Pi_n)_{n\in\mathbb{N}}$ such that $\Pi_n \subseteq \subseteq \Pi_{n-1}$

<MathBox title='Quadratic variation' boxType='definition'>
Let $\mathbf{X} = \{X_t\}_{t\geq 0}$ be a continuous-time stochastic process. The quadratic variation of $\mathbf{X}$ relative to a partition $\Pi$ is defined As

$$
  [X]_\Pi := \sum_{j=1}^n [X_{t_j} - X_{t_{j-1}}]^2
$$
</MathBox>

<MathBox title='' boxType='proposition'>
For each $n\in\mathbb{N}_+$ define the $n$th dyadic partition $\mathbb{D}_n[0,t] := \{ \frac{k}{2^n} \cup t \mid 0 \leq k \leq 2^n t \}$. For each $t > 0$ with probability $1$

$$
  \lim_{n\to\infty} [\mathbf{W}]_{\mathbb{D}_n[0,t]} = t
$$

<details>
<summary>Proof</summary>

For ease of notation, assume that $t = 1$. For each $n\geq 1$, the random variables

$$
  \xi_{n, k} \stackrel{\Delta}{=} 2^n (W_{k/2^n} - W_{(k-1)/2^n})^2,\; k=1,2,\dots,2^n
$$

are indepedent, identically distributed $\chi^2$ with one degree of free. Note that $\mathbb{E}(\xi_{n,k}) = 1$. The quadratic variation of $\mathbf{W}$ relative to $\mathbb{D}_n[0,1]$ is

$$
  [\mathbf{W}]_{\mathbb{D}_n[0,1]} = 2^{-n} \sum_{k=1}^{2^n} \xi_{n,k}
$$

Note the right side of the equation is the average of $2^n$ indepedent, identically distributed random variables. By the weak law of large numbers $\lim_{n\to\infty} [\mathbf{W}]_{\mathbb{D}_n[0,1]} = \mathbb{E}(\chi^2) = 1$ (in probability).

The stronger statement that the convergence holds with probability $1$, can be deduced from the Chebyshev inequality and the Borel-Cantelli lemma. Applying the Chebyshev inequality for $\varepsilon > 0$

$$
  \mathbb{P}\left( |[\mathbf{W}]_{\mathbb{D}_n[0,1] - 1| \geq \varepsilon \right) = \mathbb{P}\left( \left|\sum_{k=1}^{2^n} (\xi_{n,k} - 1) \right| \geq 2^n \varepsilon \right) \leq \frac{\mathbb{E}(\xi_{1,1}^2)}{4^n \varepsilon^2}
$$

Since $\sum_{n=1}^\infty 1/4^n < \infty$, the Borel-Cantelli lemma implies that, with probability $1$, the event $|[\mathbf{W}]_{\mathbb{D}_n[0,1]} - 1| \geq \varepsilon$ occurs for at most finitely many $n$. Since $\varepsilon$ can be chosen arbitrarily small, it follows that $\lim_{n\to\infty} [\mathbf{W}]_{\mathbb{D}_n[0,1]} = 1$ almost surely. The same argument shows that the convergence holds almost surely for any dyadic rational $t\in[0,1]$.
</details>
</MathBox>

<MathBox title='' boxType='lemma'>
Let $\xi, \zeta$ be indepedent Gaussian random variables with means $0$ and variances $\sigma_\xi^2, \sigma_\zeta^2$, respectively. Let $\mathcal{F}$ be any $\sigma$-algebra such that the random variables $\xi^2$ and $\zeta^2$ are $\mathcal{F}$-measurable, but such that $\mathrm{sgn}(\xi)$ and $\mathrm{sgn}(\zeta)$ are independent of $\mathcal{F}$. Then

$$
  \mathbb{E}[(\xi + \zeta)^2 \mid \mathcal{F}] = \xi^2 + \zeta^2
$$

<details>
<summary>Proof</summary>

Since $\mathrm{sgn}(\xi)$ and $\mathrm{sgn}(\zeta)$ are independent of $\mathcal{F}$ note That

$$
  \mathbb{E}(\xi\zeta\mid\mathcal{F}) &= \mathbb{E}[\mathrm{sgn}(\xi)\mathrm{sgn}(\zeta)|\xi||\zeta| \mid \mathcal{F}] \\
  &= 2|\xi||zeta|\mathbb{E}[\mathrm{sgn}(\xi)\mathrm{sgn}\mid\mathcal{F}] \\
  &= 0
$$

Expanding the square gives

$$
\begin{align*}
  \mathbb{E}[(\xi + \zeta)^2 \mid \mathcal{F}] &= \mathbb{E}(\xi^2 \mid\mathcal{F}) + 2\mathbb{E}(\xi\zeta\mid\mathcal{F}) + \mathbb{E}(\zeta^2 \mid\mathcal{F}) \\
  &= \xi^2 + \zeta^2
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
For $n\in\mathbb{N}$, let $\Pi_n$ be a nested sequence of partitions of the unit interval $[0,1]$ with mesh $\xrightarrow{n\to\infty} 0$. For a Wiener process $\mathbf{W}$

$$
  \lim_{n\to\infty} [\mathbf{W}]_{\Pi_n} = 1
$$

<details>
<summary>Proof</summary>

Without loss of generality, we may assume that each partition $\Pi_{n+1}$ is gotten by splitting one interval of $\Pi_n$, and that $\Pi_0$ is the trivial partition of $[0,1]$. Thus, $\Pi_n$ consists of $n+1$ non-overlapping intervals $J_k^n = [t_{k-1}^n, t_k^n]$. Define

$$
  \xi_{n,k} = W_{t_k^n} - W_{t_{k-1}^n}
$$

and for each $n\in\mathbb{N}$ let $\mathcal{F}_n$ be the $\sigma$-algebra generated by the random variables $\xi_{m,k}^2$ where $m\geq n$ and $k\in[m + 1]$. The $\sigma$-algebras $\mathcal{F}_n$ are decreasing in $n$, forming a reverse filtration. By the previous lemma, the random variables $[\mathbf{W}]_{\Pi_n}$ form a reverse martingale relative to the reverse filtration $\mathcal{F}_n$, i.e.

$$
  \mathbb{E}([\mathbf{W}]_{\Pi_n}\mid\mathcal{F}_{n+1}) = [\mathbf{W}]_{\Pi_{n+1}}
$$

By the reverse martingale convergence theorem, then almost surely

$$
\begin{align*}
  \lim_{n\to\infty} [\mathbf{W}]_{\Pi_n} &= \mathbb{E}([\mathbf{W}]_{\Pi_n}\mid \bigcap_{n\in\mathbb{N}}\mathcal{F}_n) \\
  &= \mathbb{E}(\mathbf{W_1}^2\mid \bigcap_{n\to\mathbb{N}}\mathcal{F}_n)
\end{align*}
$$
</details>
</MathBox>

### Skorokhod's theorems

<MathBox title='Mixture representation of mean-zero distributions' boxType='proposition'>
For any two points $-a < 0 < b$ with $a,b\in\mathbb{R}$ there is a unique two-point distribution $F_{a,b}$ with support $\{-a,b\}$, mean $0$ and variance $ab$. The two-point distribution takes the values

$$
  F_{a,b}(\{b\}) = \frac{a}{a+b}\quad F_{a,b} (\{-a\}) = \frac{b}{a+b}
$$

For any Borel probability distribution $F$ on $\mathbb{R}$ with mean $0$ there exists a Borel probability distribution $G$ on $\mathbb{R}_+^2$ such that

$$
  F = \int F_{a,b}\,\mathrm{d}G(a,b)
$$

Hence

$$
  \sigma^2 := \int x^2\,\mathrm{d}F(x) = \int ab\,\mathrm{d}G(a,b)
$$

<details>
<summary>Proof</summary>

Assume first that $F$ has finite support. If $F$ is supported by only two points, then $F = F_{a,b}$ for some $a,b > 0$ and the result holds with $G$ concentrated at the single point $(a,b)$. 

Suppose that the result is true for mean-zero distributions supported by fewer than $m$ points, and let $F$ be a mean-zero distribution supported by $m$ points. Among the $m$ support points there must be two satisfying $-a < 0 < b$ both with positive probabilities $F(-a)$ and $F(b)$ giving three possibilities

$$
\begin{align*}
  -aF(-a) + bF(b) \begin{cases}
    =0 \\ > 0 \\ < 0
  \end{cases}
\end{align*}
$$

In the first case, $F$ can obviously be decomposed as a convex combination of $F_{a,b}$ and a probability distribution $F'$ supported by the remaining $m-2$ points in the support of $F$. In the second case, there is som value $0 < \beta < F(b)$ such that $-aF(-a) + \beta F(b) = 0$, and so $F$ can be decomposed as a convex combination of $F_{a,b}$ and a distribution $F'$ supported by $b$ and the remaining $m-2$ points. Similarly, in the third case $F$ is a convex combination of $F_{a,b}$ and distribution $F'$ supported by $-a$ and the remaining $m-2$ points. In all cases the results holds by the induction hypothesis and Fubini's theorem.

Next, let $F$ be a Borel probability distribution on $\mathbb{R}$ with mean zero and compact support $[-A, A]$. Clearly, there is a sequence of probability distributions $F_n$ converging to $F$ in distribution such that $F_n$ is supported by finitely many points. In particular, if $X$ is a random variable with distribution $F$, then set

$$
  X_n = \max\{\frac{k}{2^n} \mid \frac{k}{2^n} \leq X \}
$$

and let $F_n$ be the distribution of $X_n$. Clearly $X_n \xrightarrow{n\to\infty} X$ pointwise. The distributions $F_n$ need not have mean zero, but by the dominated convergence theorem, $\lim_{n\to\infty} \mathbb{E}(X_n) = \mathbb{E}(X) = 0$. Thus if we replace $X_n$ with $X_n - \mathbb{E}(X_n)$ we will have a sequence of mean-zero distributions converging to $F$, each supported by only finitely many points, all contained in $[-A-1, A+1]$. Since the result holds for distributions with finite support, there are Borel probability distributions $G_n$ such that

$$
\begin{gather*}
  F_n = \int F_{a,b}\,\mathrm{d}G_n(a,b) \\
  \sigma_n^2 := \int x^2\,\mathrm{d}F_n(x) = \int ab\,\mathrm{d}G_n(a,b)
\end{gather*}
$$

Since each $F_n$ has supports contained in $[-A-1, A+1]$ the mixing distributions $G_n$ have supports contained in $[0, A+1]^2$. Hence, by Helly's selection principle there is a subsequence $G_k$ that converges weakly to a Borel probability distribution $G$. It follows that

$$
\begin{gather*}
  F = \int F_{a,b}\,\mathrm{d}G(a,b) \\
  $\sigma^2 := \int x^2\,\mathrm{d}F(x) = \int ab\,\mathrm{d}G(a,b) 
\end{gather*}
$$
</details>
</MathBox>

<MathBox title="Skorokhod's first embedding theorem" boxType='theorem'>
Let $F$ be any real probability distribution with mean $0$ and variance $\sigma^2 < \infty$. Then on some probability space there exists a Wiener process $\mathbf{W}$, an admissible filtration $\mathscr{F}^W$ and an increasing sequence of stopping times $(\tau_n)_{n\in\mathbb{N}}$ with $\tau_0 = 0$ such that

1. the random vectors $(\tau_{n+1} - \tau_n, W_{\tau_{n+1}} - W_{\tau_n})$ are indepedent, identically distributed
2. each random variable $W_{\tau_{n+1}} - W_{\tau_n}$ has distribution $f$
3. $\mathbb{E}(\tau_{n+1}) - \mathbb{E}(\tau_n) = \sigma^2$

<details>
<summary>Proof</summary>

Consder first the case where $F$ is supported by only two points. Since $F$ has mean $0$, the two support points must satisfy $a < 0 < b$, with $p = F(\{b\}) = 1 - F(\{a\})$. Let $\tau$ be the first time $\mathbf{W}$ visits either $a$ or $b$. Then $\tau < \infty$ almost surely, and $\tau$ is a stopping time with respect to any admissible filtration. The first passage equations imply that the distribution of $W_\tau$ is $F$ and $\mathbb{E}(\tau) = \sigma^2$.

To complete the proof in the case of a two-point distribution, we use the strong Markov property and an induction argument. Assume that stopping times $0 = \tau_0 \leq \tau_1 \leq \tau_2 \leq\dots\leq \tau_m$ have been defined such that the results hold for $n < m$. Define $\tau_{m+1}$ to be the first time after $\tau_m$ that $W_{\tau_{m+1}} - W_{\tau_m} \in \{a, b\}$. By the strong Markov property, the random vector $(\tau_{m+1} - \tau_m, W_{\tau_{m+1}} - W_{\tau_m})$ is indepedent of the random vectors $(\tau_{n+1} - \tau_n, W_{\tau_{n+1}} - W_{\tau_n})$ for $n < m$, and $(\tau_{m+1} - \tau_m, W_{\tau_{m+1}} - W_{\tau_m})$ has the same distribution as $(\tau_1 - \tau_0, W_{\tau_1} - W_{\tau_0})$. This completes the induction for two-point distributions.

Next, let $F$ be any mean-zero distribution with finite variance $\sigma^2$. By the previous proposition, $F$ has a representation as a mixture of two-point distributions $F_{a,b}$ with mixing measure $G$. Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space that supports a sequence $\{(A_n, B_n)\}_{n\in\mathbb{N}_+}$ of independent, identically distributed random vectors each with distribution $G$, and an independent process Wiener process $\mathbf{W}$. Let $\mathcal{F}_0$ be the $\sigma$-algebra generated by the random vectors $(A_n, B_n)$ and for each $t\geq 0$ let $\mathcal{F}_t$ be the $\sigma$-algebra generated by $\mathcal{F}_0$ and the random variables $W_s$ for $s\leq t$. Since the random vectors $(A_n, B_n)$ are independent of $\mathbf{W}$, the filtration $\{\mathcal{F}_t\}_{t\geq 0}$ is admissible. Define stopping times $\tau_n$ inductively as follows: $\tau_0 = 0$ And

$$
  \tau_{n+1} = \min\{ t\geq 0 \mid W_{\tau_n + t} - W_{\tau_n} = -A_n \lor B_n \}
$$

By the strong Markov property, the random vectors $(\tau_{n+1} - \tau_n, W_{\tau_{n+1}} - W_{\tau_n})$ are independent conditional on $\mathcal{F}_0$. The random variable $W_{\tau_{n+1}} - W_{\tau_n}$, conditional on $\mathcal{F}_0$, has the two-point distribution $F_{a,b}$ with $a = A_n$ and $b = B_n$. Since the unconditional distribution of $(A_n, B_n)$ is $G$, it follows that unconditionally the random vectors $(\tau_{n+1} - \tau_n, W_{\tau_{n+1}} - W_{\tau_n})$ are independent, identically distributed, and $W_{\tau_{n+1}} - W_{\tau_n}$ has distribution $F$. That $\mathbb{E}(\tau_{n+1}) - \mathbb{E}(\tau_n) = \sigma^2$ follows from the variance formula in the mixture representation.
</details>
</MathBox>

<MathBox title="Skorokhod's second embedding theorem" boxType='theorem'>
Let $F$ be any real probability distribution with mean $0$ and variance $\sigma^2 < \infty$ and let $\mathbf{W}$ be a Wiener process. Then there exists increasing stopping times $(\tau_n)_{n\in\mathbb{N}}$ and $\tau_0 = 0$ with respect to the standard filtration such that

1. the random vectors $(\tau_{n+1} - \tau_n, W_{\tau_{n+1}} - W_{\tau_n})$ are indepedent, identically distributed
2. each random variable $W_{\tau_{n+1}} - W_{\tau_n}$ has distribution $F$
3. $\mathbb{E}(\tau_{n+1}) - \mathbb{E}(\tau_n) = \sigma^2$

<details>
<summary>Proof for the uniform distribution on $[-1, 1]$</summary>

Consider the special case where $F$ is the uniform distribution on $[-1, 1]$. Define a sequence of stopping times $\tau_n$ as follows

$$
\begin{align*}
  \tau_1 &= \min\{ t > 0 \mid W_t = \pm \frac{1}{2} \} \\
  \tau_{n+1} &= \min\{ t > \tau_n \mid W_t - W_{\tau_n} = \pm\frac{1}{2^{n+1}} \}
\end{align*}
$$

By symmetry, the random variable $W(\tau_1)$ takes the values $\pm\frac{1}{2}$ with probabilities $\frac{1}{2}$ each. By the strong Markov property and induction on $n$, the random variable $W_{\tau_n}$ takes each of the values $\frac{k}{2^n}$, where $k$ is an odd number between $-2^n$ and $2^n$ with probability $\frac{1}{2^n}$. Note that these values are equally spaced in the interval $[-1,1]$ and fill the interval as $n\to\infty$. Consequently, the distribution of $W_{\tau_n}$ converges to the uniform distribution on $[-1, 1]$ as $n\to\infty$.

The stopping times $\tau_n$ are clearly increasing with $n$ and converge since they are all bounded by $T_{-1,1}$, the first passage time to $W_t = \pm 1$. Consequently, $\tau := \lim \tau_n = \sup(\tau_n)$ is finite with probability $1$. By path-continuity $\lim_{n\to\infty} W_{\tau_n} = W_\tau$ almost surely. Since the distributions of the random variables $W_{\tau_n}$ approach the uniform distribution on $[-1, 1]$ as $n\to\infty$, it follows that the random variable $W_\tau$ is uniformly distributed on $[-1,1]$.
</details>
</MathBox>