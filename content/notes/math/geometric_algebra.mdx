---
title: 'Geometric Algebra'
subject: 'Mathematics'
showToc: true
references:
  - book_vaz_roldao_2016
---

# Alternators and exterior algebras

## Permutations and alternators
A permutation of the set of $p$ elements $A = \set{1,\dots,p}$ is a bijection $\sigma: A\to A$ represented by the cycle

$$
\begin{matrix}
  1 & \cdots & p \\
  \sigma(1) & \cdots & \sigma(p)
\end{matrix}
$$

The set of all permutations is group called the symmetric group, denoted $S_p$. The number of elements in $S_p$ is $p!$.

A permutation $\sigma$ of the set $\set{1,\dots,p}$ such that $\sigma(k) = k$ for all $k \neq i$, and $k \neq j$, and moreover $\sigma(i) = j$ and $\sigma(j) = i$, is called a transposition. A permutation of $n$ elements is even or odd if the permutation is obtained respectively by an even or odd number of transpositions. The sign $\varepsilon(\sigma)$ of the permutation $\sigma$ is defined to be $\varepsilon(\sigma) = 1$ if the permutation is even, and $\varepsilon(\sigma) = -1$ if the permutation is odd.

Let us consider a tensor that is either contravariant or covariant of the form $\bigotimes_{i=1}^p X_i$, where $X$ denotes respectively either a vector or a coverctor, and the indices enumerate such elements. The operator $\operatorname{alt}$ called alternator is defined in the following way

$$
  \operatorname{alt}(X_1 \otimes\cdots\otimes X_p) = \frac{1}{p!} \sum_{\sigma\in S_p} \varepsilon(\sigma) X_{\sigma(1)} \otimes\cdots\otimes X_{\sigma(p)}
$$

The alternator is a projection operator, i.e. $\operatorname{alt}^2 = \operatorname{alt}$. Considers covariant tensors of the form $\bigotimes_{i=1}^p \alpha_i$ given by

$$
  (\alpha_1 \otimes\cdots\alpha_p)(\mathbf{v}_1,\dots,\mathbf{v}_p) = \alpha_1 (\mathbf{v}_1)\cdots\alpha_p (\mathbf{v}_p)
$$

The alternator of a contravariant tensor is then defined by writing the resulting tensor acting on vectors as

$$
  \operatorname{alt}(\alpha_1 \otimes\cdots\otimes\alpha_p)(\mathbf{v}_1,\dots,\mathbf{v}_p) = \frac{1}{p!}\begin{vmatrix}
    \alpha_1 (\mathbf{v}_1) & \cdots & \alpha_1 (\mathbf{v}_p) \\
    \vdots & \ddots & \vdots \\
    \alpha_p (\mathbf{v}_1) & \cdots & \alpha_p (\mathbf{v}_p)
  \end{vmatrix}
$$

The right-hand side is the determinant of the associated matrix. If $\mathbf{A}$ is the matrix of order $p$ with entries $\mathbf{A}_{ij}$, then the determinant of $\mathbf{A}$ is defined as

$$
  \det(\mathbf{A}) = \sum_{\sigma\in S_p} \epsilon(\sigma) \mathbf{A}_{1\sigma(1)}\cdots \mathbf{A}_{p\sigma(p)}
$$

### Alternating tensors

<MathBox title='Alternating vectors and covectors' boxType='definition'>
A $p$-vector is an alternating contravariant tensor of order $p$. A $p$-vector is denoted by $\mathbf{A}_{[p]}$ and is characterized by

$$
  \mathbf{A}_{[p]} = \operatorname{alt}(\mathbf{A}_{[p]})
$$

In particular, if $\mathbf{A}_p \in \mathrm{T}_p (V)$, the space of contravariant tensors of order $p$, then $\operatorname{alt}(\mathbf{A}_p)$ is a $p$-vector, since $\operatorname{alt}(\operatorname{alt}(\mathbf{A}_p)) = \operatorname{alt}(\mathbf{A}_p)$.

A $p$-covector is an alternating covariant tensor of order $p$. It is denoted by $\Psi^{[p]}$, and is characterized by

$$
  \Psi^{[p]} = \operatorname{alt}(\Psi^{[p]})
$$

The spaces of $p$-vectors and $p$-covectors are denoted $\Lambda_p (V)$ and $\Lambda^p (V)$, respectively. In particular,
- $\Lambda^0 (V) = \Lambda_0 (V) = \R$
- $\Lambda^1 (V) = V^*$
- $\Lambda_1 (V) = V$
</MathBox>

It is common to use the term bivector for a $2$-vector, trivector for a $3$-vector, and so on (analogously for the $p$-covectors.)

<MathBox title='Bicovectors and trivectors' boxType='example'>
Let $\Psi = \Psi_{ij} \varepsilon^i \otimes \varepsilon^j \in \mathrm{T}^2 (V)$ be a covariant tensor of rank $2$. A $2$-covector $\Psi^{[2]} \in\Lambda^2 (V)$ is alternating by definitions

$$
\begin{align*}
  \Psi^{[2]} =& \frac{1}{2} \Psi_{ij} (\varepsilon^i \otimes \varepsilon^j - \varepsilon^j \otimes \varepsilon^i) \\
  =& \frac{1}{2} (\Psi_{ij} - \Psi_{ji}) \varepsilon^i \otimes \varepsilon^j
\end{align*}
$$

In this case, the inequality $\dim(V)\geq 2$ must hold since, if $\dim(V) = 1$ it follows that

$$
  \Psi^{[2]} = \frac{1}{2} \Psi_{11} (\mathbf{e}^1 \otimes \mathbf{e}^1 - \mathbf{e}^1 \otimes \mathbf{e}^1) = 0
$$

Let now $\mathbf{A} = A^{ijk} \mathbf{e}_i \otimes \mathbf{e}_j \otimes \mathbf{e}_k \in \mathrm{T}_3 (V)$ be a contravariant tensor of rank $3$. A $3$-vector $\mathbf{A}_{[3]} \in\Lambda_3 (V)$ can be written as

$$
\begin{align*}
  \mathbf{A}_{[3]} =& \frac{1}{6} A^{ijk} (\mathbf{e}_i \otimes \mathbf{e}_j \otimes \mathbf{e}_k + \mathbf{e}_j \otimes \mathbf{e}_k \otimes \mathbf{e}_i + \mathbf{e}_k \otimes \mathbf{e}_i \otimes \mathbf{e}_j \\
  & - \mathbf{e}_k \otimes \mathbf{e}_j \otimes \mathbf{e}_i - \mathbf{e}_j \otimes \mathbf{e}_i \otimes \mathbf{e}_k \mathbf{e}_i \otimes \mathbf{e}_k \otimes \mathbf{e}_j) \\
  =& \frac{1}{6} (A^{ijk} + A^{jki} + A^{kij} - A^{kji} - A^{jik} - A^{ikj}) \mathbf{e}_i \otimes \mathbf{e}_j \otimes \mathbf{e}_k
\end{align*}
$$

In this case, $\dim(V)\geq 3$, otherwise $\mathbf{A}_{[3]} = 0$.
</MathBox>

Consider the space $\mathrm{T}^p (V)$ of covariant tensors of rank $r$ with basis

$$
  B^p = \Set{\bigotimes_{k=1}^p \varepsilon^{i_k} | i_k = 1,\dots,n}
$$

where $\dim(V) = n$. A $p$-covector $\Psi^{[p]} \in\Lambda^p (V)$ can be written as $\Psi^{[p]} = \operatorname{alt}(\Psi^p)$, where $\Psi^p \in \mathrm{T}^p (V)$. To determine $\dim[\Lambda^p (V)]$, we count the basis elements of $\mathrm{T}^p (V)$ that contribute to $\Lambda^p (V)$.

The alternator $\operatorname{alt}$ annihilates all elements in $B^p$ that contain repeated indices. Thus, we must select index tuples $(i_1,\dots,i_p)$ with distinct values. There a $n$ choices for $i_1$, then $n - 1$ choices for $i_2$, continuing until $i_p$, which has $n - p + 1$ choices. This results in $n(n - 1)\cdots(n - p + 1)$ basis elements. However, these elements are not all independent in $\Lambda^p (V)$ because the alternator symmetrizes over index permutations, treating any permutation of a given set $\set{i_1,\dots,i_p}$ as the same. Since there are $p!$ such permutations, we by divide by $p!$, yielding

$$
  \dim[\Lambda^p (V)] = \dim[\Lambda_p (V)] = \frac{n(n-1)\cdots(n - p + 1)}{p!} = \frac{n!}{(n-p)! p!} = \binom{n}{p}
$$

Using the symmetry of binomial coefficients $\binom{n}{p} = \binom{n}{n - p}$, it follows that

$$
  \dim[\Lambda^p (V)] = \dim[\Lambda^{n-p} (V)]
$$

Although the spaces $\Lambda^p (V)$ and $\Lambda^{n-p} (V)$ have the same dimension are isomorphic, there is no natural isomorphism between them.

## Exterior product

<MathBox title='Exterior product (wedge product)' boxType='definition'>
Let $\mathbf{A}_{[p]} \in\Lambda_p (V)$ be a $p$-vector and let $\mathbf{B}_{[q]} \in\Lambda_q (V)$ be a $q$-vector. The exterior product (or wedge product) $\wedge: \Lambda_p (V) \to \Lambda_q (V)$ is defined as

$$
  \mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]} = \operatorname{alt}(\mathbf{A}_{[p]} \otimes \mathbf{B}_{[q]}) = \frac{p!q!}{(p + q)!} \sum_{\sigma\in S_{p,q}} (\mathbf{A}_{[p]} \otimes \mathbf{A}_{[q]})^\sigma
$$

where $S_{p,q}$ is the subset of $S_{p + q}$ containing all permutations $\sigma$ such that $\sigma(i) < \sigma(i + 1)$ if $0 < i < p$, or $p < i < p + 1$.

In particular, for vectors $\mathbf{u}, \mathbf{v}\in \Lambda_1 (V)$ we have


$$
  \mathbf{u}\wedge\mathbf{v} = \frac{1}{2} (\mathbf{u}\otimes\mathbf{v} - \mathbf{v}\otimes\mathbf{u})
$$

from which it follows that

$$
\begin{equation*}
  \mathbf{u}\wedge\mathbf{v} = -\mathbf{v}\wedge\mathbf{u}
\tag{\label{equation-1}}
\end{equation*}
$$
</MathBox>

<MathBox title='Properties of exterior product' boxType='proposition'>
Let $\mathbf{A}_{[p]} \in \Lambda_p (V)$, $\mathbf{B}_{[q]} \in \Lambda_q (V)$,  $\mathbf{C}_{[r]} \in \Lambda_r (V)$ and $a\in\Lambda_0 (V) = \R$. Then:
1. **Associativity:** $(\mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]}) \wedge \mathbf{C}_{[r]} = \mathbf{A}_{[p]} \wedge (\mathbf{B}_{[q]} \wedge \mathbf{C}_{[r]})$
2. **Bilinearity:** $a\wedge\mathbf{A}_{[p]} = a\mathbf{A}_{[p]}$

In particular,

$$
  \mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]} \wedge \mathbf{C}_{[r]} = \frac{p!q!r!}{(p + q + r)!} \sum_{\sigma\in S_{p,q,r}} (\mathbf{A}_{[p]} \otimes \mathbf{B}_{[q]} \otimes \mathbf{C}_{[r]})
$$

where $S_{p,q,r}\subset S_{p+q+r}$ contains all $\sigma$ such that $\sigma(i) < \sigma(i + 1)$ if
- $0 < i < p$ or $p < i < p + q$, and
- $0 < i < p + q$ or $p + q < i < p + q + r$
</MathBox>

From the associativity and bilinearity of the exterior product, we can generalize $\eqref{equation-1}$ as follows: Let $\mathbf{A}_{[p]} \in\Lambda_p (V)$ and $\mathbf{B}_{[q]} \in\Lambda_q (V)$ have the form

$$
\begin{equation*}
\begin{split}
  \mathbf{A}_{[p]} =& \bigwedge_{i=1}^p \mathbf{u}_i \\
  \mathbf{B}_{[q]} =& \bigwedge_{j=1}^q \mathbf{v}_j
\end{split}
\tag{\label{equation-2}}
\end{equation*}
$$

The exterior product $\mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]}$ can thus be written

$$
  \mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]} = \bigwedge_{i=1}^p \mathbf{u}_i \wedge \bigwedge_{j=1}^q \mathbf{v}_j
$$

Applying $\eqref{equation-1}$, we can reorder the right-hands side as

$$
  \bigwedge_{i=1}^p \mathbf{u}_i \wedge \bigwedge_{j=1}^q \mathbf{v}_j = (-1)^{pq} \bigwedge_{j=1}^q \mathbf{v}_j \wedge \bigwedge_{i=1}^p \mathbf{u}_i
$$

or 

$$
  \mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]} = (-1)^{pq} \mathbf{B}_{[q]} \wedge \mathbf{A}_{[p]}
$$

A $p$-vector that can be written as the exterior product of a $p$ numbr of $1$-vectors, as in $\eqref{equation-2}$, is called a simple $p$-vector. In vector spaces $V$ with $\dim(V) \leq 3$, every $p$-vector is simples. For $\dim(V) \geq 4$, not all $p$-vectors are simples. For instance, let $V$ be a vector space of dimension $4$, with basis $\set{\mathbf{e}_1, \mathbf{e}_2, \mathbf{e}_3, \mathbf{e}_4}$. Let $\mathbf{A}_{[2]}$ be the $2$-vector given by $\mathbf{A}_{[2]} = \mathbf{e}_1 \wedge \mathbf{e}_2 + \mathbf{e}_3 \wedge \mathbf{e}_4$. There is no linear combination of the basis vectors $set{\mathbf{e}_i}_{i=1}^4$ that allows us to write $\mathbf{A}_{[2]} = \mathbf{v}_1 \wedge \mathbf{v}_2$.

<details>
<summary>Proof</summary>

Let $0 \neq \boldsymbol{\psi}\in\Lambda_2 (V)$. Then, $\boldsymbol{\psi}$ is simple if and only if $\boldsymbol{\psi}\wedge\boldsymbol{\psi} = 0\in\Lambda_4 (V)$. 

**Proof ($\impliedby$):**
If $\boldsymbol{\psi} = \mathbf{u}\wedge\mathbf{v}$, for $\mathbf{u},\mathbf{v}\in V$, then

$$
\begin{align*}
  \boldsymbol{\psi}\wedge\boldsymbol{\psi} =& \mathbf{u}\wedge\mathbf{v} \wedge \mathbf{u} \wedge \mathbf{v} \\
  =& \mathbf{u}\wedge\mathbf{v} \wedge(- \mathbf{v} \wedge \mathbf{u}) \\
  =& -\mathbf{u} \wedge \underbrace{(\mathbf{v} \wedge \mathbf{v})}_{=0} \wedge \mathbf{u} \\
  =& 0
\end{align*}
$$

**Proof ($\implies$):**
The converse can be shown by induction on $\dim(V)$. In the base cases $\dim(V) = 0$ or $1$, then $\Lambda_2 (V) = \set{0}$, and therefore the first case to be considered is when $\dim(V) = 2$. In this case, $\dim[\Lambda_2 (V)] = 1$, and $\mathbf{v}_1 \wedge \mathbf{v}_2$ is a non-trivial element if $\set{\mathbf{v}_1, \mathbf{v}_2}$ is a basis of $V$ and $\boldsymbol{\psi}$ is simple.

Now let us consider the case $\dim(V) = 3$. Given $0\neq \boldsymbol{\psi}\in\Lambda_2 (V)$, let us define a mapping $\mathrm{A}:V \to\Lambda_2 (V)$ by $\operatorname{A}(\mathbf{v}) = \boldsymbol{\psi}\wedge\mathbf{v}$. Since $\dim[\Lambda_3 (V)] = 1$, therefore $\dim[\ker(A)] \geq 2$. Now let $\mathbf{u}_1, \mathbf{u}_2 \in\ker(A)$ be linearly independent vectors which can be extended to a basis $\set{\mathbf{u}_1,\mathbf{u}_2,\mathbf{u}_3}$ of $V$, so we can write

$$
  \boldsymbol{\psi} = a\mathbf{u}_1 \wedge \mathbf{u}_2 + b\mathbf{u}_1 \wedge \mathbf{u}_3 + c\mathbf{u}_2 \wedge \mathbf{u}_3
$$

By definition, $\mathrm{A}(\mathbf{u}_1) = 0$, and therefore $0 = \boldsymbol{\psi}\wedge\mathbf{u}_1 = c\mathbf{u}_1 \wedge\mathbf{u}_2 \wedge\mathbf{u}_3$, which implies that $c = 0$. Similarly, $\operatorname{A}(\mathbf{u}_2) = 0$, and so $0 = \boldsymbol{\psi}\wedge\mathbf{u}_2 = -b\mathbf{u}_1 \wedge \mathbf{u}_2 \wedge \mathbf{u}_3$, which means that $b = 0$. It follows that $\boldsymbol{\psi} = a \mathbf{u}_1 \wedge \mathbf{u}_2$, which is simple.

Suppose now by induction that the assumption holds for $\dim(V) \leq n - 1$, and consider the case where $\dim(V) = n$. In terms of the basis $\set{\mathbf{v}_i}_{i=1}^n$, we can expand $\boldsymbol{\psi}$ as

$$
\begin{align*}
  \operatorname{\psi} =& \sum_{1\leq i < j}^n a_{ij} \mathbf{v}_i \wedge \mathbf{v}_j = \left( \sum_{i=1}^{n-1} a_{in} \mathbf{v}_i \right) \wedge \mathbf{v}_n 0 \sum_{1 \leq i < j}^{n-1} a_{ij} \mathbf{v}_i \wedge \mathbf{v}_j \\
  =& \mathbf{u}\wedge\mathbf{v}_n + \boldsymbol{\psi}'
\end{align*}
$$

where $U$ is the subspace generated by $\set{\mathbf{v}_i}_{i=1}^{n-1}$, $\mathbf{u}\in U$, and $\boldsymbol{\psi}' \in\Lambda_2 (U)$. Now,

$$
\begin{align*}
  0 =& \boldsymbol{\psi} \wedge\boldsymbol{\psi} = (\mathbf{u}\wedge\mathbf{v}_n + \boldsymbol{\psi}') \wedge (\mathbf{u}\wedge\mathbf{v}_n + \boldsymbol{\psi}') \\
  =& 2\mathbf{u}\wedge\boldsymbol{\psi}' \wedge \mathbf{v}_n + \boldsymbol{\psi}' \wedge \boldsymbol{\psi}'
\end{align*}
$$

but $\mathbf{v}_n$ appears neither in the expansion of $\mathbf{u}\wedge\boldsymbol{\psi}'$ nor in the expansion of $\boldsymbol{\psi}' \wedge\boldsymbol{\psi}'$, and separately we obtain $\mathbf{u}\wedge\boldsymbol{\psi}' = 0 = \boldsymbol{\psi}' \wedge \boldsymbol{\psi}'$. By induction, $0 = \boldsymbol{\psi}' \wedge \boldsymbol{\psi}'$ implies that $\boldsymbol{\psi}' = \mathbf{u}_1 \wedge \mathbf{u}_2$, and so $\mathbf{u} \wedge \mathbf{u}_1 \wedge \mathbf{u}_2 = 0$. Hence, there exists $\mu, \lambda_1, \lambda_2 \in \mathbb{F}$ such that $\mu\mathbf{u} + \lambda_2 \mathbf{u}_2 + \lambda_1 \mathbf{u}_1 = 0$. If $\mu = 0$, then $\mathbf{u}_1$ and $\mathbf{u}_2$ are linearly dependent, and therefore $\boldsymbol{\psi}' = \mathbf{u}_1 \wedge \mathbf{u}_2 = 0$, which means that $\boldsymbol{\psi} = \mathbf{u}\wedge\mathbf{v}_n$, and therefore $\boldsymbol{\psi}$ is simple. If $\mu\neq 0$, then $\mathbf{u} = -\frac{\lambda_2}{\mu}\mathbf{u}_2 - \frac{\lambda_1}{\mu}\mathbf{u}_1$ and

$$
  \boldsymbol{\psi} = -\frac{\lambda_1}{\mu}\mathbf{u}_1 \wedge \mathbf{v}_n - \frac{\lambda_2}{\mu} \mathbf{u}_2 \wedge\mathbf{v}_n + \mathbf{u}_1 \wedge \mathbf{u}_2
$$

corresponding to the tree-dimensional case, which was shown to be always simple.
</details>

## Bases

Let $V$ be an $n$-dimensional vector space with basis $B = \set{\mathbf{e}_i}_{i=1}^n$. From this basis, we can construct a basis for each one of the spaces $\Lambda_p (V)$.

Consider at first the space $\Lambda_2 (V)$ and the exterior product of the form $\mathbf{e}_i \wedge \mathbf{e}_j$. Because of the anit-commutativity of the exterior product between basis vectors, the linearly independent set of $2$-vectors is provided by

$$
\begin{align*}
  &\mathbf{e}_1 \wedge \mathbf{e}_2,\; \mathbf{e}_1 \wedge \mathbf{e}_3,\;\dots,\mathbf{e}_1 \wedge \mathbf{e}_n, \\
  &\mathbf{e}_2 \wedge \mathbf{e}_3,\; \mathbf{e}_2 \wedge \mathbf{e}_4,\;\dots,\mathbf{e}_2 \wedge \mathbf{e}_n, \\
  &\vdots \\
  &\mathbf{e}_{n-1} \wedge \mathbf{e}_n
\end{align*}
$$

Thus, there are $(n-1) + (n - 2) + \dots + 1 = n(n - 1)/2$ elemets, which is precisely $\dim[\Lambda_2 (V)]$. This set of $2$-vectors forms a basis for $\Lambda_2 (V)$. An arbitrary $2$-vector $\mathbf{A}_{[2]}$ can therefore by written as

$$
  \mathbf{A}_{[2]} = \frac{1}{2} \sum_{i,j} A^{ij} \mathbf{e}_i \wedge \mathbf{e}_j = \sum_{i < j} A^{ij} \mathbf{e}_i \wedge \mathbf{e}_j
$$

This result can be generalized for $\Lambda_p (V)$. A basis for this space consists of elements of the form $\mathbf{e}_{\mu_1} \wedge\cdots\wedge \mathbf{e}_{\mu_p}$, and the number of distinct elements is the number of $p$-combination of $n$ elements, denoted $\binom{n}{p}$. An arbitrary $p$-vector $\mathbf{A}_{[p]} \in\Lambda_p (V)$ can be written as

$$
\begin{align*}
  \mathbf{A}_{[p]} =& \frac{1}{p!} \sum_{\mu_1,\dots,\mu_p} A^{\mu_1 \cdots \mu_p} \bigwedge_{i=1}^p \mathbf{e}_{\mu_i} \\
  =& \sum_{\mu_1 <\cdots < \mu_p} A^{\mu_1 \cdots \mu_p} \bigwedge_{i=1}^p \mathbf{e}_{\mu_i}
\end{align*}
$$

## Pseudoscalars

Let $V$ be an $n$-dimensional vector space. The exterior product of $m$ vectors is $0$ whenever $m > n = \dim(V)$. To see this, consider the exterior product of $n + 1$ vectors $\bigwedge_{i=1}^{n+1} \mathbf{v}_i$. If $\dim(V) = n$, there are at most $n$ linearly independent vectors. Therefore, the $n + 1$ given vectors are necessarily linearly dependent and we can write one of those vectors as a linear combination of the others. Without loss of generality, it is possible to choose such a vector as being $\mathbf{v}_{n+1}$. If follows that $\mathbf{v}_{n+1} = \sum_{n=1}^n a^i \mathbf{v}_i$. Substituting this into the exterior product and using multilinearity and anit-commutation, we obtain

$$
\begin{align*}
  \bigwedge_{i=1}^{n+1} \mathbf{v}_i =& \left(\bigwedge_{i=1}^n \mathbf{v}_i \right) \wedge \left(\sum_{j=1}^n a^j \mathbf{v}_j \right) \\
  =& (-1)^{n-1} a^1 \mathbf{v}_1 \wedge \mathbf{v}_1 \wedge \mathbf{v}_2 \wedge\cdots\wedge \mathbf{v}_n \\
  &+ (-1)^{n-2} a^2 \mathbf{v}_1 \wedge \mathbf{v}_2 \wedge \mathbf{v}_2 \wedge \mathbf{v}_3 \wedge\cdots\wedge \mathbf{w}_n \\
  &+\cdots+ a^n \mathbf{v}_1 \wedge\cdots\wedge \mathbf{v}_{n-1} \wedge \mathbf{v}_n \wedge \mathbf{v}_n = 0
\end{align*}
$$

Consequently, we have

$$
  \bigwedge_{i=1}^m \mathbf{v}_i = 0,\; m > n
$$

In fact, a stronger result holds:

$$
  \bigwedge_{i=1}^p \mathbf{v}_i = 0 \iff \set{\mathbf{v}_i}_{i=1}^p \text{ is linearly dependent}
$$

This implies that $\Lambda_p (V) = \set{0}$ for $p > n$. Thus, the nontrivial vector spaces that can be constructed are

$$
  \Lambda_0 (V), \Lambda_1 (V),\dots,\Lambda_{n-1} (V), \Lambda_n (V)
$$

satisfying $\Lambda_p (V) = \dim[\Lambda_{n-p} (V)]$. In particular, the space $\Lambda_n (V)$ has dimension $\binom{n}{n} = 1$. A basis for this space consists of the element $\bigwedge_{i=1}^n \mathbf{v}_i$, where $\set{\mathbf{v}_i}_{i=1}^n$ is a set of linearly independent vectors. If $B = \set{\mathbf{e}_i}_{i=1}^n$ is a basis of $V$, a natural basis for $\Lambda_n (V)$ is $\bigwedge_{i=1}^n \mathbf{e}_i$. Due to the anti-commutativity of the exterior product, any permutation of the basis vectors results in the same element up to a sign:

$$
  \bigwedge_{i=1}^n \mathbf{e}_{\sigma(i)} = \operatorname{sgn}(\sigma) \bigwedge_{i=1}^n \mathbf{e}_i
$$

Thus, the exterior product of $n$ linearly independent vectors can be written as a scalar multiple of this basis element:

$$
  \bigwedge_{i=1}^n \mathbf{v}_i = a \bigwedge_{i=1}^n \mathbf{e}_i,\; a\in\mathbb{F}
$$

The elements of $\Lambda_n (V)$ are called $n$-vectors, or more commonly, *pseudoscalars*.

## The exterior algebra $\Lambda(V)$

<MathBox title='Exterior algebra' boxType='definition'>
Let $V$ be an $n$-dimensional vector space. Consider the vector space $\Lambda(V)$ defined by the direct sum of the vectors spaces $\Lambda_p (V)$:

$$
  \Lambda (V) = \bigoplus_{p=0}^n \Lambda_p (V)
$$

The pair $(\Lambda(V), \wedge)$ is called the exterior algebra associated with the vector space $V$. An arbitary element $\mathbf{A}\in \Lambda(V)$ is called a multivector, and is written

$$
\begin{align*}
  \mathbf{A} =& \underbrace{a}_{\text{scalar}} + \underbrace{v^i e_i}_{\text{vector}} + \underbrace{F^{ij} e_i \Lambda e_j}_{2\text{-vector}} \\
  &+ \underbrace{T^{ijk} e_i \Lambda e_j \Lambda e_k}_{3 \text{-vector}} + \cdots + \underbrace{p e_1 \Lambda\cdots\Lambda e_n}_{n \text{-vector}} \in \Lambda(V)
\end{align*}
$$

The dimension of $\Lambda (V)$ is given by

$$
  \dim[\Lambda (V)] = \sum_{p=0}^n \dim[\Lambda_P (V)] = \sum_{p=0}^n \binom{n}{p} = 2^n
$$

We define the projection $\braket{\cdot}_p : \Lambda (V) \to \Lambda_p (V)$ such that

$$
  \braket{A}_p = \mathbf{A}_{[p]}
$$

where $\mathbf{A}_{[p]} \in \Lambda_p (V)$ is the $p$-vector component of the multivector $\mathbf{A}\in\Lambda (V)$.
</MathBox>

The operations grade involution, reversion, and conjugation, as dened in the tensor algebra, descend to the exterior algebra, since they leave the ideal invariant. The grade involution is given by

$$
  \#(\mathbf{A}_{[p]}) = \widehat{\mathbf{A}}_{[p]} = (-1)^p \mathbf{A}_{[p]}
$$

For the reversion, it follows that

$$
  \widetilde{\left(\bigwedge_{i=1}^p \mathbf{v}_i \right)} = \bigwedge_{i=p}^1 \mathbf{v}_i
$$

which implies that

$$
  \widehat{\mathbf{A}}_{[p]} = (-1)^{p(p-1)/2} \mathbf{A}_{[p]}
$$

The conjugation is known to the be composition of the two operations

$$
  \overline{\mathbf{A}}_{[p]} = \widetilde{\widehat{\mathbf{A}}}_{[p]} = \widehat{\widetilde{\mathbf{A}}}_{[p]}
$$

<MathBox title="Cramer's rule" boxType='example'>
Cramer's rule for solving linear equations can be derived in terms of exterior algebras. Consider a system of $n$ linear equations in $n$ unknowns

$$
  \mathbf{Ax} = \mathbf{y}
$$

where $\mathbf{A}\in\R^{n\times n}$ and $\mathbf{x},\mathbf{y}\in\R^n$. In terms of basis $\set{\mathbf{e}_i}_{i=1}^n$ of $\R^n$, we can expand the columns of $\mathbf{A}$ explicitly as

$$
  \sum_{i=1}^n x_i \mathbf{a}_i = \mathbf{y}
$$

where each $\mathbf{a}_j \in\R^n$ is the $j$th column of $\mathbf{A}$. Taking the exterior product with $\mathbf{a}_1,\dots,\widehat{\mathbf{a}}_k,\dots,\mathbf{a}_n$, i.e. all $\mathbf{a}_j$ except $\mathbf{a}_k$ for $k\in\set{1,\dots,n}$, annihilates all terms in the sum except $x_k \mathbf{a}_k$:

$$
\begin{align*}
  \left(\sum_{i=1}^n x_i \mathbf{a}_i \right) \wedge \bigwedge_{j\neq k} \mathbf{a}_i =& \mathbf{y} \wedge \bigwedge_{j\neq k} \mathbf{a}_j \\
  x_k \bigwedge_{i=1}^n \mathbf{a}_i =& \mathbf{y} \wedge \bigwedge_{i\neq k} \mathbf{a}_j
\end{align*}
$$

Solving for $x_k$ yields

$$
  x_k = \frac{\mathbf{y}\wedge \bigwedge_{j\neq k} \mathbf{a}_j}{\bigwedge_{j=1}^n \mathbf{a}_j}
$$

Each exterior product of $n$ vectors in $\R^n$ corresponds to a determinant:

$$
  \bigwedge_{i=1}^n \mathbf{a}_i = \det(\mathbf{A}) \bigwedge_{i=1}^n \mathbf{e}_i
$$

Likewise,

$$
  \mathbf{y} \bigwedge_{j\neq k} \mathbf{a}_j = \det(\mathbf{A}_k) \bigwedge_{i=1}^n \mathbf{e}_i
$$

where $\mathbf{A}_k$ is the matrix formed by replacing the $k$-column of $\mathbf{A}$ wwith $\mathbf{y}$. Hence, we arrive at

$$
  x_k = \frac{\det(\mathbf{A}_k)}{\det{\mathbf{A}}}
$$

which is precisely Cramer's rule.
</MathBox>

### The exterior algebra as the quotient of the tensor algebra

<MathBox title='Ideals' boxType='definition'>
Let $\mathcal{A}$ denote an algebra. A subset $I_\text{L} \subseteq \mathcal{A}$ is a *left ideal* of $\mathcal{A}$ if, for all $a\in\mathcal{A}$ and for all $x\in I_\text{L}$, the relation $ax\in I_\text{L}$ holds. Similarly, $I_\text{R} \subset\mathcal{A}$ is a *right ideal* of $\mathcal{A}$ if, for all $a\in\mathcal{A}$ and $x\in I_\text{R}$, it follows that $xa \in I_\text{R}$. The set $I \subset \mathcal{A}$ is a *two-sided ideal*, or, *bilateral idela* of $\mathcal{A}$ if, for all $a,b\in\mathcal{A}$ and $i\in I$, we have $axb \in I$. Two-sided ideals are also simply called ideals.
</MathBox>

<MathBox title='Quotient algebra by an ideal' boxType='proposition'>
Let $\mathcal{A}$ be an algebra given as a sum of two subspaces:

$$
  \mathbf{A} = \mathcal{B} + \mathcal{C}
$$

Here, we do not assume a priori that $\mathcal{B}$ or $\mathcal{C}$ are subalgebras, nor that the sum i direct. If $\mathcal{C}$ is a two-sided ideal, then the quotient space $\mathcal{A}/\mathcal{C}$ becomes an algebra, called the quotient algebra $\mathcal{A}$ by the ideal $\mathcal{C}$. In particular if $\mathcal{A} = \mathcal{B} \oplus \mathcal{C}$, then $\mathbf{A}/\mathcal{C} = \mathcal{B}$.

<details>
<summary>Proof</summary>

Given $a,b\in\mathcal{A}$, define following equivalence relation $\sim$ on $\mathcal{A}$:

$$
  a \sim b \iff a = b + x,\; x\in\mathcal{C}
$$

The set of equivalence classes under this relation is denoted $\mathcal{A}/\mathcal{C}$, and inherits a natural vector space structure defined by

$$
\begin{align*}
  [a] + [b] :=& [a + b], \\
  \alpha[a] :=& [\alpha a], \; \alpha\in\mathbb{F} 
\end{align*}
$$

To endow $\mathcal{A}/\mathcal{C}$ with an algebra structure, we define the product of equivalence classes by

$$
  [a][b] := [ab]
$$

To ensure this is well-defined, we must verify that the product is independent of the choice of representatives. Suppose

$$
  [a] = [a + x],\quad [b] = [b + y],\; x,y\in\mathcal{C}
$$

then

$$
\begin{align*}
  [a][b] =& [a + x] [b + y] = [(a + x)(b + y)] \\
  =& [ab + ay + xb + xy]
\end{align*}
$$

Thus, for the product to be well-defined, $ay + xb + xy$ must belong to $\mathcal{C}$, i.e.

$$
  ay + xb + xy \in \mathcal{C},\quad \forall a,b \in \mathcal{A},\; \forall x, y \in\mathcal{C}
$$

which only holds if $\mathcal{C}$ is a two-sided ideal.
</details>
</MathBox>

Let $\operatorname{T}(V)$ denote the algebra of contravariant tensors over a vector space $V$. Let $\mathcal{I}_E$ be the ideal of $\operatorname{T}(V)$, generated by the elements $\mathbf{v}\otimes\mathbf{v}$ for $\mathbf{v}\in V$. Explicitly, $\mathcal{I}_E$ consists of finite sums

$$
  \sum_i \mathbf{A}_i \otimes \mathbf{v}_i \otimes \mathbf{v}_i \otimes \mathbb{B}_i
$$

where $\mathbf{v}_i \in V$, and $\mathbf{A}_i, \mathbf{B}_i \in \mathcal{T}(V)$. Equivalently, $\mathcal{I}_E$ is generated by the set of symmetric tensors of rank $2$, which lie in the kernel of the alternation map $\operatorname{alt}: \operatorname{T}(V) \to \Lambda (V)$:

$$
  \mathbf{v}\otimes\mathbf{u} + \mathbf{u}\otimes\mathbf{v} \in \operatorname{ker}(\operatorname{alt}) = \mathcal{I}_E,\; \forall  \mathbf{v},\mathbf{u}\in V
$$

We now show that the exterior algebra $\Lambda(V)$ is isomorphic to the quotient algebra $\operatorname{T}(V)/\mathcal{I}_E$. The underlying equivalence relation of this quotient is given by

$$
  \mathbf{A} \sim \mathbf{B} \iff \mathbf{A} = \mathbf{B} + \mathbf{x},\; \mathbf{x} \in \mathcal{I}_E
$$

The equivalence class of $\mathbf{A}$ is denoted $[\mathbf{A}]$, and the exterior product of equivalence classes is given by

$$
\begin{equation*}
  [\mathbf{A}] \wedge [\mathbf{B}] = [\mathbf{A} \otimes \mathbf{B}]
\tag{\label{equation-4}}
\end{equation*}
$$

For all $\mathbf{u}, \mathbf{v}\in V$, we have $[\mathbf{u}] \sim \mathbf{u}$, and similarly for $\mathbf{v}$. Applying $\eqref{equation-4}$, we can compute $\mathbf{v}\wedge\mathbf{u}$ by noting

$$
  \mathbf{v}\otimes\mathbf{u} = \frac{1}{2} (\mathbf{v}\otimes\mathbf{u} - \mathbf{u}\otimes\mathbf{v}) + \frac{1}{2}(\mathbf{v}\otimes\mathbf{u} + \mathbf{u}\otimes\mathbf{v})
$$

where the symmetric part $\frac{1}{2}(\mathbf{v}\otimes\mathbf{u} + \mathbf{u}\otimes\mathbf{v})$ belongs to $\mathcal{I}_E$, as shown by the identity

$$
  (\mathbf{v}\otimes\mathbf{u} + \mathbf{u}\otimes\mathbf{v}) = (\mathbf{v} + \mathbf{u})\otimes(\mathbf{v} + \mathbf{u}) - \mathbf{v}\otimes\mathbf{v} - \mathbf{u}\otimes\mathbf{u}
$$

Hence, in the quotient algebra:

$$
  \mathbf{v}\otimes\mathbf{u} \sim \mathbf{v}\wedge\mathbf{u} = \frac{1}{2} (\mathbf{v}\otimes\mathbf{u} - \mathbf{u}\otimes\mathbf{v})
$$

or $[\mathbf{v}\otimes\mathbf{u}] = [\mathbf{v}\wedge\mathbf{u}]$ and $[\mathbf{v}]\wedge[\mathbf{u}] = [\mathbf{v}\wedge\mathbf{u}]$. This result can be generalized as

$$
  \bigotimes_{i=1}^p \mathbf{v}_i \sim \operatorname{alt}\left(\bigotimes_{i=1}^p \mathbf{v}_i \right) = \bigwedge_{i=1}^p \mathbf{v}_i
$$

In fact, $\bigotimes_{i=1}^p \mathbf{v}_i$ is congruent to every permutation $\left(\bigotimes_{i=1}^p \mathbf{v}_i \right)^\sigma$, since this assertion holds when $\sigma$ is the transposition of to consecutive elements of $\set{1,\dots,p}$. These transpositions generate the symmetric group $S_p$.

<MathBox title='' boxType='proposition'>
Let $\operatorname{T}(V)$ denote the algebra of contravariant tensors over a vector space $V$. Suppose $\mathcal{I}_E$ is the ideal of $\operatorname{T}(V)$, generated by the elements $\mathbf{v}\otimes\mathbf{v}$ for $\mathbf{v}\in V$. Then $\operatorname{T}(V)$ is the direct sum of $\Lambda(V)$ and $\operatorname{ker}(\operatorname{alt})$, which is equal $\mathbf{I}_E$, i.e.

$$
  \operatorname{T}(V) = \Lambda(V) \oplus \operatorname{ker}(\operatorname{alt}) = \Lambda (V) + \mathcal{I}_E
$$

It follows immediately that

$$
\begin{equation*}
  \Lambda(V) = \operatorname{T}(V) / \mathcal{I}_E
\tag{\label{equation-5}}
\end{equation*}
$$

and that for all $\mathbf{A}, \mathbf{B} \in \Lambda(V)$

$$
  \mathbf{A} \wedge \mathbf{B} \sim \mathbf{A} \otimes \mathbf{B} \mod \mathcal{I}_E
$$
</MathBox>

The universal property of $\Lambda(V)$ follows from $\eqref{equation-5}$. Specifically, since $\mathcal{I}_E$ is the ideal of $\operatorname{T}(V)$ generated by all $\mathbf{v}\otimes\mathbf{v}$, this property can be states as follows: Let $\mathbf{A}$ be associative unital algebra. Then there is a bijection between
- the set of algebra homomorphisms $\varphi: \Lambda(V)\to\mathcal{A}$ and
- the set of linear maps $f: V\to\mathcal{A}$ satisfying $f(\mathbf{v})^2 = 0_\mathcal{A}$ for all $\mathbf{v}\in V$

This bijection is given by restricting each algebra homomorphism $\varphi$ to $V\subset \Lambda(V)$, yielding a linear map $f = \varphi|_V$. Conversely, given a linear map $f: V\to\mathcal{A}$ with $f(\mathbf{v})^2 = 0$, there exists a unique algebra homomorphism $\varphi: \Lambda(V) \to\mathcal{A}$ such that $\varphi|_V = f$.

By definition, all algebra homomorphism are assumed to preserve the multiplicative identity, i.e. theu map the unit element of $\Lambda(V)$ to the unit of $\mathcal{A}$.

## Contractions

Given a vector $\mathbf{v}\in V$ and a covector $\alpha\in V^*$, the scalar $\alpha(\mathbf{v})$ can be understood in two equivalent ways:
1. **As a linear evaluation:** Interpreting $\alpha: V\to\mathbb{F}$, we regard $\alpha(\mathbf{v})$ as the action of the linear functional $\alpha$ on $\mathbf{v}$.
2. **As dual action:** Alternatively, viewing $\xi_\mathbf{v}: V^* \to \mathbb{F}$, we interpret $\xi_\mathbf{v} (\alpha) = \alpha (\mathbf{v})$ as the action of the linear functional $\xi_\mathbf{v}$ on $\alpha$.

These perspectives reveal a symmetry between vectors and covectors, and the quantity $\alpha(\mathbf{v})$ may be thought as a kind of bilinear pairing, i.e. an operation $V \times V^* \to\mathbb{F}$ or $V^* \times V\to\mathbb{F}$.

In terms of the exterior algebra, the covector $\alpha$ can be regarded as a linear map $\alpha: \Lambda_1 (V) \to\Lambda_0 (V)$, which naturally extends to a general operation $\Lambda_p (V) \to \Lambda_{p-1} (V)$ for $0\leq p \leq n$, known as left contraction, or interior product. This contraction captures the idea of inserting a covector into a differential form, reducing its degree by one and preserving the alternating multilinear structure.

### Left contraction

<MathBox title='Left contraction (interior product)' boxType='definition' tag="definition-1">
Let $\mathbf{A}_{[p]}\in\Lambda_p (V)$ be a $p$-vector and let $\alpha \in V^*$ be a covector. The left contraction of $\mathbf{A}_{[p]}$ by $\alpha$, denoted $\underline{\alpha}|$ is defined as

$$
  (\underline{\alpha}|\mathbf{A}_{[p]})(\alpha_1,\dots,\alpha_{p-1}) = p\mathbf{A}_{[p]} (\alpha, \alpha_1,\dots,\alpha_{p-1})
$$

where $\alpha_1,\dots,\alpha_{p-1}\in V^*$ are arbitrary covectors. Taking $\mathbf{A}_{[p]} = \bigwedge_{i=1}^p$ on the right-hand side means that

$$
  \left(\sum_{i=1}^p \mathbf{v}_i \right)(\alpha, \alpha_1,\dots,\alpha_{p-1}) = \frac{1}{p!} \sum_{\sigma\in S_p} \varepsilon(\sigma) \alpha(\mathbf{v}_{\sigma(1)}) \alpha_1 (\mathbf{v}_{\sigma(2)}) \cdots \alpha_{p-1} (\mathbf{v}_{\sigma(p)})
$$

This definition clearly shows that $\underline{\alpha}|\mathbf{A}_{[p]}$ is a $(p - 1)$-vector. In particular, the left contraction of a vector $\mathbf{v}\in \Lambda_1 (V)$ is

$$
  \underline{\alpha}|\mathbf{v} = \alpha(\mathbf{v})
$$

while for scalar elements of $\Lambda_0 (V)$, it is assumed that

$$
  \underline{\alpha}|1 = 0
$$
</MathBox>

<MathBox title='Left graded Leibniz rule' boxType='proposition'>
Let $\alpha \in V^*$ be a covector. The left contraction of $\mathbf{A}_{[p]} \wedge \mathbf{B}_{[p]}$, where $\mathbf{A}_{[p]}\in \Lambda_p (V)$ is a $p$-vector, and $\mathbf{B}_{[q]} \in\Lambda_{[q]} (V)$ is a $q$-vector, is given by 

$$
  \underline{\alpha}|(\mathbf{A}_{[p]} \wedge \mathbf{B}_{[p]}) = (\underline{\alpha}|\mathbf{A}_{[p]}) \wedge \mathbf{B}_{[p]} + (-1)^p \mathbf{A}_{[p]} \wedge (\underline{\alpha}|\mathbf{B}_{[p]})
$$

Introducing $\widehat{\mathbf{A}}_{[p]} = \#\mathbf{A}_{[p]} = (-1)^p \mathbf{A}_{[p]}$, we can simplify this to

$$
  \underline{\alpha}|(\mathbf{A}_{[p]} \wedge \mathbf{B}_{[p]}) = (\underline{\alpha}|\mathbf{A}_{[p]}) \wedge \mathbf{B}_{[p]} + \widehat{\mathbf{A}} \wedge (\underline{\alpha}|\mathbf{B}_{[p]})
$$

In particular, for vectors $\mathbf{u}, \mathbf{v} \in V$ the left contraction of $\mathbf{u}\wedge\mathbf{v}$ by $\alpha$ becomes

$$
\begin{equation*}
  \underline{\alpha}|(\mathbf{u}\wedge\mathbf{v}) = (\underline{\alpha}|\mathbf{u}) - \mathbf{v}(\underline{\alpha}|\mathbf{u}) = \alpha(\mathbf{u})(\mathbf{v}) - \mathbf{u}\alpha(\mathbf{v})
\tag{\label{equation-6}}
\end{equation*}
$$

<details>
<summary>Proof</summary>

First, let us consider the contraction of a $2$-vector, which, without loss of generality, can be expressed as a simple $2$-vector $\mathbf{u}\wedge\mathbf{v}$. By the definition of the left contraction (Definition $\ref{definition-1}$), we get for any covectors $\alpha, \beta \in V*$

$$
\begin{align*}
  (\underline{\alpha}|(\mathbf{v}\wedge\mathbf{u}))(\beta) =& 2(\mathbf{v} \wedge \mathbf{u})(\alpha,\beta) = \alpha(\mathbf{v}) \beta(\mathbf{u}) - \alpha(\mathbf{u})\beta(\mathbf{v}) \\
  =& (\alpha(\mathbf{v})\mathbf{u} - \alpha(\mathbf{u})\mathbf{v})(\beta) = ((\underline{\alpha}|\mathbf{v})\mathbf{u} - (\underline{\alpha}|\mathbf{u})\mathbf{v})(\beta)
\end{align*}
$$

Since this must hold for any covector $\beta$, it follows that

$$
  \underline{\alpha}|(\mathbf{u}\wedge\mathbf{v}) = (\underline{\alpha}|\mathbf{u}) - \mathbf{v}(\underline{\alpha}|\mathbf{u}) = \alpha(\mathbf{u})(\mathbf{v}) - \mathbf{u}\alpha(\mathbf{v})
$$

This result can be generalized for the $3$-vector $\mathbf{u}\wedge\mathbf{v}\wedge\mathbf{w}$. For any covectors $\alpha,\beta,\gamma\in V^*$, we have

$$
\begin{align*}
  (\underline{\alpha}|(\mathbf{u}\wedge\mathbf{v}\wedge\mathbf{w}))(\beta, \gamma) =& 3(\mathbf{u}\wedge\mathbf{v}\wedge\mathbf{w})(\alpha,\beta,\gamma) \\
  =& \frac{3}{3!} [\alpha(\mathbf{u}) \beta(\mathbf{v}) \gamma(\mathbf{w}) + \beta(\mathbf{u}) \gamma(v) \alpha (\mathbf{w}) + \gamma(\mathbf{u}) \alpha(v) \gamma(\mathbf{w}) \\
  &- \gamma(\mathbf{u}) \beta(\mathbf{v}) \gamma(\mathbf{w}) - \beta(\mathbf{u}) \alpha(\mathbf{v}) \gamma(w) - \alpha(\mathbf{u}) \gamma(\mathbf{v}) \beta(\mathbf{w})] \\
  =& \frac{1}{2!}\alpha(\mathbf{u}) [\beta(\mathbf{v})\gamma(\mathbf{w}) - \beta(\mathbf{w})\gamma(\mathbf{v})] \\
  &- \frac{1}{2!}\alpha(\mathbf{v}) [\beta(\mathbf{u})\gamma(\mathbf{w}) - \beta(\mathbf{w})\gamma(\mathbf{u})] \\
  &+ \frac{1}{2!}\alpha(\mathbf{w}) [\beta(\mathbf{u})\gamma(\mathbf{v}) - \beta(\mathbf{v})\gamma(\mathbf{u})] \\
  =& \alpha(\mathbf{u})(\mathbf{v}\wedge\mathbf{w})(\beta,\gamma) - \alpha(\mathbf{v})(\mathbf{u}\wedge\mathbf{w})(\beta,\gamma) + \alpha(\mathbf{w})(\mathbf{u}\wedge\mathbf{v})(\beta,\gamma)
\end{align*}
$$

Since this must hold for any covectors $\beta$ and $\gamma$, it follows that

$$
\begin{align*}
  (\underline{\alpha}|(\mathbf{u}\wedge\mathbf{v}\wedge\mathbf{w})) =& \alpha(\mathbf{u})(\mathbf{v}\wedge\mathbf{w}) - \alpha(\mathbf{v})(\mathbf{u}\wedge\mathbf{w}) + \alpha(\mathbf{w})(\mathbf{u}\wedge\mathbf{v}) \\
  =& (\underline{\alpha}|\mathbf{u})\mathbf{v}\wedge\mathbf{w} - (\underline{\alpha}|\mathbf{v}) \mathbf{u}\wedge\mathbf{w} + (\underline{\alpha}|\mathbf{w})\mathbf{u}\wedge\mathbf{v}
\end{align*}
$$

Applying $\eqref{equation-6}$, we obtain

$$
\begin{align*}
  \underline{\alpha}|((\mathbf{u}\wedge\mathbf{v}) \wedge \mathbf{w}) =& (\underline{\alpha}|(\mathbf{u}\wedge\mathbf{v}))\mathbf{w} - \mathbf{u}\wedge\mathbf{v}(\underline{\alpha}|\mathbf{w}) \\
  \underline{\alpha}|(\mathbf{u}\wedge(\mathbf{v} \wedge \mathbf{w})) =& (\underline{\alpha}|\mathbf{u})\mathbf{v}\wedge\mathbf{w} - \mathbf{u}\wedge(\underline{\alpha}|(\mathbf{v} \wedge \mathbf{w}))
\end{align*}
$$
</details>
</MathBox>

### Right contraction

<MathBox title='Right contraction' boxType='definition' tag='definition-2'>
Let $\mathbf{A}_{[p]}\in\Lambda_p (V)$ be a $p$-vector and let $\alpha \in V^*$ be a covector. The right contraction of $\mathbf{A}_{[p]}$ by $\alpha$, denoted $|\underline{\alpha}$ is defined as

$$
  (\mathbf{A}_{[p]}|\underline{\alpha})(\alpha_1,\dots,\alpha_{p-1}) = p\mathbf{A}_{[p]} (\alpha_1,\dots,\alpha_{p-1},\alpha)
$$

where $\alpha_1,\dots,\alpha_{p-1} \in V^*$ are arbitrary covectors. In particular, the right contraction of a vector $\mathbf{v}\in \Lambda_1 (V)$ is

$$
  \mathbf{v}|\underline{\alpha} = \alpha(\mathbf{v}) = \underline{\alpha}|\mathbf{v}
$$

while for scalar elements of $\Lambda_0 (V)$, it is assumed that

$$
  1|\underline{\alpha} = 0
$$
</MathBox>

<MathBox title='Right graded Leibniz rule' boxType='proposition'>
Let $\alpha \in V^*$ be a covector. The right contraction of $\mathbf{A}_{[p]} \wedge \mathbf{B}_{[p]}$, where $\mathbf{A}_{[p]}\in \Lambda_p (V)$ is a $p$-vector, and $\mathbf{B}_{[q]} \in\Lambda_{[q]} (V)$ is a $q$-vector, is given by 

$$
  (\mathbf{A}_{[p]} \wedge \mathbf{B}_{[p]})|\underline{\alpha} = \mathbf{A}_{[p]} \wedge (\mathbf{B}_{[p]}|\underline{\alpha}) + (\mathbf{A}_{[p]}|\underline{\alpha}) \wedge (-1)^q(\underline{\alpha}|\mathbf{B}_{[p]})
$$

Introducing $\widehat{\mathbf{B}}_{[q]} = \#\mathbf{B}_{[q]} = (-1)^q \mathbf{B}_{[p]}$, we can simplify this to

$$
  (\mathbf{A}_{[p]} \wedge \mathbf{B}_{[q]})|\underline{\alpha} = \mathbf{A}\wedge(\mathbf{B}|\underline{\alpha}) + (\mathbf{A}_{[p]}|\underline{\alpha}) \wedge \widehat{\mathbf{B}}_{[q]}
$$

In particular, for vectors $\mathbf{u}, \mathbf{v} \in V$, the right contraction of $\mathbf{u}\wedge\mathbf{v}$ by $\alpha$ becomes

$$
\begin{equation*}
  (\mathbf{u}\wedge\mathbf{v})|\underline{\alpha} = (\underline{\alpha}|\mathbf{u}) - \mathbf{v}(\underline{\alpha}|\mathbf{u}) = \alpha(\mathbf{u})(\mathbf{v}) - \mathbf{u}\alpha(\mathbf{v})
\tag{\label{equation-16}}
\end{equation*}
$$
</MathBox>

<MathBox title='Relationship between left and right contractions' boxType='proposition'>
Let $\mathbf{A}_{[p]}\in\Lambda_p (V)$ be a $p$-vector and let $\alpha \in V^*$ be a covector. Then

$$
  \underline{\alpha} \mathbf{A}_{[p]} = (-1)^{p-1} \mathbf{A}_{[p]}|\underline{\alpha}
$$

Introducing $\widehat{\mathbf{A}}_{[p]} = \#\mathbf{A}_{[p]} = (-1)^q \mathbf{A}_{[p]}$, we can simplify this to

$$
  \underline{\alpha}|\mathbf{A} = -\widehat{\mathbf{A}}|\underline{\alpha}
$$

<details>
<summary>Proof</summary>

It follows immediately from Definition $\ref{definition-1}$ and $\ref{definition-2}$ that

$$
  \mathbf{A}_{[p]} (\alpha_1,\dots,\alpha_{p-1}, \alpha) = (-1)^{p-1} \mathbf{A}_{[p]} (\alpha,\alpha_1,\dots,\alpha_{p-1}) 
$$

from which the result follows.
</details>
</MathBox>

### Generalization of left and right contractions

Since the exterior product of covectors is a $p$-covector, it is natural to extend the definitions of the left and right contractions to act by a general $p$-covector.

<MathBox title='Nilpotency of repeated contractions' boxType='lemma'>
Let $\alpha\in V^*$ be a covector $\mathbf{A}_{[p]} \in \Lambda_p (V)$ a $p$-vector. The repeated (left of right) contraction of $\mathbf{A}_{[p]}$ by $\alpha$ vanishes, i.e.

$$
  \underline{\alpha}|\underline{\alpha}|\mathbf{A}_{[p]} = 0 = \mathbf{A}_{[p]} |\underline{\alpha}|\underline{\alpha}
$$

<details>
<summary>Proof</summary>

Let $\alpha_1,\dots,\alpha_{p-2}\in V^*$ be arbitrary covectors. By Definition $\ref{definition-1}$ of the left contraction, we have


$$
\begin{align*}
  (\underline{\alpha}|(\underline{\alpha}|\mathbf{A}_{[p]}))(\alpha_1,\dots,\alpha_{p-2}) =& (p - 1) (\underline{\alpha}| \mathbf{A}_{[p]}) (\alpha,\alpha_1,\dots,\alpha_{p-2}) \\
  =& p(p-1) \mathbf{A}_{[p]} (\alpha,\alpha,\alpha_1,\dots,\alpha_{p-2}) \\
  =& \frac{1}{(p-2)!} \sum_{\sigma\in S_p} \varepsilon(\sigma) \alpha(\mathbf{v}_{\sigma(1)})\alpha(\mathbf{v}_{\sigma(2)})\alpha_1(\mathbf{v}_{\sigma(3)})\cdots\alpha_{p-2} (\mathbf{v}_{\sigma(p)}) \\
  =& 0
\end{align*}
$$

This expression vanishes because the contraction is antisymmetric over all covector covector arguments, and the appearance of $\alpha$ twice forces the alternating sum to cancel. Using a similar argument, if follows that $\mathbf{A}_{[p]}|\underline{\alpha}|\underline{\alpha} = 0$.
</details>
</MathBox>

For an arbitrary multivector $\mathbf{A}\in \Lambda(V)$, we note that the identity covector $1\in\Lambda(V)^*$ acts as the identity operator on multivectors:

$$
  1|\underline{\mathbf{A}} = \mathbf{A} = \underline{\mathbf{A}}|1
$$

Moreover, the mapping

$$
  \alpha\mapsto (\mathbf{A} \mapsto \underline{\alpha}|\mathbf{A})
$$

is a liner map $V^* \to\operatorname{End}(\Lambda(V))$. Since left contractions satisfies the graded Leibniz rule, this maps extends uniquely to an algebra homomorphism $\Lambda(V^*) \to \operatorname{End}(\Lambda(V))$, where $\operatorname{End}(\Lambda(V))$ is the space of endomorphisms of $V$. In particular, the unit element $1$ of $\Lambda(V^*)$ is mapped to the unit element of $\operatorname{End}(\Lambda(V))$.

<MathBox title='Generalized contractions' boxType='definition'>
Let $\bigwedge_{i=1}^p \alpha_i \in \Lambda^p (V^*)$ be a $p$-covector. The left contraction by $\bigwedge_{i=1}^p \alpha_i$ is defined as

$$
  \left(\bigwedge_{i=1}^p \alpha_i \right)\llcorner := \underline{\alpha_1}|\cdots\underline{\alpha_p}|
$$

while the right contraction by $\bigwedge_{i=1}^p \alpha_i$ is defined as

$$
  \lrcorner\left(\bigwedge_{i=1}^p \alpha_i \right) = |\underline{\alpha}_1 \cdots |\underline{\alpha}_p
$$
</MathBox>

From the definition of generlized contractions, it immediately follows that the (left or right) contraction of a $p$-vector by a $q$-covector equals $0$ if $q > p$, since there are too many anti-symmetric argument to contract into the available slots.

In particular, from $\eqref{equation-6}$ the left contraction of $2$-vector $\mathbf{u}\wedge\mathbf{v}\in\Lambda_2 (V)$ by the covector $\alpha\wedge\beta\in\Lambda^2 (V^*)$ is given by

$$
  (\alpha\wedge)\llcorner (\mathbf{u}\wedge\mathbf{v}) = \underline{\alpha}|(\underline{\beta}|(\mathbf{u}\wedge\mathbf{v})) = \alpha(\mathbf{v})\beta(u) - \alpha(\mathbf{u})\beta(\mathbf{v})
$$

On the other hand, the action of the $2$-covector $\alpha\wedge\beta$ on the the $2$-vector $\mathbf{u}\wedge\mathbf{v}$ can be defined vi the antisymmetrization of the tensor product. Recall from the definition of the tensor product that

$$
  (\alpha\otimes\beta)(\mathbf{u}\otimes\mathbf{v}) = \alpha(\mathbf{u})\beta(\mathbf{v})
$$

By the definition of the exterior product, we then have

$$
  (\alpha\wedge\beta)(\mathbf{u}\wedge\mathbf{v}) = \frac{1}{2} (\alpha(\mathbf{u})\beta(\mathbf{v}) - \alpha(\mathbf{v})\beta(\mathbf{u}))
$$

It follows that this action is related to the contraction via

$$
  (\alpha\wedge\beta)(\mathbf{u}\wedge\mathbf{v}) = \frac{1}{2}(\beta\wedge\alpha)\llcorner (\mathbf{u}\wedge\mathbf{v})
$$

More generally, the appropriate expression involves reversion of the covector exterior product:

$$
  (\alpha\wedge\beta)(\mathbf{u}\wedge\mathbf{v}) = \frac{1}{2}(\widetilde{\alpha\wedge\beta})\llcorner (\mathbf{u}\wedge\mathbf{v})
$$

where $\widetilde{\cdot}$ denotes the grade involution or reversal. This observation can generalized to higher-grade forms. Given a $p$-covector $\Psi^{[p]} \in\Lambda^p (V^*)$ and a $p$-vector $\mathbf{A}_{[p]} \in\Lambda_p (V)$, the action is given by

$$
\begin{equation*}
  \Psi^{[p]} (\mathbf{A}_{[p]}) = \frac{1}{p!} \underline{\tilde{\Psi}}^{[p]}|\mathbf{A}_{[p]}
\tag{\label{equation-7}}
\end{equation*}
$$

where $\tilde{\Psi}$ denotes the reversal of $\Psi$. In the case involving a simple $p$-vector and a simple $p$-covector, this equation can be written as

$$
\begin{align*}
  \left(\bigwedge_{i=1}^p \alpha_i \right)\left(\bigwedge_{j=1}^p \mathbf{v}_i\right) =& \frac{1}{p!} \left(\bigwedge_{i=1}^p \alpha_i \right)\llcorner \left(\bigwedge_{j=1}^p \mathbf{v}_i\right) \\
  =& \frac{1}{p!}\begin{vmatrix}
    \alpha_1 (\mathbf{v}_1) & \cdots & \alpha_1 (\mathbf{v}_p) \\
    \vdots & \ddots & \vdots \\
    \alpha_p (\mathbf{v}_1) & \cdots & \alpha_p (\mathbf{v}_p)
  \end{vmatrix}
\end{align*}
$$

The (left or right) contraction involing a $p$-covector and a $q$-covector can be similarly defined using recursive applications of the left contraction, and extended to arbitrary multivectors through linearity.

<MathBox title='' boxType='proposition'>
Let $\Psi^{[p]} \in\Lambda^p (V^*)$ be a $p$-covector and $\mathbf{A}_{[q]} \in\Lambda_q (V)$ a $q$-vector. Then the left and right contractions are related by the following graded symmetry identities:

$$
\begin{align*}
  \underline{\Psi}^{[p]}|\mathbf{A}_{[q]} =& (-1)^{p(q - 1)} \mathbf{A}_{[q]} |\underline{\Psi}^{[p]},\; p\leq q \\
  \mathbf{A}_{[q]}|\underline{\Psi}^{[p]} =& (-1)^{q(p - 1)} \underline{\Psi}^{[p]}|\mathbf{A}_{[q]},\; q\leq p
\end{align*}
$$

In terms of reversion, we have the identity

$$
  \widetilde{\underline{\Psi}^{[p]}|\mathbf{A}_{[p]}} = \tilde{\mathbf{A}}_{[q]} |\underline{\tilde{\Psi}}^{[p]}
$$

In particular, when $p = q$, the left and right contractions agree:

$$
  \underline{\Psi}^{[p]}|\mathbf{A}_{[p]} = \mathbf{A}_{[p]} |\underline{\Psi}^{[p]} = \mathbf{A}_{[p]} |\underline{\Psi}^{[p]}
$$
</MathBox>

## Orientation

Let $V$ be an $n$-dimensional vector space over $\R$ with basis $B = \set{\mathbf{e}_i}_{i=1}^n$. Recall that any natural basis for $\Lambda_n (V)$ can be written in terms of a permutation $\sigma\in S_n$ as

$$
  \bigwedge_{i=1}^n \mathbf{e}_{\sigma(i)} = \operatorname{sgn}(\sigma) \bigwedge_{i=1}^n \mathbf{e}_i
$$

Thus, the exterior product of $n$ linearly independent vectors can be written as a scalar multiple of this basis element:

$$
  \bigwedge_{i=1}^n \mathbf{v}_i = a \bigwedge_{i=1}^n \mathbf{e}_i,\; a\in\R
$$

where $a > 0$ or $a < 0$. Given an $n$-vector $\Omega \in\Lambda_n (V)$, we can define two equivalence classes:

$$
\begin{align*}
  [\Omega] =& \set{\mathbf{A}_{[n]} \in \Lambda_n (V) | \mathbf{A}_{[n]} = a \Omega,\; a > 0}
  [-\Omega] =& \set{\mathbf{A}_{[n]} \in \Lambda_n (V) | \mathbf{A}_{[n]} = a \Omega,\; a < 0}
\end{align*}
$$

These two disjoint classes comprise the orientations of the vector space. There exists exactly two possible orientations for a vector space, completely determined by the choice of a nonzero $n$-vector. Selecting a representative $n$-vector $\Omega_V \in\Lambda_n (V)$ from one of these classes endows $V$ with an orientation, making $(V,\Omega_V)$ an oriented vector space.

We can immediately define an orientation for the dual space $V^*$ via the $n$-covector $\Omega_{V^*} \in\Lambda^n (V^*)$. Let $B^* = \set{\varepsilon^i}_{i=1}^n$ be a basis for $V^*$ and choose $\Omega_{V^*} = a' \bigwedge_{j=1}^n \varepsilon^j$. Using $\eqref{equation-7}$, we find that

$$
\begin{align*}
  \Omega_{V^*} (\Omega_V) =& \frac{1}{n!} \underline{\tilde{\Omega}}_{V^*}| \Omega_V \\
  =& \frac{1}{n!} a a' \left(\bigwedge_{i=1}^n \varepsilon^i \right)\llcorner \left(\bigwedge_{i=1}^n \mathbf{e}_j \right) \\
  =& \frac{1}{n!} a a'
\end{align*}
$$

Since the exterior product of a basis with its dual evaluates to $1$, the scalar $\Omega_{V^*} (\Omega_V)$ is nonzero, and its sign depends on the signs of $a$ and $a'$, i.e.

$$
  0 \neq \Omega_{V^*} (\Omega_V) = \begin{cases}
    > 0 &\text{ if $a > 0$ and $a' > 0$; or $a < 0$ and $a' < 0$} \\
    < 0 &\text{ if $a > 0$ and $a' < 0$; or $a < 0$ and $a' > 0$}
  \end{cases}
$$

This allows us to relate the orientations of $V$ and $V^*$. The orientations determined by $\Omega_V \in\Lambda_n (V)$ and $\Omega_{V^*} \in\Lambda^n (V^*)$ are *compatible* if $\Omega_V (\Omega_{V^*}) > 0$. That is, once the orientation of either $V$ or $V^*$ is fixed, the compatible orientation of the other space is uniquely determined.

To construct $\Omega_{V^*}$ in a canonical and compatible way given $\Omega_V$, we proceed as follows. Suppose the orientation of $V$ is defined by

$$
  \Omega_V = \bigwedge_{i=1}^n
$$

with respect to a basis $B = \set{\mathbf{e}_i}_{i=1}^n$. Then we define the orientation of $V^*$ using the corresponding dual basis $B^* = \set{\varepsilon^i}_{i=1}^n$ by setting

$$
  \Omega_{V^*} = \bigwedge_{i=1}^n
$$

With this choice, we have

$$
\begin{equation*}
  \underline{\tilde{\Omega}}_{V^*}| \Omega_V = 1
\tag{\label{equation-20}}
\end{equation*}
$$

## Quasi-Hodge isomorphisms

<MathBox title='Quasi-Hodge isomorphism' boxType='definition'>
Let $(V,\Omega_V)$ be an oriented vector space, with orientation determined by the $n$-vector $\Omega_V \in\Lambda_n (V)$. The quasi-Hodge isomorphisms are linear maps that establish a duality between multivectors and multicovectors of complementary degrees:

$$
\begin{align*}
  \bar{\star}:& \Lambda_p (V) \to \Lambda^{n-p} (V^*) \\
  \underline{\star}:& \Lambda^p (V^*) \to \Lambda_{n-p} (V)
\end{align*}
$$

These maps are defined implicitly via the orientation form $\Omega_V$, using the exterior product and evaluation pairing:
Given a $p$-vector $\mathbf{A}_{[p]} \in\Lambda_p (V)$, we define $\bar{\star}\mathbf{A}_{[p]}$ as

$$
\begin{equation*}
  \Psi^{[p]} \wedge \bar{\star} \mathbf{A}_{[p]} = p! \Psi^{[p]} (\mathbf{A}_{[p]}) \Omega_V,\; \forall \Psi^{[p]} \in \Lambda^p (V)
\tag{\label{equation-8}}
\end{equation*}
$$

Similarly, given a $p$-covector $\Psi^{[p]} \in\Lambda^p (V)$, we define $\underline{\star}\Psi^{[p]}$ as

$$
\begin{equation*}
  \mathbf{A}_{[p]} \wedge \underline{\star}\Psi^{[p]} = p! \Psi^{[p]} (\mathbf{A}_{[p]}) \Omega_V,\; \forall \mathbf{A}_{[p]}\in\Lambda_p (V)
\tag{\label{equation-13}}
\end{equation*}
$$

These mappings are called "quasi-Hodge" because they resemble the classical Hodge star operator, but without assuming an inner product structure on $V$. Instead, they rely only on the orientation and the natural pairing between vectors and covectors.
</MathBox>

For $p = 0$, the identification $\Lambda^0 (V^*) = \mathbb{F}$ implies that for scalars $a, b\in \mathbb{F}$, the evaluation $a(b)$ is simply the product $ab$, i.e. $a(b) = ab$. Taking this into account, applying $\eqref{equation-8}$ to $1 \in \Lambda_0 (V)$ yields

$$
  a \wedge \bar{\star} 1 = a(1) \Omega_{V^*} = a \Omega_{V^*},\; a\in \Lambda^0 (V^*)
$$

Thus, it follows that

$$
\begin{equation*}
  \bar{\star}1 = \Omega_{V^*}
\tag{\label{equation-23}}
\end{equation*}
$$

Next, consider the case $p = 1$. Applying $\eqref{equation-8}$ to the vector $\mathbf{v}\in\Lambda_1 (V)$, gives

$$
\begin{equation*}
  \alpha \wedge \bar{\star} \mathbf{v} = \alpha(\mathbf{v}) \Omega_{V^*} = (\underline{\alpha}|\mathbf{v})\Omega_{V^*} = (\mathbf{v}|\underline{\alpha}) \Omega_{V^*},\; \alpha\in\Lambda^1 (V^*)
\tag{\label{equation-9}}
\end{equation*}
$$

Since $\Omega_{V^*} \in\Lambda^n (V^*)$, it follows that $\alpha\wedge\Omega_{V^*} = 0$ for all $\alpha\in\Lambda^1 (V^*)$. 

Now consider the left contraction $\mathbf{v} \lrcorner(\alpha\wedge\Omega_{V^*})$, which satisfies the graded Leibniz rule

$$
  \mathbf{v} \lrcorner(\alpha\wedge\Omega_{V^*}) = (\mathbf{v}|\underline{\alpha}) \wedge\Omega_{V^*} - \alpha\wedge (\mathbf{v}|\underline{\Omega}_{V^*})
$$

since $\alpha\wedge\Omega_{V^*} = 0$, this implies

$$
\begin{gather*}
  0 = (\mathbf{v}|\underline{\alpha})\Omega_{V^*} - \alpha\wedge (\mathbf{v}|\Omega_{V^*}) \\
  \implies (\mathbf{v}|\underline{\alpha})\Omega_{V^*} = \alpha\wedge (\mathbf{v}|\Omega_{V^*})
\end{gather*}
$$

Substituting into $\eqref{equation-9}$, we obtain

$$
  \alpha\wedge\bar{\star}\mathbf{v} = \alpha\wedge (\underline{\mathbf{v}}|\Omega_{V^*})
$$

Since this expression holds for all $\alpha\in\Lambda^1 (V)$, we conclude

$$
\begin{equation*}
  \bar{\star}\mathbf{v} = \underline{\mathbf{v}}|\Omega_{V^*}
\tag{\label{equation-11}}
\end{equation*}
$$

Now consider a $p$-vector of the form $\mathbf{A}_{[p-1]} \wedge \mathbf{v}$. Applying $\eqref{equation-8}$ gives

$$
\begin{align*}
  \Psi^{[p]} \wedge \bar{\star} (\mathbf{A}_{[p-1]} \wedge\mathbf{v}) =& p! \Psi^{[p]} (\mathbf{A}_{[p-1]} \wedge\mathbf{v})\Omega_{V^*} \\
  =& ((\widetilde{\mathbf{A}_{[p-1]} \wedge\mathbf{v}})|\underline{\Psi}^{[p]})\Omega_{V^*}
\end{align*}
$$

Using the antiautomorphism property of the reversion map, we have

$$
  \widetilde{\mathbf{A}_{[p-1]} \wedge\mathbf{v}} = \mathbf{v}\wedge\tilde{\mathbf{A}}_{[p-1]} = (-1)^{p-1} \mathbf{A}_{[p-1]} \wedge\mathbf{v}
$$

which gives

$$
\begin{align*}
  \Psi^{[p]} \wedge \bar{\star}(\mathbf{A}_{[p-1] \wedge\mathbf{v}}) =& ((\mathbf{v}\wedge\tilde{\mathbf{A}}_{[p-1]})|\underline{\Psi}^{[p]})\Omega_{V^*} \\
  =& (-1)^{p-1} ((\tilde{\mathbf{A}}_{[p-1]} \wedge\mathbf{v})|\underline{\Psi}^{[p]}) \Omega_{V^*} \\
  =& (-1)^{p-1} (\tilde{\mathbf{A}}_{[p-1]} \lrcorner{(\mathbf{v} \lrcorner \Psi^{[p]})}) \Omega_{V^*} 
\end{align*}
$$

By $\eqref{equation-8}$, the last term reads

$$
\begin{equation*}
  (-1)^{p-1} (\tilde{\mathbf{A}}_{[p-1]} \lrcorner {(\mathbf{v} \lrcorner \Psi^{[p]})})\Omega_{V^*} = (-1)^{p-1} (\mathbf{v}|\underline{\Psi}^{[p]}) \wedge\bar{\star}\mathbf{A}_{[p-1]}
\tag{\label{equation-10}}
\end{equation*}
$$

On the other hand, according to the graded Leibniz rule

$$
  \mathbf{v}\lrcorner (\Psi^{[p]} \wedge\bar{\star}\mathbf{A}_{[p-1]}) = (\mathbf{v}\lrcorner \Psi^{[p]})\wedge\bar{\star}\mathbf{A}_{[p-1]} + (-1)^p \Psi^{[p]} \wedge (\mathbf{v}\lrcorner \bar{\star}\mathbf{A}_{[p-1]})
$$

However, since $\bar{\star}\mathbf{A}_{[p-1]} \in\Lambda^{n-(p-1)} (V) = \Lambda^{n-p+1} (V)$ and $\Psi^{[p]} \in\Lambda^p (V^*)$, their exterior product vanishes due to degree mismatch:

$$
  \Psi^{[p]} \wedge \bar{\star} \mathbf{A}_{[p-1]} = 0
$$

Thus, the graded Leibniz rule simplifies to

$$
  (\mathbf{v}\lrcorner \Psi^{[p]})\wedge\bar{\star}\mathbf{A}_{[p-1]} = -(-1)^p \Psi^{[p]} \wedge (\mathbf{v}\lrcorner \mathbf{A}_{[p-1]})
$$

Substituting into $\eqref{equation-10}$ gives

$$
  \Psi^{[p]} \wedge \bar{\star}(\mathbf{A}_{[p-1]} \wedge\mathbf{v}) = \Psi^{[p]} \wedge (\mathbf{v}\lrcorner \bar{\star} \mathbf{A}_{[p-1]})
$$

Since this holds for all $\Psi^{[p]} \in\Lambda^p (V)$, we conclude

$$
  \bar{\star}(\mathbf{A}_{[p-1]} \wedge\mathbf{v}) = (\mathbf{v}\lrcorner \bar{\star}\mathbf{A}_{[p-1]})
$$

Applying $\eqref{equation-11}$ recursively yields

$$
  \bar{\star}\left(\bigwedge_{i=1}^p \mathbf{v}_i \right) = \left(\bigwedge_{j=p}^1 \mathbf{v}_j \right)|\underline{\Omega}_{V^*}
$$

Finally, by linearity, we obtain the general quasi-Hodge formula for an arbitrary $p$-vector:

$$
\begin{equation*}
  \bar{\star}\mathbf{A}_{[p]} = \tilde{\mathbf{A}}_{[p]}|\underline{\Omega}_{V^*}
\tag{\label{equation-12}}
\end{equation*}
$$

The calculations for $\underline{\star}$ are similar, resulting in

$$
  \begin{equation*}
  \underline{\star} 1 = \Omega_V
  \tag{\label{equation-25}}
\end{equation*}
$$

and generally

$$
\begin{equation*}
  \underline{\star} \Psi^{[p]} = \tilde{\Psi}^{[p]} \llcorner \Omega_V
  \tag{\label{equation-24}}
\end{equation*}
$$

It is possible to show that the isomorphisms $\bar{\star}$ and $\underline{\star}$ are the inverse of each other, up to a sign, i.e.

$$
  \underline{\star}\bar{\star} = \bar{\star}\underline{\star} = (-1)^{p(n-p)} 1
$$

It is natural to define

$$
\begin{align*}
  \bar{\star}^{-1} =& (-1)^{p(n-p)} \underline{\star}
  \underline{\star}^{-1} =& (-1)^{p(n-p)} \bar{\star}
\end{align*}
$$

Recall the compatibility assumption between the orientations of $V$ and $V^*$, which ensures the scalar identity

$$
  \tilde{\Omega}_{V^*} \llcorner \Omega_V = \tilde{\Omega}_{V^*} \lrcorner \Omega_{V^*} = 1
$$

Using this, along with $\eqref{equation-8}$ we compute

$$
  (\widetilde{\Psi^{[p]} \wedge\bar{\star}\mathbf{A}_{[p]}})\llcorner \Omega_V = \tilde{\mathbf{A}}_{[p]} \lrcorner \Psi^{[p]} (\tilde{\Omega}_{V^*} \llcorner \Omega_V) = \tilde{\mathbf{A}}_{[p]} \lrcorner \Psi^{[p]}
$$

Alternatively, invoking $\eqref{equation-12}$, we can express the left-hand side as

$$
\begin{equation*}
  \underline{\star}(\Psi^{[p]} \wedge \bar{\star}\mathbf{A}_{[p]}) = \tilde{\mathbf{A}}_{[p]} \lrcorner \Psi^{[p]}
\tag{\label{equation-14}}
\end{equation*}
$$

On the other hand, $\eqref{equation-13}$ implies that

$$
  (\widetilde{\mathbf{A}_{[p]} \wedge \underline{\star} \Psi^{[p]}}) \llcorner \Omega_{V^*} = \tilde{\mathbf{A}}_{[p]} \llcorner \Psi^{[p]} (\tilde{\Omega}_{V^*} \llcorner \Omega_{V^*}) = \tilde{\mathbf{A}}_{[p]} \lrcorner \Psi^{[p]}
$$

and by using $\eqref{equation-12}$, we obtain

$$
\begin{equation*}
  \bar{\star}(\mathbf{A}_{[p]} \wedge \underline{\star} \Psi^{[p]}) = \tilde{\mathbf{A}}_{[p]} \llcorner\Psi^{[p]}
\tag{\label{equation-15}}
\end{equation*}
$$

Comparing $\eqref{equation-14}$ and $\eqref{equation-15}$, we conclude the symmetry relation

$$
  \underline{\star}(\Psi^{[p]} \wedge \bar{\star} \mathbf{A}_{[p]}) = \bar{\star} (\mathbf{A}_{[p]} \wedge \underline{\star} \Psi^{[p]})
$$

## Regressive product

<MathBox title='Co-exterior algebra' boxType='definition'>
Let $V$ be an $n$-dimensional vector space. The *co-exterior algebra*, or *regressive algebra*, of contravariant rank $p$, denoted $\vee_p (V)$ is defined as

$$
  \vee_p (V) := \Lambda_{n-p} (V)
$$

That is, elements of $\vee_p (V)$ are $(n-p)$-vectors in the exterior algebra $\Lambda(V)$, but intepreted in a dual algebraic role. Given an $(n-p)$-vector $\mathbf{A}_{[n-p]} \in\Lambda_{n-p} (V)$ its *dual degree* $p$ is denoted 

$$
  \mathbf{A}_{\{p\}} := \mathbf{A}_{[n-p]} \in \vee_p (V)
$$

Similarly, the *co-exterior algebra* of covariant rank $p$, denoted $\vee^p (V^*)$ is defined as

$$
  \vee_p (V^*) := \Lambda^{n-p} (V^*)
$$

Given an $(n-p)$-covector $\Psi^{[n-p]} \in\Lambda^{n-p} (V^*)$ its dual degree $p$ is denoted

$$
  \Psi^{\{p\}} = \Psi^{[n-p]} \in \vee^p (V)
$$
</MathBox>

<MathBox title='Regressive product' boxType='definition'>
Let $V$ be an $n$-dimensional vector space. The regressive product of multivectors is the binary operation

$$
  \vee: \vee_p (V) \times \vee_q (V) \to \vee_{p+q} (V)
$$

given by

$$
\begin{equation*}
  \mathbf{A}_{[p]} \vee \mathbf{B}_{[p]} = \bar{\star}^{-1} (\bar{\star}\mathbf{A}_{[p]} \wedge \bar{\star} \mathbf{B}_{[q]})
\tag{\label{equation-26}}
\end{equation*}
$$

for a $p$-vector $\mathbf{A}_{[p]} \in\Lambda_p (V)$ and $q$-vector $\mathbf{B}_{[q]} \in\Lambda_q (V)$. Since $\bar{\star}: \Lambda_p (V) \to \Lambda^{n-p} (V^*)$, we have

$$
\begin{align*}
  \bar{\star} \mathbf{A}_{[p]} \in\Lambda^{n-p} (V^*) = \vee^{[p]} (V^*)
  \bar{\star}\mathbf{B}_{[q]} \in\Lambda^{n-q} (V^*) = \vee^{[q]} (V^*)
\end{align*}
$$

Thus, the exterior product $\bar{\star}\mathbf{A}_{[p]} \wedge \bar{\star} \mathbf{B}_{[q]}$ belongs to $\Lambda^{2n-p-q} (V^*)$. Applying $\bar{\star}^{-1}$, which differs from $\underline{\star}$ only by a sign, maps this back to 

$$
  \mathbf{A}_{[p]} \vee \mathbf{B}_{[q]} \in\Lambda_{p+q-n} (V) = \vee_{p+q} (V)
$$ 

Analogously, the regressive product of multicovectors is a binary relation $\vee: \vee^p (V^*) \times \vee^q (V^*) \to \vee_{p+q} (V^*)$ given by

$$
  \Psi^{[p]} \wedge \Phi^{[q]} = \underline{\star}^{-1} (\underline{\star} \Psi^{[p]} \vee \underline{\star} \Phi^{[q]})
$$

where $\Psi^{[p]} \in\Lambda^p (V^*)$ and $\Phi^{[q]} \in \Lambda^q (V^*)$. Since $\underline{\star}: \Lambda^p (V^*) \to \Lambda_{n-p} (V)$, we have

$$
\begin{align*}
  \underline{\star} \Psi^{[p]} \in\Lambda_{n-p} (V) = \vee_{[p]} (V)
  \underline{\star} \Phi^{[q]} \in\Lambda_{n-q} (V) = \vee_{[q]} (V)
\end{align*}
$$

Thus, the exterior product $\underline{\star}\Psi^{[p]} \wedge \underline{\star} \Phi^{[q]}$ belongs to $\Lambda_{2n-p-q} (V)$. Applying $\underline{\star}^{-1}$, which differs from $\bar{\star}$ only by a sign, maps this back to 

$$
  \Psi^{[p]} \vee \Phi_{[q]} \in \Lambda^{p+q-n} (V^*) = \vee^{p+q} (V^*)
$$ 
</MathBox>

<MathBox title='Properties of regressive product' boxType='proposition'>
The regressive product $\vee: \vee_p (V) \times \vee_q \to \vee_{p+q} (V)$ satisfies the following properties:
1. **Associativity:** For $\mathbf{A}_{[p]} \in \Lambda_p (V)$, $\mathbf{B}_{[q]} \in \Lambda_q (V)$ and $\mathbf{C}_{[r]} \in \Lambda_r (V)$ 
$$
  (\mathbf{A}_{[p]} \vee \mathbf{B}_{[q]}) \vee \mathbf{C}_{[r]} = \mathbf{A}_{[p]} \vee (\mathbf{B}_{[q]} \vee \mathbf{C}_{[r]})
$$
2. For $\Psi^{[q]} \in\Lambda^q (V^*)$, the regressive product is related to the contraction via 
$$
  \mathbf{A}_{[p]} \vee \underline{\star} \Psi^{[q]} = \tilde{\Psi}^{[q]} \llcorner \mathbf{A}_{[p]}
$$

Analogously,

$$
  \tilde{\mathbf{A}}_{[p]} \llcorner\Psi^{[q]} = \Psi^{[q]} \vee \bar{\star} \mathbf{A}_{[p]}
$$

<details>
<summary>Proof</summary>

**(1):**

$$
\begin{align*}
  (\mathbf{A}_{[p]} \vee \mathbf{B}_{[q]}) \vee \mathbf{C}_{[r]} =& \overline{\star}^{-1} (\overline{\star} (\mathbf{A}_{[p]} \vee \mathbf{B}_{[q]}) \wedge \overline{\star} \mathbf{C}_{r}) \\
  =& \bar{\star}^{-1} (\bar{\star}\bar{\star}^{-1} (\bar{\star}\mathbf{A}_{[p]} \wedge \bar{\star} \mathbf{B}_{[q]}) \wedge \bar{\star} \mathbf{C}_{[r]}) \\
  =& \bar{\star}^{-1} ((\bar{\star}\mathbf{A}_{[p]} \wedge \bar{\star} \mathbf{B}_{[q]}) \wedge \bar{\star} \mathbf{C}_{[r]}) \\
  =& \bar{\star}^{-1} (\bar{\star} \mathbf{A}_{[p]} \wedge (\bar{\star} \mathbf{B}_{[q]} \wedge \bar{\star} \mathbf{C}_{[r]})) \\
  =& \bar{\star}^{-1} (\bar{\star} \mathbf{A}_{[p]} \wedge \bar{\star} \bar{\star}^{-1} (\bar{\star} \mathbf{B}_{[q]} \wedge \mathbf{C}_{[r]})) \\
  =& \bar{\star}^{-1} (\bar{\star} \mathbf{A}_{[p]} \wedge \bar{\star}(\mathbf{B}_{[q]} \vee \mathbf{C}_{[p]})) \\
  =& \mathbf{A}_{[p]} \vee (\mathbf{B}_{[q]} \vee \mathbf{C}_{[r]}) 
\end{align*}
$$

**(2):**

$$
\begin{align*}
  \mathbf{A}_{[p]} \vee \underline{\star} \Psi^{[q]} =& \bar{\star}^{-1} (\bar{\star} \mathbf{A}_{[p]} \wedge \bar{\star} \underline{\star} \Psi^{[q]}) \\
  =& (-1)^{q(n-q)} (-1)^{(n+q-p)(p-q)} \underline{\star} (\bar{\star} \mathbf{A}_{[p]} \wedge \Psi^{[q]}) \\
  =& (-1)^{p(n-p)} (\widetilde{\bar{\star} \mathbf{A}_{[p]} \wedge \Psi^{[q]}}) \llcorner \Omega_V \\
  =& (-1)^{p(n-p)} \tilde{\Psi}^{[q]} \llcorner (\widetilde{\bar{\star} \mathbf{A}_{[p]}} \lrcorner \Omega_V) \\
  =& (-1)^{p(n-p)} \tilde{\Psi}^{[q]} \llcorner (\underline{\star} \bar{\star} \mathbf{A}_{[p]})
  =& \tilde{\Psi}^{[q]} \llcorner \mathbf{A}_{[p]}
\end{align*}
$$
</details>
</MathBox>

## The Grassmann algebra

Let $V$ be an $n$-dimensional vector space. The exterior algebra is the pair $(\Lambda(V), \wedge)$, where $\Lambda(V)$ is the graded vector space of multivectors endowed with the exterior product $\wedge$. Suppose now that $V$ is equipped with a symmetric bilinear form $g:V\times V\to\R$. Equivalently, we can endow $V$ with the symmetric correlation $\flat: V\to V^*$, defined by $\mathbf{v} \mapsto g(\mathbf{v}, \cdot)$. The bilinear form $g$ is also known as a metric, making $(V,g)$ a metric space.

The bilinear form $g$ can be generalized to the whole of $\Lambda(V)$ by extending $\flat$. This results in a mapping $\flat:\Lambda_p (V) \to \Lambda^p (V^*)$ given by

$$
\begin{equation*}
  \left(\bigwedge_{i=1}^p \mathbf{v}_i \right)_\flat = \bigwedge_{i=1}^p \mathbf{v}_{i\flat}
\tag{\label{equation-17}}
\end{equation*}
$$

By the extension of $\flat$, we can immediately define the extension of the bilinear form $g$ via namely $g(\mathbf{u},\mathbf{v}) = \mathbf{u}_\flat (\mathbf{v})$. Let us denote this extension by $G$. We define $G:\Lambda_p (V) \times \Lambda_p (V) \to\R$ for the case of simple $p$-vectors as

$$
\begin{equation*}
  G(\mathbf{u}_1 \wedge\cdots\wedge \mathbf{u}_p, \mathbf{v}_1 \wedge\cdots\wedge \mathbf{v}_p) = p! \left(\bigwedge_{i=1}^p \mathbf{u}_i \right)_\flat \left(\bigwedge_{i=1}^p \mathbf{v}_i \right)_\flat
\tag{\label{equation-22}}
\end{equation*}
$$

and extend $G$ for all $\Lambda_p (V)$ by bilinearity. The factor $p!$ is conventional and accounts for normalization that arises from embedding the exterior algebra into the tensor algebra. Previously, the duality mapping $\Lambda(V^*) \times \Lambda(V) \to\mathbb{F}$ was defined by means of a duality mapping $\operatorname{T}(V^*) \times \operatorname{T}(V) \to\mathbb{F}$, as well as by the inclusions $\Lambda(V) \subset \operatorname{T}(V)$ and $\Lambda(V^*) \subset \operatorname{T}(V^*)$. However, this method generates the inopportune factor $p!$ when elements of degree $p$ are taken into account. 

The bilinear form $G$ is symmetric, in the sense that

$$
  G(\mathbf{u}_1 \wedge\cdots\wedge \mathbf{u}_p, \mathbf{v}_1 \wedge\cdots\wedge \mathbf{v}_p) = G(\mathbf{v}_1 \wedge\cdots\wedge \mathbf{v}_p, \mathbf{u}_1 \wedge\cdots\wedge \mathbf{u}_p)
$$

There are several equivalent expressions for $G$. For instance, we can write

$$
\begin{equation*}
  G(\mathbf{u}_1 \wedge\cdots\wedge \mathbf{u}_p, \mathbf{v}_1 \wedge\cdots\wedge \mathbf{v}_p) = \left(\bigwedge_{i=1}^p \mathbf{u}_i \right)_\flat \left(\bigwedge_{i=1}^p \llcorner \mathbf{v}_i \right)
\tag{\label{equation-21}}
\end{equation*}
$$

or express it in terms of the determinant of the $p\times p$ Gram matrix:

$$
\begin{align*}
  G(\mathbf{u}_1 \wedge\cdots\wedge \mathbf{u}_p, \mathbf{v}_1 \wedge\cdots\wedge \mathbf{v}_p) = \begin{vmatrix}
    g(\mathbf{u}_1, \mathbf{v}_1) & \cdots & g(\mathbf{u}_1, \mathbf{v}_p) \\
    \vdots & \ddots & \vdots \\
    g(\mathbf{u}_p, \mathbf{v}_1) & \cdots & g(\mathbf{u}_p, \mathbf{v}_p)
  \end{vmatrix}
\end{align*}
$$

Finally, the bilinear form $G$ extends naturally to $\Lambda(V)$ as a graded symmetric bilinear form. For $\mathbf{A}_{[p]}\in\Lambda_p (V)$ and $\mathbf{B}_{[q]} \in\Lambda_q (V)$ with $p \neq q$, we define

$$
  G(\mathbf{A}_{[p]}, \mathbf{B}_{[q]}) := 0,\; p \neq q
$$

This ensures that $G$ respects the grading of the exterior algebra.

<MathBox title='Grassmann algebra' boxType='definition'>
Let $(V,g)$ be a real vector space equipped with a symmetric bilinear form $g:V\times V\to\R$. *The Grassmann algebra*, or *exterior algebra with metric*, is the pair $\mathcal{G}(V) = (\Lambda(V), G)$, where $(\Lambda(V),\wedge)$ is the exterior algebra of $V$, and $G: \Lambda(V) \times \Lambda(V) \to\R$ is the natural extension of $g$ to multivectors.
</MathBox>

## The Hodge isomorphism

The Hodge isomorphism is closely related to the quasi-Hodge isomorphism, though the former requires additional structure on the underlying vector space $V$. While the quasi-Hodge isomorphisms only requires a choosen orientation of $V$, the Hodge isomorphism also requires a symmetric bilinear form (or metric) on $V$. Consequently, the Hodge isomorphism is defined only in the context of the Grassmann algebra, where the metric structure is available. In contrast, within the purely algebraic framework of the exterior algebra, only the quasi-Hodge isomorphism can be defined.

The presence of a symmetric bilinear form $g$ on $V$ allows us to identify $V$ with its dual space $V^*$ via the correlation $\flat:V\to V^*$. This correlation extends to multivectors with the map $\flat: \Lambda_p (V) \to \Lambda^p (V^*)$ given in $\eqref{equation-17}$. The inverse correlation $\sharp = \flat^{-1}$ extends similarly to $\sharp: \Lambda^p (V^*) \to \Lambda_p (V)$.

Now consider the quasi-Hodge isomorphism $\bar{\star} : \Lambda_p (V) \to \Lambda^{n-p} (V^*)$, which depends only on the orientation of $V$. Composing this with the correlation $\sharp$, we obtain the map

$$
  \sharp\circ\bar{\star} : \Lambda_p (V) \to \Lambda_{n-p} (V)
$$

Similarly, starting from a $p$-covector in $\Lambda^p (V^*)$, we can define the composition

$$
  \bar{\star}\circ\sharp: \Lambda^p (V) \to \Lambda^{n-p} (V)
$$

In terms of the quasi-Hodge isomorphism $\underline{\star}: \Lambda^p (V) \to \Lambda_{n-p}$, we can consider two compositions:

$$
\begin{align*}
  \flat\circ\underline{\star}: \Lambda^p (V) \to \Lambda^{n-p} (V) \\
  \underline{\star}\circ\flat: \Lambda_p (V) \to \Lambda_{n-p} (V)
\end{align*}
$$

We aim to define the Hodge isomorphism $\star:\Lambda_p (V) \to \Lambda_{n-p} (V)$ by requiring that it satisfies

$$
  \sharp\circ\bar{\star} = \underline{\star}\circ\flat
$$

Consider first the left composition. Applying the quasi-Hodge isomorphism $\bar{\star}$ defined by $\eqref{equation-8}$ followed $\sharp$, and using the property $\sharp(\Psi\wedge\Phi) = \Psi^\shar \wedge \Phi^\sharp$, we find

$$
  \Psi^{[p]} \wedge^\sharp (\shar\circ\bar{\star})\mathbf{A}_{[p]} = p! \Psi^{[p]} (\mathbf{A}_{[p]}) \Omega_{V^*}^\sharp
$$

which can be rewritten as

$$
\begin{equation*}
  \mathbf{B}_{[p]} \wedge (\sharp\circ\bar{\star}) \mathbf{A}_{[p]} = p! \mathbf{A}_{[p]\flat} (\mathbf{B}_{[p]}) \Omega_{V^*}^\sharp
\tag{\label{equation-18}}
\end{equation*}
$$

On the other hand, applying $\underline{\star}$ given in $\eqref{equation-13}$ follows by $\flat$, we obtain

$$
\begin{equation*}
  \mathbf{A}_{[p]} \wedge (\underline{\star}\circ \flat)\mathbf{B}_{[p]} = p! \mathbf{B}_{[p]\flat} (\mathbf{A}_{[p]}) \Omega_V
\tag{\label{equation-19}}
\end{equation*}
$$

Comparing $\eqref{equation-18}$ and $\eqref{equation-19}$, we see that for the equality $\sharp\circ\bar{\star} = \underline{\star}\circ\flat$ to hold, then $\Omega_{V^*}^\sharp = \Omega_V$ or equivalently

$$
  \Omega_{V^*} = \Omega_V^\flat
$$

The relationship between $\Omega_{V^*}$ and $\Omega_V$ is given by $\eqref{equation-20}$. With this last condition, it therefore follows that

$$
  \widetilde{\Omega_V^\flat} (\Omega_V) = 1
$$

In terms of the extended bilinear form $G$ as given in $\eqref{equation-21}$, this condition is equivalent to

$$
  G(\Omega_V, \Omega_V) = 1
$$

that is, the $n$-vector $\Omega_V \in \Lambda_n (V)$ must be of unit length. Thus, when $\Omega_n$ is unitary, we define the Hodge isomorphism, denoted $\star$, as

$$
\begin{equation*}
  \star = \sharp\circ\bar{\star} = \underline{\star}\circ\flat: \Lambda_p (V) \to \Lambda_{n-p} (V)
\tag{\label{equation-25}}
\end{equation*}
$$

With $G$ as given in $\eqref{equation-22}$, we can thus define $\star$ as

$$
  \mathbf{A}_{[p]} \wedge \star\mathbf{B}_{[p]} = G(\mathbf{A}_{[p]}, \mathbf{B}_{[p]}) \Omega_V
$$

where $G(\Omega_V, \Omega_V) = 1$ and $G(\mathbf{A}_{[p]}, \mathbf{B}_{[q]}) = 0$ if $p \neq q$.

The Hodge isomorphism between $\Lambda^p (V^*)$ and $\Lambda^{n-p} (V^*)$ is similarly defined as the mapping $\overset{*}\star: \Lambda^p (V*) \to \Lambda^{n-p} (V^*)$ given by the composition

$$
  \overset{*}{\star} = \flat\circ\star\circ\sharp
$$

The same reasoning and calculations for $\bar{\star}$ and $\underline{\star}$ apply to $\star$ with careful consideration of the correlations $\flat$ and $\sharp$, as given in $\eqref{equation-23}$, $\eqref{equation-12}$, $\eqref{equation-24}$ and $\eqref{equation-25}$. For the case of $\star$, the following identities hold

$$
\begin{align*}
  \star 1 =& \Omega_V \\
  \star \mathbf{A} = \tilde{\mathbf{A}}_\flat \llcorner \Omega_V,\; \mathbf{A}\in\Lambda (V)
\end{align*}
$$

Moreover, the regressive product can be expressed in terms of the Hodge isomorphism. From $\eqref{equation-25}$, we have the identities

$$
  \underline{\star} = \star\circ\sharp,\quad \bar{\star} = \flat\circ\star
$$

Using the inverses $\overline{\star}^{-1} = \star\circ\flat^{-1} = \star\circ\sharp$, if follows from $\eqref{equation-26}$ that the regressive product of two multivectors $\mathbf{A}_{[p]} \in\Lambda_p (V)$ and $\mathbf{B}_{[p]} \in \Lambda_q (V)$ takes the form

$$
  \mathbf{A}_{[p]} \vee \mathbf{B}_{[q]} = \star^{-1} (\star \mathbf{A}_{[p]} \vee \star \mathbf{B}_{[q]})
$$

<MathBox title='Explicit expression for $\Omega_V$' boxType='example'>
The Hodge isomorphism can be explicitly calculated in terms of the unit $n$-vector $\Omega_V$. To find an explicit expression for $\Omega_V$, let $B = \set{\mathbf{e}_i}_{i=1}^n$ be a basis of $V$ and let $g$ be the symmetric bilinear form $g(\mathbf{u},\mathbf{v}) = \mathbf{u}_\flat (\mathbf{v}) = g_{ij} v^i u^j$, where $g_{ij} = g(\mathbf{e}_i, \mathbf{e}_j) = g_{ji}$. Let $B' = \set{\mathbf{e}'_i}_{i=1}^n$ be an orthonormal basis

$$
\begin{equation*}
  g(\mathbf{e}'_i, \mathbf{e}'_j) = \lambda_i \delta_{ij}
\tag{\label{equation-27}}
\end{equation*}
$$

where

$$
  \lambda_i = \begin{cases}
    1,\quad& i=1,\dots,p \\
    -1,\quad& i=p+1,\dots,n
  \end{cases}
$$

defining the quadratic space $\R^{p,q} (p + q = n)$. Since the basis vectors $\mathbf{e}'_i$ are orthonormal, it follows from the extended symmetric bilinear form $G$ that $\Omega_V$ is a unit $n$-vector of the form

$$
  \Omega_V = \bigwedge_{i=1}^n \mathbf{e}'_i
$$

Now, consider expression $\Omega_V$ in terms of an arbitrary basis $B$. Let $\mathbf{h} \in \operatorname{T}_1^1 (V)$ be the basis transformation such that

$$
  \mathbf{e}'_i = \mathbf{h}(\mathbf{e}_i) = h_i^j \mathbf{e}_j,
$$

It then follows that

$$
  \bigwedge_{i=1}^n \mathbf{e}'_i = \det(\mathbf{h}) \bigwedge_i^n \mathbf{e}_i
$$

From the orthonormality condition $\eqref{equation-27}$, we also have

$$
  \lambda_i \delta_{ij} = h_i^k g_{kl} h_i^l
$$

This equation can be written in matrix form as

$$
  \boldsymbol{\lambda} = \mathbf{h}^\top \mathbf{gh}
$$

where $\mathbf{g} \in\mathrm{T}_2 (V)$ is the matrix of $g$ in the basis $B$, and $\boldsymbol{\lambda} = \operatorname{diag}(\lambda_i)_{i=1}^n$. Taking the determinant yields

$$
  \det(\boldsymbol{\lambda}) = \det(\mathbf{h}^\top \mathbf{gh}) = \det(\mathbf{h}^2) \det(\mathbf{g})
$$

Since $\det(\boldsymbol{\lambda}) = (-1)^q$ where $q = n - p$, it follows that

$$
  (-1)^q = \det(\mathbf{h})^2 \det(\mathbf{g})
$$

Taking the absolute values gives

$$
  1 = \det(\mathbf{h})^2 |\det(\mathbf{g})|
$$

with solutions $\det(\mathbf{h}) = \pm \sqrt{\det(\mathbf{g})}$. Since the set of matrices $\mathbf{h}$ must include the identity matrix $\mathbf{I}_n$ as a speciaal case, we choose the positive root. Thus, the unit $n$-vector $\Omega_V$ can be written in terms of $B$ as

$$
  \Omega_V = \frac{1}{\sqrt{|\det(\mathbf{g})|}} \bigwedge_{i=1}^n \mathbf{e}_i
$$

An alternative expression in terms of the inverse metric tensor $\mathbf{g}^-1 \in \operatorname{T}^2 (V)$ is

$$
  \Omega_V = \sqrt{|\det(\mathbf{g}^{-1})|} \bigwedge_{i=1}^n \mathbf{e}_i
$$

where the inverse metric components $g^{ij} = g(\mathbf{e}^i, \mathbf{e}^j)$ satisfy $g^{ij} g_{jk} = \delta_k^i$.
</MathBox>

# Clifford algebra

<MathBox title='Clifford mapping' boxType='definition'>
Let $V$ be a vector space over $\R$, endowed with a symmetric bilinear form $g: V\times V\to\R$. Let $\mathcal{A}$ be an associative unital algebra over $\R$ with identity element $1_\mathcal{A}$. A linear map $\gamma: V\to\mathcal{A}$ satisfying

$$
\begin{equation*}
  \gamma(\mathbf{v})^2 = Q(\mathbf{v}) = g(\mathbf{v},\mathbf{v})
\tag{\label{equation-29}}
\end{equation*}
$$

is called a *Clifford mapping*.
</MathBox>

<MathBox title='Clifford algebra' boxType='definition'>
Let $V$ be a vector space over $\R$, endowed with a symmetric bilinear form $g: V\times V\to\R$. Let $\mathcal{A}$ be an associative unital algebra over $\R$ with identity element $1_\mathcal{A}$ and let $\gamma: V\to\mathcal{A}$ be a linear map. The pair $(\mathcal{A}, \gamma)$ is a *Clifford algebra* for the quadratic space $(V, g)$ when 
1. $\mathcal{A}$ is generated as an algebra by 
$$
  \set{\gamma(\mathbf{v})|\mathbf{v}\in V} \cup \set{a1_\mathcal{A}|a\in\R}
$$
2. $\gamma$ satisfies the Clifford relation
$$
\begin{equation*}
  \gamma(\mathbf{u})\gamma(\mathbf{v}) + \gamma(\mathbf{v})\gamma(\mathbf{u}) = 2g(\mathbf{u},\mathbf{v})1_\mathcal{A}
\tag{\label{equation-28}}
\end{equation*}
$$
for all $\mathbf{u}, \mathbf{v} \in V$.

If $g$ is non-degenerate, the Clifford algebra for the dual quadratic space $(V^*, g^{-1})$ is defined in an analogous manner. In this case, $g^{-1} :V^* \times V^* \to\R$ is the induced symmetric bilinear form on $V^*$, and the the Clifford algebra is given by a pair $(\mathcal{A},\gamma)$, where now $gamma:V^* \to \mathcal{A}$ is a linear map satisfying

$$
  \gamma(\alpha) \gamma(\beta) + \gamma(\beta) \gamma(\alpha) = 2g^{-1} (\alpha, \beta) 1_\mathcal{A}
$$

for all $\alpha,\beta \in V^*$.
</MathBox>

Note that $\eqref{equation-28}$ holds for all $\mathbf{u}, \mathbf{v}\in V$ if and only if $\gamma$ satisfies $\eqref{equation-29}$. In many cases it is easier to verify $\eqref{equation-29}$ than $\eqref{equation-28}$. 

Now let $B = \set{\mathbf{e}_i}_{i=1}^n$ be an orthonormal basis of the $n$-dimensional vector space $V$. In the associated Clifford algebra $(\mathcal{A}, \gamma)$ for the quadratic space $(V, g)$, the Clifford relation implies the following identities
1. For $i \neq j$:
$$
  \gamma(\mathbf{e}_i)\gamma(\mathbf{e}_j) + \gamma(\mathbf{e}_j) \gamma(\mathbf{e}_i) = \mathcal{0}_\mathcal{A},\; i\neq j
$$
2. For each $i=1,\dots,n$
$$
  \gamma(\mathbf{e}_i)^2 = Q(\mathbf{e}_i) 1_\mathcal{A},\; $Q(\mathbf{e}_i) = g(\mathbf{e}_i, \mathbf{e}_i)$
$$

These relations allow any product of generators $\gamma(\mathbf{e}_i)$ for $i=1,\dots,n$ and their powers to be reordered, up to a sign, into a standard form

$$
  \prod_{i=1}^n \gamma(\mathbf{e}_i)^{\mu_i},\; \mu_i \in\set{0,1}
$$

where $\prod_{i=1}^n \gamma(\mathbf{e}_i)^0$ is the identity $1_\mathcal{A}$ of $\mathcal{A}$. Since $\mathcal{A}$ is generated as an algebra by $\set{\gamma(\mathbf{v}) | \mathbf{v}\in V} \cup \set{a1_\mathcal{A} | a\in\R}$, it follows that

$$
  \mathcal{A} = \operatorname{span}\Set{\prod_{i=1}^n \gamma(\mathbf{e}_i)^{\mu_i} | \mu_i = 0,1}
$$

There are $2^n$ such monomials, therefore $\dim(\mathcal{A}) \leq 2^n$. Although some Clifford algebras may have fewer than $2^n$ dimensions (typically due to degeneracy in the quadratic form), the algebras of maximal dimension have a property called universality. Such Clifford algebras serve as universal models for other algebras satisfying the same Clifford relations. 

<MathBox title='Universal Clifford algebra' boxType='definition'>
A Clifford algebra $(\mathcal{A},\gamma)$ for the quadratic space $(V,g)$ is said to be a *universal Clifford algebra* if, for each Clifford algebra $(\mathcal{B},\rho)$ for $(V,g)$ there exists an isomorphism $\phi:\mathcal{A}\to\mathcal{B}$ such that $\rho = \phi\circ\gamma$ and $\phi(1_\mathcal{A}) = 1_\mathcal{B}$. A universal Clifford algebra for the quadratic space $(V,g)$ is denoted $\operatorname{Cl}(V,g)$. 
</MathBox>

The universal Clifford algebra $\operatorname{Cl}(V,g)$, if it exists, is unique up to a unique isomorphism. Specifically, suppose $(\mathcal{A},\gamma)$ and $(\mathcal{B},\rho)$ are both Clifford algebras for the quadratic space $(V,g)$. Then, by the universal property, there exists a unique algebra isomorphism $\phi:\mathcal{A}\to\mathcal{B}$ such that $\rho 0 \phi\circ\gamma$ and $\phi(1_\mathcal{A}) = 1_\mathcal{B}$. Similarly, by applying the universal property to $(\mathcal{B},\rho)$, there exists a unique isomorphism such that $\gamma = \phi' \circ\rho$ and $\phi' (1_\mathcal{B}) = 1_\mathcal{A}$. Now consider the composition $\phi' \circ\phi: \mathcal{A}\to\mathcal{B}$. Then

$$
  (\phi' \circ\phi)\circ\gamma = \phi' \circ(\phi\circ\gamma) = \phi' \circ\rho = \gamma
$$

Since $\gamma$ generates $\mathcal{A}$ as an algebra, and $\phi' (1_\mathcal{B}) = 1_\mathcal{A}$, it follows that $\phi' \circ\phi = 1_\mathcal{A}$. A similar argument shows that $\phi\circ\phi' = 1_\mathcal{B}$. Hence, $\phi$ is an isomorphism of algebras, uniquely determinned by the condition $\rho: \phi\circ\gamma$.

<MathBox title='' boxType='theorem'>
The Clifford algebra $(\mathcal{A},\gamma)$ for the quadratic space $(V,g)$ is universal when $\dim(\mathcal{A}) = 2^n$, where $n = \dim(V)$.

<details>
<summary>Proof</summary>

Let $B = \set{\mathbf{e}_i}_{i=1}^n$ be an orthonormal basis of $V$. In the Clifford algebra $(\mathcal{A},\gamma)$ for $(V,g)$, the defining relations imply that $\gamma(\mathbf{e}_i)\gamma(\mathbf{e}_j) + \gamma(\mathbf{e}_j) \gamma(\mathbf{e}_i) = 0_\mathcal{A}$ for $i \neq j$ and $\gamma(\mathbf{e}_i)^2 = Q(\mathbf{e}_i)1_\mathcal{A}$, where $Q(\mathbf{e}_i) = g(\mathbf{e}_i, \mathbf{e}_i)$. Suppose that $\dim(\mathcal{A}) = 2^n$. In this case, the set

$$
  \Set{\prod_{i=1}^n \gamma(\mathbf{e}_i)^{\mu_i} | \mu_i = 0,1}
$$

not only generates $\mathcal{A}$ as an algebra but also forms a basis for $\mathcal{A}$. Now let $(\mathcal{B},\rho)$ be an arbitrary Clifford algebra for $(V,g)$. Then $\rho$ satisfies $\rho(\mathbf{e}_i)\rho(\mathbf{e}_j) + \rho(\mathbf{e}_j)\rho(\mathbf{e}_i) = 0_\mathcal{B}$ for $i \neq j$ and $\rho(\mathbf{e}_i)^2 = Q(\mathbf{e}_i) 1_\mathcal{B}$. It follows that the set

$$
  \Set{\prod_{i=1}^n \rho(\mathbf{e}_i)^{\mu_i} | \mu_i = 0,1}
$$

generates $\mathcal{B}$. Define the linear map $\phi:\mathcal{A}\to\mathcal{B}$ by

$$
  \phi\left(\prod_{i=1}^n \gamma(\mathbf{e}_i)^{\mu_i} \right) := \prod_{i=1}^n \rho(\mathbf{e}_i)^{\mu_i}
$$

Since both products obey the same anticommutation and square relations, and since the $\gamma$-monomials form a basis of $\mathcal{A}$, the map $\phi$ is a well-defined algebra homomorphism. It is bijective and satisfies the algebra product, i.e. $\phi(aa') = \phi(a)\phi(a')$ for all $a, a' \in\mathcal{A}$. Thus, it satisfies $\phi(\gamma(\mathbf{e}_i)) = \rho(\mathbf{e}_i)$ so that $\phi(\mathbf{e}_i)\phi(\mathbf{e}_j) + \phi(\mathbf{e}_j)\phi(\mathbf{e}_i) = 2g(\mathbf{e}_i, \mathbf{e}_j)1_\mathcal{B}$. Consequently $\phi$ is an isomorphism of algrabas, and $(\mathcal{A},\gamma)$ satisfies the universal property. Hence, $(\mathcal{A},\gamma)$ is the universal Clifford algebra $\operatorname{Cl}(V,g)$.
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
For every quadratic space $(V,g)$, there exists a universal Clifford algebra, and every universal Clifford algebra has dimension $2^n$.
</MathBox>


# Plane geometry $G(\R^2)$

Bivector basis
$$
\begin{align*}
  (e_1 e_2)^2 &= e_1 e_2 e_1 e_2 = -e_2 e_1 e_1 e_2 \\ 
  &= -e_2 e_1^2 e_2 = -e_2 e_2 = -e_2^2 \\
  &= -1
\end{align*}
$$

Geometric product
$$
\begin{align*}
  uv &= u\cdot v + u\wedge v \\ 
  &= |u|\cdot|v|\cos(\theta_{uv}) + |u|\cdot|v|\sin(\theta_{uv})I \\
  &= |u|\cdot|v|\left[\cos(\theta_{uv}) + I\sin(\theta_{uv})\right]
  &= |u|\cdot|v|e^{\theta_{uv}I}
\end{align*}
$$

## Rotations

Two reflections is a rotation 
$$
  u'' = (vw)^{-1}u(vw) = \frac{1}{|u|\cdot|v|}e^{-\theta I} u |v|\cdot|w|e^{\theta I} = e^{-\theta I}u e^{\theta I}
$$