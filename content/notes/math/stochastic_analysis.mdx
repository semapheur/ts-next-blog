---
title: 'Stochastic Analysis'
subject: 'Mathematics'
showToc: true
---

# Stochastic processes

To review, a stochastic process on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ is a collection of random variables $\mathbf{X}:=\{X_t: \Omega\to S\}_{t\in T}$, with state space $(S,\mathcal{S})$ and index space $(T,\mathcal{T})$, usually representing time. The random variable $X_t \in S$ describes the state of a system at time $t\in T$.

When representing time, the index set $T$ is usually either discrete time, $T = \mathbb{N}$, with a discrete topology or continuous time, $T = [0,\infty)$, with the usual Euclidean topology. In both cases, $T$ is given the Borel $\sigma$-algebra $\mathcal{T}$, generated by the open sets of the underlying topology. In the discrete case, this is simply the power set, $\mathcal{T} = \mathcal{P}(\mathbb{N})$, so that every subset of $T$ is measurable. The time space $(T,\mathcal{T})$ has a natural measure, which is the counting measure in the discrete case and the Lebesgue measure in the continuous case.

The state set $S$ usually has a topology and $\mathcal{S}$ is the Borel $\sigma$-algebra. A typical set of assumption is that the topology on $S$ is locally compact, Hausdorff, and with countable base (LCCB). Under these assumptions, any natural positive measure $\lambda$ on the state space $(S, \mathcal{S})$ will usually be a Borel measure satisfying $\lambda(C) < \infty$ if $C\subset S$ is compact. If $(S,\mathcal{S})$ is a discrete state space then $S$ is countable with $\mathcal{S} = \mathcal{P}(S)$. The compact sets are simply the finite sets, and the reference measure is the counting measure. If $S = \mathbb{R}^n$ for some $n\in\mathbb{N}$, then $S$ is usually gieven the Euclidean topology (which is LCCB) so that $\mathcal{S}$ is the usual Borel $\sigma$-algebra. In this case, the compact sets are the closed, bounded sets and the reference measure is the $n$-dimensional Lebesgue measure.

A filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is an increasing collection of sub $\sigma$-algebras of $\mathcal{F}$, encoding the information available at time $t$. A stochastic process $\mathbf{X}$ is adapted to a filtration $\mathscr{F}$ if $X_t$ is measurable with respect to $\mathcal{F}_t$ for each $t\in T$. The coarsest filtration is the natural filtration $\mathscr{F}^0 = \left\{ \mathcal{F}_t^0 \;|\; t\in T \right\}$, where $\mathcal{F}_t^0 = \sigma\{ X_s \;|\; s\in T, s\leq t \}$, the $\sigma$-algebra generated by the process up to time $t\in T$. In continuous time, it is often necessary to finer $\sigma$-algebras in order to have a nice mathematical theory. In particular, we often assume that the filtration $\mathscr{F}$ is right continuous in the sense that $\mathcal{F}_{t+} = \mathcal{F}_t$ for $t\in T$ where $\mathcal{F}_{t+} = \bigcup\{ \mathcal{F}_s \;|\; s\in T, s > t \}$. This can be accomplished by taking $\mathscr{F} = \mathscr{F}_+^0$ so that $\mathcal{F} = \mathcal{F}_{t+}^0$ for $t\in T$. In this case, $\mathscr{F}$ is called the right continuous refinement of the natural filtration. We also sometimes need to assume that $\mathscr{F}$ is complete with respect to $\mathbb{P}$, such that if $A\in\mathcal{S}$ with $\mathbb{P}(A) = 0$ and $B\subseteq A$ then $B\in\mathcal{F}_0$. That is, $\mathcal{F}_0$ contains all the null events (and hence also all of the almost cerain events), and therefore so does $\mathcal{F}_t$ for all $t\in T$.

In the following discussion, $\mathcal{B}$ denotes the collection of bounded, measurable functions $f: S\to\mathbb{R}$, $\mathcal{C}$ the collection of bounded, continuous functions $f:S\to\mathbb{R}$, and $\mathcal{C}_0$ the set of continuous functions $f:S\to\mathbb{R}$ vanishing at $\infty$. The latter property means that for every $\varepsilon > 0$, there exists a compact set $K\subseteq S$ such that $|f(x)| < \varepsilon$ for $x\in K^c$. These are all vector spaces under the usual (pointwise) addition and scalar multiplication, and $\mathcal{C}_0 \subseteq\mathcal{C}\subseteq\mathcal{B}$. The norm on these spaces is the supremum norm, defined by $\lVert f \rVert = \sup\{|f(x)|:x\in S\}$ for $f\in\mathcal{B}$.

## Markov process

A Markov process is a stochastic process with the property that the probability of a future event dependens only on the present state, i.e. the future is independent of the past.

| | Countable (discrete) state space | Continuous or general state space |
|---|---|---|
| **Discrete-time** $T=\mathbb{N}$ | discrete-time Markov chain | Markov process on a measurable space |
| **Continuous-time** $T=[0,\infty)$ | continuous-time Markov chain | Continuous stochastic process with the Markov property |

<MathBox title='Markov process' boxType='definition'>
A stochastic process $\mathbf{X}$ is a *Markov process* if it satisfies the Markov property

$$
  \mathbb{P}(X_{s+t}\in A|\mathcal{F}_s) = \mathbb{P}(X_{s+t}\in A|X_s)
$$

for all $s,t\in T$ and $A\in\mathcal{S}$. In particular, a Markov process $\mathbf{X}$ is *time homogeneous* (stationary) if

$$
  \mathbb{P}(X_{s+t}\in A | X_s = x) = \mathbb{P}(X_t\in A | X_0 = x)
$$
</MathBox>

The Markov property states that the conditional distribution of a future state $X_{s+t}$ given $\mathcal{F}_s$ is the same as the conditional distribution of $X_{s+t}$ just given the current state $X_s$. This means that any additional knowledge of events in the past is irrevelant in terms of predicting the future state $X_{s+t}$.

<MathBox title='Markov property in terms of conditional expectation' boxType='proposition'>
A stochastic process $\mathbf{X}$ is a *Markov process* if and only if

$$
  \mathbb{E}\left[f(X_{s+t})|\mathcal{F}_s\right] = \mathbb{E}\left[f(X_{s+t})|X_s\right]
$$

for all $s,t\in T$ and $f\in\mathcal{B}$. If a Markov process $\mathbf{X}$ is *time homogeneous* (stationary) then

$$
  \mathbb{E}\left[f(X_{s+t})|X_s = x\right] = \mathbb{E}\left[f(X_{s+t})|X_0 = x\right]
$$

<details>
<summary>Proof</summary>

By letting $f = \mathbf{1}_A$ for $A\in\mathcal{S}$ then $\mathbb{E}[\mathbf{1}_A(X_{x+t})] = \mathbb{P}(X_{x+s}\in A)$. Thus the conditional expectation formulation is equivalent with the Markov property.

</details>
</MathBox>

<MathBox title='Markov property is preserved under coarser filtrations' boxType='proposition'>
Suppose that the stochastic process $\mathbf{X}$ is adapted to the filtration $\mathscr{F}$, and $\mathscr{F}\subseteq\mathscr{G}$, i.e. $\mathscr{G}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a Markov process relative to $\mathscr{G}$, then $\mathbf{X}$ is a Markov process relative to $\mathscr{F}$.

In particular, if $\mathbf{X}$ is a Markov process, then $\mathbf{X}$ satisfies the Markov property relative to the natural filtration $\mathcal{F}^0$

<details>
<summary>Proof</summary>

Note $\mathbf{X}$ is adapted to $\mathscr{G}$, since $\mathbf{X}$ is adapted to $\mathscr{F}$ and $\mathscr{F}\subseteq\mathbf{G}$. If $s,t\in T$ and $f\in\mathcal{B}$ then

$$
\begin{align*}
  \mathbb{E}[f(X_{t+s})|\mathcal{F}_s] &= \mathbb{E}\left(\mathbb{E}[f(X_{s+t})|\mathcal{G}_s] | \mathcal{F}_s \right) \\
  &= \mathbb{E}\left( \mathbb{E}[f(X_{s+t})|X_s]|\mathcal{F}_s \right) \\
  &= \mathbb{E}[f(X_{s+t})|X_s]
\end{align*}
$$

The first equality is a basic property of conditional expected value. The second uses the fact that $\mathbf{X}$ is Markov relative to $\mathscr{G}$, and the third follows since $X_s$ is measurable with respect to $\mathcal{F}_s$
</details>
</MathBox>

<MathBox title='Feller process' boxType='definition'>
A Markov process $\mathbf{X}$ is a *Feller process* if it satisfies
1. Continuity in space: For $t\in T$ and $y\in S$, the distribution of $X_t$ given $X_0 = x$ converges to the distribution of $X_t$ given $X_0 = y$ as $x\to y$. This means taht $\mathbb{E}[f(X_t)| X_0 = x] \xrightarrow{x\to y}$ for every $f\in\mathcal{C}$.
2. Continuity in time: Given $X_0 = x$ for $x\in S$, then $X_t \xrightarrow{t\downarrow 0} x$ in probability. This means that $\mathbb{P}[X_t \in U | X_0 = x] \xrightarrow{t\downarrow 0}$ for every neighbourhood $U$ of $x$.
</MathBox>

Note that if $S$ is discrete, the first Feller property is always satisfied, and if $T$ is discrete, the second Feller property is always satisfied. In partical, every discrete-time Markov chain is a Feller process.

### Strong Markov process (stopping time)

Strong Markov processes arise with stopping times. Recall that random time is a random variable $\tau:\Omega\to T_\infty$ on $(\Omega,\mathcal{F},\mathbb{P})$ where $T_\infty = T \cup \{\infty\}$ is an enlarged time space. For a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ filtration on $(\Omega,\mathcal{F})$, a random time $\tau$ is called a stopping time relative to $\mathscr{F}$ if $\{\tau\leq t\}\in\mathcal{F}_t$ for each $t\in T$. For any stopping time $\tau$ on $\Omega$ we can define

$$
  \mathcal{F}_\tau = \{ A\in\mathcal{F} \;|\; A\cap \{\tau \leq t \}\in\mathcal{F}_t \; \forall t\in T \}
$$

Note that if $\mathbf{X} = \{X_t \}_{t\in T}$ is a stochastic process adapted to a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$, then for a stopping time $\tau$ the random variable $X_\tau$ is not necessarily measurable with respect to $\mathcal{F}_\tau$. For this we require that $\mathbf{X}$ is progressively measurable relative to $\mathscr{F}$ in the sense that $\mathbf{X}:\Omega\times T_t\to S$ is measurable with respect to $\mathcal{F}_t \otimes\mathcal{T}_t$ and $\mathcal{S}$. This is always true in the discrete case and more generally if $S$ has an LCCB topology with $\mathcal{S}$ as the Borel $\sigma$-algebra, and $\mathbf{X}$ is right continuous.

<MathBox title='Strong Markov process' boxType='definition'>
The process $\mathbf{X}$ is a strong Markov process if

$$
  \mathbb{E}\left[ f(X_{\tau + t})|\mathcal{F}_\tau \right] = \mathbb{E}[f(X_{\tau + t})|X_\tau]
$$

for every $t\in T$, stopping time $\tau$ and $f\in\mathcal{B}$. If a strong Markov process $\mathbf{X}$ is *time homogeneous* (stationary) then

$$
  \mathbb{E}\left[f(X_{\tau + t})|X_\tau = x\right] = \mathbb{E}\left[f(X_{\tau+t})|X_0 = x\right]
$$
</MathBox>

For a stationary process, the strong Markov property implies the ordinary Markov process, since a fixed time $t\in T$ is trivially also a stopping time. The converse is also true in discrete time. In continuous time it depends on the continuity of $\mathbf{X}$ and the filtration $\mathscr{F}$

<MathBox title='Stationarity and the strong Markov property' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a time homogeneous Markov process in discrete time. Then $\mathbf{X}$ is a strong Markov process.

If $\mathbf{X} = \{X_t \}_{t\in[0,\infty)}$ is a Feller Markov process, then $\mathbf{X}$ is a strong Markov process relative to the filtration $\mathscr{F}_+^0$, the right-continuous refinement of the natural filtration.
</MathBox>

<MathBox title='The strong Markov property is preserved under coarser filtrations' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is progressively measurable relative to the filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ and that the filtration $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a strong Markov process relative to $\mathscr{G}$ then $\mathbf{X}$ is a strong Markov process relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Since $\mathbf{X}$ is adapted to $\mathscr{F}$, it is also adapted to $\mathscr{G}$. Suppose that $\tau$ is a stopping time for $\mathscr{F}$ and that $t\in T$ and $f\in\mathcal{B}$. Then $\tau$ is also a stopping time for $\mathscr{G}$ and $\mathcal{F}_\tau \subseteq\mathcal{G}_\tau$. Hence

$$
\begin{align*}
  \mathbb{E}\left[f(X_{\tau + t})|\mathcal{F}_\tau\right] &= \mathbb{E}\left(\mathbb{E}\left[f(X_{\tau + t})|\mathcal{G}_\tau\right]|\mathcal{F}_\tau \right) \\
  &= \mathbb{E}\left(\mathbb{E}\left[f(X_{\tau + t})|X_\tau\right]|\mathcal{F}_\tau \right) \\
  &= \mathbb{E}\left[f(X_{\tau + t})|X_\tau\right]
\end{align*}
$$

The last equation follows since $\mathbf{X}_\tau$ is measurable with respect to $\mathcal{F}_\tau$ given that $\mathbf{X}$ is progressively measurable to $\mathscr{F}$.
</details>
</MathBox>

### Transition kernels of Markov processes

The transition kernels of a time-homogeneous Markov process is the conditional distribution given the initial distribution of the process. This means that the initial distribution and the transition kernels determine the finite dimensional distributions of a Markov process.

<MathBox title='Transition kernel' boxType='definition'>
Suppose that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a time-homogeneous Markov process. For $t\in T$ let

$$
  P_t(x,A) = \mathbb{P}(X_t\in A \;|\; X_0 = x),\; x\in S, A\in\mathcal{S}
$$

Then $P_t$ is a probability kernel on $(S,\mathcal{S})$ known as the transition kernel of $\mathbf{X}$ for time $t$. 

<details>
<summary>Proof</summary>

For a fixed $t\in T$, the measurability of $x\mapsto\mathbb{P}(X_t \in A \;|\; X_0 = x)$ for $A\in\mathcal{S}$ is built into the definition of conditional probability. Additionally, $A\mapsto\mathbb{P}(X_t\in A \;|\; X_0 = x)$ is a probability measure on $\mathcal{S}$ for $x\in S$. In general, the conditional distribution of one random variable, conditioned on a value of another random variable defines a probability kernel.
</details>
</MathBox>

The transition kernel $P_t(x,\cdot)$ of a time-homogeneous Markov process $\mathbf{X}$ at time $t$ is the conditional distribution of $X_t$ given $X_0 = x \in S$. By the time-homogeneous property, $P_t(x, \cdot)$ is also the conditional distribution of $X_{s+t}$ given $X_s = x$ for $s\in T$

$$
  P_t(x, A) = \mathbb{P}(X_{s+t}\in A | X_s = x),\; s,t\in T, x\in S, A\in\mathcal{S}
$$

Usually there is a natural reference measure $\lambda$ on $(S,\mathcal{S})$, in which case the transition kernel $P_t$ will often have a transition density with respect to $\lambda$

$$
  P_t(x, A) = \mathbb{P}(X_t \in A \;|\; X_0 = x) = \int_A p_t(x, y)\lambda(\mathrm{d}y),\; x\in S, A\in\mathcal{S}
$$

<MathBox title='Chapman-Kolmogorov equation' boxType='theorem'>
Suppose that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a time-homogeneous Markov process with transition kernels $\mathbf{P} = \{ P_t \}_{t\in T}$. For $s,t\in T$ then $P_s P_t = P_{s+t}$ given by

$$
  P_{s+t}(x,A) = \int_S P_s(x, \mathrm{d}y) P_t(y, A),\; x\in S, A\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

Note that $P_x(x,\cdot)$ is the conditional distribution of $X_s$ given $X_0 = x \in S$. Conditioning on $X_s$ for $A\in\mathcal{S}$ gives

$$
\begin{align*}
  P_{s+t}(x,A) &= \mathbb{P}(X_{s+t}\in A \;|\; X_0 = x) \\
  &= \int_S P_s(x, \mathrm{d}y)\mathbb{P}(X_{s+t}\in A \;|\; X_s = y, X_0 = x)
\end{align*}
$$

By the Markov and time-homogeneous properties, we have

$$
  \mathbb{P}(X_{s+t}\in A \;|\; X_s = y, X_0 = x) = \mathbb{P}(X_t\in A \;|\; X_0 = y) = P_t(y,A)
$$

Substituting we get

$$
  P_{s+t}(x,A) &= \int_S P_s (x,\mathrm{d}y)P_t(y, A) = (P_s P_t)(x, A)
$$
</details>
</MathBox>

The set of transition kernels $\mathbf{P}$ is a semi-group. Generally, the commutative property does not hold for the product operation on kernels. However, transition kernels a of time-homogeneous Markov process are commutative, i.e. $P_s P_t = P_t P_s = P_{s+t}$ for $s,t\in T$.

In discrete time, $T = \mathbb{N}$, the transition kernels of $\mathbf{X}$ are simply the powers of the one-step transition kernel. That is if $P = P_1$ then $P_n = P^n$ for $n\in\mathbb{N}$.

<MathBox title='' boxType='corollary'>
Suppose that $\lambda$ is the reference measure on $S$ and that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a Markov process with transition densities $\{ p_t \}_{t\in T}$. If $s,t \in T$, then $p_s p_t = p_{s+t}$

$$
  p_t (x, z) = \int_S p_s(x, x) p_t(y, z)\lambda(\mathrm{d}y),\; x, z\in S
$$

<details>
<summary>Proof</summary>

By the Chapman-Kolmogorov equation, the transition kernels of $\mathbf{X}$ satisfy $P_s P_t = P_{s+t}$. Since $P_s$ has density $p_s$, $P_t$ has density $p_t$ and $P_s P_t$ has density $p_{s + t}$ it follows from the Chapman-Kolmogorov equation that $P_{s+t}$ has density $p_s p_t$.
</details>
</MathBox>

A kernel defines two operations:
- operating on the left with positive measure on $(S,\mathcal{S})$
- operating on the right with measurable, real-valued functions

<MathBox title='Left transition kernel operation' boxType='proposition'>
If $\mu_s$ is the distribution of $X_s$, then $X_{s+t}$ has distribution $\mu_{s+t} = \mu_s P_t$ for $s,t\in T$

$$
  \mu_{s+t}(A) = \int_S \mu_s(\mathrm{d}x)P_t(x, A),\; A\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

Conditioning on $X_s$ gives

$$
\begin{align*}
  \mathbb{P}(X_{s+t}\in A) &= \mathbb{E}\left[\mathbb{P}(X_{s+t}\in A \;|\; X_s) \right] \\
  &= \int_S \mu_s(\mathrm{d}x)\mathbb{P}(X_{s+t}\in A \;|\; X_s = x) \\
  &= \int_S \mu_s(\mathrm{d}x)\mathbb{P}_t(x, A) \\
  &= \mu_s P_t (A)
\end{align*}
$$
</details>
</MathBox>

If $\mathcal{P}$ denotes the collection of probability measures on $(S,\mathcal{S})$, the left operator $P_t$ maps $\mathcal{P}$ back into $\mathcal{P}$. In particular, if $X_0$ has distribution $\mu_0$ then $X_t$ has distribution $\mu_t = \mu_0 P_t$ for every $t\in T$.

<MathBox title='Invariant positive measures' boxType='definition'>
A positive measure $\mu$ on $(S, \mathcal{S})$ is invariant for $\mathbf{X}$ if $\mu P_t = \mu$ for every $t\in T$.
</MathBox>

If $\mu$ is a probability measure that is invariant for $\mathbf{X}$, and $X_0$ has distribution $\mu$, then $X_t$ also has distribution $\mu$ for every $t\in T$ making the process $\mathbf{X}$ identically distributed. In discrete time, note that if $\mu P = \mu$ then $\mu P^n = \mu$ for every $n\in \mathbb{N}$ so $\mu$ is invariant for $\mathbf{X}$

<MathBox title='Right transition kernel operation' boxType='proposition'>
Suppose that $f:S\to\mathbb{R}$. If $t\in T$ then

$$
  P_t f(x) = \int_S P_t(x, \mathrm{d}y)f(y) = \mathbb{E}[f(X_t)\;|\; X_0 = x],\; x\in S
$$

<details>
<summary>Proof</summary>

This follows directly from the definition of conditional expectation.
</details>
</MathBox>

In particular, the right operator $P_t$ is defined on $\mathcal{B}$, the vector space of bounded, linear functions $f:S\to\mathbb{R}$, and is in fact a linear operator on $\mathcal{B}$. That is, if $f,g\in\mathcal{B}$ and $c\in\mathbb{R}$ then $P_t (f+g) = P_t f + P_t g$ and $P_t (cf) = cP_t f$. Moreover, $P_t$ is a contraction operator on $\mathcal{B}$, since $\lVert P_t f \rVert\leq \lVert f \rVert$ for $f\in\mathcal{B}$. It follows that $P_t$ is a continuous operator on $\mathcal{B}$.

<MathBox title='Harmonic measurable function' boxType='definition'>
A measurable function $f:S\to\mathbb{R}$ is harmonic for $\mathbf{X}$ is $P_t f = f$ for all $t\in T$.
</MathBox>

In discrete time, if $Pf = f$ then $P^n f = f$ for all $n\in\mathbb{N}$, making $f$ harmonic for $\mathbf{X}$.

<MathBox title='Differential form of Markov distributions' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a Markov process with transition operators $\mathbf{P} = \{P_t \}_{t\in T}$ and that $(t_i)_{i=1}^{n\in\mathbb{N}} \in T^n$ is strictly increasing. If $X_0$ has distribution $\mu_0$, then in differential form the distribution of $(X_i)_{i=0}^{t_n}$ is

$$
  \mu_0(\mathrm{d}x_0)P_{t_1}(x_0, \mathrm{d}x_1)\prod_{i=2}^{n} P_{t_n - t_{n-1}}(x_{n-1}, \mathrm{d}x_n)
$$

<details>
<summary>Proof</summary>

This follows from induction and repeated use of the Markov property. If $t\in T$ with $t> 0$, then conditioning on $X_0$ gives for $A, B\in\mathcal{S}$

$$
\begin{align*}
  \mathbb{P}(X_0 \in A, X_t\in B) = \int_A \mathbb{P}(X_t\in B \;|\; X_0 = x)\mu_0 (\mathrm{d}x) \\
  &= \int_A P_t (x, B\mu(\mathrm{d}x) \\
  &= \int_A \int_B P_t(x,\mathrm{d}y)\mu_0 (\mathrm{d}x)
\end{align*}
$$

Hence in differential form, the distribution of $(X_0, X_t)$ is $\mu(\mathrm{d}x)P_t(x,\mathrm{d}y)$. If $s,t\in T$ with $0 < s < t$, then conditioning on $(X_0, X_s=$ and using the previous result gives for $A, B, C \in\mathcal{S}$

$$
  \mathbb{P}(X_0\in A, X_s\in B, X_t\in C) = \int_{A\times B} \mathbb{P}(X_t\in C \;|\; X_0 = x, X_s = y)\mu_0 (\mathrm{d}x) P_s(x, \mathrm{d}y)
$$

By the Markov property

$$
\begin{align*}
  \mathbb{P}(X_t\in C \;|\; X_0 = x, X_s = y) &= \mathbb{P}(X_t \in C | X_s = y) \\
  &= P_{t-s}(y, C) = \int_C P_{t-s}(y,\mathrm{d}z)
\end{align*}
$$

Hence in differential form, the distribution of $(X_0, X_s, X_t)$ is $\mu_0(\mathrm{d}x)P_s(x,\mathrm{d}y)P_{t-s}(y,\mathrm{d}z})$. Continuing in this manner gives the general result.
</details>
</MathBox>

Knowing the transition kernels and the initial distribution determines a finite set of distributions for a Markov process. From the Kolmogorov construction theorem, we know that there exists a stochastic process that has these finite dimensional distributions. This is straightforward in discrete time, however in continuous time two problems arise. First, it is not clear how to construct the transition kernels so that the Chapman-Kolmogorov equations are satisfied. Second, we want the Markov process to exhibit certain properties that go beyond the finite dimensional distributions.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a Markov process on an LCCB state space $(S,\mathcal{S})$ with transition operators $\mathbf{P} = \{P_t \}_{t\in [0,\infty)}$. Then $\mathbf{X}$ is a Feller process if and only if

1. Continuity in space: If $f\in\mathcal{C}_0$ and $t\in[0,\infty)$, then $P_t f\in\mathcal{C}_0$
2. Continuity in time: If $f\in\mathcal{C}_0$ and $x\in S$ then $P_t f(x) \xrightarrow{t\downarrow 0} f(x)$

A semi-group of probability kernels $\mathbf{P}$ satisfying these properties is called a Feller semi-group.
</MathBox>

This means that a Markov process $\mathbf{X}$ is Feller if and only if $\mathbf{P}$ is Feller. The first property means that $P_t$ is an operator on the vector space $\mathcal{C}_0$, in addition to being an operator on the larger space $\mathcal{B}$. The second condition implies a stronger form of continuity in time.

Note that if $S$ is discrete, then the first property is automatically satisfied. If $T$ is discrete, then the second property is automatically satisfied.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{P} = \{P_t \}_{t\in [0,\infty)}$ is a Feller semi-group of transition operators. Then $t\mapsto P_t f$ is continuous (with respect to the supremum norm) for $f\in\mathcal{C}_0$, i.e.

$$
  \lVert P_{t+s} f - P_t f \rVert = \sup\{|P_{t+s}f(x) - P_t f(x)| : x\in S \} \xrightarrow{s\to 0} 0
$$
</MathBox>

#### Sampling in time

<MathBox title='Time sampled Markov process gives a time-discrete Markov process' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a Markov process with state space $(S,\mathcal{S})$ and that $(t_i)_{i=0}^{n\in\mathbb{N}}$ is an increasing sequence in $T$. Let $Y_n = X_{t_n}$, then $\mathbb{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a Markov process in discrete time.

<details>
<summary>Proof</summary>

For $n\in\mathbb{N}$, let $\mathcal{G}_n = \sigma\{ Y_k \;|\; k\in\mathbb{N}, k\leq n \}$ so that $\{\mathcal{G}_n\}_{n\in\mathbb{N}}$ is the natural filtration associated with $\mathbf{Y}$. Note that $\mathcal{G}_n \subseteq \mathcal{F}_{t_n}$ and $Y_n = X_{t_n}$ is measurable with respect to $\mathcal{G}_n$ for $n\in\mathcal{N}$. Let $k, n\in\mathbb{N}$ and let $A\in\mathcal{S}$, then

$$
\begin{align*}
  \mathbb{P}(Y_{k+n}\in A \;|\; \mathcal{G}_k) = \mathbb{P}(X_{t_{n+k}}\in A \;|\; \mathcal{G}_l) \\
  &=  \mathbb{P}(X_{t_{n+k}}\in A \;|\; X_{t_k}) \\
  &= \mathbb{P}(Y_{n+k}\in A \;|\; Y_k) 
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a time-homogenous Markov process with state space $(S,\mathcal{S})$ and transition kernels $\mathbf{P} = \{P_t\}_{t\in T}$. Fix $r\in T$ with $r>0$ and define $Y_n = X_{nr}$ for $n\in\mathbb{N}$. Then $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a time-homogenous Markov process in discrete time, with one-step transition kernel

$$
  Q(x, A) = P_r (x, A),\; x\in S, A\in\mathcal{A}
$$
</MathBox>

#### Enlarging the sample space

A non-homogeneous Markov process can be turned into a time-homogenous Markov process at the expense of enlarging the state space.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a non-homogenous Markov process with state space $(S,\mathcal{S})$. Suppose that $\tau$ is a random variable taking values in $T$, independent of $\mathbf{X}$. Let $\tau_t = \tau + t$ and let $Y_t = (X_{\tau_t}, \tau_t)$ for $t\in T$. Then $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a homogenous Markov process with state space $(S\times T, \mathcal{S} \otimes \mathcal{T})$. For $t\in T$, the transition kernel $P_t$ is given by

$$
  P_t [(x, r), A\times B] = \mathbb{P}(X_{r+t}\in A\;|\; X_r = x)\mathbf{1}(r + t\in B), (x,r)\in S\times T, A\times B\in\mathcal{S}\otimes\mathcal{T}
$$

<details>
<summary>Proof</summary>

By definition and the substitution rule

$$
\begin{align*}
  \mathbb{P}[Y_{s+t}\in A\times B \;|\; Y_s = (x,r)] &= \mathbb{P}(X_{\tau_{s+t}}\in A, \tau_{s+t}\in B \;|\; X_{\tau_{s}} = x, \tau_s = r) \\
  &= \mathbb{P}(X_{tau+s+t}\in A, \tau+s+t\in B \;|\; X_{\tau+s} = x, \tau+s = r) \\
  &= \mathbb{P}(X_{r+t}\in A, r+t\in B \;|\; X_r = x, \tau+s = r)
\end{align*}
$$

Since $\tau$ is independent of $\mathbf{X}$ the last term is

$$
  \mathbb{P}(X_{r+t}\in A, r+t\in B \;|\; X_r = x, \tau+s = r) = \mathbb{P}(X_{r+t}\in A \;|\; X_r = x)
$$

which does not depend on $s$, making $\mathbf{Y}$ time-homogenous.
</details>
</MathBox>

Sometimes a stochastic process with weak memory can be made into a Markov process by enlarging the state space appropriately

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{n\in\mathbb{N}}$ is a random process with state space $(S,\mathcal{S})$ in which the future depends on the last $k$ states, i.e.

$$
  \mathbb{P}(X_{n+k} \in A | \mathcal{F}_{n+k-1}) = \mathbb{P}(X_{n+2}\in A \;|\; X_n,\dots,X_{n+k}),\; A\in\mathcal{S}
$$

where $\{\mathcal{F}_n\}_{n\in\mathbb{N}}$ is the natural filtration associated with the process $\mathbf{X}$. Suppose also that the process is time-homogenous in the sense that

$$
  \mathbb{P}(X_{n+k}\in A \;|\; X_n = x_0, \dots, X_{n+k} = x_k) = Q(x_0,\dots,x_k, A)
$$
 
independently of $n\in\mathbb{N}$. Let $Y_n = (X_n+i)_{i=0}^k-1$, then $\mathbf{N} = \{Y_n\}_{n\in\mathbb{N}}$ is a time homogenous Markov process with state space $S^k, \bigotimes_{i=1}^k \matcal{S}$. The one-step transition kernel is

$$
  P[(x_i)_{i=1}^k, \bigtimes_{i=1}^k A_i] = I(x_1, A_1)Q_1(x_1, x_2, A_2)\dots Q_{k-1}(x_1,\dots,x_k, Q_k)\; x_i\in S, A_i\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

For $k=2$ note that $\sigma\{Y_k \;|\; k\leq n\} = \sigma\{(X_k, X_{k+1}) \;|\; k\leq n \} = \mathcal{F}_{n+1}$ for $n\in\mathbb{N}$. Thus, the natural filtration associated with $\mathbf{Y}$ is $\{\mathcal{F}_n\}_{n\in\mathbb{N}}$. If $C\in\mathcal{S}\mathcal{S}$ then

$$
\begin{align*}
  \mathbb{P}(Y_{n+1}\in C \;|\; \mathcal{F}_{n+1}) &= \mathbb{P}[(X_{n+1}, X_{n+2})\in C \;|\; \mathcal{F}_{n+1}] \\
  &= \mathbb{P}[(X_{n+1}, X_{n+2})\in C \;|\; X_n, X_{n+1}] = \mathbf{P}(Y_{n+1}\in C \;|\; Y_n)
\end{align*}
$$

by the given assumption on $\mathbf{X}$. Hence $\mathbf{Y}$ is a Markov process. Next,

$$
\begin{align*}
  \mathbb{P}[Y_{n+1}\in A\times B \;|\; Y_n = (x,y)] &= \mathbb{P}[(X_{n+1}, X_{n+2})\in A\times B \;|\; (X_n, X_{n+1}) = (x,y)] \\
  &= \mathbb{P}(X_{n+1}\in A, X_{n+2}\in B \;|\; X_n = x, X_{n+1} = y) \\
  &= \mathbb{P}(y\in A, X_{n+2}\in B \;|\; X_n = x, X_{n+1} = y) \\
  &= I(y, A)Q(x,y,B)
\end{align*}
$$
</details>
</MathBox>

### Potential operators

#### Discrete time

<MathBox title='' boxType='proposition'>

For $\alpha\in (0,1]$, the $\alpha$-potential kernel $R_\alpha$ of a discrete time Markov process $\mathbf{X}$ is defined as

$$
  R_\alpha (x, A) = \sum_{n=0}^\infty \alpha^n P^n (x, A),\; x\in S, A\in\mathcal{S}
$$

The special case $R = R_1$ is simply the potential kernel of $\mathbf{X}$ where $R(x, A)$ is the expected number of visits of $\mathbf{X}$ to $A$, starting at $x$.

<details>
<summary>Proof</summary>

The function $x\mapsto R_\alpha (x, A)$ from $S$ to $[0,\infty)$ is measurable for $A\in\mathcal{S}$ since $x\mapsto P^n(x, A)$ is measurable for each $n\in\mathbb{N}$. The mapping $A\mapsto R_\alpha (x, A)$ is a positive measure on $\mathcal{S}$ for $x\in S$ since $A\mapsto P^n(x, A)$ is a probability measure for each $n\in\mathbb{N}$. The interpretation of $R(x, A)$ comes from interchanging sum and expected value, which is allowed since the terms are nonnegative.

$$
\begin{align*}
  R(x, A) &= \sum_{n=0}^\infty P^n (x, A) \\
  &= \sum_{n=0}^\infty \mathbb{E}[\mathbf{1}(X_n \in A) | X_0 = x] \\
  &= \mathbb{E}\left( \sum_{n=0}^\infty \mathbf{1}(X_n \in A) \mid| X_0 = x \right) \\
  &= \mathbb{E}[#\{n\in\mathbb{N} : X_n \in A\}|X_0 = x]
\end{align*}
$$
</details>
</MathBox>

For a discrete-time Markov process $\mathbf{X}$, the potential kernel $R_\alpha (x, A)$ for $\alpha\in(0,1)$ can be interpreted as the expected number of times $\mathbf{X}$ visits $A\in\mathcal{S}$ starting at $x\in S$. The parameter $\alpha$ represents a discount rate of this expected value in the sense that a future vists at time $n$ has a present value of $\alpha^n$.

The potential kernel $R_\alpha$ defines two operators, operating on the right on measurable functions, and on the left on positive measures. For measurable functions $f:S\to\mathbb{R}$, the right potential operator is defined as

$$
\begin{align*}
  R_\alpha f(x) &= \sum_{n=0}^\infty \alpha^n P^n f(x) \\
  &= \sum_{n=0}^\infty \alpha^n \int_S P^n (x,\mathrm{d}y) f(y) \\
  &= \sum_{n=0}^\infty \alpha^n \mathbb{E}[f(X_n)|X_0 = x]
\end{align*}
$$

The functions $f\in\mathcal{B}$ represents the reward/cost when $\mathbf{X}$ visits $x\in S$.

<MathBox title='' boxType='proposition'>

If $\alpha\in (0,1)$, then $R_\alpha (x, S) = \frac{1}{1-\alpha}$. It follows that the right operator $R_\alpha$ is a bounded, linear operator on $\mathcal{B}$ with $\lVert R_\alpha \rVert = \frac{1}{1-\alpha}$. It also follows that $(1-\alpha)R_\alpha$ is a probability kernel.

<details>
<summary>Proof</summary>

Using geometric series

$$
  R_\alpha (x, S) \sum_{n=0}^\infty \alpha^n P^n (x, S) = \sum_{n=0}^\infty \alpha^n = \frac{1}{1-\alpha}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $\alpha\in (0,1)$, then $(1-\alpha)R_\alpha (x, \cdot)$ is the conditional distribution of $X_N$ given $X_0 = x\in S$, where $N$ is independent of $\mathbf{X}$ and has the geometric distribution on $\mathbb{N}$ with parameter $1-\alpha$.

<details>
<summary>Proof</summary>

Conditioning on $N$ gives

$$
  \mathbb{P}(X_N \in A | X_0 = x) = \sum_{n=0}^\infty \mathbb{P}(N=n)\mathbb{P}(X_N \in A | N = n, X_0 =x)
$$

By the substitution rule and the assumption of independence

$$
\begin{align*}
  \mathbb{P}(X_N \in A | N = n, X_0 = x) &= \mathbb{P}(X_n \in A | N=n, X_0 = x) \\
  &= \mathbb{P}(X_n \in A | X_0 = x) = P^n(x,A)
\end{align*}
$$

Since $N$ has the geometric distribution on $\mathbb{N}$ with parameter $1-\alpha$ it follows that $P(N = n) = (1-\alpha)\alpha^n$ for $n\in\mathbb{N}$. Substituting gives

$$
  \mathbb{P}(X_N \in A | X_0 = x) = \sum_{n=0}^\infty (1-\alpha)\alpha^n P^n (x, A) = (1-\alpha) R_\alpha (x, A)
$$
</details>
</MathBox>

The kernel $(1-\alpha)R_\alpha$ is a transition probability corresponding to the random time $N$ rather than the deterministic time $n\in\mathbb{N}$.

For positive measures $\mu$ on $\mathcal{S}$, the left potential operator is defined as

$$
  \mu R_\alpha (A) = \sum_{n=0}^\infty \alpha^n \mu P^n (A) = \sum_{n=0}^\infty \alpha^n \int_S \mu(\mathrm{d}x)P^n (x, A),\; A\in\mathcal{S} 
$$

If $X_0$ has distribution $\mu$, then $\mu P^n$ is the distribution of $X_n$ for $n\in\mathbb{N}$. In this case, $(1-\alpha)\mu R_\alpha$ is the distribution of $X_N$, where $N$ is independent of $\mathbf{X}$ and is geometrically distributed on $\mathbb{N}$ with parameter $1 - \alpha$.

<MathBox title='' boxType='proposition'>
The potential kernels $\mathbb{R} = \{ R_\alpha \}_{\alpha\in (0, 1)}$ completely determine the transition kernels $\mathbf{P} = \{P_n\}_{n\in\mathbb{N}}$.

<details>
<summary>Proof</summary>

For $x\in S$ and $A\in\mathcal{A}$, the function $\alpha\mapsto R_\alpha(x, A)$ is a power series in $\alpha$ with coefficients $n\mapsto P^n(x,A)$. In combinatorial terms, $\alpha\mapsto R_\alpha(x, A)$ is the ordinary generating function of the sequence $n\mapsto P^n (x, A)$. This power series has radius of convergence at least $1$, extending the domain to $\alpha\in (-1, 1)$. Thus, we can recover the transition kernels by derivating $R_\alpha$ and evaluating at $\alpha = 0$

$$
  P^n (x, A) = \frac{1}{N!}\left. \frac{\mathrm{d}^n}{\mathrm{d}\alpha^n} R_\alpha (x, A) \right|_{\alpha = 0}
$$
</details>
</MathBox>

The kernels $\mathbf{R} = \{ R_\alpha \}_{\alpha\in (0,1)}$, along with the initial distribution, completely determine the finite dimensional distributions of the discrete-time Markov process $\mathbf{X}$.

<MathBox title='' boxType='proposition'>

If $\alpha,\beta\in (0, 1]$ and $k\in\mathbb{N}$, then (as kernels)

1. P^k R_\alpha = R_\alpha P^k = \sum_{n=0}^\infty \alpha^n P^{n+k}
2. R_\alpha R_\beta = R_\beta R_\alpha = \sum_{m=0}^\infty\sum_{n=0}^\infty \alpha^m \beta^n P^{m+n}
3. $I + \alpha R_\alpha P = I + \alpha P R_\alpha = R_\alpha $

If $\alpha\leq\beta$ then (as kernels)

4. $\beta R_\beta = \alpha R_\alpha + (\beta - \alpha) R_\alpha R_\beta$

If $\alpha\in (0,1)$, then as operator as on $\mathcal{B}$

5. $R_\alpha = (I - \alpha P)^{-1}$
6. $P = \frac{1}{\alpha}(1 - R_\alpha^{-1})$
 
<details>
<summary>Proof</summary>

Suppose that $f\in\mathcal{B}$ is nonnegative. Since the kernels are nonnegative we can interchange sums with kernel operations.

1. Evaluating $R_\alpha P^k$ directly
$$
  R_\alpha P^k f = \sum_{n=0}^\infty \alpha^n P^n P^k f = \sum_{n=0}^\infty \alpha^n P^{n+k} f
$$

The other direction requires an interchange

$$
  P^k R_\alpha f = P^k \sum_{n=0}^\infty \alpha^n P^n f = \sum_{n=0}^\infty \alpha^n P^k P^n f = \sum_{n=0}^\infty \alpha^n P^{n+k}f
$$

2. Only the first direction is shown as the other is similar.
$$
\begin{align*}
  R_\alpha R_\beta &= \sum_{m=0}^\infty \alpha^m P^m R_\beta f \\
  &= \sum_{m=0}^\infty \alpha^m P^m \left( \sum_{n=0}^\infty \beta^n P^n f \right) \\
  &= \sum_{m=0}^\infty \sum_{n=0}^\infty \alpha^m \beta^n P^m P^n f \\
  &= \sum_{m=0}^\infty \sum_{n=0}^\infty \alpha^m \beta^n P^{m+n} f
\end{align*}
$$

3. From the 1st identity
$$
\begin{align*}
  (I + \alpha R_\alpha P)f &= (I + \alpha RP_\alpha)f \\
  &= f + \sum_{n=0}^\infty \alpha^{n + 1} P^{n+1} f \\
  &= \sum_{n=0}^\infty \alpha^n P^n f = R_\alpha f
\end{align*}
$$

4. Assume $\alpha < \beta$ as the case $\alpha = \beta$ is trivial. From the 2nd identity

$$
  R_\alpha R_\beta f = \sum_{j=0}^\infty \sum_{k=0} \alpha^j \beta^k P^{j+k} f
$$

Changing the sum variables to $n = j + k$ and $j$

$$
\begin{align*}
  R_\alpha R_\beta f = \sum_{n=0}^\infty \sum_{j=0}^n \alpha^j \beta^{n-j} P^n f \\
  &= \sum_{n=0}^\infty \sum_{j=0}^n \left( \frac{\alpha}{\beta} \right)^j \beta^n P^n f \\
  &= \sum_{n=0}^\infty \frac{1 - \left( \frac{\alpha}{\beta} \right)^{n+1}}{1 - \frac{\alpha}{\beta}} \beta^n P^n f \\
  &= \frac{1}{\beta - \alpha}  \beta \left( \sum_{n=0}^\infty \beta^n P^n f \right) - \alpha \left( \sum_{n=0}^\infty \alpha^n P^n f \right) \\
  &= \frac{1}{\beta - \alpha} (\beta R_\beta f -\alpha R_\alpha f)
\end{align*}
$$

Note that $R_\alpha f$ is finite since $\alpha < 1$.

5. Since the operators are bounded, we can subtract. From the 3rd property

$$
\begin{gather*}
  I + \alpha R_\alpha  P = R_\alpha \iff R_\alpha (I - \alpha P) = I \\
  I + \alpha P R_\alpha = R_\alpha \iff (I - \alpha) R_\alpha = I
\end{gather*}
$$

6. This follows from the 5th property.
</details>
</MathBox>


#### Continuous time

### Examples and applications

#### Recurrence relations and differential equations

Markov processes can be viewed as stochastic counterparts of deterministic recurrence relations (discrete time) and differential equations (continuous time)

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{n\in\mathbb{N}}$ is a stochastic process with state space $(S,\mathcal{S})$ satisfying the recurrence relation

$$
  X_{n+1} = g(X_n),\; n\in\mathbb{N}
$$

where $g:S\to S$ is measurable. Then $\mathbf{X}$ is a homogenous Markov process with one-step transition operator $P$ given by $Pf = g\circ g$ for a measurable function $f:S\to\mathbb{R}$

<details>
<summary>Proof</summary>

Clearly $\mathbf{X}$ is determined by the initial state, and in fact $X_n = g^n (X_0)$ for $n\in\mathbb{N}$ where $g^n$ is the $n$-fold composition power of $g$. Therefore, the only possible source of randomness is in the initial state. The Markov and time homogenous properties simply follow from the trivial fact that $g^{m+n}(X_0) = g^n[g^m(X_0)]$ so that $X_{m+n} = g^n(X_m)$. That is, the state at time $m+n$ is completely determined by the state at time $m$ (regardless of the previous states) and the time increment $n$. In particular, $Pf(x) = \mathbb{E}[g(X_1)\;|\; X_0 = x] = f[g(x)]$ for measurable $f:S\to\mathbb{R}$ and $x\in S$. Note that for $n\in\mathbb{N}$, the $n$-step transition operator is given by $P^n f = f\circ g^n$.
</details>
</MathBox>

<MathBox title='Recurrence relation' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{t\in[0,\infty)}$ is a stochastic process with state space $(\mathbb{R},\mathcal{R})$ satisfying the first-order differential equation

$$
  \frac{\mathrm{d}}{\mathrm{d}t}X_t = g(X_t)
$$

where $g:\mathbb{R}\to\mathbb{R}$ is Lipschitz continuous. Then $\mathbf{X}$ is a Feller Markov process.

<details>
<summary>Proof</summary>

Lipschitz continuity means that there exists a constant $k\in(0,\infty)$ such that $|g(y) - g(x)|\leq k|x-y|$ for $x,y\in\mathbb{R}$. This is a standard condition on $g$ that guarantees the existence of a solution to the differential equation on $[0,\infty)$. Therefore, the only source of randomness in the process comes from the initial value $X_0$. Let t\mapsto X_t(x) denote the unique solution with $X_0(x) = x$ for $x\in\mathbb{R}$. The Markov and time homogeneous properties follow from the fact that $X_{t+s}(x) = X_t(X_s(x))$ for $x,t\in[0,\infty)$ and $x\in S$. That is, the state at time $t+s$ depends only on the state at time $s$ and the time increment $t$. The Feller properties follow from the continuity of $t\mapsto X_t(x)$ and the continuity of $x\mapsto X_t(x)$. The latter is the continuous dependence on the initial value, guaranteed by the assumption on $g$. Note that the transition operator is given by $P_t f(x) = f[X_t (x)]$ for a measurable function $f:S\to\mathbb{R}$ and $x\in S$.
</details>
</MathBox>

The deterministic process $\mathrm{d}X_t = g(X_t)\mathrm{d}t$ can be turned into a diffusion processs, with Markov property, by adding a stochastic term related to a Wiener process (Brownian motion).


## Processes with independent, stationary increments

<MathBox title='Independent and stationary increments' boxType='definition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process adapted to $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$. Then for all $s,t\in T$ with $s\leq t$, the process $\mathbf{X}$ is said to have
1. *Independent increments* if $X_t - X_s$ is independent of $\mathcal{F}_s$
2. *Stationary increments* if $X_t - X_s$ has the same distribution as $X_{t-s} - X_0$

Processes with independent and stationary increments are random walk processes. In continuous time, such processes are known as Lévy processes, which also have a third property

3. *Continuity in probability*: for any $\epsilon > 0$ and $t\geq 0$ then $\lim_{h\to 0} \mathbb{P}(|X_{t+h} - X_t|>\epsilon) = 0$
</MathBox>

Stationary increments means that the probability distribution of any increment $X_t - X_s$ depends only the length $t - s$ of the time interval. Several stochastic processes are characterized by specific distributions of their stationary increments
- Wiener process: $X_t - X_s$ has a normal distribution with $\mathbb{E}(X_t - X_s) = 0$ and $\mathrm{Var}(X_t - X_s) = t - s$
- Poisson process:  $X_t - X_s$ has a poisson distribution with $\mathbb{E}(X_t - X_s) = \gamma(t - s)$ where $\gamma > 0$ is the intensity of the process.
- Cauchy process: $X_t - X_s$ has a Cauchy distribution with density $f(x, t) = \frac{1}{\pi}\frac{t}{x^2 + t^2}$

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process with independent, stationary increments, and let $Q$ denote the distribution of $X_t - X_0$. Then

$$
  Q_s * Q_t = Q_{s+t},\; s,t\in T
$$

<details>
<summary>Proof</summary>

Note that $Q_s$ is the distribution of $X_s - X_0$, and by the stationary property, $Q_t$ is the distribution of $X_{s+t} - X_s$. By the independence property, $X_s - X_0$ and $X_{s+t} - X_s$ are independent. Hence $Q_s * Q_t$ is the distribution of $[X_s - X_0] + [X_{s+t} - X_{s}] = X_{s+t} - X_0$. By definition, this variable has distribution $Q_{s+t}$.
</details>
</MathBox>

The collection of increment distributions $\mathbf{Q} = \{Q_t\}_{t\in T}$ forms a semi-group with convolution as the operator.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a Lévy process, and let

$$
  m(t) = \mathbb{E}(X_t) \quad v(t) = \mathrm{var}(X_t)
$$

1. If $\mu_0 = \mathbb{E}(X_0) \in\mathbb{R}$ and $\mu_1 = \mathbb{E}(X_1)\in\mathbb{R}$ then $m(t) = \mu_0 + (\mu_1 + \mu_0)t$
2. If in addition $\sigma_0^2 = \mathrm{var}(X_0)\in (0,\infty)$ and $\sigma_1^2 = \mathrm{var}(X_1)\in (0, \infty)$ then $v(t) = \sigma_0^2 + (\sigma_1^2 + \sigma_0^2)t$

<details>
<summary>Proof</summary>

Let $m_0 (t) = \mathbb{E}(X_t - X_0) = m(t) - \mu_0$ and $v_0 (t) = \mathrm{var}(X_t - X_0) = v(t) - \sigma_0^2$ denote the mean and variance functions for the centered process $\{ X_t - X_0 \}_{t\in T}$. Let $s,t\in T$

1. From the additive property of expected value and the stationary property
$$
\begin{align*}
  m_0 (t + s) &= \mathbb{E}(X_{t+s} - X_0) \\
  &= \mathbb{E}[(X_{t+s} - X_s) + (X_s - X_0)] \\
  &= \mathbb{E}(X_{t+s} - X_s) + \mathbb{E}(X_s - X_0) \\
  &= m_0 (t) + m_0 (s)
\end{align*}
$$

1. From the additive property of variance for independent variables and the stationary property
$$
\begin{align*}
  v_0 (t + s) &= \mathrm{var}(X_{t+s} - X_0) \\
  &= \mathrm{var}[(X_{t+s} - X_s) + (X_s - X_0)] \\
  &= \mathrm{var}(X_{t+s} - X_s) + \mathrm{var}(X_s - X_0) \\
  &= v_0 (t) + v_0 (s)
\end{align*}
$$

This shows that $m_0$ and $v_0$ satisfy the Cauchy equation. By the Lévy properties there exists $a\in\mathbb{R}$ and $b^2\in(0,\infty)$ such that $m_0(t) = at$ and $v_0(t) = b^2 t$. Substituting $t=1$ gives $a = \mu_1 - \mu_0$ and $b^2 = \sigma_1^2 - \sigma_0^2$ producing the desired result.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
A discrete time process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ has independent increments if and only if there exists a sequence of independent, real-valued random variables $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+} such that

$$
  X_n = \sum_{i=0}^n U_i
$$

In addition, $\mathbf{X}$ has stationary increments if and only if $(U_n)_{n\in\mathbb{N}}$ are indentically distributed.

<details>
<summary>Proof</summary>

Suppose first that $\mathbf{U}$ is a sequence of independent, real-valued random variables, and define $X_n = \sum_{i=0}^n U_i$ for $n\in\mathbb{N}$. Note that $\mathcal{F}_n = \sigma\{X_i\}_{i=0}^n = \sigma\{U_i\}_{i=0}^n$. If $k, n\in\mathbb{N}$ with $k\leq n$, then $X_n - X_k = \sum_{i=k+1}^n U_i$ which is independent of $\mathcal{F}_k$ by the independence assumption on $\mathbf{U}$. Hence $\mathbf{X}$ has independent increments. Suppose in addition that  $(U_n)_{n\in\mathbb{N}}$ are identically distributed. Then the increment $X_n - X_k$ above has the same distribution as $\sum_{i=1}^{n-k} U_i = X_{n-k} - X_0$. Hence $\mathbf{X}$ has stationary increments.

Conversely, suppose that $\mathbf{X}$ has independent increments. Let $U_0 = X_0$ and $U_n = X_n - X_{n-1}$ for $n\in\mathbb{N}$ such that $X_n = \sum_{i=0}^n U_i$ and $\mathcal{F}_n = \sigma\{X_i\}_{i=0}^n = \sigma\{U_i\}_{i=0}^n$. Since $\mathbf{X}$ has independent increments, $U_n$ is indepedent of $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$ making $(U_n)_{n\in\mathbb{N}_+}$ mutually independent. If in addition, $\mathbf{X}$ has stationary increments, $U_n = X_n - X_{n-1}$ has the same distribution as $X_1 - X_0 = U_1$ for $n\in\mathbb{N}_+$. Hence $(U_n)_{n\in\mathbb{N}}$ are identically distributed. 
</details>
</MathBox>

### Relation to Markov processes

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process with independent, stationary increments, and let $Q$ denote the distribution of $X_t - X_0$. Then $\mathbf{X}$ is a time-homogeneous Markov process with transition operator

$$
  P_t f(x) = \int_S f(x+y)Q_t (\mathrm{d}y),\; f\in\mathcal{B}
$$

<details>
<summary>Proof</summary>

Since $X_{s+t} - X_{s}$ is independent of $\mathcal{F}_s$ it follows that

$$
  \mathbb{E}[f(X_{s+t})|\mathcal{F}_s] = \mathbb{E}[f(X_{s+t} - X_s + X_s)|\mathcal{F}_s] = \mathbb{E}[f(X_{s+t})|X_s]
$$

By the stationary property

$$
  \mathbb{E}[f(X_{s+t}|X_s = x)] = \int_S f(x+y)Q_t(\mathrm{d}y)\; x\in S
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that for positive $t\in T$ is a process with independent, the distribution $Q_t$ has probability density function $g_t$ with respect to the reference measure $\lambda$. Then the transition density is

$$
  p_t (x,y) = g_t (y - x),\; f\in\mathcal{B}
$$

By the property of $Q_t$, it follows that $g_s * g_t = g_{s+t}$.
</MathBox>

<MathBox title='Lévy processes are Feller Markov' boxType='proposition'>
If $Q_t \xrightarrow{t\downarrow 0} Q_0$ (Lévy property) then $\mathbf{X}$ is a Feller Markov process.
</MathBox>

#### Random walk

<MathBox title='Markov random walk' boxType='definition'>
Suppose that $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ is a sequence of indepedent, real-valued random variables, with $(U_n)_{n\in\mathbb{N}}$ identically distributed with common distribution $Q$. Then the partial sum process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ associated with $\mathbf{U}$ is a time homogeneous Markov process with one-step transition kernel

$$
  P(x, A) = Q(A - x),\; x\in S, A\in\mathcal{S}
$$

More generally, the $n$-step transition kernel is 

$$
  P^n (x, A) = Q^{*n}(A - x)
$$

This Markov process is known as a random walk where $U_n$ represents the distance on the real in which the process moves at time $n$. If $Q$ has probability density function $g$ with respect to the reference measure $\lambda$, the one-step transition density is

$$
  p(x, y) = g(y - x),\; x,y\in S
$$
</MathBox>

<MathBox title='' boxType='proposition'>
For $t\in[0,\infty)$, let $g_t$ denoted the probability density function of the Poisson distribution with parameter $t$, i.e.

$$
  g_t (n) = e^{-1} \frac{t^n}{n!},\; n\in\mathbb{N}
$$

Let $p_t(x,y) = g_t (y - x)$ for $x,y\in\mathbb{N}$. Then $\{p_t\}_{t\in[0,\infty)}$ is the collection of transition densities for a Feller semigroup on $\mathbb{N}$.

<details>
<summary>Proof</summary>

We need to show that $\{g_t\}_{t\in[0,\infty)}$ satisfies the semi-group property, and that the continuity result holds. By the properties of the Poisson distribution, if $U, V$ are independent Poisson variables with parameters $s,t\in[0,\infty)$, respectively, then $U+V$ has a Poisson distribution with parameter $s + t$. Hence $g_s * g_t = g_{s+t}$. Moreover $g_t \xrightarrow{t\downarrow 0} g_0$. 
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
For $t\in[0,\infty)$, let $g_t$ denoted the probability density function of the normal distribution with mean $0$ and variance $t$, i.e.

$$
  g_t(z) = \frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2t}},\; z\in\mathbb{R}
$$

and let $p_t(x,y) = g_t (y - x)$ for $x,y\in\mathbb{R}$. Then $\{p_t\}_{t\in[0,\infty)}$ is the collection of transition densities for a Feller semigroup on $\mathbb{N}$.

<details>
<summary>Proof</summary>

We need to show that $\{g_t\}_{t\in[0,\infty)}$ satisfies the semi-group property, and that the continuity result holds. By the properties of the normal distribution, if $U, V$ are independent normal variables with mean $0$ and variances $s,t\in(0,\infty)$ respectively, then $U+V$ is normally distributed with mean $0$ and parameter $s + t$. Hence $g_s * g_t = g_{s+t}$. Moreover, the normal distribution with variance $t$ converges to a point mass at $0$ as $t\downarrow 0$. 
</details>
</MathBox>

## Martingale

A martingale is a stochastic process for which the conditional expectation of the next value is equal to the present value.

<MathBox title='Martingale' boxType='definition'>
A stochastic process $\mathbf{X}$ is a *martingale* with respect to a filtration $\mathscr{F}$ if $\mathbb{E}(X_t|\mathcal{F}_s) = X_s$ for all $s, t\in T$ with $s\leq t$.

If the equality in the martingale conditions does not hold, then for  for all $s, t\in T$ with $s\leq t$, the process $\mathbf{X}$ is (with respect to $\mathscr{F}$)
1. *sub-martingale* $\mathbb{E}(X_t|\mathcal{F}_s) \geq X_s$ for all $s, t\in T$ with $s\leq t$.
2. *super-martingale* $\mathbb{E}(X_t|\mathcal{F}_s) \leq X_s$ for all $s, t\in T$ with $s\leq t$.

If $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is discrete, then for all $n\in\mathbb{N}$ the process $\mathbf{X}$ is (with respect to $\mathscr{F}$)
1. martingale if and only if $\mathbb{E}(X_{n+1}|\mathcal{F}_n) = X_n$
2. sub-martingale if and only if $\mathbb{E}(X_{n+1}|\mathcal{F}_n) \geq X_n$
3. super-martingale if and only if $\mathbb{E}(X_{n+1}|\mathcal{F}_n) \leq X_n$

<details>
<summary>Details</summary>

To show the bicondationality in the discrete case, suppose that $k,n\in\mathbb{N}$ with $k< n$. Then $k\leq n - 1$ so $\mathcal{F}_k\subseteq\mathcal{F}_{n-1}$ and hence

$$
\begin{align*}
  \mathbb{E}(X_n | \mathcal{F}_k) &= \mathbb{E}[\mathbb{E}(X_n|\mathcal{F}_{n-1})] \\
  &= \mathbb{E}(X_{n-1}|\mathcal{F}_k)
\end{align*}
$$
</details>
</MathBox>

In gambling terms, martingale, sub-martingale and super-martingale processes are abstractions of fair, favourable or unfair games (from the gambler's perspective).

<MathBox title='Martingales are preserved under coarser filtrations' boxType='proposition'>
Suppose that the stochastic process $\mathbf{X}$ is adapted to the filtration $\mathscr{F}$, and $\mathscr{F}\subseteq\mathscr{G}$, i.e. $\mathscr{G}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a (sub/super-)martingale relative to $\mathscr{G}$, then $\mathbf{X}$ is a (sub/super-)martingale process relative to $\mathscr{F}$.

In particular, if $\mathbf{X}$ is a (sub/super-)martingale relative to some filtration, then $\mathbf{X}$ is also a (sub/super-)martingale relative to the natural filtration $\mathcal{F}^0$

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s\leq t$. Note that $\mathbf{X}$ is adapted to $\mathscr{G}$, since $\mathbf{X}$ is adapted to $\mathscr{F}$ and $\mathscr{F}\subseteq\mathscr{G}$. Appyling the tower and monotonicity of conditional expected value we have that

1. If $\mathbf{X}$ is a martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t|\mathcal{G}_s)|\mathcal{F}_s] \\
  &= \mathbb{E}(X_s|\mathcal{F_s}) = X_s
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t|\mathcal{G}_s)|\mathcal{F}_s] \\
  &\geq \mathbb{E}(X_s|\mathcal{F_s}) = X_s
\end{align*}
$$

3. If $\mathbf{X}$ is a super-martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t|\mathcal{G}_s)|\mathcal{F}_s] \\
  &\leq \mathbb{E}(X_s|\mathcal{F_s}) = X_s
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Linear properties of martingales' boxType='proposition'>
For the processes $\mathbf{X} = \{X_t \}_{t\in T}$ and $\mathbf{Y} = \{Y\}_{t\in T}$, let $\mathbf{X} + \mathbf{Y} = \{ X_t + Y_t \}_{t\in T}$.

1. If $\mathbf{X}$ and $\mathbf{Y}$ are (sub/super-)martingales with respect to $\mathscr{F}$ then $\mathbf{X}+\mathbf{Y}$ is a (sub/super-)martingale with respect to $\mathscr{F}$.

For the constant $c\in\mathbb{R}$, let $c\mathbf{X} = \{ cX_t \}_{t\in T}$.

2. If $\mathbf{X}$ is a martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is also a martingale with respect to $\mathscr{F}$.
3. If $\mathbf{X}$ is a sub-martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is a sub-martingale if $c > 0$, a super-martingale if $c < 0$, and a martingale if $c = 0$.
4. If $\mathbf{X}$ is a super-martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is a super-martingale if $c > 0$, a sub-martingale if $c < 0$, and a martingale if $c = 0$.

The linearity properties implies that the collection of martingales with respect to a fixed filtration $\mathscr{F}$ forms a vector space.

<details>
<summary>Proof</summary>

The additive property (1) follows from the additive property of conditional expectation. Note that $\mathbb{E}(|X_t + Y_t|)\leq\mathbb{E}(|X_t|) + \mathbb{E}(|Y_t|) < \infty$ for $t\in T$. For $s, t\in T$ with $s\leq t$ we have

$$
  \mathbb{E}(X_t + Y_t | \mathcal{F}_s) = \mathbb{E}(X_t|\mathcal{F}_s) + \mathbb{E}(Y_t |\mathcal{F}_s)
$$

The scalar properties (2, 3, 4) follows from the scalar property of conditional expectation. Note that $\mathbb{E}(|cX_t|) = |c|\mathbb{E}(|X_t|)\leq\infty$. For $s, t\in T$ with $s\leq t$ we have

$$
  \mathbb{E}(cX_t | \mathcal{F}_s) = c\mathbb{E}(X_t | \mathcal{F}_s)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that the process $\mathbf{X}$ takes values in an interval $S\subseteq\mathbb{R}$ and that $g:S\to\mathbb{R}$ is convex with $\mathbb{E}[|g(X_t)|]< \infty$ for $t\in T$. Then $g(\mathbf{X}) = \{g(X_t)\}_{t\in T}$ is a sub-martingale with respect to $\mathscr{F}$ if either

1. $\mathbf{X}$ is a martingale.
2. $\mathbf{X}$ is a sub-martingale and $g$ is also increasing.

Since $x \mapsto |x|^k$ is convex on $\mathbb{R}$ for $k\in[1,\infty)$, it follows that $|\mathbf{X}|^k = \{|X_t|^k \}_{t\in T}$ is a sub-martingale if $\mathbf{X}$ is a martingale and $\mathbb{E}\left(|X_t|^k \right)< \infty$ for $t\in T$. 

In particular, if $\mathbf{X}$ is a sub-martingale, then $\mathbf{X}^+ = \{X_t^+\}_{t\in T}$ is also a sub-martingale since $x\mapsto x^+ = \max\{x, 0\}$ is increasing and convex on $\mathbb{R}$.

<details>
<summary>Proof</summary>

Let $s,t\in T$ with $s\leq t$. Since $g$ is convex, it follows from Jensen's inequlity that

$$
  \mathbb{E}[g(X_t)|\mathcal{F}_s] \geq g[\mathbb{E}(X_t|\mathcal{F}_s)]
$$

1. Since $\mathbf{X}$ is a martingale, then $\mathbb{E}(X_t | \mathscr{F}_s) = X_s$ and substituting into the inequality above sbows that $g(\mathbf{X})$ is sub-martingale

$$
  \mathbb{E}[g(X_t)|\mathcal{F_s}] \geq g(X_s) 
$$

2. Since $\mathbf{X}$ is a sub-martingale, then $\mathbb{E}(X_t |\mathcal{F}_t) \geq X_s$. Since $g$ is also increasing, then $g[\mathbb{E}(X_t|\mathcal{F}_s)]\geq g(X_s)$. Substituting into the inequlity above shows that $g(\mathbf{X})$ is a sub-martingale

$$
  \mathbb{E}[g(X_t)|\mathcal{F}_s] \geq g(X_s)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in[0,\infty)}$ is a continuous-time process adapted to $\mathscr{F} = \{ \mathcal{F}_t\}_{t\in[0,\infty)}$. Let $\{ t_n\}_{n\in\mathbb{N}}\subset [0,\infty)$ be a strictly increasing sequence of time points with $t_0$ and define $Y_n = X_{t_n}$ nad $\mathcal{G}_n = \mathcal{F}_{t_n}$ for $n\in\mathbb{N}$. If $\mathbf{X}$ is a (sub/super)-martingale with respect to $\mathscr{F}$, then $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a (sub/super-martingale) with respect to $\mathscr{G}$.

<details>
<summary>Proof</summary>

Since $\{t_n\}_{n\in\mathbb{N}}$ is increasing, $\mathscr{G}$ is a discrete-time filtration. Next, $\mathbb{E}(|Y_n|) = \mathbb{E}(|X_{t_n}|) < \infty$. Finally, suppose that $\mathbf{X}$ is a martingale and $n, k\in \mathbb{N}$ with $k< n$. Then $t_k < t_n$ so

$$
  \mathbb{E}(Y_n | \mathcal{G}_k) = \mathbb{E}(X_{t_n} | \mathcal{F}_{t_k}) = X_{t_k} = Y_k
$$

Hence $\mathbf{Y}$ is also a martingale. The proof is analogous for sub- and super-martingales, but with inequalities replacing the second equality above.
</details>
</MathBox>

### Martingale transform

<MathBox title='Martingale transform' boxType='proposition'>
Suppose that the discrete process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is adapted to the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ and that $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ is predictable relative to $\mathscr{F}$, i.e. $Y_n$ is measurable to $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$. The transform of $\mathbf{X}$ by $\mathbf{Y}$ is the process $\mathbf{Y}\cdot\mathbf{X}$ defined by

$$
  (\mathbf{Y}\cdot\mathbf{X})_n = X_0 + \sum_{k=1}^n Y_k (X_k - X_{k-1})
$$

1. If $\mathbf{X}$ is a martingale relative to $\mathscr{F}$ then $\mathbf{Y}\cdot\mathbf{X}$ is also a martingale relative to $\mathscr{F}$.
2. If $\mathbf{X}$ is sub-martingale relative to $\mathscr{F}$ and $\mathbf{Y}$ is non-negative, then $\mathbf{Y}\cdot\mathbf{X}$ is also a sub-martingale relative to $\mathscr{F}$.
3. If $\mathbf{X}$ is a super-martingale relative to $\mathscr{F}$ and $\mathbf{Y}$ is non-negative, then $\mathbf{Y}\cdot\mathbf{X}$ is also a super-martingale relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Suppose that $|Y_n|\leq c\in(0,\infty)$ for $n\in\mathbb{N}$, then

$$
\begin{align*}
  \mathbb{E}\left[|(\mathbf{Y}\cdot\mathbf{X})_n| \right] \leq \mathbb{E}(|X_0|) + c\sum_{k=1}^n \left[\mathbb{E}(|X_k|) + \mathbb{E}(|X_{k+1}|) \right] \\
  &< \infty
\end{align*}
$$

Since $(\mathbf{Y}\cdot\mathbf{X})_n$, $Y_{n+1}$ and $X$ are measurable with respect to $\mathcal{F}_n$ for $n\in\mathbb{N}$, it follows that

$$
\begin{align*}
  \mathbb{E}\left[ (\mathbf{Y}\cdot\mathbf{X})_{n+1} |\mathcal{F}_{n} \right] &= \mathbb{E}\left[(\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}(X_{n+1} - X_n)|\mathcal{F}_n \right] \\
  &= (\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}\mathbb{E}(X_{n+1} - X_n |\mathcal{F}_n) \\
  &= (\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}\left[\mathbb{E}(X_{n+1}|\mathcal{F}_n) - X_n \right]
\end{align*}
$$
</details>
</MathBox>

Let $\{X_n\}_{n\geq 0}$ be a martingale relative to a filtration $\mathscr{F}_n$. The martingale difference sequence associated with the martingale $X_n$ is defined as

$$
  \xi_n = X_n - X_{n-1}
$$

A predictable sequence $\{Z_n\}_{n\geq 1}$ relative to the filtration $\mathscr{F}_n$ is a sequence of random variables such that for every $n$ the random variable is measurable relative to $\mathscr{F}_{n-1}$. The martingale transform $\left\{ (Z \cdot X)_n \right\}_{n\geq 0}$ is defined by

$$
  E\left( X_n + Y_{n+1} | \mathscr{F}_n \right) = X_0 + \sum_{j=1}^n Z_j \xi_j
$$

Assume that the predictable sequence $\{Z_n\}_{n\geq 1}$ consists of bounded random variables. Then the martingale transform $\left\{ (Z \cdot X)_n \right\}_{n\geq 0}$ is itself a martingale

$$
\begin{align*}
  E\left( (Z\cdot X)_{n+1} | \mathscr{F}_n \right) &= (Z\cdot X)_n + E\left( Z_{n+1} \xi_{n+1} | \mathscr{F}_n \right) \\
  &= (Z\cdot X)_n + Z_{n+1}E\left( \xi_{n+1} | \mathscr{F}_n \right) \\
  &= (Z\cdot X)_n
\end{align*}
$$

Let $(Z_j)_{j\geq 0}$ be a predictable sequence of bounded nonnegative random variables. Then the submartingale transform $\{ Z \cdot X \}_{n\geq 0}$ (respectively, supermartingale) is defined by

$$
  (Z \cdot X)_n = Z_0 X_0 + \sum_{k=1}^n Z_k \xi_k
$$

which is also a submartingale. If $0 \leq Z_n \leq 1$ for each $n \geq 0$, then

$$
  E(Z \cdot X)_n \leq \mathrm{E}[X_n]
$$

To show that $(Z\cdot X)_n$ is a submartingale, if suffices to verify that the differences $Z_j \xi_j$ constitute a submartingale difference sequence

$$
\begin{gather*}
  E\left( Z_j \xi_j | \mathscr{F}_{j-1} \right) = Z_j E\left( \xi_j | \mathscr{F}_{j-1} \right) \\
  \implies E\left( Z_j \xi_j \right) \leq \mathrm{E}\left[ \xi_j \right]
\end{gather*}
$$

### Doob decomposition

<MathBox title='Doob decomposition theorem' boxType='theorem'>
Suppose that the discrete process $\mathbf{X} = \{ X_n\}_{n\in\mathbb{N}}$ is adapted to the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$. Then there is a unique decomposition $\mathbf{X} = \mathbf{Y} + \mathbf{Z}$ where $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$ and $\mathbf{Z} = \{Z_n\}_{n\in\mathbb{N}}$ is predictable relative to $\mathscr{F}$.

1. If $\mathbf{X}$ is a sub-martingale relative to $\mathscr{F}$, then $\mathbf{Z}$ is increasing.
2. If $\mathbf{X}$ is a super-martingale relative to $\mathscr{F}$, then $\mathbf{Z}$ is decreasing.

<details>
<summary>Proof</summary>

Define $Z_0 = 0$ and for $n\in\mathbb{N}_+$

$$
  Z_n = \sum_{k=1}^n \left[\mathbb{E}(X_k | \mathcal{F}_{k-1} - X_{k-1} \right]
$$

Then $Z_n$ is measurable with respect to $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$, so $\mathbf{Z}$ is predictable with respect to $\mathscr{F}$. Define for $n\in\mathbb{N}_+$

$$
\begin{align*}
  Y_n &= X_n - Z_n \\
  &= X_n - \sum_{k=1}^n \left[\mathbb{E}(X_k | \mathcal{F}_{k-1} - X_{k-1} \right]
\end{align*}
$$

Then $\mathbb{E}(|Y_n|) < \infty$ and trivially $X_n = Y_n + Z_n$ for $n\in\mathbb{N}$. Next we show that $\mathbf{Y}$ is martingale

$$
  \mathbb{E}(Y_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_{n+1}|\mathcal{F}_n) - Z_{n+1} \\
  &= \mathbb{E}(X_{n+1}|\mathcal{F}_n) - \sum_{k=1}^{n+1} \left[\mathbb{E}(X_k | \mathcal{F}_{k-1} - X_{k-1} \right] \\
  &= X_n - \sum_{k=1}^n \left[\mathbb{E}(X_k |\mathcal{F}_{k-1}) - X_{k-1} \right] = Y_n
$$

It remains to prove the uniqueness of the decomposition. Suppose that $\mathbf{X}$ has the decomposition in terms of $\mathbf{Y}$ and $\mathbf{Z}$ given in the theorem. Since $\mathbf{Y}$ is a martingale and $\mathbf{Z}$ is predictable

$$
\begin{align*}
  \mathbb{E}(X_n - X_{n-1} | \mathcal{F}_{n-1}) &= \mathbb{E}(Y_n | \mathcal{F}_{n-1}) - \E(Y_{n-1} | \mathcal{F}_{n-1}) + \E(Z_n | \mathcal{F}_{n-1}) - \E(Z_{n-1} | \mathcal{F}_{n-1}) \\ 
  &= Y_{n-1} - Y_{n-1} + Z_n - Z_{n-1} \\
  &= Z_n - Z_{n-1}, \quad n \in \mathbb{N}_+
\end{align*}
$$

Since $Z_0 = 0$, then $\mathbf{X}$ uniquely determines $\mathbf{Z}$. Finally, since $Y_n = X_n - Z_n$ for $n\in\mathbb{N}$, then $\mathbf{X}$ also uniquely determines $\mathbf{Z}$.

1. If $\mathbf{X}$ is a sub-martingale, then $\mathbb{E}(X_n|\mathcal{F}_{n-1}) - X_{n-1} \geq 0$ for $n\in\mathbb{N}_+$ so $\mathbf{Z}$ is increasing.
2. If $\mathbf{X}$ is a super-martingale, then $\mathbb{E}(X_n|\mathcal{F}_{n-1}) - X_{n-1} \leq 0$ for $n\in\mathbb{N}_+$ so $\mathbf{Z}$ is decreasing.
</details>
</MathBox>

### Doob's optional sampling theorem

Doob's theorem states that stopping a martingale at random time $\tau$ does not alter the martingale property, provided the decision about when to stop is solely based on information available up to $\tau$. 

<MathBox title="Doob's optional sampling theorem" boxType='theorem'>
Let $\{X_n\}_{n\geq \mathbb{Z}^+}$ be a martingale relative to a filtration $\mathscr{F}_n$ and let $\tau$ be a stopping time. Then the stopped sequence $\{ X_{\tau \land n} \}_{n\geq 0}$ is a martingale. Consequently, for any $n \in \mathbb{N}$

$$
  \mathrm{E}\left[ X_{\tau \land n} \right] = \mathrm{E}\left[ X_0 \right]
$$
</MathBox>

<details>
<summary>Proof</summary> 

The sequence $\{ X_{\tau \land n} \}_{n\geq 0}$ may be represented as a transform of the sequence $\{X_n\}_{n\geq \mathbb{Z}^+}$

$$
\begin{gather*}
  X_{\tau \land n} = (Z\cdot X)_n \\
  Z_n = \begin{cases} 1, &\quad \tau \geq n \\ 0, &\quad \tau < n \end{cases}
\end{gather*}
$$

The transform is easily verified

$$
\begin{align*}
  (Z\cdot X)_n &= X_0 + \sum_{j=1}^n Z_j \left( X_j - X_{j - 1} \right) \\
  &= X_0 + \sum_{j=1}^{\tau \land n} \left( X_j - X_{j - 1} \right) \\
  &= X_{\tau \land n}
\end{align*}
$$
</details>

<MathBox title='Wald identities' boxType='proposition'>
Let $S_n = \sum_{i=1}^n \xi_i$, then the following identities hold: 
- First identity: if $\mathrm{E}\left[ |\xi_i | \right] < \infty$ and $\mathrm{E}\left[ \tau \right] < \infty$ then $ \mathrm{E}[|S_\tau|] < \infty$ and  
$$
  \mathrm{E}[S_\tau] = \mathrm{E}[\tau] \cdot \mathrm{E}[\xi_k]
$$
- Second identity: if $\mathrm{E}\left[ \xi_i \right] = 0$ and $\sigma^2 = \mathrm{E}\left[ \xi_i^2 \right] < \infty$ then 
$$
  \mathrm{E}[S_\tau^2] = \sigma^2 \mathrm{E}[\tau]
$$
- Third identity: assume that $\mathrm{E}\left[ e^{\theta \xi_1} \right] = e^{-\psi(\theta)} < \infty$, then for every bounded stopping time
$$
  \mathrm{E}\left[ \theta S_\tau - \tau \psi(\theta) \right] = 1
$$
</MathBox>

## Examples

### Constant sequence

<MathBox title='Martingale conditions for partial sums' boxType='definition'>
Suppose that $X$ is a random variable that is measurable with respect to $\mathcal{F}_0\in\mathscr{F}$, and with $\mathbb{E}(|X|) < \infty$. Let $X_t = X$ for $t\in T$. Then the constant sequence process $\mathbf{X} = \{ X_t \}_T$ is a martingale with respect to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Since $X$ is measurable with respect to $\mathcal{F}_0$, it is measurable with respect to $\mathcal{F}_t$ for all $t\in T$. Thus $\mathbb{X}$ is adapted to $\mathscr{F}$. If $s,t\in T$ with $s\leq t$, then

$$
  \mathbb{E}(X_t |\mathcal{F}_s) = \mathbb{E}(X | \mathcal{F}_s) = X = X_s
$$
</details>
</MathBox>

### Lévy process

<MathBox title='Martingale conditions for processes with independent increments' boxType='definition'>
Suppose that the continuous process $\mathbf{X} = \{X_t\}_{t\in [0,\infty]}$ has independent increments, and let $m(t) = \mathbb{E}(X_t)$ for $t\in T$. Then $\mathbf{X}$ is
1. Martingale if $m$ is constant.
2. Sub-martingale if $m$ is increasing.
3. Super-martingale if $m$ is decreasing.

<details>
<summary>Proof</summary>

Suppose that $s,t\in[0,\infty)$ with $s< t$. Then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F}_s) &= \mathbb{E}\left[X_s + (X_t - X_s) |\mathcal{F}_s \right] \\
  &= \mathbb{E}(X_s |\mathcal{F}_s ) + \mathbb{E}(X_t - X_s |\mathcal{F}_s)
\end{align*}
$$

Since $X_s$ is measurable to $\mathcal{F}_s$ and $X_t - X_s$ is independent of $\mathcal{F}_s$, we obtain

$$
\begin{align*}
   \mathbb{E}(X_t | \mathcal{F}_s) &= \mathbb{E}(X_s |\mathcal{F}_s ) + \mathbb{E}(X_t - X_s |\mathcal{F}_s) \\
   &= X_s + \mathbb{E}(X_t - X_s) = X_s + m(t) - m(s)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Second moment martingale for processes with independent increments' boxType='definition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has independent increments with constant mean function, and with $\mathrm{var}(X_t) < \infty$ for $t\in T$. Let 

$$
  Y_t = X_t^2 - \mathrm{var}(X_t)\quad t\in T
$$

Then $\mathbf{Y} = \{Y_t\}$ is a martingale.

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s< t$. Note that $\mathbb{E}(Y_t|\mathcal{F}_s) = \mathbb{E}(X_t^2 | \mathcal{F}_s) -\mathrm{var}(X_t)$. Rewriting $X_t^2$ as

$$
\begin{align*}
  X_t^2 &= [(X_t - X_s) + X_s]^2 \\
  &= (X_t - X_s)^2 + 2(X_t - X_s)X_s + X_s^2 
\end{align*}
$$

Since $X_t - X_s$ is independent of $\mathcal{F}_s$, $X_s$ is measurable with respect to $\mathcal{F}_s$ and $\mathbb{E}(X_t - X_s) = 0$, it follows that

$$
\begin{align*}
  \mathbb{E}(X_t^2 | \mathcal{F}_s) &= \mathbb{E}[(X_t - X_s)^2] + 2X_s \mathbb{E}(X_t - X_s) + X_s^2 \\
  &= \mathbb{E}[(X_t - X-s)^2] + X_s^2
\end{align*}
$$

Since $X_t - X_s$ also has mean $0$

$$
\begin{align*}
  \mathrm{var}(X_t) &= \mathrm{var}[(X_t - X_s) + X_s] \\
  &= \mathrm{var}(X_s) + \mathrm{var}(X_t - X_s)^2 \\
  &= \mathrm{var}(X_s) + \mathbb{E}[(X_t - X_s)^2]
\end{align*}
$$

Combining the results gives

$$
  \mathbb{E}(Y_t | \mathcal{F}_s) = X_s^2 - \mathrm{var}(X_s) = Y_s
$$
</details>
</MathBox>

<MathBox title='Martingale conditions for random walks' boxType='definition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has stationary, independent increments, and let $a = \mathbb{E}(X_1 - X_0)$. Then $\mathbf{X}$ is
1. Martingale if $a=0$.
2. Sub-martingale if $a\geq 0$.
3. Super-martingale if $a\leq 0$.

<details>
<summary>Proof</summary>

Note that for a process with stationary, independent increments, the mean function reduces to $m(t) = \mathbb{E}(X_0) + at$ for $t\in T$. Follwing the same argument as for processes with independent increments, we get

$$
  \mathbb{E}(X_t | \mathcal{F}_s) = X_s + a(t - s)
$$
</details>
</MathBox>

<MathBox title='Second moment martingale for random walks' boxType='definition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has independent increments with $\mathbb{E}(X_0) = \mathbb{E}(X_1)$ and $b^2 = \mathbb{E}\left(X_1^2\right) < \infty$. Let

$$
  Y_t = X_t^2 - \mathrm{var}(X_0) - b^2 t,\quad t\in T
$$

Then $\mathbf{Y} = \{Y_t\}$ is a martingale.

<details>
<summary>Proof</summary>

Since $\mathbb{E}(X_0) = \mathbb{E}(X_1)$, then $\mathbf{X}$ has constant mean function. Note that $\mathrm{var}(X_t) = \mathrm{var}(X_0) + b^2 t$. Following the same argument as for second order martingales for processes with independent increments, we obtain

$$
\begin{align*}
  \mathbb{E}(Y_s|\mathcal{F}_s) &= X_s - \mathrm{var}(X_s) \\
  &= X_s - \mathrm{var}(X_0) - b^2 t = Y_s
\end{align*}
$$
</details>
</MathBox>

#### Partial sums

In discrete time, a process with independent increments reduces to a partial sum process.

<MathBox title='Martingale conditions for partial sums' boxType='definition'>
Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is a sequence of random variables with $\mathbb{E}(|V_n|) < \infty$, and let

$$
  X_n = \sum_{k=0}^n V_n
$$

Then $\mathbf{X} = \{X_n\}$ is a partial sum process associated with $\mathbf{V}$. For $n\in\mathbb{N}$, the process $\mathbf{X}$ is called
1. sub-martingale if $\mathbb{E}(V_n)\geq 0$
2. super-martingale if $\mathbb{E}(V_n)\leq 0$
3. martingale if $\mathbb{E}(V_n) = 0$

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}} = \sigma\{V_i\}_{i=0}^{n\in\mathbb{N}}$. Note first that

$$
  \mathbb{E}(|X_n|) \leq \sum_{k=0}^n \mathbb{E}(|V_k|) < \infty
$$

Next

$$
\begin{align*}
  \mathbb{E}(X_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_n + V_{n+1}|\mathcal{F}_n) \\
  &= \mathbb{E}(X_n|\mathcal{F}_n) + \mathbb{E}(V_{n+1}|\mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$

The last equality holds since $X_n$ is measurable with respect to $\mathcal{F}_N$ and $V_{n+1}$ is independent of $\mathcal{F}_n$.
</details>
</MathBox>

<MathBox title='Second moment martingale' boxType='definition'>
Let $\mathbf{X}$ be a partial sum process associated with $\mathbf{V}$. Suppose that $\mathbb{E}(V_k) = 0$ for $k\in\mathbb{N}_+$ and $\mathrm{var}(V_k) < \infty$ for $k\in\mathbb{N}$, and let 

$$
  Y_n = X_n^2 - \mathrm{var}(X_n)
$$

Then $\mathbf{Y} = \{ Y_n\}_{n\in\mathbb{N}}$ is a martingale with respect to $\mathbf{X}$.

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}}$. Since $\mathbf{V}$ is independent, note that

$$
  \mathrm{var}(X_n) = \mathrm{var}\left( \sum_{k=0}^n V_k \right) = \sum_{k=0}^n \mathrm{var}(V_k)
$$

Since $\mathbb{E}(V_k) = 0$, then $\mathrm{var}(V_k) = \mathbb{E}(V_k^2)$. In particular, $\mathbb{E}(|Y_n|) < \infty$ for $n\in\mathbb{N}$. Next

$$
\begin{align*}
  \mathbb{E}(Y_{n+1}|\mathcal{F}_n) &= \mathbb{E}[X_{n+1}^2 - \mathrm{var}(X_{n+1}|\mathcal{F}_n)] \\
  &= \mathbb{E}\left[(X_n + V_{n+1})^2 - \mathrm{var}(X_{n+1})|\mathcal{F}_n \right] \\
  &= \mathbb{E}\left[ X_n^2 + 2X_n V_{n+1} + V_{n+1}^2 - \mathrm{var}(X_{n+1})|\mathcal{F}_n \right] \\
  &= X_n^2 + 2X_n\mathbb{E}(V_{n+1}) + \mathbb{E}(V_{n+1}^2) - \mathrm{var}(X_{n+1})
\end{align*}
$$

Next

$$
\begin{align*}
  \mathbb{E}(X_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_n + V_{n+1}|\mathcal{F}_n) \\
  &= \mathbb{E}(X_n|\mathcal{F}_n) + \mathbb{E}(V_{n+1}|\mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$
</details>
</MathBox>

#### Difference sequence

<MathBox title='Martingale difference sequence' boxType='definition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a discrete process adapted to $\mathscr{F}$. Let $V_0 = X_0$ and $V_n = X_n - X_{n-1}$ for $n\in\mathbb{N}$. The process $\mathbf{V} = \{ V_n\}_{n\in\mathbb{N}}$ is the martingale difference sequence associated with $\mathbb{X}$ such that for $n\in\mathbb{N}$

$$
  X_n = \sum_{k=0}^n V_k
$$
</MathBox>

<MathBox title='Properties of martingale difference sequence' boxType='definition'>
Let $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ be a discrete process adapted to $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$. Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is the martingale difference sequence associate with $\mathbf{X}$. Then
1. $\mathbb{V}$ is adapted to $\mathscr{F}$.
2. $\mathbb{E}(V_n|\mathcal{F}_k) = 0$ for $k,n\in\mathbb{N}$ with $k< n$.
3. $\mathbb{E}(V_n) = 0$ for $n\in\mathbb{N}_+$
4. If $\mathrm{var}(X_n) < \infty$ for $n\in\mathbb{N}$, then $\mathbf{V}$ is an uncorrelated sequence and

$$
  \mathrm{var}(X_n) = \sum_{k=0}^n \mathrm{var}(V_k) = \mathrm{var}(X_0) + \sum_{k=1}^n \mathbb{E}\left(V_k^2\right)
$$

<details>
<summary>Proof</summary>

1. Obviously, $V_0 = X_0$ is measurable with respect to $\mathcal{F}_0$. For $n\in\mathbb{N}_+$, then $X_n$ and $X_{n-1}$ and thus $V_n$ are measurable with respect to $\mathcal{F}_n$. Hence $\mathbf{V}$ is adapted to $\mathscr{F}$.
2. Let $k\in\mathbb{N}$. By the martingale and adapted properties

$$
\begin{align*}
  \mathbb{E}\left( V_{k+1} | \mathcal{F}_k \right) &= \mathbb{E}(X_{k+1}|\mathcal{F}_k) - \mathbb{E}(X_k | \mathcal{F}_k) \\
  &= X_k - X_k = 0
\end{align*}
$$

By the tower property of conditional expectation

$$
  \mathbb{E}\left( V_{k+1} | \mathcal{F}_k \right) = \mathbb{E}[\mathbb{E}(V_{k+2}|\mathcal{F}_{k+1})|\mathcal{F}_k] = 0
$$

The result follows from induction.
3. Since $\mathbf{X}$ is a martingale, it has constant mean. Hence $\mathbb{E}(V_n) = \mathbb{E}(X_n) - \mathbb{E}(X_{n-1}) = 0$ for $n\in\mathbb{N}_+$.
4. Let $k,n\in\mathbb{N}$ with $k< n$. To show that $V_k$ and $V_n$ are uncorrelated, we just have to show that $\mathbb{E}(V_k V_n) = 0$ since $\mathbb{E}(V_n) = 0$. By $(3)$

$$
\begin{align*}
  \mathbb{E}(V_k V_n) &= \mathbb{E}[\mathbb{E}(V_k V_n |\mathcal{F}_k)] \\
  &= \mathbb{E}[V_k\mathbb{E}(V_n|\mathcal{F}_k)] = 0
\end{align*}
$$

To prove the formula for $\mathrm{var}(X_n)$, note that the variance of a sum of uncorrelated variables is the sum of the variances. Since $V_k$ has mean $0$, then $\mathrm{var}(V_k) = \mathbb{E}(V_k^2)$ for $k\in\mathbb{N}_+$. Hence it follows that

$$
  \mathrm{var}(X_n) = \sum_{k=0}^n \mathrm{var}(V_k) = \mathrm{var}(X_0) + \sum_{k=1}^n \mathbb{E}\left(V_k^2\right)
$$
</details>
</MathBox>