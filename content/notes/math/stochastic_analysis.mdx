---
title: 'Stochastic Analysis'
subject: 'Mathematics'
showToc: true
---

# Stochastic processes

To review, a stochastic process on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ is a collection of random variables $\mathbf{X}:=\{X_t: \Omega\to S\}_{t\in T}$, with state space $(S,\mathcal{S})$ and index space $(T,\mathcal{T})$, usually representing time. The random variable $X_t \in S$ describes the state of a system at time $t\in T$.

When representing time, the index set $T$ is usually either discrete time, $T = \mathbb{N}$, with a discrete topology or continuous time, $T = [0,\infty)$, with the usual Euclidean topology. In both cases, $T$ is given the Borel $\sigma$-algebra $\mathcal{T}$, generated by the open sets of the underlying topology. In the discrete case, this is simply the power set, $\mathcal{T} = \mathcal{P}(\mathbb{N})$, so that every subset of $T$ is measurable. The time space $(T,\mathcal{T})$ has a natural measure, which is the counting measure in the discrete case and the Lebesgue measure in the continuous case.

The state set $S$ usually has a topology and $\mathcal{S}$ is the Borel $\sigma$-algebra. A typical set of assumption is that the topology on $S$ is locally compact, Hausdorff, and with countable base (LCCB). Under these assumptions, any natural positive measure $\lambda$ on the state space $(S, \mathcal{S})$ will usually be a Borel measure satisfying $\lambda(C) < \infty$ if $C\subset S$ is compact. If $(S,\mathcal{S})$ is a discrete state space then $S$ is countable with $\mathcal{S} = \mathcal{P}(S)$. The compact sets are simply the finite sets, and the reference measure is the counting measure. If $S = \mathbb{R}^n$ for some $n\in\mathbb{N}$, then $S$ is usually gieven the Euclidean topology (which is LCCB) so that $\mathcal{S}$ is the usual Borel $\sigma$-algebra. In this case, the compact sets are the closed, bounded sets and the reference measure is the $n$-dimensional Lebesgue measure.

A filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ is an increasing collection of sub $\sigma$-algebras of $\mathcal{F}$, encoding the information available at time $t$. A stochastic process $\mathbf{X}$ is adapted to a filtration $\mathscr{F}$ if $X_t$ is measurable with respect to $\mathcal{F}_t$ for each $t\in T$. The coarsest filtration is the natural filtration $\mathscr{F}^0 = \left\{ \mathcal{F}_t^0 \;|\; t\in T \right\}$, where $\mathcal{F}_t^0 = \sigma\{ X_s \;|\; s\in T, s\leq t \}$, the $\sigma$-algebra generated by the process up to time $t\in T$. In continuous time, it is often necessary to finer $\sigma$-algebras in order to have a nice mathematical theory. In particular, we often assume that the filtration $\mathscr{F}$ is right continuous in the sense that $\mathcal{F}_{t+} = \mathcal{F}_t$ for $t\in T$ where $\mathcal{F}_{t+} = \bigcup\{ \mathcal{F}_s \;|\; s\in T, s > t \}$. This can be accomplished by taking $\mathscr{F} = \mathscr{F}_+^0$ so that $\mathcal{F} = \mathcal{F}_{t+}^0$ for $t\in T$. In this case, $\mathscr{F}$ is called the right continuous refinement of the natural filtration. We also sometimes need to assume that $\mathscr{F}$ is complete with respect to $\mathbb{P}$, such that if $A\in\mathcal{S}$ with $\mathbb{P}(A) = 0$ and $B\subseteq A$ then $B\in\mathcal{F}_0$. That is, $\mathcal{F}_0$ contains all the null events (and hence also all of the almost cerain events), and therefore so does $\mathcal{F}_t$ for all $t\in T$.

In the following discussion, $\mathcal{B}$ denotes the collection of bounded, measurable functions $f: S\to\mathbb{R}$, $\mathcal{C}$ the collection of bounded, continuous functions $f:S\to\mathbb{R}$, and $\mathcal{C}_0$ the set of continuous functions $f:S\to\mathbb{R}$ vanishing at $\infty$. The latter property means that for every $\varepsilon > 0$, there exists a compact set $K\subseteq S$ such that $|f(x)| < \varepsilon$ for $x\in K^c$. These are all vector spaces under the usual (pointwise) addition and scalar multiplication, and $\mathcal{C}_0 \subseteq\mathcal{C}\subseteq\mathcal{B}$. The norm on these spaces is the supremum norm, defined by $\lVert f \rVert = \sup\{|f(x)|:x\in S\}$ for $f\in\mathcal{B}$.

## Markov process

A Markov process is a stochastic process with the property that the probability of a future event dependens only on the present state, i.e. the future is independent of the past.

| | Countable (discrete) state space | Continuous or general state space |
|---|---|---|
| **Discrete-time** $T=\mathbb{N}$ | discrete-time Markov chain | Markov process on a measurable space |
| **Continuous-time** $T=[0,\infty)$ | continuous-time Markov chain | Continuous stochastic process with the Markov property |

<MathBox title='Markov process' boxType='definition'>
A stochastic process $\mathbf{X}$ is a *Markov process* if it satisfies the Markov property

$$
  \mathbb{P}(X_{s+t}\in A|\mathcal{F}_s) = \mathbb{P}(X_{s+t}\in A|X_s)
$$

for all $s,t\in T$ and $A\in\mathcal{S}$. In particular, a Markov process $\mathbf{X}$ is *time homogeneous* (stationary) if

$$
  \mathbb{P}(X_{s+t}\in A | X_s = x) = \mathbb{P}(X_t\in A | X_0 = x)
$$
</MathBox>

The Markov property states that the conditional distribution of a future state $X_{s+t}$ given $\mathcal{F}_s$ is the same as the conditional distribution of $X_{s+t}$ just given the current state $X_s$. This means that any additional knowledge of events in the past is irrevelant in terms of predicting the future state $X_{s+t}$.

<MathBox title='Markov property in terms of conditional expectation' boxType='proposition'>
A stochastic process $\mathbf{X}$ is a *Markov process* if and only if

$$
  \mathbb{E}\left[f(X_{s+t})|\mathcal{F}_s\right] = \mathbb{E}\left[f(X_{s+t})|X_s\right]
$$

for all $s,t\in T$ and $f\in\mathcal{B}$. If a Markov process $\mathbf{X}$ is *time homogeneous* (stationary) then

$$
  \mathbb{E}\left[f(X_{s+t})|X_s = x\right] = \mathbb{E}\left[f(X_{s+t})|X_0 = x\right]
$$

<details>
<summary>Proof</summary>

By letting $f = \mathbf{1}_A$ for $A\in\mathcal{S}$ then $\mathbb{E}[\mathbf{1}_A(X_{x+t})] = \mathbb{P}(X_{x+s}\in A)$. Thus the conditional expectation formulation is equivalent with the Markov property.

</details>
</MathBox>

<MathBox title='Markov property is preserved under coarser filtrations' boxType='proposition'>
Suppose that the stochastic process $\mathbf{X}$ is adapted to the filtration $\mathscr{F}$, and $\mathscr{F}\subseteq\mathscr{G}$, i.e. $\mathscr{G}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a Markov process relative to $\mathscr{G}$, then $\mathbf{X}$ is a Markov process relative to $\mathscr{F}$.

In particular, if $\mathbf{X}$ is a Markov process, then $\mathbf{X}$ satisfies the Markov property relative to the natural filtration $\mathcal{F}^0$

<details>
<summary>Proof</summary>

Note $\mathbf{X}$ is adapted to $\mathscr{G}$, since $\mathbf{X}$ is adapted to $\mathscr{F}$ and $\mathscr{F}\subseteq\mathbf{G}$. If $s,t\in T$ and $f\in\mathcal{B}$ then

$$
\begin{align*}
  \mathbb{E}[f(X_{t+s})|\mathcal{F}_s] &= \mathbb{E}\left(\mathbb{E}[f(X_{s+t})|\mathcal{G}_s] | \mathcal{F}_s \right) \\
  &= \mathbb{E}\left( \mathbb{E}[f(X_{s+t})|X_s]|\mathcal{F}_s \right) \\
  &= \mathbb{E}[f(X_{s+t})|X_s]
\end{align*}
$$

The first equality is a basic property of conditional expected value. The second uses the fact that $\mathbf{X}$ is Markov relative to $\mathscr{G}$, and the third follows since $X_s$ is measurable with respect to $\mathcal{F}_s$
</details>
</MathBox>

<MathBox title='Feller process' boxType='definition'>
A Markov process $\mathbf{X}$ is a *Feller process* if it satisfies
1. Continuity in space: For $t\in T$ and $y\in S$, the distribution of $X_t$ given $X_0 = x$ converges to the distribution of $X_t$ given $X_0 = y$ as $x\to y$. This means taht $\mathbb{E}[f(X_t)| X_0 = x] \xrightarrow{x\to y}$ for every $f\in\mathcal{C}$.
2. Continuity in time: Given $X_0 = x$ for $x\in S$, then $X_t \xrightarrow{t\downarrow 0} x$ in probability. This means that $\mathbb{P}[X_t \in U | X_0 = x] \xrightarrow{t\downarrow 0}$ for every neighbourhood $U$ of $x$.
</MathBox>

Note that if $S$ is discrete, the first Feller property is always satisfied, and if $T$ is discrete, the second Feller property is always satisfied. In partical, every discrete-time Markov chain is a Feller process.

### Strong Markov process (stopping time)

Strong Markov processes arise with stopping times. Recall that random time is a random variable $\tau:\Omega\to T_\infty$ on $(\Omega,\mathcal{F},\mathbb{P})$ where $T_\infty = T \cup \{\infty\}$ is an enlarged time space. For a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ filtration on $(\Omega,\mathcal{F})$, a random time $\tau$ is called a stopping time relative to $\mathscr{F}$ if $\{\tau\leq t\}\in\mathcal{F}_t$ for each $t\in T$. For any stopping time $\tau$ on $\Omega$ we can define

$$
  \mathcal{F}_\tau = \{ A\in\mathcal{F} \;|\; A\cap \{\tau \leq t \}\in\mathcal{F}_t \; \forall t\in T \}
$$

Note that if $\mathbf{X} = \{X_t \}_{t\in T}$ is a stochastic process adapted to a filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$, then for a stopping time $\tau$ the random variable $X_\tau$ is not necessarily measurable with respect to $\mathcal{F}_\tau$. For this we require that $\mathbf{X}$ is progressively measurable relative to $\mathscr{F}$ in the sense that $\mathbf{X}:\Omega\times T_t\to S$ is measurable with respect to $\mathcal{F}_t \otimes\mathcal{T}_t$ and $\mathcal{S}$. This is always true in the discrete case and more generally if $S$ has an LCCB topology with $\mathcal{S}$ as the Borel $\sigma$-algebra, and $\mathbf{X}$ is right continuous.

<MathBox title='Strong Markov process' boxType='definition'>
The process $\mathbf{X}$ is a strong Markov process if

$$
  \mathbb{E}\left[ f(X_{\tau + t})|\mathcal{F}_\tau \right] = \mathbb{E}[f(X_{\tau + t})|X_\tau]
$$

for every $t\in T$, stopping time $\tau$ and $f\in\mathcal{B}$. If a strong Markov process $\mathbf{X}$ is *time homogeneous* (stationary) then

$$
  \mathbb{E}\left[f(X_{\tau + t})|X_\tau = x\right] = \mathbb{E}\left[f(X_{\tau+t})|X_0 = x\right]
$$
</MathBox>

For a stationary process, the strong Markov property implies the ordinary Markov process, since a fixed time $t\in T$ is trivially also a stopping time. The converse is also true in discrete time. In continuous time it depends on the continuity of $\mathbf{X}$ and the filtration $\mathscr{F}$

<MathBox title='Stationarity and the strong Markov property' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a time homogeneous Markov process in discrete time. Then $\mathbf{X}$ is a strong Markov process.

If $\mathbf{X} = \{X_t \}_{t\in[0,\infty)}$ is a Feller Markov process, then $\mathbf{X}$ is a strong Markov process relative to the filtration $\mathscr{F}_+^0$, the right-continuous refinement of the natural filtration.
</MathBox>

<MathBox title='The strong Markov property is preserved under coarser filtrations' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is progressively measurable relative to the filtration $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$ and that the filtration $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a strong Markov process relative to $\mathscr{G}$ then $\mathbf{X}$ is a strong Markov process relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Since $\mathbf{X}$ is adapted to $\mathscr{F}$, it is also adapted to $\mathscr{G}$. Suppose that $\tau$ is a stopping time for $\mathscr{F}$ and that $t\in T$ and $f\in\mathcal{B}$. Then $\tau$ is also a stopping time for $\mathscr{G}$ and $\mathcal{F}_\tau \subseteq\mathcal{G}_\tau$. Hence

$$
\begin{align*}
  \mathbb{E}\left[f(X_{\tau + t})|\mathcal{F}_\tau\right] &= \mathbb{E}\left(\mathbb{E}\left[f(X_{\tau + t})|\mathcal{G}_\tau\right]|\mathcal{F}_\tau \right) \\
  &= \mathbb{E}\left(\mathbb{E}\left[f(X_{\tau + t})|X_\tau\right]|\mathcal{F}_\tau \right) \\
  &= \mathbb{E}\left[f(X_{\tau + t})|X_\tau\right]
\end{align*}
$$

The last equation follows since $\mathbf{X}_\tau$ is measurable with respect to $\mathcal{F}_\tau$ given that $\mathbf{X}$ is progressively measurable to $\mathscr{F}$.
</details>
</MathBox>

### Transition kernels of Markov processes

The transition kernels of a time-homogeneous Markov process is the conditional distribution given the initial distribution of the process. This means that the initial distribution and the transition kernels determine the finite dimensional distributions of a Markov process.

<MathBox title='Transition kernel' boxType='definition'>
Suppose that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a time-homogeneous Markov process. For $t\in T$ let

$$
  P_t(x,A) = \mathbb{P}(X_t\in A \;|\; X_0 = x),\; x\in S, A\in\mathcal{S}
$$

Then $P_t$ is a probability kernel on $(S,\mathcal{S})$ known as the transition kernel of $\mathbf{X}$ for time $t$. 

<details>
<summary>Proof</summary>

For a fixed $t\in T$, the measurability of $x\mapsto\mathbb{P}(X_t \in A \;|\; X_0 = x)$ for $A\in\mathcal{S}$ is built into the definition of conditional probability. Additionally, $A\mapsto\mathbb{P}(X_t\in A \;|\; X_0 = x)$ is a probability measure on $\mathcal{S}$ for $x\in S$. In general, the conditional distribution of one random variable, conditioned on a value of another random variable defines a probability kernel.
</details>
</MathBox>

The transition kernel $P_t(x,\cdot)$ of a time-homogeneous Markov process $\mathbf{X}$ at time $t$ is the conditional distribution of $X_t$ given $X_0 = x \in S$. By the time-homogeneous property, $P_t(x, \cdot)$ is also the conditional distribution of $X_{s+t}$ given $X_s = x$ for $s\in T$

$$
  P_t(x, A) = \mathbb{P}(X_{s+t}\in A | X_s = x),\; s,t\in T, x\in S, A\in\mathcal{S}
$$

Usually there is a natural reference measure $\lambda$ on $(S,\mathcal{S})$, in which case the transition kernel $P_t$ will often have a transition density with respect to $\lambda$

$$
  P_t(x, A) = \mathbb{P}(X_t \in A \;|\; X_0 = x) = \int_A p_t(x, y)\lambda(\mathrm{d}y),\; x\in S, A\in\mathcal{S}
$$

<MathBox title='Chapman-Kolmogorov equation' boxType='theorem'>
Suppose that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a time-homogeneous Markov process with transition kernels $\mathbf{P} = \{ P_t \}_{t\in T}$. For $s,t\in T$ then $P_s P_t = P_{s+t}$ given by

$$
  P_{s+t}(x,A) = \int_S P_s(x, \mathrm{d}y) P_t(y, A),\; x\in S, A\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

Note that $P_x(x,\cdot)$ is the conditional distribution of $X_s$ given $X_0 = x \in S$. Conditioning on $X_s$ for $A\in\mathcal{S}$ gives

$$
\begin{align*}
  P_{s+t}(x,A) &= \mathbb{P}(X_{s+t}\in A \;|\; X_0 = x) \\
  &= \int_S P_s(x, \mathrm{d}y)\mathbb{P}(X_{s+t}\in A \;|\; X_s = y, X_0 = x)
\end{align*}
$$

By the Markov and time-homogeneous properties, we have

$$
  \mathbb{P}(X_{s+t}\in A \;|\; X_s = y, X_0 = x) = \mathbb{P}(X_t\in A \;|\; X_0 = y) = P_t(y,A)
$$

Substituting we get

$$
  P_{s+t}(x,A) &= \int_S P_s (x,\mathrm{d}y)P_t(y, A) = (P_s P_t)(x, A)
$$
</details>
</MathBox>

The set of transition kernels $\mathbf{P}$ is a semi-group. Generally, the commutative property does not hold for the product operation on kernels. However, transition kernels a of time-homogeneous Markov process are commutative, i.e. $P_s P_t = P_t P_s = P_{s+t}$ for $s,t\in T$.

In discrete time, $T = \mathbb{N}$, the transition kernels of $\mathbf{X}$ are simply the powers of the one-step transition kernel. That is if $P = P_1$ then $P_n = P^n$ for $n\in\mathbb{N}$.

<MathBox title='' boxType='corollary'>
Suppose that $\lambda$ is the reference measure on $S$ and that $\mathbf{X}=\{X_t: \Omega\to S\}_{t\in T}$ is a Markov process with transition densities $\{ p_t \}_{t\in T}$. If $s,t \in T$, then $p_s p_t = p_{s+t}$

$$
  p_t (x, z) = \int_S p_s(x, x) p_t(y, z)\lambda(\mathrm{d}y),\; x, z\in S
$$

<details>
<summary>Proof</summary>

By the Chapman-Kolmogorov equation, the transition kernels of $\mathbf{X}$ satisfy $P_s P_t = P_{s+t}$. Since $P_s$ has density $p_s$, $P_t$ has density $p_t$ and $P_s P_t$ has density $p_{s + t}$ it follows from the Chapman-Kolmogorov equation that $P_{s+t}$ has density $p_s p_t$.
</details>
</MathBox>

A kernel defines two operations:
- operating on the left with positive measure on $(S,\mathcal{S})$
- operating on the right with measurable, real-valued functions

<MathBox title='Left transition kernel operation' boxType='proposition'>
If $\mu_s$ is the distribution of $X_s$, then $X_{s+t}$ has distribution $\mu_{s+t} = \mu_s P_t$ for $s,t\in T$

$$
  \mu_{s+t}(A) = \int_S \mu_s(\mathrm{d}x)P_t(x, A),\; A\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

Conditioning on $X_s$ gives

$$
\begin{align*}
  \mathbb{P}(X_{s+t}\in A) &= \mathbb{E}\left[\mathbb{P}(X_{s+t}\in A \;|\; X_s) \right] \\
  &= \int_S \mu_s(\mathrm{d}x)\mathbb{P}(X_{s+t}\in A \;|\; X_s = x) \\
  &= \int_S \mu_s(\mathrm{d}x)\mathbb{P}_t(x, A) \\
  &= \mu_s P_t (A)
\end{align*}
$$
</details>
</MathBox>

If $\mathcal{P}$ denotes the collection of probability measures on $(S,\mathcal{S})$, the left operator $P_t$ maps $\mathcal{P}$ back into $\mathcal{P}$. In particular, if $X_0$ has distribution $\mu_0$ then $X_t$ has distribution $\mu_t = \mu_0 P_t$ for every $t\in T$.

<MathBox title='Invariant positive measures' boxType='definition'>
A positive measure $\mu$ on $(S, \mathcal{S})$ is invariant for $\mathbf{X}$ if $\mu P_t = \mu$ for every $t\in T$.
</MathBox>

If $\mu$ is a probability measure that is invariant for $\mathbf{X}$, and $X_0$ has distribution $\mu$, then $X_t$ also has distribution $\mu$ for every $t\in T$ making the process $\mathbf{X}$ identically distributed. In discrete time, note that if $\mu P = \mu$ then $\mu P^n = \mu$ for every $n\in \mathbb{N}$ so $\mu$ is invariant for $\mathbf{X}$

<MathBox title='Right transition kernel operation' boxType='proposition'>
Suppose that $f:S\to\mathbb{R}$. If $t\in T$ then

$$
  P_t f(x) = \int_S P_t(x, \mathrm{d}y)f(y) = \mathbb{E}[f(X_t)\;|\; X_0 = x],\; x\in S
$$

<details>
<summary>Proof</summary>

This follows directly from the definition of conditional expectation.
</details>
</MathBox>

In particular, the right operator $P_t$ is defined on $\mathcal{B}$, the vector space of bounded, linear functions $f:S\to\mathbb{R}$, and is in fact a linear operator on $\mathcal{B}$. That is, if $f,g\in\mathcal{B}$ and $c\in\mathbb{R}$ then $P_t (f+g) = P_t f + P_t g$ and $P_t (cf) = cP_t f$. Moreover, $P_t$ is a contraction operator on $\mathcal{B}$, since $\lVert P_t f \rVert\leq \lVert f \rVert$ for $f\in\mathcal{B}$. It follows that $P_t$ is a continuous operator on $\mathcal{B}$.

<MathBox title='Harmonic measurable function' boxType='definition'>
A measurable function $f:S\to\mathbb{R}$ is harmonic for $\mathbf{X}$ is $P_t f = f$ for all $t\in T$.
</MathBox>

In discrete time, if $Pf = f$ then $P^n f = f$ for all $n\in\mathbb{N}$, making $f$ harmonic for $\mathbf{X}$.

<MathBox title='Differential form of Markov distributions' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a Markov process with transition operators $\mathbf{P} = \{P_t \}_{t\in T}$ and that $(t_i)_{i=1}^{n\in\mathbb{N}} \in T^n$ is strictly increasing. If $X_0$ has distribution $\mu_0$, then in differential form the distribution of $(X_i)_{i=0}^{t_n}$ is

$$
  \mu_0(\mathrm{d}x_0)P_{t_1}(x_0, \mathrm{d}x_1)\prod_{i=2}^{n} P_{t_n - t_{n-1}}(x_{n-1}, \mathrm{d}x_n)
$$

<details>
<summary>Proof</summary>

This follows from induction and repeated use of the Markov property. If $t\in T$ with $t> 0$, then conditioning on $X_0$ gives for $A, B\in\mathcal{S}$

$$
\begin{align*}
  \mathbb{P}(X_0 \in A, X_t\in B) = \int_A \mathbb{P}(X_t\in B \;|\; X_0 = x)\mu_0 (\mathrm{d}x) \\
  &= \int_A P_t (x, B\mu(\mathrm{d}x) \\
  &= \int_A \int_B P_t(x,\mathrm{d}y)\mu_0 (\mathrm{d}x)
\end{align*}
$$

Hence in differential form, the distribution of $(X_0, X_t)$ is $\mu(\mathrm{d}x)P_t(x,\mathrm{d}y)$. If $s,t\in T$ with $0 < s < t$, then conditioning on $(X_0, X_s=$ and using the previous result gives for $A, B, C \in\mathcal{S}$

$$
  \mathbb{P}(X_0\in A, X_s\in B, X_t\in C) = \int_{A\times B} \mathbb{P}(X_t\in C \;|\; X_0 = x, X_s = y)\mu_0 (\mathrm{d}x) P_s(x, \mathrm{d}y)
$$

By the Markov property

$$
\begin{align*}
  \mathbb{P}(X_t\in C \;|\; X_0 = x, X_s = y) &= \mathbb{P}(X_t \in C | X_s = y) \\
  &= P_{t-s}(y, C) = \int_C P_{t-s}(y,\mathrm{d}z)
\end{align*}
$$

Hence in differential form, the distribution of $(X_0, X_s, X_t)$ is $\mu_0(\mathrm{d}x)P_s(x,\mathrm{d}y)P_{t-s}(y,\mathrm{d}z})$. Continuing in this manner gives the general result.
</details>
</MathBox>

Knowing the transition kernels and the initial distribution determines a finite set of distributions for a Markov process. From the Kolmogorov construction theorem, we know that there exists a stochastic process that has these finite dimensional distributions. This is straightforward in discrete time, however in continuous time two problems arise. First, it is not clear how to construct the transition kernels so that the Chapman-Kolmogorov equations are satisfied. Second, we want the Markov process to exhibit certain properties that go beyond the finite dimensional distributions.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a Markov process on an LCCB state space $(S,\mathcal{S})$ with transition operators $\mathbf{P} = \{P_t \}_{t\in [0,\infty)}$. Then $\mathbf{X}$ is a Feller process if and only if

1. Continuity in space: If $f\in\mathcal{C}_0$ and $t\in[0,\infty)$, then $P_t f\in\mathcal{C}_0$
2. Continuity in time: If $f\in\mathcal{C}_0$ and $x\in S$ then $P_t f(x) \xrightarrow{t\downarrow 0} f(x)$

A semi-group of probability kernels $\mathbf{P}$ satisfying these properties is called a Feller semi-group.
</MathBox>

This means that a Markov process $\mathbf{X}$ is Feller if and only if $\mathbf{P}$ is Feller. The first property means that $P_t$ is an operator on the vector space $\mathcal{C}_0$, in addition to being an operator on the larger space $\mathcal{B}$. The second condition implies a stronger form of continuity in time.

Note that if $S$ is discrete, then the first property is automatically satisfied. If $T$ is discrete, then the second property is automatically satisfied.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{P} = \{P_t \}_{t\in [0,\infty)}$ is a Feller semi-group of transition operators. Then $t\mapsto P_t f$ is continuous (with respect to the supremum norm) for $f\in\mathcal{C}_0$, i.e.

$$
  \lVert P_{t+s} f - P_t f \rVert = \sup\{|P_{t+s}f(x) - P_t f(x)| : x\in S \} \xrightarrow{s\to 0} 0
$$
</MathBox>

#### Sampling in time

<MathBox title='Time sampled Markov process gives a time-discrete Markov process' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a Markov process with state space $(S,\mathcal{S})$ and that $(t_i)_{i=0}^{n\in\mathbb{N}}$ is an increasing sequence in $T$. Let $Y_n = X_{t_n}$, then $\mathbb{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a Markov process in discrete time.

<details>
<summary>Proof</summary>

For $n\in\mathbb{N}$, let $\mathcal{G}_n = \sigma\{ Y_k \;|\; k\in\mathbb{N}, k\leq n \}$ so that $\{\mathcal{G}_n\}_{n\in\mathbb{N}}$ is the natural filtration associated with $\mathbf{Y}$. Note that $\mathcal{G}_n \subseteq \mathcal{F}_{t_n}$ and $Y_n = X_{t_n}$ is measurable with respect to $\mathcal{G}_n$ for $n\in\mathcal{N}$. Let $k, n\in\mathbb{N}$ and let $A\in\mathcal{S}$, then

$$
\begin{align*}
  \mathbb{P}(Y_{k+n}\in A \;|\; \mathcal{G}_k) = \mathbb{P}(X_{t_{n+k}}\in A \;|\; \mathcal{G}_l) \\
  &=  \mathbb{P}(X_{t_{n+k}}\in A \;|\; X_{t_k}) \\
  &= \mathbb{P}(Y_{n+k}\in A \;|\; Y_k) 
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a time-homogenous Markov process with state space $(S,\mathcal{S})$ and transition kernels $\mathbf{P} = \{P_t\}_{t\in T}$. Fix $r\in T$ with $r>0$ and define $Y_n = X_{nr}$ for $n\in\mathbb{N}$. Then $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a time-homogenous Markov process in discrete time, with one-step transition kernel

$$
  Q(x, A) = P_r (x, A),\; x\in S, A\in\mathcal{A}
$$
</MathBox>

#### Enlarging the sample space

A non-homogeneous Markov process can be turned into a time-homogenous Markov process at the expense of enlarging the state space.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t \}_{t\in T}$ is a non-homogenous Markov process with state space $(S,\mathcal{S})$. Suppose that $\tau$ is a random variable taking values in $T$, independent of $\mathbf{X}$. Let $\tau_t = \tau + t$ and let $Y_t = (X_{\tau_t}, \tau_t)$ for $t\in T$. Then $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a homogenous Markov process with state space $(S\times T, \mathcal{S} \otimes \mathcal{T})$. For $t\in T$, the transition kernel $P_t$ is given by

$$
  P_t [(x, r), A\times B] = \mathbb{P}(X_{r+t}\in A\;|\; X_r = x)\mathbf{1}(r + t\in B), (x,r)\in S\times T, A\times B\in\mathcal{S}\otimes\mathcal{T}
$$

<details>
<summary>Proof</summary>

By definition and the substitution rule

$$
\begin{align*}
  \mathbb{P}[Y_{s+t}\in A\times B \;|\; Y_s = (x,r)] &= \mathbb{P}(X_{\tau_{s+t}}\in A, \tau_{s+t}\in B \;|\; X_{\tau_{s}} = x, \tau_s = r) \\
  &= \mathbb{P}(X_{tau+s+t}\in A, \tau+s+t\in B \;|\; X_{\tau+s} = x, \tau+s = r) \\
  &= \mathbb{P}(X_{r+t}\in A, r+t\in B \;|\; X_r = x, \tau+s = r)
\end{align*}
$$

Since $\tau$ is independent of $\mathbf{X}$ the last term is

$$
  \mathbb{P}(X_{r+t}\in A, r+t\in B \;|\; X_r = x, \tau+s = r) = \mathbb{P}(X_{r+t}\in A \;|\; X_r = x)
$$

which does not depend on $s$, making $\mathbf{Y}$ time-homogenous.
</details>
</MathBox>

Sometimes a stochastic process with weak memory can be made into a Markov process by enlarging the state space appropriately

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{n\in\mathbb{N}}$ is a random process with state space $(S,\mathcal{S})$ in which the future depends on the last $k$ states, i.e.

$$
  \mathbb{P}(X_{n+k} \in A | \mathcal{F}_{n+k-1}) = \mathbb{P}(X_{n+2}\in A \;|\; X_n,\dots,X_{n+k}),\; A\in\mathcal{S}
$$

where $\{\mathcal{F}_n\}_{n\in\mathbb{N}}$ is the natural filtration associated with the process $\mathbf{X}$. Suppose also that the process is time-homogenous in the sense that

$$
  \mathbb{P}(X_{n+k}\in A \;|\; X_n = x_0, \dots, X_{n+k} = x_k) = Q(x_0,\dots,x_k, A)
$$
 
independently of $n\in\mathbb{N}$. Let $Y_n = (X_n+i)_{i=0}^k-1$, then $\mathbf{N} = \{Y_n\}_{n\in\mathbb{N}}$ is a time homogenous Markov process with state space $S^k, \bigotimes_{i=1}^k \mathcal{S}$. The one-step transition kernel is

$$
  P[(x_i)_{i=1}^k, \prod_{i=1}^k A_i] = I(x_1, A_1)Q_1(x_1, x_2, A_2)\dots Q_{k-1}(x_1,\dots,x_k, Q_k)\; x_i\in S, A_i\in\mathcal{S}
$$

<details>
<summary>Proof</summary>

For $k=2$ note that $\sigma\{Y_k \;|\; k\leq n\} = \sigma\{(X_k, X_{k+1}) \;|\; k\leq n \} = \mathcal{F}_{n+1}$ for $n\in\mathbb{N}$. Thus, the natural filtration associated with $\mathbf{Y}$ is $\{\mathcal{F}_n\}_{n\in\mathbb{N}}$. If $C\in\mathcal{S}\mathcal{S}$ then

$$
\begin{align*}
  \mathbb{P}(Y_{n+1}\in C \;|\; \mathcal{F}_{n+1}) &= \mathbb{P}[(X_{n+1}, X_{n+2})\in C \;|\; \mathcal{F}_{n+1}] \\
  &= \mathbb{P}[(X_{n+1}, X_{n+2})\in C \;|\; X_n, X_{n+1}] = \mathbf{P}(Y_{n+1}\in C \;|\; Y_n)
\end{align*}
$$

by the given assumption on $\mathbf{X}$. Hence $\mathbf{Y}$ is a Markov process. Next,

$$
\begin{align*}
  \mathbb{P}[Y_{n+1}\in A\times B \;|\; Y_n = (x,y)] &= \mathbb{P}[(X_{n+1}, X_{n+2})\in A\times B \;|\; (X_n, X_{n+1}) = (x,y)] \\
  &= \mathbb{P}(X_{n+1}\in A, X_{n+2}\in B \;|\; X_n = x, X_{n+1} = y) \\
  &= \mathbb{P}(y\in A, X_{n+2}\in B \;|\; X_n = x, X_{n+1} = y) \\
  &= I(y, A)Q(x,y,B)
\end{align*}
$$
</details>
</MathBox>

### Potential operators

#### Discrete-time

<MathBox title='Discrete-time potential kernel' boxType='proposition'>

For $\alpha\in (0,1]$, the $\alpha$-potential kernel $R_\alpha$ of a discrete time Markov process $\mathbf{X}$ is defined as

$$
  R_\alpha (x, A) = \sum_{n=0}^\infty \alpha^n P^n (x, A),\; x\in S, A\in\mathcal{S}
$$

The special case $R = R_1$ is simply the potential kernel of $\mathbf{X}$ where $R(x, A)$ is the expected number of visits of $\mathbf{X}$ to $A$, starting at $x$.

<details>
<summary>Proof</summary>

The function $x\mapsto R_\alpha (x, A)$ from $S$ to $[0,\infty)$ is measurable for $A\in\mathcal{S}$ since $x\mapsto P^n(x, A)$ is measurable for each $n\in\mathbb{N}$. The mapping $A\mapsto R_\alpha (x, A)$ is a positive measure on $\mathcal{S}$ for $x\in S$ since $A\mapsto P^n(x, A)$ is a probability measure for each $n\in\mathbb{N}$. The interpretation of $R(x, A)$ comes from interchanging sum and expected value, which is allowed since the terms are nonnegative.

$$
\begin{align*}
  R(x, A) &= \sum_{n=0}^\infty P^n (x, A) \\
  &= \sum_{n=0}^\infty \mathbb{E}[\mathbf{1}(X_n \in A) | X_0 = x] \\
  &= \mathbb{E}\left( \sum_{n=0}^\infty \mathbf{1}(X_n \in A) \mid| X_0 = x \right) \\
  &= \mathbb{E}[#\{n\in\mathbb{N} : X_n \in A\}|X_0 = x]
\end{align*}
$$
</details>
</MathBox>

For a discrete-time Markov process $\mathbf{X}$, the potential kernel $R_\alpha (x, A)$ for $\alpha\in(0,1)$ can be interpreted as the expected number of times $\mathbf{X}$ visits $A\in\mathcal{S}$ starting at $x\in S$. The parameter $\alpha$ represents a discount rate of this expected value in the sense that a future vists at time $n$ has a present value of $\alpha^n$.

The potential kernel $R_\alpha$ defines two operators, operating on the right on measurable functions, and on the left on positive measures. For measurable functions $f:S\to\mathbb{R}$, the right potential operator is defined as

$$
\begin{align*}
  R_\alpha f(x) &= \sum_{n=0}^\infty \alpha^n P^n f(x) \\
  &= \sum_{n=0}^\infty \alpha^n \int_S P^n (x,\mathrm{d}y) f(y) \\
  &= \sum_{n=0}^\infty \alpha^n \mathbb{E}[f(X_n)|X_0 = x]
\end{align*}
$$

The functions $f\in\mathcal{B}$ represents the reward/cost when $\mathbf{X}$ visits $x\in S$.

<MathBox title='' boxType='proposition'>

If $\alpha\in (0,1)$, then $R_\alpha (x, S) = \frac{1}{1-\alpha}$. It follows that the right operator $R_\alpha$ is a bounded, linear operator on $\mathcal{B}$ with $\lVert R_\alpha \rVert = \frac{1}{1-\alpha}$. It also follows that $(1-\alpha)R_\alpha$ is a probability kernel.

<details>
<summary>Proof</summary>

Using geometric series

$$
  R_\alpha (x, S) \sum_{n=0}^\infty \alpha^n P^n (x, S) = \sum_{n=0}^\infty \alpha^n = \frac{1}{1-\alpha}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $\alpha\in (0,1)$, then $(1-\alpha)R_\alpha (x, \cdot)$ is the conditional distribution of $X_N$ given $X_0 = x\in S$, where $N$ is independent of $\mathbf{X}$ and has the geometric distribution on $\mathbb{N}$ with parameter $1-\alpha$.

<details>
<summary>Proof</summary>

Conditioning on $N$ gives

$$
  \mathbb{P}(X_N \in A | X_0 = x) = \sum_{n=0}^\infty \mathbb{P}(N=n)\mathbb{P}(X_N \in A | N = n, X_0 =x)
$$

By the substitution rule and the assumption of independence

$$
\begin{align*}
  \mathbb{P}(X_N \in A | N = n, X_0 = x) &= \mathbb{P}(X_n \in A | N=n, X_0 = x) \\
  &= \mathbb{P}(X_n \in A | X_0 = x) = P^n(x,A)
\end{align*}
$$

Since $N$ has the geometric distribution on $\mathbb{N}$ with parameter $1-\alpha$ it follows that $P(N = n) = (1-\alpha)\alpha^n$ for $n\in\mathbb{N}$. Substituting gives

$$
  \mathbb{P}(X_N \in A | X_0 = x) = \sum_{n=0}^\infty (1-\alpha)\alpha^n P^n (x, A) = (1-\alpha) R_\alpha (x, A)
$$
</details>
</MathBox>

The kernel $(1-\alpha)R_\alpha$ is a transition probability kernel corresponding to the random time $N$ rather than the deterministic time $n\in\mathbb{N}$.

For positive measures $\mu$ on $\mathcal{S}$, the left potential operator is defined as

$$
  \mu R_\alpha (A) = \sum_{n=0}^\infty \alpha^n \mu P^n (A) = \sum_{n=0}^\infty \alpha^n \int_S \mu(\mathrm{d}x)P^n (x, A),\; A\in\mathcal{S} 
$$

If $X_0$ has distribution $\mu$, then $\mu P^n$ is the distribution of $X_n$ for $n\in\mathbb{N}$. In this case, $(1-\alpha)\mu R_\alpha$ is the distribution of $X_N$, where $N$ is independent of $\mathbf{X}$ and is geometrically distributed on $\mathbb{N}$ with parameter $1 - \alpha$.

<MathBox title='' boxType='proposition'>
The potential kernels $\mathbb{R} = \{ R_\alpha \}_{\alpha\in (0, 1)}$ completely determine the transition kernels $\mathbf{P} = \{P_n\}_{n\in\mathbb{N}}$.

<details>
<summary>Proof</summary>

For $x\in S$ and $A\in\mathcal{A}$, the function $\alpha\mapsto R_\alpha(x, A)$ is a power series in $\alpha$ with coefficients $n\mapsto P^n(x,A)$. In combinatorial terms, $\alpha\mapsto R_\alpha(x, A)$ is the ordinary generating function of the sequence $n\mapsto P^n (x, A)$. This power series has radius of convergence at least $1$, extending the domain to $\alpha\in (-1, 1)$. Thus, we can recover the transition kernels by derivating $R_\alpha$ and evaluating at $\alpha = 0$

$$
  P^n (x, A) = \frac{1}{N!}\left. \frac{\mathrm{d}^n}{\mathrm{d}\alpha^n} R_\alpha (x, A) \right|_{\alpha = 0}
$$
</details>
</MathBox>

The kernels $\mathbf{R} = \{ R_\alpha \}_{\alpha\in (0,1)}$, along with the initial distribution, completely determine the finite dimensional distributions of the discrete-time Markov process $\mathbf{X}$.

<MathBox title='' boxType='proposition'>
If $\alpha,\beta\in (0, 1]$ and $k\in\mathbb{N}$, then (as kernels)

1. $P^k R_\alpha = R_\alpha P^k = \sum_{n=0}^\infty \alpha^n P^{n+k}$
2. $R_\alpha R_\beta = R_\beta R_\alpha = \sum_{m=0}^\infty\sum_{n=0}^\infty \alpha^m \beta^n P^{m+n}$
3. $I + \alpha R_\alpha P = I + \alpha P R_\alpha = R_\alpha$

If $\alpha\leq\beta$ then (as kernels)

4. $\beta R_\beta = \alpha R_\alpha + (\beta - \alpha) R_\alpha R_\beta$

If $\alpha\in (0,1)$, then as operator as on $\mathcal{B}$

5. $R_\alpha = (I - \alpha P)^{-1}$
6. $P = \frac{1}{\alpha}(1 - R_\alpha^{-1})$
 
<details>
<summary>Proof</summary>

Suppose that $f\in\mathcal{B}$ is nonnegative. Since the kernels are nonnegative we can interchange sums with kernel operations.

1. Evaluating $R_\alpha P^k$ directly
$$
  R_\alpha P^k f = \sum_{n=0}^\infty \alpha^n P^n P^k f = \sum_{n=0}^\infty \alpha^n P^{n+k} f
$$

The other direction requires an interchange

$$
  P^k R_\alpha f = P^k \sum_{n=0}^\infty \alpha^n P^n f = \sum_{n=0}^\infty \alpha^n P^k P^n f = \sum_{n=0}^\infty \alpha^n P^{n+k}f
$$

2. Only the first direction is shown as the other is similar.
$$
\begin{align*}
  R_\alpha R_\beta &= \sum_{m=0}^\infty \alpha^m P^m R_\beta f \\
  &= \sum_{m=0}^\infty \alpha^m P^m \left( \sum_{n=0}^\infty \beta^n P^n f \right) \\
  &= \sum_{m=0}^\infty \sum_{n=0}^\infty \alpha^m \beta^n P^m P^n f \\
  &= \sum_{m=0}^\infty \sum_{n=0}^\infty \alpha^m \beta^n P^{m+n} f
\end{align*}
$$

3. From the 1st identity
$$
\begin{align*}
  (I + \alpha R_\alpha P)f &= (I + \alpha RP_\alpha)f \\
  &= f + \sum_{n=0}^\infty \alpha^{n + 1} P^{n+1} f \\
  &= \sum_{n=0}^\infty \alpha^n P^n f = R_\alpha f
\end{align*}
$$

4. Assume $\alpha < \beta$ as the case $\alpha = \beta$ is trivial. From the 2nd identity

$$
  R_\alpha R_\beta f = \sum_{j=0}^\infty \sum_{k=0} \alpha^j \beta^k P^{j+k} f
$$

Changing the sum variables to $n = j + k$ and $j$

$$
\begin{align*}
  R_\alpha R_\beta f = \sum_{n=0}^\infty \sum_{j=0}^n \alpha^j \beta^{n-j} P^n f \\
  &= \sum_{n=0}^\infty \sum_{j=0}^n \left( \frac{\alpha}{\beta} \right)^j \beta^n P^n f \\
  &= \sum_{n=0}^\infty \frac{1 - \left( \frac{\alpha}{\beta} \right)^{n+1}}{1 - \frac{\alpha}{\beta}} \beta^n P^n f \\
  &= \frac{1}{\beta - \alpha}  \beta \left( \sum_{n=0}^\infty \beta^n P^n f \right) - \alpha \left( \sum_{n=0}^\infty \alpha^n P^n f \right) \\
  &= \frac{1}{\beta - \alpha} (\beta R_\beta f -\alpha R_\alpha f)
\end{align*}
$$

Note that $R_\alpha f$ is finite since $\alpha < 1$.

5. Since the operators are bounded, we can subtract. From the 3rd property

$$
\begin{gather*}
  I + \alpha R_\alpha  P = R_\alpha \iff R_\alpha (I - \alpha P) = I \\
  I + \alpha P R_\alpha = R_\alpha \iff (I - \alpha) R_\alpha = I
\end{gather*}
$$

6. This follows from the 5th property.
</details>
</MathBox>

#### Continuous-time

<MathBox title='Continuous-time potential kernel' boxType='proposition'>
For $\alpha\in [0, \infty)$ the $\alpha$-potential kernel $U_\alpha$ of $\mathbf{X}$ is defined as

$$
  U_\alpha (x, A) := \int_0^\infty e^{-\alpha t} P_t (x, A)\,\mathrm{d}t,\; x\in S, A\in\mathcal{S}
$$

1. The special case $U = U_0$ is simply the potential kernel of $\mathbf{X}$.
2. $U(x, A)$ is the expected amount of time that $\mathbf{X}$ spends in $A$, starting at $x$
3. The family of kernels $\mathbf{U} = \{ U_\alpha \}_{\alpha\in (0,\infty)}$ is known as the reolvent of $\mathbf{X}$

<details>
<summary>Proof</summary>

Since $\mathbf{P} = \{ P_t \}_{t\in T}$ is a Feller semigroup of transition operators, the mapping $(t,x)\mapsto P_t (x, A)$ from $[0,\infty)\times S$ to $[0,1]$ is jointly measurable for $A\in\mathcal{S}$. Thus, $U_\alpha (x, A)$ makes sense for $x\in S$ and $A\in\mathcal{S}$, and $x\mapsto U_\alpha (x, A)$ from $S$ to $[0,\infty)$ is measurable for $A\in\mathcal{S}$. That $A\mapsto U_\alpha (x, A)$ is a measure on $\mathcal{S}$ follows from the usual interchange of sum and integral, via Fubini's theorem. Suppose that $\{ A_j \}_{j\in J}$ is a countable collection of disjoint sets in $\mathcal{S}$, and let $S = \bigcup_{j\in J} A_j$, then

$$
\begin{align*}
  U_\alpha (x, A) &= \int_0^\infty e^{-\alpha t} P_t (x, A)\mathrm{d}t = \int_0^\infty \left[ \sum_{j\in J} e^{-\alpha t}P_t (x, A_j) \right]\mathrm{d}t \\
  &= \sum_{j\in J} \int_0^\infty e^{-\alpha t} P_t (x, A_j)\mathrm{d}t = \sum_{j\in J} U_\alpha (x, A_j)
\end{align*}
$$

The interpretation of $U(x, A)$ is another interchange of integrals

$$
\begin{align*}
  U(x, A) &= \int_0^\infty P_t (x, A)\mathrm{d}t = \int_0^\infty \mathbb{E}[\mathbf{1}(X_t \in A) \;|\; X_0 = x]\mathrm{d}t \\
  &= \mathbb{E}\left( \int_0^\infty \mathbf{1}(X_t \in A) \mid| X_0 = x \right)
\end{align*}
$$

The integral inside the expectation is the Lebesgue measure of $\{ t\in [0,\infty) : X_t\in A \}$
</details>
</MathBox>

The potential kernel $U_\alpha$ defines two operators, operating on the right on functions, and left on positive measures. For measurable functions $f:S\to\mathbb{R}$, the right potential operator is defined as

$$
\begin{align*}
  U_\alpha f(x) = \int_S U_\alpha (x, \mathrm{d}y)f(y) = \int_0^\infty e^{-\alpha t} P_t f(x)\mathrm{d}t \\
  &= \int_0^\infty e^{-\alpha t} \int_S P_t (x,\mathrm{d}y) f(y) = \int_0^\infty e^{-\alpha t}\mathbb{E}[f(X_t)\;|\; X_0]\mathrm{d}t,\; x\in S
\end{align*}
$$

<MathBox title='' boxType='proposition'>
If $\alpha > 0$, then $U_\alpha (x, S) = \frac{1}{\alpha}$ for all $x\in S$. It follows that the right potential operator $U_\alpha$ is a bounded, linear operator on $\mathcal{B}$ with $\lVert U_\alpha \rVert = \frac{1}{\alpha}$. It also follows that $\alpha R_\alpha$ is a probability kernel.

<details>
<summary>Proof</summary>

$$
  U_\alpha (x, S) \int_{n=0}^\infty \alpha^n P_t (x, S)\,\mathrm{d}t = \int_{n=0}^\infty e^{-\alpha t} \mathrm{d}t = \frac{1}{\alpha}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $\alpha > 0$, then $\alpha U_\alpha (x, \cdot)$ is the conditional distribution of $X_\tau$ where $\tau$ is independent of $\mathbf{X}$ and has the exponential distribution on $[0,\infty)$ with parameter $\alpha$.

<details>
<summary>Proof</summary>

Since $\tau$ is exponentially distributed it has the probability density function $f(t) = \alpha e^{-\alpha t}$ for $t\in[0,\infty)$. Conditioning on $\tau$ gives

$$
  \mathbb{P}(X_\tau \in A \;|\; X_0 = x) = \int_0^\infty \alpha e^{-\alpha t}\mathbb{P}(X_\tau \in A \;|\; \tau = t, X_0 = x) = P_t (x, A)
$$

By the substitution rule and the assumption of independence

$$
\begin{align*}
  \mathbb{P}(X_\tau \in A \;|\; \tau = t, X_0 = x) &= \mathbb{P}(X_t \in A \;|\; \tau = t, X_0 = x) \\
  &= \mathbb{P}(X_t \in A \;|\; X_0 = x) = P_t (x, A)
\end{align*}
$$

Substituting gives

$$
  \mathbb{P}(X_\tau \in A \;|\; X_0 = x) = \int_0^\infty \alpha e^{-\alpha t} P_t (x, A)\mathrm{d}t = \alpha U_\alpha (x, A)
$$
</details>
</MathBox>

The kernel $\alpha R_\alpha$ is a transition probability kernel corresponding to the random time $N$ rather than the deterministic time $n\in\mathbb{N}$.

For positive measures $\mu$ on $\mathcal{S}$, the left potential operator is defined as

$$
\begin{align*}
  \mu U_\alpha &= \int_S \mu(\mathrm{d}x) U_\alpha (x, A) = \int_0^\infty e^{-\alpha t} \mu P_t f(x)\mathrm{d}t \\
  &= \int_0^\infty e^{-\alpha t} \left[ \int_S \mu(\mathrm{d}x) P_t (x, A)\right] \mathrm{d}t = \int_0^\infty e^{-\alpha t}\left[ \int_S \mu(\mathrm{d}x)\mathbb{P}(X_t \in A) \right]\mathrm{d}t,\; A\in\mathcal{S}
\end{align*}
$$

In particular, suppose that $\alpha > 0$ and that $X_0$ has distribution $\mu$. Then $\mu P_t$ is the distribution of $X_t$ for $t\in[0,\infty)$ so that $\alpha \mu U_\alpha$ is the distribution of $X_\tau$, where $\tau$ is independent of $\mathbf{X}$ and is exponentially distributed on $[0,\infty)$ with parameter $\alpha$.

<MathBox title='' boxType='proposition'>
The resolvent $\mathbf{U} = \{U_\alpha\}_{\alpha\in (0,\infty)}$ completely determines the family of transition kernels $\mathbf{P} = \{P_t\}_{t\in (0,\infty)}$

<details>
<summary>Proof</summary>

Note that the function $\alpha\mapsto U_\alpha (x, A)$ on $(0,\infty)$ is the Laplace transform of the function $t\mapsto P_t (x, A)$ on $[0,\infty)$. The Laplace transform of a function determines the function completely.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\alpha, \beta, t \in [0,\infty)$. Then as kernels

1. $P_t U_\alpha = U_\alpha P_t = \int_0^\infty e^{-\alpha s} P_{s+t}\mathrm{d}s$
2. $U_\alpha U_\beta = U_\beta U_\alpha = \int_0^\infty \int_0^\infty e^{-\alpha s} e^{-\beta t} P_{s+t}\mathrm{d}s\,\mathrm{d}t$

If $\alpha\leq\beta$ then as kernels

3. $U_\alpha = U_\beta + (\beta -\alpha) U_\alpha U_\beta$

4. If $\alpha\in (0,\infty)$ and $f\in\mathcal{C}_0$ then $U_\alpha f \in\mathcal{U}_0$.
5. If $f\in\mathcal{C}_0$ then $\alpha U_\alpha f \xrightarrow{\alpha\to\infty} f$

<details>
<summary>Proof</summary>

Suppose that $f\in\mathcal{B}$ is nonnegative. Since the integrands are nonnegative we can interchange integrals.

1. Evaluating $U_\alpha P_t$ directly
$$
  U_\alpha P_t f = \int_0^\infty e^{-\alpha s}P_s P_t f \,\mathrm{d}s = \int_0^\infty e^{-\alpha s} P_{s+t}f\,\mathrm{d}s
$$

The 1st identity involves an interchange

$$
  P_t U_\alpha f = P_t \int_0^\infty e^{-\alpha s} P_s f\,\mathrm{d}s = \int_0^\infty e^{-\alpha s}P_t P_s f\,\mathrm{d}s = \int_0^\infty e^{-\alpha s} P_{s+t} f\,\mathrm{d}s
$$

2. Only the first direction is shown as the other is similar

$$
\begin{align*}
  U_\alpha U_\beta f &= \int_0^\infty e^{-\alpha s} P_s U_\beta f\,\mathrm{d}s = \int_0^\infty e^{-\alpha s} P_s \int_0^\infty e^{-\beta t} P_t f\,\mathrm{d}t \\
  &= \int_0^\infty e^{-\alpha s} \int_0^\infty e^{-\beta t}P_s P_t f\,\mathrm{d}s\,\mathrm{d}t = \int_0^\infty \int_0^\infty e^{-\alpha s} e^{-\beta t} P_{s+t} f\,\mathrm{d}s\,\mathrm{d}t
\end{align*}
$$

3. Assume $\alpha < \beta$ as the case $\alpha = \beta$ is trivial. From the 2nd identity

$$
  U_\alpha U_\beta f = \int_0^\infty \int_0^\infty e^{-\alpha s} e^{-\beta t} P_{s+t} f\,\mathrm{d}s\,\mathrm{d}t
$$

The transformation $u = s + t, v = s$ maps $[0,\infty)^2$ one-to-one onto $\{(u,v)\in[0,\infty)^2 : u\geq v\}$. The inverse transformation is $s = v, t = u - v$ with Jacobian $-1$. This gives

$$
\begin{align*}
  U_\alpha U_\beta f &= int_0^\infty \int_0^u e^{-\alpha v} e^{-\beta(u - v)} P_u f\,\mathrm{d}v\,\mathrm{d}u \\
  &= \int_0^\infty \left(\int_0^u e^{(\beta - \alpha)v}\,\mathrm{d}v \right) e^{-\beta u} P_u f\,\mathrm{d}u \\
  &= \frac{1}{\beta - \alpha}\int_0^\infty [e^{(\beta - \alpha)u}] e^{-\beta u} P_u f,\mathrm{d}u \\
  &= \frac{1}{\beta - \alpha}\left(\int_0^\infty e^{-\alpha u} P_u f\,\mathrm{d}u -\int_0^\infty e^{-\beta u} P_u f\,\mathrm{d}u \right) \\
  &= \frac{1}{\beta - \alpha}(U_\alpha f - U_\beta f)
\end{align*}
$$

Note that $U_\beta f$ is finite since $\beta > 0$.

4. Suppose that $f\in\mathcal{C}_0$ and that $(x_i)_{i\in\mathbb{N}}$ is a sequence in $S$. Then $P_t f\in \mathcal{C}_0$ for $t\in[0,\infty)$. Hence if $x_n \xrightarrow{n\to\infty} x \in S$ then $e^{-\alpha t}P_t f(x_n) \xrightarrow{n\to\infty} e^{-\alpha t}P_t f(x)$ for each $t\in[0,\infty)$. By the dominated convergence theorem

$$
  U_\alpha f (x_n) = \int_0^\infty e^{-\alpha t}P_t f(x_n)\,\mathrm{d}t \xrightarrow{n\to\infty} \int_0^\infty e^{-\alpha t} P_t f(x)\,\mathrm{d}t = U_\alpha f(x)
$$

Hence $U_\alpha$ is continuous. Next suppose that $x_n \xrightarrow{n\to\infty} \infty$. This means that for every compact $C\subseteq S$, there exists $m\in\mathbb{N}_+$ such that $x_n \not\in C$ for $n > m$. Then $e^{-\alpha t} P_t f(x_n) \xrightarrow{n\to\infty} 0$ for each $t\in[0,\infty)$. Again by the dominated convergence theorem

$$
  U_\alpha f(x_n) = \int_0^\infty e^{-\alpha t} P_t f(x_n)\,\mathrm{d}t \xrightarrow{n\to\infty} 0
$$

Hence $U_\alpha f \in \mathcal{C}_0$.

5. Convergence is with respect to the supremum norm on $\mathcal{C}_0$. Suppose that $f\in\mathcal{C}_0$. Note first that with change of variables $s = \alpha t$

$$
  \alpha U_\alpha f = \int_0^\infty \alpha e^{-\alpha t} P_t f\,\mathrm{d}t = \int_0^\infty e^{-s} P_{s/\alpha}f\,\mathrm{d}s
$$

and hence

$$
\begin{align*}
  |\alpha U_\alpha f - f| &= \left| \int_0^\infty e^{-s}(P_{s/\alpha} f - f)\,\mathrm{d}s \right| \\
  \leq \int_0^\infty e^{-s} |P_{s/\alpha f - f}\,\mathrm{d}s \\
  \leq \int_0^\infty e^{-s} \lVert P_{s/\alpha} f - f \rVert\,\mathrm{d}s
\end{align*}
$$

It follows that

$$
  \lVert \alpha U_\alpha f - f \rVert \leq \int_0^\infty e^{-s} \lVert P_{s/\alpha} f - f \rVert\mathrm{d}s
$$

However, $\lVert P_{s\alpha} f - f \rVert \xrightarrow{\alpha\to\infty} 0$ and hence by the dominated convergence theorem

$$
  \int_0^\infty e^{-s}\lVert P_{s/\alpha} f - f \rVert\,\mathrm{d}s \xrightarrow{\alpha\to\infty} 0
$$
</details>
</MathBox>

#### Infinitesimal generator

<MathBox title='Infinitesimal generator' boxType='definition'>
The infinitesimal generator of the Markov process $\mathbf{X}$ is the operator $G:\mathcal{D}\to\mathcal{C}_0$ defined by

$$
  Gf := \lim_{t\downarrow 0}\frac{P_t f - f}{t}
$$

on the domain $\mathcal{D}\subseteq\mathcal{C}_0$ for which the limit exists. The limit is with respect to the supremum norm such that $f\in\mathcal{D}$ and $Gf = g$ implies $f,g\in\mathcal{C}_0$ and

$$
\left\lVert \frac{P_t f - f}{t} g \right\rVert = \sup\left\{ \left| \frac{P_t f(x) - f(x)}{t} - g(x) \right|: x\in S \right\} \xrightarrow{t\downarrow 0} 0
$$

In particular

$$
  Gf(x) = \lim_{t\downarrow 0} \frac{P_t f(x) - f(x)}{t} = \lim_{t\downarrow 0}\frac{\mathbb{E}[f(X_t)\;|\;X_0 = x] - f(x)}{t},\; s\in S
$$
</MathBox>

<MathBox title='' boxType='proposition'>
The domain $\mathcal{D}$ is a subspace of $\mathcal{C}_0$ and the generator $G$ is a linear operator on $\mathcal{D}$ satisfying

1. If $f\in\mathcal{D}$ and $c\in\mathcal{R}$ then $cf\in\mathcal{D}$ and $G(cf) = cGf$.
2. If $f,g\in\mathcal{D}$ then $f+g\in\mathcal{D}$ and $G(f+g) = Gf + Gg$

<details>
<summary>Proof</summary>

These properties follows from the linearity of $P_t$ for $t\in[0,\infty)$ and basic results on convergence

1. 
$$
  \frac{P_t(cf) - (cf)}{t} = c\frac{P_t f - f}{t} \xrightarrow{t\downarrow 0} cGf
$$

2.
$$
  \frac{P_t (f+g) - (f+g){t} = \frac{P_t f - f}{t} + \frac{P_t g - g}{t} \xrightarrow{t\downarrow 0} Gf + Gg
$$
</details>
</MathBox>

Note that $G$ is the (right) derivative at $0$ of the function $t\mapsto P_t f$. Because of the semigroup property, this differentiability property at $0$ implies differentiability at arbitrary $t\in[0,\infty)$.

<MathBox title='' boxType='proposition'>
If $f\in\mathcal{D}$ and $t\in[0,\infty)$, then $P_t f\in\mathcal{D}$ and the following derivative rules hold with respect to the supremum norm

1. Kolmogorov forward equation: $P'_t f = P_t Gf$
2. Kolmogorov backward equation: $P'_t f = GP_t f$

<details>
<summary>Proof</summary>

1. By assumption

$$
  \lim_{h\downarrow 0} \frac{P_h f - f}{h} = Gf
$$

Since $P_t$ is a bounded, linear operator on $\mathcal{C}_0$, it preserves limits, giving

$$
  \lim_{h\downarrow 0}\frac{P_t P_h f - P_t}{h} = \lim_{h\downarrow 0} \frac{P_{t+h} f - P_t f}{h} = P_t G f
$$

This proves the Kolmogorov forward equation for the derivative from the right. Since $t\mapsto P_t f$ is continuous, the result is also true for the two-sided derivative.

2. From the Kolmogorov forward equation

$$
  \lim_{h\to 0}\frac{P_t P_h f - P_t}{h} = \lim_{h\to 0} \frac{P_{t+h} f - P_t f}{h} = P_t G f
$$

By definition, this means that $P_t f \in\mathcal{D}$ and $GP_t f = P_t G f = P'_t f$.
</details>
</MathBox>

Infinitesimal generators allows us to construct a Markov process with desired properties, by which the transition operators $\mathbf{P} = \{P_t\}_{t\in[0,\infty)}$ are obtained from the initial value problem

$$
  P'_t = GP_t,\quad P_0 = I
$$

<MathBox title='' boxType='proposition'>
Suppose that $\alpha\in (0,\infty)$

1. If $f\in\mathcal{D}$ then $Gf\in\mathcal{C}_0$ and $f + U_\alpha G f = \alpha U_\alpha f$
2. If $f\in\mathcal{C}_0$ then $U_\alpha f \in\mathcal{D}$ and $f + GU_\alpha f = \alpha U_\alpha f$
3. $U_\alpha = (\alpha I - G)^{-1}:\mathcal{C}_0\to\mathcal{D}$
4. $G = \alpha I - U_\alpha^{-1}:\mathcal{D}\to\mathcal{C}_0$

<details>
<summary>Proof</summary>

1. By definition, if $f\in\mathcal{D}$ then $Gf\in\mathcal{C}_0$. Hence using the Kolmogorov equations and integrating by parts

$$
\begin{align*}
  f + U_\alpha G f &= f + \int_0^\infty e^{-\alpha t} GP_t f\,\mathrm{d}t = f + \int_0^\infty e^{-\alpha t} P'_t f\,\mathrm{d}t \\
  &= \left. f - e^{-\alpha t} P_t \right_0^\infty + \alpha\int_0^\infty + \alpha\int_0^\infty e^{-\alpha t}P_t f \,\mathrm{d}t
\end{align*}
$$

Note that $e^{-\alpha t} P_t f \xrightarrow{t\to\infty} 0$ while $P_0 f = f$. The last term is $\alpha U_\alpha f$.

2. From the 1st identity and the substitution $u = s + t$

$$
\begin{align*}
  P_t U_\alpha f &= \int_0^\infty e^{-\alpha s} P_{s+t}f\,\mathrm{d}s \\
  &= \int_t^\infty e^{-\alpha (u - t)} P_u f\,\mathrm{d}u \\
  &= e^{-\alpha t}\int_t^\infty e^{-\alpha u} P_u f\,\mathrm{d}u
\end{align*}
$$

Hence

$$
  \frac{P_t U_\alpha f - U_\alpha f}{t} = \frac{1}{t}\left[ e^{-\alpha t} \int_t^\infty e^{-\alpha u} P_u f\,\mathrm{d}u - U_\alpha f \right]
$$

Adding and substracting $e^{\alpha u} U_\alpha f$ and combining integrals gives

$$
  \frac{P_t U_\alpha f - U_\alpha f}{t} = \frac{1}{t}\left[ e^{\alpha t} \int_t^\infty e^{-\alpha u} P_u f\,\mathrm{d}u - e^{\alpha t} \int_0^\infty e^{-\alpha u} P_u f\,\mathrm{d}u \right] + \frac{e^{\alpha t} - 1}{t} U_\alpha f \\
  &= -e^{\alpha t}\frac{1}{t} \int_0^t e^{-\alpha s} P_s f\,\mathrm{d}s + \frac{e^{\alpha t} - 1}{t} U_\alpha f
$$

Since $s\mapsto P_s f$ is continuous, the first term converges to $-f$, and the second term converges to $\alpha U_\alpha f$ as $t\downarrow 0$.

3. From the 1st identity we have $\alpha U_\alpha - U_\alpha G = I \iff U_\alpha (\alpha I - G) = I$, and from the 2nd identity we have $\alpha U_\alpha - GU_\alpha = I \iff (\alpha I - G)U_\alpha = I$. 
4. This follows from the 3rd identity.
</details>
</MathBox>

### Examples and applications

#### Recurrence relations and differential equations

Markov processes can be viewed as stochastic counterparts of deterministic recurrence relations (discrete time) and differential equations (continuous time)

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{n\in\mathbb{N}}$ is a stochastic process with state space $(S,\mathcal{S})$ satisfying the recurrence relation

$$
  X_{n+1} = g(X_n),\; n\in\mathbb{N}
$$

where $g:S\to S$ is measurable. Then $\mathbf{X}$ is a homogenous Markov process with one-step transition operator $P$ given by $Pf = g\circ g$ for a measurable function $f:S\to\mathbb{R}$

<details>
<summary>Proof</summary>

Clearly $\mathbf{X}$ is determined by the initial state, and in fact $X_n = g^n (X_0)$ for $n\in\mathbb{N}$ where $g^n$ is the $n$-fold composition power of $g$. Therefore, the only possible source of randomness is in the initial state. The Markov and time homogenous properties simply follow from the trivial fact that $g^{m+n}(X_0) = g^n[g^m(X_0)]$ so that $X_{m+n} = g^n(X_m)$. That is, the state at time $m+n$ is completely determined by the state at time $m$ (regardless of the previous states) and the time increment $n$. In particular, $Pf(x) = \mathbb{E}[g(X_1)\;|\; X_0 = x] = f[g(x)]$ for measurable $f:S\to\mathbb{R}$ and $x\in S$. Note that for $n\in\mathbb{N}$, the $n$-step transition operator is given by $P^n f = f\circ g^n$.
</details>
</MathBox>

<MathBox title='Recurrence relation' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_n \}_{t\in[0,\infty)}$ is a stochastic process with state space $(\mathbb{R},\mathcal{R})$ satisfying the first-order differential equation

$$
  \frac{\mathrm{d}}{\mathrm{d}t}X_t = g(X_t)
$$

where $g:\mathbb{R}\to\mathbb{R}$ is Lipschitz continuous. Then $\mathbf{X}$ is a Feller Markov process.

<details>
<summary>Proof</summary>

Lipschitz continuity means that there exists a constant $k\in(0,\infty)$ such that $|g(y) - g(x)|\leq k|x-y|$ for $x,y\in\mathbb{R}$. This is a standard condition on $g$ that guarantees the existence of a solution to the differential equation on $[0,\infty)$. Therefore, the only source of randomness in the process comes from the initial value $X_0$. Let t\mapsto X_t(x) denote the unique solution with $X_0(x) = x$ for $x\in\mathbb{R}$. The Markov and time homogeneous properties follow from the fact that $X_{t+s}(x) = X_t(X_s(x))$ for $x,t\in[0,\infty)$ and $x\in S$. That is, the state at time $t+s$ depends only on the state at time $s$ and the time increment $t$. The Feller properties follow from the continuity of $t\mapsto X_t(x)$ and the continuity of $x\mapsto X_t(x)$. The latter is the continuous dependence on the initial value, guaranteed by the assumption on $g$. Note that the transition operator is given by $P_t f(x) = f[X_t (x)]$ for a measurable function $f:S\to\mathbb{R}$ and $x\in S$.
</details>
</MathBox>

The deterministic process $\mathrm{d}X_t = g(X_t)\mathrm{d}t$ can be turned into a diffusion processs, with Markov property, by adding a stochastic term related to a Wiener process (Brownian motion).


## Processes with independent, stationary increments

<MathBox title='Independent and stationary increments' boxType='definition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process adapted to $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T}$. Then for all $s,t\in T$ with $s\leq t$, the process $\mathbf{X}$ is said to have
1. *Independent increments* if $X_t - X_s$ is independent of $\mathcal{F}_s$
2. *Stationary increments* if $X_t - X_s$ has the same distribution as $X_{t-s} - X_0$

Processes with independent and stationary increments are random walk processes. In continuous time, such processes are known as Lévy processes, which also have a third property

3. *Continuity in probability*: for any $\epsilon > 0$ and $t\geq 0$ then $\lim_{h\to 0} \mathbb{P}(|X_{t+h} - X_t|>\epsilon) = 0$
</MathBox>

Stationary increments means that the probability distribution of any increment $X_t - X_s$ depends only the length $t - s$ of the time interval. Several stochastic processes are characterized by specific distributions of their stationary increments
- Wiener process: $X_t - X_s$ has a normal distribution with $\mathbb{E}(X_t - X_s) = 0$ and $\mathrm{Var}(X_t - X_s) = t - s$
- Poisson process:  $X_t - X_s$ has a poisson distribution with $\mathbb{E}(X_t - X_s) = \gamma(t - s)$ where $\gamma > 0$ is the intensity of the process.
- Cauchy process: $X_t - X_s$ has a Cauchy distribution with density $f(x, t) = \frac{1}{\pi}\frac{t}{x^2 + t^2}$

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process with independent, stationary increments, and let $Q$ denote the distribution of $X_t - X_0$. Then

$$
  Q_s * Q_t = Q_{s+t},\; s,t\in T
$$

<details>
<summary>Proof</summary>

Note that $Q_s$ is the distribution of $X_s - X_0$, and by the stationary property, $Q_t$ is the distribution of $X_{s+t} - X_s$. By the independence property, $X_s - X_0$ and $X_{s+t} - X_s$ are independent. Hence $Q_s * Q_t$ is the distribution of $[X_s - X_0] + [X_{s+t} - X_{s}] = X_{s+t} - X_0$. By definition, this variable has distribution $Q_{s+t}$.
</details>
</MathBox>

The collection of increment distributions $\mathbf{Q} = \{Q_t\}_{t\in T}$ forms a semi-group with convolution as the operator.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a Lévy process, and let

$$
  m(t) = \mathbb{E}(X_t) \quad v(t) = \mathrm{var}(X_t)
$$

1. If $\mu_0 = \mathbb{E}(X_0) \in\mathbb{R}$ and $\mu_1 = \mathbb{E}(X_1)\in\mathbb{R}$ then $m(t) = \mu_0 + (\mu_1 + \mu_0)t$
2. If in addition $\sigma_0^2 = \mathrm{var}(X_0)\in (0,\infty)$ and $\sigma_1^2 = \mathrm{var}(X_1)\in (0, \infty)$ then $v(t) = \sigma_0^2 + (\sigma_1^2 + \sigma_0^2)t$

<details>
<summary>Proof</summary>

Let $m_0 (t) = \mathbb{E}(X_t - X_0) = m(t) - \mu_0$ and $v_0 (t) = \mathrm{var}(X_t - X_0) = v(t) - \sigma_0^2$ denote the mean and variance functions for the centered process $\{ X_t - X_0 \}_{t\in T}$. Let $s,t\in T$

1. From the additive property of expected value and the stationary property
$$
\begin{align*}
  m_0 (t + s) &= \mathbb{E}(X_{t+s} - X_0) \\
  &= \mathbb{E}[(X_{t+s} - X_s) + (X_s - X_0)] \\
  &= \mathbb{E}(X_{t+s} - X_s) + \mathbb{E}(X_s - X_0) \\
  &= m_0 (t) + m_0 (s)
\end{align*}
$$

1. From the additive property of variance for independent variables and the stationary property
$$
\begin{align*}
  v_0 (t + s) &= \mathrm{var}(X_{t+s} - X_0) \\
  &= \mathrm{var}[(X_{t+s} - X_s) + (X_s - X_0)] \\
  &= \mathrm{var}(X_{t+s} - X_s) + \mathrm{var}(X_s - X_0) \\
  &= v_0 (t) + v_0 (s)
\end{align*}
$$

This shows that $m_0$ and $v_0$ satisfy the Cauchy equation. By the Lévy properties there exists $a\in\mathbb{R}$ and $b^2\in(0,\infty)$ such that $m_0(t) = at$ and $v_0(t) = b^2 t$. Substituting $t=1$ gives $a = \mu_1 - \mu_0$ and $b^2 = \sigma_1^2 - \sigma_0^2$ producing the desired result.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
A discrete time process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ has independent increments if and only if there exists a sequence of independent, real-valued random variables $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ such that

$$
  X_n = \sum_{i=0}^n U_i
$$

In addition, $\mathbf{X}$ has stationary increments if and only if $(U_n)_{n\in\mathbb{N}}$ are indentically distributed.

<details>
<summary>Proof</summary>

Suppose first that $\mathbf{U}$ is a sequence of independent, real-valued random variables, and define $X_n = \sum_{i=0}^n U_i$ for $n\in\mathbb{N}$. Note that $\mathcal{F}_n = \sigma\{X_i\}_{i=0}^n = \sigma\{U_i\}_{i=0}^n$. If $k, n\in\mathbb{N}$ with $k\leq n$, then $X_n - X_k = \sum_{i=k+1}^n U_i$ which is independent of $\mathcal{F}_k$ by the independence assumption on $\mathbf{U}$. Hence $\mathbf{X}$ has independent increments. Suppose in addition that  $(U_n)_{n\in\mathbb{N}}$ are identically distributed. Then the increment $X_n - X_k$ above has the same distribution as $\sum_{i=1}^{n-k} U_i = X_{n-k} - X_0$. Hence $\mathbf{X}$ has stationary increments.

Conversely, suppose that $\mathbf{X}$ has independent increments. Let $U_0 = X_0$ and $U_n = X_n - X_{n-1}$ for $n\in\mathbb{N}$ such that $X_n = \sum_{i=0}^n U_i$ and $\mathcal{F}_n = \sigma\{X_i\}_{i=0}^n = \sigma\{U_i\}_{i=0}^n$. Since $\mathbf{X}$ has independent increments, $U_n$ is indepedent of $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$ making $(U_n)_{n\in\mathbb{N}_+}$ mutually independent. If in addition, $\mathbf{X}$ has stationary increments, $U_n = X_n - X_{n-1}$ has the same distribution as $X_1 - X_0 = U_1$ for $n\in\mathbb{N}_+$. Hence $(U_n)_{n\in\mathbb{N}}$ are identically distributed. 
</details>
</MathBox>

### Relation to Markov processes

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a process with independent, stationary increments, and let $Q$ denote the distribution of $X_t - X_0$. Then $\mathbf{X}$ is a time-homogeneous Markov process with transition operator

$$
  P_t f(x) = \int_S f(x+y)Q_t (\mathrm{d}y),\; f\in\mathcal{B}
$$

<details>
<summary>Proof</summary>

Since $X_{s+t} - X_{s}$ is independent of $\mathcal{F}_s$ it follows that

$$
  \mathbb{E}[f(X_{s+t})|\mathcal{F}_s] = \mathbb{E}[f(X_{s+t} - X_s + X_s)|\mathcal{F}_s] = \mathbb{E}[f(X_{s+t})|X_s]
$$

By the stationary property

$$
  \mathbb{E}[f(X_{s+t}|X_s = x)] = \int_S f(x+y)Q_t(\mathrm{d}y)\; x\in S
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that for positive $t\in T$ is a process with independent, the distribution $Q_t$ has probability density function $g_t$ with respect to the reference measure $\lambda$. Then the transition density is

$$
  p_t (x,y) = g_t (y - x),\; f\in\mathcal{B}
$$

By the property of $Q_t$, it follows that $g_s * g_t = g_{s+t}$.
</MathBox>

<MathBox title='Lévy processes are Feller Markov' boxType='proposition'>
If $Q_t \xrightarrow{t\downarrow 0} Q_0$ (Lévy property) then $\mathbf{X}$ is a Feller Markov process.
</MathBox>

#### Random walk

<MathBox title='Markov random walk' boxType='definition'>
Suppose that $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ is a sequence of indepedent, real-valued random variables, with $(U_n)_{n\in\mathbb{N}}$ identically distributed with common distribution $Q$. Then the partial sum process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ associated with $\mathbf{U}$ is a time homogeneous Markov process with one-step transition kernel

$$
  P(x, A) = Q(A - x),\; x\in S, A\in\mathcal{S}
$$

More generally, the $n$-step transition kernel is 

$$
  P^n (x, A) = Q^{*n}(A - x)
$$

This Markov process is known as a random walk where $U_n$ represents the distance on the real in which the process moves at time $n$. If $Q$ has probability density function $g$ with respect to the reference measure $\lambda$, the one-step transition density is

$$
  p(x, y) = g(y - x),\; x,y\in S
$$
</MathBox>

<MathBox title='' boxType='proposition'>
For $t\in[0,\infty)$, let $g_t$ denoted the probability density function of the Poisson distribution with parameter $t$, i.e.

$$
  g_t (n) = e^{-1} \frac{t^n}{n!},\; n\in\mathbb{N}
$$

Let $p_t(x,y) = g_t (y - x)$ for $x,y\in\mathbb{N}$. Then $\{p_t\}_{t\in[0,\infty)}$ is the collection of transition densities for a Feller semigroup on $\mathbb{N}$.

<details>
<summary>Proof</summary>

We need to show that $\{g_t\}_{t\in[0,\infty)}$ satisfies the semi-group property, and that the continuity result holds. By the properties of the Poisson distribution, if $U, V$ are independent Poisson variables with parameters $s,t\in[0,\infty)$, respectively, then $U+V$ has a Poisson distribution with parameter $s + t$. Hence $g_s * g_t = g_{s+t}$. Moreover $g_t \xrightarrow{t\downarrow 0} g_0$. 
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
For $t\in[0,\infty)$, let $g_t$ denoted the probability density function of the normal distribution with mean $0$ and variance $t$, i.e.

$$
  g_t(z) = \frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2t}},\; z\in\mathbb{R}
$$

and let $p_t(x,y) = g_t (y - x)$ for $x,y\in\mathbb{R}$. Then $\{p_t\}_{t\in[0,\infty)}$ is the collection of transition densities for a Feller semigroup on $\mathbb{N}$.

<details>
<summary>Proof</summary>

We need to show that $\{g_t\}_{t\in[0,\infty)}$ satisfies the semi-group property, and that the continuity result holds. By the properties of the normal distribution, if $U, V$ are independent normal variables with mean $0$ and variances $s,t\in(0,\infty)$ respectively, then $U+V$ is normally distributed with mean $0$ and parameter $s + t$. Hence $g_s * g_t = g_{s+t}$. Moreover, the normal distribution with variance $t$ converges to a point mass at $0$ as $t\downarrow 0$. 
</details>
</MathBox>

## Martingale

A martingale is a stochastic process for which the conditional expectation of the next value is equal to the present value.

<MathBox title='Martingale' boxType='definition'>
A stochastic process $\mathbf{X}$ is a *martingale* with respect to a filtration $\mathscr{F}$ if $\mathbb{E}(X_t|\mathcal{F}_s) = X_s$ for all $s, t\in T$ with $s\leq t$.

If the equality in the martingale conditions does not hold, then for  for all $s, t\in T$ with $s\leq t$, the process $\mathbf{X}$ is (with respect to $\mathscr{F}$)
1. *sub-martingale* $\mathbb{E}(X_t|\mathcal{F}_s) \geq X_s$ for all $s, t\in T$ with $s\leq t$.
2. *super-martingale* $\mathbb{E}(X_t|\mathcal{F}_s) \leq X_s$ for all $s, t\in T$ with $s\leq t$.

If $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is discrete, then for all $n\in\mathbb{N}$ the process $\mathbf{X}$ is (with respect to $\mathscr{F}$)
1. martingale if and only if $\mathbb{E}(X_{n+1}|\mathcal{F}_n) = X_n$
2. sub-martingale if and only if $\mathbb{E}(X_{n+1}|\mathcal{F}_n) \geq X_n$
3. super-martingale if and only if $\mathbb{E}(X_{n+1}|\mathcal{F}_n) \leq X_n$

<details>
<summary>Details</summary>

To show the bicondationality in the discrete case, suppose that $k,n\in\mathbb{N}$ with $k< n$. Then $k\leq n - 1$ so $\mathcal{F}_k\subseteq\mathcal{F}_{n-1}$ and hence

$$
\begin{align*}
  \mathbb{E}(X_n | \mathcal{F}_k) &= \mathbb{E}[\mathbb{E}(X_n|\mathcal{F}_{n-1})] \\
  &= \mathbb{E}(X_{n-1}|\mathcal{F}_k)
\end{align*}
$$
</details>
</MathBox>

In gambling terms, martingale, sub-martingale and super-martingale processes are abstractions of fair, favourable or unfair games (from the gambler's perspective).

<MathBox title='Martingales are preserved under coarser filtrations' boxType='proposition'>
Suppose that the stochastic process $\mathbf{X}$ is adapted to the filtration $\mathscr{F}$, and $\mathscr{F}\subseteq\mathscr{G}$, i.e. $\mathscr{G}$ is finer than $\mathscr{F}$. If $\mathbf{X}$ is a (sub/super-)martingale relative to $\mathscr{G}$, then $\mathbf{X}$ is a (sub/super-)martingale process relative to $\mathscr{F}$.

In particular, if $\mathbf{X}$ is a (sub/super-)martingale relative to some filtration, then $\mathbf{X}$ is also a (sub/super-)martingale relative to the natural filtration $\mathcal{F}^0$

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s\leq t$. Note that $\mathbf{X}$ is adapted to $\mathscr{G}$, since $\mathbf{X}$ is adapted to $\mathscr{F}$ and $\mathscr{F}\subseteq\mathscr{G}$. Appyling the tower and monotonicity of conditional expected value we have that

1. If $\mathbf{X}$ is a martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t|\mathcal{G}_s)|\mathcal{F}_s] \\
  &= \mathbb{E}(X_s|\mathcal{F_s}) = X_s
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t|\mathcal{G}_s)|\mathcal{F}_s] \\
  &\geq \mathbb{E}(X_s|\mathcal{F_s}) = X_s
\end{align*}
$$

3. If $\mathbf{X}$ is a super-martingale with respect to $\mathscr{G}$ then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F_s}) &= \mathbb{E}[\mathbb{E}(X_t|\mathcal{G}_s)|\mathcal{F}_s] \\
  &\leq \mathbb{E}(X_s|\mathcal{F_s}) = X_s
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Linear properties of martingales' boxType='proposition'>
For the processes $\mathbf{X} = \{X_t \}_{t\in T}$ and $\mathbf{Y} = \{Y\}_{t\in T}$, let $\mathbf{X} + \mathbf{Y} = \{ X_t + Y_t \}_{t\in T}$.

1. If $\mathbf{X}$ and $\mathbf{Y}$ are (sub/super-)martingales with respect to $\mathscr{F}$ then $\mathbf{X}+\mathbf{Y}$ is a (sub/super-)martingale with respect to $\mathscr{F}$.

For the constant $c\in\mathbb{R}$, let $c\mathbf{X} = \{ cX_t \}_{t\in T}$.

2. If $\mathbf{X}$ is a martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is also a martingale with respect to $\mathscr{F}$.
3. If $\mathbf{X}$ is a sub-martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is a sub-martingale if $c > 0$, a super-martingale if $c < 0$, and a martingale if $c = 0$.
4. If $\mathbf{X}$ is a super-martingale with respect to $\mathscr{F}$, then $c\mathbf{X}$ is a super-martingale if $c > 0$, a sub-martingale if $c < 0$, and a martingale if $c = 0$.

The linearity properties implies that the collection of martingales with respect to a fixed filtration $\mathscr{F}$ forms a vector space.

<details>
<summary>Proof</summary>

The additive property (1) follows from the additive property of conditional expectation. Note that $\mathbb{E}(|X_t + Y_t|)\leq\mathbb{E}(|X_t|) + \mathbb{E}(|Y_t|) < \infty$ for $t\in T$. For $s, t\in T$ with $s\leq t$ we have

$$
  \mathbb{E}(X_t + Y_t | \mathcal{F}_s) = \mathbb{E}(X_t|\mathcal{F}_s) + \mathbb{E}(Y_t |\mathcal{F}_s)
$$

The scalar properties (2, 3, 4) follows from the scalar property of conditional expectation. Note that $\mathbb{E}(|cX_t|) = |c|\mathbb{E}(|X_t|)\leq\infty$. For $s, t\in T$ with $s\leq t$ we have

$$
  \mathbb{E}(cX_t | \mathcal{F}_s) = c\mathbb{E}(X_t | \mathcal{F}_s)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that the process $\mathbf{X}$ takes values in an interval $S\subseteq\mathbb{R}$ and that $g:S\to\mathbb{R}$ is convex with $\mathbb{E}[|g(X_t)|]< \infty$ for $t\in T$. Then $g(\mathbf{X}) = \{g(X_t)\}_{t\in T}$ is a sub-martingale with respect to $\mathscr{F}$ if either

1. $\mathbf{X}$ is a martingale.
2. $\mathbf{X}$ is a sub-martingale and $g$ is also increasing.

Since $x \mapsto |x|^k$ is convex on $\mathbb{R}$ for $k\in[1,\infty)$, it follows that $|\mathbf{X}|^k = \{|X_t|^k \}_{t\in T}$ is a sub-martingale if $\mathbf{X}$ is a martingale and $\mathbb{E}\left(|X_t|^k \right)< \infty$ for $t\in T$. 

In particular, if $\mathbf{X}$ is a sub-martingale, then $\mathbf{X}^+ = \{X_t^+\}_{t\in T}$ is also a sub-martingale since $x\mapsto x^+ = \max\{x, 0\}$ is increasing and convex on $\mathbb{R}$.

<details>
<summary>Proof</summary>

Let $s,t\in T$ with $s\leq t$. Since $g$ is convex, it follows from Jensen's inequality that

$$
  \mathbb{E}[g(X_t)|\mathcal{F}_s] \geq g[\mathbb{E}(X_t|\mathcal{F}_s)]
$$

1. Since $\mathbf{X}$ is a martingale, then $\mathbb{E}(X_t | \mathscr{F}_s) = X_s$ and substituting into the inequality above sbows that $g(\mathbf{X})$ is sub-martingale

$$
  \mathbb{E}[g(X_t)|\mathcal{F_s}] \geq g(X_s) 
$$

2. Since $\mathbf{X}$ is a sub-martingale, then $\mathbb{E}(X_t |\mathcal{F}_t) \geq X_s$. Since $g$ is also increasing, then $g[\mathbb{E}(X_t|\mathcal{F}_s)]\geq g(X_s)$. Substituting into the inequality above shows that $g(\mathbf{X})$ is a sub-martingale

$$
  \mathbb{E}[g(X_t)|\mathcal{F}_s] \geq g(X_s)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in[0,\infty)}$ is a continuous-time process adapted to $\mathscr{F} = \{ \mathcal{F}_t\}_{t\in[0,\infty)}$. Let $\{ t_n\}_{n\in\mathbb{N}}\subset [0,\infty)$ be a strictly increasing sequence of time points with $t_0$ and define $Y_n = X_{t_n}$ nad $\mathcal{G}_n = \mathcal{F}_{t_n}$ for $n\in\mathbb{N}$. If $\mathbf{X}$ is a (sub/super)-martingale with respect to $\mathscr{F}$, then $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a (sub/super-martingale) with respect to $\mathscr{G}$.

<details>
<summary>Proof</summary>

Since $\{t_n\}_{n\in\mathbb{N}}$ is increasing, $\mathscr{G}$ is a discrete-time filtration. Next, $\mathbb{E}(|Y_n|) = \mathbb{E}(|X_{t_n}|) < \infty$. Finally, suppose that $\mathbf{X}$ is a martingale and $n, k\in \mathbb{N}$ with $k< n$. Then $t_k < t_n$ so

$$
  \mathbb{E}(Y_n | \mathcal{G}_k) = \mathbb{E}(X_{t_n} | \mathcal{F}_{t_k}) = X_{t_k} = Y_k
$$

Hence $\mathbf{Y}$ is also a martingale. The proof is analogous for sub- and super-martingales, but with inequalities replacing the second equality above.
</details>
</MathBox>

### Martingale transform

<MathBox title='Martingale transform' boxType='proposition'>
Suppose that the discrete process $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is adapted to the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ and that $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ is predictable relative to $\mathscr{F}$, i.e. $Y_n$ is measurable to $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$. The transform of $\mathbf{X}$ by $\mathbf{Y}$ is the process $\mathbf{Y}\cdot\mathbf{X}$ defined by

$$
  (\mathbf{Y}\cdot\mathbf{X})_n = X_0 + \sum_{k=1}^n Y_k (X_k - X_{k-1})
$$

1. If $\mathbf{X}$ is a martingale relative to $\mathscr{F}$ then $\mathbf{Y}\cdot\mathbf{X}$ is also a martingale relative to $\mathscr{F}$.
2. If $\mathbf{X}$ is sub-martingale relative to $\mathscr{F}$ and $\mathbf{Y}$ is non-negative, then $\mathbf{Y}\cdot\mathbf{X}$ is also a sub-martingale relative to $\mathscr{F}$.
3. If $\mathbf{X}$ is a super-martingale relative to $\mathscr{F}$ and $\mathbf{Y}$ is non-negative, then $\mathbf{Y}\cdot\mathbf{X}$ is also a super-martingale relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Suppose that $|Y_n|\leq c\in(0,\infty)$ for $n\in\mathbb{N}$, then

$$
\begin{align*}
  \mathbb{E}\left[|(\mathbf{Y}\cdot\mathbf{X})_n| \right] \leq \mathbb{E}(|X_0|) + c\sum_{k=1}^n \left[\mathbb{E}(|X_k|) + \mathbb{E}(|X_{k+1}|) \right] \\
  &< \infty
\end{align*}
$$

Since $(\mathbf{Y}\cdot\mathbf{X})_n$, $Y_{n+1}$ and $X$ are measurable with respect to $\mathcal{F}_n$ for $n\in\mathbb{N}$, it follows that

$$
\begin{align*}
  \mathbb{E}\left[ (\mathbf{Y}\cdot\mathbf{X})_{n+1} |\mathcal{F}_{n} \right] &= \mathbb{E}\left[(\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}(X_{n+1} - X_n)|\mathcal{F}_n \right] \\
  &= (\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}\mathbb{E}(X_{n+1} - X_n |\mathcal{F}_n) \\
  &= (\mathbf{Y}\cdot\mathbf{X})_n + Y_{n+1}\left[\mathbb{E}(X_{n+1}|\mathcal{F}_n) - X_n \right]
\end{align*}
$$
</details>
</MathBox>

### Doob decomposition

<MathBox title='Doob decomposition theorem' boxType='theorem'>
Suppose that the discrete process $\mathbf{X} = \{ X_n\}_{n\in\mathbb{N}}$ is adapted to the filtration $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$. Then there is a unique decomposition $\mathbf{X} = \mathbf{Y} + \mathbf{Z}$ where $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$ and $\mathbf{Z} = \{Z_n\}_{n\in\mathbb{N}}$ is predictable relative to $\mathscr{F}$.

1. If $\mathbf{X}$ is a sub-martingale relative to $\mathscr{F}$, then $\mathbf{Z}$ is increasing.
2. If $\mathbf{X}$ is a super-martingale relative to $\mathscr{F}$, then $\mathbf{Z}$ is decreasing.

<details>
<summary>Proof</summary>

Define $Z_0 = 0$ and for $n\in\mathbb{N}_+$

$$
  Z_n = \sum_{k=1}^n \left[\mathbb{E}(X_k | \mathcal{F}_{k-1} - X_{k-1} \right]
$$

Then $Z_n$ is measurable with respect to $\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$, so $\mathbf{Z}$ is predictable with respect to $\mathscr{F}$. Define for $n\in\mathbb{N}_+$

$$
\begin{align*}
  Y_n &= X_n - Z_n \\
  &= X_n - \sum_{k=1}^n \left[\mathbb{E}(X_k | \mathcal{F}_{k-1} - X_{k-1}) \right]
\end{align*}
$$

Then $\mathbb{E}(|Y_n|) < \infty$ and trivially $X_n = Y_n + Z_n$ for $n\in\mathbb{N}$. Next we show that $\mathbf{Y}$ is martingale

$$
  \mathbb{E}(Y_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_{n+1}|\mathcal{F}_n) - Z_{n+1} \\
  &= \mathbb{E}(X_{n+1}|\mathcal{F}_n) - \sum_{k=1}^{n+1} \left[\mathbb{E}(X_k | \mathcal{F}_{k-1} - X_{k-1} \right] \\
  &= X_n - \sum_{k=1}^n \left[\mathbb{E}(X_k |\mathcal{F}_{k-1}) - X_{k-1} \right] = Y_n
$$

It remains to prove the uniqueness of the decomposition. Suppose that $\mathbf{X}$ has the decomposition in terms of $\mathbf{Y}$ and $\mathbf{Z}$ given in the theorem. Since $\mathbf{Y}$ is a martingale and $\mathbf{Z}$ is predictable

$$
\begin{align*}
  \mathbb{E}(X_n - X_{n-1} | \mathcal{F}_{n-1}) &= \mathbb{E}(Y_n | \mathcal{F}_{n-1}) - \E(Y_{n-1} | \mathcal{F}_{n-1}) + \E(Z_n | \mathcal{F}_{n-1}) - \E(Z_{n-1} | \mathcal{F}_{n-1}) \\ 
  &= Y_{n-1} - Y_{n-1} + Z_n - Z_{n-1} \\
  &= Z_n - Z_{n-1}, \quad n \in \mathbb{N}_+
\end{align*}
$$

Since $Z_0 = 0$, then $\mathbf{X}$ uniquely determines $\mathbf{Z}$. Finally, since $Y_n = X_n - Z_n$ for $n\in\mathbb{N}$, then $\mathbf{X}$ also uniquely determines $\mathbf{Z}$.

1. If $\mathbf{X}$ is a sub-martingale, then $\mathbb{E}(X_n|\mathcal{F}_{n-1}) - X_{n-1} \geq 0$ for $n\in\mathbb{N}_+$ so $\mathbf{Z}$ is increasing.
2. If $\mathbf{X}$ is a super-martingale, then $\mathbb{E}(X_n|\mathcal{F}_{n-1}) - X_{n-1} \leq 0$ for $n\in\mathbb{N}_+$ so $\mathbf{Z}$ is decreasing.
</details>
</MathBox>

### Stopping time

#### Optional stopping

Doob's theorem states that stopping a martingale at random time $\tau$ does not alter the martingale property, provided the decision about when to stop is solely based on information available up to $\tau$. 

<MathBox title="Doob's optional stopping theorem" boxType='theorem'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\rho, \tau \in T$ are bounded stopping times relative to $\mathscr{F}$ with $\rho\leq\tau$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau | \mathcal{F}_p) = X_\rho$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau | \mathcal{F}_p) \geq X_\rho$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau | \mathcal{F}_p) \leq X_\rho$

<details>
<summary>Proof</summary> 

**Discrete time**
1. Suppose that $\tau\leq k\in\mathbb{N}_+$ and let $A\in\mathcal{F}_\tau$. For $j\in\mathbb{N}$ with $j\leq k$, it follows that $A\cap \{\tau = j\}\in\mathcal{F}_j$. Thus, by the martingale property

$$
  \mathbb{E}(X_k;A\cap\{\tau = j}) = \mathbb{E}(X_j;A\cap\{\tau = j}) = \mathbb{E}(X_\tau; A\cap\{\tau = j \})
$$

Since $k$ is an upper bound on $\tau$, the events $A\cap\{\tau = j \}$ partition $A$ for $j = 0, 1,\dots, k$. Summing the equation over $j$ gives $\mathbb{E}(X_k; A) = \mathbb{E}(X_\tau; A)$. By definition of conditional expectation $\mathbb{E}(X_k | \mathcal{F}_\tau) = X_\tau$. Since $k$ is also an upper bound for $\rho$, it follows that $\mathbb{E}(X_k | \mathcal{F}_\rho) = X_\rho$. Using the tower property we get

$$
\begin{align*}
  X_\rho &= \mathbb{E}(X_k | \mathcal{\rho}) = \mathbb{E}[\mathbb{E}(X_k | \mathcal{F}_\rho)|\mathcal{F}_\tau] \\
  &= \mathbb{E}[\mathbb{E}(X_k|\mathcal{F}_\tau)|\mathcal{F}_\rho] = \mathbb{E}(X_\tau|\mathcal{F}_\rho)
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale, then by Doob's decomposition theorem, $X_n = Y_n + Z_n$ for $n\in\mathbb{N}$ where $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$ and $\mathbf{Z} = \{Z_n \}_{n\in\mathbb{N}}$ is increasing and is predictable relative to $\mathscr{F}$

$$
  \mathbb{E}(X_\tau | \mathcal{F}_\rho) = \mathbb{E}(Y_\tau | \mathcal{F}_\rho) + \mathbb{E}(Z_\tau | \mathcal{F}_\rho)
$$

Since $\mathbb{E}(Y_\tau | \mathcal{F}_\rho) = Y_\rho$ by the first condition and since $\mathbf{Z}$ is increasing, $\mathbb{E}(Z_\tau | \mathcal{F}_\rho) \geq\mathbb{E}(Z_\rho | \mathcal{F}_\rho) = Z_\rho$. Hence $\mathbb{E}(X_\tau | \mathcal{F}_\rho) \geq X_\rho$.

3. The proof when $\mathbf{X}$ is a super-martingale is same as for when $\mathbf{X}$ is a sub-martingale, except that the process $\mathbf{Z}$ is decreasing.

**Continuous time**

Note that in continuous time, the proofs when $\mathbf{X}$ is a sub or super-martingale is the same as in discrete time.

Suppose that $\mathbf{X}$ is a martingale. We need to show that $\mathbb{E}(X_\tau; A) = \mathbb{E}(X_\rho; A)$ for every $A\in\mathcal{F}_\rho$. Let $\rho_n = \lceil 2^n \rho \rceil / 2^n$ and $\tau_n = \lceil 2^n \tau \rceil / 2^n$ for $n\in\mathbb{N}$. The stopping times $\rho_n$ and $\tau_n$ take values in a countable set $T_n$ for each $n\in\mathbb{N}$ and $\rho_n \xrightarrow{n\to\infty}\rho$ and $\tau_n\xrightarrow{n\to\infty}\tau$. The process $\{ X_t \}_{t\in T_n}$ is a discrete-time martingale for each $n\in\mathbb{N}$. By the right continuity of $\mathbf{X}$, 

$$
  X_{\rho_n} \xrightarrow{n\to\infty} X_\rho \quad X_{\tau_n}\xrightarrow{n\to\infty}X_\tau
$$

Suppose next that $\tau\leq c$ where $c\in(0,\infty)$ so that $\rho\leq c$ also. Then $\rho_n \leq c+1$ and $\tau_n \leq c+1$ for $n\in\mathbb{N}$ so the discrete stopping times are uniformly bounded. From the discrete version of the theorem $X_{\rho_n} = \mathbb{E}(X_{c+1} | \mathcal{F}_{\rho_n})$ adn $X_{\tau_n} = \mathbb{E}(X_{c+1}|\mathcal{F}_{\tau_n})$ for $n\in\mathbb{N}$. It follows that the sequences $\{ X_{\rho_n} \}_{n\in\mathbb{N}}$ and $\{ X_{\tau_n} \}_{n\in\mathbb{N}}$ are uniformly integrable and hence $X_{\rho_n}\xrightarrow{n\to\infty} X_\rho$ and $X_{\tau_n}\xrightarrow{n\to\infty} X_\tau$ in mean as well as with probability $1$. 

Let $A\in\mathcal{F}_p$. Since $\rho\leq\rho_n$, it follows that $\mathcal{F}_\rho \subseteq \mathcal{F}_{\rho_n}$ and thus $A\in\mathcal{F}_{\rho_n}$ for each $n\in\mathbb{N}$. By the theorem in discrete time

$$
  \mathbb{E}(X_{\tau_n};A) = \mathbb{E}(X_{\rho_n}; A)
$$

Letting $n\to\infty$ gives $\mathbb{E}(X_\tau;A) = \mathbb{E}(X_\rho;A)$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\rho, \tau \in T$ are bounded stopping times relative to $\mathscr{F}$ with $\rho\leq\tau$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau) = \mathbb{E}(X_\rho)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau ) \geq \mathbb{E}(X_\rho)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau) \leq \mathbb{E}(X_\rho)$

<details>
<summary>Proof</summary> 

Recall that $\mathbb{E}(X_\tau) = \mathbb{E}[\mathbb{E}(X_\tau | \mathcal{F}_)]$, so the results follow directly from the Doob's optional stopping theorem.
</details>
</MathBox>

#### Stopped martingale

<MathBox title='Stopped process' boxType='definition'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\tau \in T_\infty$ is a stopping time relative to $\mathscr{F}$. The stopped process $\mathbf{X}^\tau = \{X_t^\tau\}_{t\in[0,\infty)}$ is defined by

$$
  X_t^\tau = X_{t\wedge \tau} = \begin{cases} 
    X_t,\quad t < \tau \\
    X_\tau,\quad t\geq \tau
  \end{cases}
$$

<details>
<summary>Details</summary> 

In continuous times, the standard assumptions ensure that $\mathbf{X}^\tau$ is a valid stochastic process and is adapted to $\mathscr{F}$. That is, $X_t^\tau$ is measurable with respect to $\mathcal{F}_t$ for each $t\in[0,\infty)$. Moreover, $\mathbf{X}^\tau$ is also right continuous and has left limits.
</details>
</MathBox>

<MathBox title='Elementary stopping theorem' boxType='theorem'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\tau \in T$ is a stopping times relative to $\mathscr{F}$

1. If $\mathbf{X}$ is a martingale then so is $\mathbf{X}^\tau$
2. If $\mathbf{X}$ is a sub-martingale then so is $\mathbf{X}^\tau$
3. If $\mathbf{X}$ is a super-martingale then so is $\mathbf{X}^\tau$

<details>
<summary>Proof</summary> 

If $s,t\in T$ with $s\leq t$ then $\tau\wedge s$ and $\tau\wedge t$ are bounded stopping times with $\tau\wedge s\leq \tau\wedge t$. The results follow directly from the optional stopping theorem.

In discrete time, the theorem can be proved using the martingale transform. Suppose that $T=\mathbb{N}$ and define the process $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ by

$$
  Y_n = \mathbf{1}(\tau\geq n) = 1 - \mathbf{1}(\tau\leq n-1)
$$

which is bounded and nonnegative. By the definition of a stopping time, $\{ \tau\leq n - 1 \}\in\mathcal{F}_{n-1}$, so the process $\mathbf{Y}$ is predictable. The transform of $\mathbf{X}$ by $\mathbf{Y}$ is

$$
\begin{align*}
  (\mathbf{Y}\cdot\mathbf{X})_n &= X_0 + \sum_{k=1}^n Y_k(X_k - X_{k+1}) \\
  &= X_0 + \sum_{k=1}^n \mathbf{1}(\tau\geq k)(X_k - X_{k-1})
\end{align*}
$$

Note that 

$$
\begin{align*}
  X_k^\tau - X_{k-1}^\tau &= \begin{cases}
    X_k - X_{k-1}$, & $\tau \geq k$ \\
    X_k^\tau - X_{k-1}^\tau = X_\tau - X_\tau = 0, & \tau < k
  \end{cases} \\
  &= \mathbf{1}(\tau\geq k)(X_k - X_{k-1})
$$

Hence

$$
\begin{align*}
  (\mathbf{Y}\cdot\mathbf{X})_n &= X_0 + \sum_{k=1}^n (X_k^\tau - X_{k+1}^\tau) \\
  &= X_0 + X_n^\tau - X_0^\tau = X_n^\tau
\end{align*}
$
$$

If $\mathbf{X}$ is a (sub/super-)martingale, then so is the transform $\mathbf{X}\cdot\mathbf{Y}=\mathbf{X}^\tau$

</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_t \}_{t\in T}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $\tau \in T$ is a stopping times relative to $\mathscr{F}$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_{t\wedge\tau} = \mathbf{E}(X_0)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_{t\wedge\tau} \geq\mathbf{E}(X_0)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_{t\wedge\tau} \leg\mathbf{E}(X_0)$
</MathBox>

#### Discrete time

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $|X_n|$ is bounded uniformly for $n\in\mathbb{N}$ and that the stopping time $\tau$ is finites

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau) = \mathbb{E}(X_0)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau) \geq\mathbb{E}(X_0)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau) \leq\mathbb{E}(X_0)$

<details>
<summary>Proof</summary> 

Assume that $\mathbf{X}$ is a super-martingale. The proof for a sub-martingale is similar and the result follows immediately. By the mean property for a stopped super-martingale

$$
  \mathbb{E}(X_{\tau\wedge n})\leq\mathbb{E}(X_0),\; n\in\mathbb{N}
$$

Since $\tau < \infty$ with probability $1$, then $\tau\wedge n \xrightarrow{n\to\infty} \tau$ with probability $1$. Since $|X_n|$ is bounded in $n\in T$, it follows from the bounded convergence theorem that $\mathbb{E}(X_{\tau\wedge n})\xrightarrow{n\to\infty}\mathbb{E}(X_\tau)$. Letting $n\to\infty$ in the displayed equation gives $\mathbb{E}(X_\tau)\leq\mathbb{E}(X_0)$.
</details>
</MathBox>

<MathBox title='Wald identities' boxType='proposition'>
Let $S_n = \sum_{i=1}^n \xi_i$, then the following identities hold: 
1. if $\mathrm{E}\left[ |\xi_i | \right] < \infty$ and $\mathrm{E}\left[ \tau \right] < \infty$ then $ \mathrm{E}[|S_\tau|] < \infty$ and  
$$
  \mathrm{E}[S_\tau] = \mathrm{E}[\tau] \cdot \mathrm{E}[\xi_k]
$$
2. if $\mathrm{E}\left[ \xi_i \right] = 0$ and $\sigma^2 = \mathrm{E}\left[ \xi_i^2 \right] < \infty$ then 
$$
  \mathrm{E}[S_\tau^2] = \sigma^2 \mathrm{E}[\tau]
$$
3. assume that $\mathrm{E}\left[ e^{\theta \xi_1} \right] = e^{-\psi(\theta)} < \infty$, then for every bounded stopping time
$$
  \mathrm{E}\left[ \theta S_\tau - \tau \psi(\theta) \right] = 1
$$
</MathBox>

<MathBox title='' boxType='corollary'>
Let $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}}$ be a process relative to a filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$. Suppose that $|X_{n+1} - X_n|$ is bounded uniformly for $n\in\mathbb{N}$ and that $\mathbb{E}(\tau) < \infty$

1. If $\mathbf{X}$ is a martingale then $\mathbb{E}(X_\tau) = \mathbb{E}(X_0)$
2. If $\mathbf{X}$ is a sub-martingale then $\mathbb{E}(X_\tau) \geq\mathbb{E}(X_0)$
3. If $\mathbf{X}$ is a super-martingale then $\mathbb{E}(X_\tau) \leq\mathbb{E}(X_0)$

<details>
<summary>Proof</summary> 

Assume that $\mathbf{X}$ is a super-martingale. The proof for a sub-martingale is similar and the result follows immediately. By the mean property for a stopped super-martingale

$$
  \mathbb{E}(X_{\tau\wedge n})\leq\mathbb{E}(X_0),\; n\in\mathbb{N}
$$

Suppose that $|X_{n+1} - X_n| \leq c$ for $c\in (0,\infty)$. Then

$$
\begin{align*}
  |X_{\tau\wedge n - X_0}| &= \left| \sum_{k=1}^{\tau\wedge n} (X_k - X_{k-1}) \right| \\
  &\leq \sum_{k=1}^{\tau\wedge n} |X_k - X_{k-1}| \leq c(\tau\wedge n) \leq c\tau
\end{align*}
$$

Hence $|X_{\tau\wedge n}| \leq c\tau + |X_0|$. Since $\mathbb{E}(\tau) < \infty$ we know that $\tau < \infty$ with probability $1$, such that $\tau\wedge n \xrightarrow{n\to\infty} \tau$. Also $\mathbb{E}(c\tau + |X_0|) < \infty$ so by the dominated convergence theorem $\mathbb{E}(X_{\tau\wedge n}) \xrightarrow{n\to\infty}\mathbb{E}(X_\tau)$. Letting $n\to\infty$ in the displayed equation gives $\mathbb{E}(X_\tau)\leq\mathbb{E}(X_0)$.
</details>
</MathBox>

#### Wald's equation

<MathBox title="Wald's equation" boxType='proposition'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of indepedent, identically distributed variables with common mean $\mu\in\mathbb{R}$. If $N$ is a stopping time for $\mathbf{X}$ with $\mathbb{E}(N) < \infty$ then

$$
  \mathbb{E}\left( \sum_{k=1}^N X_k \right) = \mu\mathbb{E}(N)
$$

<details>
<summary>Proof</summary>

Let $\mathscr{F}$ denote the natural filtration associated with $\mathbf{X}$. Let $c = \mathbb{E}(|X_n|)$, which by assumption $c < \infty$. Let

$$
  Y_n = \sum_{k=1}^n (X_k - \mu),\; n\in\mathbb{N}_+
$$

Then $\mathbf{Y} = (Y_n)_{n\in\mathbb{N}_+}$ is a martingale relative to $\mathscr{F}$ with mean $0$. Note that

$$
  \mathbb{E}(|Y_{n+1} - Y_n|) = \mathbb{E}(|X_{n+1} - \mu|)\leq c + |\mu|
$$

By the optional stopping theorem we have $\mathbb{E}(Y_N) = 0$. Hence

$$
\begin{align*}
  0 &= \mathbb{E}(Y_N) = \mathbb{E}\left[ \sum_{k=1}^N (X_k - \mu) \right] \\
  &= \mathbb{E}\left( \sum_{k=1}^N X_k - N\mu \right) \\
  &= \mathbb{E}\left( \sum_{k=1}^N X_k \right) - \mu\mathbb{E}(N)
\end{align*}
$$
</details>
</MathBox>

### Markov processes

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_t \}_{t\in T}$ is a time-homogeneous Markov process with state space $(S,\mathcal{S})$, relative to the filtration $\mathscr{F} = \{ \mathcal{F}_t \}_{t\in T}$ and transition kernels $\mathbf{P} = \{P_t\}_{t\in T}$. Suppose that $h:S\to\mathbb{R}$ and that $\mathbb{E}[|h(X_t)] < \infty$ for $t\in T$, then

1. $h$ is *harmonic* for $\mathbf{X}$ if $P_t h = h$ for $t\in T$
2. $h$ is *sub-harmonic* for $\mathbf{X}$ if $P_t h \geq h$ for $t\in T$
3. $h$ is *super-harmonic* for $\mathbf{X}$ if $P_t h \leq h$ for $t\in T$

For $h(\mathbf{X}) = \{ h(X_t) \}_{t\in T}$
1. $h$ is *harmonic* for $\mathbf{X}$ if and only if $h(X)$ is a martingale with respect to $\mathscr{F}$
2. $h$ is *sub-harmonic* for $\mathbf{X}$ if and only if $h(X)$ is a sub-martingale with respect to $\mathscr{F}$
3. $h$ is *super-harmonic* for $\mathbf{X}$ if and only if $h(X)$ is a super-martingale with respect to $\mathscr{F}$

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s\leq T$. Then by the Markov property

$$
  \mathbb{E}[h(X_t)|\mathcal{F_s}] = \mathbb{E}[h(X_t)|X_s] = P_{t-s} h(X_s)
$$

If $h$ is harmonic, $\mathbb{E}[h(X_t)|\mathcal{F}_s] = h(X_s)$ such that $h(\mathbf{X})$ is a martingale. Conversely, if $h(\mathbf{X})$ is a martingale, then $P_{t-s} h(X_s) = h(X_s)$. Letting $s = 0$ and $X_0 = x$ gives $P_t h(x) = h(x)$ so $h$ is harmonic. The proofs for sub and super-martingales are similar, with inequalities replacing the equalities.
</details>
</MathBox>

### Inequalities

#### Maximal inequalities

<MathBox title="Markov's inequality (alternate)" boxType='proposition'>
If $X$ is a real-valued random variable then

$$
  \mathbb{P}(X\geq x) \leq \frac{1}{x}\mathbb{E}(X;X\geq x),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>
Clearly

$$
  x\mathbf{1}(X\geq x)\leq X\mathbf{1}(X\geq x),\; x\in(0,\infty)
$$

Taking expected values gives $x\mathbb{P}(X\geq) \leq\mathbb{E}(X;X\geq x)$. Dividing by $x$ gives the result.
</details>
</MathBox>

<MathBox title="Doob's inequality" boxType='theorem'>
For the process $\mathbf{X}$, define the corresponding maximal process $\mathbf{U} = \{ U_t \}_{t\in T}$ by

$$
  U_t = \sup\{ X_s : s\in T_t \},\; t\in T
$$

where $T_t = \{s\in T : s\leq t\}$. If $\mathbf{X}$ is a sub-martingale then

$$
  \mathbf{P}(U_t \geq x) \leq \frac{1}{x}\mathbf{E}(X_t; U_t \geq x),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

**Discrete time**
For $T=\mathbb{N}$ the maximal process is $U_n = \max\{X_k : k\in\mathbb{N}_n\}$ for $n\in\mathbb{N}$. Let $x\in(0,\infty)$ and define $\tau_x = \min\{k\in\mathbb{N} : X_k \geq x\}$ where $\min(\emptyset) = \infty$. The random time $\tau_x$ is a stopping time relative to $\mathscr{F}$. The processes $\{U_n\}_{n\in\mathbb{N}}$ and $\{\tau_x\}_{x\in (0,\infty)}$ are inverses in the sense that $U_n \geq x$ if and only iff $\tau_x \leq n$.

Note that

$$
  \mathbb{E}(X_{\tau_x \wedge n}) = \mathbb{E}(X_{\tau_x \wedge n}; \tau_x \leq n) + \mathbb{E}(X_{\tau_x \wedge n}; \tau_x > n)
$$

If $\tau_x \leq n$ then $X_{\tau_x \wedge n} = X_{\tau_x}\geq x$. On the other hand, if $\tau_x > n$ then $X_{\tau_x \wedge n} = X_n$ giving

$$
  \mathbb{E}(X_{\tau_x \wedge n}) \geq x\mathbb{P}(\tau_x \leq n) + \mathbb{E}(X_n; \tau_x > n) = x\mathbb{P}(U_t \geq x) + \mathbb{E}(X_n ; \tau_x > n)
$$

Similarly

$$
  \mathbb{E}(X_n) = \mathbb{E}(X_n; \tau_x \leq n) + \mathbb{E}(X_n; \tau_x > n) = \mathbb{E}(X_n; U_\tau \geq n) + \mathbb{E}(X_n ; \tau_x > n)
$$

By the optional stopping theorem $\mathbb{E}(X_{\tau_x \wedge n})\leq\mathbb{E}(X_n)$, giving

$$
\begin{gather*}
  x\mathbb{P}(U_t \geq x) + \mathbb{E}(X_n;\tau_x > n) \leq \mathbb{E}(X_n; U_t \geq x) + \mathbb{E}(X_n; \tau_x > n) \\
  \iff \mathbb{P}(U_t \geq x) \leq \frac{1}{x}\mathbb{E}(X_n; U_t \geq x)
\end{gather*}
$$
 
**Continuous time**

For $k\in\mathbb{N}$, let $\mathbb{D}_k^+ = \{ j/2^k : j\in\mathbb{N} \}$ denote the set of nonnegative dyadic rationals of rank $k$ or less. For $t\in[0,\infty)$ let $T_t^k = \left(\mathbb{D}_k^+ \cap [0,t] \right) \cup \{t\}$ so that $T_t^k$ is the finite set of such dyadic rationals that are less than $t$, including $t$. Note that $T_t^k$ has an ordered enumeration such that $\mathbf{X}^k = \{X_s\}_{s\in T_t^k}$ is a discret-time sub-martingale for each $k\in\mathbb{N}$. Let $U_t^k = \sup\{ X_s \}_{s\in T_t^k}$ and note that $T_t^j \subset T_t^k \subset [0,t]$ for $t\in[0,\infty)$ and $j,k\in\mathbb{N}$ with $j< k$. Thus $U_t^j \leq U_t^k \leq U_t$. It follows that for $x\in(0,\infty)$

$$
  \{U_t^j\} \subseteq \{U_t^k \geq x} \subset \{U_t \geq x\}
$$

The set $\mathbb{D}^+$ of all nonnegative dyadic rationals is dense in $[0,\infty)$. Since $\mathbf{X}$ is right continuous with left limits, it follows that if $U_t \geq x$ then $U_t^k \geq x$ for some $k\in\mathbb{N}$. That is

$$
  \{U_t \geq x\} = \bigcup_{k=0}^\infty \{ U_t^k \geq x \}
$$

The maximal inequality applies to the discrete-time sub-martingale $X^k$ such that for each $k\in\mathbb{N}$

$$
  \mathbb{P}(U_t^k \geq x) \leq \frac{1}{x}\mathbb{E}(X_t ; U_t^k \geq x)
$$

By the monotone convergence theorem, $\mathbb{P}(U_t^k \geq x)\xrightarrow{k\to\infty} \mathbb{P}(U_t \geq x)$, and $\mathbb{E}(X; U_t \geq x)\xrightarrow{k\to\infty}\mathbb{E}(X; U_t \geq x)$.
</details>
</MathBox>

Recall that the positive part of $x\in\mathbb{R}$ is 

$$
  x^+ = x\vee 0 = \begin{cases} x,\quad x > 0 \\ 0,\quad x \leq 0 \end{cases}
$$ 

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X}$ is a sub-martingale. For $t\in T$, 

1. Let $V_t = \sup\{ X_s^+ \}_{s\in T_t}$, then
$$
  \mathbb{P}(V_t \geq x) \leq\frac{1}{x}\mathbb{E}(X_t^+; V_t \geq x),\; x\in(0,\infty)
$$

2. Let $W_t = \sup\{ |X_s| \}_{s\in T_t}$ then
$$
  \mathbb{P}(W_t \geq x) \leq\frac{1}{x}\mathbb{E}(|X_t|; W_t \geq x),\; x\in(0,\infty)
$$
<details>
<summary>Proof</summary>

1. Since $\mathbf{X}$ is a sub-martingale and $x\mapsto x^+$ is increasing and convex, $\mathbf{X}^+ = \{ X_t^+ \}_{t\in T}$ is also a sub-martingale. Hence the result follows from the general maximal inequality for sub-martingales.

2. Since $\mathbf{X}$ is a sub-martingale and $x\mapsto |x|$ is increasing and convex, $|\mathbf{X}| = \{ |X_t| \}_{t\in T}$ is also a sub-martingale. Hence the result follows from the general maximal inequality for sub-martingales.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X}$ is a martingale. For $t\in T$, let $W_t = \sup\{|X_s|\}_{s\in T_t}$. Then for $k > 1$ 

$$
  lVert W_t \rVert_k \leq \frac{k}{k-1}\lVert X_t \rVert_k
$$

or in terms of expected value

$$
  \mathbb{E}\left(|W_t|^k \right) \leq\left(\frac{k}{k-1}\right)^k \mathbb{E}\left(|X_t|^k \right)
$$

<details>
<summary>Proof</summary>

Fix $t\in T$. If $\mathbf{E}(|X_t|^k) = \infty$ the inequality holds trivially, so assume $\mathbb{E}(|X_t|^k) < \infty$, i.e. $X_t \in L_k$. The proof relies on Hölder's inequality, which is applicable by truncating $W_t$ and considering instead the bounded random variable $W_t \wedge c$, where $c\in(0,\infty)$. First, we need to show

$$
  \mathbb{P}(W_t \wedge c \geq x) \leq \frac{1}{x}\mathbb{E}(|X_t|; W_t \wedge c \geq x),\; x\in(0,\infty)
$$

If $c < x$, both sides are $0$. If $c\in x$, then $\{ W_t \wedge c \geq x \} = \{ W_t \geq x \}$ such that from the maximum inequality corollary

$$
\begin{align*}
  \mathbb{P}(W_t \wedge c \geq x) &= \mathbb{P}(W_t \geq x) \\
  &\leq \frac{1}{x}\mathbb{E}(|X_t|; W_t \geq x) = \mathbb{E}(|X_t|; W_t \wedge c \geq x)
\end{align*}
$$

Recall that 

$$
  \lVert W_t \wedge c \rVert_k^k = \mathbb{E}[(W_t \wedge c)^k] = \int_0^\infty kx^{k-1}\mathbb{P}(W_t \wedge c \geq x)\,\mathrm{d}x
$$

Applying the inequality

$$
  \mathbb{E}[(W_t \wedge c)^k] \leq \int_0^\infty kx^{k-2}\mathbb{E}[|X_t|; W_t \wedge c \geq x]\,\mathrm{d}x
$$

Fubini's theorem allows interchanging the expected value and the integral

$$
  \mathbb{E}[(W_t \wedge c)^k] \leq \mathbb{E}\left[\int_0^{W_t \wedge c} kx^{k-2} |X_t|\,\mathrm{d}x\right] = \frac{1}{k-1}\mathbb{E}[|X_t|(W_t \wedge c)^{k-1}]
$$

Note that $X_t \in L_k$ and $(W_t \wedge c)^{k-1} \in L_j$ where $j = \frac{k}{k-1}$ is the conjugate to $k$. By Hölder's inequality

$$
  \lVert W_t \wedge c \rVert_k^k \leq \frac{k}{k-1} \lVert X_t \rVert_k \cdot \lVert (W_t \wedge c)^{k-1} \rVert_j = \frac{k}{k-1} \lVert X_t \rVert_k \cdot \lVert W_t \wedge c \rVert_k^{k-1}
$$

where we have used that $\lVert (W_t \wedge c)^{k-1} \rVert_j = \lVert W_t \wedge c \rVert_k^{k-1}$. Dividing by this factor gives

$$
  \lVert W_t \wedge c \rVert_k \leq \frac{k}{k-1}\lVert X_t \rVert_k
$$

By the monotone convergence theorem $\lVert W_k \wedge c \rVert_k \stackrel{c\to\infty}{\uparrow} \lVert W_t \rVert_k$. Letting $c\to\infty$ gives

$$
  \lVert W_t \rVert_k \leq \frac{1}{k-1}\lVert X_t \rVert_k
$$
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X}$ is a super-martingale. For $t\in T$, let $U_\infty = \sup\{ X_t \}_{t\in T}$ 

$$
  \mathbb{P}(U_\infty \geq x) \leq \frac{1}{x}\mathbb{E}(X_0),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

Let $Y_t = -X_t$ for $t\in T$. Since $\mathbf{X}$ is a super-martingale, $\mathbf{Y}$ is a sub-martingale. And since $\mathbf{X}$ is nonnegative, $Y_t^+ = X_t$ for $t\in T$. Let $U_t = \sup\{ X_s \}_{s\in T_t} = \sup\{ Y_s^+ \}_{s\in T_t}$. By the maximal inequality for sub-martingales, and since $\mathbf{X}$ is a super-martingale we have

$$
  \mathbb{P}(U_t \geq x) \leq \frac{1}{x}\mathbb{E}(Y_t^+) = \frac{1}{x}\mathbb{E}(X_t) \leq \frac{1}{x}\mathbb{E}(X_0),\; x\in(0,\infty)
$$

Note that $U_t \stackrel{\uparrow}{t\to\infty} U_\infty$. Let $x\in(0,\infty)$ and $\varepsilon\in(0,x)$. If $U_\infty \geq x$ then $U_t \geq x - \varepsilon$ for sufficiently large $t\in T$. Hence

$$
  \{ U_\infty \geq x \} \subseteq \bigcup_{k=1}^\infty \{ U_k \geq x - \varepsilon \}
$$

Using the continuity theorem for increasing events, and the result above gives

$$
  \mathbb{P}(U_\infty \geq x) \leq \lim_{k\to\infty} \mathbb{P}(U_k \geq x - \varepsilon) \leq \frac{1}{x-\varepsilon}\mathbb{E}(X_0)
$$

Since this holds for all $\varepsilon\in (0,x)$, it follows that $\mathbb{P}(U_\infty \geq x) \leq \frac{1}{x}\mathbb{E}(X_0)$.
</details>
</MathBox>

<MathBox title="Kolmogorov's inequality" boxType='proposition'>
Suppose that $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}_+}$ is a sequence of indepedent variables with $\mathbb{E}(X_n) = 0$ and $\mathrm{var}(X_n) = \mathbb{E}(X_n^2) < \infty$. Let $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}}$ be the partial sum process associated with $\mathbf{X}$, i.e.

$$
  Y_n = \sum_{i=1}^n X_i,\; n\in\mathbb{N}
$$

For $n\in\mathbb{N}$, let $U_n = \max\{|Y_i|\}_{i\in\mathbb{N}_n}$. Then

$$
  \mathbb{P}(U_n \geq x) \leq \frac{1}{x^2}\mathrm{var}(Y_n) = \frac{1}{x^2}\sum_{i=1}^n \mathbb{E}(X_i^2),\; x\in(0,\infty)
$$

<details>
<summary>Proof</summary>

Note that $\mathbf{Y}$ is a martingale. Since the function $x\mapsto x^2$ on $\mathbb{R}$ is convex, $\mathbf{Y}^2 = \{Y_i^2 \}_{i\in\mathbb{N}_n}$ is a sub-martingale. Let $V_n = \max\{Y_i^2\}_{i\in\mathbb{N}_n}$ for $n\in\mathbb{N}$ and let $x\in(0,\infty)$. Applying the maximal inequality for sub-martingales we have

$$
  \mathbb{P}(U_n \geq x) = \mathbb{P}(V_n \geq x^2) \leq \frac{1}{x^2}\mathbb{E}(Y_n^2) = \frac{1}{x^2}\mathrm{var}(Y_n)
$$

Since $\mathbb{X}$ is an independent sequence

$$
  \mathrm{var}(Y_n) = \sum_{i=1}^n \mathrm{var}(X_i) = \sum_{i=1}^n \mathbb{E}(X_i^2)
$$
</details>
</MathBox>

#### Up-crossing inequality

##### Discrete time
The up-crossing inequality gives a bound on how much a sub/super-martingale can oscillate.

<MathBox title='Up-crossing' boxType='definition'>
Suppose that $\mathbf{x} = (x_n)_{n\in\mathbb{N}}$ is a sequence of real numbers, and that $a, b\in\mathbb{R}$ with $a < b$. Define $t_0(\mathbf{x}) = 0$ and the recursively define

$$
\begin{align*}
  s_{k+1} (\mathbf{x}) &= \int\{n\in\mathbb{N} \;|\; n\geq t_k (\mathbf{x}), x_n \leq a\} \\
  t_{k+1} (\mathbf{x}) &= \int\{n\in\mathbb{N} \;|\; n\geq s_{k+1} (\mathbf{x}), x_n \geq b\}
\end{align*}
$$

1. The number of up-crossings of the interval $[a,b]$ by the sequence $\mathbf{x}$ up to time $n\in\mathbb{N}$ is
$$
  u_n(a,b,\mathbf{x}) = \sup\{k\in\mathbb{N} \;|\; t_k(\mathbf{x})\leq n \}
$$
2. The total number of up-crossings of the interval $[a,b]$ by the sequence $\mathbf{x}$ is
$$
  u_\infty (a,b,\mathbf{x}) = \sup\{k\in\mathbb{N} \;|\; t_k(\mathbf{x}) \}
$$

Note that if $t_k (\mathbf{x}) < \infty$, then $(x_n \;|\; n = s_k(\mathbf{x}),\dots,t_k(\mathbf{x}))$ is the $k$th up-crossing of the interval $[a, b]$ by the sequence $\mathbf{x}$.
</MathBox>

<MathBox title='Properties of up-crossings' boxType='proposition'>
Suppose that $\mathbf{x} = (x_n)_{n\in\mathbb{N}}$ is a sequence of real numbers, and that $a, b\in\mathbb{R}$ with $a < b$.

1. $u_n (a,b,\mathbf{x})$ is increasing in $n\in\mathbb{N}$
2. $u_n (a,b,\mathbf{x})\xrightarrow{n\to\infty} u(a,b,\mathbf{x})$
3. If $c,d\in\mathbb{R}$ with $a < c < d < b$ then $u_n (c,d,\mathbf{x}) \geq u_n(a,b,\mathbf{x})$ for $n\in\mathbb{N}$ and $u(c,d,\mathbf{x}) \geq u(a,b,\mathbf{x})$

<details>
<summary>Proof</summary>

1. Note that $\{k\in\mathbb{N} \;|\; t_k(\mathbf{x}) \leq n\}\subset\{k\in\mathbb{N} \;|\; t_k(\mathbf{x}) \leq n + 1 \}$
2. Note that $\bigcup_{n=0}^\infty \{ k\in\mathbb{N} \;|\; t_k(\mathbf{x}) \} = \{ k\in\mathbb{N} \;|\; t_k (\mathbf{x})\leq \infty \}$
3. Every up-crossing of $[a,b]$ is also an up-crossing of $[c,d]$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{x} = (x_n)_{n\in\mathbb{N}}$ is a sequence of real numbers. Then $\lim_{n\to\infty} x_n$ exists in $R^* = \mathbb{R}\cup\{-\infty, \infty\}$ if and only if $u_\infty (a,b,\mathbf{x})< \infty$ for every $a,b\in\mathbb{Q}$ with $a < b$.

<details>
<summary>Proof</summary>

Proving by contraposition, the following statements are equivalent
1. $\lim_{n\to\infty} x_n$ does not exist in $\mathbb{R}^*$
2. $\liminf_{n\to\infty} x_n < \limsup_{n\to\infty} x_n$
3. There exists $a,b\in\mathbb{Q}$ with $a < b$ and with $x_n \leq a$ and $x_n \geq b$ for infinitely many $n\in\mathbb{N}$
4. There exists $a,b\in\mathbb{Q}$ with $a < b$ and $u_\infty (a, b, \mathbf{x})$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a process with respect to the filtration $\mathscr{F} = \{F_n\}_{n\in\mathbb{N}}$, and let $a,b\in\mathbb{R}$ with $a < b$. Let $U_n = u_n (a,b,\mathbf{x})$ be the random number of up-crossing of $[a,b]$ by $\mathbf{X}$ up to time $n\in\mathbb{N}$.

1. If $\mathbf{X}$ is a super-martingale then
$$
\begin{align*}
  \mathbb{E}(U_n) &\leq \frac{1}{b-a}\mathbb{E}[(X_n - a)^-] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_n^-) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_n|) + |a|\right]
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale then
$$
\begin{align*}
  \mathbb{E}(U_n) &\leq \frac{1}{b-a}\mathbb{E}[(X_n - a)^+] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_n^+) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_n|) + |a|\right]
\end{align*}
$$

<details>
<summary>Proof</summary>

Let $\sigma_k = s_k(\mathbf{X})$ and $\tau_k = t_k(\mathbf{X})$ be the random times that define the up-crossings of $\mathbf{X}$ for $k\in\mathbb{N}$. Let $Y_k = X_{\tau_k \wedge n} - X_{\sigma_k \wedge n}$ and then define $Z_n = \sigma_{k=1}^n Y_k$. For the $k$th term $Y_k$

- If $\tau_k \leq n$ then $Y_k = X_{\tau_k} - X_{\sigma_k} \geq b - a$. By definition, the first $U_n$ terms are of this form.
- If $\sigma_k \leq n < \tau_k$ then $Y_k = X_n - X_{\sigma_k} \geq X_n - a$. There is at most one such term, with index $k = U + 1$.
- If $\sigma_k > n$ then $Y_k = X_n - X_n = 0$

Hence $Z_n \geq (b - a)U_n + (X_n - a)\mathbf{1}(\sigma_{U_n + 1} \leq n)$ and so $(b - a)U_n \leq Z_n - (X_n - a)\mathbf{1}(\sigma_{U_n + 1} \leq n)$. Note that $\sigma_k \wedge n$ and $\tau_k \wedge n$ are bounded stopping times and of course $\sigma_k \wedge n \leq \tau_k \wedge n$.

1. If $\mathbf{X}$ is a super-martingale, if follows from the optional stopping theorem that
$$
  \mathbb{E}(Y_k) = \mathbb{E}(X_{\tau_k \wedge n}) - \mathbb{E}(X_{\sigma_k \wedge n}) \leq 0
$$

Thus $\mathbb{E}(Z_n) \leq 0$. Finally, $-(X_n - a)\mathbf{1}(\sigma_{U_n + 1} \leq n) \leq (X_n - a)^-$. Taking expected values gives

$$
  (b - a)\mathbb{E}(U_n) \leq \mathbb{E}(Z_n) + \mathbb{E}[(X_n - a)^-] \leq \mathbb{E}[(X_n - a)^-]
$$

The remaining parts of the inequality follow since $(x - a)^- \leq x^- + |a| \leq |x| + |a|$ for $x\in\mathbb{R}$

**Additional details**
On a sidenote, the process $\mathbf{Z} = \{Z_n\}_{n\in\mathbb{N}}$ can be viewed as a transform of $\mathbf{X}$ by a predictable process. Specifically, for $n\in\mathbb{N}_+$, let $I_n = 1$ if $\sigma_k < n \leq \tau_k$ for some $k\in\mathbb{N}$, and let $I_n = 0$ otherwise. Since $\sigma_k$ and $\tau_k$ are stopping times, note that $\{I_n = 1\}\in\mathcal{F}_{n-1}$ for $n\in\mathbb{N}_+$. Hence the process $\mathbf{I} = \{ I_n \}_{n\in\mathbb{N}_+}$ is predictable with respect to $\mathcal{F}$. Moreover, the transform of $\mathbf{X}$ by $\mathbf{I}$ is

$$
  (\mathbf{I}\cdot\mathbf{X})_n = \sum_{j=1}^n I_j (X_j - X_{j-1}) = \sum_{k=1}^n (X_{\tau_k \wedge n} - X_{\sigma_k \wedge n}) = Z_n
$$

Since $\mathbf{I}$ is a nonnegative process, if $\mathbf{X}$ is a (sub/super-)martingale, then $\mathbf{I}\cdot\mathbf{X}$ is also a (sub/super-)martingale.
</details>
</MathBox>

##### Continuous time

<MathBox title='Continuous up-crossings' boxType='definition'>
Suppose that $\mathbf{x}: [0,\infty)\to\mathbb{R}$, and that $a, b\in\mathbb{R}$ with $a < b$.

1. If $I\subset [0,\infty)$ is finite, define $t_0^I (\mathbf{x}) = 0$ and the recursively define

$$
\begin{align*}
  s_{k+1}^I (\mathbf{x}) &= \int\{t\in I \;|\; t\geq t_k^I (\mathbf{x}), x_t \leq a\} \\
  t_{k+1}^I (\mathbf{x}) &= \int\{t\in I \;|\; t\geq s_{k+1}^I (\mathbf{x}), x_n \geq b\}
\end{align*}
$$

The number of up-crossings of the interval $[a,b]$ by the function $\mathbf{x}$ restricted to $I$ is

$$
  u_I (a, b, \mathbf{x}) = \sup\{k\in\mathbb{N} \;|\; t_k^I(\mathbf{x}) < \infty \}
$$

2. If $I\subseteq [0,\infty)$ is infinite, the number of up-crossings of the interval $[a,b]$ by $\mathbf{x}$ restricted to $I$ is

$$
  u_I(a,b,\mathbf{x}) = \sup\{u_J(a,b,\mathbf{x}) \;|\; J \textrm{ is finite and } J\subset I\}
$$
</MathBox>

For simpler notation, let $u_t (a, b, \mathbf{x}) = u_{[0,t]}(a,b,\mathbf{x})$, the number of up-crossings of $[a,b]$ by $\mathbf{x}$ on $[0,t]$ and $u_\infty(a,b,\mathbf{x}) = u_{[0,\infty)}(a,b,\mathbf{x})$, the total number of up-crossings of $[a,b]$ by $\mathbf{x}$.

<MathBox title='Properties of up-crossings' boxType='proposition'>
Suppose that $\mathbf{x}: [0,\infty)\to\mathbb{R}$ and that $a,b\in\mathbb{R}$ with $a < b$

1. If $I, J \subseteq [0,\infty)$ with $I\subseteq J$ then $u_I (a,b,\mathbf{x}) \leq u_J (a,b,\mathbf{x})$
2. If $(I_n)_{n\in\mathbb{N}}$ is an increasing sequence of sets in $[0,\infty)$ and $J = \bigcup_{n=0}^\infty I_n$ then $u_{I_n}(a,b,\mathbf{x}) \xrightarrow{n\to\infty} u_J (a,b,\mathbf{x})$
3. If $c,d\in\mathbb{R}$ with $a < c < d < b$ and $I\subset [0,\infty)$ then $u_I (c,d,\mathbf{x}) \geq u_I(a,b,\mathbf{x})$

<details>
<summary>Proof</summary>

1. The result follows easily from the definitions if $I$ is finite (and $J$ either finite of infinite). If $I$ is infinite (and hence so is $J$), note that
$$
  \{ u_K (a,b,\mathbf{x}) \;|\; K \textrm{ is finite and } K\subseteq I \} \subseteq \{ u_K (a,b,\mathbf{x}) \;|\; K \textrm{ is finite and } K \subseteq J \}
$$
2. Since $I_n$ is increasing in $n\in\mathbb{N}$, note that if $K\subset [0,\infty)$ is finite, then $K\subseteq J$ if and only if $K\subseteq I_n$ for some $n\in\mathbb{N}$.
3. Every up-crossing of $[a,b]$ is also an up-crossing of $[c,d]$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{x}:[0,\infty)\to\mathbb{R}$. Then $\lim_{t\to\infty} x_t$ exists in $R^* = \mathbb{R}\cup\{-\infty, \infty\}$ if and only if $u_\infty (a,b,\mathbf{x})< \infty$ for every $a,b\in\mathbb{Q}$ with $a < b$.

<details>
<summary>Proof</summary>

Proving by contraposition, the following statements are equivalent
1. $\lim_{t\to\infty} x_t$ does not exist in $\mathbb{R}^*$
2. $\liminf_{t\to\infty} x_t < \limsup_{t\to\infty} x_t$
3. There exists $a,b\in\mathbb{Q}$ with $a < b$, and there exists $s_n, t_n\in[0,\infty)$ with $x_{s_n} \leq a$ and $x_{t_n} \geq b$ for $n\in\mathbb{N}$
4. There exists $a,b\in\mathbb{Q}$ with $a < b$ and $u_\infty (a, b, \mathbf{x})$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in[0,\infty)}$ is a process with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in[0,\infty)}$, and let $a,b\in\mathbb{R}$ with $a < b$. Let $U_t = u_t (a,b,\mathbf{x})$ be the random number of up-crossing of $[a,b]$ by $\mathbf{X}$ up to time $t\in[0,\infty)$.

1. If $\mathbf{X}$ is a super-martingale the
$$
\begin{align*}
  \mathbb{E}(U_t) &\leq \frac{1}{b-a}\mathbb{E}[(X_t - a)^-] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_t^-) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_t|) + |a|\right]
\end{align*}
$$

2. If $\mathbf{X}$ is a sub-martingale then
$$
\begin{align*}
  \mathbb{E}(U_t) &\leq \frac{1}{b-a}\mathbb{E}[(X_t - a)^+] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(X_t^+) + |a|\right] \\
  &\leq \frac{1}{b-a}\left[\mathbb{E}(|X_t|) + |a|\right]
\end{align*}
$$

<details>
<summary>Proof</summary>

Suppose that $\mathbf{X}$ is a sub-martingale; the proof for a super-martingale is analogous. Fix $t\in[0,\infty)$ and $a,b\in\mathbb{R}$ with $a < b$. For $I\subseteq [0,\infty)$ let $U_I = u_I (a,b,\mathbf{X}$. Suppose that $I$ is finite and that $t\in I$ is the maximumm of $I$. Since $\mathbf{X}$ restricted to $I$ is also a sub-martingale, the discrete-time up-crossing theorem applies giving

$$
  \mathbf{E}(U_I) \leq \frac{1}{b-a}\mathbb{E}[(X_t - a)^+]
$$

Since $U_t = \sup\{ U_I \;|\; I \textrm{ is finite and } I\subset [0,t] \}$, there exists finite $I_n$ for $n\in\mathbb{N}$ with $U_{I_n} \stackrel{n\to\infty}{n\to\infty}$. In particular, $U_t$ is measurable. By the properties of continuous-time up-crossings, there exists such a sequence with $I_n$ increasing in $n$ and $t\in I_n$ for each $n\in\mathbb{N}$. By the monotone convergence theorem $\mathbb{E}(U_{I_n}) \xrightarrow{n\to\infty} \mathbb{E}(U_t)$, giving

$$
  \mathbb{E}(U_t) \leq\frac{1}{b-a}\mathbb{E}[(X_t - a)^+]
$$
</details>
</MathBox>

### Convergence

If $\mathbf{X}$ is a sub-martingale realtive to $\mathscr{F}$, the inequality condition for $s,t\in T$

$$
  \mathbb{E}(X_t | \mathcal{F}_s) \geq X_s,\; s\leq t
$$

suggests that $\mathbf{X}$ displays an increasing property. If $\mathbf{X}$ is a super-martingale, the inequality reverses suggesting that $\mathbf{X}$ displays a decreasing property. By coupling these properties with a boundedness property, then intuitively the sub/super-martingale should converge as $t\to\infty$. This is indeed the case as shown by the following theorems. 

<MathBox title='First martingale convergence theorem' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a sub/super-martingale with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, and that $\mathbf{E}(|X_t|)$ is bounded in $t\in T$. Then there exists a random variable $X_\infty$ that is measurable with respect to $\mathcal{F}_\infty$ such that $\mathbb{E}(|X_\infty|) < \infty$ and $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$.

<details>
<summary>Proof</summary>

Let $T_t = \{ s\in T \;|\; s\leq t\}$. For $a,b\in\mathbb{R}$ with $a < b$, let $U_t (a,b)$ denote the number of up-crossings of the interval $[a,b]$ by the process $\mathbf{X}$ on $T_t$, and let $U_\infty(a,b)$ denote the number of up-crossings of $[a,b]$ by $\mathbf{X}$ on $T$. Recall that $U_t \stackrel{\uparrow}{t\to\infty} U_\infty$. Suppose that $\mathbb{E}(|X_t|) < c$ for $c\in (0,\infty)$. By the up-crossing inequality

$$
  \mathbb{E}[U_t(a,b)] \leq \frac{1}{b-a}\left[|a| + \mathbb{E}(|X_t|)\right] \leq \frac{|a| + c}{b - a}
$$

By the monotone convergence theorem, it follows that

$$
  \mathbb{E}[U_\infty (a,b)] < \frac{|a| + c}{b - a} < \infty
$$

Showing that $\mathbb{P}[U_\infty (a,b) < \infty] = 1$. Thus $U_\infty (a,b) < \infty$ with probability $1$ for every $a,b\in\mathbb{Q}$ with $a < b$. By our characterization of convergence in terms of up-crossings, it follows that there exists a random variable $X_\infty$ with values in $\mathbb{R}^* = \mathbb{R} \cup \{-\infty, \infty\}$ such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$. Note that $X$ is measurable with $\mathcal{F}_\infty$. By Fatou's lemma

$$
  \mathbb{E}(|X_\infty|) \leq \liminf{t\to\infty}\mathbb{E}(|X_t|) < \infty
$$

Hence $\mathbb{P}(X_\infty \in\mathbb{R}) = 1$
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
If $\mathbf{X} = \{X_t\}_{t\in T}$ is a nonnegative super-martingale with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, then there exists a random variable $X_\infty$, measurable with respect to $\mathcal{F}_\infty$ such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$.

<details>
<summary>Proof</summary>

Since $\mathbb{X}$ is a nonnegative super-martingale $\mathbb{E}(|X_t|) = \mathbb{E}(X_t) \leq\mathbb{E}(X_0)$ for $t\in T$. Hence the first martingale convergence theorem applies.
</details>
</MathBox>

<MathBox title='Second martingale convergence theorem' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is uniformly integrable and a sub/super-martingale relative to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$ and in mean. If $\mathbf{X}$ is a martingale with respect to $\mathscr{F}$ then $X_t = \mathbb{E}(X_\infty | \mathcal{F}_t)$ for $t\in T$.

<details>
<summary>Proof</summary>

Since $\mathbf{X}$ is uniformly integrable, $\mathbb{E}(|X_t|)$ is bounded in $t\in T$. By the first martingale convergence theorem, there exists $X_\infty$ that is measurable with respect to $\mathcal{F}_\infty$ such that $\mathbb{E}(|X_\infty|) < \infty$ and $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$. By the uniform integrability theorem, the convergence is also in mean, i.e. $\mathbb{E}(|X_t - X_\infty|) \xrightarrow{t\to\infty} 0$. Suppose that $\mathbf{X}$ is a martingale relative to $\mathscr{F}$. For fixed $s\in T$ we know that $\mathbb{E}(X_t | \mathcal{F}_s) \xrightarrow{t\to\infty} \mathbb{E}(X_\infty | \mathcal{F}_s)$. Since $\mathbb{E}(X_t | \mathcal{F}_s) = X_s$ for $t\geq s$ it follows that $X_s = \mathbb{E}(X_\infty | \mathcal{F}_s)$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Suppose that $\mathbf{X} = \{X_t\}_{t\in T}$ is a sub/super-martingale with respect to the filtration $\mathscr{F} = \{F_t\}_{t\in T}$, and that $\lVert X_t \rVert_k$ is bounded in $t\in T$ for some $k\in (1,\infty)$. Then there exists a random variable $X_\infty \in L_k$ such that $X_t \xrightarrow{t\to\infty} X_\infty$.

<details>
<summary>Proof</summary>

Suppose that $\lVert X_t \rVert_k \leq c$ for $t\in T$ where $c\in (0,\infty)$. Since $\lVert X \rVert_1 \leq \lVert X_t \rVert_k$ then $\mathbb{E}(|X_t|)$ is bounded in $t\in T$ and the first martingale convergence theorem applies. Hence there exists $X_\infty$ measurable relative to $\mathcal{F}_\infty$ such that $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$. Equivalently, with probability $1$

$$
  |X_t - X_\infty|^k \xrightarrow{t\to\infty} 0
$$

For $t\in T$ let $T_t = \{ s\in T \;|\; s\leq t \}$ and define $W_t = \sup\{|X_s| \;|\; s\in T_t \}$. By the norm version of the maximal inequality

$$
  \lVert W_t \rVert_k \leq \frac{k}{k-1}\lVert X_t \rVert_k \leq \frac{ck}{k-1}
$$

Letting $W_\infty = \sup\{ |X_s| \;|\; s\in T \}$, then by the monotone convergence theorem

$$
  \lVert W_\infty \rVert_k = \lim_{t\to\infty} \lVert W_t \rVert_k \leq \frac{ck}{k-1}
$$

Showing that $W_\infty \in L_k$. Since $|X_\infty| \leq W_\infty$ it follows that $X_\infty \in L_k$ also. Moreover, $|X_t - X_\infty|^k \leq 2^k W_\infty^k$, so applying the dominated convergence theorem on the first displayed equation gives $\mathbb{E}(|X_t - X_\infty|^k) \xrightarrow{t\to\infty} 0$.
</details>
</MathBox>

#### Kolmogorov zero-one law

<MathBox title='Kolmogorov zero-one law' boxType='theorem'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of independent random variables on a state space $(S,\mathcal{S})$. Let $\matcal{G} = \sigma\{X_k \;|\; k\geq n\}$ for $n\in\mathbb{N}_+$ and let $\mathcal{G}_\infty = \bigcap_{n=1}^\infty \mathcal{G}_n$. That is, $\mathcal{G}_\infty$ is the tail $\sigma$-algebra of $\mathbf{X}$, the collection of events that depend only on the term of the sequence with arbitrarily large indices. 

If $A\in\mathcal{G}_\infty$ then $\mathbb{P}(A) = 0$ or $\mathbb{P}(A) = 1$. 

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{ X_k \;|\; k\leq n \}$ for $n\in\mathbb{N}_+$ so that $\mathscr{F} = \{F_n\}_{n\in\mathbb{N}_+}$ is the natural filtration associated with $\mathbf{X}$. Let $\mathcal{F}_\infty = \sigma\left( \bigcup_{n\in\mathbb{N}_+} \mathcal{F}_n \right)$ and let $A\in\mathcal{G}_\infty$ be a tail event. Then $\{\mathbb{E}(\mathbf{1}_A | \mathcal{F}_n)\}_{n\in\mathbb{N}_+}$ is the Doob martingale associated with the indicator variable $\mathbf{1}_A$ and $\mathscr{F}$. By the properties of the Doob martingale, $\mathbb{E}(\mathbf{1}_A \;|\; \mathcal{F}_n) \xrightarrow{n\to\infty} \mathbb{E}(\mathbf{1}_A|\mathcal{F}_\infty)$ with probability $1$. Since $A\in\mathcal{F}_\infty$ then $\mathbb{E}(\mathbf{1}_A | \mathcal{F}_\infty) = \mathbf{1}_A$. On the other hand $A\in\mathcal{G}_{n+1}$ and the $\sigma$-algebras $\mathcal{G}_{n+1}$ and $\mathcal{F}_n$ are independent, so that $\mathbb{E}(\mathbf{1}_A|\mathcal{F}_n) = \mathbb{P}(A)$ for each $n\in\mathbb{N}_+$. Thus $\mathbb{P}(A) = \mathbf{1}_A$.
</details>
</MathBox>

### Backwards martingales

<MathBox title='Backwards martingale' boxType='definition'>
Let $\mathbf{Y} = \{Y_t\}_{t\in T}$ be a process on a probability space $(\Omega,\mathcal{F},\mathbb{P})$, having state space $\mathbb{R}$. Suppose that $\mathcal{G}_t$ is a sub $\sigma$-algebra of $\mathcal{F}$ for each $t\in T$ and that $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is decreasing, i.e. if $s,t\in T$ with $s\leq t$ then $\mathcal{G}_t \subseteq\mathcal{G}_s$. Let $\mathcal{G}_\infty = \bigcap_{t\in T} \mathcal{G}_t$. 

The process $\mathbf{Y}$ is a *backwards martingale* (or reversed martingale) with respect to $\mathscr{G}$ if $\mathbb{E}(Y_s | \mathcal{G}_t) = Y_t$ for all $s,t \in T$ with $s\leq t$.
</MathBox>

A backwards martingale can be formulated as an ordinary martingale by using negative times as indices. Let $T^- = \{-t\}_{t\in T}$ such that in the discrete case $T^-$ is the set of non-positive integers, and in the continuous case $T^- = (-\infty, 0]$.

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. Let $X_t = Y_{-t}$ and $\mathcal{F}_t = \mathcal{G}_{-t}$ for $t\in T^-$. Then $\mathbf{X} = \{X_t\}_{t\in T^-}$ is a martingale with respect to $\mathscr{F} = \{\mathcal{F}_t\}_{t\in T^-}$.

<details>
<summary>Proof</summary>

Since $\mathscr{G}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$, the collection $\mathscr{F}$ is an increasing family of sub $\sigma$-algebras of $\mathcal{F}$, and hence is a filtration. Next, $X_t = Y_{-t}$ is measurable with respect to $\mathcal{G}_{-t}= \mathcal{F}_t$ for $t\in T^-$, so $\mathbf{X}$ is adapted to $\mathscr{F}$. If $s,t\in T^-$ with $s\leq t$ then $-t\leq -s$ so

$$
  \mathbb{E}(X_t|\mathcal{F}_s) = \mathbb{E}(Y_{-t}|\mathcal{G}_{-s}) = Y_{-s} = X_s
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. Fix $t\in T$ and define $X_s^t = Y_{t-s}$ and $\mathcal{F}_s^t = \mathcal{G}_{t-s}$ for $s\in T_t = \{s\in T \;|\; s\leq t\}$. Then $\mathbf{X}^t = \{X_s^t \;|\; s\in T_t\}$ is a martingale relative to $\mathscr{F}^t = \{\mathcal{F}_s^t\}_{s\in T_t}$.

<details>
<summary>Proof</summary>

Since $\mathscr{G}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$, the collection $\mathscr{F}^t$ is an increasing family of sub $\sigma$-algebras of $\mathcal{F}$, and hence is a filtration. Next, $X_s^t = Y_{t-s}$ is measurable with respect to $\mathcal{G}_{t-s}= \mathcal{F}_s^t$ for $s\in T_t$, so $\mathbf{X}^t$ is adapted to $\mathscr{F}^t$. If $r,s\in T_t$ with $r\leq s$ then $t - s \leq t - r$ so

$$
  \mathbb{E}(X_s^t|\mathcal{F}_r^t) = \mathbb{E}(Y_{t-s}|\mathcal{G}_{t-r}) = Y_{t-r} = X_r^t
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. Then $Y_t = \mathbb{E}(Y_0 \;|\; \mathcal{G}_t)$ for $t\in T$ and hence $\mathbf{Y}$ is uniformly integrable.

<details>
<summary>Proof</summary>

The fact that $Y_t = \mathbb{E}(Y_0 \;|\; \mathcal{G}_t)$ for $t\in T$ follows directly from the definition of a backwards martingale. Since we have assumed that $\mathbb{E}(|Y_0|) < \infty$, it follows that $\mathbf{Y}$ is uniformly integrable.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $Y$ is a random variable on a probability space $(\Omega,\mathcal{F},\mathbb{P})$ with $\mathbb{E}(|Y|) < \infty$, and that $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$. Let $Y_t = \mathbb{E}(Y|\mathcal{G}_t)$ for $t\in T$. Then $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G}$.

<details>
<summary>Proof</summary>

By definition $Y_t = \mathbb{E}(Y|\mathcal{G}_t)$ is measurable relative to $\mathcal{G}_t$. Also

$$
\begin{align*}
  \mathbb{E}(|Y_t|) &= \mathbb{E}[\mathbb{E}(Y|\mathcal{G}_t)] \\
  &\leq \mathbb{E}[\mathbb{E}(|Y|\;|\;\mathcal{G}_t)] = \mathbb{E}(|Y|) < \infty
\end{align*}
$$

Suppose that $s,t\in T$ with $s\leq t$. Then $\mathcal{G}_t \subseteq\mathcal{G}_s$ and by the tower property

$$
  \mathbb{E}(Y_s|\mathcal{G}_t) = \mathbb{E}[\mathbb{E}(Y|\mathcal{G}_s)|\mathcal{G}_t] = \mathbb{E}(Y|\mathcal{G}_t) = Y_t
$$
</details>
</MathBox>

<MathBox title='Backwards martingale convergence theorem' boxType='theorem'>
Suppose that $\mathbf{Y} = \{ Y_t \}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t\}_{t\in T}$. Then there exists a random variable $Y_\infty$ such that

1. $Y_t \xrightarrow{t\to\infty} Y_\infty$ with probability $1$
2. $Y_t \xrightarrow{t\to\infty} Y_\infty$ in mean
3. $Y_\infty = \mathbb{E}(Y_0|\mathcal{G}_\infty)$

<details>
<summary>Proof</summary>

Fix $t\in T$ and let $T_t = \{s\in T \;|\; s\leq t \}$. Let $X_s^t = Y_{t-s}$ and $\mathcal{F}_s^t = \mathcal{G}_{t-s}$ for $s\in T_t$, so that $\mathbf{X}^t = \{ X_s^t\}_{s\in T_t}$ is a martingale relative to $\mathscr{F}^t = \{F_s^t\}_{s\in T_t}$. For $a,b\in\mathbb{R}$ with $a < b$ let $U_t (a, b)$ denote the number of up-crossings of $[a, b]$ by $\mathbf{X}^t$ on $T_t$. Note that $U_t (a,b)$ is also the number of down-crossings of $[a, b]$ by $\mathbf{Y}$ on $T_t$. By the up-crossing inequality applied to $\mathbf{X}$

$$
  \mathbb{E}[U_t(a,b)] \leq\frac{1}{b - a}[\mathbb{E}(|X_t|) + |a|] = \frac{1}{b-a}[\mathbb{E}(|Y_0|) + |a|]
$$

Let $U_\infty (a,b)$ denote the number of down-crossing of $[a,b]$ by $\mathbf{Y}$ on $T$. Since $U_t \stackrel{\uparrow}{t\to -\infty}$ if follows from the monotone convergence theorem that

$$
  \mathbb{E}[U_\infty (a,b)] \leq \frac{1}{b-a}[\mathbb{E}(|Y_0|) + |a|]
$$

Thus $U_\infty(a,b) < \infty$ with probability $1$ for every $a, b \in\mathbb{Q}$ with $a < b$. By the characterization of convergence in terms of down-crossing, there exists a random variable $Y_\infty$ with values in $\mathbb{R}^* = \mathbb{R} \cup \{-\infty, \infty\}$ such that $Y_t \xrightarrow{t\to\infty} Y_\infty$. By Fatou's lemma

$$
  \mathbb{E}(|Y_\infty|) \leq\liminf_{t\to\infty}\mathbb{E}(|Y_t|) \leq\mathbb{E}(|Y_0|) < \infty
$$

In particular $\mathbb{P}(Y_\infty \in\mathbb{R}) = 1$. Since $\mathbf{Y}$ is uniformly integrable and $Y_\infty \in L_1$, it follows that $Y_t \xrightarrow{t\to\infty} Y_\infty$ in $L_1$.

It remains to show that $Y_\infty = \mathbb{E}(Y_0 |\mathcal{G}_\infty)$. Let $A\in\mathcal{G}_\infty$. Then $A\in\mathcal{G}_t$ for every $t\in T$. Since $Y_t = \mathbb{E}(Y_0|\mathcal{G}_t)$ it follows by definition that $\mathbb{E}(Y_t;A) = \mathbb{E}(Y_0;A)$ for every $t\in T$. Letting $t\to\infty$ and using the dominated convergence theorem gives $\mathbb{E}(Y_\infty;A) = \mathbb{E}(Y_0;A)$. Hence $Y_\infty = \mathbb{E}(Y_0|\mathcal{G}_\infty)$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Suppose that $\mathbf{Y} = \{Y_t\}_{t\in T}$ is a backwards martingale with respect to $\mathscr{G} = \{\mathcal{G}_t \}_{t\in T}$. If $Y_0 \in L_k$ for some $k\in[1,\infty)$ then $Y_t \xrightarrow{t\to\infty} Y_\infty$ in $L_k$.

<details>
<summary>Proof</summary>

By the backwards martingale convergence theorem, there exists a random variable $Y_\infty \in L_1$ such that $Y_t\xrightarrow{t\to\infty} Y_\infty$ with probability $1$ in $L_1$. The function $x\mapsto |x|^k$ is convex on $\mathbb{R}$ so by Jensen's inequality

$$
  \mathbb{E}(|Y_t|^k) = \mathbb{E}[|\mathbb{E}(Y_0|\mathcal{G}_t)|^k] \leq \mathbb{E}[\mathbb{E}(|Y_0|^k \;|\; \mathcal{G}_t)] = \mathbb{E}(|Y_0|^k) < \infty
$$

so $Y_t \in L_k$ for every $t\in T$. By Fatou's lemma

$$
  \mathbb{E}(|Y_\infty|^k) \leq\liminf_{t\to\infty} \mathbb{E}(|Y_t|^k) \leq \mathbb{E}(|Y_0|^k) < \infty
$$

showing that $Y_\infty \in L_k$. Since $Y_t = \mathbb{E}(Y_0|\mathcal{G}_t)$ and $Y_\infty$ is measurable relative to $\mathcal{G}_t$, then by Jensen's inequality

$$
  |Y_t - Y_\infty|^k = |\mathbb{E}(Y_0 - Y_\infty | \mathcal{G}_t)|^k \leq \mathbb{E}(|Y_0 - Y_\infty|^k \;|\;\mathcal{G}_t)
$$

It follows that the collection of random variables $\{|Y_t - Y_\infty|^k\}_{t\in T}$ is uniformly integrable, and hence $\lim_{t\to\infty} \mathbb{E}(|Y_t - Y_\infty|^k) = 0$.
</details>
</MathBox>

#### Strong law of large numbers

<MathBox title='Strong law of large numbers' boxType='theorem'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}_+}$ is a sequence of independent, identically distributed random variables with common mean $\mu\in\mathbb{R}$. Let $Y_n = \sum_{i=1}^n X_i,\;n\in\mathbb{N}$ so that $\mathbf{Y} = \{ Y_n \}_{n\in\mathbb{N}}$ is the partial sum process associated with $\mathbf{X}$. Let $M_n = Y_n / n$ for $n\in\mathbb{N}_+$ so that $\mathbf{M} = \{M_n\}_{n\in\mathbb{N}_+}$ is the sequence of sample means.

1. $\lim_{n\to\infty} M_n = \mu$ with probability $1$
2. $\lim_{n\to\infty} M_n = \mu$ in mean

<details>
<summary>Proof</summary>

For $n\in\mathbb{N}$ let

$$
  \mathcal{G}_n = \sigma\{Y_n, Y_{n+1}, Y_{n+2}, \dots\} = \sigma\{Y_n, X_{n+1}, X_{n+2}, \dots\} = 
$$

so that $\mathscr{G} = \{\mathcal{G}_n\}_{n\in\mathbb{N}}$ is a decreasing family of sub $\sigma$-algebras of $\mathcal{F}$. The core of the proof is to show that $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. For $n\in\mathbb{N}_+$, clearly $M_n$ is measurable with respect to $\mathcal{G}_n$. By independence $\mathbb{E}(X_i|\mathcal{G_n}) = \mathbb{E}(X_i|Y_n)$ for $i\in\{1,2,\dots,n\}$. By symmetry, $\mathbb{E}(X_i|Y_n) = \mathbb{E}(X_j|Y_n)$ for $i,j\in\{1,2,\dots,n\}$. Thus

$$
\begin{align*}
  Y_n &= \mathbb{E}(Y_n|\mathcal{G}_n) = \sum_{j=1}^n \mathbb{E}(X_j|\mathcal{G}_n) \\
  &= \sum_{j=1}^n \mathbb{E}(X_i|\mathcal{G}_n) = n\mathbb{E}(X_i|\mathcal{G}_n)
\end{align*}
$$

so that $\mathbb{E}(X_i|\mathcal{G}_n) = Y_n/n = M_n$ for each $i\in\{1,2,\dots,n\}$. Next

$$
\begin{align*}
  \mathbb{E}(Y_n|\mathcal{G}_{n+1}) &= \mathbb{E}(Y_{n+1} - X_{n+1}|\mathcal{G}_{n+1}) \\
  &= Y_{n+1} - \mathbb{E}(X_{n+1}|\mathcal{G}_{n+1}) \\
  &= Y_{n+1} - \frac{1}{n+1}Y_{n+1} = \frac{n}{n+1}Y_{n+1}
\end{align*}
$$

Dividing by $n$ gives $\mathbb{E}(M_n|\mathcal{G}_{n+1}) = M_{n+1}$ and hence $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. From the backwards martingale convergence theorem, there exists $M_\infty$ such that $M_n \xrightarrow{n\to\infty} M_\infty$ with probability $1$ and in mean. For $n,k\in\mathbb{N}_+$

$$
  M_{n+k} = \frac{1}{n+k}\sum_{i=1}^k X_i + \frac{n}{n+k}\frac{1}{n}\sum_{i=k+1}^{k+n} X_i
$$

Letting $n\to\infty$ gives

$$
  M_\infty = \lim_{n\to\infty}\frac{1}{n}\sum_{i=k+1}^{k+n} X_i
$$

for every $k\in\mathbb{N}_+$. Hence $M_\infty$ is a tail random variable for $\mathbf{X}$. From the Kolmogorov 0-1 law, $M_\infty$ must be a constant. Convergence in mean implies that the means converge, and since $\mathbb{E}(M_n) = \mu$ for each $n$, it follows that $M_\infty = \mu$.
</details>
</MathBox>

#### Exchangeable variables

Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is a sequence of random variables each taking values in $S$. Recall that $\mathbf{X}$ is exchangeable if for every $n\in\mathbb{N}$, every permutation of $\mathbf{X}$ has the same distribution on $(S^n,\mathcal{S}^n)$. Clearly if $\mathbf{X}$ is a sequence of indepedent, identically distributed variables, then $\mathbf{X}$ is exchangeable. Conversely, if $\mathbf{X}$ is exchangeable, by definition the variables are identically distributed, but not necessarily indepedent. On the other hand conditionally indepedent and identically distributed sequences are exchangeable.

<MathBox title='' boxType='proposition'>
Suppose that $\Theta$ is a random variable on $(T,\mathcal{T})$. If $\mathbf{X}$ is conditionally indepedent and indentically distributed given $\Theta$, then $\mathbf{X}$ is exchangeable.

<details>
<summary>Proof</summary>

Implicit in the statement is that the variables in the sequence have a regular conditional distribution $\mu_\Theta$ given $\Theta$. For every $n\in\mathbb{N}_+$, the conditional distribution of every permutation of $(X_i)_{i=1}^n$, given $\Theta$ is $\mu_\Theta^n$ on $(S^n,\mathcal{S}^n)$ where $\mu_\Theta^n$ is the $n$-fold product measure. Unconditionally, the distribution of any permutation is $B\mapsto \mathbb{E}[\mu_\Theta^n (B)]$ for $B\in\mathcal{S}^n$
</details>
</MathBox>

<MathBox title="de Finetti's theorem" boxType='theorem'>
Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is an exchangeable sequence of random variables, each taking values in $\{0,1\}$. Then there exists a random variable $P$ with values in $[0,1]$ such that given $P = p\in[0,1]$, then $\mathbf{X}$ is a sequence of Bernoulli trials with success parameter $p$

<details>
<summary>Proof</summary>

Recall the falling power notation $r^{(j)} = r(r-1)\cdots(r-j+1)$ for $r\in\mathbb{R}$ and $j\in\mathbb{N}$. For $n\in\mathbb{N}_+$ and $k\in\{0,1,\dots,n\}$ let

$$
  B_k^n = \left\{ (x_1, x_2, \dots, x_n)\in \{0,1\}^n \mid| \sum_{i=0}^n x_i = k \right\}
$$

That is, $B_k^n$ is the set of bit strings of length $n$ with $1$ occurring exactly $k$ time. Note that $|B_n^k| = \binom{n}{k} = n^{(k)}/k!$.

$\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is an exchangeable sequence variables with values in $\{0,1\}$. For $n\in\mathbb{N}_+$ let $Y_n = \sum_{n=1}^n X_i$ and $M_n = Y_n / n$, such that $\mathbf{Y} = \{Y_n\}_{n\in\mathbb{N}_+}$ is the partial sum process associated with $\mathbf{X}$ and $\mathbf{M} = \{ M_n \}_{n\in\mathbb{N}_+}$ the sequence of sample means. Let $\mathcal{G}_n = \sigma\{Y_n, Y_{n+1},\dots \}$ and $\mathcal{G}_\infty = \bigcap_{n=0}^\infty \mathcal{G}_n$. The family of $\sigma$-algebras $\mathscr{G} = \{\mathcal{G}_n\}_{n\in\mathbb{N}_+}$ is the decreasing. The key to the proof is to find two backwards martingales and use the backwards martingale convergence theorem.

Let $m\in\matbb{N}_+$ and $k\in\{0,1,\dots,m\}$. By exchangeability, the random vector $(X_i)_{i=1}^m$ given $Y_n = k$ is uniformly distributed on $B_k^m$. If $n\in\mathbb{N}_+$ and $n\leq m$, the random vector $(X_i)_{i=1}^m$ fits the hypergeometric model. Thus if $j\in\{0,1,\dots,n\}$ and $(x_i)_{i=1}^n \in B_j^n$ then

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n \;|\; Y_m = k) = \frac{k^{(j)}(m-k)^{(n-j)}}{m^{(n)}}
$$

Equivalently

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n \;|\; Y_m) = \frac{Y_m^{(j)}(m-Y_m)^{(n-j)}}{m^{(n)}}
$$

Given $Y_m$, the variables $(Y_{m+1}, Y_{m+1},\dots)$ give no additional information about the distribution of $(X_i)_{i=1}^n$ and hence

$$
\begin{align*}
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n|\mathcal{G}_m) &= \mathbb{E}[\mathbf{1}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n)|\mathcal{G}_m] \\
  &= \frac{Y_m^{(j)}(m-Y_m)^{(n-j)}}{m^{(n)}}
\end{align*}
$$

For fixed $n,j$ and $(x_i)_{i=1}^n \in B_j^n$, the conditional expected value, as a function of $m$, is a Doob backward martingale relative to $\mathscr{G}$ and hence converges to $\mathbb{P}(X_1 = x_1, X_2 = x_2,\dots, X_n = x_n|\mathcal{G}_\infty)$ as $m\to\infty$.

Next we show that $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. Trivially, $M_n$ is measurable with respect to $\mathcal{G}_n$ and $\mathbf{E}(M_n) \leq 1$ for each $n\in\mathbb{N}$. Thus we need to show that $\mathbb{E}(M_n | \mathcal{G}_m) = M_m$ for $m,n\in\mathbb{N}_+$ with $n\leq m$. We already know that the conditional distribution of $Y_n$ given $Y_m = k$ is hypergeometric with parameters $m,k$ and $n$

$$
  P(Y_n = j|Y_m = k) = \binom{n}{j}\frac{k^{(j)}(m - k)^{(n-j)}}{m^{(n)}},\; j\in\{0,1,\dots,n\}
$$

Recall that the mean of the hypergeometric distribution is the sample size times the proportion of type $1$ object in the population, giving

$$
  \mathbb{E}(Y_n = j | Y_m = k) = \frac{1}{n}\mathbb{E}(Y_n | Y_m = k) = \frac{1}{n}n\frac{k}{m} = \frac{k}{m}
$$

Equivalently $\mathbb{E}(M_n | Y_m) = Y_m / m = M_m$. Given $Y_m$, the variables $(Y_{m+1}, Y_{m+2},\dots)$ give no additional information and so $\mathbf{E}(Y_n|\mathcal{G}_m) = Y_m$. Hence $\mathbf{M}$ is a backwards martingale relative to $\mathscr{G}$. From the backwards martingale convergence theorem there exists a random variable $P$ such that $M_n \xrightarrow{n\to\infty} P$ with probability $1$.

Suppose that $n\in\mathbb{N}_+$ and $j\in\{0,1,\dots,n\}$ and that $m\in\mathbb{N}_+$ and $k_m \in \{0,1,\dots,m \}$. If $n,j$ are fixed and $\lim_{m\to\infty} k_m / m = p \in [0,1]$ then

$$
  \lim_{m\to\infty} \frac{k_m^{(j)}(m - k_m)^{(n-j)}}{m^{(n)}} = p^j (1 - p)^{n-1}
$$

Since $Y_m / m \xrightarrow{m\to\infty} P$ we get

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots,X_n = x_n|\mathcal{G}_\infty) = P^j (1 - P)^{n-j} 
$$

Since the random variable $P$ is measurable with respect to $\mathcal{G}_\infty$ then as $m\to\infty$

$$
  \mathbb{P}(X_1 = x_1, X_2 = x_2,\dots,X_n = x_n|P) = P^j (1 - P)^{n-j} 
$$

Given $P = p\in[0,1]$, it follows that $\mathbf{X}$ is a sequence of Bernoulli trials with success parameter $p$.
</details>
</MathBox>

De Finetti's theorem states that the distribution of $n$ distinct variables in the exchangeable sequence is a mixture of the product measures. If $\mu_\theta$ is the distribution of a generic $X$ on $(S,\mathcal{S})$ given $\Theta = \theta$ and $\nu$ is the distribution of $\Theta$ on $(T,\mathcal{T})$, then the distribution $n$ of the variables on $(S^n, \mathcal{S}^n)$ is

$$
  B\mapsto \int_T \mu_\theta^n (B)\,\mathrm{d}\nu(\theta)
$$

If $\mathbf{X} = (X_n)_{n\in\mathbb{N}_+}$ is an exchangeable sequence of random variables, each taking values in a measurable space $(S,\mathcal{S})$, then there exists a random variable $\Theta$ such that $\mathbf{X}$ is independent and indentically distributed given $\Theta$. The generalization of de Finetti's theorem is central in Bayesian statistical inference. For and exchangeable sequence of random variables (observations in a statistical experiment), there is a hidden, random parameter $\Theta$. Given $\Theta = \theta$, the variables are indepedent and identically distributed. We gain information about $\Theta$ by imposing a *prior distribution* on $\Theta$ and the updating thes, based on our observations and using Baye's theorem, to a posterior distribution.

### Examples

#### Constant sequence

<MathBox title='Martingale condition for constant sequences' boxType='proposition'>
Suppose that $X$ is a random variable that is measurable with respect to $\mathcal{F}_0\in\mathscr{F}$, and with $\mathbb{E}(|X|) < \infty$. Let $X_t = X$ for $t\in T$. Then the constant sequence process $\mathbf{X} = \{ X_t \}_T$ is a martingale with respect to $\mathscr{F}$.

<details>
<summary>Proof</summary>

Since $X$ is measurable with respect to $\mathcal{F}_0$, it is measurable with respect to $\mathcal{F}_t$ for all $t\in T$. Thus $\mathbf{X}$ is adapted to $\mathscr{F}$. If $s,t\in T$ with $s\leq t$, then

$$
  \mathbb{E}(X_t |\mathcal{F}_s) = \mathbb{E}(X | \mathcal{F}_s) = X = X_s
$$
</details>
</MathBox>

#### Lévy process

<MathBox title='Martingale conditions for processes with independent increments' boxType='proposition'>
Suppose that the continuous process $\mathbf{X} = \{X_t\}_{t\in [0,\infty)}$ has independent increments, and let $m(t) = \mathbb{E}(X_t)$ for $t\in [0,\infty)$. Then $\mathbf{X}$ is
1. Martingale if $m$ is constant.
2. Sub-martingale if $m$ is increasing.
3. Super-martingale if $m$ is decreasing.

Let $Y_t = X_t - m(t)$. The process $\mathbf{Y} = \{ Y_t \}_{t\in[0,\infty)}$ is called the compensated process associated with $\mathbf{X}$ and has mean $0$. If $\mathbf{X}$ has independent increments, so does $\mathbf{Y}$, making it a martingale.

<details>
<summary>Proof</summary>

Suppose that $s,t\in[0,\infty)$ with $s< t$. Then

$$
\begin{align*}
  \mathbb{E}(X_t | \mathcal{F}_s) &= \mathbb{E}\left[X_s + (X_t - X_s) |\mathcal{F}_s \right] \\
  &= \mathbb{E}(X_s |\mathcal{F}_s ) + \mathbb{E}(X_t - X_s |\mathcal{F}_s)
\end{align*}
$$

Since $X_s$ is measurable to $\mathcal{F}_s$ and $X_t - X_s$ is independent of $\mathcal{F}_s$, we obtain

$$
\begin{align*}
   \mathbb{E}(X_t | \mathcal{F}_s) &= \mathbb{E}(X_s |\mathcal{F}_s ) + \mathbb{E}(X_t - X_s |\mathcal{F}_s) \\
   &= X_s + \mathbb{E}(X_t - X_s) = X_s + m(t) - m(s)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Second moment martingale for processes with independent increments' boxType='proposition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has independent increments with constant mean function, and with $\mathrm{var}(X_t) < \infty$ for $t\in T$. Let 

$$
  Y_t = X_t^2 - \mathrm{var}(X_t)\quad t\in T
$$

Then $\mathbf{Y} = \{Y_t\}$ is a martingale.

<details>
<summary>Proof</summary>

Suppose that $s,t\in T$ with $s< t$. Note that $\mathbb{E}(Y_t|\mathcal{F}_s) = \mathbb{E}(X_t^2 | \mathcal{F}_s) -\mathrm{var}(X_t)$. Rewriting $X_t^2$ as

$$
\begin{align*}
  X_t^2 &= [(X_t - X_s) + X_s]^2 \\
  &= (X_t - X_s)^2 + 2(X_t - X_s)X_s + X_s^2 
\end{align*}
$$

Since $X_t - X_s$ is independent of $\mathcal{F}_s$, $X_s$ is measurable with respect to $\mathcal{F}_s$ and $\mathbb{E}(X_t - X_s) = 0$, it follows that

$$
\begin{align*}
  \mathbb{E}(X_t^2 | \mathcal{F}_s) &= \mathbb{E}[(X_t - X_s)^2] + 2X_s \mathbb{E}(X_t - X_s) + X_s^2 \\
  &= \mathbb{E}[(X_t - X-s)^2] + X_s^2
\end{align*}
$$

Since $X_t - X_s$ also has mean $0$

$$
\begin{align*}
  \mathrm{var}(X_t) &= \mathrm{var}[(X_t - X_s) + X_s] \\
  &= \mathrm{var}(X_s) + \mathrm{var}(X_t - X_s)^2 \\
  &= \mathrm{var}(X_s) + \mathbb{E}[(X_t - X_s)^2]
\end{align*}
$$

Combining the results gives

$$
  \mathbb{E}(Y_t | \mathcal{F}_s) = X_s^2 - \mathrm{var}(X_s) = Y_s
$$
</details>
</MathBox>

<MathBox title='Martingale conditions for random walks' boxType='proposition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has stationary, independent increments, and let $a = \mathbb{E}(X_1 - X_0)$. Then $\mathbf{X}$ is
1. Martingale if $a=0$.
2. Sub-martingale if $a\geq 0$.
3. Super-martingale if $a\leq 0$.

<details>
<summary>Proof</summary>

Note that for a process with stationary, independent increments, the mean function reduces to $m(t) = \mathbb{E}(X_0) + at$ for $t\in T$. Follwing the same argument as for processes with independent increments, we get

$$
  \mathbb{E}(X_t | \mathcal{F}_s) = X_s + a(t - s)
$$
</details>
</MathBox>

<MathBox title='Second moment martingale for random walks' boxType='proposition'>
Suppose that the process $\mathbf{X} = \{X_t\}_{t\in T}$ has independent increments with $\mathbb{E}(X_0) = \mathbb{E}(X_1)$ and $b^2 = \mathbb{E}\left(X_1^2\right) < \infty$. Let

$$
  Y_t = X_t^2 - \mathrm{var}(X_0) - b^2 t,\quad t\in T
$$

Then $\mathbf{Y} = \{Y_t\}$ is a martingale.

<details>
<summary>Proof</summary>

Since $\mathbb{E}(X_0) = \mathbb{E}(X_1)$, then $\mathbf{X}$ has constant mean function. Note that $\mathrm{var}(X_t) = \mathrm{var}(X_0) + b^2 t$. Following the same argument as for second order martingales for processes with independent increments, we obtain

$$
\begin{align*}
  \mathbb{E}(Y_s|\mathcal{F}_s) &= X_s - \mathrm{var}(X_s) \\
  &= X_s - \mathrm{var}(X_0) - b^2 t = Y_s
\end{align*}
$$
</details>
</MathBox>

#### Partial sums

In discrete time, a process with independent increments reduces to a partial sum process.

<MathBox title='Martingale conditions for partial sums' boxType='definition'>
Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is a sequence of indepedent random variables with $\mathbb{E}(|V_n|) < \infty$, and let

$$
  X_n = \sum_{k=0}^n V_k
$$

Then $\mathbf{X} = \{X_n\}$ is a partial sum process associated with $\mathbf{V}$. For $n\in\mathbb{N}$, the process $\mathbf{X}$ is
1. sub-martingale if $\mathbb{E}(V_n)\geq 0$
2. super-martingale if $\mathbb{E}(V_n)\leq 0$
3. martingale if $\mathbb{E}(V_n) = 0$

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}} = \sigma\{V_i\}_{i=0}^{n\in\mathbb{N}}$. Note first that

$$
  \mathbb{E}(|X_n|) \leq \sum_{k=0}^n \mathbb{E}(|V_k|) < \infty
$$

Next

$$
\begin{align*}
  \mathbb{E}(X_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_n + V_{n+1}|\mathcal{F}_n) \\
  &= \mathbb{E}(X_n|\mathcal{F}_n) + \mathbb{E}(V_{n+1}|\mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$

The last equality holds since $X_n$ is measurable with respect to $\mathcal{F}_N$ and $V_{n+1}$ is independent of $\mathcal{F}_n$.
</details>
</MathBox>

<MathBox title='Second moment martingale for partial sums' boxType='definition'>
Let $\mathbf{X}$ be a partial sum process associated with $\mathbf{V}$. Suppose that $\mathbb{E}(V_k) = 0$ for $k\in\mathbb{N}_+$ and $\mathrm{var}(V_k) < \infty$ for $k\in\mathbb{N}$, and let 

$$
  Y_n = X_n^2 - \mathrm{var}(X_n)
$$

Then $\mathbf{Y} = \{ Y_n\}_{n\in\mathbb{N}}$ is a martingale with respect to $\mathbf{X}$.

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}}$. Since $\mathbf{V}$ is independent, note that

$$
  \mathrm{var}(X_n) = \mathrm{var}\left( \sum_{k=0}^n V_k \right) = \sum_{k=0}^n \mathrm{var}(V_k)
$$

Since $\mathbb{E}(V_k) = 0$, then $\mathrm{var}(V_k) = \mathbb{E}(V_k^2)$. In particular, $\mathbb{E}(|Y_n|) < \infty$ for $n\in\mathbb{N}$. Next

$$
\begin{align*}
  \mathbb{E}(Y_{n+1}|\mathcal{F}_n) &= \mathbb{E}[X_{n+1}^2 - \mathrm{var}(X_{n+1}|\mathcal{F}_n)] \\
  &= \mathbb{E}\left[(X_n + V_{n+1})^2 - \mathrm{var}(X_{n+1})|\mathcal{F}_n \right] \\
  &= \mathbb{E}\left[ X_n^2 + 2X_n V_{n+1} + V_{n+1}^2 - \mathrm{var}(X_{n+1})|\mathcal{F}_n \right] \\
  &= X_n^2 + 2X_n\mathbb{E}(V_{n+1}) + \mathbb{E}(V_{n+1}^2) - \mathrm{var}(X_{n+1})
\end{align*}
$$

Next

$$
\begin{align*}
  \mathbb{E}(X_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_n + V_{n+1}|\mathcal{F}_n) \\
  &= \mathbb{E}(X_n|\mathcal{F}_n) + \mathbb{E}(V_{n+1}|\mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$
</details>
</MathBox>

#### Difference sequence

<MathBox title='Martingale difference sequence' boxType='definition'>
Suppose that $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a discrete process adapted to $\mathscr{F}$. Let $V_0 = X_0$ and $V_n = X_n - X_{n-1}$ for $n\in\mathbb{N}$. The process $\mathbf{V} = \{ V_n\}_{n\in\mathbb{N}}$ is the martingale difference sequence associated with $\mathbf{X}$ such that for $n\in\mathbb{N}$

$$
  X_n = \sum_{k=0}^n V_k
$$
</MathBox>

<MathBox title='Properties of martingale difference sequence' boxType='proposition'>
Let $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ be a discrete process adapted to $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$. Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is the martingale difference sequence associate with $\mathbf{X}$. Then
1. $\mathbb{V}$ is adapted to $\mathscr{F}$.
2. $\mathbb{E}(V_n|\mathcal{F}_k) = 0$ for $k,n\in\mathbb{N}$ with $k< n$.
3. $\mathbb{E}(V_n) = 0$ for $n\in\mathbb{N}_+$
4. If $\mathrm{var}(X_n) < \infty$ for $n\in\mathbb{N}$, then $\mathbf{V}$ is an uncorrelated sequence and

$$
  \mathrm{var}(X_n) = \sum_{k=0}^n \mathrm{var}(V_k) = \mathrm{var}(X_0) + \sum_{k=1}^n \mathbb{E}\left(V_k^2\right)
$$

<details>
<summary>Proof</summary>

1. Obviously, $V_0 = X_0$ is measurable with respect to $\mathcal{F}_0$. For $n\in\mathbb{N}_+$, then $X_n$ and $X_{n-1}$ and thus $V_n$ are measurable with respect to $\mathcal{F}_n$. Hence $\mathbf{V}$ is adapted to $\mathscr{F}$.
2. Let $k\in\mathbb{N}$. By the martingale and adapted properties

$$
\begin{align*}
  \mathbb{E}\left( V_{k+1} | \mathcal{F}_k \right) &= \mathbb{E}(X_{k+1}|\mathcal{F}_k) - \mathbb{E}(X_k | \mathcal{F}_k) \\
  &= X_k - X_k = 0
\end{align*}
$$

By the tower property of conditional expectation

$$
  \mathbb{E}\left( V_{k+1} | \mathcal{F}_k \right) = \mathbb{E}[\mathbb{E}(V_{k+2}|\mathcal{F}_{k+1})|\mathcal{F}_k] = 0
$$

The result follows from induction.
3. Since $\mathbf{X}$ is a martingale, it has constant mean. Hence $\mathbb{E}(V_n) = \mathbb{E}(X_n) - \mathbb{E}(X_{n-1}) = 0$ for $n\in\mathbb{N}_+$.
4. Let $k,n\in\mathbb{N}$ with $k< n$. To show that $V_k$ and $V_n$ are uncorrelated, we just have to show that $\mathbb{E}(V_k V_n) = 0$ since $\mathbb{E}(V_n) = 0$. By $(3)$

$$
\begin{align*}
  \mathbb{E}(V_k V_n) &= \mathbb{E}[\mathbb{E}(V_k V_n |\mathcal{F}_k)] \\
  &= \mathbb{E}[V_k\mathbb{E}(V_n|\mathcal{F}_k)] = 0
\end{align*}
$$

To prove the formula for $\mathrm{var}(X_n)$, note that the variance of a sum of uncorrelated variables is the sum of the variances. Since $V_k$ has mean $0$, then $\mathrm{var}(V_k) = \mathbb{E}(V_k^2)$ for $k\in\mathbb{N}_+$. Hence it follows that

$$
  \mathrm{var}(X_n) = \sum_{k=0}^n \mathrm{var}(V_k) = \mathrm{var}(X_0) + \sum_{k=1}^n \mathbb{E}\left(V_k^2\right)
$$
</details>
</MathBox>

#### Partial products

<MathBox title='Martingale conditions for partial products' boxType='proposition'>
Suppose that $\mathbf{V} = \{V_n\}_{n\in\mathbb{N}}$ is an sequence of indepedent random variables with $\mathbb{E}(|V_n|) < \infty$, and let

$$
  X_n = \prod_{k=0}^n V_k
$$

Then $\mathbf{X} = \{X_n\}$ is a partial products process associated with $\mathbf{V}$. For $n\in\mathbb{N}$, the process $\mathbf{X}$ is
1. martingale if $\mathbb{E}(V_n) = 0$
2. sub-martingale if $\mathbb{E}(V_n) \geq 1$
3. super-martingale if $\mathbb{E}(V_n)\leq 1$

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{X_i \}_{i=0}^{n\in\mathbb{N}} = \sigma\{V_i\}_{i=0}^{n\in\mathbb{N}}$. Since the random variables are independent

$$
  \mathbb{E}(X_n) = \prod_{k=0}^n \mathbb{E}(V_k) < \infty
$$

Next, since $X_n$ is measurable with respect to $\mathcal{F}_n$ and $V_{n+1}$ is indepedent of $\mathcal{F}_n$
$$
\begin{align*}
  \mathbb{E}(X_{n+1}|\mathcal{F}_n) &= \mathbb{E}(X_n V_{n+1}|\mathcal{F}_n) \\
  &= X_n \mathbb{E}(V_{n+1}|\mathcal{F}_n) \\
  &= X_n + \mathbb{E}(V_{n+1})
\end{align*}
$$

</details>
</MathBox>

#### Likelihood ratio test

Let $(S,\mathcal{S},\mu)$ be a measure space. Suppose that $\mathbf{X} = \{ X_n \}_{n\in\mathbb{N}}$ is a sequence of independent, identically distributed random variables, taking values in $S$. In statistical terms, $\mathbf{X}$ corresponds to sampling from the common distribution, and a central statistical problem is to draw inferences about the distribution from observations of $\mathcal{X}$. Suppose that the underlying distribution either has probability density functions $g_0$ or $g_1$ with respect to a measure $\mu$. The Likelihood ratio test is a hypothesis test, where the null and alternative hyptheses are

- $H_0$: the probability density function is $g_0$
- $H_1$: the probability density function is $g_1$

The test is based on the test statistical

$$
  L_n = \prod_{i=1}^n \frac{g_0(X_i)}{g_i (X_i)},\; n\in\mathbb{N}
$$

known as the likelihood ratio test statistic. Small values of the test statistic are evidence in favor of the alternative hypothesis $H_1$.

<MathBox title='Likelihood ratio martingale' boxType='proposition'>
Under the alternative hypothesis $H_1$, the process $\mathbf{L} = \{ L_n \}_{n\in\mathbb{N}}$ is a martingale with respect to $\mathbf{X}$, known as the likelihood ratio martingale.

<details>
<summary>Proof</summary>

Let $\mathcal{F}_n = \sigma\{ X_i \}_{i=1}^n$. Since $L_n$ is measurable with respect to $\mathcal{F}_n$ and $\frac{g_0(X_{n+1})}{g_1(X_{n+1})}$ is independent of $\mathcal{F}_n$ we have

$$
  \mathbb{E}(L_{n+1}\;|\;\mathcal{F}_n) = \mathbb{E}\left[ L_n \frac{g_0(X_{n+1})}{g_1(X_{n+1})}\mid| \mathcal{F}_n \right] = L_n\mathbb{E}\left[\frac{g_0(X_{n+1})}{g_1(X_{n+1})}\mid| \mathcal{F}_n \right]
$$

Using the change of variables formula for expected value under $H_1$ gives

$$
  \mathbb{E}\left[\frac{g_0(X_{n+1})}{g_1(X_{n+1})}\mid| \mathcal{F}_n \right] = \int_S \frac{g_0(x)}{g_1(x)}g_1(x)\,\mathrm{d}\mu(x) = \int_S g_0(x)\,\mathrm{d}\mu(x) = 1
$$
</details>
</MathBox>

<MathBox title='Likelihood ratio martingale' boxType='proposition'>
Under the alternative hypothesis $H_1$, then $L_n \xrightarrow{n\to\infty} 0$ with probability $1$.

<details>
<summary>Proof</summary>

Assume that $H_1$ is true. Since $\mathbf{L}$ is a nonnegative martingale, the first martingale convergence theorem applies and there exists a random variable $L_\infty$ with values in $[0,\infty)$ such that $L_n \xrightarrow{n\to\infty} L_\infty$ with probability $1$. Note that

$$
  \ln{L_n} = \sum_{i=1}^n \ln\left[\frac{g_0(X_i)}{g_1(X_i)}\right]
$$

The variables $\ln\left[\frac{g_0(X_i)}{g_1(X_i)}\right]$ for $i\in\mathbb{N}_+$ are also independent and identically distributed, so let $m$ denote the common mean. The natural logarithm is concave and the martingale $\mathbf{L}$ has mean $1$, so by Jensen's inequality

$$
  m = \mathbb{E}\left(\ln\left[\frac{g_0(X_i)}{g_1(X_i)}\right]\right) < \ln\left(\mathbb{E}\left[\frac{g_0(X_i)}{g_1(X_i)}\right]\right) = \ln(1) = 0
$$

It follows that $m\in[-\infty, 0)$. By the strong law of large numbers, $\lim_{n\to\infty}\frac{1}{n}\ln(L_n) = m$ with probability $1$. Hence we must have $\lim_{n\to\infty} \ln(L_n) = -\infty$ with probability $1$. By continuity $\lim_{n\to\infty} (L_n) = \ln(L_\infty)$ with probability $1$ so $L_\infty = 0$ with probability $1$.
</details>
</MathBox>

Small values of $L_n$ are evidence in favor of $H_1$ and the decision rule is to reject $H_0$ in favor of $H_1$ if $L_n \leq l$ for a chosen critical value $l\in (0,\infty)$. If $H_1$ is true and the sample size $n$ is sufficiently large, we will reject $H_0$. Since $\mathbf{L}$ is a mean $1$ martingale (under $H_1$), $\lim_{n\to\infty}\mathbf{E}(L_n) = 1$ even though $\lim_{n\to\infty} L_n = 0$ with probability $1$. 

#### Doob's martingale

<MathBox title="Doob's martingale" boxType='proposition'>
Suppose that $\mathscr{F} = \{\mathcal{F}_t \}_{t\in T}$ is a filtration on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ and that $X$ is a real-valued random variable with $\mathbb{E}(|X|)< \infty$. Define $X_t = \mathbb{E}(X|\mathcal{F}_t)$ for $t\in T$. Then $\mathbf{X} = \{ X_t \}_{t\in T}$ is a martingale with respect to $\mathscr{F}$.

Note that $\mathbf{E}(|X|) < \infty$ implies that $X$ is uniformly integrable. Thus the second martingale convergence theorem states that every uniformly integrable martingale is a Doob martingale.

<details>
<summary>Proof</summary>

For $t\in T$, recall that $|X_t| = |\mathbb{E}(X|\mathcal{F}_t)| \leq \mathbb{E}(|X_t|\;|\;\mathcal{F}_t)$. Taking expected values gives $\mathbb{E}(|X_t|)\leq\mathbb{E}(|X|)< \infty$. Suppose that $s,t\in T$ with $s< t$. Using the tower property of conditional expected value

$$
  \mathbb{E}(X_t|\mathcal{F}_s) = \mathbb{E}\left[\mathbb{E}(X|\mathcal{F}_t)|\mathcal{F}_s \right] = \mathbb{E}(X|\mathcal{F}_s) = X_s
$$
</details>
</MathBox>

Doob's martingale arises naturally in Bayesian estimations. Suppose that $\mathbf{X} = (X_n)_{n\in\mathbb{N}}$ is a sequence of indepedent random variables whose common distribution depends on an unknown real-valued parameter $\theta$, with values in the parameter space $A\subseteq\mathbb{R}$. For each $n\in\mathbb{N}_+$ let $\mathcal{F}_n = \sigma\{X_i\}_{i=1}^n$ so that $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}_+}$ is the natural filtration associated with $\mathbf{X}$. In Bayesian estimation, we model the unknown parameter $\theta$ with a random variable $\Theta$ taking values in $A$ and having a specified prior distribution. The Bayesian estimator of $\theta$ based on the sample $\mathbf{X}_n = \{ X_i \}_{i=1}^n$ is 

$$
  U_n = \mathbb{E}(\Theta | \mathcal{F}_n),\; n\in\mathbb{N}
$$

It follows that the sequence of Bayesian estimators $\mathbf{U} = (U_n)_{n\in\mathbb{N}_+}$ is a Doob martingale.

<MathBox title='' boxType='proposition'>
Let $\mathbf{X} = \{X_t\}_{t\in T}$ be the Doob martingale constructed from $X$ and $\mathscr{F}$. Then $X_t \xrightarrow{t\to\infty} X_\infty$ with probability $1$ and in mean, where

$$
  X_\infty = \mathbb{E}(X|\mathcal{F}_\infty)
$$
</MathBox>

#### Density functions

For the following discussion, let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ a filtration in discrete time. Note that $\mathcal{F}_\infty = \sigma\left(\bigcup_{n=0}^\infty \mathcal{F}_n \right)$ Suppose that $\mu$ is a finite measure on the sample space $(\Omega,\mathcal{F})$. For each $n\in\mathbb{N}\cup\{\infty\}$, the restriction of $\mu$ to $\mathcal{F}_n$ is a measure on the measurable space $(\Omega,\mathcal{F}_n)$, and similarly the restriction of $\mathbb{P}$ to $\mathcal{F}_n$ is a probability measure on $(\Omega, \mathcal{F}_n)$. For simplicity, these will be referred to as $\mu$ and $\mathbb{P}$ of $\mathcal{F}_n$, respectively.

Suppose now that $\mu$ is absolutely continuous relative to $\mathbb{P}$ on $\mathcal{F}_n$ for each $n\in\mathbb{N}$. This means that if $A\in\mathcal{F}_n$ and $\mathbb{P}(A) = 0$ then $\mu(B) = 0$ for every $B\in\mathcal{F}_n$ with $B\subseteq A$. By the Radon-Nikodym theorem, $\mu$ has a density function $X_n :\Omega\to\mathbb{R}$ with respect to $\mathbb{P}$ on $\mathcal{F}_n$ for each $n\in\mathbb{N}_+$, which is known as the Radon-Nikodym derivative.

<MathBox title='' boxType='proposition'>
The sequence of density functions $\mathbf{X} = \{X_n\}_{n\in\mathbb{N}}$ is a martingale relative to $\mathscr{F}$.

<details>
<summary>Proof</summary>

By definition $X_n$ is measurable with respect to $\mathcal{F}_n$. Also $\mathbb{E}(|X_n|) = \lVert\mu\rVert$, i.e. the total variation of $\mu$, for each $n\in\mathbb{N}$. Since $\mu$ is a finite measure $\lVert\mu\rVert < \infty$. By definition

$$
  \mu(A) = \int_A X_n\;\mathrm{d}\mathbb{P} = \mathbb{E}(X_n; A),\; A\in\mathcal{F}_n
$$

On the other hand, if $A\in\mathcal{F}_n$ then $A\in\mathcal{F}_{n+1}$ and so $\mu(A) = \mathbb{E}(X_{n+1};A)$. Since $X_n$ is measurable with respect to $\mathcal{F}_n$ and $\mathbb{E}(X_{n+1};A) = \mathbb{E}(X_n;A)$ for all $A\in\mathcal{F}_n$, if follows that $\mathbb{E}(X_{n+1}|\mathcal{F}_n) = X_n$. Hence $\mathbf{X}$ is a martingale relative to $\mathscr{F}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
There exists a random variable $X_\infty$ such that $X_n \xrightarrow{n\to\infty} X_\infty$ with probability $1$.

1. If $\mu$ is absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$ then $X_\infty$ is a density function of $\mu$ with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$.
2. If $\mu$ and $\mathbb{P}$ are mutually singular on $\mathcal{F}_\infty$ then $X_\infty = 0$ with probability $1$.

<details>
<summary>Proof</summary>

Since $\mu$ is a finite measure, $\lVert\mu\rVert < \infty$ and the first martingale convergence applies. Thus, there exists a random variable $X_\infty$ measurable relative to $\mathcal{F}_\infty$ such that $X_n \xrightarrow{n\to\infty}X_\infty$.

1. If $\mu$ is absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$, then $\mu$ has a density function $Y_\infty$ with respect to $\mathbb{P}$ on $\mathcal{F}_\infty$. It remains to show that $X_\infty = Y_\infty$ with probability $1$. By definition $Y_\infty$ is measurable with respect to $\mathcal{F}_\infty$ and

$$
  \int_A Y_\infty\;\mathrm{d}\mathbb{P} = \mathbb{E}(Y_\infty; A) = \mu(A),\; A\in\mathcal{F}_\infty
$$

Suppose that $n\in\mathbb{N}$ and $A\in\mathcal{F}_n$. By definition $\mathbb{E}(X_n;A) = \mu(A)$. Since $A\in\mathcal{F}_\infty$, then $\mathbb{E}(Y_\infty;A) = \mu(A)$. Also, since $X_n$ is measurable relative to $\mathcal{F}_n$ it follows that $X_n = \mathbb{E}(Y_\infty |\mathcal{F}_n)$, showing that $\mathbf{X}$ is the Doob martingale associated with $Y_\infty$. By the convergence property of Doob martingales $X_\infty = \mathbb{E}(X_\infty|\mathcal{F}_\infty) = Y_\infty$ with probability $1$ as $n\to\infty$.

2. Suppose that $\mu$ and $\mathbb{P}$ are mutually singular on $\mathcal{F}_\infty$. Assume first that $\mu$ is a positive measure, so that $X_n$ is nonnegative for $n\in\mathbb{N}\cup{\infty}$. By the definition of mutual singularity, there exists $B\in\mathcal{F}_\infty$ such that $\mu_\infty (B) = 0$ and $\mathbb{P}_\infty(B^c) = 0$, so that $\mathbb{P}(B) = 1$. We need to show that $\mathbb{E}(X_\infty; A) \leq \mu(A)$ for every $A\in\mathcal{F}_\infty$. Let

$$
  \mathcal{M} = \{ A\in\mathcal{F}_\infty \;|\; \mathbb{E}(\mathcal{F}_\infty; A)\leq\mu(A) \}
$$

Suppose that $A\in\bigcup_{k=0}^\infty \mathcal{F}_k$ so that $A\in\mathcal{F}_k$ some $k\in\mathbb{N}$. Then $A\in\mathcal{F}_n$ for all $n\geq k$ and therefore $\mathbb{E}(X_n;A) = \mu(A)$ for all $n\geq k$. By Fatou's lemmas

$$
  \mathbb{E}(X_\infty; A) \leq\liminf_{n\to\infty} \mathbb{E}(X_n;A)\leq\mu(A)
$$

showing that $A\in\mathcal{M}$. Suppose that $\{A_n \}_{n\in\mathbb{N}}$ is an increasing or decreasing sequence in $\mathcal{M}$, and let $A_\infty = \lim_{n\to\infty} A_n$ (the union in the increasing case, and the intersection in the second case). Then $\mathbb{E}(X_\infty;A_n) \leq \mu(A_n)$ for each $n\in\mathbb{N}$. By the continuity theorems, $\mathbb{E}(X_\infty;A_n) \xrightarrow{n\to\infty}\mathbb{E}(X_\infty;A_\infty)$ and $\mu(A_n)\xrightarrow{n\to\infty}\mu(A_\infty)$. Therefore $\mathbb{E}(X_\infty; A_\infty) \leq \mu(A_\infty)$ and so $A_\infty \in\mathcal{M}$. It follows that $\mathcal{M}$ is a monotone class. Since $\mathcal{M}$ contains the algebra $\bigcup_{n=0}^\infty \mathcal{F}_n$, it follows from the monotone class theorem that $\mathcal{F}_\infty \subseteq\mathcal{M}$. In particular $B\in\mathcal{M}$, so $\mathbb{E}(X_\infty) = \mathbb{E}(X_\infty;B)\leq\mu(B) = 0$ and therefore $X_\infty = 0$ with probability $1$. If $\mu$ is a general finite measure, the by the Jordan decomposition theorem, $\mu$ can be written uniquely in the form $\mu = \mu^+ - \mu^-$ where $\mu^+$ and $\mu^-$ are finite positive measures. Moreover, $X_n^+$ is the density function of $\mu^+$ on $\mathcal{F}_n$ and $X_n^-$ is the density function of $\mu^-$ on $\mathcal{F}_n$. By the first part of the proof $X^+ = 0 = X^-$ so $X = 0$ all with probability $1$.
</details>
</MathBox>

In certain cases, martingales can be used to give a probabilistic proof of the Radon-Nikodym theorem. Starting from a sample set $\Omega$, suppose that $\mathcal{A}_n = \{ A_i^n \}_{i\in I_n}$ is a countable partition of $\Omega$ for each $n\in\mathbb{N}$. That is, $I_n$ is countable, $A_i^n \cap A_j^n = \emptyset$ for distinct $i, j\in I_n$ and $\bigcup_{i\in I_n} A_i^n = \Omega$. Suppose also that $\mathcal{A}_{n+1}$ refines $\mathcal{A}_n$ for each $n\in\mathbb{N}$ in the sense that $A_i^n$ is a union of sets in $\mathcal{A}_{n+1}$ for each $i\in I_n$. 

Let $\mathcal{F}_n = \sigma(\mathcal{A}_n)$. Thus $\mathcal{F}_n$ is generated by a countable partition, and the sets in $\mathcal{F}_n$ are of the form $\bigcup_{j\in J} A_j^n$ where $J\subseteq I_n$. By the refinement property $\mathcal{F}_n\subseteq\mathcal{F}_{n+1}$ so that $\mathscr{F} = \{\mathcal{F}_n\}_{n\in\mathbb{N}}$ is a filtration. Let $\mathcal{F} = \mathcal{F}_\infty = \sigma\left( \bigcup_{n=0}^\infty \mathcal{F}_n \right) = \sigma\left( \bigcup_{n=0}^\infty \mathcal{A}_n \right)$, forming the sample space $(\Omega,\mathcal{F})$. Suppose that $\mathbb{P}$ is a probability measure on $(\Omega,\mathcal{F})$ with the property that $\mathbb{P}(A_i^n) > 0$ for $n\in\mathbb{N}$ and $i\in I_n$. These constructions gives the probability space $(\Omega,\mathcal{F},\mathbb{P})$.

Suppose that $\mu$ is a finite measure on $(\Omega,\mathcal{F})$. By assumption, the only null set for $\mathbb{P}$ on $\mathcal{F}_n$ is $\emptyset$, making $\mu$ automatically absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}_n$.

<MathBox title='' boxType='proposition'>
The density function of $\mu$ with respect to $\mathbb{P}$ on $\mathcal{F}_n$ is the random variable $X_n$ defined by

$$
  X_n := \sum_{i\in I_n}\frac{\mu(A_i^n)}{\mathbb{P}(A_i^n)}\mathbf{1}(A_i^n)
$$

<details>
<summary>Proof</summary>

We need to show that $\mu(A) = \mathbb{E}(X_n;A)$ for each $A\in\mathcal{F}_n$. Suppose that $A = \bigcup_{j\in J} A_j^n$ where $J\subseteq I_n$, then

$$
\begin{align*}
  \mathbb{E}(X_n;A) &= \sum_{j\in J}\mathbb{E}(X_n;A_j^n) \\
  &= \sum_{j\in J}\frac{\mu(A_j^n)}{\mathbb{P}(A_j^n)}\mathbb{P}(A_j^n) \\
  &= \sum_{j\in J}\mu(A_j^n) = \mu(A)
\end{align*}
$$
</details>
</MathBox>

For a concrete example, consider $\Omega = [0,1)$. For $n\in\mathbb{N}$ let

$$
  \mathcal{A}_n = \left\{ \left[\frac{j}{2^n}, \frac{j+1}{2^n} \right)\right\}_{j=0}^{2^n -1}
$$

This is the partition of $[0,1)$ into $2^n$ subintervals of equal length $1/2^n$ based on the dyadic rationals of rank $n$ or less. Note that every interval in $\mathcal{A}$ is the union of two adjacent intervals in $\mathcal{A}_{n+1}$, so the refinement property holds. Let $\mathbb{P}$ be the ordinary Lebesgue measure on $[0,1)$ so that $\mathbb{P}(A_i^n) = 1/2^n$ for $n\in\mathbb{N}$ and $i\in \{0,1,\dots,2^n-1\}$. Let $\mathcal{F}_n = \sigma(\mathcal{A}_n)$ and $\mathcal{F} = \sigma\left(\bigcup_{n=0}^\infty \mathcal{F}_n \right) = \sigma\left( \bigcup_{n=0}^\infty \mathcal{A}_n \right)$. Since the dyadic rationals are dense in $[0,1)$, it follows that $\mathcal{F}$ is the ordinary Borel $\sigma$-algebra on $[0,1)$. Thus, our probability space $(\Omega,\mathcal{F},\mathbb{P})$ is simply $[0,1)$ with the usual Euclidean structures. If $\mu$ is a finite measure on $([0,1),\mathcal{F})$ then the density function $\mu$ on $\mathcal{F}_n$ is the random variable $X_n$ whose value on the interval $\left[\frac{j}{2^n}, \frac{j+1}{2^n} \right]$ is

$$
  2^n \mu\left[\frac{j}{2^n}, \frac{j+1}{2^n}\right]
$$

If $\mu$ is absolutely continuous with respect to $\mathbb{P}$ on $\mathcal{F}$, then a density function of $\mu$ is $X = \lim_{n\to\infty} X_n$.