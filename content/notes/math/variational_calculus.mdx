---
title: 'Variational Calculus'
subject: 'Mathematics'
showToc: true
---

Calculus of variations provides a theoretical framework for finding extrema of functionals, which are mappings $F:X\to\mathbb{F}$ from a function space $X$ to a field $\mathbb{F}$. This framework extends the concept of optimization from finite-dimensional spaces to infinite-dimensional spaces, where the variables are functions rather than finite-dimensional vectors.

# Functional differentiation

<MathBox title='Functional' boxType='definition'>
A *functional* is a function $f:X\to\mathbb{F}$ mapping from a function space $X$ to a field $\mathbb{F}$. A functional is linear if it satisfies
1. **Homogeneity:** $f(\alpha x) = \alpha f(x)$ for $x\in X$ and $\alpha\in\mathbb{F}$
2. **Additivity:** $f(x_1 + x_2) = f(x_1) + f(x_1)$ for $x_1, x_2 \in X$

A functional $K:X^m \to\mathbb{F}$ is *m*-linear if it is linear in each argument, in which case we write $K\in\mathcal{L}^m (X,\mathbb{F})$. A functional is $f:X\to\mathbb{F}$ is quadratic if there exists a bilinear functional $K:X^2 \to\mathbb{F}$ such that $f(x) = K(x, x)$ for every $x\in X$. Any quadratic functional satisfies

$$
  f(\alpha x) = K(\alpha x, \alpha x) = \alpha K (x, \alpha x) = \alpha^2 K(x, x) = \alpha^2 f(x)
$$

A functional is continuous if $\lim_{x\to x_0} f(x) = f(x_0)$.
</MathBox>

<MathBox title='' boxType='proposition'>
Let $X$ be a normed vector space and $\mathbb{F}$ a field. If $f:X\to\mathbb{F}$ is a linear functional continuous at some point $x_0$, then $f$ is continuous on $X$.

<details>
<summary>Proof</summary>

Suppose $f:X\to\mathbb{F}$ is linear and continuous at $x_0 \in X$. Let $y_0 \in X$ and define $z = y - y_0 + x_0$. Then

$$
  \lim_{y\to y_0} \lVert z - x_0 \rVert = \lVert y - y_0 \rVert = 0 \implies z \xrightarrow{y\to y_0} x_0 
$$

Thus,

$$
  f(y) - f(y_0) = f(y - y_0) = f(z - x_0) = f(z) - f(x_0) \xrightarrow{y\to y_0} 0
$$

showing that $f$ is continuous at $y_0$. Since $y_0$ was arbitrary, $f$ is continuous on $X$.
</details>
</MathBox>

<MathBox title='Boundedness of continuous quadratic functionals' boxType='proposition' tag='proposition-11'>
If a functional $f:X\to\mathbb{F}$ is quadratic and continuous, there exists $M < \infty$ such that $|f(x)| < M$ for every $x\in B(0,1) \subset X$.

<details>
<summary>Proof</summary>

Since $f$ is continuous, the pre-image $f^{-1}[B(0,1)]$ is open. Thus, there is $\epsilon > 0$ such that $|f(x)| < 1$ for every $x \in B(0,\epsilon)\subset X$. Set $M = \epsilon^{-2}$, then for $x = 0$ we have $|f(x)| = 0 < M$. For $x\in B(0,1) \setminus\Set{0}$, let $y = \frac{\epsilon}{\lVert x \rVert}x$. Then $\lVert y \rVert = \epsilon$, giving

$$
  |f(x)| = \frac{\lVert x \rVert^2}{\epsilon^2} |f(y)| < \frac{\lVert x \rVert^2}{\epsilon^2} = M
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $f:X\to\mathbb{F}$ be a quadratic functional and $K:X^2 \to\mathbb{F}$ be a bilinear functional with $f(x) = K(x,x)$
1. $\delta f(x)h = K(x,h) +  K(h,x)$ for every $x\in X$
2. If $K$ is continuous, then $f$ is Fréchet differentiable

<details>
<summary>Proof</summary>

**(1):** Evaluating the Gâteaux derivative of $f$ at $x$ using $f(x) = K(x,x)$ gives

$$
\begin{align*}
  \delta f(x) h =& \lim_{\tau\to 0} \frac{f(x + \tau h) - f(x)}{\tau} \\
  =& \lim_{\tau\to 0} \frac{K(x + \tau h, x + \tau h) - K(x,x)}{\tau} \\
  =& \lim_{\tau\to 0} \frac{\tau K(x,h) + \tau K(h,x) + \tau^2 K(h, h)}{\tau} \\
  =& \lim_{\tau\to 0} K(x,h) + K(h, x) + \tau K(h, h) \\
  =& K(x, h) + K(h, x)
\end{align*}
$$

**(2):** Since $\delta f(x) h = K(x, h) + K(h, x)$, then $\delta f(x)$ is clearly linear. If $K$ is continuous, then $\delta f(x)$ is continuous for every $x$. By Proposition $\ref{proposition-11}$

$$
\begin{align*}
  & \frac{f(x + h) - f(x) - \delta f(x)h}{\lVert h \rVert} \\
  &= \frac{K(x + h, x + h) - K(x,x) - (K(x, h) + K(h, x))}{\lVert h \rVert} \\
  &= \frac{K(h, h)}{\lVert h \rVert} \\
  &= \lVert h \rVert K\left(\frac{h}{\lVert h \rVert}, \frac{h}{\lVert h \rVert} \right) \\
  &= \lVert h \rVert f\left(\frac{h}{\lVert h \rVert}\right) \\
  &< \lVert h \rVert M \xrightarrow{h\to 0} 0
\end{align*}
$$

Hence $f'(x) = \delta f(x)$.
</details>
</MathBox>

## Differentiable functionals

<MathBox title='Fréchet differentiable functional' boxType='definition'>
Let $X$ be a normed space. A functional $J:X\to\mathbb{F}$ is Fréchet differentiable at $x\in X$ if there is a continuous linear functional $J'(x): X\to\mathbb{F}$ such that

$$
  \lim_{h\to 0} \frac{J(x + h) - J(x) - J'(x)h}{\lVert h \rVert_X}
$$

The functional $J'(x)$ is the Fréchet derivative of $J$ at $x$. 
</MathBox>

<MathBox title='Gâteaux differentiable functional' boxType='definition'>
Let $X$ be a normed vector space. A functional $J:X\to\mathbb{F}$ is Gâteaux differentiable at $x\in X$ if there is a functional $\delta J(x): X\to\mathbb{F}$ such that

$$
  \lim_{\tau \to 0} \frac{J(x + \tau h) - J(x)}{\tau} = \left.\frac{\d}{\d\tau} J(x + \alpha h)\right|_{\tau=0} = \delta J(x; h)
$$

The functional $\delta J(x)$ is the Gâteaux derivative of $J$ at $x$. The differential $\delta J(x; h)$ is called the *first variation* of $J$.
</MathBox>

<MathBox title='Differential properties of linear functionals' boxType='proposition'>
A linear functional $f:X\to\mathbb{F}$ satisifies
1. $\delta f(x) = f$ for all $x\in X$
2. $\delta^2 f(x) = 0$ for all $x\in X$
3. If $f$ is continuous, then it is Fréchet differentiable for every $x\in X$

<details>
<summary>Proof</summary>

**(1):** By linearity of $f$ we have for $\tau\in\mathbb{F}$

$$
  \lim_{\tau\to 0} \frac{f(x + \tau h) - f(x)}{\tau} = \lim_{\tau\to 0} \frac{f(x) + \tau f(h) - f(x)}{\tau} = f(h)
$$

**(2):** From **(1)** we have $\delta f (x) = f$ such that

By linearity of $f$ we have for $\tau\in\mathbb{F}$

$$
  \lim_{\tau\to 0} \frac{f(x + \tau h) - f(x) - \tau \delta f(h)}{\tau^2} = \lim_{\tau\to 0} \frac{f(x) + \tau f(h) - f(x) - \tau f(h)}{\tau^2} = 0
$$

**(3):** By linearity of $f$ we have

$$
  \frac{f(x + h) - f(x) - f(h)}{\lVert h \rVert} = \frac{f(x) + f(h) - f(x) - f(h)}{\lVert h \rVert} = 0
$$
</details>
</MathBox>

<MathBox title='Differential properties of quadratic functionals' boxType='proposition'>
Suppose that $K:X^2 \to\mathbb{F}$ is bilinear and $f(x) = K(x,x)$ so that $f$ is quadratic.
1. $\delta^2 f(x) = 0$ for every $x\in X$
2. If $f$ is continuous, then it is twice Fréchet differentiable for every $x\in X$

<details>
<summary>Proof</summary>

**(1):** By the bilinearity of $K$

$$
\begin{align*}
  &\lim_{\tau\to 0} \frac{f(x + \tau h) - f(x) - \tau\delta f(x; h)}{\tau^2} \\
  =& \lim_{\tau\to 0} \frac{K(x + \tau h, x + \tau h) - K(x,x) - \tau (K(x, h) + K(x, h))}{\tau^2} \\
  =& \lim_{\tau\to 0} \frac{\tau^2 K(h, h)}{\tau^2} \\
  =& f(h)
\end{align*}
$$

**(2):** Clearly, $\delta^2 f(x)$ is quadratic. If $K$ is continuous, then $\delta^2 f(x)$ is continuous for every $x$. The result follows from

$$
  \frac{f(x + h) - f(x) - \delta f(x)h - \frac{1}{2}\delta^2 f(x)h}{\lVert h \rVert^2} = \frac{K(h,h) - f(h)}{\lVert h \rVert^2} = 0
$$


</details>
</MathBox>

## Definiteness of quadratic functionals

<MathBox title='Definiteness of quadratic functionals' boxType='definition'>
A quadratic functional $J:X\to\mathbb{F}$ is 
- *positive definite*, written $J > 0$, if there is $\epsilon > 0$ such that
$$
  J(x) > \epsilon\lVert x \rVert^2,\; \forall x\neq 0
$$
- *negative definite*, written $J > 0$, if there is $\epsilon > 0$ such that
$$
  J(x) < -\epsilon\lVert x \rVert^2,\; \forall x\neq 0
$$
</MathBox>

<MathBox title='Semi-definiteness of quadratic functionals' boxType='definition'>
A quadratic functional $J:X\to\mathbb{F}$ is 
- *positive semidefinite*, written $J \geq 0$, if $J(x) \geq 0$ for every $x\in X$
- *negative semidefinite*, written $J \leq 0$, if $J(x) \leq 0$ for every $x\in X$
</MathBox>

From the definition, positive (negative) definiteness of a functional implies positive (negative) semidefiniteness. Note that definiteness depends on the choice of norm.

<MathBox title='' boxType='proposition'>
A quadratic functional $J:\R^n \to\R$ by $J(\mathbf{x}) = \mathbf{x}^\top \mathbf{Px}$ is positive (negative) definite if and only if $\mathbf{P}$ is positive (negative) definite.

<details>
<summary>Proof</summary>

For convenience, choose the Euclidean norm $\lVert\mathbf{x}\rVert = \sqrt{\mathbf{x}^\top \mathbf{x}}$. Setting $\mathbf{Q} = \frac{1}{2}(\mathbf{P} + \mathbf{P}^\top)$, we can write $J(\mathbf{x}) = \mathbf{x}^\top \mathbf{Qx}$. Note that $J(\mathbf{x}) > \varepsilon\mathbf{x}^\top\mathbf{x}$ if and only if 

$$
  \mathbf{x}^\top (\mathbf{Q} - \varepsilon\mathbf{I}_n)\mathbf{x} > 0
$$

Hence, $J$ is positive definite if and only if $\mathbf{Q} - \varepsilon \mathbf{I}_n > 0$ for some $\varepsilon > 0$. The eigenvalues of $\mathbf{Q} - \varepsilon\mathbf{I}$ are $\lambda - \varepsilon$, where $\lambda$ ranges of the eigenvalues of $\mathbf{Q}$. By symmetry of $\mathbf{Q}$, it follows that $\mathbf{Q} - \varepsilon \mathbf{I}_n > 0$ if and only if each $\lambda$ satisfies $\lambda > \varepsilon$. Since we are free to choose $\varepsilon$, positive definiteness of $J$ is equivalent to $\lambda > 0$ for every eigenvalue of $\mathbf{Q}$. This implies $\mathbf{Q} > 0$, which is equivalent to $\mathbf{P} > 0$. Negative definiteness is handled analogously.
</details>
</MathBox>

## Extremas

<MathBox title='Critical point' boxType='definition'>
Let $J:X\to\mathbb{F}$ be a functional. Then $x^* \in X$ is a critical point of $J$ if $\delta J(x^*)$ exists and $\delta J(x^*) = 0$ for every $h\in X$, i.e. $\delta J (x^*) = 0$.
</MathBox>

<MathBox title='Local extrema are critical points' boxType='proposition' tag='proposition-5'>
Let $J:X\to\mathbb{F}$ be a functional. If $J$ achieves a local extremum at $x^* \in X$ and $\delta J(x^*)$ exists, then $x^*$ is a critical point. Hence, a necessary condition for an extremum is that the Gâteaux derivative vanishes in every direction.

<details>
<summary>Proof</summary>

Let $h\in J$. If $J$ achieves a local extremum at $x^*$, then $\tau = 0$ is a local extremum of $f(\tau) := J(x^* + \tau h)$ for $\tau\in\mathbb{F}$. Hence

$$
  \delta J(x^*; h) = \left.\frac{\d}{\d\tau} J(x^* + \tau h) \right|_{\tau = 0} = \left.\frac{\d}{\d\tau} f(\tau)\right|_{\tau=0} = 0
$$
</details>
</MathBox>

<MathBox title='Gâteaux conditions for local minima' boxType='proposition' tag='proposition-8'>
Suppose the functional $J:X\to\mathbb{F}$ is twice Gâteaux differentiable at $x\in X$. A necessary condition for $x\in X$ to be a local minimum is that $\delta J (x; h) = 0$ and $\delta^2 F(x; h) \geq 0$. A sufficient condition for a strict local minimum is if in addition $\delta^2 J(x; h) \geq c > 0$ for all unit vectors $h\in\partial B(0, 1)\subseteq X$ and $\delta^2 J$ is continuous at $x$ uniformly with respect to $h\in\partial B(0, 1)$.


<details>
<summary>Proof</summary>

The necessary condition for local extrema was established in Proposition $\ref{proposition-5}$. If $J$ has a local mimimum at $x\in X$, there is $\epsilon > 0$ such that $J(y) \geq J(x)$  for $y \in B(x, \epsilon)$, then

$$
  J(x) \leq J(y + \tau h),\; \tau \in\left(-\frac{\epsilon}{\lVert h \rVert}, \frac{\epsilon}{\lVert h \rVert} \right)
$$

By Proposition $\ref{proposition-5}$ $\delta J(x; h) = 0$ because $J$ has a local extremum at $x$. Since $J$ is twice Gâteaux differentiable at $x$ we have

$$
  0 \leq \frac{J(x - \tau h) - J(x) - \tau\delta J(x; h)}{\tau^2} \xrightarrow{\tau\to 0} \frac{1}{2}\delta^2 J(x; h)
$$

Since $h$ is arbitrary, it follows that $\delta^2 J(x) \geq 0$.

To see the sufficient conditions note that the assumption on $\delta^2 J$ imply that there is $\epsion > 0$ such that $\delta^2 J (y, h) \geq c/2$ for all $y\in B(0,\epsilon)$ and all $h\in\partial B(0,1)$. Equivalently, $\partial^2 J (y, h) \geq\frac{c}{2}|h|^2$ for all $y\in B(0,\epsilon)$ and all $h\in X$. Hence, applying Taylor's theorem to $f(t)$ using $\ddot{f}(t) = \delta^2 J(x + th, h)$ gives

$$
  J(x + h) = f(1) = f(0) + \int_0^1 (1 - s)\ddot{f}(s)\;\d t \geq F(x) + \frac{c}{4}|h|^2
$$

for $h\in B(0,1)$.
</details>
</MathBox>

<MathBox title='Fréchet conditions for local exrema' boxType='proposition'>
Suppose the functional $J:X\to\mathbb{F}$ has a critical point $x\in X$ and a second Fréchet derivative $J''(x)$. If $J''(x) > 0$, then $J$ has a strict local minimum at $x$.

<details>
<summary>Proof</summary>

From the definition of positive definiteness, there is $\varepsilon > 0$ such that

$$
  J''(x) h > \varepsilon\lVert h \rVert^2
$$

for every $h\in X$. Then

$$
  \lim_{h\to 0} \frac{J(x + h) - J(x) - \frac{1}{2}J''(x)h}{\lVert h \rVert^2} = 0 
$$

so there is $\delta > 0$

$$
  \frac{J(x + h) - J(x) - \frac{1}{2}J''(x)h}{\lVert h \rVert^2} > -\frac{\varepsilon}{2}
$$

for $h\in B(0,\delta)$. Hence

$$
  J(x + h) - J(x) > \frac{1}{2}(J''(x) h - \varepsilon\lVert h \rVert^2) > 0
$$

for $h \in B(0,\delta)$.
</details> 
</MathBox>

<MathBox title='Sufficient condition for twice continuously differentiable functionals' boxType='corollary'>
Suppose $J\in C^2 (U, \R)$ is twice continuously differentiable on a normed subspace $U\subseteq X$. A sufficient condition for $x \in U$ to be a strict local minimum is $J'(x) = 0$ and $\d^2 J(x)h^2 \geq c|h|^2$ for all $h\in X$.

<details>
<summary>Proof</summary>

Note that since

$$
  |\delta^2 J(x; h) - \delta^2 J(y; h)| \leq\lVert \d^2 J(x) - \d^2 J(y) \rVert\cdot|h|^2
$$

continuity requirement from Proposition $\ref{proposition-8}$ is satisfied.
</details>
</MathBox>

<MathBox title='Existence of global minima' boxType='proposition'>
Suppose $C \subseteq X$ is a convex subspace and $J:C\to\mathbb{F}$ is a convex functional. Then every local minimum is a global minimum. Moreover, if $J$ is strictly convex, then the minimum is unique.

<details>
<summary>Proof</summary>

Suppose $x$ is a local minimum and $J(y) < J(x)$. Then $J(\lambda y + (1 - \lambda) x) \leq\lambda J(y) + (1 - \lambda)J(x) < J(x)$ for $\lambda\in (0,1)$ contradicts the fact that $x$ is a local minimum. If $x, y$ are two global minima, then $J(\lambda y + (1 - \lambda)x) < J(y) = J(x)$ yielding a contradiction unless $x = y$. 
</details>
</MathBox>

<MathBox title='Condition for global minima' boxType='proposition'>
uppose $C \subseteq X$ is a convex subspace and $J:C\to\mathbb{F}$ is a convex functional. If the Gâteaux derivative exists at an interior point $x\in C$ and satisfies $\delta J(x;h) = 0$ for all $h\in X$, then $x$ is a global minimum.

<details>
<summary>Proof</summary>

By assumption $f(t) := J(x + th)$ is a convex function defined on an interval containing $0$ with $f'(0) = 0$. If $y$ is another point we can choose $h = y - x$, such that $J(y) = f(1) \geq f(0) = J(x)$.
</details>
</MathBox>

<MathBox title='Convex functionals have positive second Gâteaux derivative' boxType='proposition'>
uppose $C \subseteq X$ is a convex subspace and $J:C\to\mathbb{F}$ is twice Gâteaux differentible on $C$. Then $J$ is convex if and only if $\delta^2 J(x; h)\geq 0$ for all $x\in C$ and $h\in X$. Moreover, $J$ is strictly convex if and only if $\delta^2 F(x; h) > 0$ for all $x\in C$ and $h \in X\setminus\Set{0}$.

<details>
<summary>Proof</summary>

Define $f(t) := J(x + th)$ with $f'(t) = \delta J(x + th; h)$ and $f''(t) = \delta^2 J(x + th; h)$. Moreover, note that $f$ is (strictly) convex for all $x\in C$ and $u\in X\setminus\Set{0}$ if and only if $J$ is (strictly) convex. If $J$ is (strictly) convex, so is $f$. To see the converse note that

$$
\begin{align*}
  J(\lambda y + (1-\lambda)x) =& f(\lambda) \\
  \leq& \lambda f(1) - (1 - \lambda)f(0) \\
  =& \lambda J(y) - (1 - \lambda) J(x)
\end{align*}
$$

with strict inequality if $f$ is strictly convex.
</details>
</MathBox>

<MathBox title='Convex functionals have monotone Gâteaux derivative' boxType='proposition'>
Suppose $C\subseteq X$ is open and convex and $J:C\to\R$ has Gâteaux derivatives $\delta J(x)\in X^*$ for every $x\in C$. Then $J$ is (strictly) convex if and only if $\delta J$ is (strictly) monotone.

<details>
<summary>Proof</summary>

Define $f(t) := J(x + th)$. Note that by assumption $\delta J: C\to X^*$ and the claim follows since $f'(t) = \delta J(x + th; h)$, which shows that $\delta J$ is (strictly) monotone if and only if $f'$ is (strictly) increasing.
</details>
</MathBox>

<MathBox title='Fundamental lemma of variational calculus' boxType='lemma'>
Let $f:[a,b]\to\R$ be a continuous function. If

$$
  \int_a^b f(x)g(x)\;\d x = 0
$$

for all twice differentiable functions $g:[a,b]\to\R$ with $g(a) = g(b) = 0$ and compact support in $(a,b)$, then $f$ is identically zero.

<details>
<summary>Proof</summary>

Suppose by contradiction that $f$ is nonzero in some subinterval $(c,d) \subseteq (a, b)$. Without loss of generality, assume $f:(c,d) > 0$. Since $g$ is arbitrary, we are free to set it at our choice, say

$$
  g(x) = \begin{cases} (x - c)(d - x),\quad x\in [c,d] \\ 0,\quad x < c \lor x > d \end{cases}
$$

Noting that $(x - c) > 0$ and $(d - x) > 0$ for $x\in [c,d]$, consider the integral

$$
  \int_a^b f(x)g(x)\;\d x = \int_c^d f(x) (x - c)(d - x)\;\d x > 0
$$

which is positive because the integrand is positive in $(c,d)$. This gives a contradiction, proving that $f$ must be identically zero in $[a,b]$.
</details>
</MathBox>

# Lagrange problem

Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and evolution function $L\in C^2 (\R\times TX, \R)$ called the *Lagrangian*, where $TX$ is the tangent bundle on $X$. A Lagrange problems seek to find the path $\mathbf{q} \in C^2 ([t_0, t_1]\subseteq\R, X)$ with fixed endpoints that minimizes the integral functional 

$$
  S(\mathbf{q}) := \int_{t_0}^{t_1} L(t, \mathbf{q}(t), \dot{\mathbf{q}(t)})\;\d t
$$

on $D = \Set{\mathbf{q} \in C^2 ([t_0, t_1], X) | \mathbf{q}(t_0) = \mathbf{x}_0, \mathbf{q}(t_1) = \mathbf{x}_1}$.

<MathBox title='Euler-Lagrange equations' boxType='theorem' tag='theorem-1'>
Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and *Lagrangian* $L\in C^2 (\R\times TX, \R)$, where $TX$ is the tangent bundle of $X$. Let 

$$
  D = \Set{\mathbf{q} \in C^2 ([t_0, t_1]\subseteq\R, X) | \mathbf{q}(t_0) = \mathbf{x}_0, \mathbf{q}(t_1) = \mathbf{x}_1}
$$

be the set of twice continuously differentiable paths in $X$ with fixed endpoints. The action functional $S:D\to\R$ given by

$$
  S(\mathbf{q}) := \int_{t_0}^{t_1} L(t, \mathbf{q}(t), \dot{\mathbf{q}(t)})\;\d t
$$

is stationary on a path $\mathbf{q} \in X$ if and only if $L$ satisfies the Euler-Lagrange equations

$$
\begin{align*}
  \nabla_{\mathbf{q}} L(t,\mathbf{q}(t),\dot{\mathbf{q}}(t)) =& \frac{\d}{\d t} \nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q}(t),\dot{\mathbf{q}}(t)) \\
  \frac{\partial L}{\partial q_i}(t,\mathbf{q}(t),\dot{\mathbf{q}}(t)) =& \frac{\d}{\d t} \frac{\partial L}{\partial \dot{q}_i}(t,\mathbf{q}(t),\dot{\mathbf{q}}(t)),\; i=1,\dots,n
\end{align*}
$$

<details>
<summary>Proof</summary>

The first Gâteaux variation of $S$ at $\mathbf{q}\in D$ in the direction $\mathbf{h} \in C^2 ([t_0, t_1], X)$ for $s\in\R$ is given by

$$
\begin{align*}
  \delta S(\mathbf{q}(t); \mathbf{h}(t)) =& \left.\frac{\d}{\d s} S(\mathbf{q}(t) + t\mathbf{h}(t))\right|_{s=0} \\
  =& \left.\frac{\d}{\d s} \right|_{s=0} \int_{t_0}^{t_1} L\left(t, \mathbf{q}(t) + s\mathbf{h}(t), \dot{\mathbf{q}}(t) + s\dot{\mathbf{h}}(t)\right)\;\d t \\
  =& \int_{t_0}^{t_1} \left.\frac{\d}{\d s} L[\mathbf{q} + s\mathbf{h}] \right|_{s=0} \;\d t
\end{align*}
$$

where we use the compact notation

$$
  L[\mathbf{q} + s\mathbf{h}] = L\left(t, \mathbf{q}(t) + s\mathbf{h}(t), \dot{\mathbf{q}}(t) + s\dot{\mathbf{h}}(t)\right)
$$

Applying the chain rule gives

$$
\begin{align*}
  \delta S(\mathbf{q}; \mathbf{h}) =& \int_{t_0}^{t_1} \left.\frac{\d}{\d s} L[\mathbf{q} + s\mathbf{h}]\right|_{s=0} \;\d t \\
  =& \int_{t_0}^{t_1} \left.\mathbf{h}\cdot\nabla_{\mathbf{q} + s\mathbf{h}} L[\mathbf{q} + s\mathbf{h}]\right|_{s=0}\;\d t \\
  &+ \int_{t_0}^{t_1} \left.\dot{\mathbf{h}}\cdot\nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}} L[\mathbf{q} + s\mathbf{h}]\right|_{s=0} \;\d t \\
  =& \int_{t_0}^{t_1} \left(\mathbf{h}\cdot\nabla_\mathbf{q} L(t,\mathbf{q},\dot{\mathbf{q}}) + \dot{\mathbf{h}}\cdot\nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q},\dot{\mathbf{q}})\right)\;\d t
\end{align*}
$$

Integrating the second term by parts we get

$$
\begin{align*}
  \int_{t_0}^{t_1}& \dot{\mathbf{q}}\cdot\nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q},\dot{\mathbf{q}})\;\d t \\
  =& \underbrace{\left.\mathbf{h} L(t,\mathbf{q},\dot{\mathbf{q}})\right|_{t_0}^{t_1}}_{=0} - \int_{t_0}^{t_1} \mathbf{h} \frac{\d}{\d t}\nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q},\dot{\mathbf{q}})\;\d t
\end{align*}
$$

Since $\mathbf{q} + s\mathbf{h}$ and $\mathbf{q}$ satisfy the same boundary conditions, we must have $\mathbf{h}(t_0) = \mathbf{h}(t_1) = 0$. Substituting back gives

$$
  \delta S(\mathbf{q}; \mathbf{h}) = \int_{t_0}^{t_1} \mathbf{h}\cdot\left(\nabla_\mathbf{q} L(t,\mathbf{q},\dot{\mathbf{q}}) - \frac{\d}{\d t} \nabla_{\dot{\mathbf{q}}} L(t, \mathbf{q}, \dot{\mathbf{q}}) \right)\;\d t
$$

In order the be a critical point, a path $\mathbf{q}$ must satisfy $\delta J(\mathbf{q}; \mathbf{h}) = 0$ for all $\mathbf{h}$. By the fundamental lemma of variational calculus, we must have

$$
  \nabla_{\mathbf{q}} L(t,\mathbf{q}(t),\dot{\mathbf{q}}(t)) = \frac{\d}{\d t} \nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q}(t),\dot{\mathbf{q}}(t))
$$
</details>
</MathBox>

## Legendre condition

<MathBox title='Condition for local minima in Lagrange problems' boxType='proposition'>
Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and *Lagrangian* $L\in C^2 (\R\times TX, \R)$, where $TX$ is the tangent bundle of $X$. Let 

$$
  D = \Set{\mathbf{q} \in C^2 ([t_0, t_1]\subseteq\R, X) | \mathbf{q}(t_0) = \mathbf{x}_0, \mathbf{q}(t_1) = \mathbf{x}_1}
$$

be the set of twice continuously differentiable paths in $X$ with fixed endpoints. The action functional $S:D\to\R$ given by

$$
  S(\mathbf{q}) := \int_{t_0}^{t_1} L(t, \mathbf{q}(t), \dot{\mathbf{q}(t)})\;\d t
$$

has a local minimum at $\mathbf{q}$ if for any $\mathbf{h}\in X$

$$
  \mathbf{h}^2 \nabla_{\mathbf{q}}^2 L(t,\mathbf{q},\dot{\mathbf{q}}) + 2\mathbf{h}\cdot\dot{\mathbf{h}} \nabla_{\mathbf{q}}\nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q},\dot{\mathbf{q}}) + \dot{\mathbf{q}}^2 \nabla_{\dot{\mathbf{q}}}^2 L(t,\mathbf{q},\dot{\mathbf{q}}) > 0
$$

<details>
<summary>Proof</summary>

The second Gâteaux variation of $S$ at $\mathbf{q}(t) \in $ in the dircetion $\mathbf{h}(t)\in X$ is given by

$$
  \delta^2 S(\mathbf{q};\mathbf{h}) = \left.\frac{\d^2}{\d s^2} S(\mathbf{q}; \mathbf{h})\right|_{s=0} = \left.\frac{\d}{\d s} \delta S(\mathbf{q};\mathbf{h}) \right|_{s=0}
$$

From the proof of Theorem $\ref{theorem-1}$, we found that

$$
\begin{align*}
  \delta S(\mathbf{q};\mathbf{h}) =& \int_{t_0}^{t_1} \left.\mathbf{h}\cdot\nabla_{\mathbf{q} + s\mathbf{h}} L[\mathbf{q} + s\mathbf{h}]\right|_{s=0}\;\d t \\
  &+ \int_{t_0}^{t_1} \left.\dot{\mathbf{h}}\cdot\nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}} L[\mathbf{q} + s\mathbf{h}]\right|_{s=0} \;\d t
\end{align*}
$$

where we use the compact notation

$$
  L[\mathbf{q} + s\mathbf{h}] = L\left(t, \mathbf{q}(t) + s\mathbf{h}(t), \dot{\mathbf{q}}(t) + s\dot{\mathbf{h}}(t)\right)
$$

such that

$$
\begin{align*}
  \delta^2 S(\mathbf{q};\mathbf{h}) =& \int_{t_0}^{t_1} \left.\frac{\d}{\d s}\Big(\mathbf{h}\cdot\nabla_{\mathbf{q} + s\mathbf{h}} L[\mathbf{q} + s\mathbf{h}]\Big)\right|_{s=0}\;\d t \\
  &+ \int_{t_0}^{t_1} \left.\frac{\d}{\d s} \left(\dot{\mathbf{h}}\cdot\nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}} L[\mathbf{q} + s\mathbf{h}]\right)\right|_{s=0} \;\d t
\end{align*}
$$

Applying the chain rule to each terms gives

$$
\begin{align*}
  \frac{\d}{\d s}& \left(\mathbf{h}\cdot\nabla_{\mathbf{q} + s\mathbf{h}} L[\mathbf{q} + s\mathbf{h}] \right) \\
  =& \mathbf{h}^2 \nabla_{\mathbf{q} + s\mathbf{h}}^2 L[\mathbf{q} + s\mathbf{h}] + \mathbf{h}\cdot\dot{\mathbf{h}} \nabla_{\mathbf{q} + s\mathbf{h}}\nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}} L[\mathbf{q} + s\mathbf{h}]
\end{align*}
$$

and

$$
\begin{align*}
  \frac{\d}{\d s}& \left(\dot{\mathbf{h}}\cdot\nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}} L[\mathbf{q} + s\mathbf{h}] \right) \\
  =& \mathbf{h}\cdot\dot{\mathbf{h}} \nabla_{\mathbf{q} + s\mathbf{h}} \nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}} L[\mathbf{q} + s\mathbf{h}] + \dot{\mathbf{h}}^2 \nabla_{\dot{\mathbf{q}} + s\dot{\mathbf{h}}}^2 L[\mathbf{q} + s\mathbf{h}]
\end{align*}
$$

Substituting back and evaluating at $s = 0$ yields

$$
\begin{equation}
\begin{split}
  \delta^2 S(\mathbf{q};\mathbf{h}) = \int_{t_0}^{t_1}& \Big[\mathbf{h}^2 \nabla_{\mathbf{q}}^2 L(t,\mathbf{q},\dot{\mathbf{q}}) \\
  &+ 2\mathbf{h}\cdot\dot{\mathbf{h}} \nabla_{\mathbf{q}}\nabla_{\dot{\mathbf{q}}} L(t,\mathbf{q},\dot{\mathbf{q}}) \\
  &+ \dot{\mathbf{q}}^2 \nabla_{\dot{\mathbf{q}}}^2 L(t,\mathbf{q},\dot{\mathbf{q}})\Big]\;\d t
\end{split}
\tag{\label{equation-1}}
\end{equation}
$$

In order to be a local minimum, $\mathbf{q}$ must satisfy $\delta^2 S(\mathbf{q};\mathbf{h}) > 0$ for any nonzero $\mathbf{h}\in X$. Clearly, $\delta^2 S(\mathbf{q};\mathbf{h}) > 0$ if and only if the integrand is positive definite, which gives the desired inequality.
</details>
</MathBox>

ntegrating the mixed gradient term in $\eqref{equation-1}$ by parts, we obtain an alternative form of the second variation for the action functional.

$$
\begin{align*}
  \delta^2 S(\mathbf{q};\mathbf{h}) =& \int_{t_0}^{t_1} \left(\mathbf{h}^2 \nabla_\mathbf{q}^2 L + 2\mathbf{h}\cdot\dot{\mathbf{h}} \nabla_{\mathbf{q}}\nabla_{\dot{\mathbf{q}}} L + \dot{\mathbf{h}}^2 \nabla_{\dot{\mathbf{q}}}^2 L \right)\;\d t \\
  =& \int_{t_0}^{t_1} \left(\mathbf{h}^2 \nabla_\mathbf{q}^2 L + \dot{\mathbf{h}}^2 \nabla_{\dot{\mathbf{q}}}^2 L \right)\d t \\
  &+ \left(\mathbf{h}^2 \nabla_{\mathbf{q}} \nabla_{\dot{\mathbf{q}}} L \right)|_{t_0}^{t_1} - \int_{t_0}^{t_1} \mathbf{h}^2 \frac{\d}{\d t}\left(\nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}} L \right)\;\d t \\
  =& \int_{t_0}^{t_1} \left(\dot{\mathbf{h}}^2 \nabla_{\dot{\mathbf{q}}}^2 L + \mathbf{h}^2 \left(\nabla_\mathbf{q}^2 L - \frac{\d}{\d t} \nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}} L \right) \right)\;\d t
\end{align*}
$$

If we fix the function $\mathbf{u}$ and define

$$
\begin{align*}
  R :=& \nabla_{\dot{\mathbf{q}}}^2 L \\
  T :=& \nabla_\mathbf{q}^2 - \frac{\d}{\d t} \nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}} L
\end{align*}
$$

the second variation becomes a function over the domain of admissible variations

$$
  J(\mathbf{h}(t)) = \int_{t_0}^{t_1} \left(R\dot{\mathbf{h}}(t)^2 + S\mathbf{h}(t)^2 \right)\;\d t
$$

with Lagrangian $L(t, \mathbf{h},\dot{\mathbf{h}}) = R\dot{\mathbf{h}}^2 + S\dot{\mathbf{h}}^2$, which is the standard quadratic functional.

<MathBox title='' boxType='proposition' tag='proposition-15'>
Let $\mathbf{h} \in C^1 ([t_0,t_1],\R^n)$ be continuously differentiable functions with boundary values $\mathbf{h}(t_0) = \mathbf{h}(t_1) = 0$ and support on $[t_0, t_1]$. Suppose $R, T: [t_0, t_1]\to\R$ are continuous function of $t$. If the functional

$$
  J(\mathbf{h}) = \int_{t_0}^{t_1} (R\dot{\mathbf{h}}^2 + S\mathbf{h}^2)\;\d t
$$

is positive definite, then $R\geq 0$ for all $t\in[t_0, t_1]$.

<details>
<summary>Proof</summary>

It suffices to show that if $R < 0$ for some $t\in[t_0, t_1]$, then $J(\mathbf{h})\leq 0$. Without loss of generality, let $\tau \in [t_1, t_2$ such that $R(\tau) = -2\delta$ and $\delta > 0$. Since $R$ is continuous on the interval, there is $\varepsilon > 0$ such that $t_0 \leq \tau - \epsilon < \tau + \epsilon \leq t_1$ and $R < -\delta$ for all $t\in[\tau - \epsilon, \tau + \epsilon]$.

Suppose we define $\mathbf{h}$ by

$$
  h_i = \begin{cases}
    \sin^2 (\frac{\pi}{\epsilon}(t - \tau))\quad & t\in[\tau - \epsilon, \tau + \epsilon] \\
    0 \quad &\text{otherwise}
  \end{cases}
$$

for each $i=1,\dots,n$. Then

$$
\begin{align*}
  \int_{t_0}^{t_1} (R_i \dot{h}_i^2 + T_i h_i^2)\;\d t =& \int_{\tau-\epsilon}^{\tau+\epsilon} R_i \left[\frac{\pi}{\epsilon}\sin\left(\frac{2\pi}{\epsilon}(t - \tau) \right)\right]^2\;\d t \\
  &+ \int_{\tau-\epsilon}^{\tau+\epsilon} T_i \sin^4 \left(\frac{\pi}{\epsilon}(t - \tau)\right)\;\d t \\
  <& \int_{\tau-\epsilon}^{\tau+\epsilon} \left(-\frac{\pi^2}{\epsilon^2}\delta \right)\;\d t + \int_{\tau-\epsilon}^{\tau+\epsilon} M_i \;\d t \\
  =& -\frac{2\pi^2}{\epsilon}\delta + 2M_i \epsilon
\end{align*}
$$

where $M_i = \max_{t\in[t_0,t_1]} |T_i|$. Since $-\frac{2\pi^2}{\epsilon}\delta + 2M_i \epsilon < 0$ for sufficiently small $\epsilon$, we have that

$$
\begin{align*}
  J(\mathbf{h}) =& \int_{t_0}^{t_1} \left(\sum_{i=1}^n R_i \dot{h}_i^2 + T_i h_i^2 \right)\;\d t \\
  \leq& \sum_{i=1}^n \left(-\frac{2\pi^2}{\epsilon}\delta + 2M_i \epsilon \right) < 0
\end{align*}
$$

Thus, $J(\mathbf{h})\leq 0$ when $R < 0$ for some $t\in[t_0, t_1]$, implying that $R\geq 0$ for all $t\in[t_0,t_1]$ whenever $J(\mathbf{h}) > 0$.
</details>
</MathBox>

<MathBox title='Legendre condition' boxType='theorem'>
Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and *Lagrangian* $L\in C^2 (\R\times TX, \R)$, where $TX$ is the tangent bundle of $X$. Let 

$$
  D = \Set{\mathbf{q} \in C^2 ([t_0, t_1]\subseteq\R, X) | \mathbf{q}(t_0) = \mathbf{x}_0, \mathbf{q}(t_1) = \mathbf{x}_1}
$$

be the set of twice continuously differentiable paths in $X$ with fixed endpoints. The action functional $S:D\to\R$ given by

$$
  S(\mathbf{q}) := \int_{t_0}^{t_1} L(t, \mathbf{q}(t), \dot{\mathbf{q}(t)})\;\d t
$$

has a local minimum at $\mathbf{q}$ if

$$
  \nabla_{\dot{\mathbf{q}}}^2 L \geq 0
$$

<details>
<summary>Proof</summary>

In order to be a local minimun, $\mathbf{q}$ must satisfy $\delta^2 S(\mathbf{q};\mathbf{h}) > 0$ for any nonzero variation $\mathbf{h}\in X$. In this case $\mathbf{q}$ is a fixed critical function of $\delta S(\mathbf{q};\mathbf{h})$ so that we can write the second variation $\delta^2 S(\mathbf{q};\mathbf{h})$ as a quadratic functional

$$
\begin{align*}
  J(\mathbf{h}) =& \int_{t_0}^{t_1} \left[\dot{\mathbf{h}}^2 \nabla_{\dot{\mathbf{q}}}^2 L + \mathbf{h}^2 \left(\nabla_\mathbf{q}^2 L - \frac{\d}{\d t} \nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}} L \right) \right]\;\d t \\
  =& \int_{t_0}^{t_1} \left(R\dot{\mathbf{h}}^2 + T\mathbf{h}^2 \right)\;\d t
\end{align*}
$$

where

$$
\begin{align*}
  R :=& \nabla_{\dot{\mathbf{q}}}^2 L \\
  T :=& \nabla_\mathbf{q}^2 - \frac{\d}{\d t} \nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}} L
\end{align*}
$$

It follows from Proposition $\ref{proposition-15}$ that if $\delta^2 S(\mathbf{q}; \mathbf{h}) > 0$, then

$$
  R = \nabla_{\dot{\mathbf{q}}}^2 L \geq 0
$$
</details>
</MathBox>

<MathBox title='Jacobi equations' boxType='proposition'>
Let $\mathbf{h} \in C^1 ([t_0,t_1],\R^n)$ be continuously differentiable functions with boundary values $\mathbf{h}(t_0) = \mathbf{h}(t_1) = 0$ and support on $[t_0, t_1]$. Suppose $R, T: [t_0, t_1]\to\R$ are continuous function of $t$. Consider the quadratic functional


$$
  J(\mathbf{h}) = \int_{t_0}^{t_1} \left(R\dot{\mathbf{h}}^2 + T\mathbf{h}^2 \right)\;\d t
$$

with Lagrangian $L(\mathbf{h},\dot{\mathbf{h}}) = R\dot{\mathbf{h}}^2 + T\mathbf{h}^2$. If $\mathbf{h}$ satisfies the Euler-Lagrange equations, then it also satisfies the *Jacobi equations*

$$
  T\mathbf{h} = \frac{\d}{\d t} (R\dot{\mathbf{h}})
$$

A point $\tau \neq t_1$ is *conjugate* to $t_1$ if there is a nontrivial solution $\bar{\mathbf{h}}$ to the Jacobi equations such that $\bar{\mathbf{v}}(\tau) = \bar{\mathbf{v}}(t_1)$.

<details>
<summary>Proof</summary>

If $\mathbf{h}$ satisfies the Euler-Lagrange equations for $L(\mathbf{h},\dot{\mathbf{h}}) = R\dot{\mathbf{h}}^2 + T\mathbf{h}^2$, then

$$
\begin{align*}
  \nabla_\mathbf{h} \left(R\dot{\mathbf{h}}^2 + T\mathbf{h}^2 \right) =& \frac{\d}{\d t} \nabla_{\dot{\mathbf{h}}} //
  2 T\mathbf{h} =& \frac{\d}{\d t} 2(R\dot{\mathbf{h}}) \\
  T\mathbf{h} =& \frac{\d}{\d t} (R\dot{\mathbf{h}})
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-17'>
Let $\mathbf{h} \in C^1 ([t_0,t_1],\R^n)$ be continuously differentiable functions with boundary values $\mathbf{h}(t_0) = \mathbf{h}(t_1) = 0$ and support on $[t_0, t_1]$. Suppose $R, T: [t_0, t_1]\to\R$ are continuous function of $t$. The functional

$$
  J(\mathbf{h}) = \int_{t_0}^{t_1} (R\dot{\mathbf{h}}^2 + S\mathbf{h}^2)\;\d t
$$

is positive definite whenever $R > 0$ for all $t\in[t_0,t_1]$ and there is no point $\tau \in (t_0,t_1)$ conjugate to $t_0$.

<details>
<summary>Proof</summary>

Suppose there exists a function $\mathbf{v}\in C^1 ([t_0,t_1],\R^n)$ such that $\mathbf{v}^2 = R(S + \dot{\mathbf{v}})$ for all $t\in[t_0,t_1]$. Consider the derivative $\frac{\d}{\d t}(\mathbf{vh}^2)$ of this function. Since $\mathbf{h}$ satisfies the boundary conditions $\mathbf{v}(t_0) = \mathbf{v}(t_1) = 0$, it is clear that

$$
  \int_{t_0}^{t_1} \frac{\d}{\d t}(\mathbf{vh}^2) = 0
$$

It follows that

$$
  \int_{t_0}^{t_1} \left(R\dot{\mathbf{h}}^2 + T\mathbf{h}^2 \right)\;\d t = \int_{t_0}^{t_1} \left(R\dot{\mathbf{h}}^2 + T\mathbf{h}^2 + \frac{\d}{\d t} (\mathbf{v}\mathbf{h}^2) \right)\;\d t
$$

Evaluating the integrand gives

$$
\begin{align*}
  R\dot{\mathbf{h}}^2 + T\mathbf{h}^2 + \frac{\d}{\d t} (\mathbf{v}\mathbf{h}^2) =& R\dot{\mathbf{h}}^2 + 2\mathbf{vh}\dot{\mathbf{h}} + (T + \dot{\mathbf{v}})\dot{\mathbf{v}}^2 \\
  =& R\dot{\mathbf{v}}^2 + 2\mathbf{vh}\dot{\mathbf{h}} + \frac{\mathbf{v}^2 \mathbf{h}^2}{R} \\
  =& R\left(\dot{\mathbf{h}}^2 + \frac{2\mathbf{vh}\dot{\mathbf{h}}}{R} + \frac{\mathbf{v}^2 \mathbf{h}^}{R^2} \right) \\
  =& R\left(\dot{\mathbf{h}} + \frac{\mathbf{vh}}{R} \right)^2
\end{align*}
$$

which yields

$$
\begin{align*}
  J(\mathbf{h}) =& \int_{t_0}^{t_1} (R\dot{\mathbf{h}}^2 + T\mathbf{h}^2)\;\d t \\
  =& \int_{t_0}^{t_1} R\left(\dot{\mathbf{h}} + \frac{\mathbf{vh}}{R}\right)^2 \;\d t
\end{align*}
$$

Thus, $J(\mathbf{h})$ is positive definite whenever $R > 0$, provided that $\mathbf{v}$ exists. Using the substitution $\mathbf{v} = - R(\dot{\mathbf{u}}/\mathbf{u})$ for some function $\mathbf{u}\in C^1 ([t_0,t_1], \R^n)$, we obtain

$$
\begin{align*}
  &\mathbf{v}^2 = R(T + \dot{\mathbf{v}}) \\
  \implies& $\frac{R^2 \dot{\mathbf{u}}^2}{\mathbf{u}^2} = R\left(T - \frac{\left(R\ddot{\mathbf{u}} + \dot{\mathbf{u}}\frac{\d}{\d t}R \right)\mathbf{u} - R\dot{\mathbf{u}}^2}{\mathbf{u}^2} \right) \\
  \implies& S\mathbf{u} - \left(R\ddot{\mathbf{u}} + \dot{\mathbf{u}}\frac{\d}{\d t} R \right) = 0 \\
  \implies& S\mathbf{u} - \frac{\d}{\d t} (R\dot{\mathbf{u}}) = 0
\end{align*}
$$

which are just the Jacobi equations for $J(\mathbf{h})$. Since $\mathbf{v}$ only exists for all $t\in[t_0,t_1]$ if a nonzero $\mathbf{u}$ exists, we want $\mathbf{u}$ to be a nontrivial solution to the Jacobi equations which has no conjugate points to $t_0$ on the interval $(t_0, t_1)$. Thus, $J(\mathbf{h}) > 0$ whenever $R > 0$ and there is no point $\tau\in(t_0,t_1)$ conjugate to $t_0$.
</details>
</MathBox>

<MathBox title='Sufficient condition for local minima in Lagrange problems' boxType='proposition'>
Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and *Lagrangian* $L\in C^2 (\R\times TX, \R)$, where $TX$ is the tangent bundle of $X$. Let 

$$
  D = \Set{\mathbf{q} \in C^2 ([t_0, t_1]\subseteq\R, X) | \mathbf{q}(t_0) = \mathbf{x}_0, \mathbf{q}(t_1) = \mathbf{x}_1}
$$

be the set of twice continuously differentiable paths in $X$ with fixed endpoints. The action functional $S:D\to\R$ given by

$$
  S(\mathbf{q}) := \int_{t_0}^{t_1} L(t, \mathbf{q}(t), \dot{\mathbf{q}(t)})\;\d t
$$

has a local minimum at $\mathbf{q}$ if

$$
  \nabla_{\dot{\mathbf{q}}}^2 L > 0,\; \forall t\in[t_0,t_1]
$$

and the Jacobi equations

$$
  \left(\nabla_\mathbf{\dot{\mathbf{q}}}^2 L - \frac{\d}{\d t} \nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}}\right) \mathbf{h} - \frac{\d}{\d t} (\dot{\mathbf{h}}\nabla_{\dot{\mathbf{q}}}^2 L) = 0 
$$

have only the trivial solution $\mathbf{h}\equiv 0$, for all $t\in[t_0,t_1]$.

<details>
<summary>Proof</summary>

In order to be a local minimum, $\mathbf{q}$ must satisfy $\delta^2 S(\mathbf{q};\mathbf{h}) > 0$ for any nonzero variation $\mathbf{h}\in X$. Since $\mathbf{q}$ is a fixed critical function of $S(\mathbf{q})$, we can rewrite the second varitation as the quadratic functional

$$
  S(\mathbf{h}) = \int_{t_0}^{t_1} \left[\dot{\mathbf{h}}^2 \nabla_{\dot{\mathbf{q}}}^2 L + \mathbf{h}^2 \left(\nabla_{\mathbf{q}}^2 L - \frac{\d}{\d t}\nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}} L \right) \right]\;\d t
$$

It follows from Proposition $\ref{proposition-17}$ that $\delta^2 S(\mathbf{q};\mathbf{h}) > 0$ if

$$
  \nabla_\mathbf{\dot{\mathbf{q}}}^2 L > 0,\; \forall t\in[t_0,t_1]
$$
and there is no point $\tau\in(t_0,t_1)$ conjugate to $t_0$. Since $\mathbf{h}(t_0) = \mathbf{h}(t_1) = 0$, the latter requirement neccesitates the the Jacobi equations

$$
  \left(\nabla_\mathbf{\dot{\mathbf{q}}}^2 L - \frac{\d}{\d t} \nabla_\mathbf{q} \nabla_{\dot{\mathbf{q}}}\right) \mathbf{h} - \frac{\d}{\d t} (\dot{\mathbf{h}}\nabla_{\dot{\mathbf{q}}}^2 L) = 0 
$$

only have the trivial solution $\mathbf{h}\equiv 0$ for all $t\in[t_0,t_1]$.
</details>
</MathBox>

## Hamiltonian

<MathBox title="Equivalence of Hamilton's equations and the Euler-Lagrange equations" boxType='proposition'>
Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and *Lagrangian* $L\in C^2 (\R\times TX, \R)$, where $TX$ is the tangent bundle of $X$. Define the momenta $\mathbf{p}\in C^2 ([t_0, t_1], TX)$ as the Poisson's variables

$$
  \mathbf{p}(t) = \nabla_{\dot{\mathbf{q}}} L(t, \mathbf{q}(t), \dot{\mathbf{q}}(t))
$$

and the *Hamiltonian*

$$
  H(t, \mathbf{u}(t), \mathbf{p}(t)) = \mathbf{p}(t) \cdot \dot{\mathbf{q}}(t) - L(t, \mathbf{q}(t), \dot{\mathbf{q}}(t))
$$

which is the Legendre transform of the Lagrangian. *Hamilton's equations* are defined as

$$
\begin{align*}
  \dot{\mathbf{q}}(t) =& \nabla_\mathbf{p} H(t,\mathbf{q}(t),\mathbf{p}(t)) \\
  \dot{\mathbf{p}}(t) =& -\nabla_\mathbf{q} H(t,\mathbf{q}(t),\mathbf{p}(t))
\end{align*}
$$

If the Lagrangian satisfies the Euler-Lagrange equations $\nabla_\mathbf{q} L = \frac{\d}{\d t} \nabla_{\dot{\mathbf{q}}} L$, then Hamilton's equations and the Euler-Lagrange equations are equivalent.

<details>
<summary>Proof</summary>

The total derivative of the Hamiltonian is

$$
  \frac{\d}{\d t} H(t,\mathbf{q},\mathbf{p}) = \frac{\partial H}{\partial t}(t,\mathbf{q},\mathbf{q}) + \dot{\mathbf{q}}\cdot\nabla_\mathbf{q} H(t,\mathbf{q},\mathbf{p}) + \dot{\mathbf{p}}\nabla_\mathbf{p} H(t,\mathbf{q},\mathbf{p})
$$

In terms of the Legendre transform $H = \mathbf{p}\cdot\dot{\mathbf{q}} - L$, the total derivative of the Hamiltonian is

$$
\begin{align*}
  \frac{\d}{\d t} H(t,\mathbf{q},\mathbf{p}) =& \frac{\d}{\d t} (\mathbf{p}\cdot\dot{\mathbf{q}} - L(t, \mathbf{q},\dot{\mathbf{q}})) \\
  =& -\dot{\mathbf{q}}\cdot\nabla_\mathbf{q} L(t,\mathbf{q},\dot{\mathbf{q}}) + \dot{\mathbf{p}}\cdot\dot{\mathbf{q}} - \frac{\partial L}{\partial t}(t,\mathbf{q},\dot{\mathbf{q}}) 
\end{align*}
$$

Equating the expressions gives the equations

$$
\begin{align*}
  \frac{\partial H}{\partial t}(t,\mathbf{q},\mathbf{p}) =& -\frac{\partial L}{\partial t}(t,\mathbf{q},\dot{\mathbf{q}}) \\
  \nabla_\mathbf{q} H(t,\mathbf{q},\mathbf{p}) =& -\nabla_{\mathbf{q}} L(t,\mathbf{q},\dot{\mathbf{q}}) \\
  \nabla_\mathbf{p} H(t,\mathbf{q},\mathbf{p}) =& \dot{\mathbf{q}}
\end{align*}
$$

The second equation is recognized as one of Hamilton's equations. It remains to show that $\nabla_\mathbf{q} H =& -\nabla_{\mathbf{q}} L$ if and only if $\mathbf{q}$ satisfies both Hamilton's equation and the Euler-Lagrange equations. First, assume $\mathbf{q}$ sastifies Hamilton's equations. Then, we see by substitution that

$$
  \dot{\mathbf{p}} = \nabla_\mathbf{q} L(t,\mathbf{q},\dot{\mathbf{q}})
$$

Nest, assume $\mathbf{q}$ satisfies the Euler-Lagrange equations. Taking the time derivative of the Poisson variable $\mathbf{p}$ and applying the Euler-Lagrange equations gives

$$
  \dot{\mathbf{p}} = \frac{\d}{\d t}\nabla_{\dot{\mathbf{q}} L(t,\mathbf{q},\dot{\mathbf{q}})} = \nabla_\mathbf{q} L(t,\mathbf{q},\dot{\mathbf{q}})
$$

Since both cases yield the same result, we conclude that Hamilton's equations and the Euler Lagrange equations are equivalent.
</details>
</MathBox>

## Beltrami identity

<MathBox title='Beltrami identity' boxType='corollary' tag='corollary-1'>
Let $(X, L)$ be a real dynamical system of dimension $n$ with configuration space $X\subseteq\R^n$ and *Lagrangian* $L\in C^2 (TX, \R)$, where $TX$ is the tangent bundle of $X$. Let 

$$
  D = \Set{\mathbf{q} \in C^2 ([t_0, t_1]\subseteq\R, X) | \mathbf{q}(t_0) = \mathbf{x}_0, \mathbf{q}(t_1) = \mathbf{x}_1}
$$

be the set of twice continuously differentiable paths in $X$ with fixed endpoints. The action functional $S:D\to\R$ given by

$$
  S(\mathbf{q}) := \int_{t_0}^{t_1} L(\mathbf{q}(t), \dot{\mathbf{q}(t)})\;\d t
$$

is stationary on a path $\mathbf{q} \in X$ if and only if $L$ satisfies the Beltrami equations

$$
\begin{align*}
  \frac{\d}{\d t} \left[L(\mathbf{q}(t),\dot{\mathbf{q}}(t)) - \dot{\mathbf{q}}(t) \cdot \nabla_{\dot{\mathbf{q}}} L(\mathbf{q}(t),\dot{\mathbf{q}}(t)) \right] =& 0 \\
  \frac{\d}{\d t} \left[L(\mathbf{q}(t),\dot{\mathbf{q}}(t)) - \dot{q}_i \frac{\partial L}{\partial\dot{q}_i} (\mathbf{q}(t),\dot{\mathbf{q}}(t))\right] =& 0 ,\; i=1,\dots,n
\end{align*}
$$

giving the Beltrami identity

$$
  L(\mathbf{q}(t),\dot{\mathbf{q}}(t)) - \dot{\mathbf{q}}(t) \cdot \nabla_{\dot{\mathbf{q}}} L(\mathbf{q}(t),\dot{\mathbf{q}}(t)) = C,\; C\in\R
$$

<details>
<summary>Proof</summary>

This is a special case of the Lagrange problem where the Lagrangian is not dependent on the parametric variable $t\in[t_0, t_1]$. Thus, if $\mathbf{q}$ is a critical function of $S$, then $L$ satisfies the Euler-Lagrange equation (Theorem $\ref{theorem-1}$)

$$
  \nabla_{\mathbf{q}} L(\mathbf{q}(t),\dot{\mathbf{q}}(t)) = \frac{\d}{\d t} \nabla_{\dot{\mathbf{q}}} L(\mathbf{q}(t),\dot{\mathbf{q}}(t))
$$

Writing out the total derivative $\frac{\d L}{\d t}(\mathbf{q}(t),\dot{\mathbf{q}}(t))$ and applying the Euler-Lagrange equations gives

$$
\begin{align*}
  \frac{\d L}{\d t}(\mathbf{q},\dot{\mathbf{q}}) =& \dot{\mathbf{q}}\cdot\nabla_\mathbf{q} L(\mathbf{q}, \dot{\mathbf{q}}) + \ddot{\mathbf{q}}\cdot\nabla_{\dot{\mathbf{q}}} L(\mathbf{q}, \dot{\mathbf{q}}) \\
  =& \dot{\mathbf{q}}\cdot\left(\frac{\d}{\d t} \nabla_{\dot{\mathbf{q}}} L(\mathbf{q}, \dot{\mathbf{q}}) \right) + \ddot{\mathbf{q}}\cdot\nabla_{\dot{\mathbf{q}}} L(\mathbf{q}, \dot{\mathbf{q}}) \\
  =& \frac{\d}{\d t}\left(\dot{\mathbf{q}}\cdot\nabla_{\dot{\mathbf{q}}} L(\mathbf{q}, \dot{\mathbf{q}}) \right)
\end{align*}
$$

Rearranging gives the Beltrami equations

$$
  \frac{\d}{\d t} \left[L(\mathbf{q},\dot{\mathbf{q}}) - \dot{\mathbf{q}} \cdot\nabla_{\dot{\mathbf{q}}} L(\mathbf{q},\dot{\mathbf{q}}) \right] = 0 
$$

</details>
</MathBox>

### Brachistochrone problem

Consider a bead, subject to homogeneous gravitational field, that is allowed to slide down a frictionless wire with fixed endpoints at different heights, not directly above one another. The brachistochrone problem seeks to find the shape of the wire that minimize the time it takes for the particle to travel the wire's length.

Define a Cartesian plane $(x,y)\in\R^2$ with gravitational field $g\hat{\mathbf{y}}$ in positive $y$-direction. Let $A = (0,0)$ and $B = (x_1, x_2)$ be the endpoints of a wire such that $x_1 > 0$ and $y_1 > 0$. 

The possible shapes of the wire are represented as paths $q: ([0,t_1], \R^2)$ with boundary conditions $q(0) = (0,0)$ and $q(t_1) = (x_1,y_1)$. The curve of $q$ is the graph of a function $f\in C^2 ([0,x_1], \R)$ with boundary conditions $f(0) = 0$ and $f(x_1) = y_1$. The arclength of $q$ given by the integral

$$
  s(t) = \int_0^{x(t)} \sqrt{1 + f'(u)}\;\d u
$$

The velocity of the bead is given by $v(t) = \dot{s}(t)$ such that

$$
  v(t) = \frac{\d s}{\d t} = \sqrt{1 + f'(x(t))}\dot{x}(t)  
$$

Because the wire is frictionless, the total energy of the system must by conserved, giving

$$
\begin{gather*}
  \frac{1}{2}mv(t)^2 - mgf(x(t)) = 0 \\
  \implies v(t) = \sqrt{2gf(x(t))}
\end{gather*}
$$

Combining the expressions for $v(t)$ gives the differential equation

$$
\begin{gather*}
  \sqrt{2g f(x)} = \sqrt{1 + f'(x)^2} \frac{\d x}{\d t} \\
  \implies \d t = \sqrt{\frac{1 + f'(x)^2}{2gf(x)}}\;\d x 
\end{gather*}
$$

The transit time of the bead is given by the functional

$$
  T(f) = \int_0^{t_1} \d t = \frac{1}{\sqrt{2g}} \int_0^{x_1} \sqrt{\frac{1 + f'(x)^2}{f(x)}}\;\d x
$$

with a Lagrangian of the form

$$
  L(f(x), f'(x)) = \sqrt{\frac{1 + f'(x)^2}{2g f(x)}}
$$

Thus, to find the curve that minimize the time it takes for the bead to travel from $A$ to $B$, we want to minimize the $T(f)$. Since the Lagrangian $L$ is not dependent on $x$, a $f$ function is critical if and only if $L$ satisfies the Beltrami identity (Corollary $\ref{corollary-1}$)

$$
  L(f(x),f'(x)) - f'(x) \frac{\partial}{\partial f'} L(f(x),f'(x)) = C,\; C\in\R
$$

This gives

$$
\begin{gather*}
  \sqrt{\frac{1 + f'(x)^2}{2gf(x)}} - \frac{f'(x)^2}{\sqrt{\left[1 + f'(x)^2 \right]\left[2gf(x)\right]}} = C \\
  1 + f'(x)^2 - f'(x)^2 = C \sqrt{\left[1 + f'(x)^2 \right]\left[2gf(x) \right]} \\
  1 = C^2 \left[1 + f'(x)^2 \right]\left[2gf(x) \right] \\
  \left[1 + f'(x)^2 \right] f(x) = \frac{1}{2gC^2} = k^2 \\
  \frac{\d f}{\d x} = \sqrt{\frac{k^2 - f(x)}{f(x)}}
\end{gather*}
$$

The differential equation can be solved by separation of variables

$$
\begin{align*}
  \d x &= \sqrt{\frac{k^2 - f(x)}{f(x)}} \d f \\
  x &= \int \sqrt{\frac{k^2 - f(x)}{f(x)}} \d f
\end{align*}
$$

The right hand side integral can be solved by substituting 

$$
\begin{gather*}
  f = -k^2 \sin^2 \left( \frac{t}{2} \right) = -\frac{k^2}{2}(1 - \cos t) \\
  \d y = - k^2 \sin\left( \frac{t}{2} \right)\cos\left( \frac{t}{2} \right) \d t
\end{gather*}
$$

Inserting back into the differential equation gives

$$
\begin{align*}
  x &= -k^2 \int \sqrt{\frac{k^2 \sin^2 \left(\frac{t}{2} \right)}{k^2 \left[1 - \sin^2 \left( \frac{t}{2} \right) \right]}}  \sin\left( \frac{t}{2} \right)\cos\left( \frac{t}{2} \right) \d t \\
  &= -k^2 \int \sin^2 \left( \frac{t}{2} \right) \d t \\
  &= -\frac{k^2}{2} \int (1 - \cos t)\d t \\
  &= \frac{k^2}{2}\left( t - \sin t \right) + C_1
\end{align*}
$$

This results in the following parametric equations

$$
\begin{align*}
  x &= \frac{k^2}{2}\left(t - \sin t \right) + C_1 \\
  y &= \frac{k^2}{2}(1 - \cos t)
\end{align*}
$$

which describe a cycloid formed by revolutions of a circle of radius $k^2/2$. The boundary condition $q(0) = (x(0), y(0)) = (0, 0)$ implies $C_1 = 0$, while the boundary condition $q(t_1) = (x(t_1), y(t_1)) = (x_1, y_1)$ gives the equation set

$$
\begin{align*}
  x_1 =& \frac{1}{2}k^2 (t_1 - \sin t_1) \\
  y_1 =& \frac{1}{2}k^2 (1 - \cot t_1)
\end{align*}
$$

# Lagrange multiplier method

The Langrange multiplier method finds extrema of a function $f: \R^n \to \R$ subject to $k$ equality constraints $g_i(\mathbf{x}) = c_i$ where $g_i : \R^n \to \R$.

The extrema of $f$ are points whose gradients are linear combinations of the constraint gradients

$$
  \nabla f(\mathbf{x}) = \sum_i^k \lambda_i \left[c_i - \nabla g_i \left(\mathbf{x}\right)\right]
$$

where $\lambda_i$ are the Langrange multipliers. The problem can be converted to an unconstrained optimization by defining the Lagrange function 

$$
  L(\mathbf{x}, \lambda) = f(\mathbf{x}) - \sum_i^k \lambda_i \left[c_i - g_i\left( \mathbf{x} \right)\right]
$$

whoose extrames are given by the Euler-Lagrange equations.