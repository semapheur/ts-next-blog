---
title: 'Functional Analysis'
subject: 'Mathematics'
showToc: true
---

# Metric space

<MathBox title='Metric space' boxType='definition'>
A metric space $(X, d)$ consists of a set $X$ and a metric $d: X \times X \to [0, \infty)$ with the following properties for $x,y,z \in X$:

1. $d(x,y) \geq 0$ and $d(x, y) = 0 \iff x = y$ (positive definite)
2. $d(x, y) = d(y, x)$ (symmetric)
3. $d(x, z) \leq d(x, z) + d(z, y)$ (triangle inequality)
</MathBox>

For $X = \R^n$ the line segment between to points is given by the Euclidean metric $d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$

## Topology of a metric space

<MathBox title='Open ball' boxType='definition'>
Let $(X, d)$ be a metric space. The open ball about a point $x\in X$ with radius $\epsilon\in(0, \infty)$ is the set

$$
  B_\epsilon (x) := \Set{ y \in X | d(x, y) < \epsilon}
$$
</MathBox>

<MathBox title='Open and closed sets' boxType='definition'>
Let $(X, d)$ be a metric space. A subset $A \subseteq X$ is open if for each $x \in A$ there is an open ball with $B_\epsilon (x) \subseteq A$. Conversely, a subset $B\subseteq X$ is closed if its complement $B^c := X \setminus A$ is open.
<details>
<summary>Proof</summary>

To show that open balls in fact are open, consider $x\in B_{r}(x)\subseteq X$. Let $y\in B_\epsilon(x)$, and let $a = d(x, y) < r$. We need to find $s > 0$ such that $B_s(y)\subseteq B_r (x)$. If $z\in B_{r-a}(y), then $d(y, z) < r - a$, so by the triangle inequality

$$
  d(x, z) < a + (r - a) = r
$$

Thus $z\in B_r (x)$ and $B_{r - a}(y)\subseteq B_r(x)$. Hence $B_r (x)$ is open.
</details>
</MathBox>

<MathBox title='Boundary' boxType='definition'>
Let $(X, d)$ be a metric space. A point $x \in X$ is called a boundary point for $A \subseteq X$ if for all $\epsilon > 0$: 

$$
  B_\epsilon (x) \cap A \neq \emptyset \quad \mathrm{and} \quad  B_\epsilon (x) \cap A^c \neq \emptyset, \quad A^c = X \setminus A
$$

The set of boundary points in $A$ is denoted $\partial A$.
</MathBox>

<MathBox title='Closure' boxType='definition'>
Let $(X, d)$ be a metric space. The closure of an open set $A\subseteq X$ is the union of the set with its boundary, $\bar{A} := A \cup \partial A$, and is always closed.
</MathBox>

<MathBox title='Induced topology' boxType='proposition'>
Let $(X, d)$ be a metric space. The collection $\mathcal{T}_d$ of open subsets of $X$ is a topology.

<details>
<summary>Proof</summary>

We show that $\mathcal{T}_d$ satisfy the axioms of topology.
1. For any $x\in X$, there is $\epsilon > 0$ such that $B_\epsilon (x)\subseteq X$, hence $X$ is open. Also, $\emptyset$ is open by definition. That is, $X, \emptyset\in\mathcal{T}_d$
2. Let $\Set{U_i \subseteq X}_{i\in I}$ be a collection of open sets in $X$ for an arbitrary index set $I$. For any $x\in U = \bigcup_{i\in I} U_i$, clearly $x\in U_j$ for some $j\in I$. Since $U_j$ is open, there is $\epsilon > 0$ such that $B_\epsilon(x)\subseteq U_j\subseteq U$. Hence, $U$ is also open and $\mathcal{T}_d$ is closed under arbitrary unions.
3. Let $\Set{U_i \subseteq X}_{i\in I}$ be a finite collection of open sets in $X$ for a finite index set $I$. Trivially, if $U=\bigcap_{i\in I} U_i = \emptyset$, then $U$ is open. For any $x\in U$, clearly $x\in U_i$ for every $i\in I$. For each $i\in I$ there is $\epsilon_i > 0$ such that $B_{\epsilon_i}(x)\subseteq U_i$. Take $\epsilon = \min\Set{ \epsilon_i}_{i\in I} > 0$. Since $I$ is finite, $B_\epsilon(x) \subseteq B_{\epsilon_i}(x)\subseteq U_i$ for each $i\in I$. Hence $B_\epsilon(x)\subseteq U$, so $U$ is open and $\mathcal{T}_d$ is closed under finite intersection.  
</details>
</MathBox>

<MathBox title='Metric spaces are Hausdorff' boxType='proposition'>
A metric space $(X, d)$ is a Hausdorff space.

<details>
<summary>Proof</summary>

Consider distinct point $x, y\in X$ with $r = d(x, y) > 0$. Note that $B_{\frac{r}{2}}(x)$ and $B_{\frac{r}{2}}(y)$ are open and contain $x$ and $y$, respectively. Suppose $z\in B_{\frac{r}{2}}(x)\cap B_{\frac{r}{2}}(y)$. Applying the triangle inequality

$$
  d(x, y) \leq d(x, z) + d(z, y) < \frac{r}{2} + \frac{r}{2} = r
$$

creates a contradiction. Hence $B_{\frac{r}{2}}(x) \cap B_{\frac{r}{2}}(y) = \emptyset$ (disjoint). Since $x$ and $y$ are arbitrarily chosen, we conclude that $(X, d)$ is a Hausdorff space.
</details>
</MathBox>

## Convergence

<MathBox title='Convergent sequence' boxType='definition'>
Let $(X, d)$ be a metric space. A sequence $\left( x_n \in X \right)_{n \in \N}$ of points in $X$ is convergent if there is $\tilde{x}\in X$ with 

$$
  \forall \epsilon > 0 \quad \exists N \in \N \quad \forall n \geq N : d\left(x_n, \tilde{x} \right) < \epsilon
$$

A limit is denoted $x_n \xrightarrow{n\to\infty} \tilde{x}$ or $\lim_{n\to\infty} x_n = \tilde{x}$. Equivalently this can be stated as

$$
  x_n \xrightarrow{n\to\infty} \tilde{x} \iff d(x_n, \tilde{x})\xrightarrow{n\to\infty} 0
$$
</MathBox>

<MathBox title='Uniqueness of limits' boxType='proposition'>
Let $(X, d)$ be a metric space, and let $\left( x_n \in X \right)_{n \in \N}$ be a sequence of points in $X$. If $x_n \xrightarrow{n\to\infty} x$ and $x_n \xrightarrow{n\to\infty} y$ for $x,y\in X$, then $x = y$. 

<details>
<summary>Proof</summary>

Let $\epsilon > 0$, then

$$
\begin{gather*}
  \exists M \in \N \; \forall n \geq M: \; d(x_n, x) < \frac{\epsilon}{2} \\
  \exists N \in \N \; \forall n \geq N: \; d(x_n, y) < \frac{\epsilon}{2}
\end{gather*}
$$

Let $n \geq \max(N, \tilde{N})$, and apply the triangle inequality

$$
  d(x, y) \leq d(x, x_n) + d(x_n, y) < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
$$

Hence $d(x, y) \xrightarrow{n\to\infty} 0$ implying $x = y$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $(X, d)$ be a metric space. A subset $A \subseteq X$ is closed if and only if for every convergent sequence $\left(a_n \in A \right)_{n \in \N}$ of points in $A$, the limit is in $A$, i.e. $\lim_{n\to\infty} a_n \in A$.

<details>
<summary>Proof</summary>

Suppose $A$ is closed and that $\left(a_n \in A \right)_{n \in \N}$ is a sequence of points in $A$ such that $a_n \xrightarrow{n\to\infty} x \in X$. Suppose $x\in A^c$. Since $A^c$ is open, $x^n \in A^c$ for sufficiently large $n$, giving a contradiction. Hence $x\in A$. Conversely, suppose $A$ is not closed. Then $A^c$ is not open and there exists $x\in A^c$ with the property that every neighbourhood of $x$ has points in $A$. Note that for each $n\in\N$ there exist $x_n \in B_{\frac{1}{n}}(x)$ with $x_n \in A$. However, clearly $x_n \xrightarrow{n\to\infty} x$, giving a contraction.
</details>
</MathBox>

## Completeness (Cauchy sequence)

<MathBox title='Bounded subset' boxType='definition'>
Let $(X, d)$ be a metric space. A subset $E\subseteq X$ is bounded if for every $x\in X$ there is $M > 0$ such that $d(p,x) < M$ for all $p\in E$.
</MathBox>

<MathBox title='Cauchy sequence' boxType='definition'>
Let $(X, d)$ be a metric space. A sequence $\left( x_n \in X \right)_{n \in \N}$ is called a Cauchy sequence if 

$$
  \forall \epsilon > 0 \; \exists N \in \N: \forall n, m \geq N: \; d(x_n, x_m) < \epsilon
$$

A metric space is complete if all Cauchy sequences converge.
</MathBox>

<MathBox title='Convergent sequences are Cauchy' boxType='proposition'>
Let $(X, d)$ be a metric space. If a sequence $\left( x_n \in X \right)_{n \in \N}$ converges, then the sequence is Cauchy.
<details>
<summary>Proof</summary>

Assume the sequence $\left( x_n \in X \right)_{n\in\N}$ converges to $x\in X$. Let $\epsilon > 0$, then there exists $N\in\N$ such that $d(x_n, x) < \frac{\epsilon}{2}$ for every $n \geq N$. If $m, n > N$, then by the triangle inequality

$$
  d(x_m, x_n) \leq d(x_m, x) + d(x_n, x) < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
$$

Hence $\left( x_n \right)_{n\in\N}$ is Cauchy.
</details>
</MathBox>

<MathBox title='Cauchy sequences are bounded' boxType='proposition' tag='proposition-6'>
A Cauchy sequence in a metric space is bounded.

<details>
<summary>Proof</summary>

Let $(x_k)_{k\in\N_+}$ be a Cauchy sequence in a metric space $(X, d)$. For $\epsilon = 1$ there is $N\in\N$ such that $d(x_n, x_m) < 1$ for all $n, m \geq N$. For a fixed $x\in X$ and any $m \geq N we have

$$
  d(x_n, x) \leq d(x_n, x_m) + d(x_m, x) \leq 1 + d(x_m, x),\; n\geq N
$$

Set

$$
  M = \max\Set{d(x_1,x),\dots, d(x_{N-1},x), 1 + d(x_m,x)}
$$

Then $d(x_k, x) \leq M$ for all $k\in\N$.
</details>
</MathBox>

<MathBox title='Complete sets are closed' boxType='proposition'>
Let $(X, d)$ be a metric space. A complete set $A\subseteq X$ is also closed.

<details>
<summary>Proof</summary>

Assume the sequence $\left( a_n \in A \right)_{n\in\N}$ converges to $x \in X$. Then $\left( a_n \in A \right)_{n \in \N}$ is a Cauchy sequence, and by completeness $x\in A$. Hence $A$ is closed.
</details>
</MathBox>

<MathBox title='Cauchy sequences with a convergent subsequence are convergent' boxType='proposition' tag='proposition-8'>
Let $(X, d)$ be a metric space, and let $\left( x_n \in X \right)_{n\in\N}$ be a Cauchy sequence. If there is a subsequence $\left( x_{n_k} \right)_{k\in\N}$ with $x_{n_k}\xrightarrow{k\to\infty} x \in X$, then $x_n \xrightarrow{n\to\infty} x$.

<details>
<summary>Proof</summary>

Assume the subsequence $\left( x_{n_k} \in A \right)_{k\in\N}$ converges to $x \in X$. Let $\epsilon > 0$, then there exists $j\in\N$ such that $d\left(x_{n_k}, x) < \frac{\epsilon}{2}$. Since $\left( x_n \right)_{n\in\N}$ is Cauchy, there exists $N\in\N$ such that for $d(x_m, x_n) < \frac{\epsilon}{2}$ for $m, n \geq N$. Choose $k\in\N$ such that $k \geq j$ and $n_k \geq N$. By the triangle inequality

$$
  d(x_m, x) \leq d\left(x_m, x_{n_k} \right) + d\left(x_{n_k}, x \right) \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
$$

Hence $x_n \xrightarrow{n\to\infty} x$.
</details>
</MathBox>

## Continuity

<MathBox title='Continuity' boxType='definition'>
Given two metric spaces $(X, d_X)$ and $(Y, d_Y)$, a function $f: X \to Y$ is continuous if $f^{-1}[B] \subseteq X$ is open for all open sets $B \subseteq Y$. A function $f$ is called sequentially continuous if for all $\tilde{x} \in X$ and $\left( x_n \right)_{n \in \N} \subseteq X$ with $x_n \xrightarrow{n\to\infty} \tilde{x}$ holds $f(x_n) \xrightarrow{n\to\infty} f(\tilde{x})$. For metric spaces, the two continuity concepts are equivalent. 
</MathBox>

### Uniform continuity

<MathBox title='Point-wise continuity' boxType='definition'>
Given two metric spaces $(X, d_X)$ and $(Y, d_Y)$, a function $f: X \to Y$ is continuous at $x\in X$ if

$$
  \forall \epsilon > 0 \; \exists \delta > 0 : y\in X \land d_X(x, y) < \delta \implies d_Y(f(x), f(y)) < \epsilon
$$

<details>
<summary>Proof</summary>

The definition of point-wise continuity is equivalent with the topoligical definition of continuity. Suppose $f$ is continuous at $x$. For $\epsilon > 0$, the open ball $B_{d_Y}(f(x), \epsilon)$ is a neighbourhood of $f(x)$ and hence $U = f^{-1}\left[ B_{d_Y}(f(x), \epsilon) \right]$ is a neighbourhood of $x$. Thus there exists $\delta > 0$ such that $B_{d_Y}(x, \delta) \subseteq U$. Conversely, suppose $V$ is a neighbourhood of $f(x)$. Then there exists $\epsilon > 0$ such that $B_{d_Y}(f(x), \epsilon)\subseteq V$. By assumption, there exists $\delta > 0$ such that if $y\in B_{d_X}(x, \delta)$, then $f(y) \in B_{d_Y}(f(x), \epsilon)\subseteq V$. Hence $f^{-1}[V]$ is a neighbourhood of $x$.
</details>
</MathBox>

<MathBox title='Uniform continuity' boxType='definition'>
Given two metric spaces $(X, d_X)$ and $(X, d_Y)$, a map $f: X \to Y$ is uniformly continuous if for all $\epsilon > 0$ there exists a $\delta > 0$ such that for every $x, y \in X$ with $d_X(x, y) < \delta$, we have that $d_Y (f(x), f(y)) < \epsilon$. If $f$ is uniformly continuous, then $f$ is continuous (on $X$).
</MathBox>

### Equicontinuity

<MathBox title='Equicontinuity' boxType='definition'>
Let $F \subseteq C(X, Y)$ be a family of continuous maps from $X$ to $Y$. Then $F$ is uniformly equicontinuous if for all $\epsilon > 0$, there exists a $\delta > 0$ such that $d_Y (f(x), f(y)) < \epsilon$ for all $f \in F$ and all $x, y \in X$ such that $d_X (x, y) < \delta$. Equivalently 

$$
  \sup_{f \in F} d_Y (f(x), f(y)) \xrightarrow{d_X (x, y)\to 0} 0
$$
</MathBox>

### Hölder continuity

<MathBox title='Hölder continuity' boxType='definition'>
Given two metric spaces $\left( X, d_X \right)$ and $\left( Y, d_Y \right)$, a function $f: X\to Y$ is called Hölder continuous with exponent $\alpha\in(0,\infty)$ if there is $C\in(0, \infty)$ such that, for all $x, \tilde{x}\in X$

$$
  d_Y\left( f(x), f\left(\tilde{x}\right) \right) \leq Cd_X\left( x, \tilde{x} \right)^\alpha
$$

For any $\alpha > 0$, the Hölder condition implies that $f$ is uniformly continuous. If $\alpha = 1$, then function satisfies the Lipschitz condition.
</MathBox>

<MathBox title='Contraction' boxType='definition'>
Given two metric spaces $\left( X, d_X \right)$ and $\left( Y, d_Y \right)$, a function $f: X\to Y$ is a contraction if there is $C\in(0, 1)$ such that, for all $x, \tilde{x}\in X$

$$
  d_Y\left( f(x), f\left(\tilde{x}\right) \right) \leq Cd_X\left( x, \tilde{x} \right)
$$

Contractions have Hölder exponent $\alpha = 1$, and are thus uniformly continuous.
</MathBox>

<MathBox title='Banach fixed-point theorem' boxType='theorem'>
Let $\left( X, d \right)$ be a complete metric space. Then any contraction $f:X\to X$ has a unique fixed point. That is, there exists $x*\in X$ with $f(x*) = x*$. Alternatively, let $x_0\in X$ and recursively define $x_n = f(x_{n-1})$ for $n\in\N$. Then $x_n \xrightarrow{n\to\infty} x*$.  
</MathBox>

### Lipschitz continuity

<MathBox title='Lipschitz continuity' boxType='definition'>
Given two metric spaces $\left( X, d_X \right)$ and $\left( Y, d_Y \right)$, a function $f: X\to Y$ is called Lipschitz continuous if there exists $C\in (0, \infty)$ such that, for all $x, \tilde{x}\in X$

$$
  d_Y\left( f(x), f\left(\tilde{x}\right) \right) \leq Cd_X\left( x, \tilde{x} \right)
$$

The Lipschitz condition ensures uniform continuity, as it corresponds with a Hölder exponent $\alpha > 0$.
</MathBox>

## Compactness and boundedness

<MathBox title='Bounded set' boxType='definition'>
Let $(X, d)$ be a metric space. A subset $A \subseteq X$ is bounded if there exists $r > 0$ such that $d(x, y) \leq r$ for all $x, y \in X$. The diameter of $A$ is defined as

$$
  \mathrm{diam}(A) := \inf\Set{ r > 0 | d(x, y) < r \; \forall x,y \in A}
$$

So $A$ is bounded if and only if $\mathrm{diam}(A) < \infty$.
</MathBox>

<MathBox title='Totally bounded set' boxType='definition'>
Let $(X, d)$ be a metric space. A subset $A \subseteq X$ is totally bounded if for every $r > 0$ there is a finite cover of $A$ with open balls of radius $r$.
</MathBox>

<MathBox title='' boxType='proposition'>
Let $(X, d)$ be a metric space. If $A \subseteq X$ is totally bounded, then $A$ is bounded.
<details>
<summary>Proof</summary>

If $A$ is totally bounded, there exists a finite cover of $A$ with open unit balls (radius $1$). Let $C$ denote the center of the balls, and let $c = \max\Set{ d(u, v) | u, v\in C}$ be the maximum distance between two centers. Since $C$ is finite, $c<\infty$. Now let $x, y\in A$. Since the balls cover $A$, there exists $u, v\in C$ with $x\in B_1(u)$ and $y\in B_1(v)$. By the triangle inequality

$$
  d(x, y) \leq d(x, u) + d(u, v) + d(v, y) \leq 2 + c
$$

This shows that $\mathrm{diam}(A) < \infty$, hence $A$ is bounded.
</details>
</MathBox>

<MathBox title='Sequential compactness' boxType='definition'>
Let $(X, d)$ be a metric space. A subset $A \subseteq X$ is (sequentially) compact if for each sequence $\left( x_n \right)_{n \in \N} \subseteq A$ there is a convergent subsequence $\left( x_{n_k} \right)_{k \in \N}$ with $\tilde{x} := \lim_{k\to\infty} x_{n_k} \in A$.
</MathBox>

<MathBox title='Compactness' boxType='definition'>
Let $(X, d)$ be a metric space and $J\subseteq\N$ an index set. A collection $(G_\alpha)_{\alpha\in J}$ of open sets is an open cover of a set $E\subset X$ if

$$
  E \subset \bigcup_{\alpha\in J} G_\alpha
$$

A set $E\subset X$ is compact if every open cover of $E$ has finite subcover, i.e. there is a finite subset $J' \subset J$ of such that

$$
  E \subset \bigcup_{\alpha\in J'} G_\alpha
$$


A subset $A \subseteq X$ is (sequentially) compact if for each sequence $\left( x_n \right)_{n \in \N} \subseteq A$ there is a convergent subsequence $\left( x_{n_k} \right)_{k \in \N}$ with $\tilde{x} := \lim_{k\to\infty} x_{n_k} \in A$.
</MathBox>

<MathBox title='Lebesgue number' boxType='definition'>
Let $(X,d)$ be a metric space. An $\epsilon_0 \geq 0$ is a Lebesgue number of an open cover $(G_\alpha)_{\alpha\in J}$ if for all $x\in X$ and for all $0\leq\epsilon < \epsilon_0$, the ball $B(x,\epsilon)$ is contained in some $G_\alpha$.
</MathBox>

<MathBox title='Characteristics of compactness' boxType='proposition' tag='proposition-10'>
Let $(X,d)$ be a metric space. The following are equivalent:
1. $X$ is compact.
2. Every collection $\mathcal{C}$ of closed subsets of $X$ with finite intersection property has a nonempty intersection.
3. $X$ is sequentially compact.
4. $X$ is totally bounded and every open cover has a positive Lebesgue number.

<details>
<summary>Proof</summary>

**(1)$\implies$(2):** Suppose $X$ is compact. Let $\mathcal{C} = (F_\alpha)_{\alpha\in J}$ be a collection of closed sets with the finite intersection property. If $\bigcap_{\alpha\in J} F_\alpha = \emptyset$, then $(F_\alpha^c)_{\alpha\in J}$ is an open cover of $X$. By compactness of $X$, there is a finite subcover $(F_{\alpha_k}^c)_{k=1}^n$ of $X$ which implies that $(F_{\alpha_k})_{k=1}^n$ has empty intersection. This contrdiction implies that $\bigcap_{\alpha\in J} F_\alpha \neq\emptyset$.

**(2)$\implies$(3):** Let $(x_k)_{k\in\N_+}$ be a sequence in $X$. For each $n\in\N$, let $B_n = \Set{x_n, x_{n+1},\dots}$. Then $(\overline{B}_n)_{n\in\N_+}$ is a collection of closed sets with the finite intersection property. By hypothesis, the intersection $\bicap_{n\in\N_+} \overline{B}_n$ is nonempty.

Let $x\in\bigcap_{n\in\N_+} \overline{B}_n$. For each $i\in\N$, choose $x_{k_i} \in B(x, 1/i)$ with $k_i < k_{i+1}$. Then $(x_{k_i})_{i\in\N_+}$ is a subsequence that converges to $x$.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-11'>
A closed subset of a compact set is compact.

<details>
<summary>Proof</summary>

Let $F$ be a closed subset of a compact set $K$. For each open covering $\mathcal{G} = (G_\alpha)_{\alpha\in J}$ of $F$, the collection $\mathcal{G}\cup F^c$ is an open covering of $K$. Since $K$ is compact there is a finite subcover $\Set{F^c, G_{\alpha_1},\dots,G_{\alpha_n}}$ of $K$. The finite collection $\Set{G_{\alpha_i}}_{i=1}^n$ is a finite subcover of $F$, making $F$ compact.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-12'>
A compact subspace of a metric space is bounded and closed.

<details>
<summary>Proof</summary> 

Let $A \subseteq X$ be a compact subspace of a metric space $X$, and let $\left(x_n \right)_{n \in \N} \subseteq A$ be convergent with limit $\tilde{x} \in X$. Because $A$ is compact, there is a convergent subsequence $\left( x_{n_k} \right)_{k \in \N}$ with limit $\tilde{\tilde{x}} \in A$. Furthermore, since limits are unique, then $\tilde{x} = \tilde{\tilde{x}} \in A$. This shows that $A$ is closed.

Proving that compactness implies boundedness can be done by contraposition. Assuming that $A$ is not bounded, then for a given $a \in A$, there are $x_n \in A$ with $d(a, x_n) > n$. For any subsequence $\left( x_{n_k} \right)_{k \in \N}$ and any point $b \in A$ we have

$$
\begin{gather*}
  n_k < d(a, x_{n_k}) \leq d(a, b) + d(b, x_{n_k}) \\
  \implies n_k - d(a, b) \leq d(b,  x_{n_k}) \\
  \implies \lim_{k \to \infty} d(b,  x_{n_k}) \neq 0 \quad \forall b \in A
\end{gather*}
$$

Hence, $A$ is not compact. 
</details>
</MathBox>

<MathBox title='Heine-Borel theorem' boxType='theorem'>
For $\R^n$ with the standard Euclidean metric, if a subset $K$ is bounded and closed, then $K$ is compact.

<details>
<summary>Proof</summary>

We show first that every $n$-cell $[a,b]$ is compact. Suppose $\mathcal{G} = (G_\alpha)_{\alpha\in J}$ is an open cover of $I_1 = [a,b]$ that has no finite subcover. Let $c = (a+b)/2$ be the midpint of $a$ and $b$, i.e. $c_k = (a_k + b_k)/2$ for $k = 1,\dots,n$. The intervals $[a_k, c_k]$ and $[c_k, b_k]$ subdivide $I_1$ into $2^n$ $n$-cells. At least one of these $2^n$ $n$-cells is not covered by a finite subcollection of $\mathcal{G}$. Let $I_2$ be one of these cells.

We subdivide $I_2$ and repeat the argument to obtain a sequence of nested $n$-cells $(I_k)_{k\in\N_+}$, i.e. $I_{k+1}\subset I_k$ for all $k$, where each $I_k$ is not covered by a finite subcollection of $\mathcal{G}$. Furthermore, for $x,y\in I_k$ we have $\lVert x - y \rVert_2 \leq 2^{-n} \lVert b - a\rVert_2$.

We form a sequence $(x_k)_{k\in\N_+}$ by chooseing $x_k \in I_k$ for all $k$. This sequence is Cauchy because for $\epsilon > 0$ the choice of $N\in\N$ satisfying $2^{-N} \lVert b - a \rVert < \epsilon$ gives $\lVert x_n - x_m \rVert_2 \leq 2^{-N} \lVert b - a \rVert < \epsilon$ whenever $n, m \geq N$.Since $\R^n$ is complete, the Cauchy sequence $(x_k)_{k\in\N_+}$ converges to $x\in\R^n$.

Since $\mathcal{G}$ is an open cover of $[a,b]$, there is some $\alpha\in J$ such that $x\in G_\alpha$. Since $G_\alpha$ is open and $x\in G_\alpha$, there is $r > 0$ such that $B(x,r)\subset G_\alpha$. For this $r > 0$, there is $N\in\N$ such that $2^{-N} \lVert b - a\rVert_2 < r$. Since $\lVert x - y \rVert_2 \leq 2^{-N} \lVert b - a \rVert_2 < r$ for all $x, y \in I_N$ we obtain $I_N \subset B(x,r) \subset G_\alpha$.

Since $I_n \subset I_N$, we obtain $I_n \subset G_\alpha$ for all $n \geq N$. This gives a finite subcover of $I_n$ for all $n\geq N$, which is a contradiction. Thus, $[a,b]$ is compact.

Next we show that any closed and bounded subset $K \subset\R^n$ is compact. The boundedness of $K$ implies that there is an $n$-cell $[a,b]$ such that $K\subset[a,b]$. Since $K$ is closed, it is a closed subset of the compact $[a,b]$. By Proposition $\ref{proposition-11}$, the set $K$ is compact.
</details>
</MathBox>

<MathBox title='Generalized Heine-Borel theorem' boxType='theorem'>
A metric space is compact if and only if it is complete and totally bounded.

<details>
<summary>Proof</summary>

Suppose $(X,d)$ is a compact metric space. By Proposition $\ref{proposition-10}$, the metric space $X$ is totally bounded. To show that $X$ is complete, let $(x_k)_{k\in\N_+}$ be a Cauchy sequence in $X$. By Proposition $\ref{proposition-10}$, the sequence $(x_k)_{k\in\N_+}$ has a convergent subsequence. By Proposition $\ref{proposition-8}$, any Cauchy sequence with a convergent subsequence is convergent. Thus, the Cauchy sequence $(x_k)_{k\in\N_+}$ converges in $X$, making $X$ complete.

Conversely, suppose $X$ is complete and totally bounded. To get compactness of $X$, we show that $X$ is sequentially compact and use Proposition $\ref{proposition-10}$. Suppose $(x_k)_{k\in\N_+}$ is a sequence in $X$. Let $E = \Set{x_k}_{k\in\N_+}$. If $E$ is finite, then $(x_k)_{k\in\N_+}$ has a convergent subsequence.

Next, suppose $E$ is infinite. Since $X$ is totally bounded, it can be covered with finitely many open balls of radius $1$. One of these balls, call it $B_1$, contains infinitely many elements of $E$. Now cover $X$ with open balls of radius $1/2$. One of these balls, call it $B_2$, intersect $B_1$ and contains infinitely many elements of $E$. 

Repeating this process gives a sequence of nested open balls $((B_i))_{i\in\N_+}$ where the radius of $B_i$ is $1/i$. For each $i\in\N$, choose $x_{k_i} \in B_i$, where $k_i < k_{i+1}$ for all $i$. Thus, $(x_{k_i})_{i\in\N_+}$ is a subsequence that is Cauchy because $d(x_{k_j}, x_{k_l}) < 1/i$ for all $j, k \geq i$. Since $X$ is complete, the Cauchy sequence converges, and so $(x_k)_{k\in\N_+}$ has a convergent subsequences. Hence, $X$ is sequentially compact.
</details>
</MathBox>

## Continuity

<MathBox title='Continuous images of compact subsets are compact' boxType='proposition'>
Let $X$ and $Y$ be metric spaces. If $f:X\to Y$ is continuous and $K$ is a compact subset of $X$, then $f(K)$ is a compact subset of $Y$.

<details>
<summary>Proof</summary>

Let $(G_\alpha)_{\alpha\in J}$ be an open covering of $f(K)$. By the continuity of $f$, the collection $(f^{-1} (G_\alpha))_{\alpha\in J}$ is an open covering of $K$. Since $K$ is compact, there exists a finite subcovering $(f^{-1} (G_\alpha))_{\alpha\in J'}$ for a finite $J' \subset J$. Thus, $(G_\alpha)_{\alpha\in J'}$ is a finite subcover of $f(K)$ implying that $f(K)$ is compact.
</details>
</MathBox>

<MathBox title='Extreme value theorem' boxType='theorem'>
Let $X$ be a metric space. If $f:X\to\R$ is continuous and $K\subset X$ is nonempty and compact, then $f(K)$ contains its infimum and supremum.

<details>
<summary>Proof</summary>

The image $f(K)$ is compact in $\R$, so that by Proposition $\ref{proposition-12}$, the set $f(K)$ is closed and bounded. Because $f(K)$ is bounded, the infimum and supremum of $f(K)$ are both finite. Let $M$ be the supremum of $f(K)$. Then there exists a "maximizing" sequence $(x_k)_{k\in\N_+} \subset f(K)$ such that $f(x_k) \xrightarrow{k\to\infty} M$. Since $K$ is compact, the sequence $(x_k)_{k\in\N_+}$ has a convergent subsequence $(x_k)_{k\in\N_+}$ with limit $x\in K$. Since $f(x_k) \xrightarrow{k\to\infty} M$, the continuity of $f$ implies that $M = f(x)\in f(K)$. A similar argument applies to the infimum $m$ of $f(K)$.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-14'>
Let $X$ and $Y$ be metric spaces. If $K$ is a compact subset of $X$ and $f:K\to Y$ is continuous, then $f$ is uniformly continuous on $K$.

<details>
<summary>Proof</summary>

Let $\epsilon > 0$. Since $f:K\to Y$ is continuous, there is for each $x\in K$ a $\delta_x > 0$ such that $\rho(f(x), f(y)) < \epsilon/2$ when $d(x,y) < \delta_x$. The collection $(B(x, \delta_x /2))_{x\in K}$ is an open cover of $K$.

By compactness of $K$ there is a finite subcollecion $(B(x_k, \delta_{x_k} /2))_{k=1}^n$ that is a subcover of $K$. For any $y\in K$ there is $k\in\Set{1,\dots,n}$ such that $d(y, x_k) < \delta_{x_k}/2$.

Set $\delta = \min\Set{\delta_{x_1},\dots,\delta_{x_k}}$. For $y,z\in K$ with $d(y,z) < \delta/2$ we have

$$
  d(x_k, z) \leq d(x_k, y) + d(y, z) < \frac{\delta_{x_k}}{2} + \frac{\delta}{2} \leq \frac{\delta_{x_k}}{2} + \frac{\delta_{x_k}}{2} = \delta_{x_k}
$$

This implies that $\rho(f(x_k), f(z)) < \epsilon/2$, so that

$$
\begin{align*}
  \rho(f(y),f(z)) \leq& \rho(f(y),f(x_k)) + \rho(f(x_k),f(z)) \\
  \leq& \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
\end{align*}
$$

Thus, $f$ is uniformly continuous on $K$.
</details>
</MathBox>

## Isometry

<MathBox title='Isometry' boxType='definition'>
Let $(X, d_X)$ and $(Y, d_Y)$ be two metric spaces. A function $f: X \to Y$ is called an isometry if for any $a, b \in X$

$$
  d_Y \left( f(a), f(b) \right) = d_X \left(a, b \right)
$$

That is, $f$ preserves distance. The metric spaces $(X, d_X)$ and $(Y, d_Y)$ are isometric if there exists a bijective isometry $f:X\to Y$.
</MathBox>

<MathBox title='' boxType='proposition'>
Let $(X, d_X)$ and $(Y, d_Y)$ be two metric spaces, and consider a function $f:X\to Y$. If function $f$ is isometric, then $f$ is injective and Lipschitz continuous.
<details>
<summary>Proof</summary> 

By definition, an isometry $f$ is Hölder continuous with $\alpha = 1$ and $C = 1$, and hence $f$ is also Lipschitz continuous. To show injectivity, note that for any $x, y\in X$ with $x \neq y$, then $d_Y(f(x), f(y)) = d(x, y) > 0$. Hence $f(x)\neq f(y)$, showing that $f$ is injective (one-to-one). 
</details>
</MathBox>

<MathBox title='Isometry is an equivalence relation' boxType='proposition'>
Isometry is an equivalence relation on metric spaces that satisifies, for metric spaces $(X, d_X)$, $(Y, d_Y)$ and $(Z, d_Z)$
1. reflexivity: $X$ is isometric to $X$
2. symmetry: if $X$ is isometric to $Y$, then $Y$ is isometric to $X$
3. transitivity: if $X$ is isometric to $Y$ and $Y$ is isometric to $Z$, then $X$ is isometric to $Z$
<details>
<summary>Proof</summary> 

1. The identity function $\operatorname{id}:X\to X$ is an isometry from $X$ to $X$.
2. if $X$ is isometric to $Y$, there is a bijective isometry $f:X\to Y$ with an isometric inverse $f^{-1}: Y\to X$. Hence $Y$ is isometric to $X$.
3. if $X$ is isometric to $Y$ and $Y$ is isometric to $Z$, there are two bijective isometries $f: X\to Y$ and $g:Y\to Z$. Then the composition $g\circ f: X\to Z$ is an isometry from $X$ to $Z$.
</details>
</MathBox>

# Normed space

<MathBox title='Normed space' boxType='definition'>
Let $\mathbb{F} \in \Set{\R, \mathbb{C}}$ be a field of numbers and let $X$ be a $\mathbb{F}$-vector space. A map $\|\cdot\| : X \mapsto [0, \infty)$ is called a norm if it satisfies

1. $\lVert x\rVert = 0 \iff x = 0$ (positive definite)
2. $\lVert \lambda x\rVert = |\lambda| \lVert x\rVert, \quad \lambda \in \mathbb{F}$ (absolutely homogenous)
3. $\lVert x + y\rVert \leq \lVert x\rVert + \lVert y\rVert$ (triangle inequality)

The pair $(X, \lVert\cdot\|)$ is called a normed space. The norm $\| \cdot\rVert$ induces a metric by

$$
  d_{\lVert \cdot\rVert}(x, y) := \lVert x - y\rVert
$$

which makes the normed space $(X, \|\cdot\|)$ into a metric space $(X, d_{\|\cdot\|})$.
</MathBox>

The norm $\lVert \cdot\rVert$ is a continuous map. Considering the sequence $\left( x_n \right)_{n\in\N} \subseteq X$ with limit $\tilde{x} \in X$, then by the triangle inequality

$$
\begin{gather*}
  \lVert x_n\rVert = \lVert \left(x_n - \tilde{x}\right) + \tilde{x}\rVert \leq \lVert x_n - \tilde{x}\rVert + \lVert \tilde{x}\rVert = d \left(x_n, \tilde{x} \right) + \lVert \tilde{x}\rVert \\
  \implies \lim_{n\to\infty} \lVert x_n\rVert \leq \lVert \tilde{x}\rVert
\end{gather*}
$$

Conversely,

$$
\begin{gather*}
  \lVert \tilde{x}\rVert = \lVert \left(\tilde{x} - x_n \right) + x_n\rVert \leq \lVert \tilde{x} - x_n\rVert + \lVert x_n\rVert = d(\tilde{x}, x_n) +  \lVert x_n\rVert \\
  \implies \lVert \tilde{x}\rVert \leq \lim_{n\to\infty}  \lVert x_n\rVert
\end{gather*}
$$

<MathBox title='Banach space' boxType='definition'>
A normed space $(X,\lVert\cdot\|)$ is called a Banach space if $\left(X, d_{\| \cdot\rVert} \right)$ is a complete metric space. A Banach space is a complete normed space.
</MathBox>

<MathBox title='Closures of Banach subspaces are subspaces' boxType='definition'>
Let $X$ be a Banach space with a subspace $M\subseteq X$. The closure $\overline{M}$ is also a subspace of $X$.

<details>
<summary>Proof</summary>

For $x, y\in\overlin{M}$ there exists sequences $\Set{x_n}_{n\in\N}$ and $\Set{y_n}_{n\in\N}$ in $M$ such that $x_n \xrightarrow{n\to\infty} x$ and $y_n \xrightarrow{n\to\infty} y$. Then

$$
  \lVert (x_n + y_n) - (x + y) \rVert \leq \lVert x_n - x \rVert + \lVert y_n - y \rVert \xrightarrow{n\to\infty} 0
$$

so that $x + y \in\overline{M}$, and for $\alpha\in\mathbb{F}$

$$
  \lVert \alpha x_n - \alpha x \rVert = |\alpha|\cdot\lVert x_n - x\rVert \xrightarrow{n\to\infty} 0
$$

so that $\alpha x\in\overline{M}$. Hence, $\overline{M}$ is a subspace.
</details>
</MathBox>

## Asymptotic behaviour

<MathBox title='Bachmann-Landau notation' boxType='definition'>
Let $X, Y$ be normed spaces, and let $f:X\to Y$ and $\alpha: X\to [0,\infty)$ be functions. We write

$$
  f(x) = O(\alpha(x)),\; x\to a \in X
$$

if there exists some constants $C > 0$ and $r > 0$ such that for $a\in X$

$$
  \lVert f(x) \rVert_Y \leq C\alpha (x),\; \forall x\in B(a,r) \subset X
$$

We write

$$
  f(x) = o(\alpha(x)),\; x\to a \in X
$$

if for every $\epsilon > 0$ there is $\delta > 0$ such that

$$
  \frac{\lVert f(x) \rVert_Y}{\alpha (x)} \leq \epsilon,\; \forall x\in B(a,\delta) \subset X
$$

or equivalently

$$
  \lim_{x\to a} \frac{\lVert f(x) \rVert_X}{\alpha (x)} = 0
$$

Similarly, we write

$$
  f(x) = O(\alpha(x)),\; x\to\infty
$$

if there exists constants $C > 0$ and $K > 0$ such that $\lVert f(x) \rVert_Y < C \alpha(x)$ for all $x\in X$ with $\lVert x \rVert_X > K$.

We write 

$$
  f(x) = o(\alpha(x)),\; x\to\infty
$$

if for every $\epsilon > 0$ there is $K > 0$ such that

$$
  \frac{\lVert f(x) \rVert_Y}{\alpha (x)} \leq \epsilon
$$

for all $x \in X$ with $\lVert x \rVert$, or equivalently

$$
  \lim_{\lVert x \rVert_X \to\infty} \frac{\lVert f(x) \rVert_Y}{\alpha(x)} = 0
$$
</MathBox>

## Dual space

<MathBox title='Dual space' boxType='definition'>
The dual space $X'$ of a normed space $X$ is the space of all continuous (bounded) linear operators (functionals) $\ell : X \to \mathbb{F}$. 
</MathBox>

<MathBox title='Dual spaces are Banach spaces' boxType='proposition'>
Let $X'$ be the dual space of a normed space $X$. The dual space itself is a normed space $\left(X', \lVert \cdot\rVert_{X \to \mathbb{F}}\right)$, which is also a Banach space.

<details>
<summary>Proof</summary> 

Let $\left( \ell_k \right)_{k\in\N} \subseteq X'$ be a Cauchy sequence, i.e.

$$
  \forall \epsilon > 0 \quad \exists N \in \N \quad \forall n, m \geq N : \lVert \ell_n - \ell_m\rVert_{X\to\mathbb{F}} < \epsilon
$$

Since the operator norm $\lVert \cdot\rVert_{X\to\mathbb{F}}$ is defined by a supremum, we know that for all $x \in X$ with $x\neq 0$

$$
\begin{gather*}
  \frac{1}{\lVert x\rVert_X} \left| \ell_n - \ell_m \right| \leq \lVert \ell_n - \ell_m\rVert_{X\to\mathbb{F}} < \epsilon \\
  \left| \ell_n - \ell_m \right| < \epsilon \lVert x\rVert_X
\end{gather*}
$$

Hence, $\left( \ell_k (x) \right)_{k\in\N} \subseteq \mathbb{F}$ is a Cauchy sequence for all $x \in X$, with the limit

$$
  \ell(x) := \lim_{k\to\infty} \ell_k (x)
$$

We then have to show that $\ell: X \to \mathbb{F}$ is linear and bounded and that $\lVert \ell_k - \ell\rVert_{X \to \mathbb{F}} \xrightarrow{k\to\infty} 0$. Boundedness follows from the Cauchy property of $\left( \ell_k \right)_{k\in\N}$:

$$
\begin{gather*}
  \lVert \ell_n\rVert_{X\to\mathbb{F}} \tleq \underbrace{\lVert \ell_n - \ell_N\rVert_{X\to\mathbb{F}}}_{< \epsilon} + \underbrace{\lVert \ell_N\rVert_{X\to\mathbb{F}}}_{:= C} \leq \epsilon + C \quad \forall n\geq N \\
  \implies \left| \ell(x) \right| = \left| \lim_{k\to\infty} \ell_k (x) \right| = \lim_{k\to\infty} \left| \ell_k (x) \right| \leq \lim_{k\to\infty} \underbrace{\lVert \ell_{k}\rVert_{X\to\mathbb{F}}}_{\leq \tilde{C}} \lVert x\rVert_X \\
  \implies \lVert \ell\rVert_{X\to\mathbb{F}} = \frac{1}{\lVert x\rVert_X} \left| \ell(x) \right| \leq \tilde{C} < \infty
\end{gather*}
$$

To show the convergence of the operator norm $\lVert \cdot\rVert_{X\to\mathbb{F}}$, we have the for $\epsilon > 0$ there is a $N \in \N$ such that for all $n, m \geq N$

$$
\begin{gather*}
  \frac{1}{\lVert x\rVert_X} \left| \ell_n (x) - \ell_m (x) \right| < \epsilon \\
  \implies \sup_{\overset{x\in X}{x\neq 0}} \frac{1}{\lVert x\rVert_X}  \left| \ell_n (x) - \lim_{m\to\infty} \ell_m (x) \right| = \sup_{\overset{x\in X}{x\neq 0}} \frac{1}{\lVert x\rVert_X}  \left| \ell_n (x) - \ell (x) \right| \leq \epsilon \\
  \implies \lVert \ell_n - \ell\rVert_{X\to\mathbb{F}} \leq \epsilon
\end{gather*}
$$
</details>
</MathBox>

<MathBox title='Hahn-Banach theorem' boxType='theorem' tag='theorem-5'>
Let $\left(X, \lVert \cdot\rVert_X \right)$ be a normed space, $U \subset X$ a subspace and $\ell \in U^*$ a continuous linear functional on $U$. Then there exists a linear functional $\tilde{\ell} \in X^*$ that extends $\ell$ with $\tilde{\ell}(u) = \ell(u)$ for all $u \in U$ and $\lVert \tilde{\ell}\rVert_{X^*} = \lVert \ell\rVert_{U^*}$.
</MathBox>

## Arzelà-Ascoli theorem

<MathBox title='Arzelà-Ascoli theorem' boxType='theorem'>
Consider the Banach space $\left(C([a, b]), \lVert \cdot\rVert_\infty \right)$ of continuous functions on an interval $I = [a, b] \in \R$ with the supremum norm $\lVert f\rVert_\infty := \sup \Set{ |f(t)| | t\in[a, b]}$. A subset $F \in C([a, b])$ is compact if and only if $F$ is closed, bounded and uniformly equicontinuous.
</MathBox>

## Lebesgue space ($L^p$)

<MathBox title='$L^p$ space' boxType='definition'>
Let $(X,\mathcal{A},\mu)$ be a measure space and suppose $f: X\to\R$ is measurable. For $p\in(0,\infty)$ we define the $p$-norm

$$
  \lVert f\rVert_p := \left( \int_X |f|^p \;\d\mu \right)^{1/p}
$$

and for $p=\infty$ we define the essential supremum norm

$$
  \lVert f\rVert_\infty := \inf\Set{b\in[0,\infty] : |f|\overset{\textrm{a.e.}}{\leq} b}
$$

The function $f$ is called $p$-integrable if $\| f\|_p < \infty$. The set of all $p$-integrable functions is denoted

$$
  L^p (X,\mathcal{A},\mu) := \Set{ f:X\to\R: \| f\|_p < \infty} \subseteq \mathcal{M}(X,\R)
$$

and is called a Lebesgue space. Here $\mathcal{M}(X,\R)$ denotes the collection of all measurable functions from $X$ into $\R$.
</MathBox>

<MathBox title='$L^p$ space are normed vector spaces' boxType='proposition'>
For $p\in[1,\infty]$, let $\mathcal{L}^p = \Set{[f] : f\in L^p}$ and define $\lVert[f]\|_p =\rVert f \|_p$ for $f\in\mathcal{M}(X,\R)$ where $\mathcal{M}(X,\R)$ is the collection of measurable functions $f:X\to\R$. Then $\mathcal{L}^p \subseteq\mathcal{M}\setminus\equiv$ and $\|\cdot\|$ is a norm on $\mathcal{L}^p$ that satisfies for $f,g\in L^p$ and $c\in\mathcal{R}$
1. $\| f\|_p \geq 0$ and $\| f\|_p = 0$ if and only if $f\equiv 0$ (positive definite)
2. $\| cf\|_p = |c|\cdot\| f\|_p$ (absolutely homogenous)
3. $\lVert f+g\|_p \leq\rVert f\lVert_p +\rVert p\|_p$ (triangle inequality)

For every $p\in[0,\infty]$, the Lebesgue space $L^p$ is a Banach space.
<details>
<summary>Proof</summary> 

That $\mathcal{L}^p \subseteq\mathcal{M}\setminus\equiv$ follows immediately from that $L^p\subseteq\mathcal{M}$. It remains to show that $\|\cdot\|_p$ satisfies the norm properties.
1. The predicate $\lVert f\|_p \geq 0$ follows from the definitions. For the second part, we first consider the case $p\in(0,\infty)$. Trivially, $\| 0\|_p = 0$. Conversely, if $\| f\|_p = 0$ then $\int_X\rVert f\|^p\;\d\mu = 0$ and hence $|f|^p \overset{\textrm{a.e.}}{=} 0$ and $f \overset{\textrm{a.e.}}{=} 0$. For the case $p = \infty$, it follows trivially that $\| 0\|_\infty = 0$. Conversely, suppose $\| f\|_\infty = 0$. Then for each $n\in\N$ there exists $b_n\in[0,\infty)$ with $b_n \xrightarrow{n\to\infty}0$ and $|f\overset{\textrm{a.e.}}{\leq} b_n$, resulting in $f\overset{\textrm{a.e.}}{=}0$.
2. For $p\in(0,\infty)$ we have

$$
\begin{gather*}
  \| cf\|^p \int_X |cf|^p\;\d\mu = |c|^p \int_X |f|^p\;\d\mu = |c|^p\cdot\| f\|^p \\
  \iff \| cf\| = |c|\cdot\| f\|_p
\end{gather*}
$$

For $p=\infty$, the result is trivially true if $c=0$. For $c\neq 0$, note that $b\in[0,\infty]$ is an essential bound of $|f|$  if and only if f $|c|b$ is an essential bound of $|cf|$.
3. This follows from the Minkowski inequality.
</details>
</MathBox>

### Hölder's inequality

<MathBox title='Conjugate indices' boxType='definition'>
Two indices $p,q\in(1,\infty)$ are called conjugate if $\frac{1}{p} + \frac{1}{q} = $. Note that

$$
  q = \frac{p}{p-1} = \frac{1}{1 - 1/p}
$$

so that $q\uparrow\infty$ as $p\downarrow 1$. Hence $1$ and $\infty$ are conjugate indices.
</MathBox>

<MathBox title="Young's inequality" boxType='theorem'>
If $x, y\in(0, \infty)$ and $p, q\in(1,\infty)$ are conjugate indices, then 

$$
  xy \leq \frac{1}{p}x^p + \frac{1}{q}y^q
$$

Equality occurs if and only if $x^p = y^p$

<details>
<summary>Proof</summary>

Fix $y\geq 0$ and define $f:(0,\infty)\to\R$ by

$$
\begin{align*}
  f(x) =& \frac{x^p}{p} + \frac{y^q}{q} - xy \quad x\geq 0 \\
  f'(x) =& x^{p-1} - y \\
  f''(x) =& (p-1)x^{p-2}
\end{align*}
$$

Solving for $f'(x) = 0$ shows that $f$ has a minimum at $x_0 = y^{1/(p-1)} = y^{q/p}$ as $f''(x_0) > 0$. Noticing that $q = \frac{p}{p-1}$, we get

$$
\begin{align*}
  f(x_0) =& \frac{y^{p/(p-1)}}{p} + \frac{y^q}{q} - y^{1/(p-1)}y \\
  =& y^q \left(\frac{1}{p} + \frac{1}{q}) - y^q \\
  =& y^q - y^q = 0
\end{align*}
$$

Since $x_0$ is a minima it follows that $xy\leq \frac{x^p}{p} + \frac{y^q}{p}$. 
</details>
</MathBox>

<MathBox title="Hölder's inequality" boxType='theorem'>
Suppose $f,g:X\to\R$ are measurable on $(X,\mathcal{A},\mu)$ and that $p$ and $q$ are conjugate indices. Then

$$
  \lVert fg\|_1 = \int_X |fg|\;\d\mu\leq\| f\rVert_p \cdot \lVert g\rVert_q
$$

If $(X,\mathcal{P}(X),\#)$ is a discrete measure, Hölder's inequality reduces to

$$
  \lVert xy\rVert_1 = \left(\sum_{i\in X} |x_i + y_i| \right) \leq \lVert x\rVert_p \cdot \lVert y\rVert_q
$$

<details>
<summary>Proof</summary>

The result follows trivially if $\| f\|_p = \infty$ or $\| g\|_\infty = \infty$, so assume $f\in L^p$ and $g\in L^q$. For the case $p = 1$ and $q = \infty$, note that $|g|\overset{\mu\textrm{-a.e.}{\leq}}\| g\|_\infty$, hence

$$
  \int_X |fg|\;\d\mu = \int_X |f|\cdot|g|\;\d\mu \leq\lVert g\|_\infty \int_X |f|\;\d\mu =\rVert f\lVert_1 \cdot\rVert g\|_\infty
$$

Consider the case where $p,q\in(1,\infty)$. By positive definiteness, the result holds if $\| f\|_p = 0$ or $\| g\|_q = 0$, so assume $\| f\|_p\geq 0$ and $\| g\|_q\geq 0$. By Young's inequality

$$
  |fg|\leq\frac{1}{p}|f|^p + \frac{1}{q}|g|^q
$$

Suppose first that $\lVert f\|_p =\rVert g\|_q = 1$. From the increasing monotonicity and linearity properties of the integral

$$
  \int_X |fg|\;\d\mu\leq \frac{1}{p}\int_X |f|^p \;\d\mu + \frac{1}{q}\int_X |g|^q \;\d\mu = \frac{1}{p} + \frac{1}{q} = 1
$$

For the general case where $\lVert f\|_p > 0$ and $\| g\|_q > 0$, let $f_1 = \frac{f}{\| f\|_p}$ and $g_1 = \frac{g}{\| g\|_q}$. Then $\| f_1\|_p =\rVert g_1\|_q = 1$ and $\| f_1g_1\|_q\leq 1$. By the scaling property of the norm

$$
  \| f_1g_1\|_1 = \frac{\| fg\|_1}{\| f\|_q\cdot\| g\|_q}\leq 1
$$
</details>
</MathBox>

### Minkowski's inequality

Minkowski's inequality produces the triangle inequality for the $p$-norm and establishes that $L^p$-spaces are normed vector spaces.

<MathBox title="Minkowski's inequality" boxType='theorem'>
Suppose $f,g:X\to\R$ are measurable on $(X,\mathcal{A},\mu)$ and that $p\in[1,\infty]$. Then

$$
  \lVert f + g\|_p = \left(\int_X |f + g|^p \;\d\mu\right)^{1/p} \leq\rVert f \lVert_p +\rVert g \|_p
$$

If $(X,\mathcal{P}(X),\#)$ is a discrete measure, Minkowski's inequality reduces to

$$
  \lVert x + y\rVert_p = \left(\sum_{i\in X} |x_i + y_i|^p\right)^{1/p} \leq \lVert x\rVert_p + \lVert y\rVert_p \quad
$$

<details>
<summary>Proof</summary>

The result is trivial if $\| f\|_p = \infty$ or $\| g\|_\infty = \infty$, so assume $f,g\in L^p$. When $p = 1$, the result is the triangle inequality

$$
\begin{align*}
  \lVert f + g\rVert_p =& \int_X |f + g|\;\d\mu \leq\int_X (|f| + |g|)\;\d\mu \\
  =& \int_X |f|\;\d\mu + \int_X |g|\;\d\mu = \lVert f\|_1 +\rVert g\|_1
\end{align*}
$$

For the case $p = \infty$, note that if $a,b\in[0,\infty]$ are an essential bounds for $f$ and $g$, respectively, then $a+b$ is an essential bound for $f + g$. Hence $\lVert f + g\Vert_\infty \leq\| f\|_\infty +\rVert g\|_\infty$.

Consider the case where $p\in(1,\infty)$ and let $q$ be the conjugate index to $p$. Then

$$
\begin{align*}
  |f+g|^p =& |f+g|^{p-1}\cdot|f+g| \leq |f+g|^{p-1}(|f|+|g|) \\
  =& |f+g|^{p-1}\cdot|f| + |f+g|^{p-1}\cdot|g|
\end{align*}
$$

Integrating over $X$ gives

$$
  \| f + g\|_p^p \leq \int_X |f+g|^{p-1}|f|\;\d\mu + \int_X |f+g|^{p-1}|g|\;\d\mu
$$

By Hölder's inequality

$$
\begin{align*}
  \int_X |f+g|^{p-1}|f|\;\d\mu &\leq \left\lVert |f+g|^{p-1} \right\|_q \cdot\rVert f\|_p \\
  \int_X |f+g|^{p-1}|g|\;\d\mu &\leq \left\lVert |f+g|^{p-1} \right\|_q \cdot\rVert g\|_p
\end{align*}
$$

Combining the inequalities gives

$$
  \lVert f + g\|_p^p \leq \left\| |f+g|^{p-1} \right\|_q (\| f\|_p +\rVert g\|_p)
$$

Since $\frac{1}{q} = \frac{p-1}{p}$ we get

$$
\begin{align*}
  \left\| |f+g|^{p-1} \right\|_q =& \left(\int_X |f+g|^{p-1}q \;\d\mu \right)^{1/q} \\
  =& \left(\int_X |f+g|^p \;\d\mu \right)^{(p-1)/p} = \lVert f+g\rVert_p^{p-1}
\end{align*}
$$

Hence we get

$$
\begin{gather*}
  \lVert f+g\rVert_p^p = \lVert f+g\rVert_p^{p-1}\left(\lVert f\|_p +\rVert g\|_p \right) \\
  \iff \lVert f + g\|_p \leq\rVert f \lVert_p +\rVert g \|_p
\end{gather*}
$$

**Discrete case:**
For $p = 1$, the ordinary triangle inequality applies

$$
  \lVert x + y\rVert_1 = \sum_{j=1}^\infty \left| x_j + y_j \right| \leq \sum_{j=1}^\infty \left| x_j \right| + \left| y_j \right| = \lVert x\rVert_1 + \lVert y\rVert_1
$$

For $p \in (1, \infty)$, we note $q = \frac{p}{p-1}$

$$
\begin{align*}
  \lVert x + y\rVert_p^p =& \sum_{j=1}^\infty \left| x_j + y_j \right|^p = \lim_{n\to\infty} \sum_{j=1}^n \left| x_j + y_j \right|^p \\
  \leq& \lim_{n\to\infty} \sum_{j=1}^n \left(\left| x_j \right| + \left| y_j \right| \right)^p
\end{align*}
$$

The summand can be written as

$$
\begin{align*}
  \left(\left| x_j \right| + \left| y_j \right| \right)^p =& \left(\left| x_j \right| + \left| y_j \right| \right) \left(\left| x_j \right| + \left| y_j \right| \right)^{p-1} \\
  =& \left| x_j \right| \left(\left| x_j \right| + \left| y_j \right| \right)^{p - 1} = \left| y_j \right| \left(\left| x_j \right| + \left| y_j \right| \right)^{p-1} \\
  \equiv& a_j b_j + c_j b_j
\end{align*}
$$

Applying Hölder's inequality $\lVert a b\rVert_1 + \lVert c b\rVert_1 \leq \lVert a\rVert_p \cdot \lVert b\rVert_{q} + \lVert c\rVert_p \cdot \lVert b\rVert_{q}$ with

$$
  \lVert b\rVert_{q} = \left( \sum_{j=1}^n \left| \left( \left| x_j \right| + \left| y_j \right| \right)^{p-1} \right|^{q} \right)^{\frac{1}{q}} = \left( \sum_{j=1}^n\left( \left| x_j \right| + \left| y_j \right| \right)^p \right)^{\frac{1}{q}}
$$

We get

$$
\begin{align*}
  \sum_{j=1}^n \left(\left| x_j \right| + \left| y_j \right| \right)^p \leq& \lVert a\rVert_p \cdot \lVert b\rVert_{q} + \lVert c\rVert_p \cdot \lVert b\rVert_{q} \\
  =& \left( \lVert a\rVert_p + \lVert c\rVert_p \right) \left( \sum_{j=1}^n \left( \left| x_j \right| + \left| y_j \right| \right)^p \right)^{\frac{1}{q}} \\
  \implies \left( \sum_{j=1}^n \left( \left| x_j \right| + \left| y_j \right| \right)^p \right)^{1 - \frac{1}{q}} =& \left( \sum_{j=1}^n \left( \left| x_j \right| + \left| y_j \right| \right)^p \right)^{\frac{1}{p}} \\
  \leq& \lVert a\rVert_p + \lVert c\rVert_p = \left( \sum_{j=1}^n \left| x_j \right|^p \right)^{\frac{1}{p}} + \left( \sum_{j=1}^n \left| y_j \right|^p \right)^{\frac{1}{p}}
\end{align*}
$$

In the limit $n \to \infty$ we retrieve the Minkowski inequality.
</details>
</MathBox>

### Sequence space ($\ell^p$)

Discrete measure spaces $(X,\mathcal{P}(X),\#)$ gives a special case for $L^p$ called sequence spaces. For a measurable function $x:X\to\R$ we introduce the notation $x_i = x(i)$.

<MathBox title='Sequence space' boxType='definition'>
Let $(X,\mathcal{P}(X),\#)$ be a discrete measure space and let $x:X\to\R$ be measurable. For $p \in [1, \infty)$, we define the $p$-norm

$$
  \lVert x\rVert_p := \left( \sum_{i\in X} |x_i|^p \right)^(1/p)
$$

and for $p=\infty$ we define $\| x\|_\infty = \sup\Set{x_i | i\in X}$. The Lebesgue space takes the form

$$
  L^p(X,\mathcal{P}(X),\#) = \Set{ (x_i)_{i\in X} \in\R^n : \lVert p\rVert_p < \infty}
$$

When $X = \N$ the $L^p$ space is usually denoted $\ell^p$.
</MathBox>

<MathBox title='Sequence spaces are Banach spaces' boxType='definition'>
The normed space $\left( \ell^p, \lVert \cdot\rVert_p \right)$ is a Banach space.

<details>
<summary>Proof</summary> 

To show the completeness of $\left( \ell^p, \lVert \cdot\rVert_p \right)$ we consider a Cauchy sequence $\left( x^{(k)} \right)_{k \in \N}$ in $\ell^p$. 

$$
\begin{align*}
  x^{(1)} =& \left( x_1^{(1)}, x_2^{(1)}, \dots \right) \\
  x^{(2)} =& \left( x_1^{(2)}, x_2^{(2)}, \dots \right) \\
  \vdots
\end{align*}
$$

The elementwise difference between two points is

$$
  \left\lvert x_m^{(k)} - x_m^{(l)} \right\rvert^p \leq \sum_{n=1}^\infty \left\lvert x_n^{(k)} - x_n^{(l)} \right\rvert^p = \lVert x^{k} - x^{l}\rVert_p^p
$$

Because $\left( x^{(k)} \right)_{k \in \N}$ is a Cauchy sequence, it follows that $\forall \epsilon > 0 \; \exists N \in \N:\; \left\| x^{(k)} - x^{(l)} \right\|^p$. Hence, $\left( x_m^{(k)} \right)_{k \in \N}$ is a Cauchy sequence in $\mathbb{F}$ converging to a limit $\tilde{x}_m \in \mathbb{F}$. This suggests that $\left( x^{(k)} \right)_{k \in \N}$ converges to a limit $\tilde{x} := \left( \tilde{x}_i \right)_{i \in \N}$, which we will now show.

Let $\epsilon > 0$ and choose $K \in \N$ such that $\forall k, l \geq K:\; \left\| x^{(k)} - x^{(l)} \right\|_p < \epsilon'$

$$
\begin{align*}
  \left\| x^{(k)} - \tilde{x} \right\|_p^p =& \sum_{n=1}^\infty \left\lvert x^{(k)} - \tilde{x} \right\rvert^p = \lim_{N \to \infty} \sum_{n=1}^N \left\lvert x^{(k)} - \tilde{x} \right\rvert^p \\
  =& \lim_{N \to \infty} \lim_{l\to\infty} \sum_{n=1}^N \left\lvert x^{(k)} - x^{(l)} \right\rvert^p \leq (\epsilon')^p
\end{align*}
$$

Thus $\forall k \geq K: \left\| x^{(k)} - \tilde{x} \right\|_p \leq \epsilon' < \epsilon$, since $\epsilon'$ can be choosen arbitrarily small. Furthermore, it follows that $\tilde{x} = \left(\tilde{x} - x^{(k)} \right) + x^{(k)} \in \ell^p$ since both $\tilde{x} - x^{(k)}$ and $x^{(k)}$ are in $\ell^p$ and $\ell^p$ is a vector space and thus closed under addition.
</details>
</MathBox>

<MathBox title='Isomorphism of $\ell^p$-dual space' boxType='proposition'>
The dual space of $\ell^p (\N)$ has a natural isomorphism with $\ell^q (\N)$ where $q$ is the Hölder conjugate satisfying $\frac{1}{p} + \frac{1}{q} = 1$. This isomorphism associates $x \in \ell^q$ with the functional $T: \ell^q(\N) \to \ell^p (\N)^*$ given by

$$
\begin{gather*}
  (Tx)(y) := \sum_{j=1}^\infty x_j y_j \quad \forall y \in \ell^p (\N) \\
  x \mapsto \braket{\bar{x}, \cdot}_{\ell^2 (\N)}
\end{gather*}
$$

<details>
<summary>Proof</summary>

Since the inner product by definition is linear in its second argument, it follows that $T$ is linear. By Hölder's inequality we have

$$
  \lvert (Tx)(y) \rvert \leq \lim_{n\to\infty} \sum_{j=1}^n \left| y_j x_j \right| \leq \lVert y\rVert_p \cdot \lVert x\rVert_q < \infty
$$

which shows that $Tx$ is bounded for all $x \in \ell^q(\N)$, hence it is well-defined. The operator norm for $T$ is

$$
\begin{gather*}
  \lVert Tx\rVert_{\ell^p (\N) \to \mathbb{F}} = \sup\Set{ \left| (Tx)(y) \right| | \lVert y\rVert_p = 1} \leq \sup\Set{\lVert y\rVert_p \cdot \lVert x\rVert_q | \lVert y\rVert_p = 1} \leq \lVert x\rVert_q \\
  \implies \lVert T\rVert = \frac{\lVert Tx\rVert_{\ell^p (\N)}}{\lVert x\rVert_q} \leq 1
\end{gather*}
$$

Let $y' \in \ell^p (\N)^*$ and define $x_j := y'(e_j)$ and $x := \left( x_j \right)_{j \in \N}$ with $e_j = \left(\delta_{jk}\right)_{k\in\N}$ (unit sequence). To prove that $T$ is surjective, we need to show that $x \in \ell^q (\N)$ and $Tx = y'$.

$$
\begin{align*}
  \sum_{j=1}^n \left| x_j \right|^{q} =& \sum_{j=1}^n x_j t_j \quad\quad t_j = \begin{cases} \frac{\left| x_j \right|^q}{x_j}, & x_j \neq 0 \\ 0, & x = 0 \end{cases} \\
  =& \sum_{j=1}^n t_j y'(e_j) = y'\sum_{j=1}^n t_j e_j \\
  \leq& \lVert y'\rVert_{\ell^p (\N) \to \mathbb{F}} \lVert \sum_{j=1}^n t_j e_j\rVert_p = \lVert y'\rVert_{\ell^p (\N) \to \mathbb{F}} \left( \sum_{j=1}^n \left| t_j \right|^p \right)^{1/p}
\end{align*}
$$

since

$$
  \left| t_j \right|^p = \left(\frac{\left| x_j \right|^q}{\left| x_j \right|}\right)^p = \left| x_j \right|^{(q - 1)p} = \left| x_j \right|^q
$$

we get

$$
\begin{gather*}
  \sum_{j=1}^n \left| x_j \right|^{q} \leq \lVert y'\rVert_{\ell^p (\N) \to \mathbb{F}} \left( \sum_{j=1}^n \left| x_j \right|^q \right)^{1/p} \\
  \implies \left( \sum_{j=1}^n \left| x_j \right|^{q} \right)^{1 - 1/p} = \left( \sum_{j=1}^n \left| x_j \right|^{q} \right)^{1/q} \leq \lVert y'\rVert_{\ell^p (\N) \to \mathbb{F}} \\
  \xRightarrow{n\to\infty} \lVert x\rVert_q \leq \lVert y'\rVert_{\ell^p (\N) \to \mathbb{F}} \implies x \in \ell^q (\N)
\end{gather*}
$$

For $y \in \ell^p (\N)$ we have

$$
\begin{gather*}
\begin{aligned}
  (Tx - y')(y) =& (Tx - y')\left(\lim_{n\to\infty} \sum_{j=1}^n y_j e_j \right) \\
  =& \lim_{n\to\infty} (Tx - y') \left(\sum_{j=1}^n y_j e_j \right) \\
  =& \lim_{n\to\infty} \sum_{j=1}^n y_j (Tx - y')(e_j) = 0
\end{aligned} \\
  \implies Tx = y'
\end{gather*}
$$

To prove that $T$ is injective and thus bijective, it suffices to show that $T$ is isometric. We already know that 

$$
  \lVert Tx\rVert_{\ell^p (\N) \to \mathbb{F})} \leq \lVert x\rVert_q \leq \lVert y\rVert_{\ell^p (\N) \to \mathbb{F})}
$$

At the same time $\lVert Tx\rVert_{\ell^p (\N) \to \mathbb{F})} = \lVert y\rVert_{\ell^p (\N) \to \mathbb{F})}$, so that $\lVert Tx\rVert_{\ell^p (\N) \to \mathbb{F})} = \lVert x\rVert_q$ which shows that $T$ is ismotric.
</details>
</MathBox>

# Inner product space

<MathBox title='Inner product space' boxType='definition'>
Let $\mathbb{F} \in \Set{\R, \mathbb{C}}$ be a field of numbers and let $X$ be a $\mathbb{F}$-vector space. A map $\braket{\cdot, \cdot} : X \times X \to \mathbb{F}$ is called an inner product if it satisfies

1. Positive definite $\braket{x, x} \geq 0 \quad \forall x \in X$ and $\braket{x, x} = 0 \iff x = 0$
2. Conjugate symmetry
    - $\braket{x, y} = \braket{y, x}$ for $\mathbb{F} = \R$
    - $\braket{x, y} = \overline{\braket{y, x}}$ for $\mathbb{F} = \mathbb{C}$
3. Linearity in the 2nd argument:
    - $\braket{x, y_1 + y_2} = \braket{x, y_1} + \braket{x, y_2}$
    - $\braket{x, \lambda y} = \lambda \braket{x, y}, \quad \lambda \in \mathbb{F}$
4. Conjugate linearity in the 1st argument
    - $\braket{\lambda x, y} = \bar{\lambda} \braket{x, y}, \quad \lambda \in \mathbb{F}$
    
If $\braket{\cdot, \cdot}$ is an inner product, then $\lVert x\rVert_{\braket{\cdot, \cdot}} = \sqrt{\braket{x, x}}$ defines a norm. 
</MathBox>

The inner product $\braket{\cdot, \cdot}$ is a continuous map. Considering the sequence $\left( x_n \right)_{n\in\N}$ with limit $\tilde{x} \in X$ and a fixed $x_0 \in X$, then by the Cauchy-Schwartz inequality

$$
\begin{align*}
  \lvert \braket{x_0, x_n} - \braket{x_0, \tilde{x}} \rvert =& \lvert \braket{x_0, x_n - \tilde{x}}\rvert \\
  \leq& \lVert x_0\rVert \cdot \lVert x_n - \tilde{x}\rVert \xrightarrow{n\to\infty} 0 \\
  \implies f(x_n) \xrightarrow{n\to\infty} f(\tilde{x})
\end{align*}
$$

<MathBox title='Polarization identity' boxType='proposition'>
Let $\left(X, \braket{\cdot, \cdot} \right)$ be an inner product space over $\mathbb{F} = \mathbb{C}$ with induced norm $\lVert x \rVert := \sqrt{\braket{x,x}}$. Then, for all $x,y\in X$

$$
  \braket{x,y} = \frac{1}{4}\left(\lVert x + y\rVert^2 - \lVert x - y\rVert^2 - i\lVert x + iy\rVert^2 + i\lVert x - iy\rVert^2 \right)
$$

If $\mathbb{F} = \R$, this reduces to

$$
  \braket{x,y} = \frac{1}{4}\left(\lVert x + y\rVert^2 - \lVert x - y\rVert^2\right)
$$

<details>
<summary>Proof</summary>

By linearity of the inner product, we have

$$
\begin{align*}
  \lVert x + y\rVert^2 =& \braket{x + y, x + y} = \braket{x,x} + \braket{x,y} + \braket{x,y} + \braket{y,y} \\
  -\lVert x - y\rVert^2 =& \braket{x + y, x + y} = -\braket{x,x} + \braket{x,y} + \braket{x,y} - \braket{y,y} \\
  -i\lVert x + y\rVert^2 =& -i\braket{x + y, x + y} = -i\braket{x,x} + \underbrace{-i\overline{i}}_{=-1}\braket{x,y} + \underbrace{-i^2}_{=1}\braket{x,y} - i\braket{y,y} \\
  i\lVert x + y\rVert^2 =& i\braket{x + y, x + y} = i\braket{x,x} + \underbrace{-i\overline{i}}_{=-1}\braket{x,y} + \underbrace{-i^2}_{=1}\braket{x,y} + i\braket{y,y}
\end{align*}
$$

Summing up the terms, we obtain

$$
  \lVert x + y\rVert^2 - \lVert x - y\rVert^2 -i\lVert x + y\rVert^2 + i\lVert x + y\rVert^2 = 4\braket{x,y}
$$

giving the desired result.
</details>
</MathBox>

## Hilbert space

<MathBox title='Hilbert space' boxType='definition'>
If $\left(X, \lVert \cdot\rVert_{\braket{\cdot, \cdot}} \right)$ defines a Banach space, then $\left(X, \braket{\cdot, \cdot}\right)$ is called a Hilbert space.
</MathBox>

## $\ell^2$-space

The set of square summable sequences $\ell^2 (\N, \mathbb{F})$ endowed with the inner product  

$$
  \braket{x, y} = \sum_{i=1}^\infty \bar{x}_i y_i
$$

is a Hilbert space because $\ell^p$ is a Banach space. The map $\braket{\cdot, \cdot}: \ell^2 \times \ell^2 \to \mathbb{F}$ is indeed an inner product because it satisfies

1. Positivity: 
$$
\begin{gather*}
  \braket{x, x} = \sum_{i=1}^\infty \bar{x}_i x_i = \sum_{i=1}^\infty \lvert x_i \rvert^2 \geq 0 \\
  \braket{x, x} = 0 \implies \lvert x_i \rvert^2 = 0\; \forall i \in \N \implies x = 0
\end{gather*}
$$
2. Conjugate symmetry:
$$
  \overline{\braket{y, x}} = \sum_{i=1}^\infty \overline{\bar{y}_i x_i} = \sum_{i=1}^\infty y_i \bar{x}_i = \braket{x, y}
$$
3. Linearity in the 2nd argument: 
$$
\begin{align*}
  \braket{x, \alpha y + \beta z} =& \sum_{i=1}^\infty \bar{x}_i \left(\alpha y_i + \beta z_i \right) \\
  =& \alpha \sum_{i=1}^\infty \bar{x}_i y_i + \beta \sum_{i=1}^\infty \bar{x}_i z_i \\
  =& \alpha \braket{x, y} + \beta \braket{x, z}
\end{align*}
$$

## Cauchy-Schwarz inequality

<MathBox title='Cauchy-Scharz inequality' boxType='theorem'>
Let $\left(X, \braket{\cdot, \cdot} \right)$ be an inner product space with norm $\lVert x\rVert = \sqrt{\braket{x, x}}$. Then for all $x, y \in X$

$$
  \lvert \braket{x, y} \rvert \leq \lVert x\rVert \cdot \lVert y\rVert
$$

where the equality holds if and only if $x$ and $y$ are linearly dependent, ie. $y = \lambda x$. The triangle inequality follows from the Cauchy-Schwarz inequality

$$
\begin{align*}
  \lVert x + y\rVert^2 =& \braket{x + y, x + y} = \lVert x\rVert^2 + 2\lvert \braket{x, y} \rvert + \lVert y\rVert^2 \\
  \leq& \lVert x\rVert^2 + 2\lVert x\rVert \cdot \lVert y\rVert + \lVert y\rVert^2 = \left( \lVert x\rVert + \lVert y\rVert \right)^2
\end{align*}
$$

Taking the square root we obtain the triangle inequality $\lVert x + y\rVert \leq \lVert x\rVert + \lVert y\rVert$.

<details>
<summary>Proof</summary> 

Considering the non-trivial case $x \neq 0$, we define the unit vector $\hat{x} := \frac{x}{\lVert x\rVert}$ and take the orthogonal projection of $y$ onto $\hat{x}$ (parallel component) given by $y_\parallel = \braket{\hat{x}, y} \hat{x}$. The Cauchy-Schwarz inequality can be obtained from taking the norm of the orthogonal component $y_\perp = y - y_\parallel$

$$
\begin{align*}
  0 \leq \lVert y_\perp\rVert^2 =& \lVert y - y_\parallel\rVert^2 = \braket{y - \braket{\hat{x}, y} \hat{x}, y - \braket{\hat{x}, y} \hat{x}} \\
  =& \braket{y - \braket{\hat{x}, y} \hat{x}, y} - \braket{y - \braket{\hat{x}, y} \hat{x}, \braket{\hat{x}, y} \hat{x}} \\
  =& \braket{y, y} - \braket{\braket{\hat{x}, y} \hat{x}, y} - \braket{y, \braket{\hat{x}, y} \hat{x}} + \braket{\braket{\hat{x}, y} \hat{x}, \braket{\hat{x}, y} \hat{x}} \\
  =& \lVert y\rVert^2 - \overline{\braket{\hat{x}, y}}\braket{\hat{x}, y} - \braket{\hat{x}, y} \overline{\braket{\hat{x}, y}}  + \lvert \braket{\hat{x}, y} \rvert^2 \underbrace{\lVert \hat{x}\rVert^2}_{=1} \\
  =& \lVert y\rVert^2 - \lvert \braket{\hat{x}, y} \rvert^2
\end{align*}
$$

rearranging the inequality we get

$$
\begin{gather*}
  \lVert y\rVert^2 \geq \lvert \braket{\hat{x}, y} \rvert^2 = \left\lvert \Braket{\frac{x}{\lVert x\rVert}, y} \right\rvert^2 = \frac{1}{\lVert x\rVert^2} \lvert \braket{x, y} \rvert^2 \\
  \implies \lvert \braket{x, y} \rvert \leq \lVert x\rVert \cdot \lVert y\rVert
\end{gather*}
$$
</details>
</MathBox>

## Orthogonality

<MathBox title='Orthogonality' boxType='definition'>
Let $\left(X, \braket{\cdot, \cdot} \right)$ be an inner product space. Two vectors $x, y \in X$ are orthogonal if $\braket{ x, y } = 0$, denoted $x \perp y$. Two sets $U, V \in X$ are orthogonal, denoted $U \perp V$, if $u \perp v$ for all $u \in U$ and $v \in V$. The orthogonal component of a set $U \subseteq X$ is

$$
  U^\perp = \Set{ x \in X | \braket{x, u} = 0 \; \forall u\in U}
$$
</MathBox>

If $x \perp y$, then the triangle inequality reduces to the Pytagorean theorem

$$
\begin{align*}
  \lVert x + y\rVert^2 =& \braket{x + y, x + y} \\
  =& \lVert x\rVert^2 + 2\lvert \braket{x, y} \rvert + \lVert y\rVert^2 \\
  =& \lVert x\rVert^2 + \lVert y\rVert^2
\end{align*}
$$

<MathBox title='Orthogonal components' boxType='proposition'>
Let $(X, \braket{\cdot,\cdot})$ be an inner product space and let $U^\perp$ be the orthogonal component of $U\subseteq X$. Then $U^\perp$ is closed. 

<details>
<summary>Proof</summary>

This is proved by considering a sequence $\left( x_n \right)_{n\in\N} \subseteq U^\perp$ showing that the limit $\tilde{x} \in X$ is also in $U^\perp$. It follows that for all $u \in U$

$$
  \braket{x_n, u} = 0 \implies \lim_{n\to\infty} \braket{x_n, u} = 0 \implies \braket{\tilde{x}, u} = 0 \implies \tilde{x}\in U^\perp
$$

Hence, $U^\perp$ is closed. Here we applied the continuity property of the inner product resulting in $\braket{x_n, 0} \xrightarrow{n\to\infty} \braket{\tilde{x}, u}$.

If $U \subseteq V$ then $U^\perp \supseteq V^\perp$. For $x \in V^\perp$ we have $\braket{x, v} = 0$ for all $v \in V$. Because $U \subseteq V$, we have $\braket{x, u} = 0$ for all $u \in U$. This implies that $x \in U^\perp$, hence $U^\perp \supseteq V^\perp$. 
</details>
</MathBox>

## Riesz representation theorem

<MathBox title='Riesz representation theorem' boxType='theorem'>
For each continuous linear functional $\ell: X \to \mathbb{F}$ there is exactly one $x_\ell \in X$ such that $\ell(x) = \braket{x_\ell, x}$ for all $x \in X$ and $\lVert \ell\rVert = \lVert x_\ell\rVert_X$.

<details>
<summary>Proof</summary>

To prove the existence of $x_\ell$ we consider the kernel of $\ell$ defined as $\ker(\ell) := \Set{ x \in X | \ell(x) = 0}$. In the trivial case $\ker (\ell) = X$ it follows that $x_\ell = 0$, so we assume $\ker(\ell) \neq X$. Evidently $\ell$ is continuous because $\ker(\ell) = \ell^{-1}(\Set{ 0})$. Thus $\ker(\ell)$ is a closed subset of $X$. Consider $\hat{x} \in \ker(\ell)^\perp$ with $\lVert \hat{x}\rVert_X = 1$ and set $x_\ell := \overline{\ell(\hat{x})}\hat{x}$, then

$$
\begin{align*}
  \ell(x) =& \ell\left(x - \frac{\ell(x)}{\ell(\hat{x})}\hat{x} + \frac{\ell(x)}{\ell(\hat{x})}\hat{x} \right) = \ell\left(x - \frac{\ell(x)}{\ell(\hat{x})}\hat{x} \right) + \ell\left( \frac{\ell(x)}{\ell(\hat{x})}\hat{x} \right) \\
  =& \ell(x) - \frac{\ell(x)}{\ell(\hat{x})} \ell(\hat{x}) + \ell(\lambda \hat{x}) \\
  =& \lambda \ell(\hat{x}) \braket{\hat{x}, \hat{x} } = \lambda \braket{\overline{\ell(\hat{x})}\hat{x}, \hat{x} } = \braket{x_\ell, \lambda\hat{x} - x + x} \\
  =& \braket{x_\ell, \lambda \hat{x} - x } + \braket{x_\ell, x } \\
  =& \braket{x_\ell, x }
\end{align*}
$$

To prove the uniqueness of $x_\ell$, we assume $x_\ell, \tilde{x} \in X$ fulfil 

$$
\begin{align*}
  \ell(x) = \braket{x_\ell, x } = \braket{\tilde{x}_\ell, x } \\
  \implies \braket{x_\ell - \tilde{x}_\ell, x } = 0, \; \forall x \in X \\
  \implies \braket{x_\ell - \tilde{x}_\ell, x_\ell - \tilde{x}_\ell } = 0
\end{align*}
$$

Because the inner product is positive definite we conclude that $x_\ell = \tilde{x}_\ell$.

To prove that the operator norm is $\lVert \ell\rVert = \lVert x_\ell\rVert$, we have

$$
  \lVert \ell \rVert = \sup\Set{ \lvert \ell(x) \rvert : \lVert x \rVert_X = 1} = \sup\Set{ \underbrace{\lvert \braket{x_\ell, x} \rvert}_{\leq \lVert x_\ell \rVert_X \cdot \lVert x \rVert_X} : \lVert x \rVert_X \leq 1} \leq \lVert x_\ell \rVert
$$

Similarly

$$
  \lVert \ell\rVert \geq \left\lvert \ell \left( \frac{x_\ell}{\lVert x_\ell\rVert} \right) \right\rvert = \left\lvert \Braket{x_\ell, \frac{x_\ell}{\lVert x_\ell\rVert} } \right\rvert = \lVert x_\ell\rVert
$$

Hence, we conclude that $\lVert \ell\rVert = \lVert x_\ell\rVert$.
</details>
</MathBox>

## Strong and weak convergence

<MathBox title='Strong and weak operator topology' boxType='definition'>
Let $H$ and $K$ be Hilbert spaces.
1. For each $x\in H$, consider the seminorm $p_x$ defined on $\mathcal{L}(H, K)$ by $p_x (T) = \lVert Tx\rVert$. The topology on $\mathcal{L}(H,K)$ defined by the collection $\Set{p_x | x\in H}$ of seminorms is called the *strong operator topology*.
2. For each $x\in H$ and $y\in K$, consider the seminorm $p_{x,y}$ defined on $\mathcal{L}(H,K)$ by $p_{x,y} (T) = |\braket{Tx, y}|$. The topology on $\mathcal{L}(H,K)$ defined by the collection $\Set{p_{x,y} | x\in H,\; y\in K}$ of seminorms is called the *weak operator topology*.
</MathBox>

Suppose $H$ and $K$ are Hilbert spaces. If $\Set{T_i}_{i\in I}$ for an index set $I\subseteq\N$ is a net in $\mathcal{L}(H,K)$, then the net converges to $T\in\mathcal{L}(H,K)$ with respect to the strong operator topology precisely when $\lVert T_i x - Tx \rVert \xrightarrow{i\to\infty} 0$ for all $x\in H$, i.e. precisely when the net $\Set{T_i x}_{i\in I}$ converges to $Tx$ with respect to the strong norm topology on $K$, for every $x\in H$.

Likewise, the net $\Set{T_i}_{i\in I}$ converges to $T$ with respect to the weak operator topology if and only if $\braket{(T_i - T)x, y} \xrightarrow{i\to\infty} 0$ for all $x\in H$ and $y\in K$, i.e. if and only if the net $\Set{T_i x}$ converges to $Tx$ with respect to the weak norm topology on $K$, for every $x\in H$.

<MathBox title='' boxType='lemma' tag='lemma-0'>
Suppose $\Set{T_i}_{i\in I}$ for an index set $I\subseteq\N$ is a net in $\mathcal{L}(H,K)$ which is uniformly bounded, i.e. $\sup\Set{\lVert T_i \rVert}_{i\in I} = K < \infty$. Let $S_1$ and $S_2$ be total sets in $H$ and $K$, respectively, i.e. the set of finite linear combinations of elements in $S_1$ and $S_2$ that are in dense in $H$ and $K$, respectively
1. $\Set{T_i}_{i\in I}$ converges strongly to $0$ if and only if $\lim_{i\to\infty} \lVert T_i x\rVert = 0$ for all $x\in S_1$
2. $\Set{T_i}_{i\in I}$ converges weakly to $0$ if and only if $\lim_{i\to\infty} \braket{T_i, y} = 0$ for all $x\in S_1$ and $y\in S_2$.

<details>
<summary>Proof</summary>

The two assertions are proved analogously.

**(b):** Let $x\in H$ and $y\in K$ be arbitrary, and suppose $\epsilon > 0$ is given. We assume, without loss of generality, that $\epsilon < 1$. Let $M = 1 + \max\Set{\lVert x\rVert, \lVert x\rVert}$, and $K = 1 + \sup_{i\in I} \lVert T_i \rVert$.

The assumed totality of the sets $S_i$ for $i=1,2$ implies the existence of vectors $x' = \sum_{k=1}^m \alpha_k x_k$ and $y' = \sum_{j=1}^n \beta_j y_j$, with the property that $x_k \in S_1$, $y_j \in S_2$ for all $k,j$ and such that $\lVert x - x' \rVert < \epsilon/(3KM)$ and $\lVert y - y'\rVert < \epsilon/(3KM)$. Since $\epsilon 1 \leq K,M$, it follows that $\lVert x' \rVert \leq\lVert x\rVert + 1 \leq M$. Similarly, also $\lVert y' \rVert \leq M$. 

Let 

$$
  N = 1 + \max\Set{|\alpha_k|, |\beta|_k | 1\leq k \leq m, 1\leq j \leq n}
$$

Since $I$ is a directed set, the assumption that $\lim_{i\to\infty} \braket{T_i x_k, y_j } = 0$ for all $j,k$ implies that we can find an index $i_0 \in I$ with the property that $|\braket{T_i x_k, y_j}| < \epsilon/(3N^2 mn)$ whenever $i \geq i_0$, $1 \leq k\leq m$ and $1\leq j \leq n$. It then follows that for all $i \geq i_0$, we have

$$
\begin{align*}
  |\braket{T_i x, y}| \leq& |\braket{T_i x, y - y'}| + |\braket{T_i (x - x'), y'}| + |\braket{T_i x', y'}| \\
  \leq& 2KM \frac{\epsilon}{3KM} + \sum_{k=1}^m \sum_{j=1}^n |\alpha_k \beta_j|\cdot|\braket{T_i x_k, y_j}| \\
  \leq& \frac{2\epsilon}{3} + N^2 mn \frac{\epsilon}{3N^2 mn} \\
  = \epsilon
\end{align*}
$$
</details>
</MathBox>


# Normed algebra

<MathBox title='Normed algebra' boxType='definition'>
A *normed algebra* is a normed space $A$ equipped with a multiplication $\times: A\times A$ as $(x,y)\mapsto xy$, which satisfies for $x,y,z\in A$ and $\alpha\in\mathbb{F}$
1. **Asssociativity:** $(xy)z = x(yz)$
2. **Distributivity:** 
    - $(\alpha x + y)z = \alpha xz + yz$
    - $z(\alpha x + y) = \alpha zx + zy$
3. **Sub-multiplicativity of norm**: $\lVert xy\rVert\leq\lVert x\rVert\cdot\lVert y \rVert$

A normed space is *unital* if it has a multiplicative identity, i.e. if there exists an element $1\in A$ such that $1x = x1 = x$ for all $x\in A$.
</MathBox>

<MathBox title='Banach algebra' boxType='definition'>
A *Banach algebra* is a normed algebra which is complete as a normed space. 

<details>
<summary>Details</summary>

Suppse $A_0$ is a normed algebra, and $A$ denotes its completion as a Banach space. Then $A$ acquires a natural Banach algebra structure as follows: if $x,y\inA$, pick sequences $(x_n)$ and $(y_n)$ in $A_0$ such that $x_n \xrightarrow{n\to\infty} x$ and $y_n \xrightarrow{n\to\infty} y$. Then, pick a constant $K$ such that $\lVert x_n \rVert, \lVert y_n \rVert \leq n$, note that

$$
\begin{align*}
  \lVert x_n y_n - x_m y_m \rVert =& \lVert x_n (y_n - y_m) + (x_n - x_m)y_m \rVert \\
  \leq& \lVert x_n (y_n - y_m) \rVert + \lVert (x_n - x_m)y_m \rVert \\
  \leq& \lVert x_n \rVert \cdot \lVert y_n - y_m \rVert + \lVert x_n - x_m \rVert \cdot \lVert y_m \rVert \\
  \leq& (\lVert y_n - y_m \rVert + \lVert x_n - x_m \rVert)
\end{align*}
$$

and conclude that $(x_n y_n)$ is a Cauchy sequence and hence convergent, define $xy = \lim_{n\to\infty} x_n y_n$. To see that the product we have proposed is unambigously defined defined, we must verify that the above limit is independent of the choice of the approximating sequences, and depends only on $x$ and $y$. To see this, suppose $x_{i,n} \xrightarrow{n\to\infty} x$ and $y_{n,1} \xrightarrow{n\to\infty} y$ for $i=1,2$. Define 

$$
  x_{2n-1} =& x_{1,n} \\
  x_{2n} =& x_{2,n} \\
  y_{2n-1} =& y_{1,n} \\
  y_{2n} =& y_{2,n}
$$

and the apply the preceding reasoning to conclude that $(x_n, y_n)$ is a convergent sequence with some limit $z$; then also $(x_{1,n} y_{1,n} = x_{2n-1} y_{2n-1})$ converges to $z$, since a subsequence of a convergent sequence converges to the same limit. Similarly, $(x_{2,n} y_{2,n} = x_{2n} y_{2n})$ converges to $z$.

Thus, we have unambiguously defined the product of any two elements of $A$.
</details>
</MathBox>

<MathBox title='Group of units' boxType='definition'>
Suppose $A$ is a normed algebra. An element $x\in A$ is *invertible* if there is a unique element $x^{-1} \in A$ such that $xx^{-1} = x^{-1}x = 1$. The collection of all invertible elements of $A$ is denoted $G(A)$ and is called the *group of units* in $A$
</MathBox>

<MathBox title='Group of units properties' boxType='proposition' tag='proposition-21'>
Let $A$ be a normed algebra with group of units $G(A)$
1. If $x\in G(A)$ and if $L_x$ is a map given by left-multiplication of $x$, i.e. $L_x(y) = xy$ for $y\in A$, then $L_x \in \mathcal{L}(A)$ is a linear invertible operator on $A$ with $(L_x)^{-1} = L_{x^{-1}}$.
2. If $x\in G(A)$ and $y\in A$, then $xy \in G(A) \implies yx \in G(A) \implies y\in G(A)$
3. If $\Set{x_i}_{i=1}^n \subset A$ is a set of pairwise commuting elements, i.e. $x_i x_j = x_j x_i$ for all $i,j =1,\dots,n$, then the product $\prod_{i=1}^n x_i$ is invertible if and only if each $x_i$ is invertible.
4. If $x\in A$ and $\lVert 1 - x\rVert < 1$, then $x\in G(A)$ and
$$
\begin{equation}
  x^{-1} = \sum_{n=0}^\infty (1 - x)^n \tag{\label{equation-1}}
\end{equation}
$$
In particular, if $\lambda\in\mathbb{C}$ and $|\lambda| > \lVert x \rVert$, then $(x - \lambda)$ is invertible and
$$
\begin{equation}
  (x - \lambda)^{-1} = -\sum_{n=0}^\infty \frac{x^n}{\lambda^{n+1}}  \tag{\label{equation-2}}
\end{equation}
$$
5. $G(A)$ is an open set in $A$ and the mapping $x\mapsto x^{-1}$ is a homeomorphism of $G(A)$ onto itself.

<details>
<summary>Proof</summary>

**(1):** This follows trivially.

**(2):** If $y$ is invertible, so is $yx$, respectively $yx$. Conversely, if $xy$ is invertible, respectively $yx$, so is $y = x^{-1}(xy)$, respectively $y = (yx)x^{-1}$.

**(3):** One implication follows from the fact that $G(A)$ is closed under multiplication. Conversely, suppose $x = \prod_{i=1}^n x_i$ is invertible. It is clear that $x_i$ commutes with $x$, for each $i$. It follows easily that each $x_i$ also commutes with $x^{-1}$, and that the inverse of $x_i$ is given by the product of $x^{-1}$ with the product of all $x_j$ with $j\neq 1$.

**(4):** The series $\sum_{n=0}^\infty (1 - x)^n$ is summable since the appropriate geometric series converges under the hypothesis. Let $\Set{s_n = \sum_{i=0}^n (1 - x)^i}$ be the sequence of partial sums, and let $s$ denote the limit. Clearly, each $s_n$ commutes with $(1 - x)$, and also $(1 - x)s_n = s_n (1 - x) = s_{n+1} - 1$. Thus, in the limit $n\to\infty$ we have $(1 - x)s = s(1 - x) = s - 1$, i.e. $xs = sx = 1$.

As for $\eqref{equation-2}$, we may apply $\eqref{equation-1}$ to $(1 - x/\lambda)$ in place of $x$, and justify the steps

$$
\begin{align*}
  (x - \lambda)^{-1} =& -\lambda^{-1} \left(1 - \frac{x}{\lambda} \right)^{-1} \\
  =& -\lambda^{-1} \lambda_{n=0}^\infty \frac{x^n}{\lambda^n} \\
  =& -\sum_{n=0}^\infty \frac{x^n}{\lambda^{n+1}}
\end{align*}
$$

**(5):** The assertions in **(4)** imply that $1\in\opertorname{int}(G(A))$ and is a point of continuity of the inversion map. By **(1)** and **(2)**, we may map this local picture at $1$ via the linear homeomorphism $L_x$ (which maps $G(A)$ onto itself) to a corresponing local picture at $x$, and deduce that any element of $G(A)$ is an interior point and is a point of continuity of the inversion map.
</details>
</MathBox>

<MathBox title='Spectrum' boxType='definition'>
Let $A$ be a unital Banach algebra, and let $x\in A$. The *spectrum* of $x$ is the set, denoted by $\sigma(x)$, defined by

$$
  \sigma(x) = \Set{\lambda\in\mathbb{F} | (x - \lambda)\notin G(A)}
$$

and the *spectral radius* of $x$ is defined by

$$
\begin{equation}
  r(x) = \sup\Set{\lvert\lambda\rvert : \lambda\in\sigma(x)} \leq\lVert x \rVert \tag{\label{equation-3}}
\end{equation}
$$

The *resolvent set* of $x$ is the complementary set $\rho(x)$ defined by

$$
  \rho(x) = \mathbb{F} - \sigma(x) = \Set{\lambda\in\mathbb{F}| (x - \lambda) \in G(A)}
$$

and the map $R_x : \rho(x) \to G(A)$ by $\lambda\mapsto (x - \lambda)^{-1}$ is called the *resolvent function* of $x$.
</MathBox>

<MathBox title='Resolvent properties' boxType='proposition' tag='proposition-22'>
Let $x\in A$, then
1. $\lim_{|\lambda|\to\infty} \lVert R_x (\lambda) \rVert = 0$
2. **Resolvent equation:**
$$
  R_x (\lambda) - R_x (\mu) = (\lambda - \mu) R_x (\lambda) R_x (\mu),\; \lambda, \mu \in\rho(x)
$$
3. The resolvent function is "weakly analytic", meaning that if $\phi\in A^*$, then the map $\phi\circ R_x:\rho(x)\to\mathbb{F}$ is an analytic function such that
$$
  \lim_{|\lambda|\to\infty} \phi\circ R_x (\lambda) = 0
$$

<details>
<summary>Proof</summary>

**(1):** By $\eqref{equation-2}$, there is a constant $C > 0$ such that
$$
  \lVert R_x (\lambda) \rVert \leq \frac{C}{|\lambda|},\; |\lambda| > \lVert x \rVert
$$

**(2):** If $\lambda,\mu\in\rho(x)$, then
$$
\begin{align*}
  (\lambda-\mu)R_x (\lambda) R_x (\mu) =& (\lambda - \mu)(x - \lambda)^{-1} (x - \mu)^{-1} \\
  =& R_x (\lambda) ((x - \mu) - (x - \lambda))R_x (\mu) \\
  =& R_x (\lambda) - R_x (\mu)
\end{align*}
$$

**(3):** If $\phi\in A^*$ is any continuous linear functional on $A$, it follows from Proposition $\ref{proposition-21}.5$ and **(2)** that if $\mu\in\rho(x)$, and if $\lambda$ is sufficiently close to $\mu$, then $\mu\in\rho(x)$, and

$$
\begin{align*}
  \lim_{\lambda\to\mu} \left(\frac{\phi\circ R_x (\lambda) - \phi\circ R_x (\mu)}{\lambda - \mu} \right) =& \lim_{\lambda\to\mu} (\phi(R_x (\lambda) R_y(\mu))) \\
  =& \phi(R_x(\mu)^2)
\end{align*}
$$

This shows that $\phi\circ R_x$ is differentiable, and thereby analytic, at the point $\mu$. By **(1)** and the boundedness of the linear functional $\phi$, it follows that

$$
  \lim_{\lambda\to\mu} \phi\circ R_x (\lambda)
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $A$ is any Banach algebra and $x\in A$, then $\sigma(x)$ is a non-empty compact subset of $\mathbb{F}$.

<details>
<summary>Proof</summary>

Assume on the contrary, so that $\rho(x) = \mathbb{F}$. Let $\phi\in A^*$ be arbitrary. By Proposition $\ref{proposition-22}.3$, this means that $\phi\circ R_x$ is an entire function, differentiable on $\mathbb{F}$, which vanishes at infinity. It then follows from Liouville's theorem that $\phi\circ R_x (\lambda) = 0$ for all $\lambda\in\mathbb{F}$. Since $\phi$ is arbitrary, and since $A^*$ separates points of $A$, we may conclude that $R_x (\lambda) = 0$ for all $\lambda\in\mathbb{F}$. However, since $R_x (\lambda) \in G(A)$, this is a contradiction, completing the proof.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-24'>
If $p(z) = \sum_{n=0}^N a_n z^n$ is polynomial with $a_n \in \mathbb{F}$, and if we define $p(x) = a_0\cdot 1 + \sum_{n=1}^N a_n x^n$ for each $x\in A$, then
1. $p(z) \mapsto p(x)$ is a homomorphism from the algebra $\mathbb{F}[z]$ of polynomials onto the subalgebra of $A$ which is generated by $\Set{1,x}$.
2. **Spectral mapping theorem:** If $p$ is any polynomial as above, then
$$
  \sigma(p(x)) = p(\sigma(x)) = \Set{p(\lambda) | \lambda\in\sigma(x)}
$$

<details>
<summary>Proof</summary>

**(1):** This is obvious.

**(2):** Temporarily fix $\lambda\in\mathbb{F}$. If $p(z) = \sum_{n=0}^N a_n z^n$, assume without loss of generality that $a_N \neq 0$, and by the fundamental theorem of algebra there exist $\lambda_1,\dots,\lambda_N$ such that

$$
  p(z) - \lambda = a_N \prod_{n=1}^N (z - \lambda_i)
$$

From **(1)** we have that

$$
  p(x) - \lambda = a_N \prod_{n=1}^N (x - \lambda_i)
$$

By Proposition $\ref{proposition-21}.3$, it follows that

$$
\begin{align*}
  \lambda\notin\sigma(p(x)) \iff& \lambda_i \notin\sigma(x) \forall 1\leq i \leq n \\
  \iff& \lambda\notin p(\sigma(x))
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Spectral radius formula' boxType='theorem' tag='theorem-12'>
If $A$ is a Banach algebra and if $x\in A$, then

$$
  r(x) = \lim_{n\to\infty} \lVert x^n \rVert^{1/n}
$$

<details>
<summary>Proof</summary>

Fix an arbitrary $\phi\in A^*$, and let $F = \phi\circ R_x$. By definition, this is analytic in the exterior of the disc $\Set{\lambda\in\mathbb{F}: |\lambda| \leq r(x)}$. On the other hand, we may conclude from $\eqref{}$ that $F$ has the Laurentn series expansion

$$
  F(\lambda) = -\sum_{n=0}^\infty \frac{\phi(x^n)}{\lambda^{n+1}}
$$

which is valid in the exterior of the disc $\Set{\lambda\in\mathbb{F}: |\lambda|\leq\lVert x\rVert}$. Since $F$ vanishes at infinity, the function $F$ is analytic at the point at infinity, and consequently the Laurent expansion above is valid in the larger region $|\lambda| > r(x)$.

If we temporarily fix a $\lambda$ with $|\lambda| > r(x)$, then we find, in particular, that

$$
  \lim_{n\to\infty} \frac{\varphi(x^n)}{\lambda^n} = 0
$$

Since $\varphi$ was arbitrary, it follows from the uniform boundedness principle that there is a constant $K > 0$ such that

$$
\begin{gather*}
  \lVert x^n \rVert \leq K|\lambda|^n,\; \forall n\in\N \\
  \lVert x^n \rVert^{1/n} \leq K^{1/n} |\lambda|
\end{gather}
$$

By allowing $|\lambda|$ to decrease to $r(x)$, we may conclude that

$$
  \limsup_{n\in\N} \lVert x^n \rVert^{1/n} \leq r(x)
$$

On the other hand, from Proposition $\ref{proposition-24}.2$ and equation $\eqref{equation-3}$ that $r(x) = r(x^n)^{1/n} \leq \lVert x^n \rVert^{1/n}$. Hence, we have 

$$
  r(x) \leq \liminf_{n\in\N} \lVert x^n \rVert^{1/n}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-25'>
Let $A$ be a unital Banach algebra, and suppose $B\subset A$ is a unital Banach subalgebra of $A$. For $x\in B$, then
1. $\sigma_B (x) \supset \sigma_A (x)$
2. $\partial(\sigma_B (x)) \subset \partial(\sigma_A (x))$, where $\partial(\Sigma) = \overline{\Sigma}\cap\overline{\mathbb{F}\setminus\Sigma}$ is the topological boundary of $\Sigma$. Thus, $\lambda\in\partial\Sigma$ if and only if there are sequences $\Set{\lambda_n}_{n\in\N}\subset\Sigma$ and $\Set{z_n}_{n\in\N}\subset\mathbb{F}\setminus\Sigma$ such that $\lambda = \lim_{n\to\infty} \lambda_n = \lim_{n\to\infty} z_n$

<details>
<summary>Proof</summary>

**(1):** We need to show that $\rho_B (x) \subset \rho_A (x)$. Suppose $\lambda\in\rho_B (x)$, so that there is $z\in B\subset A$ such that $z(x - \lambda) = (x - \lambda)z = 1$; hence, $\lambda\in\rho_A (x)$.

**(2):** Suppose $\lambda\in\partial(\sigma_B (x))$. Since the spectrum is closed, it follows that $\lambda\in\sigma_B (x)$ and that there exists a sequence $\Set{\lambda_n}\subset\rho_B$ such that $\lambda_n \xrightarrow{n\to\infty} \lambda$. From **(1)**, we have $\lambda_n \in\rho_A (x)$ for all $n\in\N$. Thus, we only need to show that $\lambda\in\sigma_A (x)$. If this were not the case, then $(x - \lambda_n) \xrightarrow{n\to\infty} (x - \lambda) \in G(A)$, which would imply by Proposition $\ref{proposition-21}.5$ that $(x - \lambda_n)^{-1} \xrightarrow{n\to\infty} (x - \lambda)^{-1}$. However, the assumption that $\lambda_n \in\rho_B (x)$ and that $B$ is a Banach subalgebra of $A$ would force the conclusion $(x - \lambda)^{-1} \in B$, contradicting the assumption that $\lambda\in\sigma_B (x)$. 
</details>
</MathBox>

## Gelfand-Naimark theory

<MathBox title='Ideal' boxType='definition'>
A subset $I$ of a normed algebra $A$ is an *ideal* if for $x,y\in I$, $z\in A$ and $\alpha\in\mathbb{F}$

$$
  \alpha x + y, xz, zx\in I
$$

An ideal is *proper* if it is distinct from the trivial ideals and $A$. A proper ideal is *maximal* if it is not strictly contained in any larger ideal. 
</MathBox>

<MathBox title='Criteria for proper ideals' boxType='proposition' tag='proposition-26'>
Let $A$ be a unital normal algebra. For a non-zero ideal $I \neq \Set{0}$, the following are equivalent
1. $I$ is a proper ideal
2. $I \cap G(A) = \emptyset$
3. $1\notin I$
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-27'>
Let $A$ be a commutative Banach algebra. An element $x\in A$ is not invertible if and only if there is a maximal ideal $I$ in $A$ such that $x\in I$.

<details>
<summary>Proof</summary>

Assume there is a maximal ideal $I$ in $A$ such that $x\in I$. By definition a maximal ideal is also proper, and from Proposition $\ref{proposition-26}$ it follows that $I \cap G(A)$. Hence, any $x\in I$ is not invertible.

Conversely, suppose $x$ is not invertible. The case $x = 0$ is trivial, so assume $x\neq 0$. Then $I_0 = \Set{ax | a\in A}$ is an ideal in $A$. Notice that $I_0 \neq\Set{0}$ since it contains $x = x1$, and $I_0 \neq A$ since it does not contain $1$. Thus, $I_0$ is a proper ideal. Applying Zorn's lemma shows that there is a maximal ideal $I$ which contains $I_0$ and the proof is complete.
</details>
</MathBox>

<MathBox title='Gelfand-Mazur theorem' boxType='theorem' tag='theorem-13'>
The following conditions on a unital commutative Banach algebra $A$ are equivalent.
1. $A$ is a division algebra, i.e. every non-zero element is invertible
2. $A$ is simple, i.e. there exist no proper ideals in $A$
3. $A = \mathbb{F}1$

<details>
<summary>Proof</summary>

**(1)** $\implies$ **(2):** If $A_0$ contains a proper ideal, then by Zorn's lemma it contains maximal ideal. By Proposition $\ref{proposition-27}$ it contains non-zero non-invertible elements.

**(2)** $\implies$ **(3):** Let $x\in A$ and pick $\lambda\in\sigma(x)$. This is possible because the specturm is always non-empty. Thus, $(x - \lambda)$ is not invertible and is consequently contained in the ideal $A(x - \lambda) \neq A$. By **(2)**, it follows that $A(x - \lambda) = \Set{0}$, i.e. $x = \lambda 1$.

**(3)** $\implies$ **(1):** This implication is obvious.
</details>
</MathBox>

<MathBox title='Homomorphism on commutative Banach algebra' boxType='definition'>
A homomorphism on a commutative Banach algebra $A$ is a mapping $\phi: A\to\mathbb{F}$ which is a non-zero algebra homomorphism, i.e. $\phi$ satisifes the following conditions for $x,y\in A$ and $\alpha\in\mathbb{F}$

1. **Linearity:** $\phi(\alpha x + y) = \alpha\phi(x) + \phi(x)$
2. $\phi(xy) = \phi(x)\phi(y)$
3. $\phi \not\equiv 0$

The collection of all homomorphisms on $A$ is called the *spectrum* of $A$ and is denoted $\hat{A}$. For $x\in A$, we write $\hat{x}$ for the function $\hat{x}:\hat{A}\to\mathbb{F}$ defined by $\hat{x}(\phi) = \phi(x)$.
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-1'>
Let $A$ be a unital commutative Banach algebra.
1. The mapping $\phi\mapsto\ker{\phi}$ is a bijection between $\hat{A}$ abd the collection of all maximal ideals in $A$.
2. $\hat{x}(\hat{A}) = \sigma(x)$

If $\lVert 1 \Vert = 1$ also, the following conditions on a map $\phi:A\to\mathbb{F}$ are equivalent

3. $\phi\in\hat{A}$
4. $\phi\in A^*$, $\lVert\phi\rVert = 1$, and $\phi(xy) = \phi(x)\phi(y)$ for all $x,y\in A$

<details>
<summary>Proof</summary>

**(1):** Let $\phi\in\hat{A}$ and define $I = \ker(\phi)$. Since $\phi$ is a homomorphism of $A$ onto $\mathbb{F}$, it follows that $I$ is a maximal ideal in $A$. Conversely, if $I$ is a maximal ideal in $A$, it follows that $A/I$ is simple, and hence, by Theorem $\ref{theorem-13}$, we see that $A/I = \mathbb{F}1$. Consequently, the quotient map $A\to A/I = \mathbb{F}$ gives rise to a homomorphism $\phi_I$ which clearly has the property that $\ker(\phi_I) = I$. Finally, the desired conclusion follows from the following facts
- two linear functionals on a vector space with the same kernel are multiples of on another
- if $\phi\in\hat{A}$, then $A = \ker{\phi\oplus\mathbb{F}1}$ (as vector spaces), and $\phi(1) = 1$.

**(2):** If $x\in A$ and $\phi\in\hat{A}$, then $(x - \phi(x)1) \in\ker{\phi}$, and hence, by Proposition $\ref{proposition-27}$ we se that $\phi(x)\in\sigma(x)$. Conversely, it follows from Proposition $\ref{proposition-27}$ and **(1)**, that $\sigma(x)\subset\hat{x}(\hat{A})$.

**(3):** From **(2)** and equation $\eqref{equation-3}$, it follows that if $\phi\in\hat{A}$, then for any $x\in A$ we have

$$
  |\phi(x)| \leq r(x) \leq\lVert x \rVert
$$

and hence $\lVert\phi\rVert\leq 1$. On the other hand, since $\phi(1) = 1$, we must have $\lVert\phi\rVert = 1$, and hence **(3)** $\implies$ **(4)**. The other implication is obvious.
</details>
</MathBox>

<MathBox title='' boxType='corollary' tag='corollary-1'>
Let $A$ be a non-unital commutative Banach algebra. Then $\phi\in\hat{A} \implies\phi\in A^*$ and $\lVert\phi\rVert\leq 1$.

<details>
<summary>Proof</summary>

Let $A^+$ denote the unitisation of $A$. Define $\varphi^+: A^+ \to \mathbb{F}$ by $\phi^+ (x,\alpha) = \phi(x) + \alpha$. It is easily verified that $\phi^+ \in\hat{A}^+$. Hence, by Lemma $\ref{lemma-1}.3$, we see that $\phi^+ \in (A^+)^*$ and $\lVert\phi^+ \rVert \leq 1$, and the desired conclusion follows easily.
</details>
</MathBox>

<MathBox title='Gelfand transform' boxType='theorem' tag='theorem-14'>
Let $A$ be a commutative Banach algebra, with spectrum $\hat{A}$. Then
1. $\hat{A}$ is a locally compact Hausdorf space (with respect to the weak*-topology), which is compact in case the Banach algebra contains an identity.
2. The map $x\mapsto\hat{x}$ defines a mapping $\Gamma: A\to C_0 (\hat{A})$ which is a contractive homomorphism of Banach algebras, meaning that the following relations hold, for all $x,y\in A$ and $\alpha\in\mathbb{F}$
    - $\lVert\Gamma(x)\rVert\leq\lVert x \rVert$
    - $\Gamma(\alpha x + y) = \alpha\Gamma(x) + \Gamma(y)$
    - $\Gamma(xy) = \Gamma(x)\Gamma(y)$

The map $\Gamma$ is called the *Gelfand transform* of $A$.

<details>
<summary>Proof</summary>

**(1):** Consider the following sets: for fixed  $x,y\in A$, let $K_{x,y} = \Set{\phi\in\operatorname{ball}(A^*) | \phi(xy) = \phi(x)\phi(y)}$, and let $V = \Set{\phi\in\operatorname{ball}(A^*) | \phi\neq 0}$, where $\operatorname{ball}(A^*) = \Set{\phi\in A^* : \lVert\phi\rVert\leq 1}$. The definition of weak* topology implies that $K_{x,y}$ (respectively, $V$) is a closed (respectively, open) subset of $\operatorname{ball}(A^*)$. Thus, $K = \bigcap_{x,y\in A} K_{x,y}$ is also a closed, hence compact, set in the weak* topology. Notice now that $\hat{A}= K\cap V$, and since an open subset of a (locally) compact Hausdorff space is locally compact and Hausdorff, we see that $\hat{A}$ is a local compact Hausdorff space. In case $A$ has an identity, then $F = \Set{\phi\in\operatorname{ball}(A^*) | \phi(1) = 1}$ is weak* closed, and $\hat{A} = K\cap F$ is a closed subset of $\operatorname{ball}(A*)$.

**(2):** The definition of the weak* topology guarantees that $\hat{x}$ is a continuous function on $\hat{A}$, for every $x\in A$. Obviously, the mapping $\Gamma: x\mapsto \hat{x}$ is linear and preserves products. To complete the proof, we need to verify that $\Gamma$ maps $A$ into $C_0 (\hat{A})$, and that $\lVert\Gamma(x)\rVert\leq\lVert x\rVert$.

First, consider that case when $A$ has an identity. In this case, $C_0 (\hat{A}) = C(\hat{A})$, while, by Lemma $\ref{lemma-1}$, we find that

$$
\begin{align*}
  \lVert\Gamma(x)\rVert =& \sup\Set{\lVert\hat{x}(\phi)\rVert : \phi\in\hat{A}} \\
  =& \sup\Set{\lVert\lambda\rVert : \lambda\in\sigma(x)} \\
  =& r(x) \leq\lVert x\rVert
\end{align*}
$$

Now suppose $A$ does not have an identity. By Corollary $\ref{corollary-1}$, it follows that $\Gamma$ is contractive, so we only need to verify that functions on $(A^+)^\^$ of the form $\hat{x}$ vanish at infinity.

Let $A^+$ be the unitisation of $A$, and let $f:\hat{A}\to (A^+)^\^$ by $f(\phi) = \phi^+$ be as in the proof of Corollary $\ref{corollary-1}$. Note that $(A^+)^\^ = f(\hat{A})\cup\Set{\phi_0}$, where $\phi_0 (x,\alpha) = \alpha$, since $\phi_0$ is the unique complex homomorphism of $A^+$ whose restriction to $A$ is identically equal to $0$. On the other hand, the topologies on $\hat{A}$ and $(A^+)^\^$ show that a net $\Set{\phi_i}_{i\in I}$ converges to $\phi$ in $\hat{A}$ if and only if $\Set{\phi_i^+}_{i\in I}$ converges to $\phi^+$ in $\hat{A}$. In other words, the function $f$ maps $\hat{A}$ homemorphically onto $f(\hat{A})$.

Thus, we find - from the compactness of $(A^+)^\^$, and from the nature of the topologies on the spaces concerned - that we may identify $(A^+)^\^$ with the one-point compactification $(\hat{A})^+$ of the locally compact Hausdorff space $\hat{A}$, with the element $\phi_0$ playing the role of the point at infinity. Note that if we identify $\hat{A}$ as a subspace of $(A^+)^\^$ via $f$, then the mapping $\widehat{(x,0)}$ is a continuous function on $(A^+)^\^$ which extends $\hat{x}$ and which vanishes at infinity (since $\phi_0 (x,0) = 0$). Thus, we find that $\hat{x}\in C_0 ((A^+)^\^)$ for all $x\in A$.
</details>
</MathBox>

<MathBox title='' boxType='corollary' tag='corollary-2'>
Let $\Gamma$ be the Gelfand transform of a commutative Banach algebra $A$. For $x\in A$, the following are equivalent
1. $x\in\ker(\Gamma)$, i.e. $\Gamma(x) = 0$
2. $\lim_{n\to\infty} \lVert x^n \rVert^{1/n} = 0$

In case $A$ has an identity, these conditions are equivalent to the following also

3. $x\in I$ for every maximal ideal $I$ of $A$
4. $\sigma(x) = \Set{0}$

<details>
<summary>Proof</summary>

Suppose first that $A$ has an identity. Since $\lVert\Gamma(x)\rVert = r(x)$, the equivalence of the four conditions follows easily from Proposition $\ref{proposition-27}$, Lemma $\ref{lemma-1}$ and the spectral radius formula (Theorem $\ref{theorem-12}$).

For non-unital $A$, apply the already established unital case of the corollary to the element $(x,0)$ of the unitised algebra $A^+$.
</details>
</MathBox>

<MathBox title='' boxType='definition'>
An element of a commutative Banach algebra $A$ is *quasi-nilpotent* if it satisfies the equivalent conditions of Corollary $\ref{corollary-2}$. The *radical* of $A$ is defined to be the ideal consisting of all quasi-nilpotent elements of $A$. A commutative Banach algebra is *semi-simple* if it has trivial radical (or equivalently, it has no quasi-nilpotent elements, which is the same as saying that the Gelfand transform of $A$ is injective).
</MathBox>

## C* algebra

<MathBox title='C* algebra' boxType='definition'>
A *C\* star algebra* is a Banach algebra $A$ equipped with an involution $A\ni x\mapsto x^* \in A$, which satisfies the following for $x,y\in A$ and $\alpha\in\mathbb{F}$
1. **Conjugate linearity:** $(\alpha x + y)^* = \overline{\alpha}x^* + y^*$
2. **Product reversal:** $(xy)^* = y^* x^*$
3. **Order two:** $(x^*)^* = x$
4. **C\* identity:** $\lVert x^* y\rVert = \lVert x\rVert^2$

The element $x^*$ is called the *adjoint* of the element $x$, and the mapping $x\mapsto x^*$ is referred to as the adjoint map or as adjunction. An element $x$ is 
- *self-adjoint* if $x = x^*$
- *normal* if $x* x = xx^*$
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-28'>
Suppose $A$ is a C* algebra without identity. Then there is a C* algebra $A^+$ with identity, which contains a maximal ideal isomorphic to $A$ as a C* algebra.

<details>
<summary>Proof</summary>

Consider the map $L_x : A\to\mathcal{A}$ defined by $L_x (y) = xy$ for all $y\in A$. By sub-multiplicativity of the norm (with respect to products) in any Banach algebra, and the C* identity, it follows that this maps is an isometric algebra homomorphism of $A$ into $\mathcal{L}(A)$.

Let $A^+ = \Set{L_x + \alpha 1 | x\in A, \alpha\in\mathbb{F}}$, where $1$ is the identity operator on $A$. Since this subalgebra is expressed as the vector sum of the complete and hence closed subspace $I = \Set{L_x | x\in A}$ and the one-dimensional subspace $\mathbb{F}$, it follows that $A^+$ is a closed subspace of the complete space $\mathcal{L}(A)$ and thus $A^+$ is a Banach algebra. Also note that $I$ is a maximal ideal in $A^+$ and that the mapping $x\mapsto L_x$ is an isometric algebra isomorphism of $A$ onto the Banach algebra $I$.

Define the obvious involution on $A^+$ by demanding that $(L_x 0 \alpha)^* = L_{x^*} + \overline{\alpha}$. It is easily verified that this involution satisfies the C* properties. It remains to verify that $\lVert z^* z\rVert \geq\lVert z\rVert^2$ for all $z\in A^+$. We assume $z \neq 0$, since the other case is trivial. For $z = L_x + \alpha$, we have $z^* z = L_{x^* x + \overline{\alpha}x + \alpha x^*} + |\alpha|^2$. Note that for arbitrary $y\in A$, we have

$$
\begin{align*}
  \lVert z(y) \rVert =& \lVert xy + \alpha y \rVert^2 \\
  =& \lVert (y^* x^* + \overline{\alpha}y^* (xy + \alpha y))\rVert \\
  =& \lVert y^* \cdot (z^* z)(y) \rVert \\
  \leq& \lVert z^* z \rVert \cdot \lVert y \rVert^2
\end{align*}
$$

where we have used the C* identity in the second line, and the submultiplicativity of the norm and the definition of the norm on $A^+$ in the last line. Since $y$ is arbitrary, this shows that we have $\lVert z \rVert^2 \leq \lVert z^* z\rVert$.
</details>
</MathBox>

<MathBox title='Gelfand-Naimark theorem for commutative C*-algebras' boxType='theorem' tag='theorem-15'>
If $A$ is a commutative C* algebra, the Gelfand transform is an isometric  *-algebra isomorphism of $A$ onto $C_0 (\hat{A})$. Furthermore, $\hat{A}$ is compact if and only if $A$ has an identity.

<details>
<summary>Proof</summary>

**Case 1: $A$ has an identity**<br/>
In view of Theorem $\ref{theorem-14}$, we only need to show that
1. if $x\in A$ is arbitrary, then $\Gamma(x^*) = \Gamma(x)^*$ and $\lVert\Gamma(x)\rVert = \lVert x \rVert$ \\
2. $\hat{A}$ is compact
3. $\Gamma$ maps onto $C(\hat{A})$

**(1):** We first consider the case of a self-adjoint element $x = x^* \in A$. Define $x_t = e^{itx}$ for all $t\in\R$. Note that the self-adjointness assumption, and the continuity of adjunction, imply that

$$
\begin{align*}
  u_t^* =& \sum_{n=0}^\infty \left(\frac{(itx)^n}{n!s}\right) \\
  =& \sum_{n=0}^\infty \left(\frac{(-itx)^n}{n!}\right) \\
  =& u_{-t}
\end{align*}
$$

Thus, by the C* identity we find that for any $t\in\R$

$$
  \lVert u_t \rVert^2 = \lVert u_{-t} u_t \rVert = 1
$$


If $\phi\in\hat{H}$, then $|\phi(u_t)| \leq 1$ for all $t\in\R$ since $\lVert\phi\rVert = 1$. On the other hand, since $\phi$ is continuous and multiplicative, it is seen that $\phi(u_t) = e^{it\phi(x)}$. In other words, $|e^{it\phi(x)}|\leq 1$ for all $t\in\R$. This clearly implies that $\phi(x)\in\R$. Thus, we have shown that $\hat{x}$ is a real-valued function, for every self-adjoint element $x\in A$. By Cartesian decomposition of an element as a sum of a self-adjoint and skew-adjoint element, we may conclude that $\Gamma$ is a homomorphism of *-algebra. If $x = x^* \in A$, note that

$$
  \lVert x\rVert^2 = \lVert x^* x\rVert = \lVert x^2 \rVert
$$

and conclude by induction that $\lVert x\rVert^{2n} = \lVert x^{2n} \rVert$ for all $n\in\N_+$. It follows from the spectral radius formula (Theorem $\ref{theorem-12}$) that

$$
  r(x) = \lim_{n\to\infty} \lVert x^{2n} \rVert^{1/2^n} = \lVert x\rVert
$$

On the other hand, we know that $\lVert\Gamma(x)\rVert = r(x)$ (Lemma $\ref{lemma-1}$). Thus, for self-adjoint $x$, we find that $\lVert\Gamma(x)\rVert = \lVert x \rVert$. The case of general $x$ follows from this, the fact that $\Gamma$ is a *-homomorphism, and the C* identity. Hence

$$
\begin{align*}
  \lVert\Gamma(x)\rVert^2 =& \lVert\Gamma(x)^* \Gamma(x)\rVert \\
  =& \lVert\Gamma(x^* x)\rVert \\
  =& \lVert x^* x\rVert \\
  =& \lVert x\rVert^2
\end{align*}
$$

**(2):** This follows from Theorem $\ref{theorem-12}$.

**(3):** It follows from **(1)** that $\Gamma(A)$ is a norm-closed self-adjoint subalgebra of $C(\hat{A})$, which is easily seed to contain the constants and to separate points of $\hat{A}$. By the Stone-Weierstrass theorem, the only such subalgebra is $C(\hat{A})$.

**Case 2: $A$ does not have a unit**<br/>
Let $A^+$ and $I$ be as in the proof of Proposition $\ref{proposition-28}$. By Case 1, we know that $\Gamma_{A^+}$ is an isometric *-isomorphism of $A^+$ onto $C(\hat{A})$, and that there is a point $\phi_0 \in (A^+)^\^$ such taht $\Gamma_{A^+} (I) = \Set{f\in C(\hat{A}) | f(\phi_0) = 0}$. As in the proof of Theorem $\ref{theorem-14}$, note that if $\pi:A\to I$ is the natural isometric *-isomorphism of $A$ onto $I$, the mp $\phi\mapsto\phi\circ\pi$ defines a bijective correspondence between $(A^+)^\^ \setminus\Set{\phi_0}$ and $\hat{A}$ which is a homeomorphism from the domain, with the subspace topology inherited from $(A^+)^\^$, and the range. 

Finally, it is clear that if $x\in A$ and $\phi_0 \neq\pho \in (A^+)^\^$, then $(\Gamma_{A^+}(\pi(x)))(\phi) = (\Gamma_A (x))(\phi\circ\pi)$, and it is this seen that even in the non-unital case, the Gelfand transform is an isometric *-isomorphism of $A$ onto $C_0 (\hat{A})$.

To show the compactness-identity criterion, note that if $X$ is a locally compact Hausdorff space, then $C_0 (x)$ contains an identity precisely when $X$ is compact.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $A$ be a unital C* algebra with element $x\in A$. If $B\subseteq A$ is a C* subalgebra of $A$ such that $1,x\in B$, then $\sigma_A (x) = \sigma_B (x)$. Equivalently, if $A_0 = C^* (\Set{1,x})$, then $\sigma_A (x) = \sigma_{A_0} (x)$.

<details>
<summary>Proof</summary>

By Proposition $\ref{proposition-25}$, we know that $\sigma_B (x) \supset \sigma_A (x)$. To prove the reverse inclusion, we need to show that $\rho_A (x) \subset \rho_B (x)$, i.e. we need to show that if $\lambda\in\mathbb{F}$ is such that $(x - \lambda)$ admits an inverse in $A$, then the inverse should actually belong to $B$. In view of the spectral mapping theorem (Proposition $\ref{proposition-24}$), we may assume, without loss of generality, that $\lambda = 0$. Thus, we have to prove the following assertion: If $1,x\in B\subset A$, and if $x\in G(A)$, then $x^{-1}\in B$. We prove this in two steps.

**Case 1: $x = x^*$**<br/>
Applying Theorem $\ref{theorem-15}$ to the commutative unital C* algebra $A_0 = C^* (\Set{1,x})$, we know that $\sigma_{A_0} (x) \subset\R$. Since any closed subset of the real line, when viewed as a subset of the complex plane, its own boundary, we may deduce from Proposition $\ref{proposition-25}$ applied to the inclusions $A_0 \subset B \subset A$ that

$$
  \sigma_A (x) \subset\sigma_B (x) \subset\sigma_{A_0} (x) = \partial(\sigma_{A_0}(x)) \subset\partial(\sigma_A (x)) \subset\sigma_A (x)
$$

Consequently, all the inclusions in the equation above are equalities.

**Case 2** <br/>
Suppose $x\in G(A)$ is arbitrary, then also $x^* \in G(A)$ and consequently, $x^* x \in G(A)$. By **Case 1**, this implies that $(x^* x)^{-1} \in B$. Then $(x^* x)^{-1} x^*$ is an element in $B$, which is the left-inverse of $x$. Since $x$ is an invertible element in $A$, it follows that $x^{-1} = (x^* x)^{-1}x^* \in B$.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-30'>
Let $A$ be a C* algebra with normal element $x\in A$ and define

$$
  A_0 = \begin{cases}
    C^* (\Set{1,x}) \quad& \text{if $A$ has an identity $1$} \\
    C^* (\Set{x}) \quad& \text{otherwise}
  \end{cases}
$$

Then
1. If $A$ has an identity, there is a unique isometric isomorphism of C* algebras denoted by $C(\sigma(x)) \ni f\mapsto f(x) \in A_0$ with the property that $f_1 (x)$, where $f_1: \sigma(x) \subset\mathbb{C} \to\mathbb{C}$ is the identity function defined by $f_1 (z) = z$.
2. If $A$ does not have an identity, and if we write $C_0 (\sigma(x)) = \Set{f\in C(\sigma(x)) | f(0) = 0}$, there is a unique isometric isomorphism of C^* algebras denoted $C_0 (\sigma(x)) \ni f\mapsto f(x) \in A_0$, with the property that $f_1 (x) = x$, where $f_1$ is as in **(1)** above.

<details>
<summary>Proof</summary>

**(1):** Let $\Sigma = \sigma(x)$. Note first that $\hat{x} = \Gamma_{A_0} (x): \hat{A}_0 \to\Sigma$ is a surjective continuous map. We assert that this map is actually a homeomorphism. By the compactness of $\hat{A}_0$ and the fact that $\mathbb{C}$ is a Hausdorff space, we only need to shows that $\hat{x}$ is bijective. Suppose $\hat{x}(\phi_1) = \hat{x}(\phi_2)$ for $\phi_1, \phi_2 \in\hat{A}_0$. It follows that $\phi_1|_D = \phi_2|_D$, where 

$$
  D = \Set{\sum_{i,j=0}^n \alpha_{i,j} x^i (x^*)^j | n\in\N,\,\alpha_{i,j}\in\mathbb{C}}
$$

On the other hand, the hypothesis implies that $D$ is dense in $A_0$, and the continuity of $\phi_1, \phi_2$ implies that $\phi_1 = \phi_2$. Hence, $\hat{x}$ is a homeomorphism of $\hat{A}_0$ onto $\Sigma$. Consider the map given by

$$
  C(\Sigma)\ni f\mapsto\Gamma_{A_0}^{-1} (f\circ\hat{x})
$$

It is easily deduced that this is an isometric isomorphism of the C* algebra $C(\Sigma)$ onto $A_0$ with the desired properties.

On the other hand, it follows from the Stone-Weierstrass theorem that the set 

$$
  D' = \Set{f | f(z) = \sum_{i,j=0}^n \alpha_{i,j} z^i \overset{z}^j,\,n\in\N,\,\alpha_{i,j}\in\mathbb{C}}
$$

is dense in $C(\Sigma)$. Thus, any continuous *-homomorphism of $C(\Sigma)$ is determined by its values on the set $D'$, and hence by its values on the set $\Set{f_0, f_1}$, where $f_j (z) = z^j$ for $j=0,1$.

**(2):** Suppose $A_0$ does not have an identity. Again, let $\Sigma = \sigma(x)$ and note that $0\in\Sigma$. Thus, if $A^+$ is the unitisation of $A$ as in Proposition $\ref{proposition-28}$, and if we regard $A$ as a maximal ideal in $A^+$ by identifying $x\in A$ with $L_x \in A^+$, we see that $A_0$ is identified with the maximal ideal $I_0 = \Set{L_y | y\in A_0}$ of $A_0^+ = \Set{L_y + \alpha | y\in A_0,\,\alpha\in\mathbb{C}}$. Under the isomorphism of $C(\Sigma)$ with $A_0^+$ that is guaranteed by applying **(1)** to the element $L_x \in A_0^+$, it is easy to see that $C_0 (\Sigma)$ get mapped onto $A_0$, and this proves the existence of an isomorphism with the desired properties. Uniqueness is established analogously as in **(1)**.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-31'>
Let $A$ be a C* algebra.
1. The following conditions on an element $x\in A$ are equivalent:
    - a. $x$ is normal, and $\sigma(x)\subseteq\R$
    - b. $x$ is self-adjoint
2. The following conditions on an element $u\in A$ are equivalent:
    - a. $u$ is normal, and $\sigma(u)\subseteq\mathbb{T}$
    - b. $A$ has an identity, and $u$ is unitary, i.e. $u^* u = uu^* = 1$
3. The following condition on an element $p\in A$ are equivalent:
    - a. $p$ is normal, and $\sigma(p)\subseteq\Set{0,1}$
    - b. $p$ is a projection, i.e. $p = p^2 = p^*$
4. The following conditions on an element $x\in A$ are equivalent:
    - a. $x$ is normal, and $\sigma(x) \subset[0,\infty)$
    - b. $x$ is positive, i.e. there is a self-adjoint element $y\in A$ such that $x = y^2$
5. If $x\in A$ is positive, there is a unique positive element $y\in A$ such that $x = y^2$. This $y$ belongs to $C^* (\Set{x})$ and is given by $y = f(x)$ where $f(t) = t^{1/2}$. The unique element $y$ is called the *positive square toot* of $x$ and is denoted $y = x^{1/2}$.
6. If $x\in A$ is self-adjoint, there is a unique decomposition $x = x_+ - x_-$, where $x_+,x_-$ are positive elements of $A$ that satisfy the condition $x_+ x_- = 0$.

<details>
<summary>Proof</summary>

By Proposition $\ref{proposition-30}$, we have an isomorphism $C^* (\Set{x}) \cong C(\sigma(x))$ in which $x$ corresponds to the identity function $f_1$ on $\sigma(x)$, i.e. $f_1 (\lambda) = \lambda$ for all $\lambda\in\sigma(x)$.

**(1):**
- **(a) $\implies$ (b):** In $C(\sigma(x))$ the identity function $f_1$ on $\sigma(x)\subseteq\R$ must satisfy $f_1 = f_1^*$. Hence, $x = x^*$ in $C^* (\Set{x})$.
- **(b) $\implies$ (a):** This follows from Proposition $\ref{proposition-30}$

**(2):**
- **(a) $\implies$ (b):** Note that if $z\in\mathbb{T}$ is a complex unit number, then $|z|^2 = z^* z = 1$. Thus, in $C(\sigma(u))$, the identity function $f_1$ on $\sigma(u)\subseteq\mathbb{T}$ must satisfy $f_1^* f_1 = f_1 f_1^* = 1$. Consequently, $u^* u = uu^* = 1$ in $C^* (\Set{p})$. 
- **(b) $\implies$ (a):** This follows from Proposition $\ref{proposition-30}$

**(3):**
- **(a) $\implies$ (b):** In $C(\sigma(p))$, the identity function $f_1$ on $\sigma(p)\subseteq\Set{0,1}$ must satisfy $f_1 = f_1^2$. Hence, $p = p^2$ in $C^* (\Set{p})$.
- **(b) $\implies$ (a):** Assume $p = p^2 = p^*$. To see to that $p$ is normal, note that since $p = p^*$, we have $pp^* = p^* p$. To see that $\sigma(p) \subseteq\Set{0,1}$, note that $\lambda\in\sigma(p)$ if $p - \lambda 1 \neq G(A)$. Since $p^2 = p$, we have $0 = p^2 - p = p(p - 1)$ and $\lambda^2 = \lambda \iff \lambda\in\Set{0,1}$ for any $\lambda\in\sigma(p)$. Hence, $\sigma(p)\subseteq\Set{0,1}$.

**(4):**
- **(a) $\implies$ (b):** Define $y = f(x)$ where $f\in C(\sigma(x))$ is defined by $f(t) = t^{1/2}$.
- **(b) $\implies$ (a):** This follows from Proposition $\ref{proposition-30}$, and the following two facts: the square of a real-valued function is a function non-negative values, and if $f\in C(X)$, with $X$ a compact Hausdorff spae, then $\sigma(f) = f(X)$.

**(5):** If $f$ is as in **(4)**, and if we define $y = f(x)$, it then follows since $f(0) = 0$, that $y\in C^* (\Set{x})$ and that $y$ is positive. Suppose $z$ is some other positive element of $A$ such that $x = z^2$. It follows that if we write $A_0 = C^* (\Set{z})$, then $x\in A_0$, and consequently, also $y\in C^* (\Set{x})\subset A_0$. 

By Theorem $\ref{theorem-15}$, there is an isomorphism of $A_0$ with $C(X)$ where $X = \sigma(z)\subset\R$, and under this isomorphism, both $z$ and $y$ correspond to non-negative continuous functions on $X$, such that the squares of these two functions are identical. Since the non-negative square root of a non-negative number is unique, we may conclude that $z = y$.

**(6):** For existence of the decomposition, define $x_\pm = f_\pm (x)$, where $f_\pm$ is the continuous function on $\R$ defined by $f_\pm (t) = \max\Set{0,\pm t}$, and note that $f_\pm (t) \geq 0$, $f_+ (t) - f_ (t) = t$ and $f_+ (t) f_- (t) = 0$ for all $t\in\R$. Also, note that $f_\pm (0) = 0$, so that $f_\pm (x) \in C^* (\Set{x})$.

For uniqueness suppose $x = x_+ - x_-$ is a decomposition of the desired sort. Then note that $x_- x_+ = x_-^* x_+^* = (x_+ x_-)^* = 0$, so that $x_+$ and $x_-$ are commuting positive elements of $A$. It follows that $A_0 = C^* (\Set{x_+, x_-})$ is a commutative C^* algebra which contains $\Set{x_+, x_-, x}$ and consequently also $f_\pm (x) \in C^* (\Set{x}) \subset A_0$. The proof is completed by applying Theorem $\ref{theorem-15}$ to $A_0$, and using the following fact: if $X$ is a compact Hausdorff space, if $f$ is a real-valued continuous function on $X$, and if $g_j$ for $j = 1,2$ are non-negative continuous functions on $X$ such that $f = g_1 - g_2$ and $g_1 g_2 = 0$, then necessarily $g_1 (x) = \max\Set{f(x),0}$.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-2'>
Let $A$ be a unital Banach algebra, and suppose $x, y \in A$. Then $\sigma(xy)\cup\Set{0} = \sigma(yx)\cup\Set{0}$.

<details>
<summary>Proof</summary>

We want to show that if $\lambda\neq 0$, then $(\lambda - xy) \in G(A) \implies (\lambda - yx)\in G(x)$. By replacing $x$ by $x/\lambda$ if necessary, it is sufficient to consider the case $\lambda = 1$. By the symmetry of the problem, it suffices to show that if $(1 - yx)$ is inverible, then so is $(1 - xy)$.

Suppose $u = (1 - yx)^{-1}$, so $u - uyx = yxu = 1$. Set $v = 1 + xuy$, and note that

$$
\begin{align*}
  v(1 - xy) =& (1 + xuy)(1 - xy) \\
  =& 1 + xuy - xy - xuyxy \\
  =& 1 + x(u - 1 - uyx)y \\
  =& 1
\end{align*}
$$

An entirely similar computation shows that also $(1 - xy)v = 1$. This shows that $(1 - xy)$ is invertible with inverse given by $v$.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-32'>
If $A$ is a C* algebra, if $x,y\in A$, and if $x,y \geq 0$ are positive, then also $(x + y) \geq 0$ is positive.

<details>
<summary>Proof</summary>

To start with (by embedding $A$ in a larger unital C* algebra, if necessary), we may assume that $A$ is itself a unital C* algebra. Next, we may (by scaling both $x$ and $y$ down by the same small positive scalar, if necessary) assume without loss of generality that $\lVert x\rVert, \lVert y \rVert \leq 1$. Thus, the spectral radius is $r(x) < 1$ and we may conclude that $\sigma(x) \subset [0,1]$, and consequently deduce that $\sigma(1 - x) \subset[0,1]$, and hence that $(1 - x) \geq 0$ and $\lVert 1 - x\rVert = r(1 -x) \leq 1$. Similarly, also $\lVert 1 - y \rVert\leq 1$. Then, $\lVert 1 - \frac{x + y}{2}\rVert = \frac{1}{2}\lVert(1 - x) + (1 - y)\rVert\leq 1$ and by the spectral mapping theorem (Proposition $\ref{proposition-24}$), we have $\sigma(x + y) \subset[0,4]$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
If $A$ is a C* algebra, let $A_*$ denote set of self-adjoint elements of $A$. For $x, y\in A_*$, then $x \geq y$ if $(x - y) \geq 0$ (or equivalently $y\leq x$ if $(y - x) \geq 0$). The relation $\leq$ defines a partial order on $A_*$.

<details>
<summary>Proof</summary>

- Reflexivity follows from $0\geq 0$.
- Transitivity follows from Proposition $\ref{proposition-32}$.
- Anti-symmetry implies $x = x^*$ and $x, -x \geq 0 \iff x = 0$. Such an $x$ should have the property that $\sigma(x) \subset [0,\infty)$ and $\sigma(x)\subset (-\infty,0]$. This would mean that $\sigma(x) = \Set{0}$, and since $x = x^*$, it would follow that $\lVert x \rVert = r(x) = 0$.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-3'>
Suppose $z$ is an element of a C* algebra and that $z^* z \leq 0$, then $z = 0$.

<details>
<summary>Proof</summary>

By Lemma $\ref{lemma-2}$, the hypothesis implies that also $zz^* \leq 0$. Thus, from Proposition $\ref{proposition-32}$ it follows that $z^* z + zz^* \leq 0$. However, if $z = u + iv$ is the Cartesian decomposition of $z$, note thet $z^* z + zz^* = 2(u^2 + v^2)$. Thus, from Proposition $\ref{proposition-32}$, it follows that $z^* z + zz^* \geq 0$. Hence, we find that $z^* z + zz^* = 0$. This means that $u^2 = -v^2$. By same argument, we find that $u^2 \geq 0$ and $u^2 \leq 0$, whence $u^2 = 0$, and so $u = 0$ (siince $\lVert u \rVert = \lVert u^2 \rVert^{1/2}$ for self-adjoint $u$). Hence, also $v = 0$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $A$ be a C* algebra. If $x\in A$, the following are equivalent
1. $x \geq 0$
2. There exists $z\in A$ such that $x = z^* z$.

<details>
<summary>Proof</summary>

**(1) $\implies$ (2):** This follows by setting $z = x^{1/2}$ and applying Proposition $\ref{proposition-31}$.

**(2) $\implies$ (1):** Let $x = x_+ - x_-$ be the canonical decomposition of the self-adjoint element $x$ into its positive and negative parts. We then find (since $x_- x_+ = 0$) that $x_- xx_- = -x^3 \leq 0$. However, $x_- xx_- = (zx_-)^* (zx_-)$, and we may conclude from Lemma $\ref{lemma-3}$ that $x_-^3 = 0$, whence $z^* z = x = x_+ \geq 0$.
</details>
</MathBox>

### Representations of C* algebras

<MathBox title='Representation of unital C* algebras' boxType='definition'>
A representation of a unital C* algebra $A$ is a *-homomorphism $\pi:A\to\mathcal{L}(H)$, where $H$ is a Hilbert space. This will always be assumed to be a unital homorphism, meaning that $\pi(1) = I$, where $1$ is the identity of $A$ and $I\in\mathcal{L}(H)$ is the identity operator on $H$.

Two representations $\pi_i:A\to\mathcal{L}(H_i)$ for $i=1,2$ are *equivalent* if there is a unitary operator $U:H_1 \to H_2$ with the property that $\pi_2 (x) = U\pi (x) U^*$ for all $x\in A$.

A representation $\pi: A\to\mathcal{L}(H)$ is *cyclic* if thre is a vector $\mathbf{x}\in H$ such taht $\Set{\pi(x)(\mathbf{x}): x\in A}$ is dense in $H$. In this case, the vector $\mathbf{x}\in H$ is said to be a *cyclic vector* for the representation $\pi$.
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-4'>
If $\pi:A\to B$ is a unital *-homomorphism between unital C* algbras, then
1. $x\in A \implies \sigma(\pi(x))\subseteq\sigma(x)$
2. $\lVert\pi(x)\rVert\leq\lVert x \rVert \forall x\in A$

<details>
<summary>Proof</summary>

**(1):** Since $\pi$ is a unital algebra homomorphism, it follows that $\pi$ maps invertible elements to invertible elements. This clearly implies the asserted spectral inclusion.

**(2):** If $x = x^* \in A$, the also $\pi(x) = \pi(x^*) = \pi(x)^* \in B$, and since the norm of a self-adjoint element in a C* algebra is equal to its spectral radius, we find from **(1)** that

$$
  \lVert\pi(x)\rVert = r(\pi(x)) \leq r(x) = \lVert x \rVert
$$

for any $x\in A$, it follows that

$$
\begin{align*}
  \lVert\pi(x)\rVert^2 =& \lVert\pi(x)^* \pi(x)\rVert = \lVert\pi(x^* x)\rVert \\
  \leq& \lVert x^* x \rVert = \lVert x\rVert^2
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Commutant' boxType='definition'>
If $H$ is a Hilbert space, and if $S\subset\mathcal{L}(H)$ is any set of operators, the *commutant* of $S$ is defined by

$$
  S' := \Set{x' \in\mathcal{L}(H) | x' x = xx' \; \forall x\in S}
$$
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-34'>
Let $H$ be a Hilbert space.
1. If $S\subset\mathcal{L}(H)$ is arbitrary, then the commutant $S'$ is a unital subalgebra of $\mathcal{L}(H)$ that is closed in the weak-operator topology (and consequently also in the stron operator and norm topologies) on $\mathcal{L}(H)$.
2. If $S$ is closed under formation of adjoints, i.e. if $S = S^*$, where $S^* = \Set{x^* | x \in S}$, then $S'$ is a C* subalgebra of $\mathcal{L}(H)$.
3. If $S\subset T \subset\mathcal{L}(H)$, then
    - a. $S' \supset T'$
    - b. If we inductively define $S'^{(n+1)} = (S'^{(n)})'$ and $S'^{(1)} = S'$, then
$$
\begin{align*}
  S' =& S'^{(2n+1)}, \forall n\in\N \\
  S\subset S'' =& S'^{(2)} = S'^{(2n + 2)}, \forall n\in\N
\end{align*}
$$

4. Let $M$ be a closed subspace of $H$ and let $p$ denote the orthogonal projection onto $M$, and let $S\subset\mathcal{L}(H)$. Then the following conditions are equivalent:
    - a. $x(M)\subset M$ for all $x\in S$
    - b. $xp = pxp$ for all $x\in S$

If $S = S^*$ is self-adjoint, then the above conditions are also equivalent to
    
    - c. $p\in S'$

<details>
<summary>Proof</summary>

**(1):** The topological assertion is a consequence of the fact that multiplication is separately weakly continuous. The algebraic assertions are obvious.

**(2):** Note that

$$
\begin{align*}
  y\in S \iff& yx^* = x^* y\; \forall x\in S \\
  \iff& xy^* = y^* x\; \forall x\in S \\
  \iff& *y \in S'
\end{align*}
$$

so that $(S^*)' = (S')^*$, for any $S\subset\mathcal{L}(H)$.

**(3):** Note that **(a)** is a an immediate consequence of the definition, as is the fact that $\subset S''$. Applying **(a)** to this inclusion, we find that $S' \supset S'''$. On the other hand, if we replace $S$ by $S'$ in the inclusion, we see taht $S' \subset S''$, proving **(b)**.

**(4):** For an operator $x \in\mathcal{L}(H)$, the condition that $\mathbf{x}(M) \subset M$, and that $xp = pxp$ are both seen to be equivalent to the requirement that if $((x_j^i))_{1\leq i, j\leq 2}$ is the matrix of $x$ with respect to the direct sum decomposition $H = M \oplus M^\perp$, then $x_1^2 = 0$, i.e. the matrix of $x$ has the form

$$
  [x] = \begin{bmatrix} a & b \\ 0 & c \end{bmatrix}
$$

where, of course, $a\in\mathcal{L}(M)$, $b\in\mathcal{M^\perp, M}$ and $c\in\mathcal{L}(M^\perp)$ are the appropriate compressions of $x$. A compression of an operator $x\in\mathcal{L}(H)$ is an operator of the form $z = P_M \circ x|_N$ for some subspaces $M, N \subset H$.

If $S$ is self-adjoint, and if **(a)** and **(b)** are satisfied, we find that $xp = pxp$ and $x^* p = px^* p$ for all $x\in S$. Taking adjoints in the second equation, we find that $px = pxp$. Combining with the first equation, we thus find that $px = xp$ for all $x\in S$, i.e. $p \in S'$. 

Conversely, **(c)** clearly implies **(b)**, since if $px = xp$, then $pxp = xp^2 = xp$.
</details>
</MathBox>

<MathBox title="von Neumann's density theorem" boxType='theorem' tag='theorem-16'>
Let $A$ be a unital *-subalgebra of $\mathcal{L}(H)$. Then $A''$ is closure of $A$ in the strong operator topology.

<details>
<summary>Proof</summary>

Since $A\subset A''$, and since $A''$ is closed in the strong operator topology, we only need to show that $A$ is strongly dense in $A''$. By the definition of the strong topology, we need to prove the following:

**Assertion:** Let $z\in A''$, then for any $n\in\N$, $\mathbf{x}_1,\dots,\mathbf{x}_n \in H$ and $\epsilon > 0$, there exists $x \in A$ such taht $\lVert (x - z)\mathbf{x}_i \rVert < \epsilon$ for $1\leq i \leq n$.

**Case 1: $n = 1$** 

Let us write $\mathbf{x} = \mathbf{x}_1$, and let $M$ denote the closure of the set $A\mathbf{x} = \Set{x\mathbf{x} : x\in A}$. Note that $A\mathbf{x}$ is a vector space containing $\mathbf{x}$ (since $A$ is an algebra containing $1$), and hence $M$ is a closed subspace of $H$, which is obviously stable under $A$, meaning that $xM \subset M$ for all $x\in A$. Hence, if $p$ is the projection onto $M$, we may deduce from Proposition $\ref{propsition-34}.4$ that $p\in A'$ and that $p\mathbf{x} = \mathbf{x}$. Since $z\in A''$, we find that $xp = pz$, whence $zM \subset M$. In particular, $z\mathbf{x} \in M$. By definition, this means that there exists $x\in A$ such that $\lVert (z\mathbf{x} - x\mathbf{x})\rVert < \epsilon$.

**Case 2: $n\in\N_+$**

Let $H^n = \bigoplus_{i=1}^n H$. We shall identify $\mathcal{L}(H^n)$ with $M_n (\mathcal{L}(H))$. Let us adopt the following notation: if $a\in\mathcal{L}(H)$, we write $a^{(n)}$ for the lementof $M_n (\mathcal{L}(H))$ with $(i,j)$-th entry being given by $\delta_j^i a$, i.e. $a^{(n)} = \operatorname{diag}_n(a)$. With this notation, define

$$
\begin{equation}
  A^{(n)} = \Set{a^{(n)} | a\in A} \tag{\label{equation-5}}
\end{equation}
$$

and observe that $A^{(n)}$ is a unital *-subalgebra of $\mathcal{L}(H^{(n)})$. We claim that

$$
\begin{equation}
  (A^{(n)})' = \Set{((b_j^i)) | b_j^i \in A',\; i,j=1,\dots,n} \tag{\label{equation-6}}
\end{equation}
$$

and that

$$
  (A^{(n)})'' = (A'')^{(n)} = \Set{z^{(n)} | z\in A''}
$$

Let $b = ((b_j^i))$. Then $ba^{(n)} = ((b_j^i a))$, while $a^{(n)} b = ((ab_j^i))$, proving $\eqref{equation-5}$. In view of $\eqref{equation-5}$, we have $e_j^i \in (A^{(n)})'$, where $e_j^i$ is the matrix which has entry $1 = \operatorname{id}_H$ in the $(i,j)$-th place and $0$ elsewhere. Hence, if $y\in (A^(n))''$, we expect, inparticular, that $ye_j^i = e_j^i y$ for all $1\leq i,j \leq n$. This is seen, fairly easily, to imply that there must exist some $z\in\mathcal{L}(H)$ such that $y = z^{(n)}$. Another routine verification shows that $z^{(n)}$ will commute with $((b_j^i))$ for arbitrary $b_j^i \in A'$ if and only if $z\in A''$, proving $\eqref{equation-6}$.

If $z\in A''$, consider the element $z^{(n)} \in (A^{(n)})''$ and the vector $\mathbf{x} = (\mathbf{x}_i)_{i=1}^n \in H^n$. By **Case 1**, there is an element of $a^{(n)} \in A^{(n)}$ with $a\in A$ such that $\lVert(z^{(n)} - a^{(n)}\mathbf{x}\rVert < \epsilon$. This implies that $\lVert (z - a)\mathbf{x}_i \rVert < \epsilon$ for $1 \leq i \leq n$.
</details>
</MathBox>

<MathBox title='Double commutant theorem' boxType='corollary'>
The following conditions on a unital *-subalgebra $M\subset\mathcal{L}(K)$ are equivalent
1. $M$ is weakly closed
2. $M$ is strongly closed
3. $M = M''$

A subalgebra $M$ as above is called a *von Neumann algrebra*.

<details>
<summary>Proof</summary>

**(1)$\implies$(2):** This is obvious.

**(2)$\implies$(3):** This follows from Theorem $\ref{theorem-}$.

**(3)$\implies$(1):** This follows from Proposition $\ref{proposition-34}$.
</details>
</MathBox>

<MathBox title='Stable representations of C* algebras' boxType='definition'>
Suppose $\pi: A\to \mathcal{L}(H)$ is a representation of a C* algebra $A$ in terms of a Hilbert space $H$. A closed subspace $M\subset H$ is $\pi$-stable if $\pi(x)(M) \subset M$ for al $x\in A$.

By Proposition $\ref{proposition-34}.4$, the stable condition is equivalent to the condition that $p\in\pi(A)'$, where $p$ is the projection of $H$ onto $M$. Thus, $\pi$-stable subspaces of $H$ are bijective to projections in the von Neumann algebra $\pi(A)'$. In particular, since $p\in M \implies 1 - p \in M$, we see that the orthogonal complement of a $\pi$-stable subspace is also $\pi$-stable.

Every $\pi$-stable subspace yields a new representation $\pi|_M : A\to\mathcal{L}(M)$ by the restriction $\pi|_M (x)(\mathbf{x}) = \pi(x)(\mathbf{x})$ for all $x\in A$ and $\mathbf{x}\in M$. The representation $\pi|_M$ is a called a *sub-representation* of $\pi$. 
</MathBox>

<MathBox title='' boxType='lemma'>
Any representation of a C* algebra is equivalent to a direct sum of cyclic (sub-)representations. Any separable representation is equivalent to a countable direct sum of cyclic representations.

<details>
<summary>Proof</summary>

If $\pi:A\to\mathcal{L}(H)$ is a representation of a C* algebra $A$ in terms of a Hilbert space $H$, and $\mathbf{x}\in H$ is arbitrary, then the subspace $M = \overline{\Set{\pi(x)(\mathbf{x}) | x\in A}}$ is a closed subspace that is $\pi$-stable, and, by definition, the sub-representation $\pi|_M$ is cyclic (with cyclic vector $\mathbf{x}$). Consider the non-empty collection $\mathcal{P}$ whose typical element is a non-empty collection $\mathcal{S} = \Set{M_i}_{i\in I}$ of pairwise orthogonal nonzero $\pi$-stable subspaces that cyclic (in the sense that the sub-representation afforded by each of them is a cyclic representation). It is clear that the set $\mathcal{P}$ is partially ordered by inclusion, and that if $\mathcal{C} = \Set{\mathcal{S}_\lambda | \lambda\in\Lambda}$ is any totally ordered subset of $\mathcal{P}$, then $\mathcal{S} = \bigcup_{\lambda\in\Lambda} \mathcal{S}_\lambda$ is an element of $\mathcal{P}$. Thus, every totally ordered subset of $\mathcal{P}$ admits an upper bound. Hence, Zorn's lemma implies the existence of a maximal element $\mathcal{S} = \Set{M_i}_{i\in I}$ of $\mathcal{P}$.

Then $M = \bigplus_{i\in I} M_i$ is clearly a $\pi$-stable subspace of $H$, and so also is $M^\perp$. If $M^\perp \neq\Set{0}$, pick a non-zero $\mathbf{x}\in M^\perp$, let $M_0 = \overline{\Set{\pi(x)\mathbf{x} | x\in A}}$, and observe that $\mathcal{S} \cap\Set{M_0}$ is a member of $\mathcal{P}$, which contradicts the maximality of $\mathcal{S}$. Thus, it should be the case that $M^\perp = \Set{0}$, i.e. $H = \bigoplus_{i\in I} M_i$, proving the first assertion.

If $H = \bigoplus_{i\in I} M_i$ is an orthogonal decomposition of $H$ as a direct sum of non-zero cyclic $\pi$-stable subspaces as above, let $\mathbf{x}_i$ be any unit vector in $M_i$. Then $\Set{\mathbf{x}_i}_{i\in I}$ is an orthonormal set in $H$, and the assumed separability of $H$ implies that $I$ is necessarily countable. 
</details>
</MathBox>

<MathBox title='State on a unital algebra' boxType='definition'>
A *state* on a unital C* algebra $A$ is a linear functional $\phi:A\to\mathbb{F}$, which satisfies the following
1. $\phi$ is positive, meaning that $\phi(x^* x)\geq 0$ for all $x\in A$
2. $\phi(1) = 1$
</MathBox>

<MathBox title='Characterization of states' boxType='proposition' tag='proposition-35'>
The following conditions on a linear function $\phi:A\to\mathbb{F}$ are equivalent:
1. $\phi$ is a state
2. $\phi\in A^*$ and $\lVert\phi\rVert = \phi(1) = 1$

<details>
<summary>Proof</summary>

**(1)$\implies$(2):** First note that since any self-adjoint element is expressible as a difference of two positive elements (see Proposition $\ref{proposition-31}.6$), then $\phi(x)\in\R$ whenever $x = x^*$. It follows from the Cartesian decomposition, that $\phi(x^*) = \overline{\phi(x)}$ for all $x\in A$.

Consider the sequilinear form $B_\phi : A\times A\to\mathbb{C}$ defined by

$$
  B_\phi (x,y) = \phi(y^* x),\; \forall x,y\in A
$$

It follows from the assumed positivity of $\phi$ that $B_\phi$ is a positive semi-definite sesquilinear form on $A$, i.e.

$$
  |\phi(y^* x)|^2 \leq \phi(x^* x) \cdot \phi(y^* y),\; \forall x,y\in A
$$

In particular, setting $y = 1$ and using the obvious inequality $x^* x \leq \lVert x \rVert^2 1$ and positivity of $\phi$, we find that

$$
  |\phi(x)|^2 \leq \phi(x^* x) \phi(1) \leq\lVert x \rVert^2 \phi(1)^2 = \lVert x \rVert^2
$$

so that $\phi\in A^*$ and $\lVert\phi\rVert\leq 1$. Since $\lVert 1\rVert = 1 = \phi(1)$, we find that $\lVert\phi\rVert = \phi(1) = 1$, as desired.

**(2)$\implies$(1):** We want to show that if $x = x^*$, and if $\sigma(x)\subset[a,b]$, then $\phi(x) \in [a,b]$. This will imply that $\phi$ is positive and that $\phi(1) = 1$. Set $c = (a+b)/2$ and $r = (b-a)/2$, and note that $\sigma(x-c)\subset[-r,r]$ and consequently $\lVert x - c\rVert\leq r$. Hence, it follows from the assumptions **(2)** that

$$
  |\phi(x) - c| = |\phi(x - c)| \leq \lVert x - c\rVert \leq r
$$

in other words, we have $\phi(x)\in[a,b]$ as asserted.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-6'>
Let $I\subseteq\N$ be an index set. Suppose $D^{(k)} = \Set{x_i^{(k)}}_{i\in I}$ is a dense subspace of Hilbert spaces $H_k$ for $k = 1, 2$, so that 

$$
  \Braket{x_i^{(1)}, x_j^{(1)}}_{H_1} = \Braket{x_i^{(2)}, x_j^{(2)}}_{H_2},\;\forall i,j\in I
$$ 

Then there exists a unique unitary operator $U:H_1\to H_2$ such that $Ux_i^{(1)} = x_i^{(2)}$ for all $i\in I$.
</MathBox>

<MathBox title='Gelfand-Naimark-Segal (GNS) construction' boxType='theorem' tag='theorem-17'>
If $\phi:A\to\mathbb{F}$ is a state on a unital C* algebra $A$, there exists a cyclic representation $\pi_\phi : A\to\mathcal{L}(H_\phi)$ with a cyclic unit vector $\mathbf{x}_\phi \in H_\phi$ such that

$$
  \phi(x) = \braket{\pi_\phi (x)\mathbf{x}_\phi, \mathbf{x}_\phi},\;\forall x\in A
$$

The triple $(H_\phi, \pi_\phi, \mathbf{x}_\phi)$ is unique in the sense that if $\pi:A\to H$ is a cyclic representation with cyclic vector $\mathbf{x}$ such that $\phi(x) = \braket{\pi(x)\mathbf{x}, \mathbf{x}}$ for all $x\in A$, then there exists a unique unitary operator $U:H\to H_\phi$ such that $U\mathbf{x} = \mathbf{x}_\phi$ and $U\pi(x)U^* = \pi_\phi$ for all $x\in A$.

<details>
<summary>Proof</summary>

Let $B_\phi : A\times A \to\mathbb{F}$ be the positive semi-definite sesquilinear form defined by

$$
  B_\phi (x,y) = \phi(y^*, x),\; \forall x,y \in A
$$

Let $N_\phi = \Set{x\in A | B_\phi (x, x) = 0}$. It follows from

$$
  |\phi(y* x)|^2 \leq\phi(x^* x) \cdot \phi(y^* y),\; \forall x,y\in A
$$

that $x\in N_\phi$ if and only if $\phi(y* x) = 0$ for all $y\in A$. This implies that $N_\phi$ is a vector subspace of $A$ which is in fact a left-ideal, i.e. $x\in N_\phi \implies zx\in N_\phi \forall z \in A$.

The equation

$$
  \braket{x + N_\phi, y + N_\phi} = \phi(y^* x)
$$

defines a genuine inner product on the quotient space $V = A/N_\phi$. For notational convenience, we introduce $\eta(x) = x + N_\phi$ so that $\eta:A\to V$. Since $N_\phi$ is a left-ideal in $A$, it follows that each $x\in A$, unambiguously defines a linear map $L_x : V\to V$ by the prescription $L_x \eta(y) = \eta(xy)$.

We claim now that each $L_x$ is a bounded operator on the inner product space $V$ and that $\lVert L_x \rVert_{\mathcal{L}(V)} \leq \lVert x \rVert_A$. This amounts to the assertion that

$$
  \phi(y^* x^* xy) = \lVert L_x \eta(y)\rVert^2 \leq \lVert x\rVert^2 \lVert\eta(y)\rVert^2 = \lVert x \rVert^2 \phi(y^* y),\; \forall x,y\in A
$$

Note now that, for each fixed $y\in A$, if we consider the functional $\psi(z) = \phi(y^* zy)$, then $\psi$ is a positive linear functional. By Proposition $\ref{proposition-35}$, we find that $\lVert\psi\rVert = \psi(1) = \phi(y^* y)$. In particular, we find that for arbitrary $x,y\in A$, we must have $\phi(y^* x^* xy) = \psi(x^* x) \leq\lVert\psi\rVert\cdot\lVert x^* x\rVert$. In other words, $\phi(y^* x^* xy) \leq\lVert x\rVert^2 \phi(y^* y)$ as asserted.

Since $V$ is a genuine inner product space, we may form its completion, call it $H_\phi$, where we think of $V$ as a dense subspace of $H_\phi$. We may deduce from the previous argument that each $L_x$ extends uniquely to a bounded operator on $H_\phi$, which we will denote by $\pi_\phi (x)$. The operator $\pi_\phi (x)$ is defined by the requirement that $\pi_\phi (x)\eta(y) = \eta(xy)$. This immediately implies that $\pi_\phi$ is a unital algebra homomorphism of $A$ into $\mathcal{L}(H_\phi)$. To see that $\pi_\phi$ preserves adjoints, note that if $x,y,z\in A$ are arbitrary, then

$$
\begin{align*}
  \braket{\pi_\phi (x)\eta(y),\eta(z)} =& \phi(z^* (xy)) \\
  =& \phi((x^* z)^* y) \\
  =& \braket{\eta(y),\pi_\phi (x^*)\eta(z)}
\end{align*}
$$

which implies, by the the density of $\eta(A)$ in $H_\phi$, that $\pi_\phi (x)^* = \pi_\phi (x^*)$, so that $\pi_\phi$ is a representation of $A$ in $H_\phi$. Finally, it should be obvious that $\mathbf{x}_\phi = \eta(1)$ is a cyclic vector for this representation.

Conversely, if $(H,\pi,\mathbf{x})$ is another triple which also works for $\phi$ as asserted in the second statement of the theorem, note that for arbitrary $x,y\in A$ we have

$$
  \braket{\pi(x)\mathbf{x},\pi(y)\mathbf{x}}_H = \phi(y^* x) = \braket{\pi_\phi (x)\mathbf{x}_\phi, \pi_\phi(y)\mathbf{x}_\phi}_{H_\phi}
$$

The assumptions that $\mathbf{x}$ and $\mathbf{x}_\phi$ are cyclic vectors for the representations $\pi$ and $\pi_\phi$ respectively imply via Lemma $\ref{lemma-6}$ that there is a unique operator $U:H\to H_\phi$ with the property that $U(\pi(x)\mathbf{x}) = \pi_\phi (x)\mathbf{x}_\phi$ for all $x\in A$. It is clear that $U$ has the properties asserted in the theorem.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-7'>
Let $x$ be a self-adjoint element of a C* algebra $A$. Then there exists a cyclic representation $\pi$ of $A$ such that $\lVert\pi(x)\rVert = \lVert x \rVert$.

<details>
<summary>Proof</summary>

Let $A_0 = C^* (\Set{1,x})$ be the commutative unital C* subalgebra generated by $x$. Since $A_0 \cong C(\sigma(x))$, there exists a complex homomorphism $\phi_0 \in \hat{A}_0$ such that $|\phi_0 (x)| = \lVert x\rVert$. Notice that $\lVert\phi_0 \rVert = 1 = \phi_0 (1)$.

By the Hahn-Banach theorem ($\ref{theorem-5}$), we can find a $\phi\in A^*$ such that $\phi|_{A_0} = \phi_0$ and $\lVert\phi\rVert = \lVert\phi_0 \rVert$. It follows then that $\lVert\phi\rVert = 1 = \phi(1)$. Hence $\phi$ is a state on $A$, by Proposition $\ref{proposition-35}$.

If $\pi_\phi$ is the (cyclic) GNS-representation afforded by the state $\phi$ as in Theorem $\ref{\theorem-17}$, it follows from Lemma $\ref{lemma-4}$ that

$$
  \lVert x\rVert = |\phi_0 (x)| = |\phi(x)| = |\braket{\pi_\phi (x)\mathbf{x}_\phi, \mathbf{x}_\phi\rangle|\leq\lVert\pi_\phi (x)\rVert
$$
</details>
</MathBox>

<MathBox title='' boxType='theorem'>
If $A$ is any C* algebra, there exists an isometric representation $\pi:A\to\mathcal{L}(H)$. If $A$ is separable, we can choose the Hilbert space $H$ to be separable.

<details>
<summary>Proof</summary>

Let $\Set{x_i}_{i\in I}$ be a dense set in $A$. For each $i\in I$, pick a cyclic representation $\pi_i A\to\mathcal{L}(H_i)$ such that $\lVert\pi_i (x_i^* x_i)\rVert = \lVert x_i^* x_i\rVert$, which is possible by Lemma $\ref{lemma-7}$. Note that the C*-identity shows that we have $\lVert\pi_i (x_i)\rVert = \lVert x_i \rVert$ for all $i\in I$.

Let $\pi = \bigoplus_{i\in I} \pi_i$. From Lemma $\ref{lemma-4}$ and the previous argument, it follows that for arbitrary $i,j\in I$, we have $\lVert\pi_j (x_i)\rVert\leq\lVert x_i \rVert = \lVert \pi_i (x_i)\rVert$. Thus, we see that $\lVert\pi(x_i)\rVert = \lVert x_i \rVert$ for all $i\in I$. Since the set $\Set{x_i}_{i\in I}$ is dense in $A$, we conclude that the representation $\pi$ is necessarily isometric.

Suppose now that $A$ is separable. Then, we may assume that $I$ is countable. Furthermore, note that if $\mathbf{x}_i \in H_i$ is a cyclic vector for the cyclic representation $\pi_i$, then it folows that $\Set{\pi_i (x_j)\mathbf{x}_i}_{j\in I}$ is a countable dense set in $H_i$. It follows that each $H_i$ is separable, and since $I$ is countable, also $H$ must be separable.
</details>
</MathBox>

### The Hahn-Hellinger theorem

<MathBox title='' boxType='proposition' tag='proposition-36'>
Let $X$ be a compact metric space. If $\pi:C(X)\to\mathcal{L}(H)$ is any separable representation of $C(X)$, then  there exists a (finite or infinite) countable collection $\Set{\mu_n}_n$ of probability measures on $(X,\mathcal{B}_X)$ such that $\pi$ is equivalent to $\bigoplus_n \pi_{\mu_n}$.  
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-8'>
Let $X$ be a compact metric space and $\mathcal{B}_X$ the Borel subsets of $X$.
1. If $\mu$ and $\nu$ are two probability measures defined on $(X,\mathcal{B}_X)$ which are mutually absolutely continuous, then the representations $\pi_\mu$ and $\pi_\nu$ are equivalent.
2. If $\mu$ and $\nu$ are two finite positive measures defined on $(X,\mathcal{B}_X)$ which are mutually singular, and if we let $\lambda = \mu + \nu$, then $\pi_\mu \cong\pi_\mu \oplus \pi_\nu$.

<details>
<summary>Proof</summary>

**(1):** Let $\phi = (\d\nu / \d\mu)^{1/2}$, and note that by the defining property of the Radon-Nikodym derivative the equation $(U\mathbf{x}) = \phi\mathbf{x}$ for $\mathbf{x}\in H_\nu$, defines an isometric linear operator $U:H_\nu\to H_\mu$, where we write $H_\lambda = L^2 (X,\mathcal{B},\lambda)$.

To see this, note that if $\mathbf{x}\in H_\nu$, then

$$
\begin{align*}
  \lVert U\mathbf{x}\rVert^2 =& \int |\mathbf{x}|^2 \phi^2\;\d\mu = \int |\mathbf{x}|^2 \frac{\d\nu}{\d\mu}\d\mu \\
  =& \int |\mathbf{x}|^2 \d\nu = \lVert\mathbf{x}\rVert^2
\end{align*}
$$

In an identical fashion, if we set $\psi = (\d\mu/\d\nu)^{1/2}$ then the equation $V\nu = \psi\nu$ defines an isometric operator $V:H_\mu \to H_\nu$. However, the uniqueness of the Radon-Nikodym derivative implies that $\psi = \phi^{-1}$, and that $V$ and $U$ are inverses of one another.

Finally, it is easy to deduce from the definitions that

$$
  U\pi_\nu (f)(\mathbf{x}) = \phi f\mathbf{x} = \pi_\mu (f) U\mathbf{x},\; \mathbf{x}\in H_\nu,\; f\in C(X)
$$

In other words, $U$ is a unitary operator which implements the equivalence of the representations $\pi_\nu$ and $\pi_\mu$.

**(2):** By hypothesis, there exists a Borel partition $X = A \sqcup B$ such that $\mu = \mu|_A$ and $\nu = \nu|_B$, where the notation $\mu|_E$ denote the measure defined by $\mu|_E (A) = \mu(E\cap A)$. It is easily seen then that also $\mu = \lambda|_A$ and $\nu = \lambda|_B$. The mapping $H_\lambda \ni f\mapsto (1_A f, 1_B f) \in H_\mu \oplus H_\nu$ is a unitary operator that establishes the desired equivalence of representations. 
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-9'>
Let $\phi\in L^2 (X, \mathcal{B}_X, \mu)$ for a compact metric space $X$. Then there is a sequence $\Set{f_n}_{n\in\N}\subset C(X)$ such that
1. $\sup_n \lVert f_n \rVert_{C(X)} < \infty$
2. the sequence $\Set{f_n (x)}_n$ converges to $\phi(x)$, for $\mu$-almost every $x\in X$.

<details>
<summary>Proof</summary>

Since $C(X)$ is dense in $L^2 (X,\mathcal{B}_X, \mu)$, we may find a sequence $\Set{h_n}_{n\in\N}$ in $C(X)$ such that $\lVert h_n - \phi\rVert_{L^2 (X,\mathbb{B}_X,\mu)} \xrightarrow{n\to\infty} 0$. Since every null convergent sequence in $L^2 (X,\mathcal{B}_X,\mu)$ is known, we can find a subsequence, say $\Set{g_n}_{n\in\N}$ of $\Set{h_n}_{n\in\N}$, such that $g_n (x) \xrightarrow{n\to\infty} \phi(x)$ almost everywhere.

Let $\lVert\phi\rVert_{L^\infty} = K$, and define a continuous "retraction" of $\mathbb{C}$ onto the disc of radius $K+1$ as follows

$$
  r(z) = \begin{cases}
    z,\quad& |z| \leq (K + 1) \\
    \left(\frac{K + 1}{|z|}\right)z, \quad& |z|\geq (K + 1)
  \end{cases}
$$

Finally, consider the continuous functions defined by $f_n = r\circ g_n$. It should be clear that $\lVert f_n \rVert \leq (K + 1)$ for all $n\in\N$, and that $f_n (x) \xrightarrow{n\to\infty} f(x)\mu$ almost everywhere.
</details>
</MathBox>

<MathBox title='Hahn-Hellinger theorem' boxType='theorem' tag='theorem-19'>
Let $X$ be a compact metric space.
1. If $\pi$ is a separable representation of $C(X)$, then there exists a probability measure $\mu$ defined on $(X,\mathcal{B}_X)$ and a collection $\Set{E_n}_{n=1}^\aleph_0$ of pairwise disjoint Borel subsets of $X$ such that
    - a. $\mu$ is supported on $\bigcup_{1\leq n\leq\aleph_0} E_n$
    - 
$$
  \pi\cong\bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu|E_n}^n
$$
2. Suppose $\mu_1$ and $\mu_2$ are two probability measures, and suppose that for each $i=1,2$, we have a collection $\Set{E_n^{(i)}}_{n=1}^\aleph_0$ of pairwise disjoint Borel subsets of $X$ such that $\mu_i$ is supported on $\bigcup_{1\leq n\le\aleph_0} E_n^{(i)}$. Then the following conditions are equivalent:
    - a. The measures $\mu_i$ are mutually absolutely continuous, and further, $\mu_i (E_n^{(1)} \Delta E_n^{(2)}) = 0$ for all $n$ and for $i = 1,2$, where of course, the symbol $\Delta$ has been used to signify the symmetric difference of sets.
    - 
$$
  \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu_1|_{E_n^{(1)}}}^n \cong\bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu_2|_{E_n^{(2)}}}^n
$$

<details>
<summary>Proof</summary>

**(1):** By Proposition $\ref{proposition-36}$, we can find a countable set, say $\Set{\mu_n}_{n\in N}$, of probability measures on $(X,\mathcal{B}_X)$ such that

$$
  \pi\cong\bigoplus_{n\in N} \pi_{\mu_n}
$$

Let $\Set{\epsilon_n}_{n\in N}$ be any set of strictky positive numbers such that $\sum_{n\in N} \epsilon_n = 1$, and define $\mu = \sum_{n\in N} \epsilon_n \mu_n$. The definitions imply the following facts
- I. $\mu$ is a probability measure
- II. if $E\in\mathcal{B}_X$, then $\mu(E) = 0 \iff \mu_n (E) = 0 \forall n\in N$

In particular, it follows from **(ii)** that each $\mu_n$ is absolutely continuous with respect to $\mu$. Thus, if we set $A_n = \Set{x\in X | (\d \mu_n/\d \mu)(x) > 0}$, it follows that $\mu_n$ and $\mu|_{A_n}$ are mutually absolutely continuous. Also, it follows from **(ii)** that $\mu$ is supported on $\bigcup_{n\in N} A_n$. We this find that

$$
  \pi\cong\bigoplus_{n\in N} \pi_{\mu|_{A_n}}
$$

We will find it convenient to make the following assumption: $N = \Set{1,2,\dots,n}$ for some $n\in\N$ if $N is finite$ or $N = \N$ if $N$ is infinite. Let $K = \Set{1,2,\dots,|N|}$, and for each $k\in K$, define

$$
  E_k = \Set{x\in X | \sum_{n\in N} |_{A_n} (x) = k}
$$

Thus, $x\in E_k$ precisely when $x$ belong to exactly $k$ of the $A_i$. In particular, $\Set{E_k}_{k\in K}$ is easily seen to be a Borel partition of $\bigcup_{n\in N} A_n$. By Lemma $\ref{lemma-8}$, it follows that

$$
  \pi \cong \bigoplus_{n\in N} \bigoplus_{k\in K} \pi_{\mu|_{(A_n \cap E_k)}}
$$

Next, for each $n\in N$, $k\in K$, $l\in\N$ such that $1\leq l\leq k$, define

$$
  A_{n,k,l} = \Set{x \in A_n \cap E_k | \sum_{j=1}^n 1_{A_j} (x) = l}
$$

Thus, $x\in A_{n,k,l}$ if and only if $x\in E_k$ and further, $n$ is exactly the $l$-th index $j$ for which $x\in A$, i.e. $x\in A_n \cap E_k$ and there are exactly $l$ values of $j$ for which $1\leq j\leq n$ and $x\in A_j$. By definitions, we have

$$
\begin{align*}
  A_n \cap E_k =& \bigsqcup_{t\in\N, 1\leq l\leq k} A_{n,k,l},\; \forall n\in N, k\in K \\
  E_k =& \bigsqcup_{n\in N} A_{n,k,l},\; \forall k\in K,\; 1\leq l \leq k
\end{align*}
$$

From Lemma $\ref{lemma-8}$ and the preceeding equations, we conclude that

$$
\begin{align*}
  \pi \cong& \bigoplus_{n\in N} \bigoplus_{k\in K} \pi_{\mu|_{(A_n \cap E_k)}} \\
  \cong& \bigoplus_{n\in N} \bigoplus_{k\in K} \bigoplus_{l\in \N, 1\leq l \leq k} \pi_{\mu|_{(A_{n,k,l})}} \\
  \cong& \bigoplus_{k\in K} \bigoplus_{l\in \N, 1\leq 1\leq k} \pi_{\mu|_{E_k}} \\
  \cong& \bigoplus_{k\in K} \pi_{\mu|_{E_k}}^k
\end{align*}
$$

**(2):** Suppose for $i=1,2$ that $\mu^{(i)}$is a probability measure on $(X,\mathcal{B}_X)$, and $\Set{E_n^{(i)}}_{i=1}^{\aleph_0}$ is a collection of pairwise disjoint Borel sets such that $\mu^{(i)}$ is supported on $\bigsqcup_{1\leq n\leq\aleph_0} E_n^{(i)}$, and suppose that

$$
  \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu^{(1)}|_{E_n^{(1)}}}^n \cong \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu^{(2)}|_{E_n}^{(2)}}^n
$$

It follows from the proof of Lemma $\ref{\lemma-11}$ that a choice for the measure associated to the representation

$$
  \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu^{(i)}|_{E_n^{(i)}}}^n
$$

is given by $\mu^{(i)}$ for $i = 1,2$. We may conclude from Lemma $\ref{lemma-11}.2$ that the measures $\mu^{(1)}$ and $\mu^{(2)}$ are mutually absolutely continuous. By Lemma $\ref{lemma-9}.1$, it is seen that $\pi_{\mu^{(1)}|_F}$ is equivalent to $\pi_{\mu^{(2)}|_F}$ for any $F\in\mathcal{B}_X$. Hence, we may assume, without loss of generality, that $\mu^{(1)} = \mu^{(2)} = \mu$. Thus, we need to show that if $\Set{E_n^{(i)}}_{i=1}^{\aleph_0}$ for $i=1,2$ are two collections of pairwise Borel sets such that

$$
\begin{equation}
  \mu\left(X - \bigsqcup_{1\leq n\leq\aleph_0} E_n^{(i)} \right) = 0,\; i = 1,2 \tag{\label{equation-11}}
\end{equation}
$$

and

$$
  \pi_i = \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu|_{E_n^{(1)}}}^n \cong \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu|_{E_n}^{(2)}}^n = \pi_2
$$

then it is the case that $\mu(E_n^{(1)} \Delta E_n^{(2)}) = 0\;\forall 1\leq n\leq\aleph_0$.

Let $H_i$ be the Hilbert space underlying the representation $\pi_i$, and let $U$ be a unitary operator $U:H_1 \to H_2$ such that $U\pi_1 (f) = \pi_2 (f) U$ for all $f\in C(X)$. Then, also $U\tilde{\pi}_1 (\phi) = \tilde{\pi}_2 (\phi) U$ for all $\phi\in L^\infty (X,\mu)$. In particular, we see that

$$
\begin{equation}
  U\tilde{\pi}_1 (1_A) U^* = \tilde{\pi}_2 (1_A)\; \forall A\in\mathcal{B}_X \tag{\label{equation-12}}
\end{equation}
$$

Thus, we need to show that if $1\leq k\neq m\leq\aleph_0$, then $\mu(E_m^{(1)} \cap E_k^{(2)}) = 0$. By equation $\eqref{equation-11}$, this implies that $E_m^{(1)} \subset E_m^{(2)} \mod\mu$. The symmetry of the problem allows us to assume without loss of generality that $1\leq k < m \leq\aleph_0$. Fix $k,m$ as above, and choose a finite integer $n$ such that $k < n \leq m$.

Apply Corollary $\ref{corollary-5}$ to the representation $\pi_1$ and set $E_m^{(1)}$ to deduce the existence of a collection $\Set{p_i}_{i=1}^n$ of pairwise orthogonal projections in $\pi_1 (C(X))'$ such that

$$
\begin{equation}
  p_i = p_i \tilde{\pi}_i (1_{E_m^{(1)}}),\; \forall 1 \leq i \leq n \tag{\label{equation-13}}
\end{equation}
$$

and

$$
\begin{equation}
  F \in \mathcal{B}_X,\; \mu(F\cap E_m^{(1)}) > 0 \implies p_i \tilde{\pi}_1 (1_F) \neq 0,\; \forall 1\leq i\leq n \tag{\label{equation-14}}
\end{equation}
$$

Setting $q_i = Up_i U^*$, it follows from $\eqref{equation-12}$ that $U\pi_1 (C(X))' U^* = \pi_2 (C(X))'$. Consequently, $\eqref{equation-13}$ and $\eqref{equation-14}$ translate into the fact that $\Set{q_i}_{i=1}^n$ is a collection of pairwise orthogonal projections in $\pi_2 (C(X))'$ such that

$$
  q_i = q_i \tilde{\pi}_2 (1_{E_m^{(1)}}),\; \forall 1\leq i\leq n
$$

and

$$
  F\in\mathcal{B}_X,\; \mu(F\cap E_m^{(1)}) > 0 \implies p_i \tilde{\pi}_2 (1_F) \neq 0,\; \forall 1\leq i \leq n
$$

Applying Corollary $\ref{corollary-5}$ to the representation $\pi_2$ and the set $E_m^{(1)}$, it follows that $\mu(E_m^{(1)} \cap E_k^{(2)}) = 0$.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-11'>
Let $X$ be a compact metric space, and  $H$ a separable Hilbert space. 
1. If $\pi:C(X)\to\mathcal{L}(H)$ is a representation, there exists a probability measure $\mu$ defined on $\mathcal{B}_X$, and a representation $\tilde{\pi}:L^\infty (X, \mathcal{B}_X, \mu)\to\mathcal{L}(H)$ such that
    - a. $\tilde{\pi}$ is isometric
    - b. $\tilde{\pi}$ extends $\pi$ in the sense that $\tilde{\pi}(t) = \pi(f)$ whenever $f\in C(X)$
    - c. $\tilde{\pi}$ respects bounded convergence, meaning that whenever $\phi$ is the $\mu$-almost everywhere limit of a sequence $\Set{\phi_n}_{n\in\N}\subset L^\infty (X,\mu)$, which is uniformly bounded, i.e. $\sup_{n\in\N} \lVert\phi_n \rVert_{L^\infty (\mu)} < \infty$, then it is the case that the sequence $\Set{\tilde{\pi}(\phi_n)}_{n\in\N}$ converges in the strong operator topology to $\tilde{\pi}(\phi)$.
2. Suppose that $\tilde{\pi}_i : L^\infty (X,\mathcal{B}_X,\mu_i) \to \mathcal{L}(H_i)$ for $i=1,2$ is a representation which is related to a representation $\pi_i:C(X)\to\mathcal{L}(H_i)$ as in **(1)** above. If $\pi_1 \cong\pi_2$, then the measures $\mu_1$ and $\mu_2$ are mutually absolutely continuous.

<details>
<summary>Proof</summary>

**(1):** First consider the case when $\pi$ is a cyclic representation. Then there exists a probability measure $\mu$ such taht $\pi\cong\pi_\mu$. Take this $\mu$ as the measure in the statement of **(a)** and define $\tilde{\pi}$ to be the natural multiplication representation defined by $\tilde{\pi}(\phi)\mathbf{x} = \phi\mathbf{x}$ for all $\phi\in L^\infty (\mu)$ and $\mathbf{x}\in L^2 (\mu)$. Then we see that **(a)** is is obvious, while **(c)** is an immediate consequence of the dominated convergence theorem. 

As for **(a)**, suppose $\phi\in L^\infty (\mu)$ and $\epsilon > 0$. If $E=\Set{x : |\phi(x)|\geq \lVert\phi\rVert - \epsilon}$. Thus, if $\mathbf{x} = \mu(E)^{-1/2} 1_E$, we find that $\mathbf{x}$ is a unit vector in $L^2 (\mu)$ such that $\lVert\tilde{\pi}(\phi)\mathbf{x}\rVert\geq\lVert\phi\rVert - \epsilon$. The validity of **(1)**, at least in the cyclic case under consideration, follows from the arbitrariness of $\epsilon$ and from Lemma $\ref{lemma-4}$ applied to the C* algebra $L^\infty (\mu)$. 

For general (separable) $\mu$, we may assume without loss of generality that $\pi = \bigoplus_{n\in N} \pi_{\mu|_{E_n}}^n$ by the Hahn-Hellinger theorem (Theorem $\ref{theorem-19}.1$). Then define $\tilde{\pi} = \bigoplus_{n\in\N} = (\tilde{\pi}_{\mu|_{E_n}})^n$ where the summands are defined as above. Since $\mu$ is supported on $\bigcup_{n\in\N} E_n$ by Theorem $\ref{theorem-19}.1.b$, and since $\tilde{\pi}_{\mu|_{E_n}}$ is an isometric map of $L^\infty (E_n, \mu|_{E_n})$, it is fairly easy to deduce that $\tilde{\pi}$ is an isometric *-homormophism of $L^\infty (X,\mu)$, thus establishing **(1.a)**. The assertion **(b)** follows immediately from the definition and the already established cyclic case.

As for **(c)**, note that the Hilbert space underlying the representation $\tilde{\pi}$ is of the form 

$$
  H = \bigoplus_{1\leq n\leq\aleph_0} \bigoplus_{1\leq m\leq n} H_{n,m}
$$

where $H_{n,m} = L^2 (E_n, \mu|_{E_n})$ for all $1\leq m \leq n \leq\aleph_0$. Thus, if $\Set{\phi_k}_{k,\phi}$ are as in **(b)**, we see that $\pi(\phi_k)$ has the form 

$$
  x^{(k)} = \bigoplus_{1\leq m\leq n\leq\aleph_0} x_{n,m}^{(k)}
$$

where $x_{n,m}^(k) = \tilde{\pi}_{\mu|_{E_n}} (\phi_k)$ for $1\leq m\leq n\leq\aleph_0$. Similarly, $\tilde{\pi}(\phi)$ has the form 

$$
  x = \bigoplus_{1\leq m\leq n\leq\aleph_0} x_{n,m}
$$

where $x_{n,m} = \tilde{\pi}_{\mu|_{E_n}} (\phi)$ for $1\leq m\leq n\leq\aleph_0$. The assumption that $\sup_k \lVert\phi_k \rVert < \infty$ shows that the sequence $\Set{x^{(k)}}_k$ is uniformly bounded in norm. Furthermore, if we let $S = \bigcup_{1\leq m\leq n\leq\aleph_0} H_{n,m}$, where we naturally regard the $H_{n,m}$ as subspaces of $H$, then we find that $S$ is a total set in $H$ and that $x^{(k)} \mathbf{x} \xrightarrow{k\to\infty} x\mathbf{x}$ whenever $\mathbf{x}\in S$ (by the already established cyclic case). Thus, we may deduce from Lemma $\ref{lemma-0}$ that the sequence $\Set{x^{(k)}}$ converges strongly to $x$.

**(2):** Suppose $U:H_1 \to H_2$ is a unitary operator such that $U\pi_1 (f)U^* = \pi_2 (f)$ for all $f\in C(X)$. Define $\mu = \frac{1}{2}(\mu_1 + \mu_2)$, and note that both $\mu_1$ and $\mu_2$ are absolutely continuous with respect to $\mu$. Let $\phi$ be any bounded measurable function on $X$. By Lemma $\ref{lemma-9}$, we may find a sequence $\Set{f_k}_l \subset C(X)$ such that $\sup_k \lVert f_k \rVert < \infty$ and such that $f_k (x) \to \phi(x)$ for all $x\in X\setminus N$ where $\mu(N) = 0$. Then also $\mu_i (N) = 0$ for $i=1,2$. Hence, by the assumed property of the $\tilde{\pi}_i$, we find that $\Set{\pi_i (f_k)}_k$ converges in the strong operator topology to $\tilde{\pi}_i (\phi)$. From the second intertwining nature of the unitary operator $U$, we may deduce that $U\tilde{\pi}_1 (\phi) U^* = \tilde{\pi}_2 (\phi)$ for every bounded measurable function $\phi: X\to\mathbb{C}$. In particular, we see that

$$
  U\tilde{\pi}_1 (1_E)U^* = \tilde{\pi}_2 (1_E),\; \forall E\in\mathcal{B}_X
$$

Since the $\tilde{\pi}_i$ are isometric, we find that, for $E\in\mathcal{B}_X$

$$
\begin{align*}
  \mu_1 (E) = 0 \iff& \tilde{\pi}_1 (1_E) = 0 \\
  \iff& \tilde{\pi}_2 (1_E) \\
  \iff& \mu_2 (E) = 0
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-12'>
If $\pi$, $\mu$ and $\tilde{\pi}$ are as in Lemma $\ref{lemma-11}.1$, then

$$
  (\pi(C(X)))'' = \tilde{\pi}(L^\infty (X,\mu))
$$

Thus, $\tilde{\pi}(L^\infty (X,\mu))$ is the von Neumann algebra generated by $\pi(C(X))$.

<details>
<summary>Proof</summary>

Introducing $A = \pi(C(X))$, $M = \tilde{\pi}(L^\infty(X,\mu))$, we need to show that $M = A''$. Since $A$ is clearly commutative, it follows that $A\subset A'$. Since $A$ is a unital *-subalgebra of $\mathcal{L}(H)$, and since $A'$ is closed in the strong operator topology, we may conclude from the preceding inclusion and von Neumann's density theorem (Theorem $\ref{theorem-16}$) that we must have $A'' \subset A'$.

By Lemma $\ref{lemma-9}$, Lemma $\ref{lemma-11}.1.c$ and Theorem $\ref{theorem-16}$, we necessarily have $M\subset A''$. Thus, we find that we always have 

$$
\begin{equation}
  M \subset A'' \subset A' \tag{\label{equation-7}}
\end{equation}
$$

**Case 1: $\pi$ is cyclic**

In this case, we asert that we actually have $A' = A'' = M$. We may assume that the underlying Hilbert space is $H = \mathcal{L}^2 (X,\mu)$, and that $\tilde{\pi}$ is the multiplication representation of $L^\infty (X,\mu)$. In view of $\eqref{equation-7}$, we need to show that $A' \subset M$.

Suppose $x\in A'$. We want to show that $x = \tilde{\pi}(\phi)$, for some $\phi\in L^\infty (X,\mu)$. Note that if this were true, it must be the case that $\phi = x\mathbf{x}_\mu$, where $\mathbf{x}_\mu$ denotes the constant function $1$. Definining $\phi = x\mathbf{x}_\mu$, we need to show that $L^\infty (X,\mu)$ and that $x = \tilde{\pi}(\phi)$. From the inclusion $\eqref{equation-7}$, we have for arbitray $\psi\in L^\infty (X,\mu)$ that

$$
  x\psi = x\tilde{\pi}(\psi)\mathbf{x}_\mu = \tilde{\pi}(\psi)x\mathbf{x}_\mu = \tilde{\pi}(\psi)\phi = \phi\psi
$$

Furthermore, if we set $E_r = \Set{x \in X : |\phi(s)| > r}$, then $r1_{E_r} \leq |\phi|1_{E_r}$, and consequently

$$
\begin{align*}
  \mu(E_r)^{1/2} =& \lVert 1_{E_r} \rVert_H \\
  \leq& \frac{1}{r}\lVert\phi 1_{E_r} \rVert_H \\
  =& \frac{1}{r}\lVert x 1_{E_r} \rVert_H \\
  \leq& \frac{1}{r} \lVert x \rVert_{\mathcal{L}(H)} \cdot \lVert 1_{E_r} \rVert_H
\end{align*}
$$

which clearly implies that $\mu(E_r) = 0$ for all $r > \lVert x\rVert_{\mathcal{L}(H)}$. In other words, $\phi\in L^\infty (X,\mu)$. However, then $x$ and $\tilde{\pi}(\phi)$ are two bounded operators on $H$ that agree on the dense set $L^\infty (X,\mu)$, and hence $x = \tilde{\pi}(\phi)$ as desired.

**Case 2: $\pi = \pi_\mu^n$ for some $1\leq n\leq\aleph_0$**

We may assume that $H = H_\mu^n$ is the Hilbert space direct sum of $n$ copies of $H_\mu = L^2 (X,\mu)$. Moreover, we may identify an operator $x$ on $H_\mu^n$ with its representing matrix $((x(i,j)))$, where $x(i,j)\in\mathcal{L}(H_\mu)$ for all $i,j\in\N$ such that $1\leq i$ and $j\leq n$. In the notation of the proof of Theorem $\ref{theorem-16}$, we find that $A = \pi_\mu (C(X))^{(n)} = \Set{x^{(n)} : x\in\pi_\mu (C(X))}$, where $x^{(n)} = [x\delta_i^j]$.

Arguing exactly as in the proof of Theorem $\ref{theorem-16}$, and using the fact that $\pi_\mu (C(X))' = \tilde{\pi}_\mu (L^\infty (X,\mu))$ from **Case 1**, we find that $y\in A'$ precisely when the entries of the representing matrix satisfy $y(i,j) = \tilde{\pi}_\mu (\phi_{i,j})$ for all $i, j$ and for some collection $\Set{\phi_{i,j} | 1\leq i, j\leq n}\subset L^\infty (X,\mu)$. Again, arguing as in proof of Theorem $\ref{theorem-16}$, and using the fact that $\tilde{\pi}_\mu (L^\infty (X,\mu))'' = \tilde{\pi}_\mu (L^\infty (X,\mu))$ from **Case 1**, we find that $A'' = \Set{z^{(n)} | z\in\tilde{\pi}_\mu (L^\infty (X,\mu))}$. In other words, this says exactly that $A'' = \tilde{\pi}_\mu^n (L^\infty (X,\mu)) = M$.

**Case 3: $\pi$ arbitrary**

By Theorem $\ref{theorem-19}.1$, we may assiume, as in the notation of that theorem, that

$$
  \pi = \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu|_{E_n}}^n
$$

Let $p_n = \tilde{\pi}(1_{E_n})$ for $1\leq n\leq\aleph_0$, and let $H_n = \operatorname{ran}(p_n)$, so that the Hilbert space underlying the representation $\pi$ (as well as $\tilde{\pi}$) is given by $H = \bigoplus_{1\leq n\leq\aleph_0} H_n$.

By $\eqref{equation-7}$, we see that $p_n \in A'' \subset A'$. This measn that any operator in $A'$ has the form $\oplus_n x_n$ with $x_n \in \mathcal{L}(H_n)$. In fact, it is not hard to see that in order that such a direct sum operator belongs to $A'$, it is necessary and sufficient that $x_n \in \pi_{\mu|_{E_n}}^n (C(X))'$ for all $1\leq n\leq\aleph_0$. From **Case 2**, there must exist $\phi_n \in L^\infty (E_n, \mu|_{E_n})$ such that $z_n = \tilde{\pi}_{\mu|_{E_n}}^n (\phi_n)$ for all $1\leq n\leq\aleph_0$.

In order for $\oplus_n z_n$ to be bounded, it must be the ase that the collection $\Set{\lVert z_n \rVert = \lVert\phi_n \rVert_{L^\infty (E_n, \mu|_{E_n})}}$ be uniformly bounded, or equivalently, that the equation $\phi = \sum_n 1_{E_n} \phi_n$ define an element of $L^\infty (X,\mu)$. In other words, we have shown that an operator belongs to $A''$ if and only if it has the form $z = \tilde{\pi}(\phi)$ for some $\phi\in L^\infty (X,\mu)$, i.e. $A'' \subset M$.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-13'>
Let $\pi = \pi_\mu^n$ and $H = H_\mu^n$ denote the Hilbert space direct sum of $n$ copies of $H_\mu = L^2 (X,\mu)$, where $1\leq n\leq\aleph_0$. Consider the following conditions on a collection $\Set{p_i}_{i\in I} \subset\mathcal{L}(H)$ for an index set $i\in I\subseteq\N$:
- a. $\Set{p_i}_{i\in I}$ is a collectin of pairwise orthogonal projections in $\pi(C(X))'$
- b. if $F\in\mathcal{B}_X$ is any Borel set such that $\mu(F) > 0$, and if $\tilde{\pi}$ is associated to $\pi$ as in Lemma $\ref{lemma-11}$, then $p_i \tilde{\pi}(1_F) \neq 0$ for all $i\in I$.

1. There is a collection $\Set{p_i}_{i\in I}$ which satisfies **(a)** and **(b)**, such that $|I| = n$.
2. If $n < \infty$ and if $\Set{p_i}_{i\in I}$ is any collection satisfying **(a)** and **(b)**, then $|I| \leq n$.

<details>
<summary>Proof</summary>

Note that since $H = H_\mu^n$, we may identity operators on $H$ with their representing matrices $((x(i,j)))$, where $x(i,j)\in\mathcal{L}(H_\mu)$ for all $1\leq i$ and $j\leq n$. Furthermore, $A = \pi(C(X))$ consists of those operators $x$ whose matrices satisfy $x(i,j) = \delta_{i,j} \pi_\mu (f)$ for some $f\in C(X)$. The proof of **Case 2** in Lemma $\ref{lemma-12}$ shows that $A'$ consists of precisely those operators $y\in\mathcal{L}(H)$ whose matrix entries satisfy $y(i,j)\in\pi_\mu (C(X))' = \tilde{\pi}_{\mu} (L^\infty (X,\mu))$.

1. For $1\leq m\leq n$, define $p_m (i, j) = \delta_{i,j} \delta_{i,m} 1_{H_\mu}$. We have already established that $\Set{p_m}_{m=1}^n$ is a collection of pairwise orthogonal projections in $A'$, which satisfy **(a)**. If $F$ is as in **(b)**, note that $\tilde{\pi}(1_F)$ is the projection $q\in\mathcal{L}(H)$ whose matrix is given by $q(i,j) = \delta_{i,j} \tilde{\pi}_\mu (1_F)$, and it follows that for any $1\leq m\leq n$, the operator $p_m q$ is not zero, since it has the non-zero entry $\tilde{\pi}_\mu (1_F)$ in the $(m, m)$-th place.

2. In order to prove that $|I|\leq n < \infty$, it is enough to show that $|I_0| \leq n$ for every finite subset $I\subset I$. Thus, we may assume without loss of generality that $I$ is a finite set.

Suppose $\Set{p_m}_{m\in I}$ is a collection of pairwise orthogonal projections in $A'$ that satisfies **(b)**. We can find a collection $\Set{\phi_m (i,j) | m\in I,\; 1\leq i,\; j\leq n}\subset L^\infty (X,\mu)$ such that the matrix of the projection $p_m$ is given by $p_m (i,j) = \tilde{\pi}_\mu (\phi_m (i,j))$. We then see that

$$
  p_m = p_m p_m^* \implies p_m (i,i) = \sum_{j=1}^n p_m (i,j) p_m (i,j)^*,\; \forall i\in I
$$

By definition of $\phi_m (i,j)$ and the fact that $\tilde{\pi}$ is a *-homomorphism, it is fairly easy to deduce no, that we must have

$$
\begin{equation}
\begin{gathered}
  \phi_m (i,i) = \sum_{j=1}^n |\phi_m (i,j)|^2 \; \text{a.e.} \\
  \forall 1\leq i\leq n,\; \forall m\in I
\end{gathered} \tag{\label{equation-8}}
\end{equation}
$$

In a similar fashion, if $m,k\in I$ and if $m \neq k$, then notice that

$$
\begin{align*}
  p_m p_k = 0 \implies& p_m p_k^* = 0 \\
  \implies& \sum_{j=1}^n p_m (i, j) p_k (l, j)^* = 0,\; \forall i,l \in I
\end{align*}
$$
which is seen to imply, as before, that

$$
\begin{equation}
\begin{gathered}
  \sum_{j=1}^n \phi_m (i,j)\overline{\phi_k (l,j)} = 0\;\text{a.e.} \\
  \forall 1\leq i, l\leq n,\;\forall m\neq k\in I
\end{gathered} \tag{\label{equation-9}}
\end{equation}
$$

Since $I$ is finite, as in $n$, and since the union of a finite number of sets of measure zero is also a set of measure zero, we may assume that the functions $\phi_m (i,j)$ satisfy the conditions expressed in $\eqref{equation-8}$ and $\eqref{equation-9}$ everywhere. Thus, we assume that the following equations hold pointwise at every point of $X$

$$
\begin{equation}
\begin{gathered}
  \sum_{j=1}^n |\phi_m (i,j)|^2 = \phi_m (i,i) \\
  \forall 1\leq i \leq n,\;\forall m\in I \\
  \sum_{j=1}^n \phi_m (i,j)\overline{\phi_k (l,j)} = 0 \\
  \forall 1\leq i,l\leq n,\forall m\neq k \in I
\end{gathered}\tag{\label{equation-10}}
\end{equation}
$$

Now, for each $m\in I$, define $F_m = \Set{x\in X | (\phi_m (i,i))(s) = 0,\forall 1\leq i\leq n}$. If $s\notin F_m$ we can pick an index $1\leq i_m \leq n$ such hat $(\phi_m (i_m, i_m))(s) \neq 0$. Thus, if it is possible to pick a point $s$ which does not belong to $F_m$ for all $m\in I$, then we could find vectors

$$
  v_m = \begin{bmatrix}
    (\phi_m (i_m, 1))(s) \\
    \vdots \\
    (\phi_m (i_m, n))(s)
  \end{bmatrix},\; m\in I
$$

which would constitute a set of non-zero vectors in $\mathbb{C}^n$ which are pairwise orthogonal in view of equations $\eqref{equation-10}$. This would show that $|I| \leq n$.

Our proof will be complete once we know that $X\neq \bigcup_{m\in I} F_m$. We make the even stronger assertion that $\mu(F_m) = 0\;\forall m$. Note that if $s\in F_m$, then $\phi_m (i,i)(s) = 0$ for all $1\leq i\leq n$. However, then by equation $\eqref{equation-8}$, we find that $\phi_m (i,j)(s) 0\; \forall 1\leq i,j\leq n$. This implies that $\phi_m (i,j) 1_F = 0\;\text{a.e.}\;\forall 1\leq i, j\leq n$. It follows that every entry of the matrix representing the operator $p_m \tilde{\pi}(1_F)$ is $0$. However, by the assumption that the collection $\Set{p_m}_{m\in I}$ satisfies condition **(b)**, this can happen only if $\mu (F_m) = 0$.
</details>
</MathBox>

<MathBox title='' boxType='corollary' tag='corollary-5'>
Let 

$$
  \pi = \bigoplus_{1\leq n\leq\aleph_0} \pi_{\mu|_{E_n}}^n
$$

Suppose $A\in\mathcal{B}_X$ for a compact metrix space $X$ is such that $\mu(A) > 0$, and let $1\leq n < \infty$. Then the following conditions on $A$ are equivalent:
1. There exists a collection $\Set{p_i}_{i=1}^n$ of pairwise orthogonal projections in $\pi(C(X))'$ such that
    - a. $p_i = p_i \tilde{\pi}(1_A)\;\forall 1\leq i\leq n$
    - b. $F\in\mathcal{B}_X, \mu(A\cap F) > 0 \implies p_i \tilde{\pi}(1_F) \neq 0\; \forall 1\leq i\leq n$
2. $A\subset \bigsqcup_{n\leq m\leq\aleph_0} E_m \mod\mu$, or equivalently, $\mu(A\cap E_k) = 0\;\forall 1\leq k\leq n$.

<details>
<summary>Proof</summary>

If we write $e_n = \tilde{\pi}(1_{E_n})$, it is seen that any projection $p \in \pi(C(X))'$ has the form $p = \sum_n q_n$, where $q_n = pe_n$ is an element of $\pi_{\mu|_{E_n}}^n (C(X))'$ when thought of as an operator on $e_n H$.

**(1)$\implies$(2):** Fix $1\leq k < \infty$, and suppose $\mu(A\cap E_k) \neq 0$. Setting $q_i = p_i e_k$, we can apply Lemma $\ref{lemma-13}.2$ to the representation $\pi_{\mu|_{A\cap E_k}}^k$ and the collection $\Set{q_i}_{i=1}^n$ to conclude that $n\leq k$. In other words, if $1\leq k < n$, then $\mu(A\cap E_k) = 0$. 


**(2)$\implies$(1):** Fix any $m\geq n$ such that $\mu(A\cap E_m) > 0$. Applying Lemma $\ref{lemma-13}.1$ to the representation $\pi_{\mu|_{A\cap E_m}}^m$, we establish the existence of a collection $\set{q_i^{(m)}}_{i=1}^m$ of pairwise orthogonal projections in $\pi_{\mu|_{A\cap E_m}}^m (C(X))'$ with the property that $q_i^{(m)} \tilde{\pi}_{\mu|_{A\cap E_m}}^m (1_F) \neq 0$ whenever $F$ is a Borel subset of $A\cap E_m$ such that $\mu(F) > 0$. We can regard each $q_i^{(m)}$ as a projection in the big ambient Hilbert space $H$, such that $q_i^{(m)} = q_i^{(m)} \tilde{\pi}(1_{A\cap E_m})$, so that $q_i^{(m)} \in\pi(C(X))'$. If we define for $1\leq i\leq n$

$$
  p_i = \sum_{\substack{n\leq m\leq\aleph_0 \\ \mu(A\cap E_m) > 0}} q_i^{(m)}
$$

it is clear that $\Set{p_i}_{i=1}^n$ is a family of pairwise orthogonal projections in $\pi(C(X))'$, and that $p_i = p_i \tilde{\pi}(1_A)\;\forall l1\leq i\leq n$. Furthermore, if $F\in\mathcal{B}_X$ satisfies $\mu(A\cap F) > 0$, then there must exist $m\geq n$ such that $\mu(A\cap F\cap E_m) > 0$ because $\mu(A\cap E_k) = 0\; \forall 1\leq k < n$. In this case, note that $(p_i \tilde{\pi}(1_F))\tilde{\pi}(1_{A\cap E_m}) = q_i^{(m)}\tilde{\pi}(1_{A\cap F\cap E_m})$ which is non-zero by the way in which the $q_i^{(m)}$ were chosen. Hence it must be that $p_i \tilde{\pi}(1_F) \neq 0$. 
</details>
</MathBox>

# Linear operators

<MathBox title='Linear operator' boxType='definition'>
Let $(X, \lVert \cdot\rVert_X)$ and $(Y, \lVert \cdot\rVert_Y)$ be two normed spaces. An operator $T: X \to Y$ is linear if it is closed under addition and scalar multiplication

$$
\begin{gather*}
  T(x + \tilde{x}) = Tx + T\tilde{x} \\
  T(\lambda x) = \lambda T x
\end{gather*}
$$

for all $x, \tilde{x} \in X$ and $\lambda \in \mathbb{F}$. The operator norm of $T$ is defined as

$$
  \lVert T\rVert = \lVert T\rVert_{X\to Y} := \sup\Set{ \frac{\lVert T_X\rVert_Y}{\lVert X\rVert_X} | x \in X\setminus\Set{0}}
$$
</MathBox>

## Bounded operators

<MathBox title='Bounded operator' boxType='definition'>
Let $T\in\mathcal{L}(X,Y)$ be a linear operator between normed spaces $X$ and $Y$. If there exists some $M > 0$ such that $\lVert T x\rVert_Y \leq M\lVert x\rVert_X  < \infty$ for all $x \in X$, then $T$ is a bounded operator with operator norm $M$. The set of all linear and bounded operators $T: X \to Y$ is denoted $\mathcal{B}(X, Y)$.

If $W$ is a subspace of $X$, then $T$ is *bounded below* on $W$ if there exists $\epsilon > 0$ such that $\lVert Tx\rVert\geq\epsilon\lVert x \rVert$ for all $x\in W$. 
</MathBox>

<MathBox title='The space of bounded linear operators is Banach' boxType='proposition'>
Let $X$ and $Y$ be normed spaces, where $X$ is also a Banach space. The space $\mathcal{B}(X,Y)$ of bounded linear operators from $X$ to $Y$ is a Banach space when equipped with the induced norm $\lVert\cdot\rVert_{X\to Y}$.

<details>
<summary>Proof</summary>

Since $\mathcal{B}(X,Y)$ is a normed space, it remains to show that is complete. Let $(A_k)_{k\in\N_+}$ be a Cauchy sequence in $\mathcal{B}(X,Y)$. We show that the Cauchy sequence converges in three steps.

**(1):** We construct a candidate function $A:X\to Y$ for the limit of the Cauchy sequence. For $\epsilon > 0$ there is $N\in\N$ such that

$$
  \sup\Set{\frac{\lVert A_m (x) - A_n (x) \rVert_Y}{\lVert x \rVert_X} | x\in X\setminus\Set{0}} = \lVert A_m - A_n \rVert_{X\to Y} < \epsilon
$$

whenever $m, n \geq N$. Thus, for each nonzero $x\in X$ we have

$$
  \lVert A_m (x) - A_n (x) \rVert_Y < \epsilon\lVert x \rVert_X
$$

This says that for each fixed nonzero $x\in X$, the sequence $(A_n (x))_{n\in\N_+}^\infty$ is Cauchy in $Y$. Since $Y$ is a Banach space, the sequence $(A_n (x))_{n\in\N_+}$ converges to an element $A(x)\in Y$. We define $A(0) = 0$, giving a function $A:X\to Y$.

**(2):** We show that $A\in\mathcal{B}(X,Y)$. The function $A$ is linear because for $\alpha, \beta\in\mathbb{F}$

$$
\begin{align*}
  A(\alpha x_1 + \beta x_1) =& \lim_{k\to\infty} A_n (\alpha x_1 + \beta x_2) \\
  =& \lim_{k\to\infty} (\alpha A_k (x_1) + \beta A_k (x_2)) \\
  =& \alpha A(x_1) + \beta A(x_2)
\end{align*}
$$

We show that $A$ is bounded. For $\epsilon > 0$ there is $N\in\N$ such that $\lVert A_m - A_n \rVert_{X\to Y} < \epsilon$ whenever $m,n \geq N$. This implies that for all $x\in X$

$$
  \lVert A_m (x) - A_n (x) \rVert_Y \leq \lVert A_n - A_m \rVert_{X\to Y} \cdot\lVert x \rVert_X < \epsilon\lVert x \rVert_X
$$

Taking the limit $m\to\infty$ and using the continuity of the norm we get

$$
  \lVert A(x) - A_n (x) \rVert_Y \leq \epsilon\lVert x \rVert_X
$$

By the triangle inequality, we have for any $n\geq N$ that

$$
\begin{align*}
  \lVert A(x) \rVert_Y \leq& \lVert A(x) - A_n (x)\rVert_Y + \lVert A_n (x) \rVert \\
  \leq& \lVert x \rVert_X + \lVert A_n \rVert_{X\to Y} \cdot \lVert x \rVert_X \\
  =& (\epsilon + \lVert A_n \rVert_{X\to Y})\lVert X \rVert_X
\end{align*}
$$

Since $(A_n)_{n\in\N_+}$ is Cauchy, it is bounded by Proposition $\ref{proposition-6}$. Thus, there is $M > 0$ such that $\lVert A_n \rVert_{X\to Y} \leq M$ for all $n\in\N$. This implies that

$$
  \lVert A(x) \rVert_Y \leq (\epsilon +  M)\lVert X \rVert_X
$$

and also that

$$
  \lVert A \rVert_{X\to Y} = \sup\Set{\frac{\lVert A(x) \rVert_Y}{\lVert x \rVert_X} | x\in X\setminus\Set{0}} \leq (\epsilon + M)
$$

Hence $A$ is bounded.

**(3):** We show that $\lim_{k\to\infty} \lVert A - A_k \rVert_{X\to Y} = 0$. We established in **(2)** that for $\epsilon > 0$ there is $N\in\N$ such that $\lVert A(x) - A_n (x) \rVert_Y < \epsilon\lVert x \rVert_X$ whenever $n \leq N$.

This implies that for each nonzero $x$ and for all $n\geq N$ that

$$
  \frac{\lVert A(x) - A_n (x)\rVert_Y}{\lVert x \rVert_X} < \epsilon
$$

Taking the supremum of the left-hand side gives

$$
  \lVert A - A_n \rVert_{X\to Y} \leq\epsilon
$$

Hence, $(A_n)_{n\in\N_+}$ converges to $A$ in the norm $\lVert\cdot\rVert_{X\to Y}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-18'>
A linear normed operator is bounded if and only if it is continuous.

<details>
<summary>Proof</summary> 

Suppose $T$ is bounded. Then for a sequence $\left(x_n \right)_{n\in\N} \subseteq X$ with limit $\tilde{x} \in X$ we have

$$
  \lVert Tx_n - T\tilde{x}\rVert_Y = \lVert T(x_n - \tilde{x})\rVert_Y \leq M \lVert x_n - \tilde{x}\rVert_X \xrightarrow{n\to\infty} 0
$$

which shows that $T$ is continuous. Conversly, suppose $T$ is continuous. Then there exists $\delta > 0$ such that $\lVert Tx\rVert_Y < 1$ for all $x \in X$ with $\lVert x\rVert_X < \delta$, thus

$$
  \lVert Tx\rVert_Y = \left\lVert \frac{\| x\rVert}{\delta} T\left( \delta \frac{x}{\lVert x\rVert} \right) \right\lVert = \frac{\| x\rVert}{\delta} \left\lVert T\left( \delta \frac{x}{\| x\rVert} \right) \right\lVert \leq \frac{\| x\rVert}{\delta} < \infty
$$
</details>
</MathBox>

<MathBox title='Norm-preserving linear extension of bounded operators' boxType='theorem'>
Let $X$ and $Z$ be normed spaces, $S\subseteq Z$ a subspace of $Z$ with norm $\lVert\cdot\rVert_Z$. If $T\in\mathcal{B}(S,Z)$ is a bounded linear operator, a norm-preserving extension of $T$ is a bounded linear operator $\overline{T}\in\mathcal{Z,X}$ such that $\overline{T}(s) = T(s)$ for all $s\in S$ and $\lVert\overline{T}\rVert_{Z\to Y} = \lVert T \rVert_{S\to Z}$.
</MathBox>

<MathBox title='Continuous linear extension theorem' boxType='theorem' tag='theorem-9'>
Let $Z$ be a normed space, $S\subseteq Z$ a dense subset of $Z$ and $X$ a Banach space. If $T\in\mathcal{B}(S,X)$, then $T$ has a unique norm-preserving extension $\overline{T}\in\mathbb{B}(Z,X)$.

<details>
<summary>Proof</summary>

Since $S$ is dense in $Z$, there is for each $z\in Z$ a Cauchy sequence $(s_k)_{k\in\N_+}$ in $S$ such that $\lim_{k\to\infty} \lVert z - s_k \rVert_Z = 0$. Since $T\in\mathcal{B}(S,X)$, the operator $T$ is uniformly continuous on $S$ (Proposition $\ref{proposition-18}$). Thus, the sequence $(T(s_k))_{k\in\N_+}$ is Cauchy in $X$. This sequence converges because $X$ is a Banach space. For each $z\in Z$ we define $\overline{T}:Z\to X$ by $\overline{T}(z) = \lim_{k\to\infty} T(s_k)$. Note that for $s\in S$ we get $\overline{T}(s) = T(s)$ by the continuity of $T$.

Because we have used a sequence to define $\overline{T}$ we cannot assume that $\overline{T}$ is well-defined. For $\epsilon > 0$, there is $K_1 \in\N$ such that $\lVert\overline{T}(z) - T(s_k)\rVert_X < \epsilon/2$ whenever $k \geq K_1$. Suppose $(s'_k)_{k\in\N_+}$ is another sequence in $S$ converging to $z$. By the uniform continuity of $T$ on $S$, for each $\epsilon < 0$ there is $\delta > 0$ such that $\lVert T(a) - T(b) \rVert_X < \epsilon/2$ when $\lVert a - b \rVert_S < \delta$. For this $\delta > 0$, there exists $K_2, K_3 \in\N$ such that $\lVert s_k - Z \rVert_Z < \delta$ when $k \geq K_2$ and $\lVert s'_k - z \rVert_Z < \delta$ when $k \geq K_3$.

Choose $K = \max\Set{K_1,K_2,K_3}$, then $\lVert s_k - z \rVert_Z < \delta$ and $\lVert s'_k - z \rVert < \delta$ whenever $k \geq K$. Thus, we obtain

$$
\begin{align*}
  \lVert T(s'_k) - \overline{T}(z)\rVert_X \leq& \lVert T(s'_k) - T(s_k) \rVert + \lVert T(s_k) - \overline{T}(z) \rVert_X \\
  < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon 
\end{align*}
$$

whenever $k \geq K$. This implies that $\lim_{k\to\infty} T(s'_k) \to\overline{T}(z)$, so that $\overline{T}(z)$ is well-defined.

Next, we show that $\overline{T}$ is linear. For $(s_k)_{k\in\N_+}$ in $S$ converging to $z\in Z$ and $(\tilde{s}_k)_{k\in\N_+}$ in $S$ converging to $\tilde{z}\in Z$ and $\alpha, \beta \in\mathbb{F}$ we have

$$
  \overline{T}(\alpha z + \beta\tilde{z}) - \alpha\overline{T}(z) - \beta\overline{T}(\hat{z}) =& \lim_{k\to\infty} (T(\alpha s_k + \beta\tilde{s}_k) - \alpha T(s_k) - \beta T(\hat{s}_k)) = 0
$$

Next, we show that $\lVert\overline{T}\rVert_{Z\to X} = \lVert T \rVert_{S\to X}$. For $(s_k)_{k\in\N_+}$ in $S$ converging to $z\in Z$, we have

$$
\begin{align*}
  \lVert\overline{T}(z)\rVert_Z =& \left\lVert \lim_{k\to\infty} T(s_k) \rVert \\
  =& \lim_{k\to\infty} \lVert T(s_k) \rVert \\
  \leq& \lim_{k\to\infty} \lVert T \rVert_{S\to X} \lVert s_k \rVert_S \\
  =& \lVert T \rVert_{S\to X} \lVert z \rVert_Z 
\end{align*}
$$

This implies that

$$
  \lVert\overline{T}\rVert_{Z\to X} = \sup\Set{\frac{\lVert\overline{T}(z)\rVert_X}{\lVert z \rVert_Z} | z\in Z\setminus\Set{0}} \leq \lVert T \rVert_{S\to X}
$$

On the other hand, since $\overline{T}(s) = T(s)$ for all $s\in S$, we have

$$
\begin{align*}
  \lVert\overline{T}\rVert_{Z\to X} =& \sup\Set{\frac{\lVert\overline{T}(z)\rVert_X}{\lVert z \rVert_Z} | z\in Z\setminus\Set{0}} \\
  \geq& \frac{\lVert\overline{T}(s)\rVert_X}{\lVert z \rVert_S} = \lVert T \rVert_{S\to X}
\end{align*}
$$

Thus, $\lVert\overline{T}\rVert_{Z\to X} = \lVert T \rVert_{S\to X} < \infty$, which implies that $\overline{T}$ is bounded.

Finally, we show that $\overline{T}$ is unique. Suppose there is another norm-preserving linear extension $\tilde{T}$ of $T$ from $S$ to $Z$. If $\tilde{T}(z) \neq T(z)$ for some $z\in Z$, then for a sequence $(s_k)_{k\in\N_+}$ converging to $z$, we have

$$
\begin{align*}
  0 \neq& \tilde{T}(z) - T(z) \\
  =& \tilde{T}\left(\lim_{k\to\infty} s_k \right) - T\left(\lim_{k\to\infty} s_k \right) \\
  =& \lim_{k\to\infty} (\tilde{T}(s_k) - T(s_k)) \\
  =& \lim_{k\to\infty} (0) = 0
\end{align*}
$$

because $\tilde{T}(s) = T(s)$ for all $s\in S$.
</details>
</MathBox>

## Isomorphism

<MathBox title='Isomorphism' boxType='definition'>
A map linear and bijective map $f: X \to Y$ is an isometric isomorphism if $\lVert f(x)\rVert_Y = \lVert x\rVert_X$ for any $x \in X$.
</MathBox>

## Uniform boundedness principle

<MathBox title='Banach-Steinhaus theorem' boxType='theorem'>
Let $X$ and $Y$ be normed spaces, where $X$ is also a Banach space. For every subset $\mathcal{M} \subseteq \mathcal{B}(X, Y)$, then $\mathcal{M}$ is bounded pointwise on $X$ if and only if $\mathcal{M}$ is uniformly bounded. Pointwise boundedness implies that for all $x\in X$ there is a $C_x \geq 0$ such that $\lVert Tx\rVert_Y \leq C_x$, while uniformly boundedness implies that for all $T \in \mathcal{M}$ there is a $C \geq 0$ such that $\lVert T\rVert_{X \to Y} \leq C$.
</MathBox>

## Open mapping theorem

<MathBox title='Banach-Schauder theorem' boxType='theorem'>
Let $X$ and $Y$ be Banach spaces, and $T \in \mathcal{B}(X, Y)$ a bounded linear operator $T: X \to Y$. The operator $T$ is surjective if and only if $T$ is an open map.
</MathBox>

## Bounded inverse theorem

<MathBox title='Bounded inverse theorem' boxType='theorem'>
Let $X$ and $Y$ be Banach spaces, and $T \in \mathcal{B}(X, Y)$ a bounded linear operator $T: X \to Y$. If $T$ is bijective then $T^{-1} \in \mathcal{B}(X, Y)$, i.e. continuous.
</MathBox>

## Neumann series

<MathBox title='Neumann series' boxType='definition'>
A Neumann series is a geometric series for an operator $T$

$$
  \sum_{k=0}^\infty T^k
$$

where $T^k = T^{k-1} \circ T$. If $T$ is a bounded linear operator on a normed space $X$, and the Neumann series converges in the operator norm then $I - T$ is invertible with the inverse as the series

$$
  (I - T)^{-1} = \sum_{k=0}^\infty
$$

In analogy to a geometric series $\sum_{k=0}^n = x^k = 1 - x^{n+1}$, we have that

$$
\begin{align*}
  \lim_{n\to\infty} (I - T)\sum_{k=0}^\infty T^k =& \lim_{n\to\infty} \left(\sum_{k=0}^\infty T^k - \sum_{k=1}^\infty T^{k + 1} \right) \\
  =& \lim_{n\to\infty} I - T^{n + 1} = I
\end{align*}
$$

Convergence is guaranteed when $X$ is a Banach space with $\lVert T\rVert < 1$.
</MathBox>

# Spectral theory

<MathBox title='Spectrum and resolvent set' boxType='definition'>
Let $X$ be a complex Banach space and $T: X \to X$ be a bounded linear operator. The spectrum of $T$ is defined by

$$
  \sigma(T) := \Set{ \lambda \in \mathbb{C} | (T - \lambda I) \textrm{ not bijective} }
$$

The resolvent set of $T$ is defined by

$$
  \rho(T) := \Set{ \lambda \in \mathbb{C} | (T - \lambda I) \textrm{ bijective and} (T - \lambda I)^{-1} \textrm{ bounded} }
$$

The bounded inverse theorem implies that $\sigma(T) = \mathbb{C}\setminus \rho(T)$. The spectrum can be split into disjoint sets $\sigma(T) = \sigma_p(T) \cup \sigma_c(T) \cup \sigma_r(T)$ where

- Point spectrum (eigenvalues): $\sigma_p(T) := \Set{ \lambda \in \mathbb{C} | (T - \lambda I) \textrm{ not injective} }$
- Continuous spectrum: $\sigma_c(T) := \Set{ \lambda \in \mathbb{C} | (T - \lambda I) \textrm{ injective and not surjective with} \overline{\operatorname{ran}(T - \lambda I)} = X}$
- Residual spectrum: $\sigma_c(T) := \Set{ \lambda \in \mathbb{C} | (T - \lambda I) \textrm{ injective and not surjective with} \overline{\operatorname{ran}(T - \lambda I)} \neq X}$
</MathBox>

<MathBox title='Properties of spectra and resolvent sets' boxType='proposition'>
The spectrum $\sigma(T)$ and the resolvent $\rho(T)$ has the following properties
1. The resolvent $\rho(T)$ is open, while the spectrum $\sigma(T)$ is closed
2. The map $\rho(T): \to \mathcal{B}(X)$ given by $\lambda \mapsto (T - \lambda)^{-1}$ is analytical, i.e. it can be locally expressed as a Taylor series
3. The inverse of the distance of any $\lambda \in \rho(T)$ to the spectrum, written $d(\lambda, \sigma(T))$, satisfies

$$
  \lVert (T - \lambda)^{-1}\rVert \geq \frac{1}{d(\lambda, \sigma(T))}
$$

<details>
<summary>Proof</summary>

The first property can be shown by choosing $\lambda_0 \in \rho(T)$ and setting $c := \lVert (T - \lambda_0)^{-1}\rVert$ and $\epsilon := \frac{1}{c}$. Consider any $\lambda \in \mathbb{C}$ with $\left| \lambda - \lambda_0 \right| < \epsilon$, then

$$
  T - \lambda = (T - \lambda_0) - (\lambda - \lambda_0) = (T - \lambda_0) \left( I - (\lambda - \lambda_0)(T - \lambda_0)^{-1} \right) = (T - \lambda_0) (I - S)
$$

Furthermore, $\lVert S\rVert = \lVert \lambda - \lambda_0\rVert \cdot \lVert (T - \lambda_0)^{-1}\rVert < \epsilon c = 1$. This implies that $I - S$ is a convergent Neumann series, and thus invertible. Since, $T - \lambda$ is product a two invertible operators, it is also invertible. This shows that $\lambda \in \rho(T)$, meaning that $\rho(T)$ is open. Thus, $\sigma(T)$ is closed.

The second property follows from the results above, by writing out the inverse of $T - \lambda$

$$
\begin{align*}
  (T - \lambda)^{-1} =& (I - S)^{-1} (T - \lambda)^{-1} = \sum_{k=0}^\infty S^k (T - \lambda_0)^{-1} \\
  =& \sum_{k=0}^\infty (\lambda - \lambda_0 )^k (T - \lambda_0)^{-k} (T - \lambda_0)^{-1} \\
  =& \sum_{k=0}^\infty (T - \lambda_0)^{-(k + 1)} (\lambda - \lambda_0)^k
\end{align*}
$$

which takes the form of a Taylor series.

The third property also follows from the results above as

$$
  |\lambda - \lambda_0 | \geq \epsilon \implies \frac{1}{| \lambda - \lambda_0 |} \leq C = \lVert (T - \lambda)^{-1}\rVert
$$

Hence, we get

$$
  \frac{1}{d(\lambda, \sigma(T))} = \frac{1}{\inf_{\lambda \in \sigma(T)} | \lambda - \lambda_0 |} = \sup_{\lambda \in \sigma(T)} \frac{1}{| \lambda - \lambda_0 |} \leq \lVert (T - \lambda)^{-1}\rVert
$$
</details>
</MathBox>

## Spectral radius

<MathBox title='Properties of spectra and spectral radi' boxType='proposition'>
Let $X$ be a complex Banach space and $T: X \to X$ be a bounded linear operator. The spectrum $\sigma(T)$ has the following properties

1. $\sigma(T) \subseteq \mathbb{C}$ is compact (closed and bounded).
2. $\sigma(T) \neq \emptyset$ for $X \neq \Set{ 0}$
3. The spectral radius $r(T)$ is bounded as
$$
\begin{align*}
  r(T) :=& \sup_{\lambda\in\sigma(T)}|\lambda| = \lim_{k\to\infty} \lVert T^k\rVert^{1/k} = \inf_{k\in\N} \lVert T^k\rVert^{1/k} \\
  \leq& \lVert T\rVert < \infty
\end{align*}
$$

<details>
<summary>Proof</summary>

The boundedness implied by the first and last property can be proved by choosing $\lambda \in \mathbb{C}$ with $|\lambda| > \lVert T\rVert$ and consider $\frac{T}{\lambda}$ as a Neumann series

$$
\begin{gather*}
  \left( I - \frac{T}{\lambda} \right)^{-1} = \sum_{k=0}^\infty \left( \frac{T}{\lambda} \right)^k \\
  \implies (T - \lambda)^{-1} = -\frac{1}{\lambda} \left(I - \frac{T}{\lambda} \right)^{-1} = -\frac{1}{\lambda} \sum_{k=0}^\infty \left( \frac{T}{\lambda} \right)^k \\
  \sup_{\lambda \in \sigma(T)} |\lambda | \leq \lVert T\rVert
\end{gather*}
$$

which shows that $\sigma(T)$ is bounded. 

The second property can be proved by contraposition, assuming $\sigma(T) = \emptyset \implies \rho(T) = \mathbb{C}$. Recall that the map $\rho(T) \to \mathcal{B}(X)$ given by $\lambda \mapsto (T - \lambda)^{-1}$ is analytic. Thus, we can take any linear functional $\ell \in \mathcal{B}(X)^*$ and apply it on the map above resulting in the map $f_\ell: \mathbb{C} \to \mathbb{C}$ given by $\lambda \mapsto \ell\left[ (T - \lambda)^{-1} \right]$. Then for any $\lambda \geq \lVert T\rVert$ we have

$$
  \left| f_\ell(\lambda) \right| \leq \lVert \ell\rVert \cdot \lVert (T - \lambda)^{-1}\rVert \leq \lVert \ell\rVert \frac{1}{|\lambda|}\sum_{k=0}^\infty \left\lVert \frac{T}{\lambda} \right\|^k \leq \frac{\| \ell\rVert}{\lVert T\rVert}
$$

which shows that $f_\ell$ is a bounded entire function. Applying Liouville's theorem implies that $f_\ell$ is constant. We can then proceed to calculate this constant for $\lambda_0 = 0$

$$
  f_\ell (0) = \ell(T^{-1})
$$

This should hold for all $\lambda \in \mathbb{C}$

$$
  f_\ell (\lambda) = \ell\left[ (T - \lambda)^{-1} \right] = \ell\left( \sum_{k=0}^\infty (T - \lambda_0)^{-(k + 1) (\lambda - \lambda_0)^k} \right) = \sum_{k=0}^\infty \ell \left( T^{-(k+1)} \right)\lambda^k
$$

Consequently $\ell\left(T^{-2}\right) = 0$ for all $\ell \in \mathcal{B}(X)^*$. By the Hahn-Banach theorem, we must have $T^{-2} = 0$, but this implies that $X = \Set{ 0}$ since $T$ is bijective. Hence $\sigma(T) \neq \emptyset$ for  $X \neq \Set{0}$.
</details>
</MathBox>

## Spectral measure

<MathBox title='Spectral measure' boxType='definition'>
Let $X$ be a compact metric space. A *spectral measure* on the measurable space $(X,\mathbb{B}_X)$ is a mapping $P:\mathcal{B}_X \to \mathcal{P}(H)$, where $\mathcal{P}(H)$ is the set of projections on a Hilbert space $H$, which satisfies:
1. $P(\emptyset) = 0$, $P(X) = \operatorname{id}_H$
2. $P$ is countably additive, meaning that if $\Set{E_n}_{n\in I\subseteq\N}$ is a countable collection of pairwise disjoint Borel sets in $X$ with $E = \bigsqcup_{n\in I} E_n$, then $P(E) = \sum_{n\in I} P(E_n)$, where the series is interpreted in the strong operator topology on $H$.
</MathBox>

Let $(X,\mathcal{B}_X)$ be a measurable space for a compact metric space $X$ and suppose $H$ is a separable Hilbert space. If $P:\mathcal{B}_X \to\mathcal{P}(H)$ is a spectral measure, then for fixed $\mathbf{x}, \mathbf{y} \in H$ the equation

$$
  \mu_{\mathbf{x},\mathbf{y}} (E) = \braket{ P(E)\mathbf{x}, \mathbf{y}}
$$

defines a complex measure $\mu_{\mathbf{x},\mathbf{y}}$ on $(X,\mathcal{B}_X)$. The Cauchy-Shwarz inequality implies that $\mu_{\mathbf{x},\mathbf{y}}$ has total variation norm bounded by $\lVert\mu_{\mathbf{x},\mathbf{y}}\rVert \leq \lVert\mathbf{x}\rVert\cdot\lVert\mathbf{y}\rVert$.

It is easily seen that for fixed $f\in C(X)$, the equation

$$
  B_f (\mathbf{x},\mathbf{y}) = \int_X f\;\d\mu_{\mathbf{x},\mathbf{y}}
$$

defines a sesquilinear form on $H$ bounded by

$$
  | B_f (\mathbf{x},\mathbf{y})| \leq \lVert f\rVert_{C(X)} \cdot\lVert\mathbf{x}\rVert\cdot\lVert\mathbf{y}\rVert
$$

Thus, there is exists unique operator, say $\pi(f)$, on $H$ such that

$$
  \braket{\pi(f)\mathbf{x}, \mathbf{y}} = \int_X f \;\d\mu_{\mathbf{x},\mathbf{y}}
$$

It can be verified that the mapping $f\mapsto \pi(f)$ defines a representation of $\pi: C(X)\to\mathcal{L}(H)$. The operator $\pi$ is commonly written in terms of the spectral measure $P$ as

$$
  \pi(f) = \int_X f\;\d P = \int_X f(x)\;\d P(x)
$$

This shows that there is a bijection between separable representations of $C(X)$ and spectral measrues defined on $(X,\mathcal{B}_X)$ and taking values in projection operators in a separable Hilbert space. One possible choise for the measure $\mu$ that is associated to the representation $\pi$ is given in terms of the spectral measure $P$ by

$$
  \mu(E) = \sum_{n\in I} \braket{P(E),\mathbf{x}_n, \mathbf{x}_n} = \sum_{n\in I} \lVert P(E) \mathbf{x}_n \rVert^2
$$

where $\Set{\mathbf{x}_n}_{n\in I}$ is an orthonormal basis for $H$.

Given a probability measure $\mu$ defined on $(X,\mathcal{B}_X)$, let $P_\mu : \mathcal{B}_X \to\mathcal{L}(L^2 (X,\mathcal{B}_X, \mu))$ be the spectral measure defined by

$$
  \braket{P_\mu (E)f, g} = \int_E f(x)\overline{g(x)}\;\d\mu(x)
$$

For $1\leq n\leq\aleph_0$, we have a natural spectral measure $P_\mu^n :\mathcal{B}\to\mathcal{L}((L^2 (X,\mathcal{B},\mu))^n)$ obtained by defining $P_\mu^n (E) = \bigoplus_{k\in I_n} P_\mu (E)$, where $H^n$ denotes the direct sum of $n$ copies of $H$ and $I_n$ is any set with cardinality $|I_n| = n$.

<MathBox title='Hahn-Hellinger theorem (spectral form)' boxType='theorem'>
If $X$ is a compact Hausdorff space and if $P:\mathbb{B}\to\mathcal{L}(H)$ is a separable measure (meaning that $H$ is a separable Hilbert space), then there exists a probability measure $\mu:\mathcal{B}\to[0,1]$ and a partition $X = \bigsqcup_{0\leq n\leq\aleph_0} E_n$ of $X$ into measurable sets such that $\mu$ is supported on $X - E_0$ and

$$
  P \cong \bigoplus_{1\leq n\leq\aleph_0} P_{\mu|_{E_n}}^n
$$

If $\tilde{P}:\mathcal{B}\to\mathcal{L}(H)$ is another spectral measure, with associated probability measure $\tilde{\mu}$ and partition $X = \bigsqcup_{0\leq n\leq\aleph_0} \tilde{E}_n$, then $\mu$ and $\tilde{\mu}$ are mutually absolutely continuous, and $\mu(E_n \Delta\tilde{E}_n) = 0$ for all $0\leq n\leq\aleph_0$.
</MathBox>

Let $X$ be a locally compact Hausdorff space, and let $\hat{X}$ denote the one-point compactification of $X$. THen any spectral measure $P:\mathcal{B}_X \to\mathcal{L}(H)$ may be viewed as a spectral measure $P_1$ defined on $\mathcal{B}_{\hat{X}}$ with the understanding that $P_1 (\Set{\infty}) =$, or equivalently, $P_1 (E) = P(E\setminus\Set{\infty})$.

Hence, we may deduce that the above formulation of the Hahn-Hellinger theorem is valid under the assumption that $X$ is a locally compact Hausdorff space.

## Spectral theorem

<MathBox title='Spectral theorem (bounded case)' boxType='theorem'>
Let $H$ be separable Hilbert space, and let $\mathcal{P}(H)$ denote the set of projection operators onto closed subspaces of $H$.
1. **Bijection between normal operators and spectral measures**

Let $\Sigma\subset\mathbb{C}$ be a compact subset of the complex plane. There is a bijection between:
- a. Normal operators $T\in\mathcal{L}(H)$, such that $\sigma(T)\subset\Sigma$, and 
- b. Spectral measures $P:\mathcal{B}_\Sigma \to\mathcal{P}(H)$

This bijection is given by the equation
$$
  \braket{Tx, y} = \int_{\Sigma} \lambda\;\d\mu_{x,y} (\lambda)
$$
where $\mu_{x,y} (E) = \braket{P(E)x, y}$.

2. **Characterization of the spectrum**

If $T$ and $P(E)$ are as above, the spectrum of $T$ is the support of the spectral measure $P(\cdot)$. Specificaly, $\lambda\in\sigma(T)$ if and only if $P(U) \neq 0$ for every open neighbourhood $U$ of $\lambda$ in $\Sigma$.

<details>
<summary>Proof</summary>

**(1):** If $T\in\mathcal{L}(H)$ is a normal operator such that $\sigma(T) = \Sigma_0 \subset\Sigma$, then by Proposition $\ref{}$, there is a unique representation $f: C(\Sigma_0)\to C^* (\Set{1,T}) \subset\mathcal{L}(H)$ such taht $f_j (T) = T^j$ if $f_j (\lambda) = \lambda^j$ for $j = 0,1$. This representation gives rise to a unique spectral measure $\mathbb{B}_{\Sigma_0}\ni E\mapsto P(E) \in \mathcal{P}(H)$ such that

$$
\begin{equation}
  \braket{f(T)x, y} = \int_{\Sigma_0} f\;\d\mu_{x,y},\; \forall f,x,y tag{\label{equation-4}}
\end{equation}
$$

We may think of $P$ as a spectral measure being defined for all Borel subsets of $\Sigma$ by the rule $P(E) = P(E\cap\Sigma_0)$.

Conversely, every spectral measure as in **(1.b)** clearly gives rise to a representation of $C(\Sigma)$ into $H$ and consequently a normal operator $T\in\mathcal{L}(H)$ such that $\eqref{equation-4}$ is vali for $f\in C(\Sigma)$. Since homomorphisms of C* algebras "shrink spectra" (Lemma $\ref{}$), we find that $\sigma(T)\subset\Sigma$.

**(2):** Let $T = \int_\sigma \lambda\;\d P(\lambda)$ as in **(1)** above. Define the measure $\mu$ by $\mu(E) = \sum_{n\in N} 2^{-n} \lVert P(E)e_n \rVert^2$, where $\Set{e_n}_{n\in N}$ is an orthonormal basis for $H$. There is an isometric *-isomorphism $L^\infty (\Sigma_0, \mu) \ni \phi\mapsto \int_{\Sigma_0} \phi\;\d P \in\mathcal{L}(H)$, where $\Sigma_0 = \sigma(T)$. Under this isomorphism, the function $f_1 (\lambda) = \lambda$ for $\lambda\in\Sigma_0$ corresponds to $T$. However, it is easy to see that $\lambda_0 \in\sigma_{L^\infty (\Sigma_0, \mu)}(f_1)$ if and only if $\mu(\Set{\lambda: |\lambda-\lambda_0| < \epsilon}) > 0$ for every $\epsilon > 0$. The negation of this latter condition is clearly equivalent to the statement that the function $\lambda\mapsto 1/(\lambda-\lambda_0)$ belongs to $L^\infty (\Sigma_0,\mu)$. Finally, $\mu(E) = 0 \iff P(E) = 0$.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
A complex number $\lambda_0$ belongs to the spectrum of a normal operator $T\in\mathcal{L}(H)$ on a separable Hilbert space $H$ if and only $\lambda_0$ is an approximate eigenvalue for $T$, meaning that there exists a sequence $\Set{x_n}_{n\in\N}$ of unit vectors in $H$ such that $\lVert T\mathbf{x}_n - \lambda_0 x_n \rVert \xrightarrow{n\to\infty} 0$.

<details>
<summary>Proof</summary>

An approximate eigenvalue of any (not necessarily normal) operator must necessarily belong to the spectrum of that operator, since an invertible operator is necessarily bounded below.

On the other hand, if $T$ is normal, if $P$ is the associated spectral measure, and if $\lambda_0 \in\sigma(T)$, then $P(U) \neq 0$ for every neighbourhood $U$ of $\lambda_0$. In particular, we can find a unit vector $x_n$ belonging to the range of the projection $P(U_n)$, where $U_n = \Set{\lambda\in\mathbb{C} : |\lambda - \lambda_0| < 1/n}$. Since $|(\lambda - \lambda_0)1_{U_n} (\lambda)| < 1/n \;\forall\lambda$, we find that $\lVert (T-\lambda_0)P(U_n) \rVert\leq 1/n$, and in particular $\lVert(T - \lambda_0)x_n \rVert \leq 1/n \;\forall n$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $T\in\mathcal{L}(H)$ be a normal operator on a separable Hilbert space $H$. Let $\Sigma = \sigma(T)$ and let $P$ be the unique spectral measure associated to $T$ and let $\mu(E) = \sum_{n\in I} 2^{-n} \lVert P(E) e_n \rVert^2$, where $\Set{e_n}_{n\in\N}$ is any orthonormal basis for $H$. Then the assignment

$$
  \phi\mapsto\phi(T) = \int_\Sigma \phi\;\d P
$$

defines an isometric *-isomorphism of $L^\infty (\Sigma,\mu)$ onto the von Neumann subalgebra $W^* (\Set{1,T})$ of $\mathcal{L}(H)$ generated by $\Set{1,T}$, such that
1. $\phi_j (T) = T^j$, where $\phi_j (\lambda) = \lambda^j$ for $j = 0,1$
2. The representation is weakly continuous, meaning that if $\Set{\phi_n}_{n\in\N}$ is a sequence in $L^\infty (X,\mu)$ which converges to $\phi$ with respect to the weak * topology, then $\phi_n (T) \xrightarrow{\phi(T)}$ in the weak operator topology.

Furthermore, the representation is uniquely determined by conditions **(1)** and **(2)**, and is called the *measurable functional calculus* for $T$.

<details>
<summary>Proof</summary>

Note that if $\pi: C(\Sigma)\to\mathcal{L}(H)$ is the continuous functional calculus for $T$, and if $\tilde{\pi}$ and $\mu$ are associated with $\pi$ as in Lemma $\ref{lemma-11}$, then

$$
  \tilde{\pi}(\phi) = \sum_{\Sigma} \phi\;\d P
$$

where $P(E) = \tilde{\pi}(1_E)$. By Lemma $\ref{lemma-13}$, the image of this representation of $L^\infty (\Sigma,\mu)$ is precisely the von Neumann algebra generated by $\pi(C(\Sigma)) = C^* (\Set{1,T})$.

Through repeated applications of the Cauchy-Schwarz inequality, we can verify that if $\Set{\phi_n}_{n\in\N}$ is a sequence in $L^\infty (\Sigma,\mu)$, then to say that the sequence $\Set{\tilde{\pi}(\phi_n)}_{n\in\N}$ converges to $\tilde{\pi}(\phi)$ with respect to the weak operator topology is exactly equivalent to requiring that $\int_\Sigma (\phi_n - \phi) f\;\d\mu \xrightarrow{n\to 0}$ for every $f\in L^1 (\Sigma,\mu)$, proving **(2)**.
</details>
</MathBox>

<MathBox title='' boxType='corollary'>
Let $H$ be a separable Hilbert space.
1. Let $U\in\mathcal{L}(H)$ be a unitary operator. Then there exists a self-adjoint operator $A\in\mathcal{L}(H)$ such that $U = e^{iA}$, where the right hand side is interpreted as the result of the continuous functional calculus for $A$. Furthermore, given any $a\in\R$, we may choose $A$ to satisfy $\sigma(A)\subset [a,a+2\pi]$.
2. If $T\in\mathcal{L}(H)$ is a normal operator, and if $n\in\N$, then there exists a normal operator $A\in\mathcal{L}(H)$ such that $T = A^n$.

<details>
<summary>Proof</summary>

**(1):** Let $\phi:\mathbb{C}\to\Set{z\in\mathbb{C} | \im z\in [a,a+2\pi]}$ be any measurable branch of the logarithm. For instance, we might set $\phi(z) = \ln |z| + i\theta$ if $z = |z| e^{i\theta}$ for $a\leq\theta < a + 2\pi$. Setting $A = \phi(U)$, we find $U = e^{iA}$ since $e^{\phi(z)} = z$.

**(2):** This is proved like **(1)**, by taking some measurable branch of the logarithm defined everywhere in $\mathbb{C}$ and choosing the $n$-th root as the complex function defined using this choice of logarithm.
</details>
</MathBox>

## Polar decomposition

<MathBox title='' boxType='lemma' tag='lemma-14'>
If $T\in\mathcal{L}(H,K)$ is a linear operator between Hilbert spaces, then

$$
  \ker(T) = \ker(T^* T) = \ker(T^* T)^{1/2} = \operatorname{ran}(T^*)^\perp
$$

In particular, also

$$
  \ker(T)^\perp = \overline{\operatorname{ran}(T^*)}
$$

<details>
<summary>Proof</summary>

Note first that for arbitrary $x\in H$, we have

$$
  \lVert Tx \rVert^2 = \braket{T^* Tx, x} = \braket{(T^* T)^{1/2} x, (T^* T)^{1/2} x = \lVert (T^* T)^{1/2} x \rVert^2
$$

Hence it follows that $\ker(T) = \ker(T^* T)^{1/2}$.

Note next that

$$
\begin{align*}
  x \in\operatorname{ran}(T^*)^\perp \iff& \braket{x, T^* x} = 0\; \forall y\in K \\
  \iff& \braket{Tx, y} = 0\; \forall y\in K \\
  \iff& Tx = 0
\end{align*}
$$

and hence $\operatorname{ran}(T^*)^\perp = \ker(T)$. The particular statement of the lemma follows from the fact that $V^{\perp\perp} = \overline{V}$ for any linear subspace $V\subset K$.

Finally, if $\Set{p_n}_{n\in\N}$ is any sequence of polynomial with the property that $p_n (0) = 0$ for all $n\in\N$ and such that $\Set{p_n (t)}$ converges uniformly to $\sqrt{t}$ on $\sigma(T^* T)$, it follows that $\lVert p_n (T^* T) - (T^* T)^{1/2} \rVert \xrightarrow{n\to 0}$, and hence

$$
\begin{align*}
  x\in\ker(T^* T) \implies& p_n (T^* T)x = 0 \;\forall n \\
  \implies& (T^* T)^{1/2} x = 0
\end{align*}
$$

and hence we see that also $\ker(T^* T) \subset\ker(T^* T)^{1/2} x = 0$. The reverse inclusion is obvious, completing the proof.
</details>
</MathBox>

<MathBox title='Partial isometry' boxType='proposition' tag='proposition-42'>
If $U\in\mathcal{L}(H,K)$ is a linear operator between Hilbert spaces, the following are equivalent:
1. $U = UU^* U$
2. $P = U^* U$ is a projection
3. $U|_{\ker(U)^\perp}$ is an isometry

An operator satisfying the equivalent conditions **(1)**-**(3)** is called a *partial isometry*.

<details>
<summary>Proof</summary>

**(1)$\implies$(2):** If $U = UU^* U$, then

$$
  P^2 = U^* U U^* U = U^* (U U^* U) = U^* U = P
$$

**(2)$\implies$(1):** Let $M = \operatorname{ran}(P)$. For arbitrary $x\in H$, we have

$$
  \lVert Px \rVert^2 = \braket{Px, x} = \braket{U^* Ux, x} = \lVert U x\rVert^2
$$

This implies that $\ker(U) = \ker(U) = M^\perp$, and that $U$ is isometric on $M$ because $P$ is identity on $M$.

**(3)$\implies$(2):** Let $M = \ker(U)^\perp$. For $i=1,2$, suppose $z_i \in H$ and $x_i \in M$, $y_i \in M^\perp$ are such taht $z_i = x_i + y_i$. Then

$$
\begin{align*}
  \braket{U^* Uz_1, z_2} =& \braket{Uz_1, Uz_2} \\
  =& \braket{Ux_1, Ux_2} \\
  =& \braket{x_1, x_2} \\
  =& \braket{x_1, z_2}
\end{align*}
$$

where the third equation follows since $U|_M$ is isometric. Hence, $U^* U$ is the projection onto $M$.

**(2)$\implies$(1):** Let $M = \operatorname{ran}(U^* U)$. Then by Lemma $\ref{lemma-14}$, we get $M^\perp = \ker(U^* U) = \ker(U)$. If $x\in M$ and $y\in M^\perp$ are arbitrary and if $z = x + y$, then note that

$$
  Uz = Ux + Uy = Ux = U(U^* U)z
$$
</details>
</MathBox>

Suppose $U\in\mathcal{L}(H,K)$ is a partial isometry between Hilbert spaces. Setting $M = \ker(T)^\perp$ and $N = \operatorname{ran}(U) = \overline{\operatorname{ran}(U)}$, we find that $U \equiv 0$ on $M^\perp$, and $U$ maps $M$ isometrically onto $N$. It is customary to refer to $M$ as the *initial space*, and to $N$ as the *final space*, of the partial isometry $U$.

Taking adjoint adjoints in **(2)** of Proposition $\ref{\proposition-42}$, it is seen that $U^* \in\mathcal{L}(K,H)$ is also a partial isometry. By Lemma $\ref{\lemma-14}$, we find that $\ker(U^*) = N^\perp$ and $\operatorname{ran}(U^*) = M$. Thus, $N$ is the initial space of $U^*$ and $M$ is the final space of $U^*$.

Finally, if follows from Proposition $\ref{proposition-42}$ that $U^* U$ is the projection of $H$ otno $M$ while $UU^*$ is the projection of $K$ onto $N$.

<MathBox title='' boxType='lemma' tag='lemma-15'>
Let $U\in\mathcal{L}(H,K)$ be a partial isometry between Hilbert spaces with initial space $M = \ker(U)^\perp$ and final space $N = \operatorname{ran}(U)$. If $y\in N$, then $U^* y$ is the unique element $x\in M$ such that $Ux = y$.

<details>
<summary>Proof</summary>

</details>
</MathBox>

<MathBox title='Polar decomposition' boxType='theorem'>
1. Any linear operator $T\in\mathcal{L}(H,K)$ between Hilbert spaces admits a decomposition $T = UA$ such that
  - a. $U\in\mathcal{L}(H,K)$ is a partial isometry
  - b. $A\in\mathcal{L}(H)$ is a positive operator
  - c. $\ker(T) = \ker(U) = \ker(A)$
2. If $T = VB$ is another decomposition of $T$ as a product of a partial isometry $V$ and a positive operator $B$ such that $\ker(V) = \ker(B)$, then necessarily $U = V$ and $B = A = (T^* T)^{1/2} = |T|$. This unique decomposition is called the polar decomposition of $T$.
3. If $T = U|T|$ is the polar decomposition of $T$, then $|T| = U^* T$.

<details>
<summary>Proof</summary>

**(1):** If $x,y\in H$ are arbitrary, then

$$
  \braket{Tx, Ty} = \braket{ T^* Tx, y} = \braket{|T|^2 x, y} = \braket{|T|x, |T|y}
$$

Hence is follows that there exists a unique operator $U_0 : \overline{\operatorname{ran}(|T|)}\to\overline{\operatorname{ran}(T)}$ such that $U_0 (|T|x) = Tx \; \forall x\in H$. Let $M = \overline{\operatorname{ran}(|T|)}$ and let $P = P_M$ denote the orthogonal projection onto $M$. Then the operator $U = U_0 P$ clearly defines a partial isometry with initial space $M$ and final space $N = \overline{\operatorname{ran}(T)}$ which further satisfies $T = U|T|$. It follows from Lemma $\ref{lemma-14}$ that $\ker(U) = \ker(|T|) = \ker(T)$.

**(2):** Suppose $T = VB$. Then $V^* V$ is the projection onto $\ker(V)^\perp = \ker(B)^\perp = \overline{\operatorname{ran}(B)}$, which clearly implies that $B = V^* VB$. Thus, we see that $T^* T = BV^* VB = B^2$, showing that $B$ is the positive square root of $|T|^2$, i.e. $B = |T|$. It then follows that $V(|T|x) = Tx = U(|T|x) \forall x\in H$. By continuity, we see that $V$ agrees with $U$ on $\overline{\operatorname{ran}(|T|)}$, but since this is precisely the initial space of both partial isometries $U$ and $V$, we see that we must have $U = V$.

**(3):** This is an immediate consequence of the definition of $U$ and Lemma $\ref{lemma-15}$.
</details>
</MathBox>

## Adjoint operators

<MathBox title='Adjoint operator' boxType='definition'>
Let $X$ be a Hilbert space and $T: X \to X$ a bounded linear operator. The adjoint operator of $T$, denoted $T^\dagger: X \to X$, satisfies

$$
  \braket{y, Tx} = \braket{T^* y, x} \quad \forall x, y \in X
$$

A bounded linear operator $T$ is called
1. self-adjoint if $T^* = T$
2. skew-adjoint if $T^* = -T$
3. normal if $T^* T = T T^*$

If $T$ is normal then the spectral radius of $T$ is equal to the operator norm, i.e. $r(T) = \lVert T\rVert$.
</MathBox>

## Compact operators

<MathBox title='Compact operator' boxType='proposition'>
Let $\left(X ,\lVert \cdot\rVert_X\right)$ and $\left(X ,\lVert \cdot\rVert_X\right)$ be normed spaces. A bounded linear operator $T: X \to Y$ is *compact* if for every bounded sequence $\Set{x_n}_{n\in\N} \subset X$, the sequence $\Set{Tx_n}_{n\in\N}$ has a subsequence which converges with respect to the norm in $Y$. Equivalently, $T$ is compact if it maps the unit ball $B_1 (0) \subset X$ into a set whose closure is compact, i.e. $\overline{T\left[\mathcal{B}_1(0)\right]}$ is compact. The set of compact operators from $X$ to $Y$ is denoted $\mathcal{K}(X,Y)$.
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-39'>
Let $X,Y,Z$ be Banach spaces.
1. $\mathcal{K}(X,Y)$ is a norm-closed subspace of $\mathcal{L}(X,Y)$
2. if $A\in\mathcal{L}(Y,Z)$, $B\in\mathcal{L}(X,Y)$, and if either $A$ or $B$ is compact, then $AB$ is also compact.
3. In particular, $\mathcal{K}(X)$ is a closed two-sided ideal in the Banach-algebra $\mathcal{L}(X)$.

<details>
<summary>Proof</summary>

**(1):** Suppose $A, B\in\mathbb{K}(X,Y)$ are compact operators, and $\alpha\in\mathbb{F}$, and suppose $\Set{x_n}_{n\in\N}$ is a bounded sequence in $X$. Since $A$ is compact, there is a subsequence, say $\Set{y_n}_{n\in\N}$ of $\Set{x_n}_{n\in\N}$, such that $\Set{Ay_n}_{n\in\N}$ is a norm-convergent sequence. Since $\Set{y_n}_{n\in\N}$ is a bounded sequence and $B$ is compact, we may extract a further subsequence, say $\Set{z_n}_{n\in\N}$, with the property that $\Set{Bz_n}$ is norm-convergent. It is clear that $\Set{(\alpha A + B) z_n}$ is a norm-convergent sequence. Thus $(\alpha A + B)$ is compact. In other words, $\mathcal{K}(X,Y)$ is a subspace of $\mathcal{L}(X, Y)$.

Suppse now that $\Set{A_n}_{n\in\N}$ is a sequence in $\mathcal{K}(X,Y)$, and that $A\in\mathcal{L}(X,Y)$ is such that $\lVert A_n - A \rVert\xrightarrow{n\to\infty} 0$. We will prove that $A$ is compact using a diagonal argument. Let $S_0 = \Set{x_n}_{n\in\N}$ be a bounded sequence in $X$. Since $A_1$ is compact, we can extract a subsequence $S_1 = \Set{x_n^{(1)}}_{n\in\N}$ of $S_0$ such that $\Set{Ax_n^{(1)}}_{n\in\N}$ is convergent. Proceeding in this fashion, we can find a sequence $\Set{S_k}$ such that $S_k = \Set{x_n^{(k)}}_{n\in\N}$ is a subsequence of $S_{k-1}$ and $\Set{A_k x_n^{(k)}}$ is convergent in $Y$, for each $k\geq 1$. Let us write $z_n = x_n^{(n)}$. Since $\Set{z_n}_{n\geq k\in\N}$ is a subsequence of $S_k$, note that $\Set{A_k z_n}_{n\in\N}$ is a convergent sequence in $Y$ for every $k\in\N_+$.

It remains to show that $\Set{Az_n}_{n\in\N}$ is a Cauchy sequence in $Y$. Suppose $\epsilon > 0$ and let $K = 1 + \sup_{n\in\N} \lVert z_n\rVert$. Pick an integer $N\in\N$ such that $\lVert A_N - A \rVert < \frac{\epsilon}{3K}$. Next, choose an integer $n_0$ such that $\lVert A_N z_n - A_N z_m \rVert < \frac{\epsilon}{3}$ for all $n,m\geq n_0$. If $n, m\geq n_0$, we have

$$
\begin{align*}
  \lVert Az_n - Az_m \rVert \leq& \lVert (A - A_N)z_n \rVert + \lVert A_N z_n - A_N z_m \rVert \\
  &+ \lVert (A_N - A)z_m \rVert \\
  \leq& \frac{\epsilon}{3K}K + \frac{\epsilon}{K} + \frac{\epsilon}{3K}K \\
  =& \epsilon
\end{align*}
$$

**(2):** Let $\mathcal{B}_1(0) \subset X$ be the unit ball in $X$. We need to show that $AB(\mathcal{B}_1(0))$ is totally bounded. Thus is true in case **(i)** $A$ is compact, since then $B(\mathcal{B}_1(0))$ is bounded, and $A$ maps bounded sets to totally bounded set, and **(ii)** $B$ is compact since then $B(\mathcal{B}_1 (0))$ is totally bounded, and $A$ (being bounded) preserves totally bounded sets.
</details>
</MathBox>

<MathBox title='' boxType='corollary' tag='corollary-4'>
If $T\in\mathcal{L}(H_1,H_2)$ is a linear operator between Hilbert spaces, then
1. $T$ is compact if and only if $|T| = (T^* T)^{1/2}$ is compact.
2. In particular, $T$ is compact if and only if $T^*$ is compact.

<details>
<summary>Proof</summary>

If $T = U|T|$ is the polar decomposition of $T$, then by Theorem $\ref{}$ also $U^* T = |T|$. Thus, each of $T$ and $|T|$ is a multiple of each other. Applying Proposition $\ref{proposition-39}.2$ proves **(1)**. Also, since $T^* = |T|U^*$, we see that the compactness of $T$ implies that of $T^*$, and **(2)** follows from the fact that we may interchange the roles of $T$ and $T^*$.
</details>
</MathBox>

<MathBox title='' boxType='lemma' tag='lemma-10'>
If $T\in\mathcal{K}(H_1,H_2)$ is a compact operator between Hilbert spaces and if $T$ is bounded below on a subspace $\mathcal{M}\subseteq H_1$, then $\mathcal{M}$ is finite-dimensional. In particular, if $\mathcal{N}$ is a closed subspace of $H_2$ such that $\mathcal{N}$ is contained in the range of $T$, then $\mathcal{N}$ is finite-dimensional.

<details>
<summary>Proof</summary>

If $T$ is bounded below on $\mathcal{M}$, then it is also bounded below (by the same constant) on the closure $\overline{M}$. We can therefore assume without loss of generality that $\mathcal{M}$ is closed. If $\mathcal{M}$ contains an infinite orthonormal set, say $\Set{e_n}_{n\in\N}$, and if $T$ is bounded below by $\epsilon$ on $\mathcal{M}$, then note that $\lVert Te_n - Te_m \rVert\geq \epsilon\sqrt{2}$ for all $n\neq m$. Then $\Set{e_n}_{n\in\N}$ would be a bounded sequence in $H$ such that $\Set{Te_n}_{n\in\N}$ would have no Cauchy subsequence, this contradicting the assumed compactness of $T$. Hence, $\mathcal{M}$ must be finite-dimensional.

As for the second assertion, let $\mathcal{M} = T^{-1} (\mathcal{N})\cap \ker^\top (T)$. Note that $T$ maps $\mathcal{M}$ bijectively onto $\mathcal{N}$. By the open mapping theorem, $T$ must be bounded below on $\mathcal{M}$. Thus, by the first asstion, $\mathcal{M}$ is finite-dimensional, and so is $\mathcal{N}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-40'>
Let $T\in\mathcal{L}(H_1, H_2)$ be a linear operator between separable Hilbert spaces. Then the following are equivalent
1. $T$ is compact
2. $|T|$ is compact
3. if $\mathcal{M}_\epsilon = \operatorname{ran}(\operatorname{id}_{[\epsilon,\infty)}(|T|))$, then $\mathcal{M}_\epsilon$ is finite-dimensional
4. There is a sequence $\Set{T_n}_{n\in\N_+} \subset\mathcal{L}(H_1, H_2)$ such that for each $n\in\N$
    - a. $\lVert T_n - T \rVert \xrightarrow{n\to\infty} 0$
    - b. $\operatorname{ran}(T_n)$ is finite-dimensional
5. $\operatorname{ran}(T)$ does not contain any infinite-dimensional closed subspaces of $H_2$.

<details>
<summary>Proof</summary>

For $\epsilon > 0$, we use introduce the notation $\operatorname{id}_\epsilon = \operatorname{id}_{[\epsilon,\infty)}$ and $P_\epsilon = \operatorname{id}_\epsilon (|T|)$.

**(1)$\implies$(2):** This follows from Corollary $\ref{corollary-4}$.

**(2)$\implies$(3):** Since $t\geq \epsilon\operatorname{id}_\epsilon (t)$ for all $t\geq 0$, we find easily that $|T|$ is bounded below by $\epsilon$ on $\operatorname{ran}(P_\epsilon)$ and **(3)** follows from Lemma $\ref{lemma-10}$.

**(3)$\implies$(4):** Define $T_n = TP_{1/n}$ and note that $0\leq t(1 - \operatorname{id}_{1/n} (t) \leq \frac{1}{n}$ for all $t\geq 0$ and conclude that $\lVert |T|(1 - \operatorname{id}_{1/n}(|T|))\rVert \leq\frac{1}{n}$. If $T = U|T|$ is the polar decomposition of $T$, it follows that $\lVert T - T_n \rVert\leq\frac{1}{n}$. Finally, **(3)** clearly implies that each $P_{1/n}$ and consequently $T_n$ has finite-dimensional range.

**(4)$\implies$(5):** By Proposition $\ref{proposition-39}.1$ it suffices to show that each $T_n$ is a compact operator. However, any bounded operator with finite-dimensional range is necessarily compact, since any bounded set in a finite-dimensional space is totally bounded.

**(1)$\implies$(5):** This follows from Lemma $\ref{lemma-10}$.

**(5)$\implies$(3):** Pick any bounded measurable function $g$ such that $g(t) = 1/t$ for all $t\geq\epsilon$. Then $tg(t) = 1$ for all $t\geq 1$, and it follows that $|T|g(|T|)x = x$ for all $x\in\mathcal{M}_\epsilon$. Consequently, $\mathcal{M}_\epsilon = |T|(\mathcal{M}_\epsilon)$ is a closed subspace of $\operatorname{ran}(|T|)$, and hence of the inital space of the partial isometry $U$. This implies that $T(\mathcal{M}_\epsilon) = U(\mathcal{M}_\epsilon)$ is a closed subspace of $\operatorname{ran}(T)$. By **(5)**, this implies that $T(\mathcal{M}_\epsilon)$ is finite-dimensional. However, $|T|$ and consequently $T$ is bounded below by $\epsilon$ on $\mathcal{M}_\epsilon$. In particular, $T$ maps $\mathcal{M}_\epsilon$ bijectively onto $T(\mathcal{M}_\epsilon)$. Hence, $\mathcal{M}_\epsilon$ is finite-dimensional.
</details>
</MathBox>

### Normal compact operators

<MathBox title='' boxType='proposition'>
Let $T\in\mathcal{K}(H)$ be a normal compact operator on a separable Hilbert space, and let $E\mapsto P(E) = \operatorname{id}_E (T)$ be the associated spectral measure.
1. If $\epsilon > 0$, let $P_\epsilon = P(\Set{\lambda\in\mathbb{C} : |\lambda|\geq\epsilon}$ denote the spectral projection associated to the complement of an $\epsilon$-neighbourhood of $0$. Then $\operatorname{ran}(P_\epsilon)$ is finite dimensional.
2. If $\Sigma = \sigma(T)\setminus\Set{0}$, then
    - a. $\Sigma$ is a countable set
    - b. $\lambda\in\Sigma\implies\lambda$ is an eigenvalue of finite multiplicity, i.e. $0 < \dim(\ker(T-\lambda)) < \infty$
    - c. The only possible accumulation point of $\Sigma$ is $0$
    - d. There exist scalars $\lambda_n \in\Sigma$ and an orthonormal basis $\Set{x_n}_{n\in\N}$ of ran $P(\Sigma)$ such that
$$
  Tx = \sum_{n\in\N} \lambda_n \braket{x,x_n} x_n,\; \forall x\in H
$$

<details>
<summary>Proof</summary>

**(1):** Note that the function defined by the equation

$$
  g(\lambda) = \begin{cases}
    \frac{1}{\lambda},\quad& |\lambda|\geq\epsilon \\
    0,\quad& |\lambda| < \epsilon
  \end{cases}
$$

is a bounded measurable function on $\sigma(T)$ such that $g(\lambda)\lambda = \boldsymbol{1}_{F_\epsilon} (\lambda)$, where $F_\epsilon = \Set{z\in\mathbb{F}:|z|\geq\epsilon}$. It follows that $g(T)T = Tg(T) = P_\epsilon$. Hence, $\operatorname{ran}(P_\epsilon)$ is contained in $\operatorname{ran}(T)$, and the desired conclusion follows from Proposition $\ref{proposition-40}.5$.

**(2):** Let $\mu$ be the measure defined by $\mu(E) = \Sum_{n\in\N} \lVert P(E) e_n \rVert^2$, where $\Set{\epsilon_n}_{n\in\N}$ is some orthonormal basis for $H$. Then the measurable functional calculus yields an embedding of $L^\infty (F_\epsilon, \mathcal{B}_{F_\epsilon}, \mu|_{F_\epsilon})$ into $\mathcal{L}(\operatorname{ran}(P_\epsilon))$. It follows from **(1)** that $L^\infty (F_\epsilon,\mathcal{B}_{F_\epsilon},\mu|_{F_\epsilon})$ is finite-dimensional, where $F_\epsilon$ is as in the last paragraph. This implies that there is a finite set $\Set{\lambda_i}_{i=1}^{n\in\N} \subset F_\epsilon$ such that $\mu|_{F_\epsilon} = \sum_{i=1}^n \mu_{\Set{\lambda_i}}$. 

Assume, without loss of generality, that $\mu(\Set{\lambda_i}) > 0$ for all $i$. Then $P_\epsilon = \sum_{i=1}^n P_i$ is a decomposition of $P_\epsilon$ as a finite sum of non-zero (pairwise orthogonal) projections, where $P_i = P(\Set{\lambda_i})$. Since $P_i$ is the projection onto $\ker{(T-\lambda)}$, we thus find that
- $\Set{\lambda_i : 1\leq i \leq n} = \Sigma \cap F_\epsilon$
- each $\lambda_i$ is an eigenvalue of $T$ which has finite multiplicity

By allowing $\epsilon$ to decrease to $0$ through a countable sequence of values, we prove **(a)-(c)**. For **(d)**, note that if $\Sigma = \Set{\lambda_n}_{n\in\N}$, then $\lambda = \sum_{n\in\N} \lambda_n 1_{\Set{\lambda_n}}(\lambda) \mu$ almost everywhere. Hence, $T = \sum_{\lambda\in\Sigma} \lambda P(\Set{\lambda})$. Finally, if $\Set{x_n (\lambda)}_{n\in N_\lambda}$ is an orthonormal basis for $\operatorname{ran}(P(\Set{\lambda}))$, for each $\lambda\in\Sigma$, then $P(\Set{\lambda})x = \sum_{n\in N_\lambda} \brake{x, x_n (\lambda)} x_n (\lambda)$ for all $x\in H$. Letting $\Set{x_n}_{n\in\N}$ be an enumeration of $\bigcup_{\lambda\in\Sigma} \Set{x_n (\lambda)}_{n\in N_\lambda}$, we get the desired decomposition of $T$.
</details>
</MathBox>

<MathBox title='Singular value decomposition of compact operators' boxType='proposition'>
Let $T\in\mathcal{K}(H_1,H_2)$ be a compact operator between Hilbert spaces. Then $T$ admits the following decomposition

$$
  Tx = \sum_{n\in N} \lambda_n \left(\sum_{k\in I_n} \braket{x, x_k^{(n)}} y_k^{(n)} \right),\; x\in H_1
$$

where
1. $\sigma(|T|)\setminus\Set{0} = \Set{\lambda}_{n\in N}$, where $|T| = (T^* T)^{1/2} \in\mathcal{L}(H_1)$ and $N$ is some countable set. The sequence $\Set{\lambda_n}_{n\in N}$ consists of nonzero singular values of $T$.
2. $\Set{x_k^{(n)}}_{k\in I_n}$ is an orthonormal basis for $\ker(|T| - \lambda_n)$. Or, respectively, $\Set{y_k^{(n)}}_{k\in I_n}$ is an orthonormal basis for $T(\ker(|T| - \lambda_n) = \ker(|T^*| - \lambda_n)$). Here $I_n$ denote countable index sets.

In particular, we may assume that 
- $N$ is finite if $\dim(\operatorname{ran}(|T|)) < \infty$ or infinite if $\dim(\operatorname{ran}(|T|)) = \aleph_0$
- $\Set{\lambda_n}_{n\in N}$ is increasing

If the sequence $\Set{s_n = s_n (T)}_{n\in N}$ is defined by

$$
  s_n = \begin{cases}
    \lambda_1,&\quad 0 < n \leq |I_1| \\
    \lambda_2,&\quad |I_1| < n \leq |I_1| + |I_2| \\
    \vdots& \\
    \lambda_m,&\quad \sum_{1\leq k < m} |I_k| < n \leq \sum_{1\leq k \leq m} |I_k| \\
    0,&\quad \sum_{k\in N} |I_k| < n
  \end{cases}
$$

Then $\Set{s_n}_{n\in N}$ is a non-increasing sequence of non-negative real numbers, called the sequence of *singular values* of $T$.
</MathBox>

### Hilbert-Schmidt operators

<MathBox title='' boxType='lemma' tag='lemma-5'>
Let $T\in\mathcal{L}(H_1,H_2)$ be a linear operator between Hilbert spaces. Then the following are equivalent:
1. $\sum_{n\in N\subseteq\N} \lVert Te_n \rVert^2 \rVert < \infty$, for some orthonormal basis $\Set{e_n}_{n\in N\subseteq\N}$ of $H_1$
2. $\sum_{m\in M\subseteq\N} \lVert T^* f_m \rVert^2 < \infty$, for every orthonormal basis $\Set{f_m}_{m\in M\subseteq\N}$ of $H_2$
3. $\sum_{n\in N\subseteq\N} \lVert T e_n\rVert^2 < \infty$, for some orthonormal basis $\Set{e_n}_{n\in N\subseteq\N}$ of $H_1$

If these equivalent conditions are satisfied, then the sums of the series in **(2)** and **(3)** are independent of the choice of the orthonormal bases and are all equal to one another.

<details>
<summary>Proof</summary>

If $\Set{e_n}_{n\in N}$ (respectively, $\Set{f_m}_{m\in M}$) is any orthonormal basis for $H_1$ (respectively, $H_2$), then note that

$$
\begin{align*}
  \sum_{n\in N} \lVert Te_n \rVert^2 =& \sum_{n\in N} \sum_{m\in M} |\braket{Te_n, f_m}|^2 \\
  =& \sum_{m\in M} \sum_{n\in N} |\braket{T^* f_m, e_n}|^2 \\
  =& \sum_{m\in M} \lVert T^* f_m\rVert^2
\end{align*}
$$

and all the assertions of the proposition follow.
</details>
</MathBox>

<MathBox title='Hilbert-Schmidt operator' boxType='definition'>
A linear operator $T\in\mathcal{L}(H_1, H_2)$ between Hilbert spaces is a *Hilbert-Schmidt operator* if and only if it satisfies the equivalent conditions of Lemma $\ref{lemma-2}$, and the *Hilbert-Schmidt norm* of such an operator is defined to be

$$
  \lVert T \rVert_2 = \left(\sum_{n\in N} \lVert Te_n \rVert^2 \right)^{1/2}
$$

where $\Set{e_n}_{n\in N\subseteq\N}$ is any orthonormal basis for $H_1$. The set of all Hilbert-Schmidt operators from $H_1$ to $H_2$ is denoted $\mathcal{L}^2 (H_1, H_2)$.
</MathBox>

### Fredholm operators

## Example: $\ell^p$

Consider the sequence space $X = \ell^p (\N)$. For $\Set{ \lambda_j}_{j\in\N} \subset \mathbb{C}$ with $\sup_{j\in\N}\left| \lambda_j \right| < \infty$ we define a bounded linear operator $T:\ell^p (\N) \to \ell^p (\N)$ given by $(Tx)_j := \lambda_j x_j$. Evidently, the $\lambda_j$ are eigenvalues with corresponding eigenvectors $e_j$ as unit sequences, and the set $\Set{ \lambda_j}_{j\in\N} \subset \mathbb{C}$ forms the point spectrum of $T$

$$
  \Set{ \lambda_j}_{j\in\N} = \sigma_p (T) \subseteq \sigma (T)
$$

Because $\sigma_p (T)$ is infinite it can have accumulation points $\mu \in \mathbb{C}$ with $\mu \in \overline{\sigma_p (T)}$ such that $T - \mu I$ is injective. It can be shown that $T - \mu I$ is not surjective.

Assuming by contradiction that $T - \mu I$ is surjective, implying that it is also bijective. By the bounded inverse theorem, the inverse $(T - \mu I)^{-1}$ is therefore bounded with operator norm

$$
\begin{align*}
  \lVert (T - \mu I)^{-1}\rVert \geq& \lVert (T - \mu I)^{-1} e_j\rVert_{\ell^p (\N)} \\
  =& \lVert (\lambda_j - \mu I)^{-1} e_j\rVert_{\ell^p (\N)} \\
  =& \frac{1}{\left| \lambda_j - \mu \right|}
\end{align*}
$$

Since $\mu$ is an accumulation point we can find a subsequence such that the resulting fraction goes to infinity, so that $(T - \mu I)^{-1}$ cannot be bounded. Thus, by contradiction $T - \mu I$ is not surjective. The spectrum of $T$ becomes

$$
\begin{align*}
  \sigma (T) =& \Set{ \mu \in \mathbb{C} | \mu \notin \Set{\lambda_j}_{j\in\N} \land \mu\in\overline{\Set{\lambda_j}}_{j\in\N}} \\
  =& \sigma_p(T) \cup \sigma_c(T)
\end{align*}
$$

# Analysis in normed spaces

<MathBox title='Bounded multilinear operators' boxType='definition'>
Let $X$ and $Y$ be normed spaces. The space of bounded $k$-linear operators is defined inductively by

$$
  \mathcal{B}(X,Y) = \mathcal{B}(X, \mathcal{B}^{k-1}(X,Y)),\; k\in\N
$$

where $\mathcal{B}^1(X,Y) = \mathcal{B}(X,Y)$. An element $L\in\mathcal{B}^k (X,Y)$ is a $k$-linear operator $L:X^k \to Y$
</MathBox>

<MathBox title='Continuity criterion for bounded multilinear operators' boxType='definition'>
Let $X$ and $Y$ be normed spaces. An $n$-linear operator $L\in\mathcal{B}^n (X,Y)$ is continuous if its norm

$$
  \lVert L \rVert_{X\to\mathcal{B}^{n-1}(X,Y)} = \sup\Set{\frac{\lVert L(h_1,\dots,h_n) \rVert_Y}{\prod_{i=1}^n \lVert h_i \rVert_X} | h_i \in X_i \setminus\Set{0}}
$$

is finite.

<details>
<summary>Proof</summary>

The proof is shown for $n = 2$ (the result follows by induction). An element of $\mathcal{B}^2 (X, Y)$ is a linear tranformation $L:X\to\mathcal{B}(X,Y)$ whose induced norm

$$
  \lVert L \rVert_{X\to\mathcal{B}(X,Y)} = \sup\Set{\frac{\lVert L(h_1) \rVert_{X\to Y}}{\lVert h_1 \rVert_X} | h_1 \in X\setminus\Set{0}}
$$

is finite, where for each $h_1 \in X$, the linear transformation $L(h_1): X \to Y$ is bounded, i.e.

$$
  \lVert L(h_1)\rVert_{X\to Y} = \sup\Set{\frac{\lVert L(h_1)h_2 \rVert_Y}{\lVert h_2 \rVert_X} | h_2 \in X\setminus\Set{0}} < \infty
$$

We combine $\lVert L(h_1) \rVert_{X\to Y} \leq \lVert L \rVert_{X\to\mathcal{B}(X,Y)}\lVert h_1 \rVert_X$ and $\lVert L(h_1)h_2 \rVert_Y \leq \lVert L(h_1) \rVert_{X\to Y} \lVert h_2 \rVert_X$ to get

$$
  \lVert L(h_1)h_2 \rVert_Y \leq \lVert L \rVert_{X\to\mathcal{B}(X,Y)} \lVert h_1 \rVert_X \lVert h_2 \rVert_X
$$

or when both $\lVert h_1 \rVert_X$ and $\lVert h_2 \rVert_X$ are nonzero, that

$$
  \lVert L \rVert_{X\to\mathcal{B}(X,Y)} \geq \frac{\lVert L(h_1)h_2 \rVert_Y}{\lVert h_1 \rVert_X \lVert h_2 \rVert_X}
$$

The upper bound $\lVert L \rVert_{X\to\mathcal{B}(X,Y)}$ on the ratios is the supremum because for $\epsilon > 0$ there exists a nonzero $h_1 \in X$ such that

$$
  \frac{\lVert L(h_1) \rVert_{X\to Y}}{\lVert h_1 \rVert_X} > \lVert L \rVert_{X\to\mathcal{B}(X,Y)} - \frac{\epsilon}{2}
$$

and there exists a nonzero $h_2 \in X$ such that

$$
  \frac{\lVert L(h_1)h_2 \rVert_Y}{\lVert h_2 \rVert_X} > \lVert L(h_1) \rVert_{X\to Y} - \frac{\epsilon\lVert h_1 \rVert_X}{2}
$$

so that

$$
\begin{align*}
  \frac{\lVert L(h_1) h_2 \rVert_Y}{\lVert h_1 \rVert_X \lVert h_2 \rVErt_X} >& \frac{\lVert L(h_1) \rVert_{X\to Y}}{\lVert h_1 \rVert_X} - \frac{\epsilon}{2} \\
  >& \lVert L \rVert_{X\to\mathcal{B}(X,Y)} -\epsilon
\end{align*}
$$

Thus

$$
  \lVert L \rVert_{X\to\mathcal{B}(X,Y)} = \sup\Set{\frac{\lVert L(h_1)h_2 \rVert_Y}{\lVert h_1 \rVert_X \lVert h_2 \rVert_X} | h_1, h_2 \in X\setminus\Set{0}}
$$
</details>
</MathBox>

## Fréchet derivative

<MathBox title='Fréchet derivative' boxType='definition'>
Let $(X, \lVert\cdot\rVert_X)$ and $(Y, \lVert\cdot\rVert_Y)$ be normed spaces. A function $f:X\to Y$ is *Fréchet differentiable* at $x\in X$ if there exists a bounded linear operator $T\in\mathcal{B}(X, Y)$ such that

$$
  \lim_{\lVert h \rVert_X \to 0} \frac{\lVert f(x + h) - f(x) - Th \rVert_Y}{\lVert h \rVert_X} = 0
$$

The operator $T$ is called the *Fréchet derivative* of $F$ at $x$, denoted $T = \d f(x)$. The Fréchet differential $Th = \d f(x) h$ is called the *first order variation* of $f$ at $x$. The function $f$ is *Fréchet differentiable* on $X$ if the function $\d f : X \to \mathcal{B}(X, Y)$ is continuous. The set of continuosly Fréchet differentiable functions from $X$ to $Y$ is denoted $C^1 (X, Y)$.
</MathBox>

<MathBox title='Fréchet partial derivative' boxType='definition'>
Let $X_i$ for $i=1,\dots,n$ be a finite collection of normed spaces. Fix an open set $U \subset X_1 \times\cdots\times X_n$, and an ordered list of $k$ integers $i_1,\dots,i_k$ where $i_j \in\Set{1,\dots,k}$ (not necessarily distinct). The $k$-th order partial derivative of $f\in C^k (U, Y)$ corresponding to $i_1,\dots,i_k$ is the function $\d_{i_1}\cdots\d_{i_k} f \in C(U, \mathcal{B}(X_1,\dots,X_k;Y))$.

When $X_i = \mathbb{F}$ for all $i=1,\dots,n$ and $Y$ the $k$-th order partial derivative $\d_{i_1}\cdots\d_{i_k} f$ is written

$$
  \frac{\partial^k f}{\partial x_{i_1}\cdots\partial x_{i_k}}
$$
</MathBox>

<MathBox title='The Fréchet derivative is unique' boxType='proposition'>
Let $X$ and $Y$ be normed spaces. If a function $f:X\to Y$ is Fréchet differentiable at $x\in X$, then the Fréchet derivative $\d f(x): X\to Y$ is unique.

<details>
<summary>Proof</summary>

Assume $T_1, T_2 \in\mathcal{B}(X,Y)$ are Fréchet derivatives of $f:X\to Y$ at $x\in X$ satisfying

$$
  \lim_{h\to 0} \frac{\lVert f(x + h) - f(x) - T_i h \rVert_Y}{\lVert h\rVert_X} = 0,\; i=1,2
$$

For nonzero $v\in X$ and $\tau\in\mathbb{F}$ we have

$$
\begin{align*}
  \frac{\lVert T_1 v - T_2 v \rVert_Y}{\lVert v \rVert_X} =& \frac{|\tau|}{|\tau|}\frac{\lVert T_1 v - T_2 v\rVert_Y}{\lVert v \rVert_X} \\
  =& \frac{\lVert T_1 (\tau v) - T_2 (\tau v) \rVert_Y}{\lVert \tau v \rVert_X} \\
  =& \frac{\lVert (f(x + \tau v) - f(x) - T_2 (\tau v)) - (f(x + \tau v) - f(x) - T_1 (\tau v)) \rVert_Y}{\lVert \tau v\rVert_X} \\
  \tleq \frac{\lVert f(x + \tau v) - f(x) - T_2 (\tau v) \rVert_Y}{\lVert \tau v \rVert_X} + \frac{\lVert f(x + \tau v) - f(x) - T_1 (\tau v) \rVert_Y}{\lVert \tau v \rVert_X} \xrightarrow{\tau\to 0} \to 0
\end{align*}
$$

This shows that $T_1 v = T_2 v$ for all $v\in X$, implying that $T_1 = T_2$.
</details>
</MathBox>

<MathBox title='Fréchet differentiability criterion' boxType='proposition'>
Let $X$ and $Y$ be normed spaces. Then the following are equivalent
1. A function $f:X\to Y$ is Fréchet differentiable at $x$ with derivative $T \in\mathcal{B}(X,Y)$
2. For every $\epsilon > 0$ there exists $\delta > 0$ with the open ball $B(x, \delta) \subset X$ such that for all $h\in B(x, \delta)$
$$
  \lVert f(x + h) - f(x) - Th \rVert_Y \leq \epsilon \lVert h \rVert_X
$$
</MathBox>

<MathBox title='Fréchet differentiable functions are Lipschitz' boxType='proposition' tag='proposition-23'>
Let $X$ and $Y$ be normed spaces. If $f:X\to Y$ is Fréchet differentiable at $x_0$, then $f$ is locally Lipschitz at $x_0$. That is, there exists $\delta > 0$ and $L > 0$ such that $B(x_0, \delta) \subset X$ and for all $x \in B(x,\delta)$

$$
  \lVert f(x) - f(x_0) \rVert_Y \leq L\lvert x - x_0 \rVert_X
$$

<details>
<summary>Proof</summary>

Since $f:X\to Y$ is Fréchet differentiable at $x_0 \in X$, then for $\epsilon = 1$ there is $\delta > 0$ such that for all $x\in X$ with $\lVert x - x_0 \rVert_X < \delta$ we have

$$
  \frac{\lVert f(x) - f(x_0) - \d f(x_0) (x - x_0) \rVert_Y}{\lVert x - x_0 \rVert_X} < 0
$$

This can be rewritten as

$$
  \lVert f(x) - f(x_0) - \D f(x_0)(x - x_0) \rVert_Y < \lVert x - x_0 \rVert_X
$$

By the triangle inequality, we have

$$
\begin{align*}
  \lVert f(x) - f(x_0) \rVert_Y =& \lVert f(x) - f(x_0) - \d f(x_0) (x - x_0) + \d f(x_0)(x - x_0) \rVert_Y \\
  \leq& \lVert f(x) - f(x_0) - \d f(x_0) (x - x_0) \rVert_Y + \lVert \d f(x_0)(x - x_0) \rVert_Y \\
  \leq& \lVert x - x_0 \rVert_X + \lVert \d f(x_0)(x - x_0) \rVert_Y 
\end{align*}
$$

Since $\d f(x_0)$ is a bounded linear operator, it follows that

$$
  \lVert \d f(x_0)(x - x_0) \rVert_Y \leq \lVert \d f(x_0) \rVert \cdot \lVert \rVert_X
$$

Thus, we obtain

$$
  \lVert f(x) - f(x_0) \rVert_Y \leq (1 + \lVert \d f(x_0)\rVert)\lVert x - x_0 \rVert_X
$$

Taking $L = 1 + \lVert \d f(x_0) \rVert$ shows that $f$ is locally Lipschitz at $x_0$.
</details>
</MathBox>

<MathBox title='Fréchet linearity' boxType='proposition'>
Let $X$ and $Y$ be normed spaces. If $f,g:X\to Y$ are differentiable at $x \in X$, then for any scalars $\alpha,\beta\in\mathbb{F}$, the linear combination $\alpha f + \beta g$ is differentiable at $x$ with derivative

$$
  \d (\alpha f + \beta g)(x) = \alpha \d f(x) + \beta \d g(x)
$$

<details>
<summary>Proof</summary>

By differentiability of $f$ and $g$ at $x$, for any $\epsilon > 0$ there is $\delta > 0$ such that for all $h \in B(x, \delta) \subset X$ we have

$$
\begin{align*}
  \lVert f(x + h) - f(x) - \d f(x)h \rVert_Y \leq& \frac{\epsilon \lVert h \rVert_X}{2(|\alpha| + 1)} \\
  \lVert g(x + h) - g(x) - \d g(x)h \rVert_Y \leq& \frac{\epsilon \lVert h \rVert_X}{2(|\beta| + 1)}
\end{align*}
$$

Thus

$$
\begin{align*}
  & \lVert \alpha f(x + h) + \beta g(x + h) - \alpha f(x) - \beta g(x) - \alpha\d f(x)h - \beta\d g(x) h \rVert_Y \\
  &\leq |\alpha|\cdot\lVert f(x + h) - f(x) - \d f(x)h \rVert_Y + |\beta|\cdot\lVert g(x + h) - g(x) - \d g(x)h \rVert_Y \\
  &\leq \frac{\epsilon|\alpha|\cdot\lVert h \rVert_X}{2(|\alpha| + 1)} + \frac{\epsilon|\beta|\cdot\lVert h \rVert_X}{2(|\beta| + 1)} = \epsilon \lVert h \rVert_X \left(\frac{|\alpha|}{2(|\alpha| + 1)} + \frac{|\beta|}{2(|\beta| + 1)} \right) \\
  < & \epsilon \lVert h \rVert_X
\end{align*}
$$

Since $\d f(x), \d g(x)\in\mathcal{B}(X,Y)$ it follows that $\alpha \d f(x) + \beta g(x) \in \mathcal{B}(X,Y)$. Hence, $\alpha f + \beta g$ is differentiable at $x$ with Fréchet derivative $\alpha \d f(x) + \beta g (x)$.
</details>
</MathBox>

<MathBox title='Fréchet product rule' boxType='proposition'>
Let $X$ be a normed space and $\mathbb{F}$ a field. If $f,g: X\to\mathbb{F}$ are Fréchet differentiable at $x\in X$, then the product $fg$ is differentiable at $x$ with derivative

$$
  \d (fg)(x) = g(x) \d f(x) + f(x) \d g(x)
$$

<details>
<summary>Proof</summary>

By differentiability of $f$ and $g$ at $x$, for each $\epsilon > 0$ there is $\delta_x > 0$ with $B(x,\delta_x)\subset X$, and a constant $L > 0$ (by Proposition $\ref{proposition-23}$) such that for all $0 < \lVert h\rVert < \delta_x$

$$
  |f(x + h) - f(x)| \leq L \lVert h \rVert_X
$$

and

$$
\begin{align*}
  |f(x + h) - f(x) - \d f(x)h| \leq& \frac{\epsilon \lVert h \rVert_X}{3(|g(x)| + 1)} \\
  |g(x + h) - f(x) - \d f(x)h| \leq& \frac{\epsilon \lVert h \rVert_X}{3(|f(x)| + L)}
\end{align*}
$$

For $\epsilon > 0$ choose

$$
  \delta = \min\Set{1, \delta_x, \frac{\epsilon}{3L(\lVert \d g(x) \rVert + 1)}}
$$

When $0 \leq \lVert h \rVert_X < 0$, we get

$$
\begin{align*}
  & |f(x + h)g(x + h) - f(x)g(x) - g(x) \d f(x) h - f(x) \d g(x) h| \\
  =& |f(x + h)g(x + h) - f(x + h)g(x) + f(x + h)g(x) - f(x)g(x) \\
  &+ f(x + h)\d g(x) h - f(x + h) \d g(x) h - g(x) \d f(x) h - f(x) \d g(x) h| \\
  \leq& |f(x + h)|\cdot |g(x + h) - g(x) - \d g(x)h| \\
  &+ |g(x)|\cdot|f(x + h) - f(x) - \d f(x) h| \\
  &+ |f(x + h) - f(x)|\cdot\lVert \d g(x) \rVert\cdot\lVert h \rVert_X \\
  \leq& (|f(x)| + L)\frac{\epsilon\lVert h \rVert_X}{3(|f(x) + L|)} \\
  &+ |g(x)|\frac{\epsilon\lVert h \rVert_X}{3(|g(x)| + 1)} + \delta L \lVert \d g(x) \rVert\cdot\lVert h \rVert_X \\
  <& \epsilon \lVert h \rVert_X
\end{align*}
$$

Where we have used the Lipschitz implication

$$
  |f(x + h) - f(x)| \leq L\lVert h \rVert_X \implies |f(x + h)| \leq |f(x)| + L\lVert h \rVert_X
$$

Hence, $fg$ is differentiable at $x$ with Fréchet derivative $\d (fg)(x) = g(x) \d f(x) + f(x) \d g(x)$.
</details>
</MathBox>

<MathBox title='Bilinear Fréchet product rule' boxType='proposition' tag='proposition-43'>
Let $X$ and $Y$ be normed spaces. If $L \in\mathcal{L}^2 (X,Y)$ is a bilinear operator, then $L\in C^2 (X^2, Y)$ with

$$
  \d L(x)h = L(h_1, x_2) + L(x_1, h_2)
$$

If $X$ is a normed algebra, and $L(x_1, x_2) = x_1 x_2$ we obtain the usual form of the product rule.

<details>
<summary>Proof</summary>

By bilinearity

$$
  L(x_1 + h_1, x^2 + h_2) - L(x_1, x_2) = L(h_1, x_2) + L(x_1, h_2) + L(h_1, h_2)
$$

Since $|L(h_1,h_2)| \leq \lVert L \rVert\cdot|h_1|\cdot|h_2| = o(|h|^2)$ we get

$$
  L(x_1 + h_1, x^2 + h_2) - L(x_1, x_2) = L(h_1, x_2) + L(x_1, h_2) + O(|h|^2)
$$
</details>
</MathBox>

<MathBox title='Fréchet chain rule' boxType='proposition'>
Let $X, Y, Z$ be normed spaces. If $f:X\to Y$ is Fréchet differentiable at $x\in X$ and $g:Y\to Z$ is Fréchet differentiable at $y = f(x) \in Y$, the composition $g\circ f$ is Fréchet differentiable at $x$ with derivative

$$
  \d (g\circ f)(x) = \d g(f(x)) \d f(x)
$$

<details>
<summary>Proof</summary>

Choose $\epsilon > 0$. By differentiability of $f:X\to Y$ at $x\in X$ and of $g:Y\to Z$ at $y = f(x) \in Y$, there is $\delta_1 > 0$ such that $B(x,\delta_1)\subset X$ and for all $\xi \in X$ satisfying $0 \lVert\xi\rVert_X < \delta_1$ we have

$$
  \lVert f(x + \xi) - f(x) - \d f(x)\xi \rVert_Y \leq \frac{\epsilon\lVert\xi\rVert_X}{2(\lVert \d g(y) \rVert + 1)}
$$

By Proposition $\ref{proposition-23}$, $f$ is locally Lipschitz at $x$, i.e. there is $\delta_2 > 0$ and $L > 0$ such that $B(x,\delta_2)\subset X$ and for all $\xi\in X$ satisfying $0 < \lVert\xi\rVert_X < \delta_2$ we have

$$
  \lVert f(x + \xi) - f(x) \rVert_X \leq L\lVert\xi\rVert_X
$$

Set $\delta_x = \min\Set{\delta_1, \delta_2}$. Since $g$ is differentiable at $y$, there is $\delta_y > 0$ such that $B(y, \delta_y) \subset Y$ and for all $0 \leq \lVert\eta\rVert_Y < \delta_y$ we have

$$
  \lVert g(y + \eta) - g(y) -\d g(y)\eta \rVert_Z \leq \frac{\epsilon\lVert\eta\rVert_Y}{2L}
$$

Set $\delta = \min\Set{\delta_x, \delta_y / L}$ such that $L\delta\leq\delta_y$. If we take $\eta(\xi) = f(x + \xi) - f(x) = f(x + \xi) - y$ then $h = g\circ f$ satisfies

$$
  h(x + \xi) - h(x) = g(f(x + \xi)) - g(f(x)) = g(y + \eta(\xi) - g(y))
$$

Thus for all $\xi\in X$ satisfying $\lVert\xi\rVert_X < \delta$ we have

$$
  \lVert \rVert_Y = \lVert f(x + \xi) - f(x) \rVert_Y \leq L\lVert\xi\rVert_X < L\delta \leq \delta_y
$$

so that

$$
\begin{align*}
  &\lVert h(x + \xi) - h(x) - \d g(y) \d f(x)\xi \rVert_Z \\
  =& \lVert g(y + \eta(\xi)) - g(y) - \d g(y)\eta(\xi) + \d g(y) \eta(\xi) - \d g(y) \d f(x)\xi \rVert_Z \\
  \tleq& \lVert g(y + \eta(\xi)) - g(y) - \d g(y)\eta(\xi) \rVert_Z \\
  &+ \lVert \d g(y)\eta(\xi) - \d g(y) \d f(x)\xi \rVert_Z \\
  \leq& \lVert g(y + \eta(\xi)) - g(y) - \d g(y)\eta(\xi) \rVert_Z \\
  &+ \lVert \d g(y) \rVert \cdot \lVert \eta(\xi) - \d f(x)\xi \rVert_Y \\
  =& \lVert g(y + \eta(\xi)) - g(y) - \d g(y)\eta(\xi) \rVert_Z \\
  &+ \lVert \d g(y) \rVert \cdot \lVert f(x + \xi) - f(x) - \d f(x)\xi \rVert_Y \\
  \leq& \frac{\epsilon\lVert\eta(\xi)\rVert_Y}{2L} + \lVert \d g(y) \rVert \frac{\epsilon\lVert\xi\rVert_X}{2(\lVert\d g(y)\rVert + 1)} \\
  <& \frac{\epsilon L\lVert\xi\rVert_X}{2 L} + \frac{\epsilon\lVert\xi\rVert_X}{2} = \epsilon\lVert\xi\rVert_X
\end{align*}
$$

Since $\d g(x) \in\mathcal{B}(X,Y)$ and $\d g(y) \in\mathcal{B}(Y,Z)$, it follows that $\d g(y) \d f(x) \in \mathcal{B}(X,Z)$. Hence $g\circ f$ is differentiable at $x$ with Fréchet derivative $\d (g\circ f)(x) = \d g(f(x)) \d f(x)$.
</details>
</MathBox>

<MathBox title='Fréchet mean value theorem (univariate)' boxType='theorem'>
Let $X$ be a normed space. If $f\in C^1 (I,X)$ is continuously differentiable on an interval $I\subseteq\R$, then for $s,t\in I$ with $s\leq t$

$$
\begin{gather*}
  \lVert f(t) - f(s) \rVert_X \leq M |t-s| \\
  M := \sup_{\tau\in[s,t]} \lVert \d f(\tau) \rVert
\end{gather*}
$$

<details>
<summary>Proof</summary>

Fix $\tilde{M} > M\in\R$ and consider $d(\tau) := \lVert f(\tau) - f(s)\rVert_X - \tilde{M}(\tau - s)$ for $\tau\in[s,t]$. Suppose $\tau_0$ is the largest $\tau$ for which $d(\tau) \leq 0$ holds. Then tehre must be a sequence $\epsilon_n \downarrow 0$ such that

$$
\begin{align*}
  0 \leq& d(\tau_0 + \epsilon_n) \\
  \leq& \lVert f(\tau_0 + \epsilon_n) - f(\tau_0) \rVert - \tilde{M}\epsilon_n + d(\tau_0) \\
  =& \lVert \d f(\tau_0)\epsilon_n + o(\epsilon_n) \rVert - \tilde{M}\epsilon_n \\
  \leq& (M - \tilde{M} + o(1))\epsilon_n < 0
\end{align*}
$$

Taking $n\to\infty$ contradicts our assumption.
</details>
</MathBox>

<MathBox title='Matrix representation of Fréchet derivatives' boxType='proposition' tag='proposition-33'>
Let $U\subseteq \R^n$ be open. If a vector function $f:U \to\R^m$ by $f = (f_i:U\to\R)_{i=1}^m$, in the standard basis of $\R^n$, is Fréchet differentiable at $\mathbf{x}\in U$ , then the partial derivatives $\d_j f_i \mathbf{x}$ exist for all $j = 1,\dots,n$ and $i=1,\dots,m$. The matrix representation of $\d f(\mathbf{x})$ in standard coordinates is the Jacobian matrix

$$
  J(\mathbf{x}) = \begin{bmatrix} 
    \d_1 f_1 (\mathbf{x}) & \cdots & \d_n f_1 (\mathbf{x}) \\
    \vdots & \ddots & \vdots \\
    \d_1 f_m (\mathbf{x}) & \cdots & \d_n f_m (\mathbf{x})
  \end{bmatrix}
$$

<details>
<summary>Proof</summary>

Let $J_j$ be the $j$-th column of $J(\mathbf{x})$, i.e. $J_j = \d f(\mathbf{x})\mathbf{e}_j$, and let $J_{ij}$ be the $i$-th entry of the $j$-column of $J(\mathbf{x})$. For $\mathbf{h} = r\mathbf{e}_j$ we have

$$
\begin{align*}
  0 =& \lim_{\mathbf{h}\to\mathbf{0}} \frac{\lVert f(\mathbf{x} + \mathbf{h}) - f(\mathbf{x}) - \d f(\mathbf{x}\mathbf{h}) \rVert}{\lVert \mathbf{h} \rVert} \\
  =& \lim_{r\to 0} \frac{\lVert f(\mathbf{x} + r\mathbf{e}_j) - f(\mathbf{x}) - r\d f(\mathbf{x}) \mathbf{e}_j \rVert}{|r|\cdot\lVert\mathbf{e}_j\rVert} \\
  =& \lim_{r\to 0} \frac{\lVert f(x_1,\dots,x_j + r,\dots,x_n) - f(x_1,\dots,x_n) - rJ_j \rVert}{|r|}
\end{align*}
$$

This implies that for each component of $f$

$$
  \lim_{r\to 0} \frac{|f(x_1,\dots,x_j + r,\dots,x_n) - f(x_1,\dots,x_n) - rJ_{ij} |}{|r|} = 0
$$

showing that the partial derivative $\d_j f_i (\mathbf{x}) = J_{ij}$ exists.
</details>
</MathBox>

### Higher order derivatives

<MathBox title='Higher order Fréchet derivatives' boxType='definition'>
Let $X$ and $Y$ be normed spaces, and suppose $f:X\to Y$ is Fréchet differentiable on $X$. The function $f$ is twice Fréchet differentiable on $X$ if $\d f: X\to \mathcal{X,Y}$ is differentiable on $X$. The second order Fréchet derivative is the map

$$
  \d^2 f = \d (\d f): X\to\mathcal{B}(X,\mathcal{B}(X,Y)) = \mathcal{B}^2 (X,Y)
$$

Inductively, $f$ is $n \geq 2$ times Fréchet differentiable on $X$ if the map $\d^{n-1} f:X\to\mathcal{B}^{n-1} (X,Y)$ is differentiable on $X$. The $n$-the order Fréchet derivative is the map

$$
  \d^n f = \d (\d^{n-1} f)
$$

For each $x\in X$, the $n$-th order derivative $\d^n f(x)\in\mathcal{B}^n (X,Y)$ is a continuous multilinear operator $\d^n f(x): X^n \to Y$.

The set of $n$-times continuously Fréchet differentiable functions from $X$ to $Y$ is denoted $C^n (X, Y) = \Set{f\in C^1 (X, Y) | \d f \in C^{n-1} (X, Y)}$ and is a vector space of function. A function $f$ is *smooth* if $f\in C^n (X,Y)$ for all $n\in\N$. The space of smooth functions from $X$ to $Y$ is denoted $C^\infty (X,Y)$.
</MathBox>

<MathBox title='Symmetry of second order Fréchet derivatives' boxType='proposition'>
Let $X$ and $Y$ be normed spaces with $Y$ finite-dimensional. If $f\in C^2$ (X, Y) is twice differentiable on an open subset $U\subseteq X$, then for all $\mathbf{x}\in U$ and for all $(u, v)\in X\times X$

$$
  \d^2 f(x)(u,v) = \d^2 f(x)(v,u)
$$

When $U$ is an open subset of $X = X_1 \times\cdots\times X_n$ for normed spaces $X_i$ and $f\in C^2 (U, Y)$ for finited dimensional $Y$, then for all $x\in U$ and for all $i,j\in\Set{1,\dots,n}$

$$
  \d_i \d_j f(x) = \d_j \d_i f(x)
$$

When $U$ is an open subset of $X = \mathbb{F}^n$, $Y = \mathbb{F}^m$ and $f = (f_1,\dots,f_m)\in C^2 (U,Y)$, then for all $x\in U$ and for all $i,j\in\Set{1,\dots,n}$ and for all $k\in\Set{1,\dots,m}$ there holds

$$
  \frac{\partial^2 f_k}{\partial x_i \partial x_j} = \frac{\partial^2 f_k}{\partial x_j \partial x_i}
$$

<details>
<summary>Proof</summary>

The hypothesis of finite dimensionality of $Y$ implies that we can assume without loss of generality that $Y = \mathbb{F}^m$ and that $f = (f_1,\dots,f_m)$. Since $\mathbb{C}^m$ and $\R^{2m}$ are isomorphic as Banach spaces (with the standard norms) we can assume without loss of generality that $\mathbb{F} = \R$. As $f_k :U\to\R$, it suffices to show the result for $Y = \R$.

For a fixed $x\in U$ and $u,v\in X$ there exist $t,s > 0$ by the openness of $U$ such that $x + \xi u + \eta v \in U$ for all $\xi, \eta \in [0,\max\Set{s,t}]$. Define $g:[0,t]\to\R$ by

$$
  g_\xi (x) = f(x + \xi u) - f(x)
$$

and $S_{\eta, t}(x):[0,s]\to\R$ by

$$
\begin{align*}
  S_{\eta,t}(x) =& g_t (x + \eta v) - g_t (x) \\
  =& f(x + tu + \eta v) - f(x + \eta v) - f(x + tu) + f(x) 
\end{align*}
$$

Note that $S_{0,t} (x) = 0$ and that with $x$ and $t$ fixed

$$
  \d S_{\eta, t}(x) = \d g_t (x + \eta v)v
$$

The function $S_{\eta,t}$ is continuous on $[0,s]$ and differentiable on $(0,s)$, so by the mean value theorem there is $\sigma_{s,t}\in(0,s)$ such that

$$
\begin{align*}
  S_{s,t}(x) =& S_{s,t}(x) - S_{0,t}(x) \\
  =& \d g_t (x + \sigma_{s,t}v)(v)(s - 0) \\
  =& \d g_t (x + \sigma_{s,t}v)(sv)
\end{align*}
$$

Since $g_t (x + \eta v) = f(x + tu + \eta v) - f(x + \eta v)$ we have

$$
  \d g_t (x + \sigma_{s,t}v)(sv) = \d f(x + tu + \sigma_{s,t} v)(sv) - \d f(x + \sigma_{s,t}v)(sv)
$$

The function

$$
  \xi\mapsto \d f(x + tu + \sigma_{s,t} v)(sv) - \d f(x + \sigma_{s,t}v)(sv)
$$

is zero when $\xi = 0$, is continuous on $[0,t]$ and differentiable on $(0,t)$, so by the mean value theorem there is $\tau_{s,t}\in(0,t)$ such that

$$
  \d f(x + tu + \sigma_{s,t} v)(sv) - \d f(x + \sigma_{s,t}v)(sv) = \d^2 f(x + \tau_{s,t}u + \sigma_{s,t}v)(sv)(tu)
$$

Thus,

$$
  S_{s,t}(x) = \d^2 f(x + \tau_{s,t}u + \sigma_{s,t}v)(sv)(tu)
$$

Switching the roles of $tu$ and $sv$ in the above argument gives the existence of $\tau'_{s,t}$ and $\sigma'_{s,t}$ such that

$$
  S_{s,t}(x) = \d^2 f(x + \sigma'_{s,t}v + \tau'_{s,t}u)(tu, sv)
$$

Equating the two expression for the same quantity $S_{s,t}(x)$ gives

$$
  \d^2 f(x + \tau_{s,t}u + \sigma_{s,t}v)(sv, tu) = \d^2 f(x + \sigma'_{s,t}v + \tau'_{s,t}u)(tu, sv)
$$

Since $\d^2 f(x)$ is multilinear, we can pull out the scalars $s$ and $t$ from the inputs $sv$ and $tu$ from both sides; they cancel, giving

$$
  \d^2 f(x + \tau_{s,t}u + \sigma_{s,t}v)(v,u) = \d^2 f(x + \sigma'_{s,t}v + \tau'_{s,t}u)(u,v)
$$

In the limit $s,t\to 0$, the quantities $\sigma_{s,t}, \sigma'_{s,t}, \tau_{s,t}, \tau'_{s,t}$ all go to zero. The assumed continuity of $\d^2 f$ on $U$ implies as $s,t\to 0$ that $\d^2 f(x)(v,u) = \d^2 f(x)(u,v)$. In the case that $X = X_1 \times\cdots\times X_n$, we take $u_i \in X$ and $v_j \in X_j$ and form the vectors

$$
\begin{align*}
  u =& (\delta_{ik} u_i)_{k=1}^n = (0,\dots,u_i,\dots,0) \\
  v =& (\delta_{jk} v_i)_{k=1}^n = (0,\dots,v_j,\dots,0)
\end{align*}
$$

to get

$$
  \d^2 f(x)(u,v) = \d^2 f(x)(v,u)
$$

which implies that $\d_i \d_j f(x) = \d_j \d_i f(x)$ and 

$$
  \frac{\partial^2 f_k}{\partial x_i \partial x_j} = \frac{\partial^2 f_k}{\partial x_j \partial x_i}
$$

for all $k=1,\dots,m$.
</details>
</MathBox>

<MathBox title='Representation of Fréchet derivatives' boxType='proposition'>
Let $X$ and $Y$ be normed spaces. If $f\in C^r (X,Y)$, then for every $x\in X$ the $k$-th derivative of $f$ at $x$ takes the form

$$
  \d^k f(x)(u_1,\dots,u_k) = \left.\partial_{t_1}\cdots\partial_{t_k} f\left(x + \sum_{i=1}^k t_i u_i \right)\right|_{t_1=\cdots=t_k=0}
$$

Moreover, $\d^k f(x) \in \mathcal{B}^k (X,Y)$ is a bounded symmetric multilinear operator.
</MathBox>

<MathBox title='Hessian matrix' boxType='example'>
For an open subset $U\subseteq\R^n$, suppose $f:U\to\R$ is differentiable on $U$, implying that the derivative $\d f(x) \in\mathcal{B}(\R^n,\R)$ exists at each $\mathbf{x}\in U$. The Banach space $\mathcal{B}(\R^n,\R)$ is the dual space space of $\R^n$, which by the Riesz representation theorem is isomorphic to $\R^n$. This means that for each $L\in\mathcal{B}(\R^n,\R)$ there is a unique $\mathbf{u}\in\R^n$ such that $L(\mathbf{v}) = \braket{\mathbf{u},\mathbf{v}} = \mathbf{u}^\top \mathbf{v}$.

The derivative $\d f(\mathbf{x})$ can thus be represented as a row vector, which in the standard basis of $\R^n$ is

$$
  \d f(x) = [\d_i f(\mathbf{x})]_{i=1}^n
$$

where $\d_i f(\mathbf{x}) = \d f(\mathbf{x})\mathbf{e}_i \in \R$ for $i=1,\dots,n$ are the partial derivative.

Suppose $f$ is twice differentiable on $U$, i.e. $\d^2 f(x) \in\mathcal{B}^2 (\R^n,\R)$ exists at each $\mathbf{x}\in U$. Since $\mathcal{B}(\R^2,\R) = \mathcal{B}(\R^n,\mathcal{B}(\R^n,\R)) = \mathcal{B}(\R^n,(\R^n)^*)$, the directional derivative of $\d f(x)$ in the direction $\mathbb{u}\in\R^n$, i.e. $\d^2 f(\mathbf{x})(\mathbf{u})\in(\R^n)^*$, is a row vector. Applying Proposition $\ref{proposition-33}$, gives the matrix form $\d^2 f(\mathbf{x})(\mathbf{u}) = \mathbf{u}^\top \mathbf{H}^\top (\mathbf{x})$, where $H(\mathbf{x})$ is the Hessian matrix of $f$ at $\mathbf{x}$

$$
\begin{align*}
  H(\mathbf{x}) =& \d \begin{bmatrix} \d_1 f(\mathbf{x}) & \cdots & \d_n \mathbf{x} \end{bmatrix}^\top \\
  =& \begin{bmatrix} 
    \d_1 \d_1 f(\mathbf{x}) & \cdots & \d_n \d_1 f(\mathbf{x}) \\ 
    \vdots & \ddots & \vdots \\
    \d_1 \d_n f(\mathbf{x}) & \cdots & \d_n \d_n f(\mathbf{x})  
  \end{bmatrix}
\end{align*}
$$

so that

$$
  \d^2 f(\mathbf{x})(\mathbf{u})(\mathbf{v}) = \mathbf{u}^\top H^\top \mathbf{v} \in\R,\; \mathbf{u},\mathbf{v}\in\R^n
$$

From $\d^2 f(\mathbf{x})(\mathbf{u})(\mathbf{v}) = \mathbf{u}^\top H^\top \mathbf{v} = \mathbf{v}^\top H \mathbf{v}$, we see that $\d^2 f(\mathbf{x}):\R^n \times \R^n \to \R$ is a bilinear map. 
</MathBox>

<MathBox title='Higher order directional derivatives' boxType='example'>
For an open subset $U\subseteq\mathbb{F}^n$ and a $k$ times continuously differentiable function $f\in C^k (U,\mathbb{F}^m)$, the derivative $\d^k f(\mathbf{x})\in \mathcal{B}^k (\mathbb{F}^n,\mathbb{F}^m)$ is a multilinear map $\d^k f(\mathbf{x}): \prod_{i=1}^k \mathbb{F}^n \to \mathbb{F}^n$. The $k$-th directional derivative of $f$ at $\mathbf{x}\in U$ in the direction $\mathbf{v}\in\mathbb{F}^n$ is defined as

$$
  \d_\mathbf{v}^k f(\mathbf{x}) = \d^k f(\mathbf{x})(\mathbf{v},\dots,\mathbf{v})
$$

A vector in $\mathbb{F}^n$ takes the form $\mathbf{v} = \sum_{i=1}^n v_i \mathbf{e}_i \in\mathbb{F}^n$ in standard coordinates. The first-order directional derivative of $f$ at $\mathbf{x}$ in the direction $\mathbf{v}$ is the vector

$$
  \d f(\mathbf{x})\mathbf{x} = \begin{bmatrix} \d_1 f(\mathbf{x}) & \cdots & \d_n f(\mathbf{x}) \end{bmatrix} \mathbf{v} = \sum_{j=1}^n \d_j f(\mathbf{x})v_j \in \mathbb{F}^m
$$

The second-order directional derivative of $f$ at $\mathbf{x}$ in the direction $\mathbf{v}$ is 

$$
\begin{align*}
  \d_\mathbf{v}^2 f(\mathbf{x}) =& \d_\mathbf{v} \sum_{j=1}^n \d_j f(\mathbf{x})v_j \\
  =& \sum_{i=1}^n \sum_{j=1}^n \d_i \d_j f(\mathbf{x})v_i v_j \\
  =& \mathbf{v}^\top H(\mathbf{x})\mathbf{v}
\end{align*}
$$

where $H(\mathbf{x})$ is the Hessian of $f$ at $\mathbf{x}$. Inductively, the $k$th order direction derviative of $f$ at $\mathbf{x}$ in the direction $\mathbf{v}$ is

$$
  \d_\mathbf{v}^k f(\mathbf{x}) = \sum_{i_1,\dots, i_k = 1}^n \d_{i_1} \cdots \d_{i_k} f(\mathbf{x})v_{i_1} \cdots v_{i_k}
$$

Combining the mixed terms gives

$$
  \d_\mathbf{v}^k f(\mathbf{x}) = \sum_{j_1 +\cdots+ j_n = k} \frac{k!}{j_1!\cdots j_n!} \d_1^{j_1} \cdots \d_n^{j_n} f(\mathbf{x}) v_1^{j_1} \cdots v_n^{j_n}
$$

The $k$-th order directional derivative of $f$ at $\mathbf{x}\in$ along $\mathbf{v}$ is also written $\d^k f(\mathbf{x}) \mathbf{v}^{(k)}$ where $\mathbf{v}^{(k)} \in X^k$
</MathBox>

## Gâteaux derivative

<MathBox title='Gâteaux derivative' boxType='definition'>
Let $X$ and $Y$ be locally convex topological vector spaces. A function $f: X \to Y$ is Gâteaux differentiable at $x\in X$ in the direction $h\in X$ if the following limit exists

$$
  \D f(x; z) = \lim_{\tau\to 0} \frac{f(x + \tau v) - f(x)}{\tau} = \left.\frac{\d}{\d\tau} f(x + \tau v)\right|_{\tau=0}
$$

This limit is called the *Gâteaux differential* of $f$ at $x$ in the direction $v$. If the limit exists for all $v\in X$, then $f$ is Gâteaux differentiable at $x$. 

If the Gâteaux differential $\D f(x; \cdot): X\to Y$ is linear and continuous, i.e. there is a linear map $A\in\mathcal{L}(X,Y)$ with $\D f(x; h) = Ah$ for all $h\in X$, then $A$ is called the *Gâteaux derivative* of $F$ at $x$, denoted $\D f(x) = A$.

If $f$ is $n$-times Gâteaux differentiable at $x$, the $n$-th order Gâteaux differential in iterated directions $h_1,\dots,h_n \in X$ is defined recursively as 

$$
  \D^n f(x; h_1,\dots,h_n) = \D(\D^{n-1} f)(x; h_1,\dots,h_{n-1};h_n)
$$

The $n$-th order Gâteaux derivative of $f$ at $x$ in the direction $h\in X$ is defined recursively as

$$
\begin{align*}
  \D^n f(x; h) :=& \lim_{\tau\to 0} \frac{\D^{n-1} f(x + \tau h; h) - \D^{n-1} f(x; h)}{\tau^n} \\
  =& \left.\frac{\d^n}{\d\tau^n} f(x + \tau h) \right|_{\tau=0}
\end{align*}
$$
</MathBox>

<MathBox title='Gâteaux derivatives are homogeneous' boxType='definition'>
Let $X$ and $Y$ be locally convex topological vector spaces. If a function $f: X \to Y$ is Gâteaux differentiable at $x\in X$, i.e. $\D f(x)$ exists, then for all $\alpha\in\mathbb{F}$

$$
  \D f(x; \alpha h) = \alpha \D f(x; \alpha)
$$

<details>
<summary>Proof</summary>

From the definition of $\D f(x; h)$

$$
\begin{align*}
  \D f(x; \alpha h) =& \lim_{\tau\to 0} \frac{f(x + \tau(\alpha h)) - f(x)}{\tau} \\
  =& \alpha \lim_{\tau\to 0} \frac{f(x + \tau\alpha h) - f(x)}{\alpha\tau} \\
  =& \alpha \D f(x; h)
\end{align*}
$$
</details>
</MathBox>

<MathBox title='Fréchet differentiability implies Gâteaux differentiability' boxType='proposition'>
Let $X, Y$ be normed spaces. If $f:X\to Y$ is Fréchet differentiable at $x\in X$, then $f$ is Gâteaux differentiable at $x$. In this case $\d f(x) = \D f(x)$, where $\d f(x)$ is the Fréchet derivative of $f$ at $x$ and $\D f(x)$ is the Gâteaux derivative of $f$ at $x$.

<details>
<summary>Proof</summary>

Because $f: X\to Y$ is a Fréchet differentiable at $x\in X$, we have

$$
  f(x + h) = f(x) + \d f(x) h + o(h)
$$

For any $v\in X$, the Gâteaux differential limit at $x$ is

$$
  \lim_{t\to 0} \frac{f(x + tv) - f(x)}{t}
$$

Inserting the Fréchet differentiability condition with $h = tv$, we get

$$
\begin{align*}
  \lim_{t\to 0} \frac{\d f(x)(tv) + o(\lVert tv \rVert)}{t} =& \lim_{t\to 0} \frac{t \d f(x)(v) + o(\lVert tv \rVert)}{t} \\
  =& \d f(x)(v) + \lim_{t\to 0} \frac{o(|t|\cdot\lVert v \rVert)}{t} \\
  =& \d f(x)(v)
\end{align*}
$$

Hence, 

$$
  \lim_{t\to 0} \frac{f(x + tv) - f(x)}{t} = \d f(x)(v),\; \forall v\in X
$$

showing that the Gâteaux differential of $f$ at $x$ in the direction $v$ equals the Fréchet differential of $f$ at $x$. Since the Fréchet derivative $\d f(x) \in \mathcal{B}(X,Y)$ is a bounded linear operator, it follows that $f$ is Gâteaux differentiable at $x$ with Gâteaux derivative $\D f(x) = \d f(x)$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $X$ and $Y$ be normed spaces. If $f:U\subseteq X\to Y$ is Gâteaux differentiable such that the Gâteaux derivative is continuously linear, i.e. $\D f \in C(U, \mathcal{L}(X,Y))$, then $f\in C^1 (U, Y)$ and $\d f = \D f$, where $\d f$ is the Fréchet derivative of $f$.

<details>
<summary>Proof</summary>

Assume $g(t) := f(x + th)$ is in $C^1 ([0,1], Y)$ for $h\in U$ with sufficiently small norm. Moreover, by definition we have

$$
  \dot{g}(t) := \frac{\d}{\d t} g(t) = \D f(x + th)h 
$$

Using the fundamental theorem of calculus, we obtain

$$
\begin{align*}
  f(x + h) - f(x) =& g(1) - g(0) = \int_0^1 \dot{g}(t)\;\d t \\
  =& \int_^1 \D f(x + th)h\;\d t \\
  =& \left(\int_0^1 \D f(x + th)\;\d t \right)h
\end{align*}
$$

where the last equality follows from continuity of the integral since it clearly holds for simple functions. Consequently

$$
\begin{align*}
  |f(x + h) - f(x) - \delta f(x)h| = \left|\left(\int_0^1 (\D f(x + th) - \D f(x))\;\d t \right)h \right| \\
  \leq& \left(\int_0^1 \lVert \D f(x + th) - \D f(x) \rVert\;\d t \right)|h| \\
  \leq& \max_{t\in[0,1]} \lVert \D f(x + th) - \D f(x) \rVert\cdot|h|
\end{align*}
$$

By continuity of $\D f$, the right-hand side is $o(h)$ as required.
</details>
</MathBox>

<MathBox title='Gâteaux mean value theorem' boxType='theorem'>
Let $X$ and $Y$ be normed space and suppose $f:X\to Y$ is Gâteaux differentiable on $X$. If $X$ is convex then for $x, y\in X$

$$
\begin{gather*}
  \lVert f(x) - f(y) \rVert_Y \leq M \lVert x - y \rVert_X \\
  M := \sup{t\in[0,1]} \Set{\D f((1 - t)x + ty), \frac{x - y}{\lVert x - y \rVert_X}}
\end{gather*}
$$

Converserly, if 

$$
  \lVert f(x) - f(y) \rVert_Y \leq M \lVert x - y \rVert_X
$$

then

$$
  \sup_{x\in X, \lVert e\rVert_X} \lVert \D f(x; e) \rVert \leq M
$$

<details>
<summary>Proof</summary>

Define $g(t) = f((1 - t)x + ty)$ with $\D f(t) = \delta g(t) = \delta f((1 - t)x + ty;y - x)$ for $t\in[0,1]$. This implies $\lVert \d g(t) \rVert \leq \tilde{M} := M\lVert x - y \rVert$ by homogeneity of the Gâteaux derivative.  
</details>
</MathBox>

## Taylor's theorem

<MathBox title="Taylor's theorem" boxType='theorem'>
Let $X$ and $Y$ be normed spaces. If $f \in C^k (U,Y)$ is a $k$ times differentiable function on an open subset $U\subseteq X$, then for all $x\in U$ and $h\in X$ such that the line segment $\ell(x,x+h) = \Set{(1-t)x + th | t\in[0,1]}$ lies in $U$, then

$$
\begin{align*}
  f(x + h) =& R_k + \sum_{i=1}^k \frac{\d_h^{k-1} f(x)}{(k-1)!} \\
  =& R_k + \sum_{i=1}^k \frac{\d^{k-1} f(x)h^{(k-1)}}{(k-1)!}
\end{align*}
$$

where $h^{(k) \in X^k}$, and the remainder $R_k$ is given by the integral form

$$
  R_k (x,h) \equiv o(|h|^k) = \int_0^1 \frac{(1 - t)^{k-1}}{(k-1)!}\d^k f(x + th)h^{(k)}\;\d t
$$

Expressing $R_k$ as $o(|h|^k)$ is called the *Peano form* of the remainder.

<details>
<summary>Proof</summary>

We use proof by induction. In the base case $k = 0$, assume $g(t) := f(x + th)$ is in $C^1 ([0,1], Y)$ for $h\in U$ with sufficiently small norm. Moreover, by definition we have

$$
  \dot{g}(t) := \frac{\d}{\d t} g(t) = \D f(x + th)h 
$$

Using the fundamental theorem of calculus, we obtain

$$
\begin{align*}
  f(x + h) - f(x) =& g(1) - g(0) = \int_0^1 \dot{g}(t)\;\d t \\
  =& \int_^1 \D f(x + th)h\;\d t \\
  =& \left(\int_0^1 \D f(x + th)\;\d t \right)h
\end{align*}
$$

For the induction step, we use integration by parts. Let $f_j \in C^1 ([0,1], X_j)$ for $j=1,2$ and suppose $L\in\mathcal{L}^2 (X_1 \times X_2, Y)$ is bilinear. Applying the fundamental theorem of calculus on the bilinear product rule (Proposition $\ref{proposition-43}$) we get

$$
\begin{align*}
  \int_0^1 L(\dot{f}_1 (t), f_2 (t))\;\d t =& L(f_1 (1), f_2 (1)) - L(f_1 (0), f_2 (0)) \\
  &- \int_0^1 L(f_1 (t), \dot{f}_2 (t))\;\d t
\end{align*}
$$

Applying by parts with with $L(y,t) = ty$, $f_1 (t) = \d^k f(x + ht)$ and $f_2 (t) = \frac{(1 - t)^{k}}{(k!)}$ establishes the induction step.

To show the Peano form for the remainder we estimate

$$
\begin{align*}
  &\left| \int_0^1 \frac{(1 - t)^{k-1}}{(k-1)!}\d_h^k f(x + th)\;\d t - \frac{1}{k!} \d^k f(x) \right|h^{k} \\
  &\leq \frac{|h|^k}{(k - 1)!} \int_0^1 (1 - t)^{k-1} \lVert \d^k f(x + th) - d^k f(x) \rVert\;\d t \\
  &\leq \frac{|h|^k}{k!} \sup_{t\in[0,1]} \lVert \d^k f(x + th) - d^k f(x) \rVert
\end{align*}
$$
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
Let $X$ and $Y$ be normed spaces. If $f \in C^k (U,Y)$ is a $k$ times differentiable function on an open subset $U\subseteq X$, then for all $x\in U$ and $h\in X$
</MathBox>

<MathBox title='Upper bound for the Taylor remainders' boxType='corollary'>
If $\lVert \d^k (fx + th) \rVert < M$ for all $t\in[0,1]$, then

$$
  \lVert R_k \rVert_Y \leq \frac{M}{k!} \lVert h \rVert_X^k
$$
</MathBox>

## Banach-valued integrals

### Integrals of step function

<MathBox title='Step function' boxType='definition'>
Let $X$ be a Banach space. A function $f:[a,b]\subset\R\to X$ is a step function if there exists finitely many $t_0,\dots,t_N \in [a,b]$ and finitely many $x_1,\dots,x_N \in X$ such that $a = t_0 < \cdots < t_N = b$ and

$$
  f = \left( \sum_{i=1}^{N-1} x_i \chi_{[t_{i-1}, t_i)} \right) + x_N \chi_{[t_{N-1},t_N]}
$$

where $\chi$ is the characteristic function. The set of all step functions from $[a,b]$ to $X$ is denoted $S([a,b], X)$.
</MathBox>

<MathBox title='' boxType='proposition' tag='proposition-52'>
Let $X$ be a Banach space. The set $S([a,b], X)$ is a subspace of $(L^\infty ([a,b], X), \lVert\cdot\rVert_\infty)$.

<details>
<summary>Proof</summary>

For $f\in S([a,b], X)$ we have

$$
  \lVert f \rVert_\infty = \sup\Set{\lVert x_i \rVert}_{i=1}^N < \infty
$$

It remains to show that $S([a,b], X)$ is closed under linear combinations. For $f,g \in S([a,b],X)$ we have

$$
\begin{align*}
  f =& \left(\sum_{i=1}^{N-1} x_i \chi_{[t_{i-1}, t)} \right) + x_N \chi_{[t_[N-1], t_N]} \\
  g =& \left(\sum_{i=1}^{M-1} y_i \chi_{[s_{i-1}, s)} \right) + y_M \chi_{[s_[M-1], s_M]}
\end{align*}
$$

where both $\Set{t_0,\dots,t_N}$ and $\Set{s_0,\dots,s_M}$ define disjoint partitions of $[a,b]$. Taking the ordered union $\Set{u_0,\dots,u_L} = \Set{t_0,\dots,t_N}\cup\Set{s_0,\dots,s_M}$, then there exists $x'_i, y'_i \in X$ for $i = 1,\dots,L$ such that

$$
\begin{align*}
  f =& \left(\sum_{i=1}^{L-1} x'_i \chi_{[u_{i-1}, u)} \right) + x'_L \chi_{[u_[L-1], u_L]} \\
  g =& \left(\sum_{i=1}^{L-1} y'_i \chi_{[u_{i-1}, u)} \right) + y'_L \chi_{[u_[L-1], u_L]}
\end{align*}
$$

Thus, for scalars $\alpha, \beta\in\mathbb{F}$ we get

$$
  \alpha f + \beta g = \left(\sum_{i=1}^{L-1} (\alpha x'_i + \beta y'_i) \chi_{[u_{i-1}, u)} \right) + (\alpha x'_L + \beta y'_L) \chi_{[u_[L-1], u_L]} \in S([a,b], X)
$$
</details>
</MathBox>

<MathBox title='Regulated integral of step functions' boxType='definition'>
Let $X$ be a Banach space. The integral $I(f)$ of a step function $f\in S([a,b], X)$ is defined as

$$
  I(f) = \sum_{i=1}^N x_i (t_i - t_{i-1}) = \int_a^b f(t)\;\d t \in X
$$

The integral defines a function $I:S([a,b],X)\to X$.
</MathBox>

<MathBox title='Integral of step functions is a bounded linear operator' boxType='proposition' tag='proposition-53'>
Let $X$ be a Banach space. The integral of step functions $I:S([a,b],X)\to X$ is a bounded linear transformation with $\lVert I \rVert = b - a$.

<details>
<summary>Proof</summary>

Linearity of $I$ follow from the proof of Proposition $\ref{proposition-52}$ where we showed how to combine two subdivisions of $[a,b]$. For

$$
  f = \left(\sum_{i=1}^{N-1} x_i \chi_{[t_{i-1}, t_i)]}\right) + x_N \chi_{[t_{N-1}, t_N]}
$$

we have

$$
\begin{align*}
  \lVert I(f) \rVert =& \left\lVert \sum_{i=1}^N x_i (t_i - t_{i-1}) \right\rVert \\
  \leq& \sum_{i=1}^N (t_i - t_{i-1}) \lVert x_i \rVert \\
  \leq& \sum_{i=1}^N (t_i - t_{i-1}) \sup\Set{\lVert x_i \rVert}_{i=1}^N \\
  =& (b - a)\lVert f \rVert_\infty
\end{align*}
$$

This implies for all nonzero $f\in S([a,b], X)$ that

$$
  \frac{\lVert I(f) \rVert}{\lVert f \rVert_\infty} \leq b - a
$$

Thus, $\lVert I \rVert \leq b - a$. The upper bound on $\lVert I \rVert$ is realized for the function $f = \chi_[a,b] \in S([a,b], X)$ and so $\lVert I \rVert = b - a$.
</details>
</MathBox>

### Single-variable Banach-valued integral

<MathBox title='Single-variable Banach-valued integration' boxType='theorem'>
Let $X$ be a Banach space. There is a unique bounded linear extension $\overline{I}: \overline{S([a,b],X)}\to X$ of the integral operator $I:S([a,b], X)\to X$.

<details>
<summary>Proof</summary>

This follows immediately from the continuous linear extension theorem (Theorem $\ref{theorem-9}$).
</details>
</MathBox>

<MathBox title='Single-variable Banach-valued integral' boxType='definition'>
Let $X$ be a Banach space. The integral of $f\in\overline{S([a,b], X)}$ is defined by

$$
  \overline{I}(f) = \lim_{n\to\infty} I(s_n) = \lim_{n\to\infty} \int_a^b s_n (d)\;\d t
$$

where $(s_n)_{n\in\N_+}$ is a sequence of step functions converging uniformly to $f$. For every $f\in \overline{S([a,b], X)}$ we define

$$
  \int_b^a f(t)\;\d t = -\int_a^b f(t)\;\d t
$$
</MathBox>

<MathBox title='' boxType='theorem'>
Let $X$ be a Banach space. Every continuous function from $[a,b]\subset\R$ to $X$ is the uniform limit of step functions, i.e. $C([a,b],X) \subset\overline{S([a,b], X)}$.

<details>
<summary>Proof</summary>

Any $f\in C([a,b], X)$ is uniformly continuous because $[a,b]$ is compact. For $\epsilon > 0$ there is $\delta > 0$ such that $\lVert f(x) - f(y) \rVert < \epsilon$ whenever $x,y \in [a,b]$ satisfy $|x - y| < \delta$. Choose $N\in\N$ such that $(b-a)/N < \delta$. Set $t_i = a + i(b - a)/N$ for $i=0,\dots,N$. Define the step funcion $f_N \in S([a,b],X)$ by

$$
  f_N = \left(\sum_{i=1}^{N} f(t_{i-1})\chi_{[t_{i-1}, t_i)}\right) + f(t_{N-1})\chi_{[t_{N-1},t_N]}
$$

Since any $t\in [t_{i-1}, t_i)$ for $i=1,\dots,N-1$ and $t\in[t_{N-1}, t_N]$ is within $\delta$ of the endpoints, we have $\lVert f(t) - f_N (t) \lVert < \epsilon$. As this holds for all $t\in[a,b]$, we obtain $\lVert f - f_N \rVert < \epsilon$. Since $\epsilon > 0$ is arbitrary, we have that $f$ is a limit point of $S([a,b], X)$. This shows that $C([a,b],X)\subset\overline{S([a,b],X)}$.
</details>
</MathBox>

<MathBox title='Properties of single-variable Banach-valued integrals' boxType='proposition' tag='proposition-37'>
Let $X$ be a Banach space. If $f\in\overline{S([a,b],X)}$ and $\alpha,\beta,\gamma\in[a,b]$ with $\alpha < \gamma < \beta$, then
1. $\lVert \int_a^b f(t)\;\d t \rVert \leq (b-a)\lVert f\rVert_\infty$
2. $\lVert \int_a^b f(t)\;\d t \rVert \leq \int_a^b \lVert f \rVert\;\d t$
3. if $f\chi_{\alpha,\beta} \in\overline{S([a,b],X)}$, then $\int_a^b f(t)\chi_{[\alpha,\beta]}(t)\;\d t = \int_\alpha^\beta f(t)\;\d t$
4. $\int_\alpha^\beta f(t)\;\d t = \int_\alpha^\gamma f(t)\;\d t + \int_\gamma^\beta f(t)\;\d t$
5. The function $F(t) = \int_a^t f(s)\;\d s$ for $s\in[a,b]$ is continuous on $C$.

<details>
<summary>Proof</summary>

**(1):** This is a restatement of $\lVert\overline{I}\rVert = b-a$ in Proposition $\ref{proposition-53}$.

**(2):** The function $t\mapsto \lVert f(t) \rVert$ belongs to $\overline{S([a,b],X)}$, and so $\int_a^b \lVert f(t) \rVert\;\d t$ is defined.

**(3):** Let $(s_k)_{k\in\N_+}$ in $S([a,b],X)$ converge uniformly to $f\in\overline{S([a,b],X)}$. Let $I_{ab}$ be the integral on $S([a,b], X)$ and $I_{\alpha\beta}$ the integral on $S([a,b],X)$. Since $s_k \chi_{[\alpha,\beta]}$ is zero outside of $[\alpha,\beta]$, the value $I_{\alpha\beta} (s_k \chi_{[\alpha,\beta]})$ is the same as that of $I_{ab}(s_k \chi_{[\alpha,\beta]})$. Thus for each $k\in\N_+$ we have

$$
  \int_a^b s_k (t) \chi_{[\alpha,\beta]}\;\d t = \int_\alpha^\beta s_k (t)\;\d t
$$

Since $\overline{I}$ is continuous, the uniformly convergence $s_k \xrightarrow{k\to\infty} f$ implies that $\overline{I}(s_k) \xrightarrow{k\to\infty} \overline{I}(f)$ by continuity of $\overline{I}$.
</details>
</MathBox>

<MathBox title='' boxType='proposition'>
If $f\in\overline{S([a,b],\R^n)}$ is written in coordinates as $f(t) = (f_i(t))_{i=1}^n$, then $f_i \in\overline{S([a,b],\R)}$ for each $i$ and

$$
  \int_a^b f(t)\;\d t = \left(\int_a^b f_i (t)\;\d t \right)_{i=1}^n
$$

<details>
<summary>Proof</summary>

Since $\overline{I}:\overline{S([a,b],\R^n)}\to\R^n$ is continuous, we have $\overline{I}(s_k) \xrightarrow{k\to\infty} \overline{I}(f)$ whenever $s_k \xrightarrow{k\to\infty} f$ uniformly. Thus, it suffices to show that the integral can be written as stated for step function. For a step function $s(t) = (s_i(t))_{i=1}^n$ we have

$$
\begin{align*}
  \int_a^b s(t)\;\d t =& \sum_{i=1}^M s(t_i)(t_i - t_{i-1}) \\
  =& \sum_{i=1}^M (s_1 (t_i),\dots,s_n (t_i))(t_i - t_{i-1}) \\
  =& \left(\sum_{i=1}^M s_1 (t_i)(t_i - t_{i-1}),\dots,\sum_{i=1}^M s_n (t_i)(t_i - t_{i-1}) \right) \\
  =& \left(\int_a^b s_j (t)\;\d t \right)_{j=1}^n
\end{align*}
$$
</details>
</MathBox>

### Fundamental theorem of calculus

<MathBox title='Constant functions have zero derivative' boxType='proposition' tag='proposition-29'>
Let $X$ be a normed space and suppose $f \in C^1 (I, X)$ is a continuously differentiable function on an open interval $I\subseteq \R$. If $\d f(t) \equiv 0$ for all $t\in I$, then $f$ is constant.

<details>
<summary>Proof</summary>

Let $a, b \in I$ with $a < b$ and fix an arbitrary $t\in (a, b)$. By hypothesis, for all $\epsilon > 0$ there is $\delta_t > 0$ such that for all $|h| < \delta_t$ we have

$$
\begin{align*}
  \lVert f(t + h) - f(t) \rVert_X =& \lVert f(t + h) - f(t) - 0 \rVert_X \\
  =& \lVert f(t + h) - f(t) - \d f(t)h \rVert_X \leq \epsilon |h|
\end{align*}
$$

The collection of open intervals $(t - \delta_t, t + \delta_t)$ is an open covering of the compact $[a,b]$ so there is a finite subcovering $(t_i - \delta_{t_i}, t_i + \delta_{t_i})$ of $[a,b]$ for $i = 1,\dots,n$. Without loss of generality we can assume taht $a < t_1 < \cdots < t_n < b$. Choose points $x_0,\dots,x_n \in [a,b]$ so that

$$
  a = x_0 < t_1 < x_1 < \cdots < t_n < x_n = b
$$

with $|x_i - t_i| < \delta_{t_i}$ and $|x_i - t_{i-1}| < \delta_{t_i - 1}$. We then have

$$
\begin{align*}
  \lVert f(b) - f(a) \rVert_X =& \left\lVert \sum_{i=1}^n f(x_i) - f(x_{i-1}) \right\rVert_X \\
  =& \left\lVert \sum_{i=1}^n (f(x_i) - f(t_i)) + (f(t_i) - f(x_{i-1})) \right\rVert_X \\
  \tleq& \sum_{i=1}^n \lVert f(x_i) - f(t_i) \rVert_X + \sum_{i=1}^n \lVert f(t_i) - f(x_{i-1}) \rVert_X \\
  \leq& \sum_{i=1}^n \epsilon((x_i - t_i) + (t_i - x_{i-1})) \\
  =& \epsilon(b - a)
\end{align*}
$$

Since $\epsilon > 0$ is arbitrary, if follows that $f$ is constant on $(a, b)$. Furthermore, $f$ is constant on $I$ because $a, b \in I$ with $a < b$ are arbitrary.
</details>
</MathBox>

<MathBox title='Fundamental theorem of calculus' boxType='theorem'>
Let $X$ be a normed space.
1. If $f\in C([a,b], X)$ is continuous on $[a,b]$, then $t \mapsto \int_a^t f(s)\;\d s$ is differentiable on $(a,b)$ and for all $t\in(a,b)$
$$
  \frac{\d}{\d t} \int_a^t f(s)\;\d s = f(t)
$$
2. If $f\in C^1((a, b), X)$ is continuously differentiable on $(a,b)$, and $\d f(t)$ extends to a continuous function on $[a,b]$, then
$$
  \int_a^b \d f(s)\;\d s = f(b) - f(a)
$$

<details>
<summary>Proof</summary>

**(1):** By Proposition $\ref{proposition-14}$, the function $f$ is uniformly continuous since $f$ is continuous on the compact interval $[a,b]$. Consequently, for every $\epsilon > 0$ there is $\delta > 0$ such that for all $t\in[a,b]$ and all $|h| < \delta$ with $t + h\in[a,b]$

$$
  \lVert f(t + h) - f(t) \rVert_X < \epsilon
$$

From the properties of univariate Banach-valued integral (Proposition $\ref{proposition-37}$)

$$
\begin{align*}
  &\left\lVert \int_a^{t+h} f(x)\;\d s - \int_a^t f(s)\;\d s - f(t)h \right\rVert_X \\
  &= \left\lVert \int_t^{t+h} f(s)\;\d s - f(t)h \right\rVert_X \\
  &= \left\lVert \int_t^{t+h} (f(s) - f(t))\;\d s \right\rVert_X \\
  &\leq \left| \int_t^{t+h} \lVert f(s) - f(t) \rVert_X \;\d s \right| \\
  \leq& \left| \int_t^{t+h} \epsilon\;\d s \right| \\
  &= \epsilon |h|
\end{align*}
$$

This shows that $\int_a^t f(s)\;\d s$ is a differentiable function of $t$ on $(a,b)$, whose derivative is $f(t)$.

**(2):** By hypothesis
- the function $s\mapsto \d f(s)$ from $[a,b]$ to $X$ is continuous
- the function $f:[a,b]\to X$ is continuous

Then the function $G:[a,b]\to X$ defined by

$$
  g(t) = \int_a^t \d f(s)\;\d s - f(t)
$$

is continuous on $[a,b]$ by Proposition $\ref{proposition-29}$, and $g$ is differentiable on $(a,b)$ by part **(1)**. Applying **(1)** we have for $t\in(a,b)$ that

$$
  \d g(t) = \frac{\d}{\d t} \left[\int_a^t \d f(s)\;\d s - f(t) \right] = \d f(t) - \d f(t) = 0
$$

By Proposition $\ref{proposition-29}$, it follows that $g$ is constant on $[a,b]$. Since

$$
\begin{align*}
  g(a) =& \int_a^a \d f(s)\;\d s - f(a) = -f(a) \\
  g(b) =& \int_a^b \d f(s)\;\d s - f(b)
\end{align*}
$$

the equality $g(a) = g(b)$ implies

$$
  \int_a^b \d f(s)\;\d s = f(b) - f(a)
$$
</details>
</MathBox>

<MathBox title='Integral mean value theorem' boxType='theorem'>
Let $X, Y$ be normed spaces. If $f\in C^1 (X,Y)$ is continuous differentiable on $X$, and for $x_0, x_1$ the line segment $\ell (x_0, x_1) = \Set{(1-t)x_1 + (1 - t)x_0 | t\in [0,1]}$ lies entirely in $X$, then

$$
  f(x_1) - f(x_0) = \int_0^1 \d f (tx + (1 - t)x_0)(x_1 - x_0)\;\d t
$$

Alternatively, with $h = x_1 - x_0$

$$
  f(x_0 + h) - f(x_0) = \int_0^1 \d f(x_0 + th)h\;\d t
$$

Moreover,

$$
  \lVert f(x_1) - f(x_0) \rVert_Y \leq \sup_{c\in\ell(x_0,x_1)} \lVert \d f(c) \rVert\cdot\lVert x_1 - x_0 \rVert
$$
</MathBox>

<MathBox title='Change of variables formula' boxType='theorem'>
Let $X$ be a normed space and $f\in C([a,b], X)$ a continuous function on $[a,b]$. If $g:[c,d]\to[a,b]$ is continuous with $g$ continuously differentiable on $(c, d)$ and $\d g$ continuously extendable to $[c,d]$, then

$$
  \int_c^d f(g(s))\;\d g(s)\;\d s = \int_{g(c)}^{g(d)} f(t)\;\d t
$$
</MathBox>

### Uniform convergence and derivatives

<MathBox title='' boxType='definition'>
Let $X$ and $Y$ be Banach spaces. We say that a sequence $(f_n)_{n\in\N_+}$ in $C(X,Y)$
1. is Cauchy in $C(X, Y)$ if for every compact $K\subset U$, the sequence $(f_n |_K )_{n\in\N_+}$ is Cauchy in $(C(K,Y),\lVert\cdot\rVert_\infty)$ and
2. converges uniformly on compact subsets of $X$ to $f\in C(X,Y)$ if for every compact $K\subset U$, the sequence $(f_n |_K)_{n\in\N_+}$ converges to $f|_K$ in $(C(K,Y),\lVert\cdot\rVert_\infty)$.

Note that a Cauchy sequence $(g_n)_{n\in\N_+}$ in $(C(K,Y),\lVert\cdot\rVert_\infty)$ converges uniformly to a unique $g\in C(K,Y)$ because $(C(K,Y), \lVert\cdot\rVert_\infty)$ is a Banach space. 
</MathBox>

<MathBox title='' boxType='proposition'>
Let $X$ and $Y$ be finite-dimensional Banach spaces, and $U = B(x_*, r) \subset X$ an open set for $x_* \in X$ and $r > 0$. For a sequence $(f_n)_{n\in\N_+} \in C^1 (U,Y)$, if
1. $(f_n (x_*))_{n\in\N_+}$ converges in $Y$ and
2. $(\d f_n)_{n\in\N_+}$ converges uniformly on compact subsets of $U$ to $g\in C(U,\mathcal{B}(X,Y))$,

then $(f_n)_{n\in\N_+}$ converges uniformly on compact subsets of $U$ to $f\in C^1 (U,Y)$ for which $\d f = g$.

<details>
<summary>Proof</summary>

By hypothesis, the sequence $(f_n (x_*))_{n\in\N_+}$ converges to, say $z\in Y$. For each $x\in B(x_*, r) = U$ set $h = x - x_*$. A candidate for the limit function $f\in C(U,Y)$ is

$$
  f(x) = z + \int_0^1 g(x_* + th)h\;\d t
$$

where $g\in C(U,\mathcal{B}(X,Y))$ is what $(\d f_n)_{n\in\N_+}$ converges uniformly on compact sets by hypothesis.

Since $U = B(x_*, r)$ is convex, the function $g(x_* + th)$ is defined for all $t\in[0,1]$. When $h = 0$, i.e. $x = x_*$, then

$$
  f(x_*) = z + \int_0^1 g(x_* + t0)0\;\d t = z = \lim_{n\to\infyt} f_n (x_*)
$$

We show that $(f_n)_{n\in\N_+}$ converges uniformly on compact subsets of $B(x_*, r)$. It suffices to show uniform convergence on the arbitrary compact set $K = \overline{B(x_*, \rho)}\subset U$, i.e. $0 < \rho < r$. On $K$ we have, by applying the mean value theorem to $f_n$ and using the definition of $f$ that

$$
\begin{align*}
  &\lVert f_n (x) - f(x) \rVert_Y \\
  =& \left\lVert f_n (x_*) + \int_0^1 \d f_n (x_* + th)h\;\d - z - \int_0^1 g(x_* + th)h\;\d t \right\rVert_Y \\
  \leq& \lVert f_n (x_*) - z \rVert_Y + \left\lVert \int_0^1 (\d f_n (x_* + th) - g(x_* + th))h\;\d t \right\rVert_Y \\
  \leq& \lVert f_n (x_*) - z \rVert_Y + \sup_{c\in K} \lVert \d f_n (c) - g(c) \rVert_{X\to Y} \lVert h \rVert_X
\end{align*}
$$

Since $f_n (x_*) \to z$, for $\epsilon > 0$ there is $N\in\N$ such that for all $n\geq N$ we have

$$
  \lVert f_n (x_*) - z \rVert_Y < \frac{\epsilon}{2}
$$

and since $\d f_n \xrightarrow{n\to\infty} g$ uniformly on the compact $K$, there is M \geq N$ such that for $n\geq M$ we have

$$
  \sup_{c\in K} \lVert \d f_n (c) - g(c) \rVert_Y < \frac{\epsilon}{2r}
$$

Thus, for all a$n\geq M$, and with $\lVert h \rVert_X$, we have

$$
  \lVert f_n (x) - f(x) \rVert_Y < \frac{\epsilon}{2} + \frac{\epsilon}{2r}r = \epsilon
$$

The choice of $N$ and $M$ is independent of the point $x\in K$ chosen, so for all $n\geq N$ we have

$$
  \lVert f_n - f\rVert_\infty = \sup_{x\in K} \lVert f_n (x) - f(x) \rVert_Y \leq \epsilon
$$

Thus, $f_n \xrightarrow{n\to\infty} f$ uniformly on the compact $K$. 

Finally, we show that $\d f(x) = g(x)$ for all $x\in U$. For a fixed $x\in B(x_*, r) = U$, there is $a > 0$ such that $K = \overline{B(x,a)}\subset U$. For $\lVert h \rVert_X \leq a$ we have by the integral mean value theorem that

$$
  f_n (x + h) - f_n (x) = \int_0^1 \d f_n (x + th)h\;\d t
$$

The left-hand side of this converges uniformly on the compact set $K$ to $f(x + h)  - f(x)$, while the integrand on the right-hand side converges uniformly on $K$ to $g(x + th)h$. By commutativity of integration with uniform limits, we get

$$
\begin{align*}
  f(x + h) - f(x) =& \lim_{n\to\infty} (f_n (x + h) - f_n (x)) \\
  =& \lim_{n\to\infty} \int_0^1 \d f_n (x + th)h\;\d t \\
  =& \int_0^1 \lim_{n\to\infty} \d f_n (x + th)h\;\d t \\
  =& \int_0^1 g(x + th)h\;\d t
\end{align*}
$$

Hence,

$$
\begin{align*}
  \lvert f(x + h) - f(x) - g(x)h \rVert =& \left\lVert \int_0^1 (g(x + th)h - g(x)h)\;\d t \right\rVert_Y \\
  =& \left\lVert \int_0^1 (g(x + h) - g(x))h\;\d t \right\rVert_Y
\end{align*}
$$

Continuity of $g$ on the compact $K = \overline{B(x,a)}$ implies $g$ is uniformly continuous on $K$. For $\epsilon > 0 $ there is $0 < \delta < a$ such that for all $|h|_X < \delta$

$$
  \lVert g(x + h) - g(x)\rVert_{X\to Y} < \epsilon
$$

We thus arrive at

$$
  \lVert f(x + h) - f(x) - g(x)h \rVert_Y \leq \epsilon\lVert h \rVert_X
$$

This shows that $f$ is differentiable at $x$ with derivative $\d f(x) = g(x)$.
</details>
</MathBox>
